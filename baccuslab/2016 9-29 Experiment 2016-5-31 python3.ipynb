{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install GPy (pip install GPy) to fit the GP regression nonlinearity.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.io\n",
    "import itertools\n",
    "import os\n",
    "import h5py\n",
    "import pyret.visualizations as pyviz\n",
    "import pyret.filtertools as ft\n",
    "import pyret.spiketools as st\n",
    "import pyret.stimulustools as stimtools\n",
    "from pyret.spiketools import binspikes\n",
    "import jetpack\n",
    "from jetpack.timepiece import hrtime\n",
    "from experiments.iotools import read_channel # from niru-analysis github\n",
    "from experiments.photodiode import find_peaks, find_start_times\n",
    "# import binary     # in igor >> recording\n",
    "import pdb\n",
    "import string\n",
    "# from jetpack.signals import peakdet\n",
    "from scipy.signal import find_peaks_cwt\n",
    "from os.path import expanduser\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the\n",
    "# notebook rather than in a new window.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import plot, xlabel, ylabel, title, imshow\n",
    "\n",
    "# note that nonposx(y) for log plots will no longer work with this package\n",
    "import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "rcParams['image.interpolation'] = 'nearest'\n",
    "rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiment directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_dir = '/Users/lmcintosh/experiments/data/16-05-31/'\n",
    "# stim_dir = '/Users/lmcintosh/experiments/data/16-05-31/stimulus/'\n",
    "data_dir = '/Volumes/group/baccus/Lane/2016-05-31/'\n",
    "stim_dir = '/Volumes/group/baccus/Lane/2016-05-31/stimulus/'\n",
    "stimulus_filename = 'stimulus.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = sorted(os.listdir(data_dir))\n",
    "fs = [f for f in fs if f.endswith(\".txt\")]\n",
    "\n",
    "cells = []\n",
    "for f in fs:\n",
    "    text_file = open(data_dir + f, \"r\")\n",
    "    spikes = text_file.read().split('\\n')\n",
    "    cells.append([float(spike) for spike in spikes if (not (not spike)) and float(spike) > 0])\n",
    "    \n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['expt1',\n",
       " 'expt10',\n",
       " 'expt100',\n",
       " 'expt101',\n",
       " 'expt102',\n",
       " 'expt103',\n",
       " 'expt104',\n",
       " 'expt105',\n",
       " 'expt106',\n",
       " 'expt107',\n",
       " 'expt108',\n",
       " 'expt109',\n",
       " 'expt11',\n",
       " 'expt110',\n",
       " 'expt111',\n",
       " 'expt112',\n",
       " 'expt113',\n",
       " 'expt114',\n",
       " 'expt115',\n",
       " 'expt116',\n",
       " 'expt117',\n",
       " 'expt118',\n",
       " 'expt119',\n",
       " 'expt12',\n",
       " 'expt120',\n",
       " 'expt121',\n",
       " 'expt122',\n",
       " 'expt123',\n",
       " 'expt124',\n",
       " 'expt125',\n",
       " 'expt126',\n",
       " 'expt127',\n",
       " 'expt128',\n",
       " 'expt13',\n",
       " 'expt14',\n",
       " 'expt15',\n",
       " 'expt16',\n",
       " 'expt17',\n",
       " 'expt18',\n",
       " 'expt19',\n",
       " 'expt2',\n",
       " 'expt20',\n",
       " 'expt21',\n",
       " 'expt22',\n",
       " 'expt23',\n",
       " 'expt24',\n",
       " 'expt25',\n",
       " 'expt26',\n",
       " 'expt27',\n",
       " 'expt28',\n",
       " 'expt29',\n",
       " 'expt3',\n",
       " 'expt30',\n",
       " 'expt31',\n",
       " 'expt32',\n",
       " 'expt33',\n",
       " 'expt34',\n",
       " 'expt35',\n",
       " 'expt36',\n",
       " 'expt37',\n",
       " 'expt38',\n",
       " 'expt39',\n",
       " 'expt4',\n",
       " 'expt40',\n",
       " 'expt41',\n",
       " 'expt42',\n",
       " 'expt43',\n",
       " 'expt44',\n",
       " 'expt45',\n",
       " 'expt46',\n",
       " 'expt47',\n",
       " 'expt48',\n",
       " 'expt49',\n",
       " 'expt5',\n",
       " 'expt50',\n",
       " 'expt51',\n",
       " 'expt52',\n",
       " 'expt53',\n",
       " 'expt54',\n",
       " 'expt55',\n",
       " 'expt56',\n",
       " 'expt57',\n",
       " 'expt58',\n",
       " 'expt59',\n",
       " 'expt6',\n",
       " 'expt60',\n",
       " 'expt61',\n",
       " 'expt62',\n",
       " 'expt63',\n",
       " 'expt64',\n",
       " 'expt65',\n",
       " 'expt66',\n",
       " 'expt67',\n",
       " 'expt68',\n",
       " 'expt69',\n",
       " 'expt7',\n",
       " 'expt70',\n",
       " 'expt71',\n",
       " 'expt72',\n",
       " 'expt73',\n",
       " 'expt74',\n",
       " 'expt75',\n",
       " 'expt76',\n",
       " 'expt77',\n",
       " 'expt78',\n",
       " 'expt79',\n",
       " 'expt8',\n",
       " 'expt80',\n",
       " 'expt81',\n",
       " 'expt82',\n",
       " 'expt83',\n",
       " 'expt84',\n",
       " 'expt85',\n",
       " 'expt86',\n",
       " 'expt87',\n",
       " 'expt88',\n",
       " 'expt89',\n",
       " 'expt9',\n",
       " 'expt90',\n",
       " 'expt91',\n",
       " 'expt92',\n",
       " 'expt93',\n",
       " 'expt94',\n",
       " 'expt95',\n",
       " 'expt96',\n",
       " 'expt97',\n",
       " 'expt98',\n",
       " 'expt99']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File(stim_dir + stimulus_filename)\n",
    "print(len(list(f)))\n",
    "list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = h5py.File(data_dir + '16-05-31.h5')\n",
    "pd = read_channel(raw_data, channel=119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniques = np.unique(pd)\n",
    "time = np.linspace(0, len(pd)/20000., len(pd))\n",
    "timestamps = [time[i] for i,p in enumerate(pd) if p == uniques[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peaks = [t for i,t in enumerate(timestamps[1:]) if t > (timestamps[i]+5.0)]\n",
    "peaks.insert(0, timestamps[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align spikes within the experiment blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_times = peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expt_spikes = []\n",
    "for expt_id, start in enumerate(start_times):\n",
    "    expt_spikes.append([])\n",
    "    expt_name = 'expt%d' %(expt_id+1)\n",
    "    stop = f[expt_name + '/timestamps'][-1] # last timestamp, in seconds\n",
    "    for c in cells:\n",
    "        expt_spikes[-1].append([sp-start for sp in c if sp >= start and sp <= start+stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spikes_to_array(spikes):\n",
    "    '''\n",
    "    Converts a list of spike times to an array with labels for easy\n",
    "    pyret.visualizations.raster() use.\n",
    "    \n",
    "    INPUT:\n",
    "        spikes    list of list of spike times\n",
    "    '''\n",
    "    collapsed_spikes = []\n",
    "    collapsed_labels = []\n",
    "    nlists = len(spikes)\n",
    "    for idl, l in enumerate(spikes):\n",
    "        labels = idl * np.ones((len(l),))\n",
    "        collapsed_spikes.extend(l)\n",
    "        collapsed_labels.extend(labels)\n",
    "        \n",
    "    return np.array(collapsed_spikes), np.array(collapsed_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_spikes, all_labels = spikes_to_array(expt_spikes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stimulus_seq = []\n",
    "stimulus_seq.append('whitenoise')\n",
    "# 14 single trials of 5 min each (70 min total)\n",
    "for block in range(14):\n",
    "    stimulus_seq.append('naturalscene_single')\n",
    "    # 14 * 8 = 112 repeats\n",
    "    for repeat in range(8):\n",
    "        stimulus_seq.append('naturalscene_repeat')\n",
    "stimulus_seq.append('whitenoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whitenoise_test_expts = [i for i,stim_type in enumerate(stimulus_seq) if stim_type == 'whitenoise']\n",
    "naturalscene_train_expts = [i for i,stim_type in enumerate(stimulus_seq) if stim_type == 'naturalscene_single']\n",
    "naturalscene_test_expts = [i for i,stim_type in enumerate(stimulus_seq) if stim_type == 'naturalscene_repeat']\n",
    "print('# whitenoise = %i, # ns repeats = %i, # ns single trial = %i' %(len(whitenoise_test_expts),\n",
    "                                                                      len(naturalscene_test_expts),\n",
    "                                                                      len(naturalscene_train_expts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmcintosh/code/pyret/pyret/spiketools.py:141: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return np.convolve(filt, bspk, mode='full')[size:size + tax.size] / dt\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(stim_dir + stimulus_filename) as f:\n",
    "    with h5py.File('/Users/lmcintosh/experiments/data/16-05-31/naturalscene.h5', 'w') as h:\n",
    "\n",
    "        ##### spikes #####\n",
    "        ncells = len(cells)\n",
    "        for idx in range(ncells):\n",
    "            h.create_dataset('spikes/cell%02d' %(idx+1), data=np.array(cells[idx]))\n",
    "\n",
    "        ##### train #####\n",
    "        train_stimuli = []\n",
    "        train_times = []\n",
    "        train_response_binned = []\n",
    "        train_response_5ms = []\n",
    "        train_response_10ms = []\n",
    "        train_response_20ms = []\n",
    "        last_time = 0.0\n",
    "        for idx in naturalscene_train_expts:\n",
    "            expt_name = 'expt%d' %(idx+1)\n",
    "            stim = f[expt_name + '/stim']\n",
    "        #     time = f[expt_name + '/timestamps']\n",
    "            time = np.arange(0, stim.shape[0])/25.00940617\n",
    "            stimulus_upsample, time_upsample = stimtools.upsample_stim(stim, 4, time)\n",
    "            binned_spikes = []\n",
    "            response_5ms = []\n",
    "            response_10ms = []\n",
    "            response_20ms = []\n",
    "            for c in range(len(cells)):\n",
    "                bspk, tax = binspikes(expt_spikes[idx][c], binsize=0.01, time=time_upsample)\n",
    "                binned_spikes.append(bspk)\n",
    "                r5ms = st.estfr(tax, bspk, sigma=0.005) # 5 ms Gaussian\n",
    "                r10ms = st.estfr(tax, bspk, sigma=0.01) # 10 ms Gaussian\n",
    "                r20ms = st.estfr(tax, bspk, sigma=0.02) # 20 ms Gaussian\n",
    "                response_5ms.append(r5ms)\n",
    "                response_10ms.append(r10ms)\n",
    "                response_20ms.append(r20ms)\n",
    "            train_response_binned.append(np.vstack(binned_spikes))\n",
    "            train_response_5ms.append(np.vstack(response_5ms))\n",
    "            train_response_10ms.append(np.vstack(response_10ms))\n",
    "            train_response_20ms.append(np.vstack(response_20ms))\n",
    "            train_stimuli.append(stimulus_upsample[:-1])\n",
    "            train_times.append(time_upsample[:-1] + last_time)\n",
    "            last_time += time_upsample[-1]\n",
    "        # create datasets\n",
    "        h.create_dataset('train/stimulus', data=np.vstack(train_stimuli))\n",
    "        h.create_dataset('train/time', data=np.hstack(train_times))\n",
    "        h.create_dataset('train/response/binned', data=np.hstack(train_response_binned))\n",
    "        h.create_dataset('train/response/firing_rate_10ms', data=np.hstack(train_response_10ms))\n",
    "        h.create_dataset('train/response/firing_rate_20ms', data=np.hstack(train_response_20ms))\n",
    "        h.create_dataset('train/response/firing_rate_5ms', data=np.hstack(train_response_5ms))\n",
    "\n",
    "        ##### test #####\n",
    "        test_stimuli = []\n",
    "        test_times = []\n",
    "        test_response_binned = []\n",
    "        test_response_5ms = []\n",
    "        test_response_10ms = []\n",
    "        test_response_20ms = []\n",
    "        test_repeats = []\n",
    "        for repeat, idx in enumerate(naturalscene_test_expts):\n",
    "            expt_name = 'expt%d' %(idx+1)\n",
    "            stim = f[expt_name + '/stim']\n",
    "        #     time = f[expt_name + '/timestamps']\n",
    "            time = np.arange(0, stim.shape[0])/25.00940617\n",
    "            stimulus_upsample, time_upsample = stimtools.upsample_stim(stim, 4, time)\n",
    "            binned_spikes = []\n",
    "            response_5ms = []\n",
    "            response_10ms = []\n",
    "            response_20ms = []\n",
    "            for c in range(len(cells)):\n",
    "                bspk, tax = binspikes(expt_spikes[idx][c], binsize=0.01, time=time_upsample)\n",
    "                binned_spikes.append(bspk)\n",
    "                r5ms = st.estfr(tax, bspk, sigma=0.005) # 5 ms Gaussian\n",
    "                r10ms = st.estfr(tax, bspk, sigma=0.01) # 10 ms Gaussian\n",
    "                r20ms = st.estfr(tax, bspk, sigma=0.02) # 20 ms Gaussian\n",
    "                response_5ms.append(r5ms)\n",
    "                response_10ms.append(r10ms)\n",
    "                response_20ms.append(r20ms)\n",
    "                if repeat == 0:\n",
    "                    test_repeats.append([bspk])\n",
    "                else:\n",
    "                    test_repeats[c].append(bspk)\n",
    "            test_response_binned.append(np.vstack(binned_spikes))\n",
    "            test_response_5ms.append(np.vstack(response_5ms))\n",
    "            test_response_10ms.append(np.vstack(response_10ms))\n",
    "            test_response_20ms.append(np.vstack(response_20ms))\n",
    "        # create datasets\n",
    "        h.create_dataset('test/stimulus', data=stimulus_upsample[:-1])\n",
    "        h.create_dataset('test/time', data=time_upsample[:-1])\n",
    "        h.create_dataset('test/response/binned', data=np.mean(test_response_binned, axis=0))\n",
    "        h.create_dataset('test/response/firing_rate_10ms', data=np.mean(test_response_10ms, axis=0))\n",
    "        h.create_dataset('test/response/firing_rate_20ms', data=np.mean(test_response_20ms, axis=0))\n",
    "        h.create_dataset('test/response/firing_rate_5ms', data=np.mean(test_response_5ms, axis=0))\n",
    "        for c in range(len(cells)):\n",
    "            dataset_name = 'test/repeats/cell%02d' %(c+1)\n",
    "            h.create_dataset(dataset_name, data=np.vstack(test_repeats[c]))\n",
    "\n",
    "        h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File(stim_dir + stimulus_filename) as f:\n",
    "    with h5py.File('/Users/lmcintosh/experiments/data/16-05-31/whitenoise.h5', 'w') as h:\n",
    "\n",
    "        ##### spikes #####\n",
    "        ncells = len(cells)\n",
    "        for idx in range(ncells):\n",
    "            h.create_dataset('spikes/cell%02d' %(idx+1), data=np.array(cells[idx]))\n",
    "\n",
    "        ##### test #####\n",
    "        test_stimuli = []\n",
    "        test_times = []\n",
    "        test_response_binned = []\n",
    "        test_response_5ms = []\n",
    "        test_response_10ms = []\n",
    "        test_response_20ms = []\n",
    "        test_repeats = []\n",
    "        test_spike_times = []\n",
    "        for repeat, idx in enumerate(whitenoise_test_expts):\n",
    "            expt_name = 'expt%d' %(idx+1)\n",
    "            stim = f[expt_name + '/stim']\n",
    "        #     time = f[expt_name + '/timestamps']\n",
    "            time = np.arange(0, stim.shape[0])/25.00940617\n",
    "            stimulus_upsample, time_upsample = stimtools.upsample_stim(stim, 4, time)\n",
    "            binned_spikes = []\n",
    "            spike_times = []\n",
    "            response_5ms = []\n",
    "            response_10ms = []\n",
    "            response_20ms = []\n",
    "            for c in range(len(cells)):\n",
    "                bspk, tax = binspikes(expt_spikes[idx][c], binsize=0.01, time=time_upsample)\n",
    "                binned_spikes.append(bspk)\n",
    "                r5ms = st.estfr(tax, bspk, sigma=0.005) # 5 ms Gaussian\n",
    "                r10ms = st.estfr(tax, bspk, sigma=0.01) # 10 ms Gaussian\n",
    "                r20ms = st.estfr(tax, bspk, sigma=0.02) # 20 ms Gaussian\n",
    "                response_5ms.append(r5ms)\n",
    "                response_10ms.append(r10ms)\n",
    "                response_20ms.append(r20ms)\n",
    "                if repeat == 0:\n",
    "                    test_repeats.append([bspk])\n",
    "                else:\n",
    "                    test_repeats[c].append(bspk)\n",
    "            test_response_binned.append(np.vstack(binned_spikes))\n",
    "            test_response_5ms.append(np.vstack(response_5ms))\n",
    "            test_response_10ms.append(np.vstack(response_10ms))\n",
    "            test_response_20ms.append(np.vstack(response_20ms))\n",
    "        # create datasets\n",
    "        h.create_dataset('test/stimulus', data=stimulus_upsample[:-1])\n",
    "        h.create_dataset('test/time', data=time_upsample[:-1])\n",
    "        h.create_dataset('test/response/binned', data=np.mean(test_response_binned, axis=0))\n",
    "        h.create_dataset('test/response/firing_rate_10ms', data=np.mean(test_response_10ms, axis=0))\n",
    "        h.create_dataset('test/response/firing_rate_20ms', data=np.mean(test_response_20ms, axis=0))\n",
    "        h.create_dataset('test/response/firing_rate_5ms', data=np.mean(test_response_5ms, axis=0))\n",
    "        for c in range(len(cells)):\n",
    "            dataset_name = 'test/repeats/cell%02d' %(c+1)\n",
    "            h.create_dataset(dataset_name, data=np.vstack(test_repeats[c]))\n",
    "\n",
    "        h.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going to make a compressed version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with h5py.File(stim_dir + stimulus_filename) as f:\n",
    "    with h5py.File('/Users/lmcintosh/experiments/data/16-05-31/whitenoise_compressed.h5', 'w') as h:\n",
    "        ##### test #####\n",
    "        test_stimuli = []\n",
    "        test_times = []\n",
    "        test_response_10ms = []\n",
    "        test_repeats = []\n",
    "        test_spike_times = []\n",
    "        for repeat, idx in enumerate(whitenoise_test_expts):\n",
    "            expt_name = 'expt%d' %(idx+1)\n",
    "            stim = f[expt_name + '/stim']\n",
    "        #     time = f[expt_name + '/timestamps']\n",
    "            time = np.arange(0, stim.shape[0])/25.00940617\n",
    "            stimulus_upsample, time_upsample = stimtools.upsample_stim(stim, 4, time)\n",
    "            binned_spikes = []\n",
    "            spike_times = []\n",
    "            response_10ms = []\n",
    "            for c in range(len(cells)):\n",
    "                bspk, tax = binspikes(expt_spikes[idx][c], binsize=0.01, time=time_upsample)\n",
    "                binned_spikes.append(bspk)\n",
    "                r10ms = st.estfr(tax, bspk, sigma=0.01) # 10 ms Gaussian\n",
    "                response_10ms.append(r10ms)\n",
    "                if repeat == 0:\n",
    "                    test_repeats.append([bspk])\n",
    "                else:\n",
    "                    test_repeats[c].append(bspk)\n",
    "            test_response_binned.append(np.vstack(binned_spikes))\n",
    "            test_response_10ms.append(np.vstack(response_10ms))\n",
    "        # create datasets\n",
    "        h.create_dataset('test/stimulus', data=stimulus_upsample[:-1])\n",
    "        h.create_dataset('test/time', data=time_upsample[:-1])\n",
    "        h.create_dataset('test/response/firing_rate_10ms', data=np.mean(test_response_10ms, axis=0))\n",
    "        for c in range(len(cells)):\n",
    "            dataset_name = 'test/repeats/cell%02d' %(c+1)\n",
    "            h.create_dataset(dataset_name, data=np.vstack(test_repeats[c]).astype('uint8'))\n",
    "\n",
    "        h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
