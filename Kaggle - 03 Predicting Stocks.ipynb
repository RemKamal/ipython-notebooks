{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "9/22/2013\n",
      "# Kaggle Competition - Predicting relative stock price\n",
      "\n",
      "Deadline: 10/1/2013\n",
      "State of the art error: 0.40458\n",
      "\n",
      "For this competition, you are asked to predict the percentage change in a financial instrument at a time 2 hours in the future.  The data represents features of various financial securities (198 in total) recorded at 5-minute intervals throughout a trading day.  To discourage cheating, you are not provided with the features' names or the specific dates.\n",
      "\n",
      "__data.zip__ - contains features for 510 days worth of trading, including 200 training days and 310 testing days  \n",
      "__trainLabels.csv__ - contains the targets for the 200 training days  \n",
      "__sampleSubmission.csv__ - shows the submission format\n",
      "\n",
      "Each variable named O1, O2, O3, etc. (the outputs) represents a percent change in the value of a security.  Each variable named I1, I2, I3, etc. (the inputs) represents a feature. The underlying securities and features represented by these anonymized names are the same across all files (e.g. O1 will always be the same stock).\n",
      "\n",
      "Within each trading day, you are provided the outputs as a relative percentage compared to the previous day's closing price.  The first line of each data file represents the previous close. For example, if a security closed at \\$1 the previous day and opened at \\$2 the next day, the first output would be 0, then 100.  All output values are computed relative to the previous day's close. The timestamps within each file are as follows (ignoring the header row):\n",
      "\n",
      "Line 1 = Outputs and inputs at previous day's close (4PM ET)  \n",
      "Line 2 = Outputs and inputs at current day's open (9:30AM ET)  \n",
      "Line 3 = Outputs and inputs at 9:35AM ET  \n",
      "...  \n",
      "Line 55 = Outputs and inputs at 1:55PM ET\n",
      "\n",
      "You are asked to predict the outputs 2 hours later, at 4PM ET.\n",
      "\n",
      "Evaluation is by the mean absolute error, $MAE = \\frac{1}{n} \\sum_{i = 1}^n |y_i - \\hat{y}_i |$\n",
      "\n",
      "---\n",
      "###Results\n",
      "- Last-observed benchmark is surprisingly good; achieves private score of 0.44 and public score of 0.42007\n",
      "- An increase in the private performance doesn't necessarily correspond to a better public score, for instance  \n",
      "    - Exponential filter with 0.5 discount rate gets a better private score than 0.9 discount rate, but a worse public score\n",
      "- Using a linear model (per stock) of last observed price and the direction (derivative) doesn't improve public score\n",
      "    - This could just be because I'm improperly optimizing the coefficients\n",
      "- My best result so far is $x_{i,t} = a_i x_{i,t-1} + b_i$ where $x_{i,t-1}$ is the last observed price and where $i$ is the $i^{\\rm th}$ stock\n",
      "\n",
      "\n",
      "###To-do\n",
      "- I'm using handwritten gradient descent, but could probably use scipy optimize for better results\n",
      "- Actually use features\n",
      "- Try random forests\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Data Pre-Processing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Change directory and import modules"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/lane/Kaggle/03\\ Predicting\\ Stock\\ Prices/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/lane/Kaggle/03 Predicting Stock Prices\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[0m\u001b[01;34mData\u001b[0m/          infoTheory.pyc  linearMAE.pyc      makeSubmission_temp.py  meanAbsoluteError.pyc  scraps.py\r\n",
        "infoTheory.py  linearMAE.py    makeSubmission.py  meanAbsoluteError.py    mh_test.py\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import cross_validation\n",
      "from scipy import optimize\n",
      "import meanAbsoluteError as err\n",
      "import numpy as np\n",
      "import datetime\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Import and format data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#DATA PROCESSING\n",
      "#create the training & test sets, skipping the header row with [1:]\n",
      "trainingDays = range(1,511) #200 days of training data, 510 total days\n",
      "headers = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\n",
      "numRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\n",
      "numCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\n",
      "isOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\n",
      "isInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\n",
      "trainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\n",
      "trainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\n",
      "for i in trainingDays:\n",
      "    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\n",
      "    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\n",
      "    for j in range(0,numCols):\n",
      "        if headers[j][0] == 'O':\n",
      "            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\n",
      "        elif headers[j][0] == 'I':\n",
      "            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\n",
      "\n",
      "#target prices 2 hours later (only outputs, no inputs) \n",
      "target = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\n",
      "target = target[:,1:]  # (day,price2HrsLater)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-7-f9d6f029d75e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtrainInput\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingDays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumRows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misInput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainingDays\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data/data/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (5minIncrement,stock/feature)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumCols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skiprows, skip_header, skip_footer, converters, missing, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mloose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m         rows = zip(*[map(converter._loose_call, map(itemgetter(i), rows))\n\u001b[1;32m-> 1661\u001b[1;33m                      for (i, converter) in enumerate(converters)])\n\u001b[0m\u001b[0;32m   1662\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1663\u001b[0m         rows = zip(*[map(converter._strict_call, map(itemgetter(i), rows))\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/_iotools.pyc\u001b[0m in \u001b[0;36m_loose_call\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    645\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_loose_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Data Exploration"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Linear Models\n",
      "\n",
      "---\n",
      "First with hand-built gradient method"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initialize variables\n",
      "iterations   = 100\n",
      "learningRate = 0.01\n",
      "h            = (2e-15)**(1./3)\n",
      "coeff        = np.zeros((sum(isOutput),3))\n",
      "coeff[:,1]   = np.squeeze(np.ones((sum(isOutput),1)))\n",
      "error        = []\n",
      "gradient     = [0,0,0]\n",
      "pred0P = np.zeros((len(trainingDays),sum(isOutput)))\n",
      "pred0M = np.zeros((len(trainingDays),sum(isOutput)))\n",
      "pred1P = np.zeros((len(trainingDays),sum(isOutput)))\n",
      "pred1M = np.zeros((len(trainingDays),sum(isOutput)))\n",
      "pred2P = np.zeros((len(trainingDays),sum(isOutput)))\n",
      "pred2M = np.zeros((len(trainingDays),sum(isOutput)))\n",
      "pred   = np.zeros((len(trainingDays),sum(isOutput)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### The following model achives state-of-the art performance: 0.41947\n",
      "\n",
      "---\n",
      "Linear model on last-observed value and last derivative, with coefficients that vary by stock.  Coefficients are optimized by hand-created gradient using 100 iterations for each stock and day"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run model\n",
      "for stock in range(0,sum(isOutput)):\n",
      "    for i in range(0,iterations):\n",
      "        for day in range(0,len(trainingDays)):\n",
      "            deriv = trainOutput[day,-1,stock] - trainOutput[day,-2,stock]\n",
      "            pred0P[day,stock] = (coeff[stock,1])*trainOutput[day,-1,stock] + (coeff[stock,2])*deriv + (coeff[stock,0] + h)\n",
      "            pred0M[day,stock] = (coeff[stock,1])*trainOutput[day,-1,stock] + (coeff[stock,2])*deriv + (coeff[stock,0] - h)\n",
      "            pred1P[day,stock] = (coeff[stock,1]+h)*trainOutput[day,-1,stock] +  (coeff[stock,2])*deriv + (coeff[stock,0])\n",
      "            pred1M[day,stock] = (coeff[stock,1]-h)*trainOutput[day,-1,stock] +  (coeff[stock,2])*deriv +(coeff[stock,0])\n",
      "            pred2P[day,stock] = (coeff[stock,1])*trainOutput[day,-1,stock] +  (coeff[stock,2]+h)*deriv + (coeff[stock,0])\n",
      "            pred2M[day,stock] = (coeff[stock,1])*trainOutput[day,-1,stock] +  (coeff[stock,2]-h)*deriv +(coeff[stock,0])\n",
      "            pred[day,stock]   = (coeff[stock,1])*trainOutput[day,-1,stock] + (coeff[stock,2])*deriv +(coeff[stock,0])\n",
      "\n",
      "        gradient[0] = (err.maeFun(target,pred0P[0:200,:]) - err.maeFun(target,pred0M[0:200,:]))/(2*h)\n",
      "        gradient[1] = (err.maeFun(target,pred1P[0:200,:]) - err.maeFun(target,pred1M[0:200,:]))/(2*h)\n",
      "        gradient[2] = (err.maeFun(target,pred2P[0:200,:]) - err.maeFun(target,pred2M[0:200,:]))/(2*h)\n",
      "        coeff[stock,:] = [coeff[stock,x] - learningRate*gradient[x] for x in range(0,len(gradient))]\n",
      "        #print \"Stock: \" + str(stock) + \" Error: \" + str(err.maeFun(target[:,stock],pred[0:200,stock])) + \" Coeff: \" + str(coeff[stock,:])\n",
      "\n",
      "    error.append(err.maeFun(target,pred[0:200,:])) #maeFun(actual,pred)\n",
      "    print \"Results: \" + str(error[-1]) + \" Variance of coefficients: \" + str([np.var(coeff[:,0]), np.var(coeff[:,1])])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plot(error)\n",
      "ax = pylab.axes()\n",
      "ax.set_title('Gradient Descent on Coefficients')\n",
      "ax.set_xlabel('Error')\n",
      "ax.set_ylabel('Stocks')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Save predictions to file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savetxt('Data/submission'+str(datetime.date.today())+'.csv', pred[200:510,:], delimiter=',', fmt='%f')  #predictions for file 201 to 510"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Linear Model on all datapoints with scipy.optimize\n",
      "\n",
      "Define model and use scipy optimize to see if you get better results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def linearModel(coeff,trainOutput):\n",
      "    \n",
      "    # Set constants and initialize vars\n",
      "    numTrainingDays = trainOutput.shape[0]  #510\n",
      "    numTimes        = trainOutput.shape[1]  #55\n",
      "    numStocks       = trainOutput.shape[2]  #198\n",
      "    pred            = np.zeros((numTrainingDays,numStocks))\n",
      "    \n",
      "    # need coeff in format (numStocks, numTimes)\n",
      "    # scipy.optimize.minimize reshapes coeff as vector\n",
      "    timesUsed = 2  # could be numTimes\n",
      "    coeff = coeff.reshape((numStocks,timesUsed))\n",
      "    \n",
      "    # Run model\n",
      "    for stock in xrange(numStocks):\n",
      "        for day in xrange(numTrainingDays):\n",
      "            pred[day,stock] = np.dot(coeff[stock,-timesUsed:-1],trainOutput[day,-timesUsed:-1,stock])\n",
      "    \n",
      "    return pred"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def errorLinear(coeff, trainOutput, target):\n",
      "    # function of coeff, trainOutput, & target\n",
      "    \n",
      "    pred = linearModel(coeff,trainOutput)\n",
      "    \n",
      "    return err.maeFun(target,pred[0:200,:]) #maeFun(actual,pred)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Optimize using scipy.optimize"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# intial parameters\n",
      "timesUsed   = 2\n",
      "coeff       = np.zeros((trainOutput.shape[2],timesUsed)) # (numStocks, timesUsed), where timesUsed could = trainOutput.shape[1]\n",
      "coeff[:,-1] = np.squeeze(np.ones((trainOutput.shape[2],1)))\n",
      "res         = optimize.minimize(errorLinear, x0=coeff, args=[trainOutput,target], method='nelder-mead', options={'xtol': 1e-8, 'disp': True, 'maxiter' : 5})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: Maximum number of iterations has been exceeded.\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "opt_coeff = res.x\n",
      "opt_coeff = opt_coeff.reshape((trainOutput.shape[2],timesUsed))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "opt_coeff.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "(198, 2)"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import special\n",
      "errorLinear(opt_coeff, trainOutput, target)\n",
      "x = res.x\n",
      "y = special.jv(3,x)\n",
      "plot(x, y, '-', res.x, -res.fun, 'o')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "1.443943303472226"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}