{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "9/22/2013\n",
      "# Kaggle Competition - Predicting relative stock price\n",
      "\n",
      "Deadline: 10/1/2013\n",
      "State of the art error: 0.40458\n",
      "\n",
      "For this competition, you are asked to predict the percentage change in a financial instrument at a time 2 hours in the future.  The data represents features of various financial securities (198 in total) recorded at 5-minute intervals throughout a trading day.  To discourage cheating, you are not provided with the features' names or the specific dates.\n",
      "\n",
      "__data.zip__ - contains features for 510 days worth of trading, including 200 training days and 310 testing days  \n",
      "__trainLabels.csv__ - contains the targets for the 200 training days  \n",
      "__sampleSubmission.csv__ - shows the submission format\n",
      "\n",
      "Each variable named O1, O2, O3, etc. (the outputs) represents a percent change in the value of a security.  Each variable named I1, I2, I3, etc. (the inputs) represents a feature. The underlying securities and features represented by these anonymized names are the same across all files (e.g. O1 will always be the same stock).\n",
      "\n",
      "Within each trading day, you are provided the outputs as a relative percentage compared to the previous day's closing price.  The first line of each data file represents the previous close. For example, if a security closed at \\$1 the previous day and opened at \\$2 the next day, the first output would be 0, then 100.  All output values are computed relative to the previous day's close. The timestamps within each file are as follows (ignoring the header row):\n",
      "\n",
      "Line 1 = Outputs and inputs at previous day's close (4PM ET)  \n",
      "Line 2 = Outputs and inputs at current day's open (9:30AM ET)  \n",
      "Line 3 = Outputs and inputs at 9:35AM ET  \n",
      "...  \n",
      "Line 55 = Outputs and inputs at 1:55PM ET\n",
      "\n",
      "You are asked to predict the outputs 2 hours later, at 4PM ET.\n",
      "\n",
      "Evaluation is by the mean absolute error, $MAE = \\frac{1}{n} \\sum_{i = 1}^n |y_i - \\hat{y}_i |$\n",
      "\n",
      "---\n",
      "###Results\n",
      "- Last-observed benchmark is surprisingly good; achieves private score of 0.44 and public score of 0.42007\n",
      "- An increase in the private performance doesn't necessarily correspond to a better public score, for instance  \n",
      "    - Exponential filter with 0.5 discount rate gets a better private score than 0.9 discount rate, but a worse public score\n",
      "- Using a linear model (per stock) of last observed price and the direction (derivative) doesn't improve public score\n",
      "    - This could just be because I'm improperly optimizing the coefficients\n",
      "- My best result so far is $x_{i,t} = a_i x_{i,t-1} + b_i$ where $x_{i,t-1}$ is the last observed price and where $i$ is the $i^{\\rm th}$ stock\n",
      "\n",
      "\n",
      "###To-do\n",
      "- I'm using handwritten gradient descent, but could probably use scipy optimize for better results\n",
      "- Actually use features\n",
      "- Try random forests\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Data Pre-Processing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Change directory and import modules"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/lane/Kaggle/03\\ Predicting\\ Stock\\ Prices/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/lane/Kaggle/03 Predicting Stock Prices\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[0m\u001b[01;34mData\u001b[0m/           linearMAE.py       makeSubmission_temp.py  mh_test.py\r\n",
        "infoTheory.py   linearMAE.pyc      meanAbsoluteError.py    scraps.py\r\n",
        "infoTheory.pyc  makeSubmission.py  meanAbsoluteError.pyc\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import cross_validation\n",
      "from scipy import optimize\n",
      "import meanAbsoluteError as err\n",
      "import numpy as np\n",
      "import datetime\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Import and format data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#DATA PROCESSING\n",
      "#create the training & test sets, skipping the header row with [1:]\n",
      "trainingDays = range(1,511) #200 days of training data, 510 total days\n",
      "headers = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\n",
      "numRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\n",
      "numCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\n",
      "isOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\n",
      "isInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\n",
      "trainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\n",
      "trainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\n",
      "for i in trainingDays:\n",
      "    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\n",
      "    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\n",
      "    for j in range(0,numCols):\n",
      "        if headers[j][0] == 'O':\n",
      "            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\n",
      "        elif headers[j][0] == 'I':\n",
      "            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\n",
      "\n",
      "#target prices 2 hours later (only outputs, no inputs) \n",
      "target = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\n",
      "target = target[:,1:]  # (day,price2HrsLater)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Data Exploration"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Linear Models\n",
      "\n",
      "---\n",
      "First with hand-built gradient method"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initialize variables\n",
      "iterations   = 100\n",
      "learningRate = 0.01\n",
      "h            = (2e-15)**(1./3)\n",
      "coeff        = np.zeros((sum(isOutput),3))\n",
      "coeff[:,1]   = np.squeeze(np.ones((sum(isOutput),1)))\n",
      "error        = []\n",
      "gradient     = [0,0,0]\n",
      "pred0P = np.zeros((len(trainingDays),sum(isOutput)))\n",
      "pred0M = np.zeros((len(trainingDays),sum(isOutput)))\n",
      "pred1P = np.zeros((len(trainingDays),sum(isOutput)))\n",
      "pred1M = np.zeros((len(trainingDays),sum(isOutput)))\n",
      "pred2P = np.zeros((len(trainingDays),sum(isOutput)))\n",
      "pred2M = np.zeros((len(trainingDays),sum(isOutput)))\n",
      "pred   = np.zeros((len(trainingDays),sum(isOutput)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### The following model achives performance: 0.41947\n",
      "\n",
      "---\n",
      "Linear model on last-observed value and last derivative, with coefficients that vary by stock.  Coefficients are optimized by hand-created gradient using 100 iterations for each stock and day"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run model\n",
      "for stock in range(0,sum(isOutput)):\n",
      "    for i in range(0,iterations):\n",
      "        for day in range(0,len(trainingDays)):\n",
      "            deriv = trainOutput[day,-1,stock] - trainOutput[day,-2,stock]\n",
      "            pred0P[day,stock] = (coeff[stock,1])*trainOutput[day,-1,stock] + (coeff[stock,2])*deriv + (coeff[stock,0] + h)\n",
      "            pred0M[day,stock] = (coeff[stock,1])*trainOutput[day,-1,stock] + (coeff[stock,2])*deriv + (coeff[stock,0] - h)\n",
      "            pred1P[day,stock] = (coeff[stock,1]+h)*trainOutput[day,-1,stock] +  (coeff[stock,2])*deriv + (coeff[stock,0])\n",
      "            pred1M[day,stock] = (coeff[stock,1]-h)*trainOutput[day,-1,stock] +  (coeff[stock,2])*deriv +(coeff[stock,0])\n",
      "            pred2P[day,stock] = (coeff[stock,1])*trainOutput[day,-1,stock] +  (coeff[stock,2]+h)*deriv + (coeff[stock,0])\n",
      "            pred2M[day,stock] = (coeff[stock,1])*trainOutput[day,-1,stock] +  (coeff[stock,2]-h)*deriv +(coeff[stock,0])\n",
      "            pred[day,stock]   = (coeff[stock,1])*trainOutput[day,-1,stock] + (coeff[stock,2])*deriv +(coeff[stock,0])\n",
      "\n",
      "        gradient[0] = (err.maeFun(target,pred0P[0:200,:]) - err.maeFun(target,pred0M[0:200,:]))/(2*h)\n",
      "        gradient[1] = (err.maeFun(target,pred1P[0:200,:]) - err.maeFun(target,pred1M[0:200,:]))/(2*h)\n",
      "        gradient[2] = (err.maeFun(target,pred2P[0:200,:]) - err.maeFun(target,pred2M[0:200,:]))/(2*h)\n",
      "        coeff[stock,:] = [coeff[stock,x] - learningRate*gradient[x] for x in range(0,len(gradient))]\n",
      "        #print \"Stock: \" + str(stock) + \" Error: \" + str(err.maeFun(target[:,stock],pred[0:200,stock])) + \" Coeff: \" + str(coeff[stock,:])\n",
      "\n",
      "    error.append(err.maeFun(target,pred[0:200,:])) #maeFun(actual,pred)\n",
      "    print \"Results: \" + str(error[-1]) + \" Variance of coefficients: \" + str([np.var(coeff[:,0]), np.var(coeff[:,1])])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plot(error)\n",
      "ax = pylab.axes()\n",
      "ax.set_title('Gradient Descent on Coefficients')\n",
      "ax.set_xlabel('Error')\n",
      "ax.set_ylabel('Stocks')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Save predictions to file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savetxt('Data/submission'+str(datetime.date.today())+'.csv', pred[200:510,:], delimiter=',', fmt='%f')  #predictions for file 201 to 510"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Linear Model on all datapoints with scipy.optimize\n",
      "\n",
      "Define model and use scipy optimize to see if you get better results.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "9/27/13  \n",
      "Results: You improved on your best score by 0.00126.  You just moved up 49 positions on the leaderboard.  \n",
      "\n",
      "#### The following model achives state-of-the-art performance: 0.41820\n",
      "\n",
      "---\n",
      "Linear model on last-observed value and last derivative, with coefficients that vary by stock.  Coefficients are optimized by scipy optimize.minimize for each stock and day"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def linearModel(coeff,trainOutput):\n",
      "    \n",
      "    # Set constants and initialize vars\n",
      "    numTrainingDays = trainOutput.shape[0]  #510\n",
      "    numTimes        = trainOutput.shape[1]  #55\n",
      "    numStocks       = trainOutput.shape[2]  #198\n",
      "    pred            = np.zeros((numTrainingDays,numStocks))\n",
      "    \n",
      "    # need coeff in format (numStocks, numTimes)\n",
      "    # scipy.optimize.minimize reshapes coeff as vector\n",
      "    coeffDim = 2  # could be numTimes\n",
      "    coeff    = coeff.reshape((numStocks,coeffDim))\n",
      "    \n",
      "    # Run model\n",
      "    for stock in xrange(numStocks):\n",
      "        for day in xrange(numTrainingDays):\n",
      "            deriv           = trainOutput[day,-1,stock] - trainOutput[day,-2,stock]\n",
      "            pred[day,stock] = coeff[stock,0]*trainOutput[day,-1,stock] + coeff[stock,1]*deriv\n",
      "            #pred[day,stock] = np.dot(coeff[stock,-timesUsed:-1],trainOutput[day,-timesUsed:-1,stock])\n",
      "    \n",
      "    return pred"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def errorLinear(coeff, trainOutput, target):\n",
      "    # function of coeff, trainOutput, & target\n",
      "    \n",
      "    pred = linearModel(coeff,trainOutput)\n",
      "    \n",
      "    return err.maeFun(target,pred[0:200,:]) #maeFun(actual,pred)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Optimize using scipy.optimize"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# intial parameters\n",
      "coeffDim    = 2\n",
      "coeff       = np.zeros((trainOutput.shape[2],coeffDim)) # (numStocks, timesUsed), where timesUsed could = trainOutput.shape[1]\n",
      "coeff[:,0]  = np.squeeze(np.ones((trainOutput.shape[2],1)))\n",
      "res         = optimize.minimize(errorLinear, x0=coeff, args=[trainOutput,target], method='nelder-mead', options={'xtol': 1e-8, 'disp': True})  #'maxiter' : 500"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Reformat coefficient shape to (numStocks,numDim)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "opt_coeff = res.x\n",
      "opt_coeff = opt_coeff.reshape((trainOutput.shape[2],coeffDim))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualize optimal coefficients"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = opt_coeff[:,0]\n",
      "z = opt_coeff[:,1]\n",
      "\n",
      "fig, axes = subplots(ncols=2)\n",
      "fig.set_size_inches(16,4)\n",
      "subplot(121)\n",
      "plot(y)\n",
      "subplot(122)\n",
      "plot(z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "[<matplotlib.lines.Line2D at 0x52a3d10>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAA60AAAD9CAYAAABXw5G1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x4e7a650>"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Save prediction to file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = linearModel(opt_coeff,trainOutput)\n",
      "np.savetxt('Data/submission'+str(datetime.date.today())+'.csv', pred[200:510,:], delimiter=',', fmt='%f')  #predictions for file 201 to 510"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Affine Model: Previous linear model + constant  \n",
      "$$y = a_0 x_{i-1} + a_1 (x_{i-1} - x_{i-2}) + a_2$$\n",
      "\n",
      "---\n",
      "- First try just two coefficients, one for positive and one for negative trends  \n",
      "- Then try stock-specific coefficients"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### This model did not improve score over previous model.  Score = 0.41923\n",
      "Note that this is still better than per-stock with hand drawn gradient"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def affineModel(coeff,trainOutput):\n",
      "    \n",
      "    # Set constants and initialize vars\n",
      "    numTrainingDays = trainOutput.shape[0]  #510\n",
      "    numTimes        = trainOutput.shape[1]  #55\n",
      "    numStocks       = trainOutput.shape[2]  #198\n",
      "    pred            = np.zeros((numTrainingDays,numStocks))\n",
      "    \n",
      "    # need coeff in format (numStocks, numTimes)\n",
      "    # scipy.optimize.minimize reshapes coeff as vector\n",
      "    coeffDim = 3  # could be numTimes\n",
      "    coeff    = coeff.reshape((2,coeffDim))\n",
      "    \n",
      "    # Run model\n",
      "    for stock in xrange(numStocks):\n",
      "        for day in xrange(numTrainingDays):\n",
      "            deriv = trainOutput[day,-1,stock] - trainOutput[day,-2,stock]\n",
      "            if trainOutput[day,-1,stock] >= 0:\n",
      "                pred[day,stock] = coeff[0,0]*trainOutput[day,-1,stock] + coeff[0,1]*deriv + coeff[0,2]\n",
      "            elif trainOutput[day,-1,stock] < 0:\n",
      "                pred[day,stock] = coeff[1,0]*trainOutput[day,-1,stock] + coeff[1,1]*deriv + coeff[1,2]\n",
      "    \n",
      "    return pred"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def errorAffine(coeff, trainOutput, target):\n",
      "    # function of coeff, trainOutput, & target\n",
      "    \n",
      "    pred = affineModel(coeff,trainOutput)\n",
      "    \n",
      "    return err.maeFun(target,pred[0:200,:]) #maeFun(actual,pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Optimize using scipy optimize.minimize"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import smtplib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# intial parameters\n",
      "coeffDim    = 3\n",
      "coeff       = np.zeros((2,coeffDim))\n",
      "coeff[:,0]  = np.squeeze(np.ones((2,1)))\n",
      "res         = optimize.minimize(errorAffine, x0=coeff, args=[trainOutput,target], method='nelder-mead', options={'xtol': 1e-8, 'disp': True})  #'maxiter' : 500\n",
      "\n",
      "# text me when you're done\n",
      "to = 'lanemcintosh@gmail.com' #insert reciever email address (can be same as sender)\n",
      "gmail_user = 'mcintoshlane@gmail.com' #your gmail sender address\n",
      "gmail_pwd = 'hansolo8chewy' #your gmail password\n",
      "smtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\n",
      "smtpserver.ehlo() #the technical stuff\n",
      "smtpserver.starttls() #the technical stuff\n",
      "smtpserver.ehlo #the technical stuff\n",
      "smtpserver.login(gmail_user, gmail_pwd) #the technical stuff\n",
      "header = 'To:' + to + '\\n' + 'From: ' + gmail_user + '\\n' + 'Subject:Master\\'s Thesis iPython Notebook \\n'\n",
      "msg = header + '\\n' + 'Your Python Script has now Completed!' #The completion message\n",
      "smtpserver.sendmail(gmail_user, to, msg) #Sending the mail\n",
      "smtpserver.close() #closing the mailserver connection"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "opt_coeff = res.x\n",
      "opt_coeff = opt_coeff.reshape((2,coeffDim))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = opt_coeff[0,:]\n",
      "z = opt_coeff[1,:]\n",
      "\n",
      "fig, axes = subplots(ncols=2)\n",
      "fig.set_size_inches(16,4)\n",
      "subplot(121)\n",
      "plot(y)\n",
      "subplot(122)\n",
      "plot(z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "[<matplotlib.lines.Line2D at 0x4b7ddd0>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAA6wAAAD9CAYAAAC4AfqLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nd76Y6gAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x39f98d0>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res.fun"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "0.43923450784062007"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = affineModel(opt_coeff,trainOutput)\n",
      "np.savetxt('Data/submission'+str(datetime.date.today())+'affine.csv', pred[200:510,:], delimiter=',', fmt='%f')  #predictions for file 201 to 510"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Affine Model: Previous linear model + constant \n",
      "### with stock-specific coefficients  \n",
      "$$y = a_0 x_{i-1} + a_1 (x_{i-1} - x_{i-2}) + a_2$$\n",
      "\n",
      "---\n",
      "Models using scipy optimize:  \n",
      "- $a x_{i-1} + b (x_{i-1} - x{i-2})$ with Stock-specific coefficients: 0.41820  \n",
      "- $a x_{i-1} + b (x_{i-1} - x{i-2}) + c$ with just two coefficients, one for positive and one for negative trends: 0.41923  \n",
      "- $a x_{i-1} + b (x_{i-1} - x{i-2}) + c$ with stock-specific coefficients: 0.41797"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### This is the new state-of-the-art model:  Score = 0.41797  \n",
      "You improved on your best score by 0.00024.   \n",
      "You just moved up 12 positions on the leaderboard."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def affineModel2(coeff,trainOutput):\n",
      "    \n",
      "    # Set constants and initialize vars\n",
      "    numTrainingDays = trainOutput.shape[0]  #510\n",
      "    numTimes        = trainOutput.shape[1]  #55\n",
      "    numStocks       = trainOutput.shape[2]  #198\n",
      "    pred            = np.zeros((numTrainingDays,numStocks))\n",
      "    \n",
      "    # need coeff in format (numStocks, numTimes)\n",
      "    # scipy.optimize.minimize reshapes coeff as vector\n",
      "    coeffDim = 3  # could be numTimes\n",
      "    coeff    = coeff.reshape((numStocks,coeffDim))\n",
      "    \n",
      "    # Run model\n",
      "    for stock in xrange(numStocks):\n",
      "        for day in xrange(numTrainingDays):\n",
      "            deriv           = trainOutput[day,-1,stock] - trainOutput[day,-2,stock]\n",
      "            pred[day,stock] = coeff[stock,0]*trainOutput[day,-1,stock] + coeff[stock,1]*deriv + coeff[stock,2]\n",
      "    \n",
      "    return pred"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def errorAffine2(coeff, trainOutput, target):\n",
      "    # function of coeff, trainOutput, & target\n",
      "    \n",
      "    pred = affineModel2(coeff,trainOutput)\n",
      "    \n",
      "    return err.maeFun(target,pred[0:200,:]) #maeFun(actual,pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Optimize using scipy optimize.minimize  \n",
      "Then send me a text when you're done"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import smtplib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# intial parameters\n",
      "coeffDim    = 3\n",
      "coeff       = np.zeros((trainOutput.shape[2],coeffDim)) # (numStocks, timesUsed), where timesUsed could = trainOutput.shape[1]\n",
      "coeff[:,0]  = np.squeeze(np.ones((trainOutput.shape[2],1)))\n",
      "res         = optimize.minimize(errorAffine2, x0=coeff, args=[trainOutput,target], method='nelder-mead', options={'xtol': 1e-8, 'disp': True})  #'maxiter' : 500\n",
      "\n",
      "# text me when you're done\n",
      "to = 'lanemcintosh@gmail.com' #insert reciever email address (can be same as sender)\n",
      "gmail_user = 'mcintoshlane@gmail.com' #your gmail sender address\n",
      "gmail_pwd = 'hansolo8chewy' #your gmail password\n",
      "smtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\n",
      "smtpserver.ehlo() #the technical stuff\n",
      "smtpserver.starttls() #the technical stuff\n",
      "smtpserver.ehlo #the technical stuff\n",
      "smtpserver.login(gmail_user, gmail_pwd) #the technical stuff\n",
      "header = 'To:' + to + '\\n' + 'From: ' + gmail_user + '\\n' + 'Subject:Master\\'s Thesis iPython Notebook \\n'\n",
      "msg = header + '\\n' + 'Your Python Script has now Completed!' #The completion message\n",
      "smtpserver.sendmail(gmail_user, to, msg) #Sending the mail\n",
      "smtpserver.close() #closing the mailserver connection"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "opt_coeff = res.x\n",
      "opt_coeff = opt_coeff.reshape((trainOutput.shape[2],coeffDim))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = opt_coeff[:,0]\n",
      "z = opt_coeff[:,1]\n",
      "w = opt_coeff[:,2]\n",
      "\n",
      "fig, axes = subplots(ncols=3)\n",
      "fig.set_size_inches(16,4)\n",
      "subplot(131)\n",
      "plot(y)\n",
      "subplot(132)\n",
      "plot(z)\n",
      "subplot(133)\n",
      "plot(w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "[<matplotlib.lines.Line2D at 0x5849e50>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAA60AAAD9CAYAAABXw5G1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBEEQBCFm+f8bkc0Lq9J8wAAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x4e0c150>"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res.fun"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "0.4358769108214533"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = affineModel2(opt_coeff,trainOutput)\n",
      "np.savetxt('Data/submission'+str(datetime.date.today())+'affine2.csv', pred[200:510,:], delimiter=',', fmt='%f')  #predictions for file 201 to 510"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write out all the proper headers (top column and first row).  Also, using %s gives you much higher precision!  \n",
      "\n",
      "Note that this increase in precision didn't affect my score."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output = pred.tolist()  # transform pred from np array to list\n",
      "sheet  = output[200:510][:]\n",
      "\n",
      "firstLine = ['O' + str(j) for j in xrange(1,len(sheet[0])+1)]\n",
      "firstLine.insert(0, 'fileId')\n",
      "sheet.insert(0, firstLine)\n",
      "for i in xrange(1,len(sheet)):\n",
      "    sheet[i].insert(0, str(200+i))\n",
      "\n",
      "np.savetxt('Data/submission'+str(datetime.date.today())+'.csv', sheet, delimiter=',', fmt=\"%s\")  #predictions for file 201 to 510"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Now let's try some crazy stuff: Random Forests  \n",
      "### This does not perform better than the affine model.  Score: 0.42016\n",
      "---\n",
      "To do:  \n",
      "- reformat input/output so that you have all the sentiment analysis then the derivative, then the last observed value  \n",
      "- figure out how to have multiple values for single output  \n",
      "- maybe better to predict target - lastObserved rather than lastObserved"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import cross_validation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Create Random Forest"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create the random forest\n",
      "#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
      "rf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\n",
      "cv = cross_validation.KFold(len(target), n_folds=63, indices=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Create features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The input to rf.fit(X,y) should be:  \n",
      "\n",
      "X : array-like of shape = [n_samples, n_features]             - The training input samples.  \n",
      "y : array-like, shape = [n_samples] or [n_samples, n_outputs] - The target values (integers that correspond to classes in classification, real numbers in regression)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lastObserved = trainOutput[:,-1,:]\n",
      "deriv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\n",
      "normTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\n",
      "\n",
      "#train            = np.zeros((510,55,244+198))\n",
      "#train[:,:,0:198] = trainOutput\n",
      "#train[:,:,198:]  = trainInput"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = gcf()\n",
      "fig.set_size_inches(16,5.5)\n",
      "\n",
      "normTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\n",
      "y = hist(normTarget_vector,100,log=True,histtype='stepfilled')\n",
      "title('Distribution of Normalized Percent Gain/Loss after last observed value')\n",
      "ylabel('Frequency')\n",
      "xlabel('Percent Gain/Loss After Last Observed Value')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 111,
       "text": [
        "<matplotlib.text.Text at 0x9894b90>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAA7gAAAFtCAYAAAAtVcbuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEXULTHCJiIiIiIioW/h/ff4p+Q1lEl4AAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0xaa97ad0>"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Train and run random forest\n",
      "Recall that the random forest was trained on normalized targets, so we need to add last observed value back to predicted_probs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import smtplib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Fit Random Forest and generate predictions\n",
      "numStocks   = trainOutput.shape[2]\n",
      "performance = []\n",
      "pred        = np.zeros((310,numStocks))\n",
      "for stock in xrange(numStocks):\n",
      "    \n",
      "    # get stock-specific features\n",
      "    X     = deriv[:,stock].reshape((deriv.shape[0],1))\n",
      "    y     = normTarget[:,stock]\n",
      "    train = X[:200,:]\n",
      "    test  = X[200:,:]\n",
      "\n",
      "    # iterate through the training and test cross validation segments and\n",
      "    #run the classifier on each one, aggregating the results into a list\n",
      "    results = []\n",
      "    for traincv, testcv in cv:\n",
      "        probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\n",
      "        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\n",
      "\n",
      "    performance.append(np.array(results).mean())\n",
      "\n",
      "    # generate predictions (making sure to add last observed value back in)\n",
      "    predicted_probs = [x[1] for x in rf.predict_proba(test)]\n",
      "    thisColumn      = np.asarray(predicted_probs)\n",
      "    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\n",
      "\n",
      "#print out the mean of the mean of the cross-validated results\n",
      "print \"Results: \" + str( np.array(performance).mean() )\n",
      "\n",
      "\n",
      "## Save to file\n",
      "sheet = pred.tolist()  # transform pred from np array to list\n",
      "\n",
      "firstLine = ['O' + str(j) for j in xrange(1,len(sheet[0])+1)]\n",
      "firstLine.insert(0, 'fileId')\n",
      "sheet.insert(0, firstLine)\n",
      "for i in xrange(1,len(sheet)):\n",
      "    sheet[i].insert(0, str(200+i))\n",
      "\n",
      "np.savetxt('Data/submission'+str(datetime.date.today())+'.csv', sheet, delimiter=',', fmt=\"%s\")  #predictions for file 201 to 510\n",
      "\n",
      "\n",
      "## Text me when you're done\n",
      "to = 'lanemcintosh@gmail.com' #insert reciever email address (can be same as sender)\n",
      "gmail_user = 'mcintoshlane@gmail.com' #your gmail sender address\n",
      "gmail_pwd = 'hansolo8chewy' #your gmail password\n",
      "smtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\n",
      "smtpserver.ehlo() #the technical stuff\n",
      "smtpserver.starttls() #the technical stuff\n",
      "smtpserver.ehlo #the technical stuff\n",
      "smtpserver.login(gmail_user, gmail_pwd) #the technical stuff\n",
      "header = 'To:' + to + '\\n' + 'From: ' + gmail_user + '\\n' + 'Subject:Kaggle iPython Notebook \\n'\n",
      "msg = header + '\\n' + 'Your Python Script has now Completed!' #The completion message\n",
      "smtpserver.sendmail(gmail_user, to, msg) #Sending the mail\n",
      "smtpserver.close() #closing the mailserver connection"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Random Forests Take 2: Using all the metrics  \n",
      "#### Scored 0.58913, which was not an improvement\n",
      "\n",
      "---\n",
      "Ported over from local machine"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import cross_validation\n",
      "from scipy import optimize\n",
      "import meanAbsoluteError as err\n",
      "import numpy as np\n",
      "import datetime\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#DATA PROCESSING\n",
      "#create the training & test sets, skipping the header row with [1:]\n",
      "trainingDays = range(1,511) #200 days of training data, 510 total days\n",
      "headers = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\n",
      "numRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\n",
      "numCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\n",
      "isOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\n",
      "isInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\n",
      "trainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\n",
      "trainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\n",
      "for i in trainingDays:\n",
      "    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\n",
      "    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\n",
      "    for j in range(0,numCols):\n",
      "        if headers[j][0] == 'O':\n",
      "            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\n",
      "        elif headers[j][0] == 'I':\n",
      "            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\n",
      "\n",
      "#target prices 2 hours later (only outputs, no inputs) \n",
      "target = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\n",
      "target = target[:,1:]  # (day,price2HrsLater)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import cross_validation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create the random forest\n",
      "#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
      "rf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\n",
      "cv = cross_validation.KFold(len(target), n_folds=63, indices=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lastObserved = trainOutput[:,-1,:]\n",
      "deriv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\n",
      "normTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import smtplib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numStocks = trainOutput.shape[2]\n",
      "pred      = np.zeros((310,numStocks))\n",
      "for stock in xrange(numStocks):\n",
      "    numMetrics = len(trainInput[0,0])\n",
      "    X = np.array(deriv[:,stock])\n",
      "    X = X[...,None]\n",
      "\n",
      "    for j in xrange(1,10):\n",
      "        for i in xrange(numMetrics):\n",
      "            thisMetric = trainInput[:,-j,i]\n",
      "            thisMetric = thisMetric[...,None]\n",
      "            X = np.append(X,thisMetric,1)\n",
      "    \n",
      "    y     = normTarget[:,stock]\n",
      "    train = X[:200,:]\n",
      "    test  = X[200:,:]\n",
      "    \n",
      "    X_transformed    = rf.fit_transform(train,y)\n",
      "    test_transformed = rf.transform(test)\n",
      "    rf.fit(X_transformed,y)\n",
      "    \n",
      "    thisColumn    = rf.predict(test_transformed)\n",
      "    thisColumn    = thisColumn + lastObserved[200:,stock]\n",
      "    pred[:,stock] = np.asarray(thisColumn)\n",
      "\n",
      "    \n",
      "    \n",
      "## Save to file\n",
      "sheet = pred.tolist()  # transform pred from np array to list\n",
      "\n",
      "firstLine = ['O' + str(j) for j in xrange(1,len(sheet[0])+1)]\n",
      "firstLine.insert(0, 'fileId')\n",
      "sheet.insert(0, firstLine)\n",
      "for i in xrange(1,len(sheet)):\n",
      "    sheet[i].insert(0, str(200+i))\n",
      "\n",
      "np.savetxt('Data/submission'+str(datetime.date.today())+'.csv', sheet, delimiter=',', fmt=\"%s\")  #predictions for file 201 to 510\n",
      "\n",
      "\n",
      "## Text me when you're done\n",
      "to = 'lanemcintosh@gmail.com' #insert reciever email address (can be same as sender)\n",
      "gmail_user = 'mcintoshlane@gmail.com' #your gmail sender address\n",
      "gmail_pwd = 'hansolo8chewy' #your gmail password\n",
      "smtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\n",
      "smtpserver.ehlo() #the technical stuff\n",
      "smtpserver.starttls() #the technical stuff\n",
      "smtpserver.ehlo #the technical stuff\n",
      "smtpserver.login(gmail_user, gmail_pwd) #the technical stuff\n",
      "header = 'To:' + to + '\\n' + 'From: ' + gmail_user + '\\n' + 'Subject:Local Kaggle iPython Notebook \\n'\n",
      "msg = header + '\\n' + 'Your Python Script has now Completed!' #The completion message\n",
      "smtpserver.sendmail(gmail_user, to, msg) #Sending the mail\n",
      "smtpserver.close() #closing the mailserver connection"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Random Forests Take 3: Using all the metrics and a different predict function\n",
      "#### Scored x\n",
      "\n",
      "---\n",
      "Ported over from local machine with adjustments"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import cross_validation\n",
      "from scipy import optimize\n",
      "import meanAbsoluteError as err\n",
      "import numpy as np\n",
      "import datetime\n",
      "import random\n",
      "import smtplib\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import cross_validation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#DATA PROCESSING\n",
      "#create the training & test sets, skipping the header row with [1:]\n",
      "trainingDays = range(1,511) #200 days of training data, 510 total days\n",
      "headers = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\n",
      "numRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\n",
      "numCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\n",
      "isOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\n",
      "isInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\n",
      "trainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\n",
      "trainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\n",
      "for i in trainingDays:\n",
      "    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\n",
      "    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\n",
      "    for j in range(0,numCols):\n",
      "        if headers[j][0] == 'O':\n",
      "            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\n",
      "        elif headers[j][0] == 'I':\n",
      "            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\n",
      "\n",
      "#target prices 2 hours later (only outputs, no inputs) \n",
      "target = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\n",
      "target = target[:,1:]  # (day,price2HrsLater)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create the random forest\n",
      "#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
      "rf = RandomForestClassifier(n_estimators=500, n_jobs=2)  #was 1500 n_estimators\n",
      "cv = cross_validation.KFold(len(target), n_folds=25, indices=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lastObserved = trainOutput[:,-1,:]\n",
      "deriv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\n",
      "normTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numStocks   = trainOutput.shape[2]\n",
      "pred        = np.zeros((310,numStocks))\n",
      "performance = []\n",
      "for stock in xrange(numStocks):\n",
      "    numMetrics = len(trainInput[0,0])\n",
      "    X = np.array(deriv[:,stock])\n",
      "    X = X[...,None]\n",
      "\n",
      "    for j in xrange(1,10):\n",
      "        for i in xrange(numMetrics):\n",
      "            thisMetric = trainInput[:,-j,i]\n",
      "            thisMetric = thisMetric[...,None]\n",
      "            X = np.append(X,thisMetric,1)\n",
      "    \n",
      "    y     = normTarget[:,stock]\n",
      "    train = X[:200,:]\n",
      "    test  = X[200:,:]\n",
      "    \n",
      "    train_transformed = rf.fit_transform(train,y)\n",
      "    test_transformed  = rf.transform(test)\n",
      "    \n",
      "    # iterate through the training and test cross validation segments and\n",
      "    #run the classifier on each one, aggregating the results into a list\n",
      "    results = []\n",
      "    for traincv, testcv in cv:\n",
      "        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\n",
      "        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\n",
      "\n",
      "    performance.append(np.array(results).mean())\n",
      "\n",
      "    # generate predictions (making sure to add last observed value back in)\n",
      "    predicted_probs = [x[1] for x in rf.predict_proba(test_transformed)]\n",
      "    thisColumn      = np.asarray(predicted_probs)\n",
      "    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\n",
      "\n",
      "    \n",
      "\n",
      "#print out the mean of the mean of the cross-validated results\n",
      "print \"Results: \" + str( np.array(performance).mean() )\n",
      "\n",
      "    \n",
      "    \n",
      "## Save to file\n",
      "sheet = pred.tolist()  # transform pred from np array to list\n",
      "\n",
      "firstLine = ['O' + str(j) for j in xrange(1,len(sheet[0])+1)]\n",
      "firstLine.insert(0, 'fileId')\n",
      "sheet.insert(0, firstLine)\n",
      "for i in xrange(1,len(sheet)):\n",
      "    sheet[i].insert(0, str(200+i))\n",
      "\n",
      "np.savetxt('Data/submission'+str(datetime.date.today())+'.csv', sheet, delimiter=',', fmt=\"%s\")  #predictions for file 201 to 510\n",
      "\n",
      "\n",
      "## Text me when you're done\n",
      "to = 'lanemcintosh@gmail.com' #insert reciever email address (can be same as sender)\n",
      "gmail_user = 'mcintoshlane@gmail.com' #your gmail sender address\n",
      "gmail_pwd = 'hansolo8chewy' #your gmail password\n",
      "smtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\n",
      "smtpserver.ehlo() #the technical stuff\n",
      "smtpserver.starttls() #the technical stuff\n",
      "smtpserver.ehlo #the technical stuff\n",
      "smtpserver.login(gmail_user, gmail_pwd) #the technical stuff\n",
      "header = 'To:' + to + '\\n' + 'From: ' + gmail_user + '\\n' + 'Subject:Local Kaggle iPython Notebook \\n'\n",
      "msg = header + '\\n' + 'Your Python Script has now Completed!' #The completion message\n",
      "smtpserver.sendmail(gmail_user, to, msg) #Sending the mail\n",
      "smtpserver.close() #closing the mailserver connection"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/my_exceptions.py:26: DeprecationWarning: BaseException.message has been deprecated as of Python 2.6\n",
        "  self.message,\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/my_exceptions.py:26: DeprecationWarning: BaseException.message has been deprecated as of Python 2.6\n",
        "  self.message,\n"
       ]
      },
      {
       "ename": "JoblibValueError",
       "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n    ...........................................................................\n/home/lane/Kaggle/03 Predicting Stock Prices/<string> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/kernel/zmq/kernelapp.py in main()\n    463 \n    464 def main():\n    465     \"\"\"Run an IPKernel as an application\"\"\"\n    466     app = IPKernelApp.instance()\n    467     app.initialize()\n--> 468     app.start()\n        app.start = <bound method IPKernelApp.start of <IPython.kernel.zmq.kernelapp.IPKernelApp object at 0x269ac90>>\n    469 \n    470 \n    471 if __name__ == '__main__':\n    472     main()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/kernel/zmq/kernelapp.py in start(self=<IPython.kernel.zmq.kernelapp.IPKernelApp object>)\n    453     def start(self):\n    454         if self.poller is not None:\n    455             self.poller.start()\n    456         self.kernel.start()\n    457         try:\n--> 458             ioloop.IOLoop.instance().start()\n    459         except KeyboardInterrupt:\n    460             pass\n    461 \n    462 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    177         self._waker.close()\n    178         self._impl.close()\n    179     \n    180     def start(self):\n    181         try:\n--> 182             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object at 0x2720a50>>\n    183         except ZMQError as e:\n    184             if e.errno == ETERM:\n    185                 # quietly return on ETERM\n    186                 pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    667             # this IOLoop that update self._events\n    668             self._events.update(event_pairs)\n    669             while self._events:\n    670                 fd, events = self._events.popitem()\n    671                 try:\n--> 672                     self._handlers[fd](fd, events)\n        self._handlers = {<zmq.sugar.socket.Socket object at 0x2714e88>: <function wrapped at 0x2725758>, 65: <function wrapped at 0x27256e0>, <zmq.sugar.socket.Socket object at 0x271f050>: <function wrapped at 0x27257d0>}\n        fd = <zmq.sugar.socket.Socket object at 0x2714e88>\n        events = 1\n    673                 except (OSError, IOError) as e:\n    674                     if e.args[0] == errno.EPIPE:\n    675                         # Happens when the client closes the connection\n    676                         pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in wrapped(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    297                     top = n.old_contexts[1]\n    298 \n    299             # Execute callback if no exception happened while restoring state\n    300             if top is None:\n    301                 try:\n--> 302                     ret = fn(*args, **kwargs)\n        ret = None\n        args = (<zmq.sugar.socket.Socket object at 0x2714e88>, 1)\n        kwargs = {}\n    303                 except:\n    304                     exc = sys.exc_info()\n    305                     top = contexts[1]\n    306 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    422             # dispatch events:\n    423             if events & IOLoop.ERROR:\n    424                 logging.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    425                 return\n    426             if events & IOLoop.READ:\n--> 427                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object at 0x2720a10>>\n    428                 if not self.socket:\n    429                     return\n    430             if events & IOLoop.WRITE:\n    431                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    454                 logging.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    455         else:\n    456             if self._recv_callback:\n    457                 callback = self._recv_callback\n    458                 # self._recv_callback = None\n--> 459                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object at 0x2720a10>>\n        callback = <zmq.eventloop.minitornado.stack_context._StackContextWrapper object at 0x3250aa0>\n        msg = [<zmq.core.message.Frame object at 0x3b9c218>, <zmq.core.message.Frame object at 0x3b77cc8>, <zmq.core.message.Frame object at 0x3b773e0>, <zmq.core.message.Frame object at 0x3b77f28>, <zmq.core.message.Frame object at 0x32358a0>, <zmq.core.message.Frame object at 0x3235808>, <zmq.core.message.Frame object at 0x3235218>]\n    460                 \n    461         # self.update_state()\n    462         \n    463 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<zmq.eventloop.minitornado.stack_context._StackContextWrapper object>, *args=([<zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>],), **kwargs={})\n    396         close our socket.\"\"\"\n    397         try:\n    398             # Use a NullContext to ensure that all StackContexts are run\n    399             # inside our blanket exception handler rather than outside.\n    400             with stack_context.NullContext():\n--> 401                 callback(*args, **kwargs)\n        callback = <zmq.eventloop.minitornado.stack_context._StackContextWrapper object at 0x3250aa0>\n        args = ([<zmq.core.message.Frame object at 0x3b9c218>, <zmq.core.message.Frame object at 0x3b77cc8>, <zmq.core.message.Frame object at 0x3b773e0>, <zmq.core.message.Frame object at 0x3b77f28>, <zmq.core.message.Frame object at 0x32358a0>, <zmq.core.message.Frame object at 0x3235808>, <zmq.core.message.Frame object at 0x3235218>],)\n        kwargs = {}\n    402         except:\n    403             logging.error(\"Uncaught exception, closing connection.\",\n    404                           exc_info=True)\n    405             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/minitornado/stack_context.py in wrapped(*args=([<zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>],), **kwargs={})\n    236                 callback(*args, **kwargs)\n    237         elif new_contexts:\n    238             with new_contexts[0]:\n    239                 callback(*args, **kwargs)\n    240         else:\n--> 241             callback(*args, **kwargs)\n        callback = <function dispatcher at 0x325cc80>\n        args = ([<zmq.core.message.Frame object at 0x3b9c218>, <zmq.core.message.Frame object at 0x3b77cc8>, <zmq.core.message.Frame object at 0x3b773e0>, <zmq.core.message.Frame object at 0x3b77f28>, <zmq.core.message.Frame object at 0x32358a0>, <zmq.core.message.Frame object at 0x3235808>, <zmq.core.message.Frame object at 0x3235218>],)\n        kwargs = {}\n    242     return _StackContextWrapper(wrapped, fn, _state.contexts)\n    243 \n    244 \n    245 @contextlib.contextmanager\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/kernel/zmq/ipkernel.py in dispatcher(msg=[<zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>])\n    268         if self.control_stream:\n    269             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    270 \n    271         def make_dispatcher(stream):\n    272             def dispatcher(msg):\n--> 273                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.core.message.Frame object at 0x3b9c218>, <zmq.core.message.Frame object at 0x3b77cc8>, <zmq.core.message.Frame object at 0x3b773e0>, <zmq.core.message.Frame object at 0x3b77f28>, <zmq.core.message.Frame object at 0x32358a0>, <zmq.core.message.Frame object at 0x3235808>, <zmq.core.message.Frame object at 0x3235218>]\n    274             return dispatcher\n    275 \n    276         for s in self.shell_streams:\n    277             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/kernel/zmq/ipkernel.py in dispatch_shell(self=<IPython.kernel.zmq.ipkernel.Kernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'numStocks   = trainOutput.shape[2]\\npred        =...server.close() #closing the mailserver connection', 'silent': False, 'store_history': True, 'user_expressions': {}, 'user_variables': []}, 'header': {'msg_id': 'C0539C4A707F42009C5F3E5BBA21EFF8', 'msg_type': 'execute_request', 'session': 'FB28E85968364D02A146C50943F5C28E', 'username': 'username'}, 'metadata': {}, 'msg_id': 'C0539C4A707F42009C5F3E5BBA21EFF8', 'msg_type': 'execute_request', 'parent_header': {}})\n    236             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    237         else:\n    238             # ensure default_int_handler during handler call\n    239             sig = signal(SIGINT, default_int_handler)\n    240             try:\n--> 241                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <IPython.kernel.zmq.ipkernel.Kernel object at 0x2720e90>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object at 0x2720a10>\n        idents = ['FB28E85968364D02A146C50943F5C28E']\n        msg = {'parent_header': {}, 'msg_type': 'execute_request', 'msg_id': 'C0539C4A707F42009C5F3E5BBA21EFF8', 'content': {'user_variables': [], 'code': 'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'silent': False, 'allow_stdin': True, 'store_history': True, 'user_expressions': {}}, 'header': {'username': 'username', 'msg_id': 'C0539C4A707F42009C5F3E5BBA21EFF8', 'msg_type': 'execute_request', 'session': 'FB28E85968364D02A146C50943F5C28E'}, 'buffers': [], 'metadata': {}}\n    242             except Exception:\n    243                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    244             finally:\n    245                 signal(SIGINT, sig)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/kernel/zmq/ipkernel.py in execute_request(self=<IPython.kernel.zmq.ipkernel.Kernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['FB28E85968364D02A146C50943F5C28E'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'numStocks   = trainOutput.shape[2]\\npred        =...server.close() #closing the mailserver connection', 'silent': False, 'store_history': True, 'user_expressions': {}, 'user_variables': []}, 'header': {'msg_id': 'C0539C4A707F42009C5F3E5BBA21EFF8', 'msg_type': 'execute_request', 'session': 'FB28E85968364D02A146C50943F5C28E', 'username': 'username'}, 'metadata': {}, 'msg_id': 'C0539C4A707F42009C5F3E5BBA21EFF8', 'msg_type': 'execute_request', 'parent_header': {}})\n    385             self._publish_pyin(code, parent, shell.execution_count)\n    386 \n    387         reply_content = {}\n    388         try:\n    389             # FIXME: the shell calls the exception handler itself.\n--> 390             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object at 0x2720f90>>\n        code = 'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection'\n        store_history = True\n        silent = False\n    391         except:\n    392             status = u'error'\n    393             # FIXME: this code right now isn't being used yet by default,\n    394             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/core/interactiveshell.py in run_cell(self=<IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object>, raw_cell='numStocks   = trainOutput.shape[2]\\npred        =...server.close() #closing the mailserver connection', store_history=True, silent=False, shell_futures=True)\n   2662                     \n   2663                     code_ast = self.transform_ast(code_ast)\n   2664                     \n   2665                     interactivity = \"none\" if silent else self.ast_node_interactivity\n   2666                     self.run_ast_nodes(code_ast.body, cell_name,\n-> 2667                                        interactivity=interactivity, compiler=compiler)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance at 0x272bcb0>\n   2668                     \n   2669                     # Execute any registered post-execution functions.\n   2670                     # unless we are silent\n   2671                     post_exec = [] if silent else self._post_execute.iteritems()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/core/interactiveshell.py in run_ast_nodes(self=<IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.For object>, <_ast.Print object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.For object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, ...], cell_name='<ipython-input-134-831b400e8055>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>)\n   2766 \n   2767         try:\n   2768             for i, node in enumerate(to_run_exec):\n   2769                 mod = ast.Module([node])\n   2770                 code = compiler(mod, cell_name, \"exec\")\n-> 2771                 if self.run_code(code):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object at 0x2720f90>>\n        code = <code object <module> at 0x7f394b7ac730, file \"<ipython-input-134-831b400e8055>\", line 4>\n   2772                     return True\n   2773 \n   2774             for i, node in enumerate(to_run_interactive):\n   2775                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/core/interactiveshell.py in run_code(self=<IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f394b7ac730, file \"<ipython-input-134-831b400e8055>\", line 4>)\n   2822         outflag = 1  # happens in more places, so it's easier as default\n   2823         try:\n   2824             try:\n   2825                 self.hooks.pre_run_code_hook()\n   2826                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2827                 exec code_obj in self.user_global_ns, self.user_ns\n        code_obj = <code object <module> at 0x7f394b7ac730, file \"<ipython-input-134-831b400e8055>\", line 4>\n        self.user_global_ns = {'disp': <function disp at 0x236cd70>, 'union1d': <function union1d at 0x236c0c8>, 'all': <function all at 0x21da398>, '_i132': u'sheet.shape', 'dist': <function dist at 0x2c51758>, 'issubsctype': <function issubsctype at 0x21b8f50>, 'sca': <function sca at 0x3195410>, 'savez': <function savez at 0x23fb1b8>, '_i58': u\"fig = gcf()\\nfig.set_size_inches(16,6)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", 'entropy': <function entropy at 0x2c4fe60>, 'atleast_2d': <function atleast_2d at 0x2274668>, 'restoredot': <built-in function restoredot>, '_95': (510, 1), 'streamplot': <function streamplot at 0x3197b90>, '_93': (310,), '_92': (200,), 'ptp': <function ptp at 0x21da500>, 'Subplot': <class 'matplotlib.axes.AxesSubplot'>, 'frange': <function frange at 0x2c52050>, 'PackageLoader': <class 'numpy._import_tools.PackageLoader'>, 'show': <function show at 0x3194398>, '_83': (201,), 'fft2': <function fft2 at 0x2409320>, '_63': <matplotlib.text.Text object at 0x8d13e90>, 'xkcd': <function xkcd at 0x3194848>, 'rec2csv': <function rec2csv at 0x2c535f0>, 'ix_': <function ix_ at 0x236db18>, 'resize': <function resize at 0x21d1c80>, '_64': <matplotlib.text.Text object at 0x9b88ad0>, 'blackman': <function blackman at 0x236d140>, '_68': (200, 198), 'norm': <function norm at 0x238ccf8>, 'FLOATING_POINT_SUPPORT': 1, '_i85': u'train.shape', 'MultipleLocator': <class 'matplotlib.ticker.MultipleLocator'>, 'mlab': <module 'matplotlib.mlab' from '/usr/local/lib/python2.7/dist-packages/matplotlib/mlab.pyc'>, 'busdaycalendar': <type 'numpy.busdaycalendar'>, 'pkgload': <function pkgload at 0x2107050>, 'mpl': <module 'matplotlib' from '/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc'>, 'rc': <function rc at 0x3194668>, 'thetagrids': <function thetagrids at 0x3195f50>, 'results': [0.40249999999999986, 0.3805, 1.05975, 0.6737500000000001, 0.6269999999999998, 0.41200000000000003, 0.9955, 0.38125000000000003, 0.6900000000000002, 0.8010000000000002, 0.6927500000000002, 0.9587500000000002, 1.095, 1.0350000000000001, 0.975, 0.6989999999999998, 0.7677500000000002, 0.48375, 0.6754999999999998, 1.056, 0.9384999999999999, 0.5549999999999999, 0.48974999999999996, 0.7722500000000001, 0.70925], '_104': (510,), '_i114': u'yoda = np.asarray(predicted_probs)\\nyoda.shape', 'ERR_RAISE': 2, '_i61': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('yoda')\", 'testcv': array([False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), 'cool': <function cool at 0x3198578>, 'tri': <function tri at 0x230d7d0>, 'lapack_lite': <module 'numpy.linalg.lapack_lite' from '/usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so'>, 'diag_indices': <function diag_indices at 0x23748c0>, 'window_hanning': <function window_hanning at 0x2c4f578>, 'array_equal': <function array_equal at 0x21dbf50>, 'FormatStrFormatter': <class 'matplotlib.ticker.FormatStrFormatter'>, '_i25': u'target.shape', '_i22': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(target[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'tanh': <ufunc 'tanh'>, 'longest_contiguous_ones': <function longest_contiguous_ones at 0x2c510c8>, 'get_plot_commands': <function get_plot_commands at 0x31960c8>, 'uint32': <type 'numpy.uint32'>, 'array_equiv': <function array_equiv at 0x21dd050>, '_i12': u'trainInput.shape', 'fftn': <function fftn at 0x2409230>, '_i10': u'len(target)', '_i17': u'trainInput[509,54,244]', '_i16': u'trainInput[509,54,243]', '_i15': u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:198] = trainOutput\\nfullInput[:,:,198:] = trainInput', '_i14': u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:197] = trainOutput\\nfullInput[:,:,198:] = trainInput', 'indices': <function indices at 0x21dbaa0>, 'fftpack': <module 'numpy.fft.fftpack' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack.pyc'>, 'loads': <built-in function loads>, '_i18': u'trainInput[509,54,243]', '_ii': u'sheet.shape', 'set_numeric_ops': <built-in function set_numeric_ops>, '_114': (310,), 'pmt': <function pmt at 0x23fbc08>, 'polar': <function polar at 0x3196578>, 'diag_indices_from': <function diag_indices_from at 0x2374938>, 'object0': <type 'numpy.object_'>, 'ishold': <function ishold at 0x3195230>, 'rate': <function rate at 0x23fbf50>, 'FPE_OVERFLOW': 2, 'Circle': <class 'matplotlib.patches.Circle'>, 'index_exp': <numpy.lib.index_tricks.IndexExpression object at 0x236fa50>, 'append': <function append at 0x236da28>, 'logseries': <built-in method logseries of mtrand.RandomState object at 0x7f399f841690>, '_i128': u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=500, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=25, indices=False)', '_i129': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', 'nanargmax': <function nanargmax at 0x236ccf8>, 'hstack': <function hstack at 0x22747d0>, 'typename': <function typename at 0x2301b18>, 'YearLocator': <class 'matplotlib.dates.YearLocator'>, 'diag': <function diag at 0x230d6e0>, 'pyplot': <module 'matplotlib.pyplot' from '/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc'>, 'axes': <function axes at 0x3195320>, 'ERR_WARN': 1, '_i127': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'unravel_index': <built-in function unravel_index>, 'uniform': <built-in method uniform of mtrand.RandomState object at 0x7f399f841690>, 'polyfit': <function polyfit at 0x238ced8>, 'nanmin': <function nanmin at 0x236cb90>, 'memmap': <class 'numpy.core.memmap.memmap'>, 'axvline': <function axvline at 0x31969b0>, '_90': (200,), 'irfftn': <function irfftn at 0x2409500>, 'nan_to_num': <function nan_to_num at 0x23019b0>, 'twinx': <function twinx at 0x3195668>, 'contourf': <function contourf at 0x3196de8>, 'complex64': <type 'numpy.complex64'>, 'deriv': array([[ 0.04,  0.04, -0.02, ...,  0.  ,  0.02, -0.04],\n       [-0.11, -0.04,  0.02, ..., -0.11, -0.04, -0.08],\n       [-0.08,  0.02, -0.02, ..., -0.02, -0.02, -0.06],\n       ..., \n       [ 0.27,  0.02,  0.  , ...,  0.25,  0.15, -0.04],\n       [ 0.  , -0.01,  0.  , ..., -0.05,  0.02,  0.  ],\n       [ 0.31,  0.  , -0.03, ...,  0.04,  0.02,  0.06]]), '_i34': u'target.shape', 'fmax': <ufunc 'fmax'>, 'copysign': <ufunc 'copysign'>, 'matplotlib': <module 'matplotlib' from '/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc'>, 'l2norm': <function l2norm at 0x2c51ed8>, 'FigureCanvasBase': <class 'matplotlib.backend_bases.FigureCanvasBase'>, 'sinh': <ufunc 'sinh'>, 'unicode_': <type 'numpy.unicode_'>, 'rgrids': <function rgrids at 0x3195ed8>, 'legend': <function legend at 0x31980c8>, 'trunc': <ufunc 'trunc'>, 'box': <function box at 0x31958c0>, 'vstack': <function vstack at 0x2274758>, 'finfo': <class 'numpy.core.getlimits.finfo'>, 'ERR_PRINT': 4, 'levypdf': <function levypdf at 0x2c4ff50>, 'IndexDateFormatter': <class 'matplotlib.dates.IndexDateFormatter'>, 'MO': MO, 'asscalar': <function asscalar at 0x2301aa0>, 'LogLocator': <class 'matplotlib.ticker.LogLocator'>, 'binomial': <built-in method binomial of mtrand.RandomState object at 0x7f399f841690>, 'broken_barh': <function broken_barh at 0x3196b90>, 'poisson': <built-in method poisson of mtrand.RandomState object at 0x7f399f841690>, 'HourLocator': <class 'matplotlib.dates.HourLocator'>, 'less_equal': <ufunc 'less_equal'>, 'l1norm': <function l1norm at 0x2c51e60>, 'BUFSIZE': 8192, 'sci': <function sci at 0x31947d0>, 'object_': <type 'numpy.object_'>, 'FR': FR, 'shuffle': <built-in method shuffle of mtrand.RandomState object at 0x7f399f841690>, 'divide': <ufunc 'divide'>, 'csingle': <type 'numpy.complex64'>, 'dtype': <type 'numpy.dtype'>, 'unsignedinteger': <type 'numpy.unsignedinteger'>, '_i110': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'fftshift': <function fftshift at 0x2409668>, 'fastCopyAndTranspose': <built-in function _fastCopyAndTranspose>, 'num2date': <function num2date at 0x307d0c8>, 'silent_list': <class 'matplotlib.cbook.silent_list'>, 'bitwise_and': <ufunc 'bitwise_and'>, 'uintc': <type 'numpy.uint32'>, '_i30': u'lastObserved = trainOutput[:,-1,:]\\nlastObserved.shape', 'byte': <type 'numpy.int8'>, 'select': <function select at 0x236c488>, 'ticklabel_format': <function ticklabel_format at 0x31982a8>, 'deg2rad': <ufunc 'deg2rad'>, 'plot': <function plot at 0x31975f0>, 'nditer': <type 'numpy.nditer'>, 'eye': <function eye at 0x230d668>, 'triu_indices': <function triu_indices at 0x230db90>, 'kron': <function kron at 0x2377140>, 'newbuffer': <built-in function newbuffer>, '_i86': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:200]\\ntest  = X[200:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'pred': array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       ..., \n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]]), 'negative': <ufunc 'negative'>, 'busday_offset': <built-in function busday_offset>, 'mintypecode': <function mintypecode at 0x2301410>, 'standard_gamma': <built-in method standard_gamma of mtrand.RandomState object at 0x7f399f841690>, 'lstsq': <function lstsq at 0x238cc80>, 'print_function': _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 65536), 'header': 'To:lanemcintosh@gmail.com\\nFrom: mcintoshlane@gmail.com\\nSubject:Kaggle iPython Notebook \\n', '_26': (200, 198), '_27': (510, 55, 244), '_24': 55, '_25': (200, 198), 'MAXDIMS': 32, 'clabel': <function clabel at 0x3196cf8>, 'setxor1d': <function setxor1d at 0x2369f50>, '_21': (510, 55, 442), 'rk4': <function rk4 at 0x2c51578>, 'fftfreq': <function fftfreq at 0x2409758>, 'ifft2': <function ifft2 at 0x2409398>, 'longdouble': <type 'numpy.float128'>, 'uint0': <type 'numpy.uint64'>, 'zeros_like': <function zeros_like at 0x21c2398>, '_i62': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',norm=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_i63': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',normed=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_i60': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nyaxis('yoda')\", 'ylabel': <function ylabel at 0x3195aa0>, 'int_asbuffer': <built-in function int_asbuffer>, 'uint8': <type 'numpy.uint8'>, '_i64': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_i65': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", 'chararray': <class 'numpy.core.defchararray.chararray'>, 'train': array([[  0.04    ,   1.5     ,   2.      , ...,   0.439681,   0.074476,\n          0.142166],\n       [ -0.11    ,   0.789473,  19.      , ...,   0.767666,   0.147196,\n          0.272029],\n       [ -0.08    ,   0.5     ,  12.      , ...,   0.216333,   0.062503,\n          0.062272],\n       ..., \n       [ -0.17    ,   0.222222,   9.      , ...,   0.405073,   0.133066,\n          0.126095],\n       [  0.15    ,  -0.2     ,  10.      , ...,   0.32209 ,   0.127541,\n          0.195192],\n       [  0.11    ,   0.      ,  10.      , ...,   0.232735,   0.130486,\n          0.113186]]), 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'linspace': <function linspace at 0x2270d70>, '_i32': u'normTarget   = target - lastObserved[:target.shape[0],:]', 'hold': <function hold at 0x31951b8>, 'mirr': <function mirr at 0x23fe140>, 'uint64': <type 'numpy.uint64'>, 'sample': <built-in method random_sample of mtrand.RandomState object at 0x7f399f841690>, 'ma': <module 'numpy.ma' from '/usr/local/lib/python2.7/dist-packages/numpy/ma/__init__.pyc'>, 'err': <module 'meanAbsoluteError' from 'meanAbsoluteError.pyc'>, 'f': <built-in method f of mtrand.RandomState object at 0x7f399f841690>, 'hist2d': <function hist2d at 0x31972a8>, 'Text': <class 'matplotlib.text.Text'>, 'isneginf': <function isneginf at 0x2301578>, 'true_divide': <ufunc 'true_divide'>, 'det': <function det at 0x238cc08>, 'SU': SU, 'DateLocator': <class 'matplotlib.dates.DateLocator'>, '_i122': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', '_i8': u'len(trainOutput)', 'thisColumn': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.07301677,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.07301677,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.07301677,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.07301677,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.07301677,  0.07301677,  0.        ,  0.        ]), 'SA': SA, 'rc_context': <function rc_context at 0x31946e0>, 'scatter': <function scatter at 0x3197848>, 'Out': {8: 510, 10: 200, 12: (510, 55, 244), 13: (510, 55, 198), 16: 0.32388299999999998, 18: 0.32388299999999998, 19: 0.32388299999999998, 21: (510, 55, 442), 23: (510, 55, 198), 24: 55, 25: (200, 198), 26: (200, 198), 27: (510, 55, 244), 30: (510, 198), 31: (200, 198), 33: (200, 198), 34: (200, 198), 35: [<matplotlib.lines.Line2D object at 0x3c0f110>], 36: [<matplotlib.lines.Line2D object at 0x3df1610>], 37: (array([   3.,   11.,   42.,  112.,   26.,    4.,    0.,    0.,    0.,    2.]), array([-2.12 , -1.478, -0.836, -0.194,  0.448,  1.09 ,  1.732,  2.374,\n        3.016,  3.658,  4.3  ]), <a list of 10 Patch objects>), 38: ([array([   0.,    0.,    0.,   11.,  179.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  189.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  189.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  194.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  188.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  191.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   12.,  181.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  193.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   23.,  158.,   11.,    2.,    0.,    2.,    0.]), array([   2.,    0.,    2.,   16.,  159.,   19.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  196.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  187.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  192.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  194.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  184.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  192.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    3.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   1.,    0.,    2.,   28.,  148.,   17.,    3.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  186.,    9.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  184.,    2.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  177.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,    7.,  186.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   20.,  168.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    2.,    0.,   15.,  167.,   16.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    0.,   14.,  167.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,   16.,  165.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   14.,  182.,    2.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    3.,   26.,  153.,   16.,    0.,    0.,    2.,    0.]), array([   3.,    1.,    7.,   46.,  102.,   26.,    8.,    3.,    2.,    2.]), array([   0.,    2.,    0.,   12.,  176.,   10.,    0.,    0.,    0.,    0.]), array([   2.,    0.,    1.,   20.,  155.,   18.,    4.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  181.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  184.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  189.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  182.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   11.,  182.,    6.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  184.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   22.,  166.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  195.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    3.,  193.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  190.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  196.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   29.,  140.,   21.,    4.,    2.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  190.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    3.,   31.,  144.,   17.,    3.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  193.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  188.,    4.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.])], array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 198 Lists of Patches objects>), 44: (200, 198), 52: (array([  8.00000000e+00,   9.00000000e+00,   3.80000000e+01,\n         8.42000000e+02,   3.81220000e+04,   5.27000000e+02,\n         3.80000000e+01,   8.00000000e+00,   6.00000000e+00,\n         2.00000000e+00]), array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 10 Patch objects>), 53: (array([  2.00000000e+00,   0.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         1.00000000e+00,   2.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         2.00000000e+00,   7.00000000e+00,   3.00000000e+00,\n         4.00000000e+00,   7.00000000e+00,   8.00000000e+00,\n         2.20000000e+01,   2.00000000e+01,   1.30000000e+01,\n         2.40000000e+01,   5.30000000e+01,   5.30000000e+01,\n         8.10000000e+01,   1.17000000e+02,   1.68000000e+02,\n         2.91000000e+02,   5.90000000e+02,   1.25600000e+03,\n         2.75800000e+03,   8.53900000e+03,   1.52450000e+04,\n         6.19300000e+03,   1.99500000e+03,   9.18000000e+02,\n         4.14000000e+02,   2.14000000e+02,   1.21000000e+02,\n         1.11000000e+02,   7.50000000e+01,   6.70000000e+01,\n         3.50000000e+01,   3.70000000e+01,   3.00000000e+01,\n         2.50000000e+01,   2.00000000e+01,   6.00000000e+00,\n         7.00000000e+00,   6.00000000e+00,   9.00000000e+00,\n         4.00000000e+00,   3.00000000e+00,   1.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n         3.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         3.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         1.00000000e+00]), array([-15.55  , -15.1994, -14.8488, -14.4982, -14.1476, -13.797 ,\n       -13.4464, -13.0958, -12.7452, -12.3946, -12.044 , -11.6934,\n       -11.3428, -10.9922, -10.6416, -10.291 ,  -9.9404,  -9.5898,\n        -9.2392,  -8.8886,  -8.538 ,  -8.1874,  -7.8368,  -7.4862,\n        -7.1356,  -6.785 ,  -6.4344,  -6.0838,  -5.7332,  -5.3826,\n        -5.032 ,  -4.6814,  -4.3308,  -3.9802,  -3.6296,  -3.279 ,\n        -2.9284,  -2.5778,  -2.2272,  -1.8766,  -1.526 ,  -1.1754,\n        -0.8248,  -0.4742,  -0.1236,   0.227 ,   0.5776,   0.9282,\n         1.2788,   1.6294,   1.98  ,   2.3306,   2.6812,   3.0318,\n         3.3824,   3.733 ,   4.0836,   4.4342,   4.7848,   5.1354,\n         5.486 ,   5.8366,   6.1872,   6.5378,   6.8884,   7.239 ,\n         7.5896,   7.9402,   8.2908,   8.6414,   8.992 ,   9.3426,\n         9.6932,  10.0438,  10.3944,  10.745 ,  11.0956,  11.4462,\n        11.7968,  12.1474,  12.498 ,  12.8486,  13.1992,  13.5498,\n        13.9004,  14.251 ,  14.6016,  14.9522,  15.3028,  15.6534,\n        16.004 ,  16.3546,  16.7052,  17.0558,  17.4064,  17.757 ,\n        18.1076,  18.4582,  18.8088,  19.1594,  19.51  ]), <a list of 100 Patch objects>), 61: <matplotlib.text.Text object at 0x8c45410>, 63: <matplotlib.text.Text object at 0x8d13e90>, 64: <matplotlib.text.Text object at 0x9b88ad0>, 65: <matplotlib.text.Text object at 0x92e02d0>, 66: (510, 55, 198), 67: (510, 198), 68: (200, 198), 70: 200, 71: sklearn.cross_validation.KFold(n=200, n_folds=63), 74: array([False, False, False, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), 75: (200,), 76: (200,), 77: array([[[ 0.      ,  0.      ,  0.      , ...,  0.160672,  0.054283,\n          0.060093],\n        [ 1.61    ,  0.12    ,  0.12    , ...,  0.246306,  0.448241,\n          0.377197],\n        [ 1.12    ,  0.31    ,  0.12    , ...,  0.281271,  0.484713,\n          0.431599],\n        ..., \n        [ 0.9     ,  0.19    ,  0.07    , ...,  0.119027,  0.084617,\n          0.074685],\n        [ 0.87    ,  0.22    ,  0.08    , ...,  0.122028,  0.058538,\n          0.080691],\n        [ 0.83    ,  0.25    ,  0.08    , ...,  0.125018,  0.043205,\n          0.088569]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.405808,  0.188892,\n          0.209284],\n        [ 0.95    , -0.18    ,  0.15    , ...,  0.42738 ,  0.348119,\n          0.34322 ],\n        [ 1.04    , -0.18    ,  0.15    , ...,  0.463135,  0.439758,\n          0.449271],\n        ..., \n        [ 0.87    , -0.01    ,  0.1     , ...,  0.447247,  0.132313,\n          0.208433],\n        [ 0.83    ,  0.      ,  0.05    , ...,  0.445714,  0.153232,\n          0.138243],\n        [ 0.97    , -0.05    ,  0.05    , ...,  0.445714,  0.155649,\n          0.138243]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.934708,  0.084538,\n          0.154596],\n        [ 2.75    ,  0.25    ,  0.      , ...,  0.859673,  0.675959,\n          0.553122],\n        [ 2.22    ,  0.24    ,  0.      , ...,  0.800801,  0.754047,\n          0.652951],\n        ..., \n        [ 6.09    , -0.13    ,  0.      , ...,  0.717239,  0.111535,\n          0.55109 ],\n        [ 6.22    , -0.13    ,  0.      , ...,  0.712795,  0.116218,\n          0.388987],\n        [ 5.75    , -0.17    ,  0.      , ...,  0.715292,  0.152665,\n          0.252609]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.199729,  0.051769,\n          0.117898],\n        [-3.29    ,  0.04    ,  0.24    , ...,  0.349317,  0.77501 ,\n          0.659621],\n        [-3.53    ,  0.06    ,  0.37    , ...,  0.460716,  1.013778,\n          0.894228],\n        ..., \n        [-2.21    ,  1.33    ,  0.5     , ...,  0.221407,  0.051251,\n          0.160312],\n        [-2.25    ,  1.27    ,  0.54    , ...,  0.203557,  0.054283,\n          0.14087 ],\n        [-2.42    ,  1.27    ,  0.53    , ...,  0.185629,  0.059889,\n          0.054874]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.52827 ,  0.128219,\n          0.104881],\n        [ 0.17    , -0.06    ,  0.      , ...,  0.520413,  0.180665,\n          0.150702],\n        [ 0.59    , -0.12    , -0.06    , ...,  0.520859,  0.288167,\n          0.243676],\n        ..., \n        [ 0.97    , -0.24    , -0.08    , ...,  0.296868,  0.023381,\n          0.264344],\n        [ 0.82    , -0.24    , -0.08    , ...,  0.297405,  0.037417,\n          0.211529],\n        [ 0.97    , -0.18    , -0.04    , ...,  0.298542,  0.037238,\n          0.132077]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.31634 ,  0.082624,\n          0.108628],\n        [-0.71    ,  0.26    ,  0.74    , ...,  0.307045,  0.20775 ,\n          0.205129],\n        [-1.06    ,  0.19    ,  0.74    , ...,  0.31471 ,  0.277897,\n          0.274672],\n        ..., \n        [-1.04    , -0.08    ,  0.12    , ...,  0.184709,  0.06532 ,  0.16    ],\n        [-0.95    , -0.19    ,  0.12    , ...,  0.178122,  0.028284,\n          0.152315],\n        [-0.84    , -0.18    ,  0.12    , ...,  0.173413,  0.054283,\n          0.123063]]]), 78: (510, 55, 442), 81: (510,), 83: (201,), 84: (309,), 85: (201,), 87: (200,), 88: (310,), 89: (200,), 90: (200,), 92: (200,), 93: (310,), 95: (510, 1), 102: 310, 104: (510,), 108: <matplotlib.text.Text object at 0x918f1d0>, 109: 198, 111: <matplotlib.text.Text object at 0x9894b90>, 113: <type 'list'>, 114: (310,), 116: -3.8199999999999998}, 'Normalize': <class 'matplotlib.colors.Normalize'>, 'spy': <function spy at 0x3196758>, 'train_transformed': array([[  4.00000000e-02,   2.05333333e+02,   3.26666670e+01, ...,\n          6.56650000e-01,   7.30560000e-01,   7.44760000e-02],\n       [ -1.10000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          3.24497000e-01,   2.54928000e-01,   1.47196000e-01],\n       [ -8.00000000e-02,   0.00000000e+00,   0.00000000e+00, ...,\n          9.13311000e-01,   9.19309000e-01,   6.25030000e-02],\n       ..., \n       [ -1.70000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          9.63428000e-01,   9.62613000e-01,   1.33066000e-01],\n       [  1.50000000e-01,   2.19333333e+02,   4.73333330e+01, ...,\n          9.05099000e-01,   6.36617000e-01,   1.27541000e-01],\n       [  1.10000000e-01,   6.95000000e+01,   7.55000000e+01, ...,\n          3.40341000e-01,   2.59492000e-01,   1.30486000e-01]]), 'MinuteLocator': <class 'matplotlib.dates.MinuteLocator'>, 'quiver': <function quiver at 0x3197758>, 'figure': <function figure at 0x3194938>, 'subplot2grid': <function subplot2grid at 0x31955f0>, 'get_sparse_matrix': <function get_sparse_matrix at 0x2c516e0>, 'add_newdoc': <function add_newdoc at 0x236d848>, 'seterrcall': <function seterrcall at 0x21dd2a8>, 'autumn': <function autumn at 0x31966e0>, 'logical_or': <ufunc 'logical_or'>, 'minimum': <ufunc 'minimum'>, 'WRAP': 1, 'tan': <ufunc 'tan'>, 'rms_flat': <function rms_flat at 0x2c51de8>, 'absolute': <ufunc 'absolute'>, 'gca': <function gca at 0x3195488>, 'winter': <function winter at 0x3198aa0>, 'gcf': <function gcf at 0x31949b0>, 'gci': <function gci at 0x31945f0>, 'csd': <function csd at 0x3196e60>, 'RRuleLocator': <class 'matplotlib.dates.RRuleLocator'>, 'get_array_wrap': <function get_array_wrap at 0x23770c8>, 'polymul': <function polymul at 0x238d140>, 'hot': <function hot at 0x3198758>, 'minorticks_off': <function minorticks_off at 0x3195e60>, '_81': (510,), 'get_ipython': <bound method ZMQInteractiveShell.get_ipython of <IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object at 0x2720f90>>, 'get_figlabels': <function get_figlabels at 0x3194aa0>, 'tile': <function tile at 0x23771b8>, 'array_str': <function array_str at 0x21db9b0>, 'eigvalsh': <function eigvalsh at 0x238c7d0>, 'pinv': <function pinv at 0x238cb18>, 'stock': 0, 'longlong': <type 'numpy.int64'>, 'pink': <function pink at 0x31988c0>, 'product': <function product at 0x21da1b8>, 'int16': <type 'numpy.int16'>, 's_': <numpy.lib.index_tricks.IndexExpression object at 0x236fad0>, 'mat': <function asmatrix at 0x236dc80>, 'fv': <function fv at 0x23fbb90>, 'summer': <function summer at 0x3198a28>, '_i123': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random\\nimport smtplib\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', 'yticks': <function yticks at 0x3195d70>, 'docstring': <module 'matplotlib.docstring' from '/usr/local/lib/python2.7/dist-packages/matplotlib/docstring.pyc'>, '_i36': u'plot(normTarget[:,197])', 'asanyarray': <function asanyarray at 0x21c25f0>, 'uint': <type 'numpy.uint64'>, 'negative_binomial': <built-in method negative_binomial of mtrand.RandomState object at 0x7f399f841690>, 'npv': <function npv at 0x23fe0c8>, 'logaddexp': <ufunc 'logaddexp'>, 'flatnonzero': <function flatnonzero at 0x21c28c0>, 'short': <type 'numpy.int16'>, 'correlate': <function correlate at 0x21c29b0>, 'getfigs': <function getfigs at 0x1de1848>, 'fromstring': <built-in function fromstring>, 'pylab_setup': <function pylab_setup at 0x3186cf8>, 'left_shift': <ufunc 'left_shift'>, 'tricontour': <function tricontour at 0x3197c08>, 'subplots': <function subplots at 0x3195578>, 'searchsorted': <function searchsorted at 0x21d1c08>, 'barbs': <function barbs at 0x3197ed8>, 'int64': <type 'numpy.int64'>, 'gamma': <built-in method gamma of mtrand.RandomState object at 0x7f399f841690>, 'may_share_memory': <function may_share_memory at 0x2369500>, '_76': (200,), '__': (310,), 'GridSpec': <class 'matplotlib.gridspec.GridSpec'>, 'help': Type help() for interactive help, or help(object) for help about object., 'xlim': <function xlim at 0x3195b18>, 'copper': <function copper at 0x31985f0>, 'MONTHLY': 1, 'dsplit': <function dsplit at 0x2374f50>, 'intersect1d': <function intersect1d at 0x2369ed8>, 'cosh': <ufunc 'cosh'>, 'window_none': <function window_none at 0x2c4f5f0>, 'can_cast': <built-in function can_cast>, 'performance': [0.73306000000000016], 'ppmt': <function ppmt at 0x23fbde8>, '__package__': None, 'cumsum': <function cumsum at 0x21da410>, 'roots': <function roots at 0x238cd70>, 'Widget': <class 'matplotlib.widgets.Widget'>, 'outer': <function outer at 0x21c2aa0>, 'intc': <type 'numpy.int32'>, 'fix': <function fix at 0x2301488>, 'stineman_interp': <function stineman_interp at 0x2c537d0>, 'busday_count': <built-in function busday_count>, 'cla': <function cla at 0x3197f50>, 'timedelta64': <type 'numpy.timedelta64'>, 'strpdate2num': <class matplotlib.dates.strpdate2num at 0x3025460>, 'Rectangle': <class 'matplotlib.patches.Rectangle'>, 'standard_exponential': <built-in method standard_exponential of mtrand.RandomState object at 0x7f399f841690>, 'subplot_tool': <function subplot_tool at 0x31957d0>, 'choose': <function choose at 0x21d17d0>, '_i': u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', '_i38': u'hist(normTarget)', 'FPE_INVALID': 8, 'recfromcsv': <function recfromcsv at 0x23fb6e0>, 'fill_diagonal': <function fill_diagonal at 0x23742a8>, 'void0': <type 'numpy.void'>, 'get_fignums': <function get_fignums at 0x3194a28>, 'exception_to_str': <function exception_to_str at 0x2994b18>, 'SECONDLY': 6, 'logaddexp2': <ufunc 'logaddexp2'>, 'greater': <ufunc 'greater'>, 'suptitle': <function suptitle at 0x31950c8>, '_109': 198, 'get_backend': <function get_backend at 0x2a00668>, '_i83': u'train.shape', 'matrix_power': <function matrix_power at 0x236dcf8>, 'histogram2d': <function histogram2d at 0x230d9b0>, 'LogFormatter': <class 'matplotlib.ticker.LogFormatter'>, 'polyint': <function polyint at 0x238cde8>, 'nonzero': <function nonzero at 0x21d1ed8>, '_88': (310,), 'rank': <function rank at 0x21da848>, 'quiverkey': <function quiverkey at 0x31977d0>, 'datetime64': <type 'numpy.datetime64'>, '_84': (309,), 'complexfloating': <type 'numpy.complexfloating'>, 'is_numlike': <function is_numlike at 0x29929b0>, '_i50': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],0))', 'ndindex': <class 'numpy.lib.index_tricks.ndindex'>, 'ctypeslib': <module 'numpy.ctypeslib' from '/usr/local/lib/python2.7/dist-packages/numpy/ctypeslib.pyc'>, 'waitforbuttonpress': <function waitforbuttonpress at 0x3194f50>, '_i120': u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'PZERO': 0.0, 'relativedelta': <class 'dateutil.relativedelta.relativedelta'>, 'MonthLocator': <class 'matplotlib.dates.MonthLocator'>, 'asfarray': <function asfarray at 0x23015f0>, 'gmail_user': 'mcintoshlane@gmail.com', 'radians': <ufunc 'radians'>, 'sin': <ufunc 'sin'>, 'fliplr': <function fliplr at 0x230d500>, 'alen': <function alen at 0x21da668>, '_13': (510, 55, 198), 'recarray': <class 'numpy.core.records.recarray'>, 'fmod': <ufunc 'fmod'>, '_10': 200, '_i73': u'for i,j in cv:\\n    print i,j', 'bone': <function bone at 0x3198500>, 'mean': <function mean at 0x21daa28>, 'griddata': <function griddata at 0x2c53668>, 'poly_below': <function poly_below at 0x2c538c0>, 'square': <ufunc 'square'>, 'isvector': <function isvector at 0x2c52320>, 'ogrid': <numpy.lib.index_tricks.nd_grid object at 0x236f950>, 'bytes': <type 'str'>, 'nanargmin': <function nanargmin at 0x236cc08>, 'r_': <numpy.lib.index_tricks.RClass object at 0x236f990>, 'hanning': <function hanning at 0x236d230>, 'trainInput': array([[[ -8.00000000e-01,   5.00000000e+00,   0.00000000e+00, ...,\n           2.99584000e-01,   3.88160000e-02,   8.13090000e-02],\n        [  1.33333300e+00,   3.00000000e+00,   0.00000000e+00, ...,\n           3.14446000e-01,   2.51952000e-01,   2.06263000e-01],\n        [  6.66666000e-01,   3.00000000e+00,   5.00000000e+00, ...,\n           3.57783000e-01,   5.10176000e-01,   4.29069000e-01],\n        ..., \n        [  6.66666000e-01,   3.00000000e+00,   0.00000000e+00, ...,\n           2.69088000e-01,   1.26912000e-01,   1.03441000e-01],\n        [  0.00000000e+00,   2.00000000e+00,   1.00000000e+00, ...,\n           2.62727000e-01,   1.33116000e-01,   1.11704000e-01],\n        [  1.50000000e+00,   2.00000000e+00,   5.00000000e+00, ...,\n           2.59782000e-01,   1.21326000e-01,   1.24544000e-01]],\n\n       [[  2.92682000e-01,   4.10000000e+01,   0.00000000e+00, ...,\n           3.20344000e-01,   7.12740000e-02,   5.78310000e-02],\n        [  3.33333000e-01,   3.00000000e+00,   0.00000000e+00, ...,\n           4.10495000e-01,   6.34182000e-01,   5.21483000e-01],\n        [  2.00000000e+00,   1.00000000e+00,   3.00000000e+00, ...,\n           4.78352000e-01,   7.94850000e-01,   6.90853000e-01],\n        ..., \n        [  0.00000000e+00,   1.10000000e+01,   0.00000000e+00, ...,\n           2.31589000e-01,   6.77250000e-02,   9.07990000e-02],\n        [  3.33333000e-01,   1.50000000e+01,   1.00000000e+00, ...,\n           2.31602000e-01,   7.23880000e-02,   1.00995000e-01],\n        [  7.89473000e-01,   1.90000000e+01,   0.00000000e+00, ...,\n           2.25328000e-01,   4.84420000e-02,   8.36660000e-02]],\n\n       [[  4.41860000e-01,   4.30000000e+01,   0.00000000e+00, ...,\n           1.96550000e-01,   1.50555000e-01,   1.20830000e-01],\n        [  6.66666000e-01,   3.00000000e+00,   5.00000000e+00, ...,\n           1.94066000e-01,   1.53753000e-01,   1.28841000e-01],\n        [  0.00000000e+00,   1.00000000e+00,   5.00000000e+00, ...,\n           1.87594000e-01,   1.53753000e-01,   1.32288000e-01],\n        ..., \n        [ -1.11111000e-01,   9.00000000e+00,   5.00000000e+00, ...,\n           1.83963000e-01,   7.37560000e-02,   8.12400000e-02],\n        [  0.00000000e+00,   6.00000000e+00,   5.00000000e+00, ...,\n           1.77811000e-01,   6.03320000e-02,   6.61650000e-02],\n        [  5.00000000e-01,   1.20000000e+01,   0.00000000e+00, ...,\n           1.74681000e-01,   6.12100000e-02,   6.00000000e-02]],\n\n       ..., \n       [[  4.87500000e-01,   8.00000000e+01,   0.00000000e+00, ...,\n           1.50991000e-01,   7.33940000e-02,   6.70820000e-02],\n        [ -5.00000000e-01,   6.00000000e+00,   0.00000000e+00, ...,\n           1.50545000e-01,   6.69330000e-02,   6.70820000e-02],\n        [  7.77777000e-01,   1.80000000e+01,   0.00000000e+00, ...,\n           1.50910000e-01,   6.88960000e-02,   6.91210000e-02],\n        ..., \n        [  7.30769000e-01,   2.60000000e+01,   0.00000000e+00, ...,\n           1.97203000e-01,   7.31210000e-02,   8.36660000e-02],\n        [  2.85714000e-01,   2.80000000e+01,   5.00000000e+00, ...,\n           1.98655000e-01,   7.48330000e-02,   6.92820000e-02],\n        [  3.23529000e-01,   3.40000000e+01,   0.00000000e+00, ...,\n           1.98691000e-01,   9.95990000e-02,   8.00000000e-02]],\n\n       [[  0.00000000e+00,   2.40000000e+01,   0.00000000e+00, ...,\n           1.50959000e-01,   8.94430000e-02,   9.51020000e-02],\n        [ -2.50000000e-01,   4.00000000e+00,   2.33333300e+00, ...,\n           1.91609000e-01,   2.67133000e-01,   2.41753000e-01],\n        [  0.00000000e+00,   2.00000000e+00,   0.00000000e+00, ...,\n           2.23181000e-01,   3.15383000e-01,   2.98794000e-01],\n        ..., \n        [  1.42857000e-01,   1.40000000e+01,   0.00000000e+00, ...,\n           1.88956000e-01,   6.28230000e-02,   5.56780000e-02],\n        [  6.00000000e-01,   1.00000000e+01,   1.00000000e+00, ...,\n           1.91981000e-01,   6.62320000e-02,   5.81190000e-02],\n        [  2.94117000e-01,   1.70000000e+01,   4.00000000e+00, ...,\n           1.91485000e-01,   6.28230000e-02,   6.00000000e-02]],\n\n       [[  6.00000000e-01,   1.50000000e+01,   0.00000000e+00, ...,\n           1.10484000e+00,   5.42830000e-02,   9.48680000e-02],\n        [  0.00000000e+00,   3.00000000e+00,   3.40000000e+00, ...,\n           1.35640700e+00,   1.78215200e+00,   1.46147600e+00],\n        [  0.00000000e+00,   1.00000000e+00,   3.00000000e+00, ...,\n           1.52380800e+00,   2.13168200e+00,   1.81240200e+00],\n        ..., \n        [ -3.33333000e-01,   3.00000000e+00,   3.40000000e+00, ...,\n           5.75108000e-01,   3.00311000e-01,   3.10644000e-01],\n        [ -7.14285000e-01,   7.00000000e+00,   1.00000000e+00, ...,\n           5.69777000e-01,   2.76743000e-01,   2.84429000e-01],\n        [  1.60000000e+00,   5.00000000e+00,   0.00000000e+00, ...,\n           5.57479000e-01,   2.14942000e-01,   3.23883000e-01]]]), 'connect': <function connect at 0x3194c08>, '_i72': u'for i in cv:\\n    print i', 'str_': <type 'numpy.string_'>, 'margins': <function margins at 0x3198410>, 'allclose': <function allclose at 0x21dbe60>, 'extract': <function extract at 0x236c9b0>, 'isOutput': [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'float16': <type 'numpy.float16'>, '_i13': u'trainOutput.shape', 'ulonglong': <type 'numpy.uint64'>, 'matrix': <class 'numpy.matrixlib.defmatrix.matrix'>, 'probas': array([[ 0.006,  0.002,  0.   , ...,  0.006,  0.   ,  0.   ],\n       [ 0.002,  0.   ,  0.   , ...,  0.008,  0.018,  0.   ],\n       [ 0.002,  0.004,  0.004, ...,  0.002,  0.002,  0.01 ],\n       ..., \n       [ 0.018,  0.   ,  0.006, ...,  0.006,  0.004,  0.006],\n       [ 0.   ,  0.   ,  0.   , ...,  0.002,  0.024,  0.   ],\n       [ 0.004,  0.02 ,  0.004, ...,  0.004,  0.   ,  0.006]]), 'asarray': <function asarray at 0x21c2578>, 'True_': True, 'IndexLocator': <class 'matplotlib.ticker.IndexLocator'>, 'poly1d': <class 'numpy.lib.polynomial.poly1d'>, 'rf': RandomForestClassifier(bootstrap=True, compute_importances=None,\n            criterion='gini', max_depth=None, max_features='auto',\n            min_density=None, min_samples_leaf=1, min_samples_split=2,\n            n_estimators=500, n_jobs=2, oob_score=False, random_state=None,\n            verbose=0), 'void': <type 'numpy.void'>, '_i28': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', 'promote_types': <built-in function promote_types>, '_i26': u'target.shape', 'rec': <module 'numpy.core.records' from '/usr/local/lib/python2.7/dist-packages/numpy/core/records.pyc'>, '_i24': u'len(trainOutput[0])', 'arange': <built-in function arange>, 'datetime_as_string': <built-in function datetime_as_string>, 'plotting': <function plotting at 0x3196050>, 'math': <module 'math' (built-in)>, '_i21': u'train.shape', 'get_cmap': <function get_cmap at 0x2b80ed8>, 'log2': <ufunc 'log2'>, 'specgram': <function specgram at 0x31979b0>, 'date2num': <function date2num at 0x307bed8>, '__builtins__': {'bytearray': <type 'bytearray'>, 'IndexError': <type 'exceptions.IndexError'>, 'all': <built-in function all>, 'help': Type help() for interactive help, or help(object) for help about object., 'vars': <built-in function vars>, 'SyntaxError': <type 'exceptions.SyntaxError'>, '__IPYTHON__active': 'Deprecated, check for __IPYTHON__', 'unicode': <type 'unicode'>, 'UnicodeDecodeError': <type 'exceptions.UnicodeDecodeError'>, 'memoryview': <type 'memoryview'>, 'isinstance': <built-in function isinstance>, 'copyright': Copyright (c) 2001-2012 Python Software Foundation.\nAll Rights Reserved.\n\nCopyright (c) 2000 BeOpen.com.\nAll Rights Reserved.\n\nCopyright (c) 1995-2001 Corporation for National Research Initiatives.\nAll Rights Reserved.\n\nCopyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\nAll Rights Reserved., 'NameError': <type 'exceptions.NameError'>, 'BytesWarning': <type 'exceptions.BytesWarning'>, 'dict': <type 'dict'>, 'input': <function <lambda> at 0x5cf2398>, 'oct': <built-in function oct>, 'bin': <built-in function bin>, 'SystemExit': <type 'exceptions.SystemExit'>, 'StandardError': <type 'exceptions.StandardError'>, 'format': <built-in function format>, 'repr': <built-in function repr>, 'sorted': <built-in function sorted>, 'False': False, 'RuntimeWarning': <type 'exceptions.RuntimeWarning'>, 'list': <type 'list'>, 'iter': <built-in function iter>, 'reload': <built-in function reload>, 'Warning': <type 'exceptions.Warning'>, '__package__': None, 'round': <built-in function round>, 'dir': <built-in function dir>, 'cmp': <built-in function cmp>, 'set': <type 'set'>, 'bytes': <type 'str'>, 'reduce': <built-in function reduce>, 'intern': <built-in function intern>, 'issubclass': <built-in function issubclass>, 'Ellipsis': Ellipsis, 'EOFError': <type 'exceptions.EOFError'>, 'locals': <built-in function locals>, 'BufferError': <type 'exceptions.BufferError'>, 'slice': <type 'slice'>, 'FloatingPointError': <type 'exceptions.FloatingPointError'>, 'sum': <built-in function sum>, 'getattr': <built-in function getattr>, 'abs': <built-in function abs>, 'print': <built-in function print>, 'True': True, 'FutureWarning': <type 'exceptions.FutureWarning'>, 'ImportWarning': <type 'exceptions.ImportWarning'>, 'None': None, 'hash': <built-in function hash>, 'ReferenceError': <type 'exceptions.ReferenceError'>, 'len': <built-in function len>, 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n    for supporting Python development.  See www.python.org for more information., 'frozenset': <type 'frozenset'>, '__name__': '__builtin__', 'ord': <built-in function ord>, 'super': <type 'super'>, 'TypeError': <type 'exceptions.TypeError'>, 'license': Type license() to see the full license text, 'KeyboardInterrupt': <type 'exceptions.KeyboardInterrupt'>, 'UserWarning': <type 'exceptions.UserWarning'>, 'filter': <built-in function filter>, 'range': <built-in function range>, 'staticmethod': <type 'staticmethod'>, 'SystemError': <type 'exceptions.SystemError'>, 'BaseException': <type 'exceptions.BaseException'>, 'pow': <built-in function pow>, 'RuntimeError': <type 'exceptions.RuntimeError'>, 'float': <type 'float'>, 'MemoryError': <type 'exceptions.MemoryError'>, 'StopIteration': <type 'exceptions.StopIteration'>, 'globals': <built-in function globals>, 'divmod': <built-in function divmod>, 'enumerate': <type 'enumerate'>, 'apply': <built-in function apply>, 'LookupError': <type 'exceptions.LookupError'>, 'open': <built-in function open>, 'basestring': <type 'basestring'>, 'UnicodeError': <type 'exceptions.UnicodeError'>, 'zip': <built-in function zip>, 'hex': <built-in function hex>, 'long': <type 'long'>, 'next': <built-in function next>, 'ImportError': <type 'exceptions.ImportError'>, 'chr': <built-in function chr>, 'xrange': <type 'xrange'>, 'type': <type 'type'>, '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\", 'Exception': <type 'exceptions.Exception'>, '__IPYTHON__': True, 'tuple': <type 'tuple'>, 'UnicodeTranslateError': <type 'exceptions.UnicodeTranslateError'>, 'reversed': <type 'reversed'>, 'UnicodeEncodeError': <type 'exceptions.UnicodeEncodeError'>, 'IOError': <type 'exceptions.IOError'>, 'hasattr': <built-in function hasattr>, 'delattr': <built-in function delattr>, 'setattr': <built-in function setattr>, 'raw_input': <function <lambda> at 0x7f39504c2578>, 'SyntaxWarning': <type 'exceptions.SyntaxWarning'>, 'compile': <built-in function compile>, 'ArithmeticError': <type 'exceptions.ArithmeticError'>, 'str': <type 'str'>, 'property': <type 'property'>, 'dreload': <function reload at 0x2725c08>, 'GeneratorExit': <type 'exceptions.GeneratorExit'>, 'int': <type 'int'>, '__import__': <built-in function __import__>, 'KeyError': <type 'exceptions.KeyError'>, 'coerce': <built-in function coerce>, 'PendingDeprecationWarning': <type 'exceptions.PendingDeprecationWarning'>, 'file': <type 'file'>, 'EnvironmentError': <type 'exceptions.EnvironmentError'>, 'unichr': <built-in function unichr>, 'id': <built-in function id>, 'OSError': <type 'exceptions.OSError'>, 'DeprecationWarning': <type 'exceptions.DeprecationWarning'>, 'min': <built-in function min>, 'UnicodeWarning': <type 'exceptions.UnicodeWarning'>, 'execfile': <built-in function execfile>, 'any': <built-in function any>, 'complex': <type 'complex'>, 'bool': <type 'bool'>, 'get_ipython': <bound method ZMQInteractiveShell.get_ipython of <IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object at 0x2720f90>>, 'ValueError': <type 'exceptions.ValueError'>, 'NotImplemented': NotImplemented, 'map': <built-in function map>, 'buffer': <type 'buffer'>, 'max': <built-in function max>, 'object': <type 'object'>, 'TabError': <type 'exceptions.TabError'>, 'callable': <built-in function callable>, 'ZeroDivisionError': <type 'exceptions.ZeroDivisionError'>, 'eval': <built-in function eval>, '__debug__': True, 'IndentationError': <type 'exceptions.IndentationError'>, 'AssertionError': <type 'exceptions.AssertionError'>, 'classmethod': <type 'classmethod'>, 'UnboundLocalError': <type 'exceptions.UnboundLocalError'>, 'NotImplementedError': <type 'exceptions.NotImplementedError'>, 'AttributeError': <type 'exceptions.AttributeError'>, 'OverflowError': <type 'exceptions.OverflowError'>}, 'rec_join': <function rec_join at 0x2c526e0>, 'acorr': <function acorr at 0x31967d0>, 'cumproduct': <function cumproduct at 0x21da488>, 'diagonal': <function diagonal at 0x21d1d70>, 'atleast_1d': <function atleast_1d at 0x22741b8>, '_i116': u'pred[0]', '_i115': u'yoda = np.asarray(predicted_probs)\\nluke = np.zeros((310,198))\\nluke[:,0] = yoda', 'meshgrid': <function meshgrid at 0x236d8c0>, 'eventplot': <function eventplot at 0x3196f50>, '_i112': u'numStocks', '_i111': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", 'column_stack': <function column_stack at 0x2374c08>, 'put': <function put at 0x21d18c0>, '___': <type 'list'>, 'smtpserver': <smtplib.SMTP instance at 0x7f393945a7a0>, 'remainder': <ufunc 'remainder'>, '_i19': u'fullInput[509,54,244+197]', 'get_scale_docs': <function get_scale_docs at 0x2fc7140>, '_i118': u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'row_stack': <function vstack at 0x2274758>, 'expm1': <ufunc 'expm1'>, 'ion': <function ion at 0x3194500>, 'insert': <function insert at 0x236d9b0>, 'semilogx': <function semilogx at 0x31978c0>, 'semilogy': <function semilogy at 0x3197938>, 'ndfromtxt': <function ndfromtxt at 0x23fb578>, 'sometrue': <function sometrue at 0x21da230>, 'place': <function place at 0x236ca28>, 'DataSource': <class 'numpy.lib._datasource.DataSource'>, 'newaxis': None, 'arccos': <ufunc 'arccos'>, 'epoch2num': <function epoch2num at 0x307fa28>, '_i59': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", 'signedinteger': <type 'numpy.signedinteger'>, '_i119': u'import smtplib', 'ndim': <function ndim at 0x21da7d0>, 'rand': <built-in method rand of mtrand.RandomState object at 0x7f399f841690>, 'irfft': <function irfft at 0x23fef50>, 'ranf': <built-in method random_sample of mtrand.RandomState object at 0x7f399f841690>, 'subplots_adjust': <function subplots_adjust at 0x3195758>, 'rint': <ufunc 'rint'>, 'fill_between': <function fill_between at 0x31970c8>, 'Axes': <class 'matplotlib.axes.Axes'>, 'MaxNLocator': <class 'matplotlib.ticker.MaxNLocator'>, 'arctan2': <ufunc 'arctan2'>, 'little_endian': True, 'ldexp': <ufunc 'ldexp'>, 'lognormal': <built-in method lognormal of mtrand.RandomState object at 0x7f399f841690>, 'lookfor': <function lookfor at 0x23697d0>, 'hfft': <function hfft at 0x2409050>, 'array': <built-in function array>, 'common_type': <function common_type at 0x2301b90>, 'size': <function size at 0x21da8c0>, 'logical_xor': <ufunc 'logical_xor'>, '_i51': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))', 'geterrcall': <function geterrcall at 0x21dd320>, 'sheet': [['fileId', 'O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8', 'O9', 'O10', 'O11', 'O12', 'O13', 'O14', 'O15', 'O16', 'O17', 'O18', 'O19', 'O20', 'O21', 'O22', 'O23', 'O24', 'O25', 'O26', 'O27', 'O28', 'O29', 'O30', 'O31', 'O32', 'O33', 'O34', 'O35', 'O36', 'O37', 'O38', 'O39', 'O40', 'O41', 'O42', 'O43', 'O44', 'O45', 'O46', 'O47', 'O48', 'O49', 'O50', 'O51', 'O52', 'O53', 'O54', 'O55', 'O56', 'O57', 'O58', 'O59', 'O60', 'O61', 'O62', 'O63', 'O64', 'O65', 'O66', 'O67', 'O68', 'O69', 'O70', 'O71', 'O72', 'O73', 'O74', 'O75', 'O76', 'O77', 'O78', 'O79', 'O80', 'O81', 'O82', 'O83', 'O84', 'O85', 'O86', 'O87', 'O88', 'O89', 'O90', 'O91', 'O92', 'O93', 'O94', 'O95', 'O96', 'O97', 'O98', 'O99', 'O100', 'O101', 'O102', 'O103', 'O104', 'O105', 'O106', 'O107', 'O108', 'O109', 'O110', 'O111', 'O112', 'O113', 'O114', 'O115', 'O116', 'O117', 'O118', 'O119', 'O120', 'O121', 'O122', 'O123', 'O124', 'O125', 'O126', 'O127', 'O128', 'O129', 'O130', 'O131', 'O132', 'O133', 'O134', 'O135', 'O136', 'O137', 'O138', 'O139', 'O140', 'O141', 'O142', 'O143', 'O144', 'O145', 'O146', 'O147', 'O148', 'O149', 'O150', 'O151', 'O152', 'O153', 'O154', 'O155', 'O156', 'O157', 'O158', 'O159', 'O160', 'O161', 'O162', 'O163', 'O164', 'O165', 'O166', 'O167', 'O168', 'O169', 'O170', 'O171', 'O172', 'O173', 'O174', 'O175', 'O176', 'O177', 'O178', 'O179', 'O180', 'O181', 'O182', 'O183', 'O184', 'O185', 'O186', 'O187', 'O188', 'O189', 'O190', 'O191', 'O192', 'O193', 'O194', 'O195', 'O196', 'O197', 'O198'], ['201', -3.82, -0.88, 0.54, 0.08, -1.65, -2.8, -1.74, -5.108279403464041, -4.58, -5.23, 1.78, -3.49, -1.71, -0.32, 0.35428571428571426, -5.32, -1.46, -3.82, -2.64, -4.65, -6.76, -2.19, -0.9256947683993239, -2.17, -4.67, -2.91, -6.9, -5.18, -3.43, -2.06, -1.41, -6.98, -3.19, -5.5, -4.35, -6.32, -8.4, -3.9, -2.75, -3.88, -4.834514634175348, -8.81, -1.81, 1.84, 3.29, 3.98, -1.89, 2.1, -0.34, 0.88, -1.2, -3.39, 1.35, 2.6471428571428572, 1.37, -3.15, -4.75, -4.42, -5.05, -3.59, 1.42, 2.1, -3.67, 0.25, -2.14, -0.95, -2.99, -5.14, -0.48, 0.71, -0.46, -5.02, -4.93, 0.67, -5.02, -1.15, -3.51, -2.33, -4.35, -6.47, -1.88, -0.7, -1.86, -6.76, -11.6, 11.63, -5.57, -5.65, -1.81, -4.15, -2.98, -4.98, -7.09, -2.53, -1.36, -2.51, -1.3273809523809526, 0.09, 4.07, 1.58, 2.83, 0.71, -1.4673734626473065, 3.31, 4.54, 3.33, -1.34, 0.0, -5.22, -3.09, -3.15, -3.04, -3.83, -2.39, -1.19, -3.23, -5.38, -0.73, 0.45, -0.72, -3.03, -1.47, 1.22, -0.86, -3.06, 1.69, 2.91, 1.71, -4.7, -4.57, -0.18, -3.76, -2.65, -1.5696768707482993, -1.01, 5.73, -5.73, -2.89, -2.1, -7.4, 1.2, 6.14, 3.12, -1.91, -2.13, -9.34, 9.31, 9.23, -3.1, 8.58, -6.09, -3.55, 1.78, -11.41, 25.62, 7.66, 11.19, -1.1, -2.67, -2.06, -4.23, 0.47, 1.67, 0.49, -9.21, -0.61, -2.21, 2.58, 3.81, 2.6, 1.64, 4.91, 6.16, 4.93, -4.6, -5.86, -3.12, 1.2, 0.02, -3.01, -3.17, -5.0, 12.86, -4.81, -12.61, -4.07, -3.55, -4.181362551799029, -1.16, -3.5, -2.83, -2.03, -1.53, -2.5, -3.14, -6.31, -4.71, -3.53], ['202', 7.014285714285714, -1.9, -0.6387782843795413, 0.5821428571428573, -0.08, -1.74, -0.8458847420401708, -1.17, -1.91, -0.5, 3.17, -0.07, 1.07, 1.35, 2.39, -2.31, 3.2, 0.84, 0.74, 1.0, -1.16, 3.18, 2.54, 1.5721746031746033, -2.59, -2.91, -3.55, -3.14, -2.03, -1.77, -0.75, -5.31, 0.03, -2.26, -2.36, -2.1, -4.2, 0.01, -0.61, -1.55, -2.3, -3.1750638007838266, -0.42, 1.15, 1.42, 2.47, -2.24, 3.27, 0.92, 0.81, 1.07, -1.09, 3.26, 2.62, 1.65, -0.82, -2.27, -0.17, -1.49, -1.55, 0.27, 1.3, -3.35, 2.1, -0.23, -0.33, -0.07, -2.21, 2.09, 1.46, 0.49, -1.68, -1.6042857142857143, 1.03, -3.61, 1.82, -0.5, -0.6, -0.35, -2.47, 1.81, 1.18, 0.22, -3.28, -9.13, 9.15, -2.82, -4.59, 0.79, -1.4957142857142858, -1.62, -1.36, -3.47, 0.77, 0.15, -0.8, -0.74, 1.86, 5.64, 3.23, 3.12, 3.39, 1.18, 5.62, 4.97, 3.97, -0.97, 1.77, -4.3342762881169605, -1.94, -2.32, -2.04, -3.58, -2.28, -2.39, -2.13, -4.22, -0.02, -0.63, -1.57, -3.54, -1.33, -0.11, 0.15, -1.98, 2.32, 1.69, 0.72, -3.13, -2.54, -0.28, -3.84, -1.37, -1.66, -0.96, 3.48, -3.41, -1.73, -3.69, -1.07, 2.85, 4.0, 1.93, 3.911438775510204, -1.52, -6.48, 6.48, 5.95, -1.98, 5.25, -3.93, -4.63, 2.01, -10.86, 10.55, 7.371428571428571, 11.015714285714285, -3.14, -1.22, 0.26, -1.88, 2.43, 1.79, 0.83, -6.0, -1.48, -2.14, 2.16, 1.53, 0.57, 0.67, 4.39, 3.9828571428571427, 2.76, -1.93, -2.26, -3.56, -0.62, -1.56, -1.92, -2.27, -1.18, 5.3, -4.25, -5.42, -1.7, -2.77, -2.96, -0.95, -2.09, -1.44, -0.67, -1.779047619047619, -2.33, -2.04, -5.38, -5.58, -2.6], ['203', 2.06, -0.11, 0.37, -0.13, 0.36, 0.82, 0.97, 1.61, 1.14, 2.93, 1.87, 2.06, 1.96, 1.85, 0.97, 2.26, 2.17, 2.29, 0.5, 0.92, 3.2, 2.66, 2.12, 2.55, 1.05, 1.03, 1.0726583949931126, 0.19, 0.09, -0.02, -0.88, 0.39, 0.3, 0.41, -1.34, -0.92, 1.31, 0.78, 0.25, 0.67, 1.63, 0.020062111801242236, 0.85, -0.1, -0.21, -1.07, 0.19, 0.11, 0.22, -1.53, -1.11, 1.12, 0.59, 0.06, 0.47, 1.0700628463056765, 1.55, 0.95, 1.7, 0.95, -0.11, -0.97, 0.29, 0.2, 0.32, -1.43, -1.02, 1.21, 0.69, 0.16, 0.57, 1.8, 1.06, -0.8592857142857143, 0.4, 0.32, 0.43, -1.32, -0.91, 1.33, 0.8, 0.27, 0.69, 0.74, 2.18, -2.2694285714285716, 1.94, 1.27, 1.18, 1.3, -0.47, -0.05, 2.21, 1.67, 1.14, 1.56, 1.95, 0.66, -0.09, 0.03, -1.72, -1.3, 0.92, 0.4, -0.13, 0.28, 0.58, 0.65, 0.03, 0.55, 0.63, 0.45, 0.74, 0.12, -1.63, -1.22, 1.01, 0.48, -0.05, 0.37, 0.26, 0.63, -1.74, -1.33, 0.89, 0.37, 0.0657142857142857, 0.25, 0.87, 0.68, -0.35, 0.4, 6.0, 0.27, 0.16, -1.08, 0.97, 0.52, 0.35, 1.67, -3.9, -1.17, -0.57, 1.04, 0.3, 1.58, -1.69, -1.74, 0.55, -1.66, 1.17, 1.08, -0.54, 2.23, 1.14, -1.55, -2.29, 3.89, 2.41, 0.42, 2.68, 2.15, 1.61, 2.03, 1.65, 1.99, 2.26, 1.72, 1.3340034013605442, 1.61, -0.26, -0.52, -1.05, -0.63, 1.13, 1.31, 0.26, -0.53, -0.12, 0.53, 0.58, 1.52, 0.6, 0.46, -0.88, 1.06, 0.69, 0.79, 0.42, 0.99, 0.47021978021978017, 0.29, -0.05, 0.5, 0.37, 0.88, 0.93, 0.67], ['204', -0.62, -0.06, 0.09122171562045875, 0.26, -0.37, 0.2984196236737595, 7.22, -0.29, 0.79, -1.71, -1.87, -5.55, -1.43, -1.81, -1.65, -1.51, -2.13, -1.83, -1.94, -0.14, -1.65, -2.61, -2.17, -2.08, -0.22, -0.2, 0.16, -3.76, 0.45, 0.05, 0.22, 0.36, -0.26, 0.04, -0.07, 1.76, 0.22, -0.76, -0.31, -0.22, -0.23, 0.7949361992161734, 4.07, 4.37, 3.96, 4.13, 4.28, 3.63, 3.95, 3.83, 5.73, 4.14, 3.11, 3.59, 3.68, 0.3, 0.04, -0.22, -0.17, -0.29, -0.39, -0.23, -0.08, -0.71, -0.41, -0.52, 1.3, -0.22, -1.21, -0.75, -0.66, -2.12, 0.11, 0.16, 0.31, -0.32, -0.01, -0.13, 1.7, 0.17, -0.82, -0.36, -0.27, 0.21, 1.33, -1.35, -0.06, 0.14, -0.48, -0.18, -0.29, 1.54, 0.01, -0.98, -0.52, -0.3759922724755494, 3.21, -0.2, -0.63, -0.32, -0.43, 1.39, -0.14, -1.12, -0.67, -0.58, 0.15, -0.17, 0.09, 0.21, 0.32, 0.13567351865003197, 0.43, 0.31, 0.19, 2.03, 0.49, -0.5, -0.04, 0.05, 0.89, 0.17307674813036728, -0.11, 1.72, 0.18, -0.8, -0.35, -0.26, 0.31, 0.46, 0.53, 0.33, 9.51, -0.07, 0.06, 0.19, -0.17, -0.02118982899237888, 0.36, 0.9, 3.11, -0.38, -0.26, -0.31, 0.58, 0.66, -0.71, -0.6, 0.21, 0.21, 0.42, -1.98, 0.98, 1.3, 1.71, -0.86, -1.2, -3.15, 0.24, 1.83, 0.3, -0.69, -0.23, -0.15, 0.61, -1.57, -1.51, -2.48, -2.03, -1.94, -0.06, -0.99, -0.53, -0.44, 0.75, -0.04154645354645334, 0.93, 0.46, 0.55, 0.21, 0.23, -0.19, 0.69, 0.16, -0.6, 0.71, -0.36, 0.47, 0.09, 0.26, -0.08, 0.45, 0.67, 0.22, 0.38, 0.96, -0.42, 1.06], ['205', -0.6857142857142857, -0.84, -0.38877828437954126, 0.44, -2.77, -1.44, -1.7058847420401708, -2.17, -3.19, -2.51, 1.03, -0.44, -1.05, -0.66, -0.29, -2.35, -0.95, -2.16, -2.09, 1.65, -4.09, -0.64, -0.29, -1.17, -2.81, -2.37, -3.51, -1.46, -2.07, -1.68, -1.31, -3.35, -1.96, -3.16, -3.09, 0.61, -5.07, -1.66, -1.31, -2.136158276802161, -1.89, -4.975063800783826, -2.08, -0.62, -0.23, 0.15, -1.92, -0.52, -1.73, -1.66, 2.1011904761904763, -3.67, -0.21, 0.15, -0.74, -0.88, -2.12, -2.17, -2.85, -1.47, 0.39, 0.77, -1.31, 0.1, -1.12, -1.05, 2.73, -3.07, 0.41, 0.77, -0.12, -2.29, -1.86, 0.38, -1.7, -0.29, -1.51, -1.43, 2.33, -3.45, 0.02, 0.38, -0.51, -4.18, -6.1, 6.13, -2.23, -2.07, -0.66, -1.87, -1.8, 1.94, -3.81, -0.35, 0.0, -0.89, -1.33, -0.16, 1.43, 0.2, 0.27, 4.1, -1.78, 1.75, 2.11, 1.21, -0.35, -0.13, -1.87, -1.73, -1.72, -1.57, -1.57, -1.22, -1.15, 2.62, -3.17, 0.31, 0.67, -0.23, -1.87, -0.36, 0.07, 3.89, -1.97, 1.55, 1.91, 1.01, -1.95, -1.46, 0.47, -1.49, -2.57, -0.26, -0.84, 3.32, -3.31, -1.7, -0.94, -2.48, 7.87, 3.45, 1.73, -0.06856122448979596, -1.67, -4.94, 5.08, 5.1, -1.7, 5.02, -3.43, -2.87, 1.48, -4.66, 14.77, 3.13, 4.68, -8.0, -0.43, 3.82, -2.04, 1.48, 1.84, 0.93, -5.15, -4.09, -5.64, -2.26, -1.8601904761904762, -2.78, 1.65, 3.59, 3.96, 3.04, -3.31, -3.7, -1.88, 0.36, -0.53, -1.69, -1.66, -1.99, 7.36, -1.88, -7.51, -2.23, -2.3589064979199876, -2.23, -0.89, -1.34, -1.77, -1.55, -1.1552380952380952, -1.28, -1.35, -2.4, -2.61, -1.3], ['206', -1.64, -0.62, -0.07984710169072946, 0.09, -1.39, -0.93, -0.89, -1.8, -2.11, -0.67, 2.95, 0.17, 1.61, 1.89, 1.82, -0.97, 1.46, -0.45, -1.4, 1.72, -1.68, 0.84, 1.46, 0.35, -1.09, -2.04, -3.51, -2.7, -1.29, -1.02, -1.09, -3.81, -1.45, -3.3, -4.22, -1.19, -4.49, -2.05, -1.44, -2.52, -1.13, -2.1, -0.84, 1.44, 1.72, 1.65, -1.14, 1.29, -0.29945408163265297, -1.56, 1.55, -1.85, 0.67, 1.29, 0.18, 0.1, -0.53, -1.4, -1.81, -2.25, 0.27, 0.21, -2.55, -0.15, -2.03, -2.96, 0.1, -3.24, -0.76, -0.15, -1.24, -1.96, -2.51, -0.07, -2.81, -0.43, -2.3, -3.23, -0.17, -3.51, -0.9485714285714286, -0.43, -1.51, -3.24, -5.68, 5.61, -2.45, -2.75, -0.36, -2.23, -3.16, -0.1, -3.44, -0.97, -0.36, -1.45, -2.6, 0.31, 2.45, 0.53, -0.43, 2.72, -0.71, 1.83, 2.46, 1.34, -0.22, 0.37, -2.44, -1.3984018193170984, -1.6, -1.37, -2.09, -1.88, -2.81, 0.26, -3.09, -0.61, 0.0, -1.09, -1.49, -0.22, -0.95, 2.18, -1.24, 1.29, 1.92, 0.8, -1.95, -1.86, 0.17, -1.85, -7.74, -0.12, -0.07, 3.7, -3.68, -1.84, -1.87, -2.75, 4.93, 2.88, 1.48, -0.88, -0.9, -4.43, 4.33, 4.33, -1.46, 5.55, -2.89, -1.51, 0.77, -6.35, 17.7, 4.12, 6.24, -4.85, 0.74, 3.16, -0.29, 2.27, 2.9, 1.77, -4.246832100439243, -2.2156457669314813, -3.34, -0.87, -0.25, -1.35, 1.03, 2.56, 3.19, 2.07, -2.1, -2.91, -1.49, 0.62, -0.48, -1.44, -1.56, -1.73, 11.01, -2.12, -10.56, -1.58, -2.34, -2.1, -1.09, -1.75, -1.7354471401614255, -0.72, -0.77, -0.52, -1.01, -3.55, -3.3, -1.69], ['207', -0.27, 0.42, 0.08, 0.02, -0.25, 0.44, 1.96, 0.46, 0.44, 0.2, 0.19, -0.88, -0.8, -0.12, -1.0, 0.35, -0.27, 0.11, 4.04, 0.56, -0.09266451791264106, -0.08, 0.43, -0.23, 0.57, 0.07, 0.01, -1.07, -0.99, -0.31, -1.19, 0.16, -0.46, -0.09, 3.84, 0.37, -0.32, -0.27, 0.24, -0.42, 1.32, 1.8549361992161735, 1.09, 0.07, 0.77, -0.13, 1.24, 0.61, 0.99, 4.96, 1.45, 0.75, 0.8, 1.32, 0.65, 0.73, 1.18, 1.19, 0.11, 1.02, 0.69, -0.2, 1.17, 0.54, 0.92, 4.88, 1.38, 0.68, 0.73, 1.2527347454133169, 0.58, 0.11, 0.32, -0.89, 0.47, -0.15, 0.22, 4.16, 0.68, -0.02, 0.04, 0.55, -0.05644035827487928, 0.08, 0.01, 0.06, 1.22, 1.37, 0.74, 1.12, 5.09, 1.58, 0.88, 0.93, 1.45, 0.78, -0.83, -0.15, -0.62, -0.25, 3.67, 0.21, -0.49, -0.43, 0.08, -0.58, 0.15, -0.12, 1.31, 0.3215981806829015, 0.2, 0.48567351865003194, 0.5418094764861292, 0.37, 4.32, 0.83, 0.13, 0.19, 0.7, 0.04, 0.35, 0.1, 3.93, 0.46, -0.24, -0.19, 0.33, -0.33, -0.41, -0.21, 0.04, 0.5, -2.57, 0.29, 0.18, -0.78, 0.77, 0.39, 0.14, -0.03, 0.72, -0.5, -0.27, -0.11, 0.18, 0.78, -0.76, -0.74, 0.25, -1.16, 0.49, -0.02, 0.02, 1.45, -0.52, -0.88, -1.47, -0.69, -3.69, -3.34, -4.01, -3.96, -3.46, -4.1, 0.69, -0.36, -0.69, -0.64, -0.13, -0.79, 0.34, 0.05, 0.57, -0.1, 0.46, 0.22, 0.28, 0.52, -0.15, 0.29, 0.32, 0.5825760496238783, 0.22, 1.4901996269574993, -0.21, 0.62, -0.41, -0.23, -0.66, 0.96, 0.22, 0.18, -0.35, 0.88, 0.515957527023814, 0.15, -1.11, 0.33], ['208', -2.38, 0.11, -0.028778284379541254, 0.06, -0.82, 0.54, -0.21, 0.23, 0.57, 0.0, -0.62, 0.16, -0.42, -0.19, 0.41, 1.5, -0.38, -0.15, 2.98, 1.14, 0.14, 0.3, -0.06, -0.81, 0.69, 0.06, 0.63, 0.79, 0.21, 0.43, 1.04, 2.14, 0.24, 0.48, 3.62, 1.78, 0.77, 0.93, 0.56, -0.18, 0.42, 0.68, -0.16, -0.58, -0.36, 0.25, 1.34, -0.54, -0.31, 2.81, 0.98, -0.03, 0.14, -0.23, -0.97, 0.7400628463056765, 1.07, 0.68, 0.57, 0.42, 0.23, 0.83, 1.93, 0.04, 0.27, 3.41, 1.57, 0.56, 0.72, 0.36, -0.39, 0.54, 0.19, 0.6, 1.7, -0.19, 0.05, 3.18, 1.34, 0.33, 0.49, 0.13, -0.61, 0.74, 0.14, -0.17, -0.41, 1.09, -0.79, -0.55, 2.56, 0.73, -0.27, -0.11, -0.47, -1.21, -0.4, -1.48, -1.86, -1.63, 1.45, -0.36, -1.35, -1.19, -1.54, -2.28, 0.11, -1.49, -0.39, 0.38, 0.37, 0.37, 0.38, 0.23, 3.3701587301587304, 1.53, 0.52, 0.68, 0.32, -0.42, -0.19, 0.15, 3.13, 1.29, 0.29, 0.45, 0.08, -0.66, -0.22, -0.33, 0.1, 0.37, -1.2, 0.12, -0.03, -1.02, 0.94, 0.48, 0.21, -0.47, 2.23, -0.74, -0.38, -1.18, 0.33, 1.18, -1.29, -1.28, 0.37, -1.53, 0.76, -0.45, 0.19, 1.11, -3.54, -0.81, -1.18, -2.18, -2.89, -1.78, -2.76, -2.6, -2.95, -3.67, 1.23, -1.13, -0.99, -0.83, -1.19, -1.93, -0.14, 0.16, -0.2, -0.94, 0.6, 0.73, -0.3, -0.36, -1.0277512446849837, 0.4, 0.36, 0.17, -1.09, -0.11980037304250064, 1.17, 0.01, 0.37, 0.06, -0.74, 0.6, 0.23, 0.76, 0.1, 0.43, 0.895957527023814, 0.24, 0.11, 1.17], ['209', -2.49, -0.54, -0.16877828437954126, 0.17, -1.32, -1.11, -1.2, -2.51, -2.01, -1.55, 1.25, -0.12, 0.47, 1.35, 1.77, -0.91, -0.16, -1.06, -1.55, -0.36, -2.22, -0.52, -0.2, -0.71, -2.68, -1.72, -2.77, -1.36, -0.77, 0.1, 0.51, -2.13, -1.39, -2.28, -2.77, -1.59, -3.43, -1.75, -1.43, -1.94, -1.38, -3.0550638007838264, -1.43, 0.59, 1.47, 1.89, -0.78, -0.04, -0.94, -1.43, -0.24, -2.1, -0.4, -0.08, -0.59, -1.57, -2.3142857142857145, -2.26, -1.6, -2.01, 0.88, 1.3, -1.37, -0.63, -1.52, -2.01, -0.82, -2.68, -0.98, -0.66, -1.18, -3.04, -2.86, 0.8402278911564625, -2.22, -1.49, -2.37, -2.86, -1.68, -3.52, -1.84, -1.52, -2.03, -2.66, -3.37, 3.416, -3.27, -2.63, -1.9, -2.78, -3.27, -2.09, -3.92, -2.25, -1.93, -2.44, -2.19, -0.65, 0.75, -0.15, -0.65, 0.55, -1.33, 0.39, 0.71, 0.19, -0.73, -0.71, -1.6, -1.02, -1.02, -0.95, -1.4, -0.9, -1.3998412698412697, -0.2, -2.07, -0.36, -0.04, -0.55, -0.93, -0.5, -0.5, 0.7, -1.18, 0.54, 1.0957142857142856, 0.35, -1.4, -1.63, 0.0, -1.15, -6.82, -0.30774866403437834, -0.22, 1.61, -1.7, -0.86, -0.15, -2.73, 2.39, 2.04, 1.04, -1.25, -0.73, -3.05, 3.0, 2.97, -1.0, 2.49, -2.02, -3.06, 1.55, -4.12, 14.86, 2.84, 4.16, -2.27, 0.0, 1.21, -0.68, 1.05, 1.38, 0.85, -3.03, -1.2, -1.87, -0.16, 0.16, -0.36, 0.68, 1.74, 2.07, 1.54, -1.99, -2.12, -1.04, 0.33, -0.19, -0.99, -1.07, -2.46, 7.4, -1.53, -7.58, -2.2, -1.44, -1.36, -0.52, -1.18, -0.86, -0.66, -0.43, -0.47, -0.85, -3.67, -0.88, -0.75], ['210', 2.72, -0.11, 0.08122171562045875, 0.19, 0.17, -0.31, -0.45, 0.5217205965359587, -0.77, 0.05, 1.62, 0.15, 0.843913265120849, 0.43, -0.76, -0.51, 0.47, 0.35, 1.49, -0.77, -0.32, 0.7, 0.47, -0.5, 0.43, -0.93, -1.54, -1.44, -0.4123253968253967, -1.17, -2.33, -2.09, -1.13, -1.24, -0.12, -2.34, -1.9, -0.9, -1.13, -2.09, 0.75, -1.74, -0.1, 0.62, 0.28, -0.91, -0.66, 0.31, 0.2, 1.34, -0.92, -0.47, 0.54, 0.32, -0.66, 0.34, -0.24, 0.78, -0.82, -0.72, -0.34, -1.52, -1.28, -0.31, -0.42, 0.71, -1.53, -1.09, -0.08, -0.3, -1.27, 0.78, -0.38, -1.18, -0.94, 0.04, -0.08, 1.06, -1.19, -0.75, 0.27, 0.04, -0.93, -1.52, -1.08, 1.03, 0.81, 0.3380874332127649, 1.23, 1.12, 2.26, -0.01, 0.6052352330209474, 1.46, 1.24, 0.25, -1.33, 0.57, 0.99, 0.87, 2.01, -0.26, 0.19, 1.22, 0.99, 0.01, -0.28, 0.56, -1.25, -0.21, -0.52, 0.08, -0.42, -0.11, 1.02, -1.23, -0.78, 0.23, 0.0, -0.97, -0.66, -0.3, 1.13, -1.12, -0.67, 0.34, 0.12, -0.86, -0.7610416300368755, -0.78, 0.19, -0.43, -4.41, 0.1, -0.1, -0.95, 0.91, 0.48, -0.46, -0.07, -1.5894817511227284, 0.41, 0.22, 1.42, -0.41, -0.64, 0.63, 0.65, -0.21, -1.29, -0.4, -1.29, 0.64, -1.21, 4.18, 0.89, 1.21, 1.69, -1.42, -2.22, -1.78, -0.78, -1.01, -1.97, -0.6, 0.82, 0.45, 1.47, 1.25, 0.26, 0.37, 1.02, 0.79, -0.19, -0.82, -1.21, -0.5527253150925656, -0.23, -1.19, -0.27, -0.17560369872470916, 0.4, 2.35, 0.1, -2.21, -0.55, -0.61, -0.42, -0.97, -0.43, 0.15, -0.41, -0.99, -0.16, 0.56, -0.95, -1.07, -0.15], ['211', 0.75, -1.4, 0.07122171562045874, 0.11, -1.33, -0.49, -1.84, -1.6, -1.79, -2.88, -0.78, -1.42, -1.73, -1.4429761904761904, -1.11, -3.65, -1.77, -2.83, -2.3, -0.82, -3.32, -2.05, -1.91, -1.93, -1.82, -0.76, -2.0873416050068876, -0.64, -0.96, -0.68, -0.34, -2.89, -1.0, -2.07, -1.53, -0.04, -2.56, -1.28, -1.14, -1.16, -1.6, -3.58, -1.49, -0.32, -0.03, 0.31, -2.26, -0.36, -1.44, -0.89, 0.6, -1.93, -0.64, -0.5, -0.52, -0.7, -0.97, -1.39, -1.11, -1.17, 0.29, 0.7348467679404526, -1.95, -0.04, -1.12, -0.57, 0.93, -1.62, -0.32, -0.18, -0.2, -0.63, -1.45, 0.35, -2.23, -0.32, -1.4, -0.86, 0.64, -1.9, -0.61, -0.47, -0.48, -2.48, -2.52, 2.45, -1.789129077338006, -2.481912566787235, -0.66, -1.74, -1.2, 0.29, -2.23, -0.95, -0.81, -0.83, 1.95, 0.8, 1.95, 0.85, 1.4005714285714286, 2.94, 0.34, 1.66, 1.8, 1.79, -0.08, 0.83, -0.78, -0.71, -0.78, -0.84, -1.14, -0.9534006093113236, -0.54, 0.96, -1.58, -0.29, -0.15, -0.16, -0.9, -0.05, 0.55, 2.07, -0.5, 0.81, 0.95, 0.93, -1.21, -1.05, 0.21, -1.06, 5.74, -0.14, 0.0, 2.39, -2.42, -1.19, -1.47, -1.32, 4.290518248877271, 1.4, 0.7, 0.33, -0.25, -2.3285238095238094, 2.08, 2.08, -0.7, 3.64, -1.42, -1.45, 0.71, -3.48, 9.03, 2.37, 3.4, -4.09, -0.6, 1.51, -1.05, 0.25, 0.39, 0.38, -2.1, -2.08, -2.52, -1.24, -1.1, -1.12, 0.45, 1.31, 1.46, 1.44, -1.73, -1.8, -0.85, 0.14, 0.12, -0.71, -0.84, -1.45, 4.6, -1.08, -4.80347619047619, -1.34, -1.09, -0.99, -0.02, -0.85, -0.9, 0.38, -0.32, -0.58, -0.97, -1.36, -0.89, -0.46], ['212', 8.94, -0.21, -0.8687782843795413, 0.35, 0.51, -0.83, -1.305884742040171, -1.16, -0.81, 0.42, 0.520608843537415, 1.46, 1.09, 1.95, 1.02, -2.39, 1.89, 2.07, -0.84, -1.7974455782312924, 0.41, 1.2, 2.08, 1.74, -1.72, -0.79, -0.09, 0.95, 0.58, 1.43, 0.5, -2.88, 1.37, 1.55, -1.34, -2.63, -0.09, 0.69, 1.56, 1.23, -0.87, -0.85, -1.03, -0.37, 0.48, -0.44, -3.8, 0.42, 0.59, -2.27, -3.54, -1.03, -0.26, 0.61, 0.28, -0.89, -0.58, -0.93, -0.36, -0.5907547529341225, 0.9531047225355607, -0.07, -3.44, 0.79, 0.96, -1.91, -3.19, -0.67, 0.11, 0.98, 0.64, -1.44, -1.5, -0.91, -4.25, -0.06, 0.12, -2.73, -4.0, -1.5, -0.73, 0.13, -0.2, -0.68, -4.34, 4.4, -0.6, -3.37, 0.86, 1.04, -1.84, -3.12, -0.6, 0.18, 1.05, 0.72, 2.71, 2.87, 4.38, 4.56, 1.59, 0.26, 2.87, 3.68, 4.721108978323264, 4.23, -1.2, 2.94, -2.03, -1.04, -1.06, -1.04, -1.44, 0.18, -2.6698412698412697, -3.95, -1.44, -0.67, 0.19, -0.14, -0.59, -1.62, -2.84, -4.11, -1.62, -0.85, 0.01, -0.32, -1.8410416300368755, -1.88, 0.43, -1.2, 5.57, -0.2696768707482993, 0.29, 2.53, -2.358279874187437, -1.23, 0.54, -2.17, -4.91, 2.06, 1.09, 4.5, -0.48, -3.13, 3.19, 3.09, -1.04, 3.64, -2.02, -3.26, 1.62, -4.34, 7.93, 2.93, 4.24, 4.9, 1.26, -1.31, 1.26, 2.06, 2.94, 2.765761712843646, -3.17, 2.6, 2.6, 3.41, 4.3, 3.96, 0.0, 0.78, 1.66, 1.32, -0.75, -0.65, -0.78, 0.87, 0.53, -1.11, -0.9456036987247092, -1.13, 4.02, -1.9698003730425007, -3.9, -1.03, -1.0688174603174603, -1.63, -0.33, -1.14, -1.04, -0.51, -0.62, -1.01, -1.3, -2.14, -2.66, -1.2669832262926028], ['213', -2.57, 0.12, -0.08, -0.3, 0.6929790809910596, 0.24, -1.095884742040171, -0.7, -0.24, -0.81, -1.04, 0.07, 0.37, -0.5, -0.42, 0.08, -1.58, -0.83, -1.3, -2.33, -0.58, -1.86, -0.79, -1.29, -0.18, -0.19, 0.23, 1.12, 1.43, 0.54, 0.62, 1.13, -0.54, 0.21, -0.27, -1.31, 0.46, -0.83, 0.25, -0.25, -0.42, -0.9250638007838266, -0.88, 0.3, -0.58, -0.49, 0.01, -1.65, -0.91, -1.38, -2.4, -0.66, -1.93, -0.86, -1.36, -0.15, -0.63, -0.59, 0.06, -1.18, -0.87, -0.79, -0.29, -1.94, -1.21, -1.67, -2.7, -0.95, -2.22, -1.16, -1.66, -2.52, -0.31, 0.08, 0.59, -1.08, -0.33, -0.8, -1.84, -0.08, -1.36, -0.29, -0.79, 0.07, 0.08, -0.08, -0.39, 0.5, -1.16, -0.42, -0.89, -1.92, -0.16, -1.44, -0.37, -0.87, -1.36, -0.89, -1.65, -0.91, -1.38, -2.41, -0.66, -1.93, -0.87, -1.37, -0.48, -0.7906317967746538, 0.18572371188304004, 0.27, 0.22, 0.38, 0.8518094764861293, 0.75, 0.28, -0.77, 1.01, -0.28, 0.8, 0.29, 0.91, 0.03, -0.47, -1.51, 0.25, -1.03, 0.05, -0.46, 0.1, 0.53, 0.05603717887804044, 0.7, -3.75, -1.14, -0.29, -1.12, 1.1, 0.56, 0.39, -0.44, -3.12, -0.63, -0.3, -1.29, 0.41, 0.92, -0.93, -0.85, 0.27, -1.74, 0.55, 0.26, -0.4, 2.38, -2.66, -1.66, -2.29, 3.07, 0.8203786848072563, -1.04, 0.73, -0.56, 0.52, 0.17576171284364575, 0.8, 1.56, 1.79, 0.49, 1.58, 1.07, -0.23, -1.28, -0.21, -0.71, -0.13, 0.0, 1.07, 1.09, 0.58, 0.26, 0.32, -0.54, -1.3, -0.09, 1.49, 0.41189489941485546, 0.4, -0.02, -0.51, 0.12, 0.55, 0.12, 0.73, 0.23, 0.48, -0.45, 1.08, 0.24], ['214', 0.94, 0.16, 0.21122171562045874, 0.19, 0.47, 0.46, 0.7141152579598291, 0.88, 0.86, 0.77, -0.25, -0.72, 0.36, -0.86, -0.32, 0.21, -0.34, 0.62, 1.09, 0.09, 0.94, 0.69, 0.23, 0.29, 0.26, 0.83, 1.0526583949931125, -0.48, 0.6, -0.62, -0.022180028704908802, 0.46, -0.09, 0.87, 1.34, 0.34, 1.19, 0.94, 0.47, 0.54, 0.85, 1.8549361992161735, 1.5, 1.08, -0.14, 0.4, 0.94, 0.39, 1.35, 1.82, 0.82, 1.67, 1.42, 0.95, 1.02, 0.2, -0.15, 0.28, 0.36, 0.41, -1.21, -0.67, -0.15, -0.69, 0.26, 0.73, -0.26, 0.58, 0.34, -0.13, -0.06, 1.01, 1.64, 0.55, 1.08, 0.53, 1.5, 1.97, 0.96, 1.82, 1.57, 1.1, 1.17, 1.54, 1.01, -1.07, 1.09, 0.53, -0.01, 0.94, 1.42, 0.41, 1.27, 1.02, 0.55, 0.62, 2.81, 0.56, -0.54, 0.41, 0.88, -0.12, 0.73, 0.48, 0.02, 0.08, 0.17, 0.53, 0.12017700342548367, 0.5315981806829014, 0.5551790696343399, 0.565673518650032, 1.11, 0.96, 1.43, 0.43, 1.28, 1.03, 0.56, 0.63, -0.15, 0.15, 0.47, -0.52, 0.32, 0.07, -0.39, -0.33, 0.48, 0.33, 0.19, 0.73, 8.71, 0.09, 0.14, -2.03, 2.07, 1.01, -1.42, 1.81, -1.49, -1.03, -0.48, 0.5, 0.07, 1.42, -1.54, -1.4, 0.47, -3.0, 0.9898783572413152, -1.13, 0.54, 3.33, -5.69, -2.27, -3.28, 1.48, -0.32, -0.99, -0.15, -0.4, -0.86, -0.79, 1.42, 0.68, 0.85, 0.6, 0.14, 0.2, -0.17, -0.25, -0.71, -0.64, 0.89, 0.86, 0.07, -0.46, -0.4, 0.5, 0.53, 0.88, -2.63, 0.52, 2.54, 1.3872638105244333, 0.5, 0.54, 0.07, 0.38, 1.0, 0.22, -0.2, 0.03, 0.47, 3.34, 1.61, 0.83], ['215', 0.8, 0.12, 0.05122171562045875, 0.13, 1.12, -0.34, -0.62, -0.27, -0.03, -0.76, -0.96, -0.59, -1.23, -0.48, -0.25, -1.04, -0.56, -0.67, 1.79, -1.54, -0.49, -0.99, -0.3556947683993239, -0.25, 0.18, 0.21937141458889198, 0.2, 0.37, -0.28, 0.48, 0.7678199712950912, -0.08, 0.41, 0.29, 2.77, -0.59, 0.47, -0.04, 0.51, 0.71, -0.42, -0.37506380078382656, -0.16, -0.64, 0.11, 0.34, -0.45, 0.04, -0.08, 2.39, -0.5203333333333333, 0.1, -0.4, 0.14, 0.34, 0.28, -0.16, -1.09, 0.13, 0.5592452470658775, 0.76, 1.0, 0.2, 0.69, 0.57, 3.06, -0.31, 0.75, 0.24, 0.79, 0.99, -0.38, -0.27, 0.23, -0.56, -0.07, -0.18, 2.28, -1.06, -0.01, -0.51, 0.03, 0.23, 0.04, -0.48, 0.45, -0.51, -0.79, -0.31, -0.42, 2.04, -1.29, -0.2261298384155527, -0.74, -0.2, 0.0, 0.04, 0.28, 0.49, 0.37, 2.885904761904762, -0.51, 0.55, 0.04, 0.59, 0.79, -0.19, 0.27, 0.0, -0.13, -0.18, -0.14, -0.1990429599640126, -0.11, 2.36, -0.99, 0.06, -0.44, 0.11, 0.31, 0.26, -0.09, 2.47, -0.88, 0.17, -0.33, 0.22, 0.42, -0.27, -0.25, 0.32, -0.38, 0.0, 0.28, 0.2, 0.18, -0.21, -0.11, 0.76, 0.46, -1.58, 0.26, 0.1, 0.42, -0.39, -0.44, 0.47, 0.46, -0.15, 0.06, -0.26, -1.83, 0.9647652642842468, -0.59, -5.25, 0.36, 0.61, 1.69, -2.5, -3.27, -2.24, -2.73, -2.2, -2.0, -0.45, 0.8, 1.06, 0.55, 1.1, 1.31, -0.26, -0.5, 0.04, 0.24, 0.03, 0.12, 0.24, 0.55, 0.75, -0.16, -0.16, -0.19, -1.71, -0.69, 1.75, -0.12273618947556672, 0.7310935020800124, -0.31, 0.2, -0.56, 0.04, -0.3047020479520478, -0.35, 0.08, -0.5, -0.94, 1.1730376647162362, -0.54], ['216', -5.56, 0.22, -0.36877828437954124, 0.07, -0.38, 0.26, 1.25, -0.32, 0.27, 1.76, 2.15, 1.0, 2.03, 1.88, 2.03, 3.81, 1.46, 1.84, 0.56, 1.85, 1.51, 1.22, 1.12, 1.3921746031746032, -1.1, -0.96, -0.38, -1.13, -0.12, -0.27, -0.12, 1.63, -0.68, -0.31, -1.56, -0.29, -0.63, -0.91, -1.01, -0.74, 0.49, 0.52, 0.75, 1.02, 0.86, 1.02, 2.78, 0.46, 0.83, -0.44, 0.84, 0.5, 0.22, 0.12, 0.39, -1.1, -0.61, -0.43, 0.21, -0.26, -0.15, 0.0, 1.75, -0.56, -0.19, -1.44, -0.17, -0.51, -0.79, -0.89, -0.63, -0.66, -0.11, 0.15, 1.9, -0.41, -0.04, -1.29, -0.02, -0.36, -0.64, -0.74, -0.47, 0.0, 1.7, -1.3344319727891159, -0.26, 1.75, -0.56, -0.19, -1.44, -0.17, -0.51, -0.79, -0.89, -0.63, -3.34, -1.97, -2.26, -1.9, -3.13, -1.89, -2.22, -2.5, -2.59, -2.33, 0.02, -1.99, 0.31, 0.28, 0.42, 0.22, 0.3, 0.37, -0.89, 0.3905357142857143, 0.04, -0.24, -0.34, -0.07, 0.39, -0.07, -1.25, 0.02, -0.32, -0.6, -0.7, -0.44, 0.57, 0.46, 0.27, 0.34, -10.1, -0.1, -0.68, 0.38, -0.3, -0.19, -0.4, -1.28, 0.1, -0.57, -0.28, -2.86, 0.4, 0.84, -0.87, -0.95, 0.28, 0.62, 0.57, -1.14, 0.59, 0.92, 1.7127091836734694, -0.67, -0.97, -0.14, 1.19, 1.29, 0.94, 0.66, 0.55, 0.83, 0.85, -0.09, -0.34, -0.62, -0.72, -0.45, 0.25, -0.27711507143650005, -0.38, -0.12, 0.19, 0.23, 0.53, -0.1, 0.17, 0.3, 0.3, -0.37, 1.16, 0.44, -1.22, 0.37, -0.49, 0.64, 0.34278685149693167, 0.23, -0.13, 0.77, 0.91, 0.53, 0.37, -1.12, -0.28, 0.75], ['217', 5.23, 0.0, 0.05122171562045875, 0.17, 1.0, 0.28, -0.08, 0.68, 0.51, 1.11, 0.07, 1.31, 0.84, 0.69, 1.16, -0.21, 0.86, 1.37, -0.01, -0.32, 1.61, 0.44, 0.37, 1.19, 1.27, 0.78, 1.04, 1.24, 0.78, 0.63, 1.1, -0.28, 0.79, 1.3, -0.08, -0.39, 1.55, 0.37, 0.3, 1.12, -0.3125315746467892, 0.22, -0.2, -0.46, -0.61, -0.15, -1.5, -0.45, 0.05, -1.31, -1.61, 0.3, -0.87, -0.93, -0.12, 0.91, 1.27, 0.987827972809784, 0.52, 0.33924524706587755, -0.15, 0.32, -1.04, 0.01, 0.52, -0.85, -1.15, 0.76, -0.4, -0.47, 0.34, 0.58, 0.41, 0.47, -0.9, 0.16, 0.67, -0.7, -1.01, 0.91, -0.26, -0.32, 0.49, 0.54, 1.83, -1.86, -0.05, -1.36, -0.3, 0.2, -1.16, -1.47, 0.44, -0.72, -0.79, 0.0740077275244506, 2.32, 1.32, 1.07, 1.58, 0.2, -0.11, 1.83, 0.65, 0.58, 1.4, -0.12, 1.37, -1.75, 0.24, -0.13, -0.2, 0.25, 0.5, -0.86, -1.17, 0.75, -0.42, -0.48, 0.33, 0.54, -0.25, -1.36, -1.66, 0.25, -0.92, -0.98, -0.17, -0.25, -0.46, 0.3, 0.32, 6.91, 0.18, 0.07, 0.39, -0.32, -0.18, 0.29, 1.51, -2.75, -0.49, -0.23, 2.55, 0.03, 0.75, -0.81, -0.64, 0.26, 0.54, 0.52, -1.88, 0.95, 1.64, -25.189348639455783, -1.12, -1.69, 2.72, 1.12, -0.31, 1.63, 0.45, 0.38, 1.2, 0.74, 1.43, 1.94, 0.76, 0.69, 1.51, -0.5, -1.1571150714365, -1.23, -0.42, 0.5, 0.72, 0.67, -0.07, 0.75, 0.3, 0.25, 0.66, -5.82, -1.29, 5.91, 0.89, 1.2, 0.74, 0.82, 0.13, -0.17, 0.12, 0.0, 0.16, -0.08, 1.83, 1.96, -0.25], ['218', -0.88, 0.11, -0.21, 0.25, 0.44, 0.24, 1.2441152579598291, 0.05, 0.36, 2.45, 2.6, 1.85, 1.49, 1.83, 2.73, 2.22, 1.63, 2.2, 4.2, 1.97, 1.99, 1.55, 0.25, 1.25, 1.61, -0.44, -0.15, -0.73, -1.09, -0.76, 0.13, -0.38, -0.95, -0.2727410958555916, 1.56, -0.61, -0.6, -1.02, -2.29, -1.32, -0.62, 0.71, 0.58, -0.36, -0.03, 0.86, 0.35, -0.22, 0.34, 2.3, 0.11, 0.13, -0.3, -1.58, -0.6, -0.22, -0.34, -0.94, 0.12, 0.95, 0.44310472253556066, 1.3348467679404525, 0.72, 0.14, 0.8026050661400617, 2.68, 0.48, 0.49, 0.38746485260770963, -1.22, -0.23, 0.05, 0.61, 0.89, 0.38, -0.19, 0.37, 2.33, 0.14, 0.16, -0.04285714285714287, -1.55, -0.57, 0.17, 5.63, -5.62, -0.27, -0.4119125667872351, -1.07, -0.52, 1.43, -0.74, -0.72, -1.15, -2.3890238095238097, -1.44, -2.62, 0.23, -0.57, -0.01, 1.94, -0.24, -0.22, -0.65, -1.93, -0.95, 0.781141873999017, 0.2, 0.77, 0.44, 0.75, 0.19, 0.81, 0.56, 2.53, 0.34, 0.35, -0.08, -1.36, -0.38, 1.0165360710717855, 0.24, 1.96, -0.22, -0.21, -0.64, -1.91, -0.93, 2.1789583699631248, 1.59, 0.62, 0.83, -8.17, 0.43, 0.29, -0.34, 0.36, 0.17, 0.78, -0.96, -0.93, -0.87, -0.44, -0.35, -0.44, 1.38, -1.61, -1.37, 0.42, -0.47, 0.88, -2.23, 1.12, 2.39, -3.4, -1.63, -2.41, 0.83, -1.3596213151927437, -2.14, -2.13, -2.54, -3.8, -2.83, 1.32, 0.47, 0.02, -0.41, -1.69, -0.71, 0.45, -0.43, -1.71, -0.72, 0.7601351386708531, 0.11, 0.89, -1.28, -0.3, 0.43, 0.47, 0.05, -1.62, 1.57, 1.88, -0.35, 0.4, 2.2, 1.0, 0.21, 0.32, -0.11, -0.8, -0.64, 1.19, 0.24, 1.24, 1.48], ['219', -5.8, -0.09, -0.07, 0.02, -1.32, -0.37, -0.5258847420401709, -1.6082794034640413, -1.17, -1.37, -0.03, -0.54, -1.096086734879151, 0.2, 0.58, -0.47, -0.5, -1.14, -1.08, 0.77, -1.55, -1.22, -1.99, -1.53, -2.02, -0.770628585411108, -1.3173416050068876, -0.51, -1.14, 0.23, 0.61, -0.44, -0.47, -1.11, -1.05, 0.8, -1.53, -1.19, -1.97, -1.5, -1.77, -1.36, -0.84, -0.63, 0.74, 1.13, 0.07, 0.04, -0.6, -0.54, 1.32, -0.9919345319135571, -0.68, -1.4257142857142857, -0.99, -1.24, -1.32, -1.62, -1.3, -0.21, 1.4831047225355605, 1.77, 0.7, 0.67, 0.02, 0.08, 1.96, -0.39, -0.06, -0.84, -0.37, -1.5063939988582844, -1.57, 0.39, -0.67, -0.7, -1.34, -1.276904761904762, 0.57, -1.75, -1.42, -2.19, -1.73, -1.05, 1.13, -1.1, -1.95, -1.05, -1.08, -1.72, -1.66, 0.19, -2.13, -1.79, -2.56, -2.1, 0.73, -0.91, -0.03, -0.68, -0.61, 1.25, -1.09, -0.75, -1.53, -1.07, -0.04, -0.97, -1.19, -0.32, -0.17, -0.44432648134996805, -0.88, -0.64, -0.58, 1.28, -1.06, -0.72, -1.5, -1.03, -0.26, -0.24, 0.06, 1.94, -0.42, -0.08, -0.86, -0.39, 0.04, -0.45, -0.28, -0.73, 1.83, -0.07, -0.02, 0.25, -0.19, -0.1, 0.14, -2.44, 4.25, 0.66, 0.3, -2.94, 0.13307978986877905, -1.04, 1.09, 0.89, -0.32, 0.36, -0.65, 0.14, -0.1, -2.64, 0.32, 1.74, 2.57, -4.29, -0.3, 1.87, -0.48, -0.14, -0.92, -0.45, -0.94, -2.13, -2.31, -1.98, -2.75, -2.28, 0.18, 0.34, -0.45, 0.02, -1.16, -1.14, -0.16, -0.78, -0.31, -0.28, -0.4, -1.54, -1.19, -0.93, 1.14, -0.62, -1.73, 0.63, 0.47, -1.13, -0.33, -0.03, 0.2, -0.35, 0.16, -1.85, -2.62, 0.64], ['220', -3.78, -0.47, 0.2, -0.1, -0.18, 0.21, 2.49, -0.54, 0.29, -1.87, -2.44, -2.88, -1.83, -1.27, -1.85, -0.82, -1.9, -1.87, 0.64, -2.1, -1.9, -1.79, -2.16, -2.38, -0.36, -0.27, 0.58, -0.44, 0.62, 1.21, 0.61, 1.67, 0.56, 0.58, 3.16, 0.35, 0.56, 0.67, 0.29, 0.10384172319783916, 0.74, -0.14, 1.03, 1.07, 1.66, 1.06, 2.12, 1.01, 1.03, 3.62, 0.8, 1.01, 1.12, 0.74, 0.51, -0.07, 0.37, -1.0, 0.0, -0.04, 0.58, -0.02, 1.04, -0.06, -0.04, 2.52, -0.27, -0.06, 0.05, -0.33, -0.56, -1.18, -0.62, -0.59, 0.45, -0.64, -0.62, 1.93, -0.85, -0.64, -0.53, -0.9, -1.13, 0.38, 0.66, -0.63, -0.02, 1.05, -0.05, -0.02, 2.54, -0.25, -0.05, 0.06, -0.31, -0.54, -2.75, -1.07, -1.09, -1.07, 1.47, -1.29, -1.09, -0.98, -1.35, -1.58, 0.07, -1.04, 0.13, -0.16, 0.27, -0.48, 0.02, 0.02, 2.59, -0.21, 0.0, 0.11, -0.27, -0.49, -0.03, 0.0, 2.56, -0.23, -0.02, 0.09, -0.29, -0.52, 0.12, -0.2, -0.01, 0.17, -8.24, -0.15, -0.13, 2.81, -2.93, -1.44, -0.47, 0.24616353211204947, -0.49, 0.31, 0.16, -1.89, 0.14, -0.48, 0.35, 0.49, -0.09670919513614704, 4.31, -0.27, 0.37, -0.19, 0.04, 9.6, -0.09, -0.11, 0.6, -2.5, -2.72, -2.52, -2.41, -2.78, -3.0, -0.44, 0.23, 0.21, 0.32, -0.06, -0.29, 0.02, 0.11, -0.27, -0.49, 0.35, 0.25, -0.09, -0.38, -0.6, -0.15, -0.09, -0.49, 5.3, 0.49, -5.46, 0.07, 0.13, 0.29, -0.15721314850306833, 0.35, -1.75, 0.11, 0.27, 0.49, 0.605957527023814, -2.17, -0.59, 0.69], ['221', -2.36, 0.45, 0.16, 0.02, -0.79, 0.2384196236737595, -1.19, -0.26, 0.34, 0.45, -0.13, 0.91, 0.43, 0.39, 1.81, 1.15, 0.31, 0.33, 1.82, -0.33, 0.8, 0.25, 0.5, 0.33, -0.3, 0.28, 0.58, 1.04, 0.56, 0.52, 1.94, 1.28, 0.44, 0.45, 1.95, -0.2, 0.9307606837606838, 0.38, 0.63, 0.46, 0.35, 0.6, -0.46, -0.48, -0.52, 0.89, 0.24, -0.6, -0.58, 0.9, -1.23, -0.11, -0.66, -0.41, -0.57, 0.47, 0.17, -0.22, 0.66, 0.01, -0.04, 1.37, 0.71, -0.12, -0.11, 1.38, -0.76, 0.37, -0.18, 0.07, -0.1, -0.54, 0.06, 1.41, 0.76, -0.08, -0.07, 1.42, -0.72, 0.41, -0.14, 0.11, -0.06, 0.77, 0.01, 0.0, -1.339129077338006, -0.65, -1.47, -1.46, 0.01, -2.1, -0.99, -1.53, -1.28, -1.45, -0.74, -0.7, -0.83, -0.82, 0.66, -1.47, -0.34, -0.89, -0.64, -0.81, 0.05, -0.64, -0.8398953488372093, 0.19, 0.22, 0.27, 0.14, 0.02, 1.51, -0.64, 0.49, -0.06, 0.19, 0.02, 0.21, 0.17307674813036728, 1.49, -0.65, 0.48956235827664396, -0.07, 0.18, 0.01, -0.32, -0.16, -0.11, 0.38, -2.29, 0.31, 0.2, -0.08, 0.1, 0.04, 0.24, 0.47, -1.67, -0.39, -0.2, -1.23, 0.48, 0.62, -0.64, -0.57, 0.2, -0.12, 0.4, 0.48, -0.24, 0.44, 0.57, -0.25, -0.43, 1.64, -1.35, -2.11, -1.0, -1.54, -1.29, -1.46, 0.64, 0.78, 1.14, 0.59, 0.84, 0.67, -0.35, -0.55, -0.3, -0.47, 0.5901351386708531, 0.86, 0.19, 0.25, 0.08, 0.22, 0.2, -0.23, 0.25, -0.5088836208193301, -0.3, 0.28, 0.29, -0.06, -0.17, 0.31, 0.07, 0.2, 0.69, 0.59, 0.11, -0.93, -0.02, 0.13], ['222', 2.92, 0.01, -0.07877828437954125, 0.07, -0.1170209190089404, 0.5, 0.36411525795982913, -0.82, -0.63, -0.84, -0.15939115646258506, -1.4, -0.68, 0.12, 0.97, -1.78, -1.34, -0.72, 1.72, -0.66, -1.39, -1.61, -0.29, -0.404883372579801, -0.58, -0.19, -0.67, -1.23, -0.51, 0.3, 1.14, -1.61, -1.17, -0.54, 1.89, -0.48, -1.22, -1.44, -0.12, -0.38, -0.8, -3.02, 0.769303232481804, 0.73, 1.54, 2.4, -0.38, 0.06, 0.69, 3.16, 0.76, 0.01, -0.21, 1.12, 0.86, -0.2, -0.87, -0.13, 0.14291666666666658, -0.16, 0.81, 1.66, -1.1, -0.67, -0.03, 2.41, 0.03, -0.72, -0.93, 0.39, 0.13, 0.53, -0.96, 0.85, -1.9, -1.46, -0.84, 1.59, -0.78, -1.52, -1.73, -0.41, -0.67, -1.24, -0.95, 0.9, -1.79, -2.72, -2.29, -1.67, 0.74, -1.416255228898086, -2.34, -2.55, -1.25, -1.51, 1.66, 0.96, 0.44, 1.08, 3.56, 1.14, 0.39, 0.18, 1.6511089783232642, 1.25, 0.05, 0.98, -0.23, 0.12, -0.16, 0.47, 0.51, 0.64, 3.1, 0.7, -0.05, -0.19969498055271245, 1.07, 0.81, 0.68, -0.12, 2.45, 0.06, -0.68, -0.9, 0.43, 0.17, -0.54, 0.47, 0.06, 0.69, 3.31, -0.13, -0.15, -0.6, 0.6, 0.32, 0.82, -0.82, 0.36, -0.25, -0.12, 1.53, 0.37, 0.58, -0.51, -0.4, 0.13, -1.07, 0.26, -0.84, 0.38, 1.49, 2.87, -1.02, -1.43, -0.37, -2.51, -2.33, -3.06, -3.27, -1.97, -2.23, 0.32, -0.045645766931481174, -0.74, -0.96, 0.37, 0.11, 0.56, -0.21, 1.12, 0.86, -0.55, -0.95, 0.78, 1.33, 1.07, 0.14, 0.17, -0.57, 1.33, -0.05, -0.7707193877551022, 0.48, -0.3688174603174603, -0.55, -0.26, 0.61, 0.38, 0.64, 0.09, 0.33, -0.29, -0.09, -0.46, 0.33], ['223', 4.64, -0.4, -0.18877828437954128, -0.12, -0.66, -0.97, -1.2558847420401709, -1.24, -1.68, -0.68, 1.24, 0.55, 0.2, 0.45, -0.22, -1.23, 0.74, -0.31, -0.6, 0.91, -1.09, 0.1, 0.95, 0.54, -1.13, -1.38, -1.9, -0.69, -1.03, -0.78, -1.44, -2.44, -0.49, -1.53, -1.82, -0.33, -2.235546329921431, -1.12, -0.29, -0.6461582768021608, -0.5, -3.18, -1.22, -0.35, -0.09, -0.76, -1.77, 0.2, -0.85, -1.14, 0.3607142857142857, -1.601934531913557, -0.44, 0.4, 0.0, -2.69, -1.17, -1.39, -1.37, -0.88, 0.26, -0.42, -1.43, 0.55, -0.5, -0.79, 0.71, -1.29, -0.09, 0.75, 0.34, -1.8863939988582845, -1.13, -0.67, -1.68, 0.29, -0.76, -1.05, 0.45, -1.54, -0.35, 0.49, 0.1435596417251207, -2.18, -4.47, 4.58, -0.46, -1.01, 0.97, -0.09, -0.38, 1.13, -0.88, 0.32, 1.17, 0.77, 1.48, 0.56, 2.0, 0.94, 0.64, 2.17, 0.14, 1.35, 2.21, 1.8, -0.35, 0.55, -1.6042762881169599, -1.04, -1.19, -0.96, -1.41, -1.04, -1.33, 0.16, -1.83, -0.64, 0.2, -0.2, -0.9, -0.37, -0.29, 1.22, -0.79, 0.41, 1.26, 0.85, -1.74, -1.32, -0.46, -1.29, 2.95, -0.53, -0.35, 1.76, -1.77, -0.9, -1.29, -2.04, 3.1, 2.03, 1.03, 2.41, -0.56, -3.2, 3.18, 3.02, -1.03, 2.63, -2.03, 1.86, -0.97, -4.21, 5.55, 2.88, 4.23, -3.06, -0.08, 1.51, -0.5, 0.7, 1.56, 1.15, -3.05, -1.57, -1.99, -0.8, 0.04, -0.36, 0.42, 1.21, 2.07, 1.66, -1.76, -2.25, -0.78, 0.85, 0.44, -1.0, -1.0456036987247093, -1.3, 2.94, -1.49, -2.98, -1.34, -0.44, -1.62, -0.4, -1.23, -0.69, -0.8, -0.93, -1.14, -1.22, 0.29, -0.76, -0.98], ['224', 2.98, 0.06, 0.011221715620458745, -0.29, 0.6, 1.0684196236737595, 0.97, 0.93, 0.93, 0.25, -1.36, 0.1, -1.17, -0.7, -0.94, -0.06, -0.9, 0.48, 1.15, 0.02, 0.43, -0.51, -1.31, -0.39, 1.0, 0.66, 1.63, 1.48, 0.2, 0.68, 0.4878199712950912, 1.32, 0.47, 1.87, 2.55, 1.4, 1.82, 0.87, 0.05, 0.99, 0.35, 0.7849361992161734, 0.34930323248180406, -1.26, -0.79, -1.03, -0.16, -1.0, 0.39, 1.06, -0.08, 0.34, -0.61, -1.41, -0.48, 0.21, 0.65, 0.67, 0.27, 1.43, 0.48, 0.23, 1.12, 0.27, 1.67, 2.35, 1.2, 1.62, 0.7296581632653062, 0.015338978481835797, 0.8141848072562359, 0.3736060011417156, 0.95, -0.24, 0.64, -0.21, 1.19, 1.86, 0.72, 1.14, 0.19, -0.62, 0.31, 1.7, 4.05, -3.99, 1.2, 0.89, 0.04, 1.43, 2.11, 0.97, 1.38, 0.43, -0.38, 0.56, 1.45, 0.31, -0.84, 0.54, 1.21, 0.08, 0.49, -0.45, -1.26, -0.33, -0.1, 0.31, 0.04, 1.05, 0.99, 1.09, 1.16, 1.4, 2.08, 0.93, 1.35, 0.4, -0.41, 0.52, 0.73, -0.23, 0.67, -0.36775528629437304, -0.05, -0.99, -1.79, -0.87, 1.33, 1.24, -0.25, 0.87, 4.38, -0.2, 0.07, -2.51, 2.51, 1.28, 0.37, 1.1, -0.45, -2.07, -1.05, 1.53, 0.72, 3.17, -3.12, -3.13, 1.03, -3.88, 2.07, 1.33, -0.91, 3.47, -9.74, -2.29, -3.5, 0.43, -0.5796213151927438, -1.12, -0.5127867132867132, -1.64, -2.44, -1.52, 3.15, 0.23, 0.41, -0.53, -1.33, -0.41, -0.19, -0.8511214088935782, -1.74, -0.82, 0.98, 1.3184535464535465, 0.76, -0.81, 0.12, 1.05, 1.04, 0.92, -6.14, 0.6603332627840632, 6.15, 1.2, 0.96, 1.58, 1.0127868514969316, 1.0, 1.36, 0.7, 0.33, 0.91, 0.64, 1.58, 1.13, 0.22], ['225', 5.29, 0.13, -0.05, -0.22, 1.34, 0.28, -3.59, 1.08, 0.3, 0.68, -0.09, 3.1, 2.07, 0.07, -0.49, -1.25, 0.84, 1.72, 0.77, -1.05, 1.62, 0.34, 1.52, 0.97, 2.17, 0.72, 0.77, 3.2001785714285718, 2.16, 0.16, -0.4, -1.16, 0.94, 1.81, 0.87, -0.96, 1.71, 0.43, 1.62, 1.06, 0.61, 1.45, -2.35, -1.0, -2.94, -3.4191849704247237, -4.22, -2.19, -1.34, -2.26, -4.03, -1.44, -2.68, -1.53, -2.07, 1.44, 1.4, 1.25, 0.93, -1.36, -1.96, -2.51, -3.25, -1.2, -0.34, -1.27, -3.0497619047619047, -0.44, -1.69, -0.53, -1.08, 1.77, 0.61, -0.56, -1.32, 0.77, 1.65, 0.7, -1.12, 1.55, 0.27, 1.45, 0.9, 0.86, -2.4, 2.36, 1.18, -0.76, 1.35, 2.23, 1.28, -0.56, 2.12, 0.84, 2.03, 1.47, 2.44, 1.96, 2.12, 3.01, 2.05, 0.21, 2.91, 1.61, 2.81, 2.25, -0.79, 2.04, -2.01, -0.06, -0.09, -0.18432648134996804, -0.16, 0.87, -0.07, -1.88, 0.77, -0.5, 0.67, 0.12, 0.06, -1.02, -0.6763144197072768, -2.72, -0.1, -1.36, -0.19, -0.74, -1.23, -0.79, -0.49, -0.86, 7.8, -1.34, -1.09, 1.09, -1.13, -0.56, -1.49, 1.7, -3.53, 0.07, 0.0, 2.67, 0.38307978986877905, -0.18, 0.19, 0.17, -0.05, 1.55, -0.15, -0.73, 0.13, -0.45, 5.91, 0.28, 0.41, 3.47, -0.09, -1.81, 0.84, -0.38270294784580494, 0.74, 0.19, -0.17, 1.75, 2.69, 1.4, 2.6, 2.04, -0.8555102040816327, -1.26, -0.09, -0.64, 0.43, 0.86, 0.34, 1.3732337781266353, 0.63, -0.05, -0.22, 0.92, 3.28, -1.94, -3.16, -0.27, 0.31, -0.83, -0.4772131485030684, -0.21, -0.13, 0.52, 0.75, 0.2, -0.29, 0.07, 0.22, -0.49], ['226', -0.34, 0.33, 0.25, 0.03, 0.47, 0.46, 0.73, 0.88, 1.04, 0.11, -1.37, 0.0019344980416409752, -1.11, -1.19, -1.0, 0.11, -0.7, -0.12, -0.8, -0.78, 0.7, -1.38, 0.47, -0.33, 0.68, 0.46, 1.5326583949931125, 1.19, 0.26, 0.18, 0.38, 1.51, 0.68, 1.27, 0.58, 0.6, 2.1, 0.0, 1.87, 1.06, 0.51, 1.7549361992161734, 0.31, -0.91, -0.99, -0.79, 0.32, -0.19134863945578234, 0.08, -0.6, -0.58, 0.9, -1.18, 0.7042857142857143, -0.13, 0.55, 0.62, -0.7, 0.87, 1.23, -0.08, 0.12, 1.24, 0.41, 1.0, 0.32, 0.33, 1.83, -0.27, 1.6, 0.79, -0.38, 1.32, 0.2, 1.32, 0.5, 1.08, 0.4, 0.41, 1.92, -0.19, 1.68, 0.87, 1.45, -0.35, 0.19, 1.11, 1.12, 0.29, 0.88, 0.2, 0.21, 1.71, -0.38, 1.48, 0.67, -0.56, -0.01, -0.81, -0.24, -0.9084761904761905, -0.9, 0.59, -1.49, 0.36, -0.44, 0.2, 0.0, 2.12, 0.37, 0.34, 0.38, 0.82, 0.58, -0.1, -0.08, 1.41, -0.68, 1.18, 0.38, 1.33, 0.23, -0.68, -0.66, 0.82, -1.25, 0.59, -0.21, 0.26, 1.06, 0.03, 0.58, -1.82, 0.2980695494981211, 0.05, -0.22, 0.23, 0.11, 0.37, 1.47, -1.83, -0.77, -0.36, -0.16, 0.86, 1.0, -1.04, -1.04, 0.38, -0.35, 0.72, 0.09, -0.08, 2.41, -4.61, -1.63, -2.41, 1.7, 0.91, 0.01, 1.51, -0.58, 1.28, 0.47, 1.2, 0.9, 1.5, -0.6, 1.26, 0.46, -0.59, -2.06, -0.23, -1.02, 0.98, 1.25, 1.5, 1.87, 1.06, 0.4, 0.42, 0.91, -2.89, 0.19, 3.04, 0.27, 0.07, -0.36, -0.7172131485030684, 0.96, 0.14, 0.99, 1.07, 0.59, 0.525957527023814, -0.93, -0.49, 0.2], ['227', -1.11, 0.46, 0.41, -0.14, 0.46, 0.98, 1.48, 1.4, 1.63, 1.19, -0.97, -0.15, 0.31, 0.61, -0.15, 1.21, -0.08, 0.5, 2.4, -0.59, 1.28, 0.06, -0.73, -0.43, 1.55, 1.29, 2.18, 0.8301785714285714, 1.29, 1.59, 0.83, 2.2, 0.9, 1.48, 3.41, 0.39, 2.28, 1.04, 0.24, 0.5838417231978392, 0.71, 2.96, 1.5493032324818041, 0.46, 0.76, 0.0, 1.37, 0.08, 0.65, 2.56, -0.44, 1.44, 0.21, -0.58, -0.28, 1.26, 0.8, 2.02, 1.96, 0.88, 0.3, -0.45, 0.9, -0.38, 0.19, 2.09, -0.89, 0.97, -0.25, -1.04, -0.74, 1.44, 0.58, -0.7353571428571428, 0.6, -0.68, -0.11, 1.78, -1.19, 0.67, -0.55, -1.33, -1.03, 1.94, 5.12, -5.07, 1.34, 1.36, 0.07, 0.65, 2.55, -0.44, 1.43, 0.2, -0.58, -0.29, -0.91, -0.02, -1.27, -0.71, 1.18, -1.78, 0.07, -1.14, -1.92, -1.62, 0.64, -0.05, 3.98572371188304, 1.08, 1.19, 1.065673518650032, 1.27, 0.57, 2.48, -0.51, 1.36, 0.13, -0.65, -0.36, 1.17, 0.69, 1.9, -1.08, 0.78, -0.44, -1.22, -0.92, 2.13, 1.89, -0.2, 1.23, -2.63, 0.29, 0.42, -1.43, 1.4224623233908948, 0.7688101710076211, 0.79, 2.12, -3.58, -2.08, -1.05, -0.54, 0.5, 3.3, -3.25, -3.19, 1.123290804863853, -2.27, 2.15, 1.82, -0.91, 3.69, -5.48, -2.58, -3.76, 3.62, -1.18, -2.92, -1.09, -2.29, -3.023374458874459, -2.77, 3.13, 1.79, 1.88, 0.65, -0.14, 0.16, -0.09, -1.21, -1.99, -1.7, 1.59, 2.05, 1.14, -0.79, -0.49, 1.08, 1.11, 1.4, -4.19, 3.1711163791806696, 4.37, 1.4618948994148555, 0.54, 1.94, 0.3, 1.54, 0.85, 0.48, 0.2, 0.6, 1.63, 1.56, -0.06, 1.68], ['228', 2.85, -1.09, -0.10877828437954125, 0.03, -0.23, 0.54, -0.46, 0.31, 0.62, 0.08, -1.36, 0.4, -0.18, -0.26, -0.46, -1.37, -0.6, -0.14, 3.72, -0.07, 0.84, 0.46, -1.33, -0.27, 0.64, 0.6, 1.4926583949931125, 1.78, 1.19, 1.11, 0.91, -0.02, 0.77, 1.24, 5.14, 1.31, 2.23, 1.84, 0.03, 1.1, -0.57, 1.4949361992161734, -0.31, -0.58, -0.66, -0.86, -1.76, -0.99, -0.53, 3.31, -0.46, 0.44, 0.06, -1.72, -0.66, 0.09, 0.29, -0.14, 0.84, 0.27, -0.08, -0.28, -1.19, -0.41, 0.05, 3.91, 0.12, 1.02, 0.64, -1.091735383663955, -0.08, 1.16, 0.34, -0.2, -1.12, -0.34, 0.12, 3.99, 0.19, 1.1, 0.72, -1.07, -0.01, 1.3, 3.62, -3.66, 0.55, -0.92, 0.2999013605442177, 0.33, 4.2, 0.4016746031746032, 1.31, 0.92, -0.8390238095238095, 0.19, 4.84, 1.48, 0.79, 1.25, 5.16, 1.32, 2.24, 1.86, 0.04, 1.12, 0.33, 1.44, 0.49, 0.69, 0.83517906963434, 0.61, 0.68, 0.46, 4.34, 0.53, 1.44, 1.1203050194472877, -0.74, 0.33, -0.37, 0.22, 3.86, 0.16224471370562701, 0.97, 0.59, -1.19, -0.13, 1.56, 1.19, 0.11, 0.76, 14.887738095238095, 0.25, 0.07, -1.86, 1.79, 0.91, 0.36, 0.72, -0.36, -1.35, -0.72, 1.41, 0.57, 2.06, -2.14, -2.03, 0.69, -2.69, 1.4198783572413154, 0.26, -0.14, 1.94, -0.75, -1.35, -1.97, 0.32, -3.5, -3.65, -2.78, -3.14, -4.86, -3.84, 1.99, 0.15, 0.91, 0.53, -1.26, -0.2, -0.75, -0.38, -2.15, -1.1, 0.66, 1.04, -0.37, -1.78, -0.72, 0.71, 0.71, 0.14, -0.49, 0.58, 0.52, 0.5172638105244333, -0.07, 1.43, 1.07, 0.85, 0.99, 0.02, 0.79, 0.81, 0.35, 1.23, -0.48, 0.43], ['229', 1.62, -1.01, -0.25, 0.37, -1.72, -1.0215803763262405, -1.81, -1.6, -1.99, -2.59, 0.3, -1.4792857142857143, -0.7, -0.07, -0.95, -3.43, -1.05, -2.13, -0.35, 0.55, -3.17, -0.72, -0.78, -1.29, -2.22, -1.62, -2.8473416050068874, -1.78, -0.99, -0.36, -1.25, -3.71, -1.34, -2.42, -0.65, 0.26, -3.46, -1.01, -1.07, -1.58, -1.42, -2.98, -1.12, 0.8, 1.44, 0.54, -1.948956349206349, 0.44, -0.66, 1.15, 2.07, -1.71, 0.78, 0.8071428571428572, 0.2, 0.14, -1.81, -2.28, -2.26, -1.91, 0.63, -0.15515323205954745, -2.75, -0.35, -1.45, 0.34, 1.2602380952380952, -2.49, -0.02, -0.08, -0.59, -1.3, -2.52, -0.88, -3.36, -0.98, -2.07, -0.29, 0.62, -3.11, -0.65, -0.71, -1.22, -2.78, -5.04, 5.07, -1.65, -2.5, -0.1, -1.19, 0.6, 1.52, -2.24, 0.24, 0.18, -0.34, 0.93, 0.87, 2.46, 1.34, 3.18, 4.12, 0.26, 2.8124285714285713, 2.74, 2.22, -0.57, 0.86, -3.8542762881169597, -1.19, -1.28, -1.19, -1.4881905235138708, -1.1, 0.7, 1.62, -2.15, 0.34, 0.27, -0.24, -1.85, -0.46, 1.82, 2.75, -1.06, 1.5757995496566926, 1.39, 0.87, -2.04, -1.77, 0.21, -1.68, 2.76, -0.42, -0.35, 1.31, -1.29, -0.62, -0.74, -2.37, 6.48, 2.42, 1.21, 0.89, -0.56, -3.88, 3.56, 3.49, -1.17, 1.91, -2.35, -4.57, 2.35, -4.66, 5.57, 3.1, 4.51, -6.3, -2.24, 0.91, -2.83, -0.36, -0.42, -0.93, -3.52, -3.13, -3.7, -1.26, -1.32, -1.83, 0.6, 2.54, 2.47, 1.95, -1.99, -2.44, -1.89, -0.06, -0.57, -1.21, -1.27, -1.66, 4.11, -3.07, -4.28, -1.1627361894755668, -2.75, -1.83, -0.43721314850306836, -1.41, -0.53, -0.62, -0.5, -0.55, -1.234042472976186, -2.74, -3.96, -1.75], ['230', 0.47, 0.94, -0.07877828437954125, -0.08, -0.47, 0.92, 0.09, 1.24, 0.85, 1.2770884353741496, 0.12, 0.52, -1.04, -0.52, -2.15, -0.14, -0.35, 0.68, 2.93, 2.44, 0.83, 0.13, -0.32, 1.62, 0.91, 1.43, 0.72, 0.4, -1.16, -0.64, -2.27, -0.25, -0.47, 0.56, 2.81, 2.32, 0.794453670078569, 0.01, -0.43, 1.5, 1.26, 0.6049361992161734, 0.5093032324818041, -1.55, -1.03, -2.66, -0.65, -0.87, 0.16, 2.4, 1.91, 0.31, -0.39, -0.83, 1.09, -0.1476426685347185, 0.25, 0.78, 1.21, 1.89, 0.52, -1.12, 0.91, 0.69, 1.74, 4.01, 3.51, 1.89, 1.1959625850340136, 0.7882646163360448, 2.68, -0.09, 1.36, -1.64, 0.39, 0.17, 1.21, 3.47, 2.97, 1.36, 0.66, 0.21, 2.15, 0.98, 3.22, -3.23, 3.05, 2.06, 1.84, 2.895714285714286, 5.2, 4.69, 3.05, 2.33, 1.9109761904761904, 3.85, 0.91, 0.97, -0.22, 0.833095238095238, 3.07, 2.58, 0.97, 0.27, -0.18, 1.75, 0.37, 1.08, 1.33, 0.58, 0.94, 0.26, 1.19, 1.03, 3.3, 2.8, 1.19, 0.49, 0.04, 1.98, 0.64, 0.15, 2.24, 1.75, 0.15956235827664397, -0.54, -0.99, 0.93, 1.41, 2.279561224489796, 0.0, 0.8, 1.51, 0.38, 0.24, 0.67, -0.64, -0.33, 0.62, 3.16, 2.84, -1.09, -0.57, 0.2, 0.4, 1.71, -1.82, -1.88, 0.59, 1.11, 1.19, 1.69, -0.83, 3.49, -2.54, -2.26, -3.63, -2.93, -2.04, -0.48, -2.04, -2.72, -3.16, -1.28, 1.73, -1.56, -1.56, -2.25, -2.69, -0.8, 0.0, -0.7, -1.14, 0.78, 0.85, 1.1, 0.7, -0.45, 1.48, 0.57, 0.59, 1.27, -1.28, 2.0, 0.96, 1.02, 1.34, 1.15, 1.94, 0.4, 0.12, 0.55, 0.61, 1.37, -0.77, 1.23, 2.321595238095238, -0.52], ['231', 0.5, -0.51, 0.08, 0.32, -0.19702091900894042, -0.91, -1.48, -1.49, -1.76, -4.04, -1.36, -2.97, -2.72, -2.92, -3.2, -5.088928571428571, -2.22, -3.596530612244898, -1.58, -2.62, -4.13, -3.28, -1.96, -3.44, -2.77, -1.36, -2.72, -1.6294545454545453, -1.38, -1.58, -1.87, -3.78, -0.87, -2.28, -0.23, -1.28, -2.81, -1.94, -0.61, -2.1, -1.16, -2.92, -1.11, 0.25, 0.05, -0.24, -2.18, 0.77, -0.339454081632653, 1.43, 0.36, -1.2, -0.32, 1.04, -0.48, -0.38, -2.35, -2.44, -1.09, -1.36, -0.2, -0.49, -2.43, 0.52, -0.91, 1.17, 0.11, -1.45, -0.5103418367346938, 0.78, -0.73, -0.31, -1.16, -0.29, -2.2285714285714286, 0.72, -0.71, 1.6274764481550195, 0.31, -1.25, -0.37, 0.99, -0.53, -2.51, -5.48, 5.42, -0.87, -1.95, 1.02, -0.42, 1.67, 0.6, -0.96, -0.08, 1.28, -0.24, -0.97, 1.1, 3.02, 1.56, 3.69, 2.6, 1.0, 1.91, 3.29, 1.74, -0.52, 1.04, 0.17, -1.16, -1.26, -1.19, -1.87, -1.42, 0.65, -0.41, -1.96, -1.08, 0.26, -1.25, -0.88, -0.39692325186963273, 2.1, 1.03, -0.54, 0.35, 1.71, 0.18, -2.25, -1.71, 0.46, -1.58, -1.76, -0.32, 0.0, 2.5, -2.37, -1.2, -0.64, -2.47, 2.67, 2.34, 1.11, 0.26, -0.51, -3.68, 3.61, 3.47, -1.17, 3.6, -2.35, -3.12, 1.58, -5.6, 5.75, 3.74, 5.61, -2.73, -2.5, -1.05, -2.59, -1.72, -0.38, -1.88, -3.47, -1.46, -1.55, -0.67, 0.68, -0.84, 0.1, 0.89, 2.27, 0.73, -1.84, -2.01, -0.79, 1.36, -0.16, -1.05, -1.23, -1.47, 3.08, -0.95, -3.07, -1.46, -2.01, -2.12, -1.51, -1.63, -1.3, 0.1, -0.43, -0.43, -0.63, -2.58, -3.76, -1.65], ['232', 0.18, 0.44, -0.09877828437954125, -0.01, 0.21, 0.92, 1.4, 0.83, 1.18, 1.24, -0.17, 0.37, 0.72, -0.39, 0.19, 1.4, -0.56, 0.82, -1.44, 1.19, 1.47, 0.13, -0.11, 0.81, 0.54, 1.21, 1.41, 0.55, 0.89, -0.22, 0.36, 1.57, -0.39, 0.99, -1.27, 1.36, 1.64, 0.3, 0.06, 0.98, 0.68, 1.06, 0.86, 0.34, -0.76, -0.18, 1.02, -0.93, 0.44, -1.81, 0.81, 1.09, -0.25, -0.48, 0.44, 0.33006284630567656, 0.24, -0.15, 1.33, 0.52, -1.1, -0.52, 0.67, -1.27, 0.1, -2.14, 0.47, 0.75, -0.59, -0.82, 0.09, 0.26, 1.63, 0.58, 1.79, -0.18, 1.21, -1.05, 1.58, 1.86, 0.52, 0.28, 1.2, 1.28, 3.44, -3.48, 1.05, 1.2, -0.75, 0.62, -1.63, 1.193744771101914, 1.28, -0.06, -0.3, 0.62, 2.48, -0.15, -1.93, -0.57, -2.8, -0.21, 0.07, -1.25, -1.48, -0.58, 0.32, -0.12, -0.56, 1.04, 1.11, 1.07, 1.81, 1.39, -0.88, 1.76, 2.04, 0.69, 0.46, 1.38, 0.96, 0.47307674813036726, -2.24, 0.37, 0.8286030199958774, -0.68, -0.92, 0.0, 2.06, 2.55, -0.14, 1.53, 7.728670068027211, 0.07, -0.07, -2.82, 2.79, 1.428810171007621, 0.59, 0.96, -0.19, -2.13, -1.02, 0.12, 0.67, 3.27, -3.24, -3.08, 1.03, -4.2, 2.05, 1.59, -0.78, 5.38, -5.440028911564625, -3.53, -5.3, 0.26, 2.72, 2.66, 2.95, 1.59, 1.35, 2.28, 3.18, 0.05, 0.28, -1.05, -1.28, -0.37, -0.23, -1.32, -1.55, -0.65, 1.13, 1.29, 1.11, -0.23, 0.68, 0.99, 1.13, 0.8, -2.64, 0.55, 2.41, 1.66, 1.19, 1.35, 0.92, 0.79, 1.41, 0.75, 1.27, 0.62, 0.505957527023814, 2.67, 1.86, 1.03], ['233', -0.8, 0.0, 0.011221715620458745, -0.24, -1.23, 0.04, 1.63, -0.23, 0.82, -0.42, -1.45, -1.4, -0.9, -0.42, 2.6, -0.06, -0.63, -0.78, 0.37, 2.55, -0.38, -0.6, -1.11, -0.49, -0.04, 0.04, 1.04, 0.05, 0.56, 1.04, 4.11, 1.41, 0.83, 0.68, 1.85, 4.06, 1.08, 0.86, 0.35, 0.97, 0.06, 2.39, 0.990204081632653, 0.5, 0.99, 4.05, 1.36, 0.78, 0.62, 1.8871355564861205, 4.0, 1.03, 0.81, 0.29, 0.92, -0.07, 0.29, 0.16, 0.84, 0.48, 0.48, 3.53, 0.85, 0.28, 0.12, 1.28, 3.48, 0.52, 0.3, -0.21, 0.41, -0.11, 0.0, 3.04, 0.37, -0.2, -0.36, 0.8, 2.99, 0.04, -0.18, -0.68, -0.07, 1.24, 1.85, -1.9, -2.95, -2.59, -3.15, -3.3, -2.17, -0.05, -2.91, -3.12, -3.61, -3.01, -0.21, -0.37, -0.57, -0.73, 0.43, 2.61, -0.32, -0.55, -1.05, -0.44, 0.31, -0.33, -0.26, 0.0, 0.06, -0.09, 0.2, -0.16, 1.0, 3.2, 0.25, 0.09030501944728757, -0.48, 0.14, 0.03, 0.36, 1.16, 3.36, 0.409562358276644, 0.18, -0.33, 0.29, 0.51, 0.3, -0.01, 0.13, -0.74, 0.23, 0.22, -0.52, 0.49, 0.26, -0.53, -1.72, 5.59, 0.0, 0.03, -0.4, -0.58, 0.09, 0.0, 0.04, -0.01, -0.82, -0.17, 0.63, -0.26, 0.56, -3.08, -0.35, -0.62, -5.57, -0.4696213151927438, 2.17, -0.75, -0.97, -1.47, -0.86, -0.04, -2.9, -2.86, -3.07, -3.57, -2.97, -0.04, -0.22, -0.73, -0.11, 0.87, 1.0, 0.18, -0.51, 0.11, -0.09, -0.03, -0.08, -1.9728571428571429, -0.43, 1.77, -0.11, -0.23, 0.69, 0.62, -0.23, 0.24, -0.67, -0.9, -0.21, 0.07, 1.02, -0.5, 0.39], ['234', -2.21, -1.53, -0.18877828437954128, 0.07, -0.42, -0.34, -0.62, -0.8482794034640413, -0.9, -1.31, -0.59, -1.16, 0.19, -0.8, 0.75, -1.01, -0.94, -1.1, 2.45, -0.34, -1.92, -1.14, -1.07, -0.93, -0.46, -0.53, -0.72, -0.57, 0.79, -0.2, 1.35, -0.42, -0.34, -0.51, 3.06, 0.25, -1.33, -0.54, -0.48, -0.34, -0.76, -2.56, -0.15, 1.37, 0.5378753944468231, 1.94, 0.15, 0.23, 0.06, 3.65, 0.83, -0.76, 0.03, 0.09, 0.23, 0.0, -0.69, -0.22, -0.71, -1.5, -0.99, 0.56, -1.2, -1.13, -1.29, 2.25, -0.53, -2.11, -1.33, -1.26, -1.13, -0.43, -0.52, 1.56, -0.22, -0.14, -0.31, 3.27, 0.46, -1.13, -0.34, -0.28, -0.14, -1.48, -0.98, 1.0, -2.05, -1.7494795918367347, -1.68, -1.84, 1.68, -1.09, -2.65, -1.87, -1.8014761904761905, -1.68, -0.12, -0.3, 0.07, -0.09, 3.49, 0.67, -0.92, -0.13, -0.06, 0.08, -0.27, -0.35, -0.83, -0.28, -0.32, -0.23, -0.38, -0.17, 3.42, 0.6, -0.99, -0.2, -0.13, 0.0, -0.24, -0.21, 3.59, 0.77, -0.82, -0.04, 0.03, 0.17, 0.12, 0.16, 0.17, -0.22, -0.46, 0.0, 0.02, 0.69, -0.67, -0.34, -1.33, -1.3, 2.01, 0.54, 0.22, -1.1, 0.0, -0.87, 0.93, 0.83, -0.28, 0.97, -0.56, -0.37160934502005916, 0.24, -1.14, 1.59, 0.78, 1.01, -2.04, -3.67, -2.72, -4.26, -3.5, -3.43, -3.3, -0.81, -0.97, -1.58, -0.8, -0.73, -0.6, 0.62, 0.8, 0.86, 1.0, -0.88, -1.19, -0.17, 0.07, 0.2, -0.3, -0.23560369872470915, -0.86, 1.17, -0.84, -1.2, -0.71, -0.10890649791998751, -0.24, 0.14, -0.24399479488765202, -0.42, 0.38, 0.25, -0.55, -0.38, -0.76, -0.4, -0.28], ['235', -1.17, -0.6, -0.14, 0.14, -0.78, -1.19, -1.33, -0.67, -1.45, -0.37, 1.61, 0.83, 0.93, 0.63, 0.34, -0.36, 1.04, -0.01, -2.8, -0.55, -0.85, 0.05, 0.45, 0.35, -1.05, -1.05, -1.95, -0.77, -0.67, -0.96, -1.25, -1.94, -0.56, -1.6, -4.34, -2.12, -2.42, -1.54, -1.14, -1.24, -0.55, -4.04, -1.19, 0.1811974674961171, -0.2, -0.49, -1.18, 0.2, -0.84, -3.6, -1.37, -1.67, -0.78, -0.38, -0.48, -0.49, 0.55, -1.07, -1.56, -1.29, -0.3, -0.5792006802721088, -1.28, 0.11, -0.94, -3.69, -1.4697619047619048, -1.76, -0.88, -0.48, -0.58, -0.25, -0.99, -0.29, -0.99, 0.4, -0.64, -3.41, -1.17, -1.47, -0.58, -0.18, -0.29, -2.37, -2.49, 2.46, -0.6733017616146798, -0.7, 0.69, -0.35, -3.13, -0.89, -1.19, -0.3, 0.11, 0.0, -0.1, 0.0, 1.41, 0.35, -2.44, -0.18, -0.49, 0.41, 0.82, 0.71, -0.118858126000983, -0.07, -1.98, -1.17, -1.33, -1.06, -1.39, -1.04, -3.8, -1.57, -1.87, -0.98, -0.58, -0.69, -0.45, -0.35, -2.78, -0.53, -0.84, 0.06, 0.46, 0.36, -0.28, -0.56, 0.2, -1.5, -0.25, -0.36, -0.07, 1.61, -1.69, -0.82, 0.13, -1.68, -0.31, 2.34, 1.15, -0.57, -1.0, -3.46, 3.48, 3.52, -1.17, 2.49, -2.35, -1.69, 0.83, -4.14, 7.46, 2.8, 4.35, 0.39, 2.5, 2.31, 2.0, 2.92, 3.34, 3.23, -3.5, 0.18, -0.3, 0.6, 1.0, 0.9, 0.49, 0.9, 1.31, 1.2, -1.49, -1.79, -0.41, 0.4, 0.3, -1.067919965685943, -1.22, -0.68, 4.84, -2.2, -5.06, -1.59, -2.27, -0.81, -0.1, -1.45, -1.16, -0.54, -0.85, -1.44, -0.71, -3.24, -2.71, -1.01], ['236', -3.53, 0.4, 0.17122171562045874, -0.24, -0.04, 0.13, 0.17411525795982916, 0.69, 0.78, 0.66, 0.66, 0.33, 0.47, 0.07, 0.05, 1.27, 1.37, 0.91, 3.48, -0.8690034013605442, 0.57, 0.6, 0.39, 0.875116627420199, 0.69, 0.19, 0.0, -0.33, -0.19, -0.59, -0.61, 0.6, 0.71, 0.25, 2.8, -1.54, -0.09, -0.06, -0.27, 0.07, 0.42, 0.95, 0.33, 0.14, -0.26, -0.28, 0.94, 1.04, 0.58, 3.14, -1.21, 0.25, 0.27, 0.06, 0.4, 0.26006284630567655, 0.76, 0.82, 1.19, 0.19, -0.4, -0.42, 0.8, 0.9, 0.44, 3.0, -1.35, 0.1, 0.13, -0.08, 0.26, 0.88, 0.59, -0.02, 1.3555085034013605, 1.3, 0.84, 3.41, -0.95, 0.5, 0.53, 0.32, 0.66, 0.74, 0.35, -0.35857142857142854, 0.61, 1.22, 1.3417857142857144, 0.86, 3.43, -0.93, 0.53, 0.55, 0.34, 0.68, -1.14, -0.5226334687834371, 0.1, -0.36, 2.18, -2.13, -0.69, -0.6575714285714286, -0.87, -0.53, -0.25, -0.64, -0.93, 0.14, 0.25, -0.09, -0.7, -0.46, 2.08, -2.0302873118944547, -0.79, -0.76, -0.97, -0.63, 0.09, -0.25, 2.55, -1.78, -0.33, -0.31, -0.52, -0.18, 0.28, 0.15, -0.35, -0.4, -3.64, -0.43, -0.14, 0.22, -0.22, -0.09, 0.27, 0.6, -3.09, -0.26, -0.14, -1.73, -0.14, 0.47, -0.5, -0.47, 0.14, 0.27, 0.29, 0.82, -0.65, -2.13, -1.12, 1.35, 2.14, 3.29, -2.72, -4.22, -2.81, -2.78, -2.99, -2.66, 0.43, 1.56, 1.47, 1.5, 1.28, 1.63, 0.09, 0.03, -0.18, 0.16, 0.73, 0.84, 0.06, -0.21, 0.13, 0.14, 0.01, 0.75, -1.47, -0.38, 1.5, 0.43, 0.76, 0.27, 0.34, -0.13, -0.07, -0.31, -0.24, 0.36, -0.07, 0.7, 0.47, -0.58], ['237', 2.1, -0.24, 0.06122171562045875, -0.08, 0.69, 0.5384196236737595, 1.7000361663652803, 1.61, 1.9, 1.55, -1.48, 0.281934498041641, 0.01, 0.65, -0.26, 0.72, 0.41, 0.88, 3.07, 1.18, 2.17, 2.2, 0.96, 0.64, 1.29, 1.63, 3.08, 1.59, 1.51, 2.17, 1.24, 2.24, 1.93, 2.4, 4.63, 2.700714285714286, 3.71, 3.74, 2.48, 2.16, 1.02, 2.42, 1.47, 0.01119746749611708, 0.57, -0.34, 0.64, 0.33, 0.8, 2.99, 1.09, 2.09, 2.12, 0.88, 0.56, 0.68, 2.33, 0.94, 1.17, 1.54, 0.7431047225355607, -0.27, 0.71, 0.41, 0.88, 3.07, 1.17, 2.16, 2.19, 0.96, 0.64, 2.12, 0.89, -0.91, 0.07, -0.24, 0.23, 2.41, 0.52, 1.51, 1.54, 0.31, -0.01, 2.78, 1.61, -1.62, 1.82, 0.98, 0.68, 1.15, 3.35, 1.44, 2.44, 2.47, 1.23, 0.91, 1.01, 0.82, -0.3, 0.16, 2.34, 0.45, 1.44, 1.47, 0.24, -0.08, 0.44, 0.79, 3.12, 0.8915981806829014, 0.75, 0.99, 1.13, 0.47, 2.65, 0.76, 1.75, 1.78, 0.55, 0.23, -0.3134639289282145, 0.66, 2.17, 0.29, 1.28, 1.31, 0.08, -0.24, 0.82, 0.8, 0.14, 1.09, 3.11, 0.54, 0.28, -2.04, 2.062462323390895, 1.04, -1.0, 2.13, -0.75, -1.65, -0.91, 1.14, 0.53, 2.63, -2.63, -2.52, 0.84, -3.06, 1.72, 1.48, -0.77, 3.45, -6.12, -2.33, -3.37, 0.84, -1.48, -1.84, -0.87, -0.85, -2.033374149659864, -2.36, 2.53, 0.37, 0.99, 1.01, -0.21, -0.53, -0.61, 0.03, -1.18, -1.5, 1.92, 2.24, -0.64, -1.21, -1.52, 0.85, 0.93, 1.78, -3.84, 2.310199626957499, 3.78, 1.33, 0.68, 0.58, -0.32, 1.29, 0.97, 0.6, 0.26, 1.2, 0.9, 0.96, 1.7, 0.88], ['238', -1.93, -0.36, -0.028778284379541254, 0.08, -0.46, -0.44, -0.16588474204017084, -1.01, -0.52, -0.76, -0.38, -0.6, 0.52, -0.15, -0.02, -0.15, -0.26, -0.73, 0.18, -0.33, -0.67, -0.53, -0.53, -0.57, -1.26, -0.77, -0.38, -0.22, 0.9108333333333334, 0.23, 0.36, 0.23, 0.12, -0.36, 0.56, 0.05, -0.3, -0.16, -0.15, -0.19, -0.19, -0.5350638007838266, -0.16, 1.12, 0.45, 0.58, 0.45, 0.34, -0.14, 0.79, 0.27, -0.041934531913557026, 0.07, 0.07, 0.03, -0.36, 0.11, -0.55, -0.41, -1.27, -0.5568952774644393, -0.53, -0.66, -0.77, -1.24, -0.33, -0.84, -1.18, -1.04, -1.04, -1.08, -1.1863939988582846, -0.61, 0.13, 0.0, -0.11, -0.59, 0.33, -0.18, -0.52, -0.39, -0.38, -0.42, -0.42, -0.51, 0.52, -0.7033017616146798, -0.13, -0.24, -0.71, 0.2, -0.31, -0.65, -0.51, -0.51, -0.55, -1.11, -0.61, -0.11, -0.59, 0.33, -0.18, -0.52, -0.38, -0.38, -0.42, -0.04, -0.63, -0.23, -0.3, -0.38482093036566006, -0.2, -0.5, -0.48, 0.44, -0.07, -0.41, -0.27, -0.27, -0.25141531611693435, -0.06, -0.03, 1.1736855802927233, 0.41, 0.06, 0.2, 0.21, 0.17, -0.32, -0.44, 0.01, -0.48, -3.09, -0.1, -0.07, 0.1, -0.14, -0.06, 0.67, -0.5238364678879506, 0.83, 0.49, 0.28, -0.95, -0.29, -0.9, 0.95, 0.9, -0.31, 0.17, -0.6, -0.92, 0.47, -1.48, -3.85, 1.04, 1.55, -0.76, -0.94, -0.51, -0.85, -0.71, -0.71, -0.75, -0.96, -0.43, -0.34, -0.2, -0.2, -0.24, -0.09, 0.14, 0.15, 0.1, -0.52, -0.47, -0.23, 0.01, -0.04, -0.29, -0.31, -0.94, -1.84, -0.16, 1.84, -0.97, -0.7, -0.15136255179902908, -0.04, -0.57, 0.17455285983857427, -0.22, -0.37, -0.52, -0.19, -2.59, -1.31, -0.5], ['239', -1.72, 0.49, 0.18, -0.09, -0.72, 0.17, 0.49411525795982914, -0.11, 0.2, -0.45, -0.85, 0.05, -1.03, -0.03, -0.38, 0.34, -1.09, -0.55, -3.41, -0.66, -0.59, -0.44, -1.14, -0.63, 0.2, 0.26, 0.4, 0.91, -0.18, 0.82, 0.47, 1.21, -0.24, 0.4172589041444084, -2.58, 0.19, 0.26, 0.42, -0.29, 0.23, 0.68, 0.9049361992161734, -0.51, -1.09, -0.09, -0.43, 0.29, -1.14, -0.6, -3.46, -0.71, -0.64, -0.49, -1.19, -0.68, 0.25, -0.22, -0.51, 0.5, 0.59, 1.01, 0.66, 1.39, -0.06, 0.49, -2.4, 0.38, 0.45, 0.6, -0.11, 0.41, -0.53, -0.42, -0.35, 0.38, -1.06, -0.52, -3.38, -0.62, -0.55, -0.4, -1.11, -0.59, 0.6, 2.08, -2.09, -0.03330176161467985, 0.73, -0.71, -0.17, -3.04, -0.28, -0.21, -0.06, -0.76, -0.1859922724755494, -1.06, -0.8, -1.43, -0.89, -3.74, -1.0, -0.93, -0.78, -1.48, -0.97, 0.06, -0.86, 0.88, 0.31, 0.55, 0.11, 0.65, 0.55, -2.35, 0.44, 0.51, 0.66, -0.05, 0.5285846838830657, 0.17, 0.1, -2.88, -0.11, -0.04, 0.11, -0.59, -0.07, 1.05, 0.96, -0.11, 0.57, -3.26, 0.2, 0.27, 0.54, -0.57, -0.3, 1.34, -0.1, -0.43, -0.67, -0.33, -0.65, 0.48307978986877903, 0.82, -0.93, -0.94, 0.29, 0.75, 0.59, 0.21, -0.07, 1.93, -3.81, -1.29, -1.92, 0.46, 3.06, 2.85, 2.92, 3.08, 2.35, 2.89, 0.91, 0.21, 0.07, 0.22, -0.49, 0.03, 0.14, 0.15, -0.56, -0.04, 0.16, 0.48, -0.02, -0.71, -0.19, 0.31, 0.43439630127529083, -0.11, -1.81, 0.69, 1.62, 0.81, 1.1410935020800126, 0.7, 0.52, 0.7100774025227806, -0.4, 0.25, 0.51, 0.39, 0.17, 0.48, 0.99, 0.66], ['240', 3.13, 0.12, 0.2912217156204588, 0.19, -0.29, -0.09, 0.18, 0.44, 0.32, 0.55, 0.06060884353741497, 0.14, -0.05, -0.08, -0.78, -0.13, -0.02, 0.55, -5.2, 2.03, 0.54, 0.59, -0.08, 0.71, 0.04, 0.11, 0.5, 0.09, -0.1, 0.013189937047079991, -0.83, -0.18, -0.07, 0.5, -5.24, 1.98, 0.49, 0.54, -0.13, 0.66, 0.08746842535321082, 0.0, 0.42, -0.19, -0.22, -0.92, -0.27, -0.15, 0.42, -5.32, 1.89, 0.409654729237061, 0.45, -0.21, 0.57, 0.97, 0.3, 0.73, 0.12, 0.61, -0.03, -0.73, -0.08, 0.04, 0.61, -5.14, 2.09, 0.59, 0.64, -0.02, 0.76, 0.55, 0.64, -0.7, -0.05, 0.07, 0.64, -5.11, 2.12, 0.62, 0.67, 0.01, 0.79, 0.56, 2.01, -2.03, 1.3766982383853201, 0.65, 0.77, 1.34, -4.45, 2.83, 1.33, 1.38, 0.71, 1.5, 1.38, 0.69, 0.12, 0.69, -5.07, 2.17, 0.68, 0.72, 0.06, 0.84, 0.08, 0.68, 0.3, 0.14, 0.12, 0.18567351865003195, 0.57, 0.57, -5.18, 2.05, 0.56, 0.6, -0.06, 0.72, 0.05, 0.0, -5.72, 1.47, -0.01, 0.15579954965669268, -0.63, 0.15, 0.56, 0.84, 0.24, 0.07, 4.26, 0.21, 0.18, -0.38, 0.38, 0.18, 0.51, -0.45, 3.03, -0.29, -0.15, 1.59, 0.0, 0.6305968614718616, -0.53, -0.39, 0.14, -0.67, 0.29, -0.08, 0.03, 1.65, -4.49, -1.19, -1.65, -3.0, 6.06, 7.62, 6.05, 6.1, 5.4, 6.22, 0.44, -1.45, -1.46, -1.42, -2.06, -1.3, 0.01, 0.05, -0.61, 0.17, 0.23, 0.22, -0.03, -0.66, 0.19224875531501634, 0.14, 0.18439630127529083, 0.56, -2.33, 1.13, 2.29, -0.002736189475566718, 0.48, 0.63, 0.78, 0.05, 0.29, 0.35, -0.06, -0.53, -0.15, 1.69, 0.29, 0.05], ['241', -3.36, 0.38, 0.18122171562045875, 0.08, 0.07, 0.02, -0.49588474204017086, -0.84, -0.36, -1.03, -0.59, -0.28, -0.59, -1.19, 1.2242857142857142, -0.7, -1.5071428571428571, -0.85, 0.77, -3.49, -0.9526645179126411, -1.17, -0.58, -0.65, -0.3, 0.98, -0.45, 0.31, 0.0, -0.61, 1.82, -0.11, -0.93, -0.26, 1.37, -2.92, -0.4, -0.59, 0.02, -0.06, -1.74, 0.23, -0.75, -0.31, -0.92, 1.5, -0.42, -1.23, -0.57, 1.05, -3.22, -0.681934531913557, -0.89, -0.29, -0.37, -0.15, -0.59, -1.4580521152823784, -0.36, -0.45, -0.61, 1.82, -0.11, -0.93, -0.26, 1.36, -2.92, -0.4, -0.59, 0.01, -0.07, -0.97, 0.16, 2.44, 0.5, -0.32, 0.35, 1.99, -2.33, 0.21, 0.02, 0.63, 0.55, -0.03, -1.13, 1.1305714285714286, -2.22, -1.9, -2.7, -2.04, -0.44, -4.66, -2.18, -2.36, -1.77, -1.85, -0.02, -0.33, -0.82, -0.15, 1.48, -2.81, -0.29, -0.23718300350443208, 0.13, 0.05, -0.28, -0.4, 2.51, -0.06, -0.05, 0.03, 0.48, 0.67, 2.31, -2.01, 0.53, 0.34, 0.95, 0.87, 0.23, -0.18, 1.63, -2.67, -0.14, -0.32, 0.28, 0.44217743764172346, 1.04, 1.46, -0.33, 0.37, 0.03, -0.07, -0.14, 0.42, -0.41, -0.22, 0.62, -0.03, -5.1, 0.1, 0.05, -1.74, 0.04, -0.06, 0.06, 0.21, -0.06, 0.54, -0.15, -0.07, 0.06, 1.43, 0.13, -0.92, -1.38, 5.14, -1.4696213151927437, -4.23, -1.5427867132867132, -1.93, -1.33, -1.41, -0.08, 2.55, 2.6, 2.41, 3.03, 2.94, -0.05, -0.10112140889357832, 0.42, 0.34, -0.24, -0.23, 0.14, 0.6, 0.52, -0.09, -0.03, -0.78, 0.09, 1.4, 0.0, -0.66, 0.73, -0.46, -0.08, 0.06, -0.04, 0.27, -0.11, -0.41, -0.38, -0.25, 1.79, -0.24], ['242', -3.4, 0.11, 0.09122171562045875, 0.07, -0.6570209190089404, -0.26, -0.82, -0.49, -0.26, 1.05, 1.07, 1.92, 0.52, 2.15, 2.57, 1.71, 1.86, 1.01, 5.22, 1.77, 0.78, 1.84, 1.57, 1.34, -0.8, -0.73, -0.02, 0.8401785714285714, -0.54, 1.07, 1.48, 0.64, 0.78, -0.06, 4.1, 0.7, -0.29, 0.76, 0.5, 0.27, -0.67, -0.66, -0.86, -1.37, 0.22, 0.63, -0.21, -0.06, -0.9, 3.23, -0.15, -1.0919345319135572, -0.08, -0.34, -0.57, -0.14, 0.56, -1.31, 0.06, 0.52, 1.62, 2.03, 1.19, 1.33, 0.48, 4.67, 1.25, 0.26, 1.32, 1.05, 0.82, -0.3, -1.08, 0.41, -0.43, -0.29, -1.12, 3.0, -0.37, -1.34, -0.3, -0.57, -0.79, -0.23, -1.61, 1.57, -1.48, -0.83, -0.69, -1.52, 2.59, -0.7683253968253968, -1.74, -0.7, -0.97, -1.19, -1.49, -0.66, 0.14, -0.69, 3.45, 0.06, -0.92, 0.13, -0.14, -0.36, -0.15, -0.65, -1.98, -0.46, -0.49, -0.44, -0.8, -0.84, 3.3, -0.08, -1.06, -0.01, -0.28, -0.51, -0.83, 0.04, 4.17, 0.76, -0.22, 0.83, 0.56, 0.33, -0.46, -0.44, 0.07, -0.69, -4.57, -0.08, -0.24, 1.14, -1.13, -0.56, -0.08, -0.22383646788795053, 1.29, 1.01, 0.44, -1.7, 0.13, -1.38, 1.34, 1.41, -0.47, 1.5, -0.93, -0.29, 0.14, -2.42, 0.2721071428571429, 1.57, 2.22, -1.18, -3.97, -3.27, -4.22, -3.21, -3.46, -3.68, -1.4, -0.72, -0.97, 0.07, -0.2, -0.42, 0.26, 1.05, 0.78, 0.56, -0.29, 0.07, -0.78, -0.27, -0.49, -0.47, -0.5, -0.37, 0.84, -1.45, -0.83, -1.0, -1.03, -0.52, -0.23, -0.94, -0.64, 0.26, 0.38, -0.38, -0.29, -1.97, -2.36, -0.05], ['243', 1.92, -0.07, 0.08015289830927054, 0.15, -0.53, -0.07, -0.44588474204017087, -0.74, 0.33, -1.34, -2.31, -1.02, -1.06, -0.5, -0.11, -1.48, -1.55, -1.44, 0.97, -0.7, -1.28, -1.57, -1.57, -1.39, -0.44, 0.14, 0.99, 1.32, 1.28, 1.86, 2.25, 0.85, 0.78, 0.89, 3.35, 1.65, 1.06, 0.76, 0.76, 0.95, -0.03253157464678917, 0.95, -0.32, -0.03, 0.53, 0.92, -0.46, -0.53, -0.42, 2.01, 0.32, -0.26, -0.56, -0.55, -0.37, -0.61, -0.76, -0.47, 0.53, -0.29, 0.56, 0.95, -0.43, -0.5, -0.39, 2.04, 0.36, -0.22, -0.52, -0.52, -0.33, -0.96, -0.85, 0.39, -0.99, -1.06, -0.95, 1.47, -0.2, -0.78, -1.08, -1.08, -0.89, 1.04, 0.72, -0.7, -1.23, -1.37, -1.44, -1.33, 1.08, -0.59, -1.17, -1.46, -1.46, -1.27, -0.42, 0.14, -0.07, 0.04, 2.48, 0.79, 0.21, -0.09, -0.09, 0.1, 0.06, 0.09, -0.97427628811696, 0.17, 0.17517906963433993, 0.2, 0.21, 0.11, 2.55, 0.86, 0.28, -0.02, -0.02, 0.2285846838830657, 0.2, 0.1, 2.44, 0.75, 0.17, -0.13, -0.13, 0.06, 0.83, 0.29, 0.29, 0.14, -1.11, 0.13, 0.2, -0.54, 0.56, 0.25, 0.34, -0.6638364678879505, 1.22, -0.37, -0.19, 0.94, 0.17, 0.57, -0.54, -0.49, 0.22329080486385297, -0.87, 0.33, -1.44, 0.69, 0.72, -1.59, -0.41, -0.65, -1.26, -2.29, -1.65, -2.22, -2.51, -2.51, -2.33, 0.5, -0.64, -0.4358074110763185, -0.88, -0.87, -0.69, -0.07, -0.3, -0.3, -0.11, 0.33, 0.8084535464535467, 0.23, 0.0, 0.26224875531501635, 0.17, 0.11, -0.76, -1.32, -0.38, 1.27, -0.39, 0.22, 0.23, 0.19, -0.08, 0.29, 0.29, 0.33, 0.18, 0.04, -1.31, 0.68, 0.07], ['244', -0.53, 0.15, 0.13122171562045873, 0.03, 0.0, 0.31, 0.51, -0.58, 0.1, -0.6, -0.71, -0.96, -0.58, 0.41, -0.16, -0.69, -0.52, -0.68, -0.7, -0.22, -0.42, -0.47, -1.3, -0.86, 0.36, 0.4, 0.12, -0.25, 0.14011904761904762, 1.14, 0.56, 0.02, 0.2, 0.04, 0.02, 0.5, 0.3, 0.24, -0.59, -0.15, 0.2, -0.24, 0.37, 0.38, 1.39, 0.8, 0.27, 0.45, 0.28, 0.27, 0.75, 0.54, 0.49, -0.34, 0.1, 0.03, -0.44, -0.07, 0.22, -0.01, 1.0, 0.42, -0.11, 0.07, -0.1, -0.11, 0.37, 0.16, 0.11, -0.72, -0.28, -0.5263939988582844, -1.01, -0.57, -1.1, -0.92, -1.09, -1.1, -0.63, -0.83, -0.88, -1.5769045181009465, -1.2164403582748793, 0.0, 1.73, -1.77, -0.43, -0.53, -0.35, -0.52, -0.53, -0.06, -0.26, -0.31, -1.14, -0.7, -0.4, 0.1, 0.18, 0.02, 0.0, 0.48, 0.28, 0.22, -0.61, -0.17, 0.02, 0.11, 0.04, 0.26, 0.41, 0.13567351865003197, -0.08, -0.16, -0.18, 0.3, 0.1, 0.04, -0.79, -0.35, 0.03, 0.08, -0.02, 0.46, 0.26, 0.21, -0.62, -0.18, 0.74, 0.63, 0.08, -0.04, -1.12, 0.01, -0.07, 0.0, 0.05, 0.0, 0.52, -0.85, 0.79, -0.45, -0.26, -0.3, 0.19, 0.76, -0.78, -0.74, 0.26, -0.09, 0.5, -0.27, 0.12, -0.21, -5.32, 0.2, 0.23, -0.73, 0.1, 0.48, 0.28, 0.22, -0.61, -0.17, 0.79, -0.38, -0.2, -0.26, -1.08, -0.64, -0.18, -0.05, -0.88, -0.44, 0.16, 0.11, -0.12, -0.83, -0.39, 0.26, 0.21, -0.45, -3.66, 0.52, 3.66, 0.3718948994148555, 0.08, 0.7104317111459968, 0.44, 0.29, -0.07, 0.16, 0.21, 0.38, 0.27, -0.29, 0.07, -0.03], ['245', -2.01, 0.34, -0.028778284379541254, -0.28, -0.1, 0.06, 0.044115257959829166, 0.09, 0.31, 0.28, -0.6, 0.23, 0.35, 0.02, 0.46, 0.6, 0.23, 0.28, -3.83, -0.6, 0.21, 0.31, -0.19, -0.4, -0.86, -0.28, 0.89, 0.84, 0.96, 0.63, 1.07, 1.21, 0.84, 0.89, -3.25, 0.0, 0.82, 0.92, 0.41, 0.21, 0.36, 0.75, 0.05, 0.20119746749611708, -0.21, 0.22, 0.37, 0.0, 0.05, -4.05, -0.83, -0.02, 0.08, -0.42, -0.63, 0.35, 0.54, -0.19, 0.34, -0.07, -0.33, 0.11, 0.25, -0.11, -0.07, -4.16, -0.95, -0.13, -0.03, -0.54, -0.74, 0.76, 0.26, 0.44, 0.58, 0.21, 0.26, -3.85, -0.62, 0.19, 0.29, -0.21, -0.35644035827487924, 0.89, 1.3, -1.39, -0.17, 0.14, -0.22, -0.17, -4.27, -1.06, -0.24, -0.14, -0.65, -0.85, -1.49, -0.2426334687834371, -0.36, -0.32, -4.4, -1.2, -0.38, -0.28, -0.79, -0.99, -0.02, -0.26, 0.23572371188304003, 0.18, 0.38, -0.024326481349968038, 0.12180947648612922, 0.05, -4.05, -0.84, -0.02, 0.08, -0.43, -0.5714153161169343, 0.08, 0.0, -4.1, -0.88, -0.07, 0.03, -0.47, -0.68, 0.54, 0.59, -0.26, 0.01, -4.48, 0.26, 0.21, 0.72, -0.71, -0.35, 0.65, -0.19, -1.76, -0.43, -0.18, -0.98, 0.3, 0.37, -0.4, -0.58, 0.18, 1.07, 0.39, 0.73, -0.39, 0.14, -2.67, -0.07, -0.07, 1.78, 4.28, 3.3548095238095237, 4.206609977324264, 4.31, 3.78, 3.57, 0.56, 0.89, 0.82, 0.92, 0.41, 0.21, 0.07, 0.1, -0.41, -0.61, 0.32, 0.26, -0.03, -0.51, -0.71, 0.18, 0.11, 0.13, -1.37, 0.73, 1.21, 0.047263810524433285, 0.37, 0.48, -0.2, 0.32, 0.0, -0.03, 0.0, -0.24, 0.68, -1.31, 0.58, 0.77], ['246', -8.0, -1.26, -0.28, -0.18, -0.51, -1.11, -0.5258847420401709, -2.018279403464041, -2.3, -2.19, 0.4, -1.92, 0.4, 1.59, -0.2, 0.61, -1.33, -1.68, -1.55, -2.94, -2.69, -0.88, -1.14, -1.55, -3.32, -2.36, -2.5473416050068876, -2.3, 0.0, 1.18, -0.59, 0.21, -1.72, -2.07, -1.9392857142857143, -3.32, -3.07, -1.27, -1.53, -1.8961582768021608, -1.8025315746467891, -4.55, -0.28, 2.36, 3.57, 1.75, 2.57, 0.6, 0.24, 0.38, -1.04, -0.79, 1.06, 0.79, 0.37, -1.3199371536943236, -2.44, -1.37, -1.94, -2.510754752934122, 1.18, -0.6, 0.2, -1.73, -2.07, -1.8313219954648525, -3.33, -3.08, -1.28, -1.54, -1.95, -1.99, -3.72, -1.76, -0.97, -2.87, -3.21, -3.08, -4.46, -4.21, -2.43, -2.69, -3.09, -3.64, -3.87, 3.21, -2.0, 0.8, -1.14, -1.48, -1.35, -2.75, -2.5, -0.68, -0.95, -1.36, -4.1, -2.78, -1.93, -2.27, -2.14, -3.52, -3.27, -1.48, -1.74, -2.15, -1.08, -2.81, -1.36427628811696, -1.06, -1.09, -1.09, -0.87, -0.35, -0.22, -1.63, -1.37, 0.46, 0.19, -0.23, -1.43, -0.53, 0.13, -1.29, -1.03, 0.81, 0.54, 0.12, -0.61, -0.5, -0.13, -1.31, -8.21, -2.0219304505018787, -1.86, 1.28, -1.24, -0.62, -0.47, -1.32, -1.33, 2.13, 1.05, -4.1, -0.98, -3.34, 3.37, 3.32, -1.06, 2.04, -2.19, -0.63, 0.26, -2.65, 11.22, 1.73, 2.69, 1.63, -0.66, -1.42, -1.16, 0.68, 0.41, -0.01, -3.14, 0.77, 0.26, 2.12, 1.85, 1.43, 0.51, 1.86, 1.59, 1.16, -2.46, -2.88, -1.33, -0.27, -0.68, -1.11, -1.0, -1.94, 5.58, -0.9098003730425006, -5.46, -2.05, -1.66, -1.06, -0.42, -1.743994794887652, -0.68, -1.03, -0.46, -1.03, -0.65, -2.84, -1.97, -0.44], ['247', -2.09, 0.12, 0.09122171562045875, 0.08, 0.15, -0.63, -1.0058847420401709, -0.77, -1.12, -1.73, 1.05, -1.42, -1.61, -1.77, -0.32273809523809527, -1.36, -1.012857142857143, -1.66, -1.39, -1.7233571428571428, -2.01, -0.62, -0.29, -1.33, -0.42, -1.2, -2.76, -2.44, -2.2123253968253964, -2.79, -1.37, -2.38, -2.08, -2.68, -2.42, -2.76, -3.02, -1.66, -1.33, -2.36, -1.79, -3.1750638007838266, -0.32, -0.19, -0.35, 1.1, 0.06, 0.38, -0.24, 0.03, -0.32, -0.6, 0.81, 1.14, 0.09, -1.02, -0.65, -0.08, -0.35, -0.13, -0.16, 1.3, 0.26, 0.57, -0.05, 0.22, -0.13, -0.4, 1.0, 1.34, 0.28, 1.25, 0.03, 1.46, 0.42, 0.73, 0.11, 0.38, 0.03, -0.24, 1.16, 1.5, 0.44, -2.62, -3.39, 3.63, -1.4, -1.02, -0.72, -1.33, -1.06, -1.41, -1.68, -0.27428571428571424, 0.04, -1.0, -0.7473809523809524, -0.38, 0.31, -0.31, -0.04, -0.38, -0.66, 0.74, 1.08, 0.03, -0.19, -0.41, -0.17989534883720928, -0.62, -0.7, -0.36, -0.69, -0.62, -0.35, -0.69, -0.97, 0.43, 0.76, -0.29, -1.02, -0.08, 0.27, -0.08, -0.35, 1.05, 1.39, 0.33, -1.11, -1.05, 0.13, 0.11, -1.59, 0.3580695494981211, 0.22, 0.46, -0.47, -0.26, -0.37, 0.36, -0.32, 1.25, 0.61, -0.98, -0.56, -1.6, 1.54, 1.93, -0.63, 0.69, -1.28, 0.3, -0.18, -2.12, 2.45, 1.43, 2.04, 0.19, -0.34, -0.34, -0.62, 0.78, 1.12, 0.06, -1.85, 0.0, -0.28, 1.13, 1.47, 0.41, 0.28, 1.4128849285635, 1.75, 0.69, -1.18, -1.54, -1.12, 0.33, -0.71, -0.69, -0.52, -0.78, 1.3, 0.0, -1.16, -0.03, -0.27, -1.45, -1.04, -0.77, -0.46, -0.42, -0.68, -0.64, -0.41, 1.13, 0.5, -0.64], ['248', -0.53, 0.12, -0.43877828437954125, 0.06, 0.07, -0.41, 1.5, 0.69, 0.45, 2.23, 2.33, 0.32, 2.17, 2.46, 0.9, 1.75, 2.68, 2.47, 6.64, 1.71, 2.05, 2.8010442176870747, 2.37, 2.19, 0.13, 0.28, -0.09, -1.96, -0.16, 0.13, -1.39, -0.57, 0.35, 0.14, 4.22, -0.6, -0.27, 0.43, 0.05, -0.13, 1.95, -0.15, 1.91, 1.84, 2.13, 0.58, 1.42, 2.35, 2.14, 6.3, 1.38, 1.72, 2.43, 2.05, 1.86, -0.28, 0.39, 1.28, 0.12, 0.07, 0.29, -1.24, -0.41, 0.51, 0.3, 4.38, -0.45, -0.11, 0.59, 0.2, 0.02, 1.1, -0.22, -1.52, -0.7, 0.22, 0.01, 4.08, -0.73, -0.4, 0.3, 0.05309548189905343, -0.27, -0.2, -0.24, 0.19, 1.32, 0.84, 1.77, 1.55, 5.69, 0.8, 1.14, 1.85, 1.46, 1.27, 0.36, 0.48, 0.92, 0.71, 4.8459047619047615, -0.04, 0.3, 1.0, 0.62, 0.43, 0.18114187399901702, 0.54, 0.56, -0.1, -0.06, -0.03, -0.44, -0.21, 3.86, -0.95, -0.4442217465074606, 0.08, -0.3, -0.48, -0.48, -0.23, 4.08, -0.74, -0.41, 0.29, -0.09, -0.27, 0.37, 0.45, 0.06, 0.05, 0.92, 0.18, -0.28, -0.17, 0.18, 0.11, 0.21406627346681525, 1.05, -0.9, 0.12, 0.1, -0.25, -0.39, -0.14, 0.14, 0.26, -0.08, -0.22, -0.2, -0.5, 0.25, -1.23, 8.05, 0.87, 1.21, 1.3056150793650794, -4.14, -4.63, -4.31, -3.64, -4.0, -4.18, -0.25, 0.6543542330685188, 0.33, 1.04, 0.65, 0.47, 0.18, 0.7, 0.32, 0.14, 0.41, 0.09, -0.52, -0.38, -0.56, -0.07, -0.09, 0.64, 4.812857142857143, -0.3, -4.13, 0.3, 0.05, -0.14, -0.18, -0.88, 0.18, 0.03, -0.29, -0.03, 0.04, -0.21, 1.5030376647162362, -0.43], ['249', -0.59, 0.63, 0.04, -0.06, 0.41, 0.27, 1.17, 0.65, 0.51, -0.62, -1.48, -1.17, -1.63, -0.09, -2.94, -0.25, -1.19, -0.79, -0.52, -1.2033571428571428, -0.35, -0.77, -1.16, -1.47, 0.45, 0.63, 0.9126583949931124, 0.32, -0.14535714285714285, 1.42, -1.4221800287049087, 1.26, 0.29, 0.8272589041444084, 0.97, 0.28, 1.15, 0.72, 0.33, 0.053841723197839156, 0.88, 1.64, 0.56, -0.46, 1.1, -1.79, 0.94, -0.02, 0.39, 0.7571355564861204, -0.04, 0.83, 0.41, 0.01, -0.3, 1.05, -0.44, 0.3, -0.11, 1.03, 1.56, -1.33, 1.4, 0.44, 0.85, 1.1371802721088435, 0.42, 1.3, 1.1974648526077096, 0.48273474541331685, 0.18418480725623584, 0.14, -0.53, -2.849285714285714, -0.16, -1.11, -0.7, -0.4269047619047619, -1.12, -0.26, -0.68, -1.07, -1.38, 1.05, 1.721742947528662, -1.58, 2.4266982383853204, 2.78, 1.8, 2.22, 2.49, 1.78, 2.67, 2.23, 1.83, 1.51, -0.13, -0.37, -0.95, -0.54, -0.28, -0.97, -0.11, -0.53, -0.92, -1.23, 0.25, -0.45, 2.3157237118830403, 0.49, 0.53, 0.585673518650032, 0.6618094764861292, 0.41, 0.68, -0.02, 0.85, 0.43, 0.04, -0.22141531611693435, 0.25, 0.17, 0.27, -0.43, 0.44, 0.02, -0.38, -0.69, 0.5, 0.43, -0.16, 0.55, -0.37, 0.1, 0.1, -0.9, 0.7, 0.45, -0.26, 0.95, -1.33, -0.98, -0.52, -0.21, 0.5, 1.46, -1.49, -1.47, 0.47, -1.4, 0.9, 1.36, -0.7, 1.74, -6.02, -1.1, -1.59, 1.22, -0.09, -0.69, 0.17, -0.25, -0.64, -0.95, 1.4708051948051948, 0.6, 0.87, 0.45, 0.05, -0.26, 0.176501700680272, -0.42, -0.81, -1.12, 0.55, 0.64, 0.16, -0.39, -0.7, 0.49, 0.53, 0.6, -4.07, 2.05, 4.14, 0.51, 0.37, 0.55, -0.32, -0.14, 0.36, 0.83, 0.57, 0.67, 0.87, 0.39, 0.4, 1.23], ['250', 2.04, -0.18, 0.12, 0.05, 0.18, -0.42, -2.1758847420401706, -0.99, -0.7, -0.15, 0.5, 1.35, 0.28, 0.89, 2.03, -1.09, 0.05, -0.12, 1.18, -0.09, -0.29, 0.19, 0.26, 0.19, -0.8, -0.17, -0.65, 0.85, -0.22, 0.38, 1.52, -1.58, -0.45, -0.5027410958555916, 0.68, -0.59, -0.705546329921431, -0.31, -0.24, -0.31, -0.56, 0.07, -1.48, -0.9788025325038829, -0.46, 0.67, -2.41, -1.28, -1.46, -0.17, -1.43, -1.62, -1.14, -1.08, -1.15, -0.68, -0.59, -1.28, -0.66, -0.43, 0.61, 1.74, -1.36, -0.23, -0.4, 0.9, -0.37, -0.57, -0.09, -0.02, -0.09, -0.75, -1.03, 1.13, -1.96, -0.83, -1.0, 0.29, -0.97, -1.16, -0.69, -0.62, -0.69, -0.36, -1.09, 1.11, -2.13, -3.05, -1.94, -2.11, -0.83, -2.08, -2.1047647669790526, -1.8, -1.73, -1.8, 0.18, 0.95, 1.15, 0.98, 2.29, 1.01, 0.81, 1.29, 1.36, 1.29, -0.07, 0.87, -0.11, -0.4, -0.41, -0.3, -0.2, -0.17, 1.13, -0.14, -0.34, 0.14, 0.21, 0.14, -0.12346392892821456, -0.03, 1.31, 0.03, -0.16, 0.32, 0.39, 0.31, -0.6, -0.51, 0.07, -0.3, 0.4, 0.07, 0.24, 0.53, -0.49, -0.29, 0.14, -0.98, 0.0, 0.8, 0.39, 1.04, -0.45, -1.15, 1.09, 1.17, -0.39, 0.82, -0.77, -0.95, 0.48, -0.57, -1.7, 0.42, 0.49, -0.07, -1.32, -1.26, -1.45, -0.98, -0.91, -0.98, -1.12, -0.06, -0.2, 0.29, 0.35, 0.28, 0.14, 0.48, 0.55, 0.48, -0.6772046485260771, -0.41, -0.34, 0.07, 0.0, -0.36, -0.36, -0.93, -0.87, -0.11, 0.85, 0.08, -0.59, -0.41, -0.07, -0.7999225974772194, -0.53, -0.2, -0.34, 0.07, -0.34, -1.41, 0.07, -0.28], ['251', -7.91, -0.4, -0.3487782843795412, 0.18, -2.26, -1.24, -0.32588474204017087, -1.05, -1.7, 0.8470884353741497, 2.84, 0.86, 1.59, 2.27, 0.97, 2.54, 0.71, 0.1, 3.72, 3.7, -0.57, 2.63, 2.04, 0.74, -2.16, -1.95, -2.37, -1.93, -1.22, -0.56, -1.82, -0.29, -2.07, -2.67, 0.85, 0.84, -3.319239316239316, -0.2, -0.78, -2.04, -0.28, -2.85, -0.250696767518196, 0.73, 1.4, 0.11, 1.67, -0.14, -0.75, 2.84, 2.82, -1.41, 1.76, 1.17, -0.11, -0.97, -0.75, -1.41, -1.62, -1.17, 0.66, -0.61, 0.94, -0.87, -1.47, 2.09, 2.08, -2.13, 1.02, 0.44, -0.84, -1.57, -1.82, -1.27, 0.27, -1.52, -2.12, 1.42, 1.4, -2.78, 0.36, -0.22, -1.49, -2.64, -4.67, 4.63, -0.56, 1.56, -0.25, -0.86, 2.72, 2.71, -1.53, 1.65, 1.06, -0.22, -3.37, -2.09, -1.79, -2.377880952380952, 1.14, 1.13, -3.04, 0.09, -0.49, -1.76, 0.13, -2.11, 0.73572371188304, -1.53, -1.32, -0.76, -0.31, -0.61, 2.98, 2.97, -1.28, 1.91, 1.32, 0.03, -1.99, 0.3, 3.61, 3.6, -0.67, 2.53, 1.94, 0.64, -1.59, -1.72, 0.19, -0.55, -6.78, -0.18, -0.01, 0.24, -0.23, -0.1, -3.25, -2.36, 6.18, 2.16, 1.1, -4.03, -1.4, -2.94, 3.07, 3.14, -1.07, 0.36, -2.14, -1.37, 0.68, -0.93, 6.33, 0.6, 0.9, -6.38, -3.19, -0.01, -4.13, -1.04, -1.62, -2.87, -3.31, -3.18, -4.1164625850340135, -1.03, -1.61, -2.85, 0.98, 3.22, 2.62, 1.32, -1.79, -2.03, -2.17, -0.58, -1.84, -1.03, -0.97, -1.28, 3.23, 0.5, -3.19, -1.4, -2.15, -1.6, -1.27, -1.03, -0.2, -1.51, -0.9897755102040815, -0.64, -0.34, -1.28, -1.68, 0.35], ['252', 5.65, 0.68, 0.26122171562045876, -0.15, 2.2929790809910595, 2.69, 1.7841152579598292, 2.9117205965359587, 2.09, 2.0, -2.82, 0.65, 0.04, -1.12, -1.77, 0.54, -1.52, 0.94, 2.6, -1.66, 2.947335482087359, -0.79, -1.45, -0.6, 0.23, 1.079371414588892, 4.96, 3.56, 2.94, 1.75, 1.08, 3.46, 1.33, 3.87, 5.57, 1.18, 5.89, 2.08, 1.41, 2.28, 1.96, 3.3549361992161733, 1.35, -0.6, -1.5921246055531768, -2.4, -0.1, -2.16, 0.29, 1.94, -2.3, 2.25, -1.43, -2.08, -1.24, -0.83, 0.46, -1.14, 1.47, 1.96, -1.16, -1.81, 0.5, -1.56, 0.9, 2.56, -1.7097619047619048, 2.87, -0.84, -1.49, -0.64, 4.3, 3.16, -0.65, 1.68, -0.41, 2.09, 3.76, -0.55, 4.08, 0.33, -0.33, 0.53, 3.26, 9.54, -9.47, 3.84, 2.35, 0.25, 2.76, 4.45, 0.1, 4.76, 0.99, 0.32, 1.19, 3.18, 1.527366531216563, -2.05, 0.4, 2.05, -2.2, 2.36, -1.33, -1.98, -1.13, 1.08, 1.48, 5.43, 2.76, 2.79, 2.78, 3.58, 2.5, 4.19, -0.15, 4.5, 0.74, 0.07, 0.94, 2.88, 1.05, 1.64, -2.58, 1.95, -1.5942004503433074, -2.37, -1.53, 3.6418280382942037, 3.59, 0.0, 3.26, 9.477952380952381, 0.32225133596562167, 0.09, -5.66, 5.67, 2.8688101710076213, 1.8, 4.3, -7.34, -5.59, -2.77, 2.88, 1.82, 8.460596861471862, -8.34, -8.28, 2.79, -8.56, 5.54, 5.0, -2.49, 10.64, -10.42, -7.14, -10.58, 7.36, -0.58, -4.16, 0.3, -3.31, -3.95, -3.12, 8.37, 3.73, 4.65, 0.89, 0.22, 1.09, -0.88, -3.6, -4.24, -3.41, 3.33, 3.55, 2.82, -0.66, 0.27224875531501636, 2.8, 2.874396301275291, 3.74, -5.39, 4.9, 5.41, 3.66, 3.85, 3.5, 0.86, 3.22, 2.82, 1.82, 1.91, 1.96, 2.61, 4.87, 4.73, 2.56], ['253', -0.16, 0.15, 0.05122171562045875, -0.24, 0.28, 0.91, 0.82, 1.65, 0.8, 2.54, 1.83, 1.92, 1.76, 1.08, -0.33, 2.92, 1.91, 2.78, 3.06, 1.33, 2.387335482087359, 2.0, 1.52, 1.59, -0.2, 0.6, 0.7, 0.09, -0.07, -0.74, -2.12, 1.07, 0.08, 0.93, 1.21, -0.49, 0.51, 0.17, -0.31, -0.23, 1.73, 1.68, 0.61, -0.15, -0.82, -2.21, 0.97, -0.01, 0.84, 1.12, -0.58, 0.448065468086443, 0.08, -0.4, -0.32, 1.4, -0.08, 1.43, 1.03, 0.76, -0.67, -2.06, 1.13, 0.15, 1.0, 1.28, -0.43, 0.58, 0.24, -0.24, -0.17, 0.8, 1.44, -1.4, 1.81, 0.83, 1.68, 1.96, 0.24, 1.26, 0.91, 0.43, 0.51, 0.94, 3.3, -3.29, 2.88, 3.26, 2.26, 3.13, 3.41, 1.67, 2.7, 2.35, 1.86, 1.93, -1.51, -0.2826334687834371, -0.97, -0.13, 0.14, -1.54, -0.55, -0.88, -1.36, -1.29, -0.13, -0.34, 2.46, 0.92, 0.82, 1.17, 0.61, 0.85, 1.13, -0.58, 0.43, 0.09, -0.39, -0.26141531611693436, 0.36, -0.24, 0.5236855802927234, -1.41, -0.42, -0.76, -1.23, -1.16, 0.97, 1.279561224489796, -0.41, 2.34, -4.36, -0.4, 0.07, -2.71, 2.63, 1.37, -0.2, 0.61, -2.2, -1.82, -0.89, -0.13, 0.07, 2.76, -2.77, -2.79, 0.93, -4.22, 1.82, 1.09, -0.8, 1.84, -8.55, -1.25, -1.9, 2.3, -0.51, -1.68, -0.69, -1.03, -1.5, -1.43, 2.76, 1.2, 1.01, 0.67, 0.19, 0.26, 0.18, -0.34, -0.82, -0.74, 0.78, 0.89, 0.52, -0.48, -0.4, 0.91, 1.0, 1.45, -5.81, 2.72, 5.46, 1.75, 0.29, 1.01, 0.07, 1.59, 1.56, 0.01, -0.79, 0.64, 0.93, 3.26, 0.28, 1.41], ['254', -1.08, 0.0, 0.13122171562045873, -0.11, -0.04, 0.9484196236737595, 2.82, 0.25, 0.8, -0.95, -1.66, -2.95, -0.9, -0.04, -1.01, 0.3, -2.31, -0.95, -0.5341378641200069, -1.37, -0.9, -2.01, -1.5, -1.97, -0.24, 0.54, 0.72, -1.31, 0.7714285714285715, 1.64, 0.66, 1.99, -0.66, 0.72, 0.96, 0.29, 0.77, -0.35, 0.16, -0.32, 0.81, 0.8649361992161734, 2.06, 2.11, 3.167875394446823, 2.0, 3.35, 0.66, 2.06, 2.31, 1.62, 2.11, 0.97, 1.5, 1.01, -0.19, 1.05, 0.15, 0.37, -0.05, 0.87, -0.1, 1.21, -1.42, -0.05, 0.3086780045351474, -0.48, 0.0, -1.11, -0.5972652545866831, -1.08, 0.64, -0.91, -0.96, 0.34, -2.27, -0.91, -0.67, -1.33, -0.86, -1.97, -1.46, -1.93, 0.79, 2.12, -2.18, 0.06, 1.31, -1.32, 0.06, 0.3, -0.37, 0.1, -1.01, -0.5, -0.97, -2.73, -1.24, -2.6, -1.24, -1.0, -1.67, -1.2, -2.3, -1.79, -2.26, 0.02, -1.25, 0.39, 0.8115981806829015, 0.74, 0.8656735186500321, 1.39, 1.39, 1.64, 0.96, 1.6157782534925393, 0.31, 0.83, 0.35, 0.97, 0.0, 0.24, -0.43, 0.05, -1.07, -0.55, -1.03, 0.98, 1.14, -0.12, 0.93, -8.11, 0.2, 0.03, -1.71, 1.74, 0.89, 1.25, 0.78, -0.77, -1.52, -0.76, -0.52, 0.51, 2.23, -2.42, -2.28, 0.77, -2.57, 1.56, -0.56, 0.26, 4.13, -0.68, -2.66, -4.09, 0.86, -0.24, -0.67, -0.2, -1.31, -0.79, -1.27, 2.3, 0.43, 0.48, -0.64, -0.12, -0.6, -0.05, -1.11, -0.6, -1.08, 0.77, 0.5, 1.08, 0.52, 0.04, 0.76, 0.81, 0.06257604962387836, -0.59, 0.7, 0.72, 0.42, 0.69, 0.56, -0.48, 1.18, 0.85, 0.34, 0.66, 0.66, 1.04, 0.42, 0.9, 0.73], ['255', -1.19, -0.12, 0.06, 0.26, 0.17, 0.63, -0.1, 1.07, 0.92, 0.61, 0.41, -1.07, -0.6160867348791511, -0.74, 0.08, 1.41, -0.4, 0.2, -0.29, 0.22, 0.88, -0.84, -0.09, -0.44, 2.45, 1.26, 0.19, -1.48, -1.09, -1.15, -0.33, 0.99, -0.81, -0.21, -0.7, -0.19, 0.46, -1.24, -0.5, -0.85, 1.17, 0.8749361992161734, 1.69, 0.3936589811608609, 0.49787539444682316, 1.16, 2.5, 0.67, 1.28, 0.79, 1.3, 1.97, 0.23, 0.99, 0.9508287981859411, 0.4, 1.46, -0.11, 0.75, 1.29, -0.06, 0.77, 2.1, 0.28, 0.89, 0.4, 0.91, 1.57, -0.16, 0.6, 0.25, -0.2, 1.35, 0.83, 2.16, 0.34, 0.95, 0.45, 0.97, 1.63, -0.1, 0.65, 0.3, 0.37, 2.35, -2.36, 0.52, 1.32, -0.49, 0.12, -0.37, 0.14, 0.8, -0.92, -0.17, -0.4659922724755494, -0.88, -0.79, -1.78, -1.19, -1.67, -1.17, -0.52, -2.21, -1.47, -1.82, 0.58, -0.81, 2.84, 0.73, 0.8, 0.7, 1.0109570400359875, 0.61, 0.12, 0.63, 1.29, -0.43, 0.32, 0.028584683883065676, 1.73, 0.4, -0.49, 0.02, 0.68, -1.04, -0.29, -0.64, 0.58, 0.71, 0.49, 1.19, -2.65, 0.88, 1.06, -1.27, 1.29, 0.64, 3.67, 1.3561635321120495, -0.7, -1.43, -0.74, -0.6, 0.81, 2.13, -2.2, -2.16, 0.72, -1.89, 1.43, -1.94, 1.0, 2.96, -4.49, -1.97, -2.98, 0.6738095238095239, 0.89, 0.51, 1.17, -0.55, 0.2, -0.15, 2.16, 0.38, 0.66, -1.06, -0.31, -0.66, -0.27, -1.6111214088935784, -0.96, -1.3, 0.87, 0.45, 1.45, 0.75, 0.4, 0.72, 0.79, 1.24, -2.97, 2.49111637918067, 2.9, 0.83, 0.71, 0.69, -0.27721314850306833, 0.84, 0.62, 0.59, 0.88, 0.77, 1.04, 0.73, 0.79, 1.06], ['256', -7.27, -1.02, -0.37, 0.21, -1.48, -1.52, -1.91, -3.6, -3.27, -4.18, 0.45, -3.2, -1.27, -0.59, -0.28, -2.25, -2.18, -3.35, -4.17, -2.46, -4.67, -3.09, -1.72, -2.63, -3.61, -2.76, -4.61, -3.63, -1.71, -1.04, -0.73, -2.69, -2.62, -3.78, -4.61, -2.9, -5.1, -3.53, -2.16, -3.07, -3.5, -4.755063800783826, -1.01, 1.99, 2.69, 3.01, 0.98, 1.05, -0.15, -1.01, 0.76, -1.491934531913557, 0.11, 1.53, 0.59, -2.03, -3.57, -2.68, -3.36, -2.95, 0.69, 1.0, -0.99, -0.92, -2.11, -2.95, -1.21, -3.45, -1.85, -0.46, -1.38, -3.32, -3.61, 0.31, -1.67, -1.6, -2.77, -3.61, -1.88, -4.11, -2.52, -1.14, -2.05, -4.56, -6.54, 6.47, -3.9, -1.97, -1.9, -3.07, -3.9, -1.996255228898086, -4.4, -2.82, -1.44, -2.35, -2.85, -1.97, 0.07, -1.0246649659863944, -1.97, -0.22, -2.48, -0.87, 0.54, -0.39, -1.11, -2.04, -2.78, -1.56, -1.72, -1.49, -2.04, -1.19, -2.04, -0.29, -2.55, -0.94, 0.47, -0.46, -1.2, -0.8069232518696328, -0.86, 0.92, -1.37, 0.26, 1.68, 0.74, -2.54, -2.5, -0.21, -1.88, -8.44, -0.98, -0.63, 2.16, -2.24, -1.12, -1.07, -5.74, 3.35, 3.03, 1.53, -3.64, -0.8, -4.78, 4.65, 4.67, -1.56, 3.32, -3.12, -2.53, 1.25, -6.04, 5.28, 4.1, 6.07, -3.2, 0.0, 1.79, -0.52, 1.13, 2.56, 1.61, -4.67, -1.76, -2.27, -0.65, 0.76, -0.17, 0.52, 1.65, 3.1, 2.14, -3.17, -3.81, -1.12, 1.42, 0.48, -1.4379199656859432, -1.62, -3.63, 6.82, -2.82, -6.95, -2.02, -1.92, -2.5, -0.93, -2.24, -0.9954471401614257, -0.78, -0.51, -1.42, -1.59, -2.66, -2.21, -1.32], ['257', -5.73, -0.83, -0.45, 0.1, -1.32, -1.69, -1.2458847420401709, -2.91, -2.54, -2.4, 0.27, -0.36, 0.55, 1.45, -0.22, -1.9, 0.33, -1.39, -3.76, -0.94, -3.5, -0.19, -0.09, -0.86, -3.15, -2.61, -2.66, -0.63, 0.28, 1.18, -0.48, -2.16, 0.07, -1.5327410958555914, -4.01, -1.2, -3.75, -0.46, -0.35, -1.12, -1.51, -3.8350638007838267, -2.05, 0.91, 1.82, 0.15, -1.54, 0.7, -1.03, -3.41, -0.57, -3.14, 0.17, 0.28, -0.5, -1.0, -2.7557142857142853, -3.76, -2.4, -2.93, 0.9, -0.76, -2.43, -0.21, -1.93, -3.990306689342404, -1.47, -4.02, -0.73, -0.63, -1.4, -3.9, -3.8, -1.65, -2.8633418367346937, -1.1, -2.8, -5.13, -2.35, -4.88, -1.62, -1.52, -2.28, -3.31, -6.68, 6.73, -2.19, -1.68, 0.55, -1.17, -3.55, -0.72, -3.28, 0.03, 0.13, -0.5859922724755494, -2.19, -0.51, 2.28, 0.52, -1.89, 0.98, -1.63, 1.74, 1.84, 1.06, -1.25, -0.53, -3.5198953488372093, -1.78, -1.83, -1.79, -2.73, -1.72, -4.08, -1.27, -3.82, -0.52, -0.42, -1.19, -2.13, -1.03, -2.4, 0.46, -2.14, 1.21, 1.32, 0.54, -2.89, -3.06, -0.54, -2.41, -4.28, -1.3, -1.1, 3.72, -3.59, -1.82, -1.84, -1.53, 2.93, 3.54, 1.8645476190476191, -2.89, -1.28, -5.52, 5.42, 5.34, -1.75, 5.49, -3.52, -1.78, 0.87, -8.16, 5.32, 5.52, 8.18, -3.0, 1.41, 2.93, 0.27, 3.7, 4.129638579674294, 3.01, -5.39, -1.48, -2.59, 0.75, 0.85, 0.08, 1.13, 3.42, 3.53, 2.8014285714285716, -2.57, -2.75, -2.21, 0.1, -0.67, -1.8, -1.94, -2.82, 2.69, -2.89, -2.68, -2.13, -2.56, -2.32, -0.77, -2.07, -2.02, -0.87, -1.39, -1.05, -1.56, -4.3, -3.9, -2.05], ['258', 1.72, 0.12, 0.73, 0.4, 0.21, 1.69, -0.18, 0.39, 1.69, -0.98, -3.69, -0.62, -1.3, -2.3, -1.0, 0.06856009070294794, -1.85, -0.92, -0.1, -2.12, -0.8426645179126411, -1.66, -1.05, -2.67, 0.84, 0.28, 2.8526583949931124, 3.18, 2.48, 1.44, 2.79, 3.5733503401360545, 1.91, 2.87, 3.72, 1.63, 2.9844536700785693, 2.11, 2.74, 1.06, 1.07, 3.2349361992161736, -0.35, -0.68, -1.68, -0.38, 0.46052947845804987, -1.23, -0.3, 0.52, -1.51, -0.23193453191355703, -1.04, -0.43, -2.06, 0.42, 1.66, -0.98, 2.4, 0.33, -1.01, 0.3, 1.27, -0.56, 0.38, 1.21, -0.83, 0.42, -0.36, 0.25, -1.39, -1.42, 1.35, 1.33, 2.1, 0.46, 1.41, 2.25, 0.18, 1.45, 0.66, 1.28, -0.38, 3.42, 0.21, -0.27, 0.03, 0.76, -0.85, 0.08, 0.91, -1.13, 0.12, -0.66, -0.05, -1.69, -1.04, -0.73, -1.6, -0.67, 0.15, -1.88, -0.63, -1.41, -0.8, -2.43, -0.21, -0.81, 0.95, 1.27, 0.93, 1.59, 0.89, 0.94, 1.8869325674325674, -0.28, 1.1557782534925394, 0.19, 0.81, -0.84, 0.53, -0.05, 0.83, -1.21, 0.04, -0.74, -0.13, -1.76, -0.78, -1.71, 0.77, 0.79, -2.44, 1.44, 0.73, -2.78, 2.67, 1.34, 0.51, 1.11, -2.3222410208838777, -2.61, -1.3, 0.82, 0.92, 3.67, -3.78, -3.77, 1.24, -4.32, 2.46, -3.33, 1.8, 2.46, -4.47, -1.82, -2.84, 2.45, -0.87, -2.0151904761904764, -0.78, -1.56, -0.95, -2.57, 3.7, 1.17, 1.27, 0.47, 1.09, -0.56, -0.09, -0.78, -0.17, -1.8, 1.85, 2.32, 0.69, 0.62, -1.03, 1.29, 1.2, 0.26, -2.25, 1.85, 2.27, 1.2, 1.49, 0.08, -1.5672131485030683, 2.27, 1.06, 1.48, 0.18, 1.444626243824729, 1.74, 1.48, 1.22, 0.7], ['259', -0.46, 0.26, 0.16, 0.06, 0.48, 0.61, 0.6941152579598292, 1.23, 0.29, 0.11, -0.13, -0.54, -1.35, -0.69, -1.08, 0.58, 0.09, 0.06, -1.97, -1.29, 0.15, -0.64, -0.38, -0.17, 0.11, 0.43, 0.27265839499311245, -0.41, -1.23, -0.56, -0.95, 0.72, 0.22, 0.30725890414440843, -1.84, -1.16, 0.28, -0.51, -0.25, -0.04, 1.47, -1.25, 0.66, -0.82, -0.15, -0.55, 1.13, 0.63, 0.61, -1.44, -0.75, 0.69, -0.1, 0.16, 0.37, 1.23, 1.06, 1.03, 0.17, 1.49, 0.68, 0.28, 1.96, 1.47, 1.44, -0.62, 0.07, 1.52, 0.72, 0.99, 1.2, 1.39, 0.8, -0.3853571428571429, 1.28, 0.78, 0.76, -1.29, -0.61, 0.84, 0.04, 0.31, 0.52, -0.14, 1.5, -1.5, 1.2466982383853202, 1.68, 1.19, 1.16, -0.89, -0.21, 1.24, 0.44, 0.71, 0.92, -1.22, -0.47, -0.49, -0.52, -2.54, -1.86, -0.43, -1.22, -0.96, -0.75, 0.12, -0.45, -0.33, 0.58, 0.58517906963434, 0.59, 0.02, -0.03, -2.06, -1.3794642857142856, 0.06, -0.74, -0.47, -0.20141531611693433, 0.69, 0.05, -2.03, -1.35, 0.08, -0.71, -0.45, -0.24, 0.3, 0.11, 0.02, 0.33, -3.64, 0.05, 0.04, -0.87, 0.9, 0.48, 0.72, -0.33, -2.8, -1.16, -0.61, -0.22, 0.68, 1.79, -1.85, -1.79, 0.58, -1.46, 1.16, -0.27, 0.14, 0.12, -3.6, -0.09, -0.1, 2.84, 2.12, 0.69, 2.166609977324263, 1.35, 1.62, 1.83, 1.913167899560757, 1.42, 1.45, 0.65, 0.92, 1.13, -0.04, -0.79, -0.53, -0.32, 0.29, 0.19, 0.76, 0.26, 0.48, 0.59, 0.57, 1.07, -1.98, 0.0, 2.15, 0.41, 0.8, 0.5, 0.21, 0.41, 0.58, 0.76, 0.68, 1.05, 0.29, -0.35, 0.85, -0.33], ['260', -3.6, -0.96, 0.04, 0.04, -1.18, -0.75, -0.63, -1.7382794034640414, -0.99, -2.15, -0.63, -2.0, -0.9860867348791511, -0.04, -0.4, -0.86, -1.06, -1.67, -2.43, -0.36, -2.21, -1.29, -1.87, -1.17, -0.56, -1.29, -1.4973416050068875, -1.38, -0.42, 0.6, 0.24, -0.22, -0.43, -1.04, -1.81, 0.27, -1.58, -0.66, -1.25, -0.54, -1.2525315746467893, -0.74, -0.15, 0.97, 2.0, 1.64, 1.17, 0.96, 0.34, -0.438347866419295, 1.67, -0.20034527076293904, 0.73, 0.14, 0.85, -1.08, -0.4, -0.36, -1.74, -1.11, 1.02, 0.66, 0.2, -0.01, -0.62, -1.39, 0.7, -1.17, -0.24, -0.83, -0.12, -1.14, -2.11, -0.36, -0.81, -1.02, -1.63, -2.39, -0.32, -2.17, -1.25, -1.83, -1.13, -1.4, -1.02, 1.03, -1.759129077338006, -0.46, -0.67, -1.27, -2.04, 0.03, -1.82, -0.9, -1.48, -0.77, -2.02, -1.31, -0.21, -0.82, -1.59, 0.5, -1.36, -0.44, -1.02, -0.31, -0.37, -1.4, 0.13, -0.82, -0.81, -0.9, -1.1, -0.61, -1.38, 0.9097126881055455, -0.9842217465074605, -0.23, -0.82, -0.051415316116934326, -0.85, -0.49, -0.78, 1.33, -0.55, 0.38, -0.21, 0.51, 0.4418280382942037, 0.35, -0.21, -1.04, -6.03, -0.01, -0.01, 1.54, -1.51, -0.74, -0.09, -3.42, 3.42, 1.73, 0.79, -1.77, -0.686920210131221, -2.57, 2.56, 2.38, -0.83, 2.39, -1.65, 0.15, -0.025234735715753215, -3.22, 16.43, 2.14, 3.26, -3.49, 0.29, 2.12, 0.23, 1.17, 0.58, 1.3, -2.51, -1.79, -1.85, -0.93, -1.51, -0.81, 0.06, 0.94, 0.34, 1.06, -0.98, -1.27, -0.87, -0.59, 0.12, -0.84, -0.8856036987247091, -1.71, 7.56, -0.51, -7.100719387755102, -1.82, -1.68, -0.28, 0.72, -1.54, -0.62, -0.35, -1.03, -0.56, -0.99, -2.3, -2.67, -1.41], ['261', -0.15, 0.18, 0.15122171562045875, -0.08, 0.06297908099105959, 0.47, -1.1458847420401708, 0.46, 0.58, 1.09, 0.2, 1.54, 1.1, 0.65, 0.6, 1.15, 0.59, 0.69, 2.03, 0.48, 1.497335482087359, 0.46, 0.24, 0.69, 0.25, 0.57, 0.88, 1.3305454545454547, 0.89, 0.45, 0.4578199712950912, 0.95, 0.38, 0.48, 1.82, 0.28, 1.25, 0.25, 0.03, 0.48, 0.25, 1.5, -0.44, -0.43, -0.87, -0.92, -0.38, -0.93, -0.83, 0.48, -1.04, -0.08, -1.06, -1.28, -0.84, 0.48, 0.43, 0.44, 0.93, -0.01, -0.44, -0.3751532320595474, 0.06, -0.5, -0.4, 0.92, -0.6, 0.36, -0.63, -0.85, -0.4, 0.24, 0.43, -0.05, 0.5, -0.07, 0.04, 1.36, -0.17, 0.8, -0.19, -0.42, 0.08355964172512072, 1.49, 2.18, -2.1, 0.48, 0.55, -0.02, 0.08, 1.41, -0.12, 0.85, -0.15, -0.37, 0.08, 0.55, -0.07, -0.56, -0.46, 0.86, -0.66, 0.3, -0.69, -0.91, -0.46, 0.25, -0.14, 4.1, 0.26, 0.56517906963434, 0.04567351865003196, 0.5, 0.1, 1.43, 0.09971268810554554, 0.86, -0.06969498055271243, -0.35, 0.1, 0.51, 0.39, 1.5836855802927234, -0.2, 0.76, -0.23, -0.45, 0.0, 0.74, 0.56, -0.18, 0.38, 1.56, 0.09, 0.06, 0.44, -0.47, -0.24, 0.53, 0.16, -1.19, -0.52, -0.27, -0.07, 0.19, 0.74, -0.72, -0.77, 0.30329080486385296, 0.7, 0.5, 0.62, -0.32, 1.44, -2.37, -1.02, -1.31, 1.16, -0.92, -1.51, -0.56, -1.54, -1.76, -1.31, 0.7508051948051948, 0.6, 0.97, -0.03, -0.25, 0.2, -0.36, -0.98, -1.2, -0.76, 0.61, 1.12, 0.62, -0.22, 0.23, 0.27, 0.26, 0.34, -0.91, 3.06, 0.88, 0.15, 0.36, 0.85, 0.45, 0.49, -0.07, -0.01, 0.34, 0.15462624382472906, 0.4, 0.7, -0.47, 0.0], ['262', -0.8, -0.03, -0.05, -0.01, -0.45, -0.42, -0.44, -0.1, 0.3, 0.0, -0.66, 0.5593248299319729, 0.29, 0.28, 0.28, 0.17, 0.13, 0.01, -1.24, 0.06, 0.17, -0.42, -0.13, 0.34, -0.46, -0.1, 0.66, 1.21, 0.9708333333333333, 0.94, 0.95, 0.84, 0.79, 0.67, -0.59, 0.72, 0.83, 0.24, 0.53, 1.01, -0.16, 1.04, -0.55, -0.2563410188391391, -0.27, -0.26, -0.37, -0.42, -0.53, -1.78, -0.49, -0.37, -0.96, -0.67, -0.20495238095238094, 0.54, -0.07, 0.04, 0.06, -0.29, -0.01, 0.0, -0.11, -0.16, -0.27, -1.52, -0.23, -0.11, -0.7, -0.41, 0.05, -0.67, -0.27, 0.01, -0.1, -0.14, -0.26, -1.51, -0.22, -0.1, -0.69, -0.4, 0.07, 0.82, 0.33174294752866196, -0.17, -0.28, -0.11, -0.15, -0.27, -1.52, -0.23, -0.11, -0.7, -0.41, 0.06, -0.98, -0.17, -0.04, -0.16, -1.41, -0.12, 0.06262653735269351, -0.59, -0.3, 0.17, 0.1, -0.17, 0.41, -0.14, 0.0, -0.21, -0.13, -0.12, -1.37, -0.07, 0.04, -0.55, -0.26, 0.26858468388306567, 0.5, -0.01, -1.25, 0.05, 0.16, -0.43, -0.14, 0.33, 0.13, 0.14, 0.02, 0.22, -2.79, 0.05, -0.01, 0.36, -0.4, -0.19, 0.66, 0.07, 0.17, 0.35, 0.2, -0.39, 0.02, -0.45, 0.53, 0.49, -0.15, 0.57, -0.39, 0.05, -0.02, -0.39, 1.3, 0.11, 0.34, -0.14, 1.25, 1.31, 1.43, 0.83, 1.12, 1.6, -0.56, -0.06, 0.11, -0.48, -0.19, 0.28, -0.17, -0.59, -0.3, 0.17, 0.18, 0.5, 0.42, 0.29, 0.76, -0.16, -0.14, -0.19, 0.68, 0.0, -0.77, -0.87, -0.2, 0.13, 0.47, -0.26, -0.26, -0.21, 0.17, 0.2, -0.34, -1.08, 0.14, -0.64], ['263', -0.06, 0.04, 0.00015289830927053559, -0.09, 0.0, 0.22, 0.57, -0.38, -0.1, -0.84, -0.79, -1.32, -0.4, 1.14, -0.54, -0.47, -1.49, -1.01, -2.51, 0.06, -1.02, -1.0, -1.2, -1.42, 0.02, -0.05, -0.017341605006887542, -0.53, 0.39, 2.09318993704708, 0.25, 0.32, -0.71, -0.22, -1.73, 0.85, -0.23, -0.21, -0.41, -0.63, 0.2, -0.09, 0.49, 0.93, 2.5, 0.79, 0.86, -0.17, 0.31, -1.2, 1.4, 0.31, 0.32, 0.12, -0.1, -0.27, 0.69, 0.16, -0.12, -0.43, 1.6531047225355606, -0.14, -0.07, -1.09, -0.61, -2.11, 0.46, -0.62, -0.6, -0.8, -1.02, 0.76, -1.96, -1.67, -1.6, -2.6, -2.13, -3.61, -1.07, -2.14, -2.12, -2.31, -2.53, -0.46, 1.02, -0.96, -0.3, 0.07, -0.96, -0.47, -1.98, 0.6, -0.48, -0.46, -0.66, -0.88, -0.55, -0.36, -1.02, -0.54, -2.04, 0.53, -0.55, -0.53, -0.73, -0.95, 0.11, -0.31, 0.84, 0.28, 0.3, 0.24, 0.66, 0.4913469387755102, -1.03, 1.57, 0.48, 0.5, 0.3, 0.07, 0.2, 0.18, -1.51, 1.08, -0.01, 0.01, -0.19, -0.41, 0.89, 0.97, -0.25, 0.23, -1.4, 0.19, 0.06, -0.5, 0.48, 0.26, 0.6, -0.94, 1.57, -0.5, -0.24, -0.05, 0.25, 0.7914761904761906, -0.86, -0.84, 0.29, -0.71, 0.56, 1.0, -0.49, 1.96, -2.68, -1.18, -2.0, -1.66, 1.71, 2.63, 1.53, 1.55, 1.35, 1.12, 0.84, -0.89, -1.08, -1.06, -1.25, -1.48, 0.18, 0.02, -0.18, -0.41, -0.07, -0.22, 0.16, -0.2, -0.42, 0.3620800343140569, 0.33, -0.32, -1.81, 0.86, 1.81, 0.51, -0.44, 0.36, -0.23, 0.22, 0.42, 0.06, 0.01, 0.65, 0.675957527023814, -0.46, -0.52, 0.62], ['264', -3.75, -0.57, -0.22877828437954126, -0.34, -0.34, -0.03, -2.21, -1.33, -1.58, -2.004642857142857, -0.939391156462585, -0.15, -2.23, 0.58, -0.40285714285714286, -0.64, -2.02, -1.53, -1.47, -1.47, -2.54, -1.5, -1.635694768399324, -2.2, -1.64, -0.93, -1.0973416050068874, 0.81, -1.29, 1.55, 0.54, 0.31, -1.08, -0.59, -0.53, -0.53, -1.61, -0.56, -0.79, -1.27, -0.6, -1.9, -1.92, -2.08, 0.73, -0.27, -0.49, -1.87, -1.38, -1.2228644435138796, -1.33, -2.39, -1.36, -1.58, -2.06, -0.74, -2.03, -0.29, -1.31, 0.16, 2.88, 1.85, 1.62, 0.21, 0.72, 0.770952380952381, 0.77, -0.32, 0.74, 0.51, 0.02, -0.58, -2.64, -0.99, -1.22, -2.59, -2.1, -2.04, -2.05, -3.1, -2.08, -2.3, -2.77, -1.71, -1.01, 0.98, -1.66, -0.23, -1.61, -1.12, -1.06, -1.06, -2.13, -1.09, -1.31, -1.8, -2.23, -1.43, -1.38, -0.89, -0.83, -0.84, -1.91, -0.87, -1.09, -1.57, -0.58, -1.38, -0.04, -0.16, -0.27, 0.055673518650031964, -0.05, 0.5, 0.56, 0.55, -0.53, 0.52, 0.3, -0.19, -0.5, -0.55, 0.06, 0.05, -1.03, 0.02, -0.2, -0.69, -0.38, -0.36, -0.6, 0.08, -6.66, -0.52, -0.47, -0.13, 0.16246232339089484, 0.11881017100762112, -1.5, -1.85, 1.16, 0.37, 0.19, -1.87, -0.036920210131220946, -0.48, 0.58, 0.52, -0.16, -0.19, -0.34, 2.13, -1.02, -0.14, 0.38, 0.11, 0.18, -1.19, -0.6, 0.0, -1.08, -0.03, -0.26, -0.74, -0.55, -0.6, -1.08, -0.03, -0.25, -0.74, 0.48, 1.06, 0.83, 0.34, -1.57, -1.55, -0.57, -0.22, -0.71, -0.18, -0.15, -1.2874239503761218, 0.27, 0.42, -0.26, -0.35, -0.4989064979199875, -0.35, -0.49, 0.3, 0.19, -0.83, 0.55, -0.445373756175271, 0.14, -1.09, -0.57, 0.69], ['265', 4.4, -1.33, -0.08, 0.23, 0.78, -1.25, -3.27, -1.87, -2.29, -0.86, 1.95, 0.47, -0.43, 1.74, 1.46, -1.64, 0.63, -0.66, -2.73, 0.51, -1.08, 0.6, 1.29, 0.58, -2.13, -1.38, -2.76, -1.45, -2.33, -0.2, -0.48, -3.52, -1.29, -2.56, -4.59, -1.41, -2.895546329921431, -1.33, -0.64, -1.34, -1.56, -4.855063800783826, -1.33, -0.9, 1.27, 0.99, -2.1, 0.16, -1.12, -3.19, 0.04071428571428572, -1.511934531913557, 0.12, 0.82, 0.11, -0.89, -1.69, -2.05, -1.69, -0.43, 2.18, 1.9, -1.21, 1.06, -0.23, -2.31, 0.94, -0.65, 1.03, 1.73, 1.01, -3.28, -2.56, -0.28, -3.32, -1.09, -1.9206972789115644, -4.4, -1.21, -2.78, -1.13, -0.44, -1.15, -3.33, -5.71, 5.69, -2.29, -3.05, -0.82, -2.09, -4.13, -0.94, -2.5, -0.85, -0.17, -0.87, 1.52, 0.79, 2.31, 1.0, -1.11, 2.18, 0.57, 2.27, 3.121108978323264, 2.25, -0.27, 0.78, -1.05, -1.6, -1.66, -1.55, -1.48, -1.28, -3.34, -0.12, -1.7, -0.03, 0.66, 0.008584683883065672, -0.66, -0.2, -2.09, 1.17, -0.42, 1.26, 1.96, 1.24, -2.36, -1.81, 0.2, -1.89, 4.69, 0.03, -0.14, 3.75, -3.71, -1.86, -0.37, -1.57, 2.96, 3.19, 1.61, 2.18, -0.74, -4.9, 4.99, 4.81, -1.6, 5.51, -3.2, -2.7, 1.32, -4.4, 7.27, 2.88, 4.38, -2.85, 1.92, 3.33, 1.7, 3.42, 4.14, 3.4, -4.78, -1.36, -1.58, 0.09, 0.78, 0.07, 0.22, 1.69, 2.4, 1.68, -2.21, -2.72, -1.45, 0.69, -0.02, -2.17, -2.12, -1.79, 7.19, -1.36, -6.3186904761904765, -1.26, -2.57, -2.13, -0.71, -1.73, -1.9, -0.63, -0.32, -1.16, -1.43, -2.44, -2.91, -1.61], ['266', 3.93, 0.24, 0.13122171562045873, 0.04, 0.36, 0.03, 0.76, 0.1, -0.09, 1.68, 1.4, 1.07, 1.61, 1.53, 1.01, 1.39, 1.8, 1.78, -0.45, 1.8, 1.807335482087359, 1.54, 2.2843052316006762, 1.54, -0.07, 0.07, 0.3126583949931125, -0.33, 0.21, 0.13, -0.3321800287049088, -0.01, 0.39, 0.4872589041444084, -1.82, 0.4, 0.37, 0.14, 0.78, 0.14, -0.2, -0.98, 0.61, 0.54, 0.46, -0.06, 0.32, 0.72, 0.7, -1.5, 0.73, 0.7280654680864429, 0.47, 1.11, 0.47, -0.33, -0.88, -0.51, -0.54, 0.07, -0.08, -0.6, -0.22, 0.18, 0.16, -2.03, 0.19, 0.16, -0.07, 0.57, -0.07, -0.27, 0.15, -0.52, -0.14, 0.26, 0.24, -1.95, 0.26, 0.24, 0.01, 0.65, 0.0, -0.18, -0.99, 1.14, 0.7066982383853202, 0.38, 0.78, 0.76, -1.44, 0.79, 0.76, 0.53, 1.17, 0.53, 0.48, 0.29, 0.4, 0.38, -1.81, 0.4, 0.38, 0.15, 0.79, 0.14, -0.11, 0.25, -0.68, -0.2184018193170985, -0.08, -0.36, -0.11, -0.02, -2.2, 0.0, -0.02, -0.25, 0.38, -0.26, 0.02, -0.09, -2.18, 0.11224471370562701, 0.0, -0.23, 0.41, -0.23, 0.04, 0.28, -0.06, -0.01, 1.67, -0.1, -0.07, 1.44, -1.47, -0.6911898289923789, -0.34, 0.74, 0.18, 0.53, 0.27, 1.92, 0.12, -0.84, 0.72, 0.82, -0.27, 2.18, -0.55, 0.12, -0.07, -0.31, -1.3, 0.24, 0.33, -0.2, 2.14, 2.26, 2.23, 2.0, 2.65, 1.99, -0.7168321004392431, -0.12, -0.03, -0.25, 0.38, -0.26, -0.09, -0.23, 0.41, -0.23, -0.06, -0.28, 0.13, 0.63, 0.06224875531501633, -0.25, -0.23, 0.19, -0.57, -0.36, 0.65, -0.03, -0.33, -0.5, -0.64, 0.09, -1.0, 0.33, -0.01, 0.22, 0.14, -0.6, -0.16, -0.05], ['267', -2.43, -0.79, 0.15, 0.26, -0.7, -1.27, -1.1758847420401708, -1.75, -1.94, -1.62, 1.62, -0.68, -1.3, 0.19, -0.16, -0.77, -0.77, -1.32, 5.65, 0.07, -1.92, -0.99, 0.03, -1.3178253968253968, -0.7214063389924734, -0.99, -3.18, -2.26, -2.87, -1.41, -1.75, -2.35, -2.35, -2.89, 3.97, -1.52, -3.48, -2.57, -1.57, -2.89, -0.8125315746467892, -5.31, -0.95, -0.63, 0.87, 0.52, -0.09, -0.09, -0.65, 6.37, 0.75, -1.25, -0.32, 0.71, -0.65, -0.8499371536943234, -0.99, -1.07, -1.49, -0.32, 1.51, 1.15, 0.54, 0.54, -0.02, 7.040952380952381, 1.39, -0.63, 0.31, 1.34, -0.02, -2.6, -1.8, -0.35, -0.95, -0.96, -1.51, 5.45, -0.12, -2.1, -1.18, -0.16, -1.51, -3.79, -4.41, 4.422833333333334, -1.46, -0.61, -0.61, -1.16, 5.83, 0.23, -1.76, -0.83, 0.19, -1.16, 0.54, -0.86, 0.0, -0.56, 6.47, 0.84, -1.16, -0.23, 0.8, -0.56, -0.53, -0.84, 1.19, -1.29, -1.53, -1.04, -0.85, -0.55, 6.47, 0.85, -1.16, -0.22, 0.8, -0.56, -0.64, -0.3, 7.07, 1.41, -0.61, 0.33, 1.36, 0.0, -1.9, -1.68, 0.13, -1.21, 2.12, -0.01, 0.0, 1.74, -1.75, -0.88, -0.61, -1.98, 3.2, 2.58, 1.34, -1.21, -1.18, -3.92, 3.9, 4.0, -1.28, 2.61, -2.61, -1.9, 0.94, -2.62, 5.18, 1.74, 2.6, -3.2, -6.88, -5.29, -7.17, -6.29, -5.33, -6.6, -3.98, -1.69, -1.99, -1.06, -0.04, -1.39, 0.756501700680272, 0.94, 1.98, 0.61, -1.83, -2.46, -0.63, 1.03, -0.33, -1.29, -1.23, -1.72, 2.55, -0.04, -2.45, -1.92, -2.39, -1.64, -1.2772131485030684, -1.26, -1.1297802197802196, -1.02, -1.23, -1.35, -0.3, -2.74, -4.03, -1.3], ['268', 0.39, -0.19, 0.04, 0.19, -0.19702091900894042, -0.27, -0.41, -0.17, -0.48, 0.12, 0.32, 0.71, -0.12, -0.4, 0.39, -0.37, -0.06, 0.11, 5.8, 0.83, -0.41, -0.34, -0.56, 0.06, 0.45, -0.51, -0.2, 0.39, -0.44, -0.72, 0.07, -0.68, -0.38, -0.21, 5.46, 0.51, -0.72, -0.66, -0.88, -0.26, -0.32, -0.05506380078382657, -0.59, -0.82, -1.1, -0.31, -1.07, -0.76, -0.6, 5.06, 0.13, -1.11, -1.04, -1.26, -0.65, -0.71, 0.0, -0.07, -1.25, 0.24, -0.28, 0.51, -0.25, 0.06, 0.23, 5.93, 0.96, -0.29, -0.22, -0.44, 0.18, -1.11, 0.52, 0.79, 0.03, 0.34, 0.51, 6.22, 1.24, -0.01, 0.06, -0.16, 0.46, -0.46, 1.59, -1.58, -0.27, -0.76, -0.45, -0.28, 5.39, 0.44, -0.8, -0.73, -0.95, -0.33, -0.43738095238095237, 0.49, 0.31, 0.48, 6.19, 1.21, -0.04, 0.03, -0.19, 0.43, -0.07, 0.44, 3.82, -0.11, 0.08, -0.2, 0.18, 0.17, 5.86, 0.89, -0.35, -0.28, -0.5, 0.12, 0.63, 0.01, 5.69, 0.73, -0.51, -0.45, -0.67, -0.05, 0.07, -0.29, 0.09, 0.06, -0.87, 0.08, -0.27, -0.14, 0.19, 0.07, 0.09, -0.14, 1.33, 0.22, 0.1, 0.15, -0.31, -0.26, 0.27, 0.33, -0.1, -0.17, -0.22, -2.43, 1.19, 0.51, 2.46, -0.31, -0.55, -1.28, -5.37, -4.69, -5.87, -5.8, -6.01, -5.43, -0.38, -0.71, -1.23, -1.16, -1.38, -0.77, 0.53, 0.07, -0.15, 0.47, -0.54, -0.7815464535464534, 0.46, -0.22, 0.4, -0.1, -0.03, -0.14, 1.24, 1.8, -1.33, 0.96, -1.49, 0.68, 0.6927868514969316, 0.12, 0.12, -0.61, -0.47, -0.05537375617527095, 0.06, 0.32, -1.73, -0.34], ['269', -13.632857142857144, -0.43, -0.41877828437954123, -0.1, -1.96, -0.76, 0.21, -2.13, -0.77, -2.3, -1.21, -3.03, 0.08, -0.2, 0.87, 0.26071428571428573, 0.17, -1.4294285714285713, -0.89, 0.08, -2.52, -1.18, -0.88, -1.47, -1.93, -2.3, -1.1, -1.84, 1.3, 1.02, 2.11, 1.48, 1.4014285714285712, -0.22, 0.33, 1.31, -1.33, 0.03, 0.33, -0.26, -4.05, -0.5, 0.76, 3.2, 2.92, 4.02, 3.39, 3.3, 1.65, 2.21, 3.21, 0.53, 1.9, 2.22, 1.61, -1.68, -3.1657142857142855, -1.62, -1.49, -2.37, -0.27, 0.79, 0.43142857142857144, 0.09, -1.5, -0.96, 0.01, -2.59, -1.26, -0.96, -1.54, -2.66, -2.1, 1.07, 0.45, 0.37, -1.23, -0.69, 0.28, -2.33, -0.99, -0.69, -1.27, -0.73, -4.21, 4.14, -3.14, -0.61, -0.69, -2.28, -1.74, -0.78, -3.36, -2.04, -1.74, -2.32, -3.29, -2.55, 0.5385714285714286, -1.68, -1.14, -0.17, -2.77, -1.44, -1.14, -1.72, -0.82, -2.54, -2.46, -1.19, -1.3, -1.34, -2.46, -1.6, -1.06, -0.09, -2.68, -1.35, -1.05, -1.64, -1.09, -0.88, 0.55, 1.53, -1.11, 0.25, 0.6328571428571429, -0.04, -1.64, -2.43, -0.24396282112195955, -2.45, -6.49, -0.33967687074829933, -0.22428571428571428, 1.49, -1.43, -0.74, -0.63, -3.76, 4.55, 2.49, 1.19, -6.488561224489796, -0.38, -3.95, 3.97, 3.58, -1.23, 2.18, -2.41, 0.29, -0.08, -7.29, 6.623125850340137, 4.87, 7.23, -4.75, -1.42, 0.98, -1.64, -0.3, 0.01, -0.59, -3.45, -2.38, -2.6, -1.27, -0.96, -1.55, 0.23, 1.37, 1.68, 1.08, -0.74, -1.04, -1.13, 0.31, -0.29, -1.19, -1.41, -2.04, 3.25, -2.56, -3.1, -3.84, -2.09, -1.43, -0.5172131485030683, -1.71, -0.69, -1.06, -0.27, -1.02, -0.84, -5.84, -3.81, -1.9], ['270', -8.31, 0.04, -0.08, 0.0, -1.74, -0.5, -0.22, -0.45, -0.7, 0.22, 1.0, 0.8293248299319728, -0.4, 0.81, 0.4, 2.38, 1.27, 0.14, 3.97, 2.39, -0.47, -0.89, 0.37, -0.38, -1.02, -0.56, -0.78, -0.18, -1.39, -0.19, -0.59, 1.3633503401360545, 0.27, -0.85, 2.94, 1.37, -1.45, -1.87, -0.62, -1.37, 0.0, -1.57, -0.6, -1.21, -0.01, -0.42, 1.7842665945165948, 0.45, -0.68, 3.12, 1.55, -1.28, -1.7, -0.4157142857142857, -1.19, -1.28, -0.75, -1.06, -0.73, 0.62, 1.22, 0.81, 2.79, 1.68, 0.54, 4.39, 2.8, -0.06, -0.49, 0.78, 0.02, 0.03, -0.59, -0.4, 1.56, 0.46, -0.67, 3.14, 1.56, -1.26, -1.68, -0.43, -1.18, -0.71, -0.28, 0.19, -0.19, 1.97, 1.2999013605442178, -0.26, 3.55, 1.98, -0.86, -1.28, -0.03, -0.78, -3.48, -2.11, -1.08, -2.19, 1.55, 0.01, -2.78, -3.19, -1.96, -2.7, 0.03, -2.11, -1.17, -0.36, -0.38482093036566006, -0.34, -1.04, -1.12, 2.66, 1.1, -1.72, -2.13, -0.89, -1.63, 0.9, 0.08, 3.83, 2.24, -0.6, -0.8942004503433073, 0.23, -0.52, -0.42, -0.74, -0.07, -0.99, -10.48, -0.05, 0.04, 0.67, -0.71, -0.33, -0.56, -0.64, 4.02, 0.76, 0.32, -4.15, -0.11, -1.08, 0.97, 1.1, -0.37, 1.08, -0.76, 0.44, -0.21, -3.12, -2.93, 1.98, 3.09, -4.02, -3.61, -1.52, -4.27, -4.67, -3.46, -4.19, -0.9268321004392431, -2.12, -2.79, -3.2, -1.97, -2.7, 0.7444897959183674, -0.42, 0.84, 0.08, -0.62, -0.67, 1.11, 1.27, 0.51, -0.34, -0.48, -0.44, -0.03, -0.85, 0.06, -1.44, -1.44, -0.16, -0.75, -0.4, -0.55, 0.0, -0.47, -0.05, 0.6, -3.1, -1.47, -0.5], ['271', 3.11, 0.05, -0.028778284379541254, 0.28, -0.41, -0.64, 1.0641152579598292, -0.86, -0.75, 0.0, 1.56, -0.46, -0.22, -0.63, 2.0, -1.62, 0.63, -0.01, -4.37, 0.75, 0.3473354820873589, -0.06, 0.87, 0.97, -1.72, -1.05, -1.54, -1.99, -1.75, -2.16, 0.43, -3.13, -0.91, -1.54, -5.84, -0.8, -1.23, -1.59, -0.68, -0.58, -2.92, 0.68, 0.46, 0.24, -0.18, 2.47, -1.148956349206349, 1.1, 0.45, -3.93, 1.6496666666666666, 0.77, 0.4, 1.33, 1.7508287981859412, 0.95, -0.52, -0.9, -0.74, 0.22, -0.42, 2.22, -1.4, 0.85, 0.21, -4.16, 0.97, 0.53, 0.16, 1.09, 1.19, -2.51, 0.64, 2.65, -0.9892857142857143, 1.28, 0.63, -3.75, 1.4, 0.95, 0.58, 1.51, 1.62, -1.06, -2.52, 2.51, -1.96, -3.55, -1.34, -1.97, -6.24, -1.22, -1.65, -2.01, -1.11, -1.0, -0.17, 1.64, 2.29, 1.64, -2.79, 2.41, 1.96, 1.59, 2.53, 2.63, -0.09, 1.68, -0.26, -0.82, -0.71, -0.9, -0.63, -0.64, -4.97, 0.12, -0.32, -0.69, 0.23, 0.34, -0.14, 0.01, -4.36, 0.76, 0.32, -0.05, 0.88, 0.98, -0.75, -0.46, 0.46, -0.59, -0.5090476190476191, 0.0, -0.07, 2.58, -2.57, -1.26, 0.11, -0.9138364678879505, 1.52, 1.66, 0.83, 1.58, -0.31692021013122096, -2.46, 2.41, 2.47, -0.82, 3.95, -1.64, -5.03, 2.5, -1.82, 4.687380952380952, 1.25, 1.8, -1.6161904761904764, 4.56, 5.35, 4.89, 4.51, 5.47, 5.58, -2.52, -0.75, -0.44, -0.8, 0.12, 0.22, -0.31, -0.37, 0.56, 0.66, -0.71, -0.89, 0.06, 0.93, 1.03, -0.8, -0.77, -0.77, 3.24, -0.49, -3.23, -0.73, -0.16, -0.86, 0.1, -0.71, -1.18, -0.78, 0.1, -0.77, -0.97, -0.23, 0.94, -0.7], ['272', -1.72, 0.53, 0.09122171562045875, -0.24, -0.94, 0.3, 0.7, -0.22, 0.17, -1.84, -2.08, -1.95, -1.75, -0.79, -1.54, -0.86, -1.64, -1.9597942176870748, -4.39, -0.63, -2.53, -2.1440578231292515, -3.1, -2.59, -0.28, -0.04, 0.27265839499311245, 0.13, 0.33, 1.32, 0.56, 1.25, 0.45, 0.09, -2.36, 1.49, -0.46, -0.18, -1.04, -0.52, -0.62, 1.2349361992161734, 0.11, 0.2, 1.19, 0.42, 1.12, 0.32, -0.04, -2.48, 1.35, -0.59, -0.32, -1.17, -0.66, 0.22, 0.55, 0.08, 0.19, -0.09, 0.99, 0.22, 0.92, 0.12, -0.24, -2.571321995464853, 1.15, -0.79, -0.52, -1.37, -0.85, 0.4736060011417156, -1.06, -0.76, -0.07, -0.86, -1.22, -3.63, 0.16, -1.76, -1.49, -2.33, -1.82, 0.25, 3.59, -3.59, -0.31, 0.6905204081632652, -0.1, -0.47, -2.9, 0.92, -1.01, -0.74, -1.58, -1.07, -0.16, -1.0, -0.79, -1.15, -3.56, 0.23, -1.69, -1.42, -2.1188910216767356, -1.75, 0.26, -1.03, 2.02, 0.42, 0.58, 0.31, -0.21, -0.36, -2.8, 1.03, -0.91, -0.64, -1.4040121365844473, -0.97, 0.46, 0.16, -2.44, 1.4, -0.55, -0.27, -1.12, -0.61, 1.6689583699631245, 0.87, -0.21, 0.43, -0.3, 1.06, 0.65, -0.4, 0.38, 0.18, 0.29, -0.91, 2.7405182488772715, -0.88, -0.45, -0.83, 0.57, 1.2, -1.37, -1.3, 0.44, -0.53, 0.88, 2.55, -1.29, -0.52, -2.93, 0.36, 0.52, -2.5161904761904763, 2.66, 3.93, 1.94, 2.22, 1.366625850340136, 1.88, 1.24, -1.22, -1.91, -1.65, -2.49, -1.98, 0.7, 0.27, -0.58, -0.07, 0.2, 0.02, 0.43, -0.85, -0.34, 0.42, 0.38, -0.21, -1.3, 1.79, 0.97, 0.0, -0.08, 1.29, 0.5927868514969317, 0.54, 0.07, 0.3, 0.73, 0.27, 0.855957527023814, -2.65, -1.0784047619047619, 0.58], ['273', -8.33, 0.98, 0.0, -0.27, 0.15, 1.03, 3.55, -0.65, 1.06, -1.41, -2.31, -5.0, -1.87, 0.05, -0.75, 0.67, -1.97, -1.47, -0.64, -2.75, -1.55, -0.58, -2.46, -2.6, -0.86, 0.07, 0.92, -2.75, 0.45, 2.42, 1.59, 3.365035714285714, 0.34, 0.86, 1.71, -0.45, 0.78, 1.77, -0.15, -0.3, -0.83, 0.46493619921617346, 3.77, 3.29, 5.32, 4.47, 5.97, 3.19, 3.72, 4.59, 2.37, 3.63, 4.65, 2.68, 2.52, 0.28, -0.15, 0.27, 0.7, 0.47, 1.96, 1.14, 2.5942857142857143, -0.1, 0.41, 1.25, -0.89, 0.33, 1.31, -0.6, -0.74, -1.91, -1.47, -0.8, 0.62, -2.02, -1.52, -0.69, -2.8, -1.6, -0.63, -2.51, -2.5964403582748794, 0.63, 2.56, -2.6, -0.67, 1.43, -1.23, -0.72, 0.11, -2.01, -0.8, 0.17, -1.72, -1.86, -4.03, -2.07, -2.63, -2.12, -1.31, -3.39, -2.21, -1.007183003504432, -3.11, -3.25, 0.21, -2.1, -0.05, 0.89, 0.77, 1.02, 0.57, 0.52, 1.36, -0.79, 0.43, 1.42, -0.49, -0.64, -0.82, 0.05, 0.84, -1.3, -0.08, 0.9, -1.01, -1.15, 0.9, 0.8, -0.38, 0.6, -11.69, 0.42, 0.39, -2.07, 2.13, 1.06, -1.6, -0.2, -2.77, -1.71, -0.92, -4.22, 0.45, 2.67, -2.71, -2.61, 0.88, -3.29, 1.75, 2.69, -1.36, 1.65, -6.99, -1.16, -1.65, 2.77, -0.78, -2.12, -0.91, 0.06, -1.83, -1.97, 2.72, 1.37, 1.23, 2.22, 0.3, 0.15, 0.14, 0.98, -0.92, -1.07, 0.93, 0.49, -0.84, -1.89, -2.03, 0.94, 0.87, -0.46, -3.61, 0.23, 3.64, 0.58, 0.85, 1.07, -0.15, 1.46, 0.64, 0.87, -0.05, 0.69, 1.22, -1.64, 1.34, 1.14], ['274', -5.39, 0.06, 0.17122171562045874, 0.0, 0.11, -0.1, 0.11, 0.06, 0.13, 1.24, 0.79, 1.57, 1.89, 1.89, 0.29, 2.08, 1.67, 0.97, 3.53, 0.09, 1.33, 0.99, 1.52, 1.47, 0.34, -0.16, 0.45, 0.78, 1.09, 1.09, -0.5, 1.28, 0.88, 0.19, 2.72, -0.69, 0.54, 0.2, 0.73, 0.7238417231978392, -0.26, 0.0, -0.33, 0.31, 0.47787539444682314, -1.27, 0.5, 0.09, -0.59, 1.92, -1.46, -0.24, -0.58, -0.05, -0.1, 0.0, 0.59, 0.74, 0.17, -0.64, 0.0, -1.57, 0.19, -0.21, -0.9, 1.61, -1.77, -0.55, -0.89, -0.36, -0.41, 0.05, -0.64, -1.57, 0.19, -0.21, -0.9, 1.61, -1.77, -0.55, -0.88, -0.36, -0.41, 0.25, -0.42, 0.5, 0.95, 1.79, 1.38, 0.69, 3.23, -0.2, 1.04, 0.7, 1.23, 1.18, -1.62, -0.83, -0.4, -1.08, 1.42, -1.95, -0.74, -1.07, -0.54, -0.6, 0.18, -0.89, -0.88, -0.13, -0.08, -0.05432648134996804, -0.4290429599640126, -0.69, 1.83, -1.56, -0.34, -0.67, -0.14, -0.13141531611693433, 0.33, 0.26, 2.53, -0.88, 0.35, 0.01, 0.55, 0.49, -0.3, -0.48, 0.12603717887804045, -0.18681321637643203, -4.73, 0.01, 0.1, 0.31, -0.3175376766091052, -0.15, 0.08, 1.09, -2.29, 0.25, 0.15, -2.64, 0.22, -0.42, 0.35, 0.33, -0.12, 0.45, -0.24, 0.4, -0.22, -1.26, 4.71, 0.92, 1.2, 2.3, -2.21, -3.32, -2.12, -2.45, -1.93, -1.98, -0.4, 1.15, 1.24, 0.9, 1.44, 1.39, -0.09, -0.34, 0.19, 0.14, 0.15, 0.09, 0.25, 0.53, 0.48, -0.09, -0.14, 0.06257604962387836, 1.96, -0.62, -2.13, 0.11, -0.14, -0.20136255179902912, 0.02278685149693166, -0.23, -0.24, 0.14, 0.29, 0.1, -0.144042472976186, 0.0, -0.58, -0.32], ['275', 2.73, 0.24, 0.17122171562045874, 0.14, 2.02, -0.34, -0.85, -0.46, -0.4, -0.58, -0.48, 0.11, -1.06, 0.36, 0.89, -1.06, -0.26, -0.71, -3.61, -2.68, -0.37, -0.51, -0.17, -0.08, -0.59, -0.44062858541110805, -0.1, 0.6, -0.58, 0.84, 1.38, -0.58, 0.23, -0.23, -3.14, -2.21, 0.11, -0.03, 0.31, 0.4, -0.78, 0.7749361992161734, -0.7, -1.17, 0.24, 0.78, -1.17, -0.37, -0.82, -3.71, -2.79, -0.48, -0.62, -0.28, -0.2, 0.71, -0.88, -0.08, -0.43, 0.48, 1.43, 1.97, 0.0, 0.81, 0.35, -2.5628197278911564, -1.64, 0.7, 0.55, 0.9, 0.98, -0.71, -0.94, 0.53, -1.41, -0.61, -1.07, -3.95, -3.03, -0.72, -0.86, -0.53, -0.44, -0.04, -1.45, 1.44, -1.4233017616146797, -1.93, -1.14, -1.59, -4.46, -3.54, -1.25, -1.39, -1.05, -0.97, -0.25, 0.48, 0.81, 0.35, -2.58, -1.64, 0.69, 0.55, 0.89, 0.98, -0.02, 0.52, -0.58, -0.23, -0.4, -0.11, -0.3290429599640126, -0.46, -3.36, -2.43, -0.11, -0.25, 0.09, 0.17, -0.03, 0.13, -2.91, -1.98, 0.35, 0.2, 0.55, 0.64, -1.23, -1.24, 0.11, -0.4, -0.76, -0.18, 0.27, 0.25, -0.26, -0.14, 0.21, -0.42, -4.25, 0.5, 0.19, 1.33, -0.22, -0.67, 0.66, 0.67, -0.22, 0.32, -0.43, -1.63, 0.83, -0.95, -4.09, 0.67, 0.97, 4.48, 3.13, 0.96, 3.36, 3.21, 3.56, 3.66, -0.68, 2.15015873015873, 2.37, 2.23, 2.58, 2.67, -0.22, -0.14, 0.2, 0.29, -0.48, -0.19, -0.08, 0.34, 0.43, -0.18, -0.27, -0.52, -1.68, -0.46, 2.129280612244898, -0.57, -0.36, -0.33136255179902907, 0.09, 0.010077402522780693, -0.21, -0.2, -0.32, 0.45, -0.5, -0.67, -0.16, -0.45], ['276', -7.06, -0.93, -0.58, 0.23, -1.54, -1.91, -1.14, -2.06, -2.52, -2.35, 2.6903184712113286, -1.51, 0.84, 0.6, -0.95, -2.11, 0.5071428571428571, -0.6, 0.95, -0.23, -3.12, -0.14, 1.25, -0.41, -3.12, -3.43, -4.72, -3.9, -1.5898809523809525, -1.84, -3.35, -4.48, -1.96, -3.0, -1.5, -2.65, -5.46, -2.55, -1.2, -2.82, 1.51, -6.38, -0.85, 2.39, 2.15, 0.6408150295752765, -0.61, 2.02, 0.93, 2.5, 1.3, -1.63, 1.4, 2.8, 1.12, -3.03, -3.6957142857142857, -1.16, -1.8, -3.17, -0.24, -1.78, -2.93, 0.3114285714285714, -1.42, 0.11, -1.06, -3.92, -0.9540374149659864, 0.4, -1.24, -1.54, -2.93, -1.54, -2.7, -0.13, -1.19, 0.34, -0.83, -3.69, -0.73, 0.64, -1.01, -4.65, -10.15, 10.23, -1.42, -1.17, 1.44, 0.36, 1.91, 0.73, -2.19, 0.82, 2.22, 0.54, -0.97, -0.25, 2.64, 1.55, 3.12, 1.92, -1.03, 2.02, 3.43, 1.74, -1.9, -0.24, -2.99, -2.21, -2.59, -2.04, -2.81, -1.06, 0.47, -0.7, -3.57, -0.61, 0.77, -0.88, -2.15, -1.77, 1.55, 0.37, -2.54, 0.46, 2.0485714285714285, 0.18, -3.69, -3.16, 0.03, -2.97, -1.94, -2.02, -1.07, 4.44, -4.37, -2.21, -1.79, -3.85, 4.17, 4.651428571428572, 2.264547619047619, -3.51, -1.72, -6.99, 7.607142857142857, 6.924285714285714, -2.2, 6.68, -4.39, -4.27, 1.78, -8.43, 28.87, 5.58, 8.48, -4.28, -3.27, -1.17, -4.02, -1.07, 0.3, -1.35, -6.7, -2.13, -2.89, 0.1, 1.48, -0.18, 0.79, 3.08, 4.5, 3.0285714285714285, -2.72, -3.33, -2.22, 1.39, -0.28, -2.25, -2.41, -2.1, 14.37, -3.9, -14.29, -2.12, -2.89, -3.56, -1.64, -2.42, -2.26, -1.34, -1.72, -1.3, -1.95, -3.22, -3.9, -0.7], ['277', -1.68, 0.22, -0.15, -0.01, -0.36, -0.39158037632624054, 0.0, 0.43, 0.25, 1.75, 1.99, 1.54, 2.43, 1.41, 1.32, 1.33, 1.88, 1.72, 8.06, 2.64, 1.52, 1.5, 1.35, 2.1, -0.2, -0.04, -0.23, -0.44, 0.43, -0.57, -0.66, -0.65, -0.11, -0.26, 5.95, 0.64, -0.46, -0.48, -0.63, 0.11, 0.12, 0.40493619921617346, 0.409303232481804, 0.88, -0.13, -0.22, -0.21, 0.34, 0.18, 6.43, 1.09, -0.02, -0.03, -0.18, 0.55, 0.5, 0.41, 1.32, 0.39, -0.67, -1.0, -1.09, -1.08, -0.54, -0.69, 5.5, 0.2, -0.89, -0.91, -1.06, -0.33, -0.04, 0.34, -0.09, -0.08, 0.46, 0.31, 6.56, 1.21, 0.11, 0.09, -0.06, 0.68, 0.24, 0.93, -0.89, 0.43, 0.01, 0.56, 0.4, 6.66, 1.31, 0.2, 0.18, 0.04, 0.77, -0.14, 0.42, 0.54, 0.39, 6.65, 1.3, 0.2526265373526935, 0.17, 0.02, 0.76, 0.17, 0.42, -2.14, -0.3, -0.26, -0.33, -0.13, -0.15, 6.07, 0.75, -0.35, -0.37, -0.52, 0.22, 0.15, 0.03, 6.23, 0.9, -0.2, -0.22, -0.37, 0.37, 0.0, 0.08, 0.28, -0.22, -0.84, 0.19, 0.2, 0.23, -0.24, -0.14, 0.67, 0.23, 1.8005182488772715, 0.59, 0.31, -0.95, -0.23, -0.9, 0.83, 0.87, -0.3, 0.45, -0.55, -1.92, 0.91, -0.33, 0.28, 0.21, 0.33, -1.75, -5.84, -5.02, -6.05, -6.07, -6.21, -5.52, -0.87, -0.87, -1.09, -1.11, -1.26, -0.53, 0.23, -0.02, -0.17, 0.57, 0.5701351386708531, 0.37, 0.3272746849074344, -0.15, 0.6622487553150163, -0.25, -0.18560369872470917, 0.5625760496238783, 0.19, -1.74, -0.23, -0.3, -0.73, 0.39, 0.74, -0.55, -0.11, -0.59, -0.1, -0.17, -0.25404247297618604, -1.22, -0.69, -1.42], ['278', -12.888571428571428, 0.021428571428571422, -0.26877828437954127, 0.01, -2.11, -1.44, 0.06, -1.98, -0.92, -2.51, -1.66, -2.51, -0.98, -0.79, -0.42, 0.06, -1.13, -1.86, -4.05, 0.51, -2.6, -0.76, -0.68, -0.88, -2.11, -2.46, -0.86, -0.86, 0.7208333333333333, 0.89, 1.26, 1.76, 0.54, -0.2, -2.43, 2.210714285714286, -0.95, 0.92, 1.0, 0.8438417231978392, -1.66, -0.96, 0.0, 1.57, 1.77, 2.14, 2.64, 1.42, 0.67, -1.58, 3.09, -0.09, 1.8, 1.88, 1.67, -1.49, -1.55, -1.75, -1.54, -1.55, 0.19, 0.5607993197278912, 1.05, -0.15, -0.89, -3.1, 1.5, -1.64, 0.22, 0.3, 0.1, -1.01, -1.5242857142857142, 0.37, 0.86, -0.35, -1.08, -3.29, 1.3, -1.83, 0.03, 0.11, -0.1, -1.0010901360544218, -4.99, 4.93, -2.1, 0.49, -0.2800986394557823, -1.41, -3.65, 0.93, -2.19, -0.34, -0.26, -0.46, -3.65, -2.57, -1.19, -1.92, -4.11, 0.44, -2.66, -0.82, -0.74, -0.94, -0.8, -2.62, -1.34, -1.77, -1.53, -1.93, -1.4, -0.74, -2.95, 1.65, -1.49, 0.38, 0.45, 0.25, -1.72, -0.66, -2.24, 2.41, -0.75, 1.12, 1.2, 0.99, -0.79, -0.3, -0.65, -1.68, -7.35, -0.33, -0.36, 4.87, -4.87, -2.43, -0.78, -2.68, 5.72, 3.57, 1.76, -6.314778911564626, -1.01, -5.25, 5.37, 5.38, -1.77, 7.16, -3.42, -2.15, 1.02, -4.16, 9.65, 2.797142857142857, 4.435714285714286, -5.99, 1.61, 4.75, 1.51, 3.43, 3.51, 3.3, -5.35, -3.0, -3.09, -1.26, -1.18, -1.38, 0.09, 1.89, 2.202857142857143, 1.76, -0.99, -1.12, -1.77, 0.08, -0.13, -1.66, -1.71, -1.83, 4.89, -1.47, -4.93, -2.58, -2.32, -1.84, -0.2, -1.91, -2.22, -0.64, -0.949047619047619, -1.59, -1.64, -3.01, -3.38, -1.05], ['279', -1.09, -0.23, 0.011221715620458745, 0.15, -1.61, 0.29, -0.12, -0.17, 0.42, -0.22, -0.7, -0.43, -0.31, 0.37, -1.5, -0.19, -0.12, -0.17, -0.06, 3.93, 0.01, 0.06, -0.38, -1.16, 0.7, -0.14, 0.49, 0.27, 0.4, 1.08, -0.81, 0.52, 0.59, 0.53, 0.65, 4.67, 0.72, 0.77, 0.33, -0.46, 0.43, 0.40493619921617346, 0.21, 0.12, 0.8, -1.08, 0.24, 0.32, 0.26, 0.37, 4.809666666666667, 0.44, 0.5, 0.06, -0.73, 0.48, 0.29, 0.3, 0.28, 0.09, 0.68, -1.2, 0.12, 0.2, 0.14, 0.25, 4.26, 0.32, 0.37, -0.06, -0.85, 0.23, -0.58, -1.86, -0.56, -0.48, -0.54, -0.18252355184498031, 3.55, -0.36, -0.3, -0.74, -1.52, 0.47, 0.42, -0.41, 1.3, 1.33, 1.41, 1.35, 1.46, 5.52, 1.54, 1.59, 1.15, 0.35, 0.61, -0.03, 0.08, 0.02, 0.13, 4.13, 0.2, 0.25, -0.18, -0.97, -0.06, 0.0, 2.55, 0.2, 0.22, 0.29, -0.1, -0.06, 0.05, 4.05, 0.13, 0.18, -0.26, -1.05, -0.28, -0.05, 0.11, 4.11, 0.18, 0.24, -0.2, -0.99, 0.31, 0.17, 0.2860371788780405, 0.24, 1.89, 0.07, 0.0, -0.49, 0.41, 0.23, 0.06, -1.92, 8.13, -0.44, -0.21, -0.56, 0.5, 0.49, -0.6, -0.6, 0.21, -0.78, 0.4, -0.8116093450200591, 0.47, -0.24, -1.35, 0.16, 0.36, -8.09, -0.16, 4.0, 0.07, 0.12, -0.31, -1.1, 0.57, -3.99, -3.77, -3.72, -4.14, -4.9, -0.23, 0.05, -0.39, -1.17, 0.34, 0.56, -0.28, -0.44, -1.22, 0.19, 0.2, -0.14, -0.79, 1.78, 0.91, 0.58, -0.85, 0.16, -0.79, 0.29, 0.16, 0.5, 0.21, 0.42, 0.95, -0.56, -0.99, 0.95], ['280', 4.518571428571429, -1.87, 0.27, 0.6521428571428572, 0.88, -0.16, 0.25, 0.44, -0.06, 0.47, 1.25, 0.15, -0.36, -0.56, -0.19, -1.48, 1.56, 1.09, 2.71, -0.19, 0.42, 0.87, 0.96, 0.62, 0.13, 0.46, -0.77, -1.09, -1.59, -1.78, -1.42, -2.7, 0.31, -0.15, 1.45, -1.42, -0.82, -0.37, -0.28, -0.62, 1.09, 1.23, 0.32, -0.51, -0.7, -0.34, -1.63, 1.7186513605442175, 0.94, 2.56, -0.34, 0.27, 0.72, 0.8442857142857143, 0.48, -0.15, -0.16, -0.38, -0.48, 0.83, -0.2, 0.17, -1.13, 1.92, 1.46, 3.08, 0.17, 0.78, 1.2314285714285713, 1.33, 0.99, -0.55, 1.6757142857142857, 0.37, -0.93, 2.13, 1.66, 3.29, 0.37, 0.99, 1.44, 1.53, 1.19, -0.24109013605442178, -1.07, 1.14, 0.66, -1.29, 1.75, 1.32, 2.91, 0.0, 0.62, 1.07, 1.16, 0.82, 2.76, 1.98, 3.08, 2.61, 4.26, 1.31, 1.93, 2.39, 2.48, 2.15, -0.45, 1.98, 0.74, -0.18, -0.13, -0.34, -1.07, -0.46, 1.14, -1.72, -1.12, -0.68, -0.59, -0.92, -0.41, -0.62, 1.6, -1.27, -0.66, -0.22, -0.13, -0.47, -0.05, -0.21, -0.2, -0.87, 5.531102040816326, -0.42, -0.62, 0.46, -0.44, -0.22, -0.39, 0.81, -1.43, 0.35, 0.22, 2.23, -0.04, -0.63, 0.73, 0.42, -0.17, 0.74, -0.35, -2.37, 1.18, -3.16, 1.52, 2.2342857142857144, 3.275714285714286, 1.45, -2.18, -2.82, -2.23, -1.79, -1.7, -2.03, -0.46, 0.66, 0.61, 1.06, 1.15, 0.81, 0.05, 0.45, 0.7728571428571429, 0.2, -0.08, -0.38, -0.4, 0.09, -0.25, -0.19, -0.34, 0.33, 0.9157142857142857, -0.31, -0.67, -0.09, -0.38, -0.49, -0.34, -0.64, -0.31, 0.06, 0.06095238095238095, 0.54, -0.15, -0.35, -0.77, -0.49], ['281', 0.68, -0.07, 0.17122171562045874, 0.15, 0.3, -0.08, -1.72, -1.64, -1.14, -1.8, -1.13, -0.37, -0.53, -0.92, 0.22, -1.27, -1.01, -1.48, -3.54, -1.53, -2.1, -2.2, -0.98, -1.51, -1.61, -1.09, -0.67, 0.77, 0.61, 0.22, 1.37, -0.14, 0.12, -0.35, -2.43, -0.4, -0.98, -1.08, 0.2588796134390452, -0.3461582768021609, -1.3525315746467892, -1.89, -1.43, -0.15, -0.55, 0.6, -0.9, -0.64, -1.11, -3.18, -1.16, -1.73, -1.83, -0.61, -1.15, -0.5099371536943235, -0.3957142857142858, -1.91, -1.22, -1.28, -0.39, 0.75, -0.75, -0.49, -0.95, -3.03, -1.0, -1.58, -1.68, -0.45, -0.99, -2.55, -0.89, 1.15, -0.36, 0.04948941254823622, -0.56, -2.65, -0.61, -1.19, -1.29, -0.06, -0.6, -1.1, -1.82, 1.8, -2.02, -1.49, -1.23, -1.69, -3.75, -1.74, -2.32, -2.42, -1.2, -1.6759922724755494, -1.84, -0.54, 0.26, -0.21, -2.3, -0.26, -0.84, -0.94, 0.3, -0.25, -0.23, -0.65, 1.7, -0.4, -0.42, -0.43, -0.8, -0.47, -2.55, -0.52, -1.1, -1.2, 0.03, -0.51, 0.45, -0.33, -2.1, -0.05, -0.63, -0.73, 0.51, 0.2021774376417234, -1.01, -0.74, 0.29, -0.46, -5.7, 0.05, 0.14, 1.91, -1.91, -0.95, 0.14, -0.4938364678879505, 0.4, 0.75, 0.46, 0.46, 0.11, -1.28, 1.45, 1.22, -0.42, 2.9, -0.87, -1.27, 0.67, -2.36, 0.76, 1.62, 2.39, -0.5661904761904761, 1.8, 2.09, 1.49, 1.39, 2.66, 2.1, -1.28, -0.2798412698412699, -0.58, -0.68, 0.9794625850340136, 0.01, 0.3, -0.1, 1.14, 0.6, -1.19, -1.07, 0.41, 1.25, 0.7, -0.42, -0.51, -1.63, 0.5, 1.19, -0.63, -0.82, -0.55, -0.83, -0.54, -0.23, -0.92, 0.06, 0.11, 0.27, -0.29, -1.65, -1.4, -1.25], ['282', -4.332857142857143, 0.31, 0.09015289830927053, -0.1, 0.05, 0.29, -0.47, -1.27, -0.5, -0.9229115646258504, -1.42, -0.49, -0.61, -0.59, 0.49, -0.94, -1.23, -1.17, -5.26, -0.92, -1.46, -0.64, -1.03, -1.6, -1.59, -0.58, 0.05, 0.94, 0.82, 0.85, 1.94, 0.49, 0.19, 0.25, -3.9, 0.5, -0.04, 0.79, 0.4, -0.18, -1.16, -0.34, -0.88, -0.12, -0.1, 0.99, -0.42895634920634923, -0.7371428571428571, -0.68, -4.79, -0.43, -0.941934531913557, -0.15, -0.5242857142857144, -1.11, -1.56, -1.55, -1.86, -0.36, -0.76, 0.03, 1.12, -0.32, -0.62, -0.56, -4.68, -0.31, -0.85, -0.03, -0.42, -0.99, -3.35, -0.79, 1.09, -0.35, -0.65, -0.59, -4.7, -0.34, -0.88, -0.05, -0.44, -1.02, -0.27, -0.83, 0.95, -1.86, -1.42, -1.72, -1.66, -5.73, -1.41, -1.95, -1.13, -1.52, -2.08, -0.18, -0.44, -0.3, -0.24, -4.37, 0.01, -0.53, 0.3, -0.09, -0.67, -0.27, -0.45, 0.18, 0.05, 0.09, -0.08, -0.14, 0.06, -4.08, 0.31, -0.23, 0.6, 0.21, -0.37, -0.67, -0.2, -4.14, 0.25, -0.29, 0.54, 0.14, -0.43, 0.07, 0.22, 0.04, -0.21, -1.4022619047619047, 0.16, -0.24, 1.03, -1.04, -0.53, 0.07, -0.66, 0.94, -0.12, -0.07, -2.0707142857142857, 0.41, 0.01, 0.0, -0.13, 0.04, 1.53, 0.08, 0.64, -0.32, -0.36, 5.63, 0.21, 0.44, -1.02, 4.1, 4.58, 4.01, 4.88, 4.47, 3.87, 0.1, -0.45, -0.54, 0.29, -0.11, -0.68, 0.09, 0.83, 0.44857142857142857, -0.14, -0.49, -0.1, -0.74, -0.39, -0.97, -0.02, -0.02, -1.34, 2.84, 0.28, -2.89, -0.56, 0.12, -0.35, -0.4972131485030683, 0.4, -0.42, 0.5, 0.25, 0.3, 0.23, -1.76, -0.41, -0.08], ['283', -9.94, -0.26, 0.13, 0.29, -0.96, -0.89, -0.8058847420401708, -1.3382794034640413, -1.46, -1.32, 1.09, -0.21, -0.45, 1.03, 0.39, 0.72, -0.24, 0.09, -0.62, 0.45, -2.202664517912641, -0.54, -0.41, -0.46, -2.53, -1.33, -2.38, -1.28, -1.52, -0.05, -0.69, -0.36, -1.31, -0.98, -1.69, -0.63, -3.29, -1.61, -1.48, -1.53, -0.4, -1.81, -1.11, -0.24, 1.25, 0.6708150295752765, 0.94, -0.03, 0.3, -0.41, 0.66, -2.011934531913557, -0.33, -0.2, -0.25, -0.08, -1.1, -1.86, -1.24, -0.88, 1.49, 0.84, 1.18, 0.21, 0.54, -0.17, 0.91, -1.8, -0.09, 0.04, -0.01, -0.94, -2.33, -0.64, -0.31, -1.26, -0.93, -1.64, -0.58, -3.24, -1.56, -1.43, -1.47, -1.87, -2.64, 2.69, -1.71, 0.33, -0.63, -0.3, -1.01, 0.061674603174603174, -2.62, -0.93, -0.8, -0.84, -3.18, -2.03, -0.96, -0.63, -1.33, -0.27, -2.94, -1.25, -1.13, -1.17, -0.23, -2.0, -1.19, -0.9, -0.94, -0.94, -1.0081905235138708, 0.33, -0.38, 0.7, -2.0, -0.3, -0.17, -0.22, -0.79, -1.41, -0.71, 0.36, -2.33, -0.63, -0.5, -0.55, -1.05, -1.05, 0.28, -1.09, -9.82, -0.09, -0.12, 1.62, -1.61, -0.82, -1.92, -1.82, 3.37, 1.78, 0.9, -5.06, -0.4069202101312209, -2.83, 2.82, 2.71, -0.93, 2.43, -1.89, -3.37, 1.64, -3.17, 5.88, 2.07, 3.01, -3.42, -0.71, 1.08, -1.63, 0.08, 0.21, 0.16, -2.59, -1.77, -2.68, -0.99, -0.86, -0.91, 0.94, 1.8288785911064216, 1.87, 1.83, -1.51, -1.36, -0.79, 0.13, 0.08, -0.92, -0.8856036987247091, -1.46, 3.05, -1.29, -2.8085714285714287, -1.98, -1.63, -0.92, -0.05, -1.12, -0.67, -0.34, -0.26, -0.95, -0.87, -3.12, -2.04, -0.62], ['284', -2.1, 0.13, -0.23877828437954127, -0.01, 0.96, 0.32, 0.26, -0.37, 0.31, -1.98, -2.55, -2.09, -3.56, -1.14, -1.05, -2.06, -1.35, -2.24, -3.64, -3.6, -1.76, -1.43, -1.45, -1.8648833725798009, 1.06, 0.93, 0.6126583949931124, 0.47, -1.04, 1.45, 1.54, 0.5, 1.23, 0.4272589041444084, -1.12, -1.08, 0.81, 1.15, 1.12, 0.56, -0.5145146341753485, -0.17, 0.11, -1.51, 0.97, 1.06, 0.03, 0.75, -0.16, -1.59, -1.55, 0.33965472923706097, 0.67, 0.65, 0.08, -0.6, 0.04, -0.42, 0.51, 1.64, 2.52, 2.61, 1.56, 2.3, 1.37, -0.08, -0.04, 1.87, 2.22, 2.19, 1.62, 2.25, -0.85, 0.09, -0.93, -0.21, -1.12, -2.53, -2.49, -0.63, -0.29, -0.32, -0.88, 0.22, -1.79, 1.88, -0.94, -1.02, -0.3, -1.2, -2.62, -2.58, -0.72, -0.38, -0.41, -0.97, 0.32, 0.08, 0.73, -0.18, -1.61, -1.57, 0.31, 0.65, 0.62, 0.06, 0.35, 0.07, 1.12, 0.21159818068290148, 0.22, 0.09567351865003196, -0.64, -0.9, -2.3198412698412696, -2.28, -0.41, -0.08, -0.1, -0.66, -0.59, 0.27, -1.43, -1.39, 0.49, 0.83, 0.81, 0.24, -0.75, -0.59, -0.07, -0.13, 0.75, -0.39, -0.43, 1.56, -1.59, -0.8, -0.24, 0.09, -3.16, -0.32, -0.14, -1.06, 0.58, 0.4514761904761905, -0.48, -0.55, 0.18, 2.4, 0.36, -0.11, 0.01, -1.83, -1.89, 1.31, 1.82, 3.32, 1.73, 0.04, 1.95, 2.3, 2.27, 1.7, 0.42, 1.68, 1.91, 2.26, 2.23, 1.66, -0.22, 0.34, 0.31, -0.25, 0.26, 0.31, -0.56, -0.02, -0.59, 0.18, 0.16, -0.36, -0.92, 0.58, 1.17, 0.12, 1.52, -0.46136255179902913, -0.56, 0.0, -0.68, 1.07, 0.89, 0.28, 0.03, -0.12, 1.07, -0.89], ['285', -9.07, 1.5, 0.29, 0.3, -0.43, 0.93, -0.59, 1.34, 0.33, -1.4558571428571427, -2.08, -1.09, -3.08, -3.11, -3.23, 2.2, -2.0, -1.81, -2.06, -1.22, -1.93, -2.75, -2.58, -2.55, 1.04, 0.49, 0.6726583949931124, 1.01, -1.02, -1.05, -1.17, 4.38, 0.09, 0.28, 0.03, 0.88, 0.15, -0.68, -0.5, -0.43615827680216085, 1.41, 0.5149361992161734, -0.37, -2.01, -2.04, -2.16, 3.33, -0.91, -0.72, -0.97, -0.13, -0.85, -1.68, -1.5, -1.48, 1.17, 0.27, 0.7878279728097839, 0.11, 1.68, -0.03, -0.15, 5.45, 1.12, 1.31, 1.06, 1.92, 1.18, 0.34, 0.52, 0.54, -0.29, 1.71, -0.12, 5.49, 1.15, 1.35, 1.09, 1.95, 1.22, 0.37, 0.56, 0.58, 0.94, 3.4, -3.47, 1.83, 5.61, 1.27, 1.47, 1.21, 2.07, 1.3638701615844473, 0.49, 0.6785238095238095, 0.7, -4.53, -3.58, -4.11, -3.92, -4.17, -3.35, -4.05, -4.85, -4.68, -4.65, 0.73, -3.55, 0.27, 0.42, 0.9151790696343399, 1.065673518650032, 0.6218094764861293, 0.2, -0.06, 0.79, 0.07, -0.77, -0.59, -0.5114153161169342, 0.37, 0.36, -0.25, 0.6, -0.13, -0.96, -0.78, -0.76, 0.81, 0.74, 0.88, 0.913186783623568, -13.35, 1.27, 1.07, -1.76, 1.7, 0.888810171007621, -2.68, 0.16, 0.35, -1.82, -0.94, -4.46, 1.12, 2.76, -2.67, -2.76, 0.973290804863853, -2.59, 1.76, -1.59, 0.75, 1.55, -4.18, -1.07, -1.62, -0.31, 0.61, 0.85, 0.13660997732426305, -0.71, -0.53, -0.51, 2.68, -0.24, -0.72, -1.55, -1.37, -1.35, 0.49, -0.83, -0.66, -0.63, 0.34, 0.57, 1.33, 0.18, 0.2, 0.94, 0.91, 1.67, -1.99, 0.73, 2.03, 0.36, 0.5, 1.15, 0.02, 0.99, 0.48, 1.02, 1.23, 1.46, 1.13, -1.95, 0.26, 0.54], ['286', -0.64, 0.55, 0.16, -0.04, -0.04, -0.54, -1.4499638336347196, -0.9182794034640412, -0.57, -1.07, -0.55, -0.21, -1.15, -0.06, -0.16, -0.45, -0.51, -1.1, -0.8, -1.13, -0.8, -1.19, -0.46, -0.46, -0.61, -0.42, -0.49734160500688757, 0.34, -0.6, 0.49, 0.39, 0.1, 0.04, -0.55, -0.26, -0.58, -0.25, -0.64, 0.09, 0.09, -0.05, -1.04, -0.86, -0.94, 0.15, 0.12081502957527657, -0.24, -0.3, -0.89, -0.59, -0.92, -0.59, -0.8861344435209981, -0.25, -0.25, -0.37, -0.94, -1.68, -0.33, 0.08, 1.1, 1.000799319727891, 0.71, 0.64, 0.05, 0.35, 0.02, 0.35, -0.04, 0.7, 0.7, -0.91, -1.01, -0.1, -0.39, -0.45, -1.04, -0.75, -1.07, -0.74, -1.13, -0.4, -0.4, -0.57, -1.44, 1.49, -0.91, -0.29, -0.35, -0.94, -0.64, -0.97, -0.64, -1.03, -0.3, -0.3, -1.32, -0.63, -0.06, -0.65, -0.36, -0.68, -0.35, -0.74, -0.01, -0.01, -0.05, -0.62, 0.01, -0.5184018193170985, -0.69, -0.33432648134996806, -0.56, -0.59, -0.29, -0.6194642857142857, -0.29, -0.68, 0.05, 0.05, 0.03, 0.03, 0.3, -0.03, 0.3, -0.09, 0.65, 0.65, -0.76, -0.92, 0.12, -0.43, -4.12, -0.15, 0.07, 0.6, -0.63, -0.2811898289923789, -0.33, -1.49, -0.28, 1.07, 0.54, -0.34, -0.66, -1.68, 1.61, 1.61, -0.4867091951361471, 0.98, -1.1, -0.36, 0.17, -1.67, 1.99, 1.15, 1.58, 0.23, -0.27, -0.33, 0.0, -0.39, 0.35, 0.35, -1.67, 0.06, 0.33353741496598643, -0.06, 0.68, 0.68, -0.27, -0.39, 0.34, 0.35, -0.52, -0.3415464535464533, 0.12, 0.74, 0.74, -0.54, -0.5, -0.99, 0.94, -1.09, -0.85, -0.4, -1.07, -0.62, 0.0, -0.59, -0.41, -0.86, -1.17, 0.12, -0.62, 0.04, -0.84, -1.27], ['287', -8.23, -0.97, -0.4998471016907295, 0.07, -1.54, -2.78, -1.89, -4.0, -2.98, -4.92, -1.64, -2.74, -1.14, -1.75, -1.1157142857142859, -1.85, -1.2885714285714285, -3.82, -6.35, -2.5574455782312926, -5.17, -1.87, -2.06, -2.63, -3.82, -2.97, -3.33, -1.1194545454545455, 0.5146428571428572, -0.12, 0.52, -0.22, -0.3, -2.22, -4.8, -1.27, -3.59, -0.24, -0.43, -1.01, -3.23, -3.79, -2.24, 1.64, 1.01, 1.66, 0.92, 0.83, -1.11, -3.72, -0.15, -2.5, 0.89, 0.7, 0.11, -2.93, -2.7457142857142856, -4.49, -3.44, -3.82, -0.62, 0.02, -0.72, -0.8, -2.71, -5.28, -1.77, -4.08, -0.74, -0.93, -1.5, -4.44, -3.22, 0.64, -0.1, -0.18, -2.1, -4.68, -1.15, -3.48, -0.12, -0.31, -0.89, -3.28, -8.36, 8.4, -3.84, -0.73, -0.82, -2.72, -5.29, -1.78, -4.09, -0.6742857142857143, -0.94, -1.52, -3.22, -3.13, -0.09, -2.007880952380952, -4.59, -1.06, -3.38, -0.02, -0.21, -0.79, -1.2, -3.16, -2.28, -2.52, -2.51, -2.45, -3.04, -1.92, -4.51, -0.97, -3.3, 0.06, -0.13, -0.71, -2.96, -1.14, -2.64, 0.97, -1.41, 2.02, 1.83, 1.24, -3.45, -3.75, -0.38, -2.78, -6.32, -1.1796768707482992, -0.7942857142857144, 5.09, -5.1, -2.56, -1.88, -6.04, 4.24, 5.06, 2.9582806122448977, -4.14, -1.62, -7.5, 7.44, 7.55, -2.5, 7.64, -5.05, -2.14, 1.1, -9.07, 8.073125850340135, 6.07, 9.16, -4.18, 1.54, 3.7048095238095238, 1.27, 4.79, 4.59, 3.98, -7.5, -2.09, -2.35, 1.05, 0.86, 0.27, 0.7165017006802721, 3.48, 3.28, 3.331428571428572, -2.95, -3.32, -3.1, -0.19, -0.77, -2.46, -2.51, -3.93, 3.99, -3.19, -4.06, -2.66, -3.05, -2.92, -0.58, -3.07, -2.42, -1.79, -1.7, -2.13, -2.35, -4.94, -4.24, -2.12], ['288', -2.41, -0.01, -0.01, -0.05, -0.65, -0.07, 1.26, -0.99, 0.2, -1.01, -1.64, -1.11, -0.77, 0.51, 0.42, -0.25, -0.7, -1.11, -4.77, -0.37, -0.62, -0.73, -0.37, -0.92, -0.98, -0.21, 0.64, 0.54, 0.89, 2.19, 2.09, 1.42, 0.95, 0.54, -3.18, 1.29, 1.04, 0.93, 1.29, 0.7738417231978392, -0.82, 0.6449361992161734, 0.1, 0.35, 1.64, 1.6108150295752766, 0.87, 0.41, 0.0, -3.71, 0.75, 0.49, 0.48386555647900187, 0.75, 0.19, -0.39, -0.72, -0.88, -0.05, -0.17075475293412243, 1.28, 1.19, 0.52, 0.06, -0.35, -4.04, 0.4, 0.15, 0.04, 0.4, -0.16, -0.82, -1.51, -0.09, -0.75, -1.2, -1.61, -5.01252355184498, -0.87, -1.12, -1.23, -0.7369045181009466, -1.3764403582748792, 0.77, -1.64, 1.68, -1.42, -0.66, -1.12, -1.52, -5.17, -0.78, -1.03, -1.14, -0.78, -1.34, -0.09, -0.77, -0.46, -0.87, -4.54, -0.12, -0.3173734626473065, -0.48, -0.13, -0.68, 0.09, -0.83, -0.29427628811696, -0.2, -0.3, -0.09, -0.31, -0.41, -4.1, 0.34, 0.08, -0.03, 0.33, -0.22, -0.23, 0.11, -3.7, 0.75, 0.5, 0.5157995496566927, 0.75, 0.19, -1.22, -1.33, 0.08, -0.29, -0.39, 0.14, 0.07, -0.04, 0.0, -0.01, 0.07, -0.83, 1.27, 0.41, 0.21, -1.16, -0.21, -0.66, 0.59, 0.64, -0.15670919513614703, 0.03, -0.44, -0.85, 0.45, -0.88, -0.17, 0.6, 0.92, -1.3, 3.95, 4.63, 4.36, 4.25, 4.62, 4.04, -0.6391948051948052, -0.64, -0.26, -0.36, 0.0, -0.56, -0.39, -0.11, 0.25, -0.3, 0.18, 0.35, -0.28, 0.36, -0.2, -0.22, -0.2, -0.9, 0.3, -0.25, -0.31, -0.3781051005851445, -0.16, -0.64, -0.56, -0.48, 0.05, 0.17, -0.19, -0.26, -0.09, -1.61, -0.2, -0.14698322629260274], ['289', 0.91, -0.53, -0.12, 0.08, -0.01, 0.57, -1.0299638336347197, -0.5482794034640412, -0.05062194561298938, -0.93, -1.03, -0.11, -1.05, -1.1, -0.41, -0.71, -0.84, -0.91, -0.43, 0.1, -0.95, -0.96, -0.93, -0.87, -0.04, -0.82, 0.1, 0.93, -0.02, -0.08, 0.6878199712950912, 0.33, 0.19, 0.12, 0.6, 1.14, 0.08, 0.07, 0.1, 0.16, -0.15, -1.11, -0.82, -0.94, -0.99, -0.29, -0.59, -0.73, -0.79, -0.32, 0.21, -0.84, -0.84, -0.82, -0.76, -0.2, 0.0, -0.52, 0.16, 0.12, -0.05, 0.65, 0.35, 0.21, 0.15, 0.63, 1.16, 0.1, 0.1, 0.12, 0.18, -1.33, 0.18, 0.71, 0.4, 0.27, 0.2, 0.68, 1.22, 0.15, 0.15, 0.18, 0.24, -0.41, -0.12, 0.08, -0.53, -0.2119125667872351, -0.43, -0.5, -0.03, 0.51, -0.3847647669790526, -0.55, -0.53, -0.47, -1.85, -0.23, -0.13, -0.2, 0.28, 0.81, -0.25, -0.25, -0.23, -0.17, -0.12, -0.24, 1.3, 0.13, -0.13, 0.40567351865003193, -0.09, -0.07, 0.41, 0.94, -0.12, -0.12, -0.01401213658444736, -0.03, 0.05, -0.02, 0.48, 1.01, -0.05, -0.05, -0.02, 0.04, -0.39, -0.64, 0.19603717887804045, 0.08, -5.17, -0.05, 0.0, -1.23, 1.25, 0.6588101710076211, -0.03, 0.29, 1.88, -0.27, -0.11, 0.48, -0.2, 0.5505968614718616, -0.47, -0.4, 0.14, -1.88, 0.3, 0.22, -0.12, -0.25, -5.18, 0.22, 0.35, -1.9428690476190476, -0.5, 0.53, -0.513390022675737, -0.53, -0.5, -0.44, 0.42, -1.03, -1.05, -1.05, -1.03, -0.97, 0.02, 0.0, 0.02, 0.08, -0.19, 0.04, 0.03, 0.03, 0.09, 0.15, 0.12, -0.71, -1.98, 0.67, 1.94, -0.33, -0.42, 0.0, 0.06, 0.11, 1.15, -0.07, -0.28, -0.12, -0.06, -0.68, -0.76, 0.02], ['290', 5.23, -1.59, -1.08, 0.09, -1.9570209190089405, -2.0315803763262403, -2.55, -2.23, -2.3, -1.2592857142857143, 2.04, 1.42, 0.17, 0.65, 0.77, -5.16, 1.57, 0.2, 1.58, 2.93, -1.11, 1.0, 2.35, 1.81, -1.73, -1.74, -3.23, -0.61, -1.83, -1.36, -1.24, -7.05, -0.46, -1.8, -0.45, 0.88, -3.09, -1.02, 0.31, -0.22, -1.6, -1.3650638007838265, -2.64, -1.23, -0.75, -0.64, -6.48, 0.15, -1.2, 0.16, 1.5, -2.49, -0.41, 0.92, 0.39, -1.66, -2.49, -3.81, -1.96, -1.43, 0.48, 0.6, -5.32, 1.39, 0.13260506614006173, 1.4271802721088434, 2.76, -1.28, 0.83, 2.18, 1.64, -2.09, -1.9, 0.12, -5.77, 0.91, -0.45, 0.92, 2.5891309523809523, -1.75, 0.34, 1.69, 1.15, -2.58, -9.65, 9.62, -1.9833017616146797, -5.88, 0.79, -0.57, 0.8, 2.15, -1.87, 0.23, 1.57, 1.03, 6.74, 4.11, 7.09, 5.65, 7.11, 8.53, 4.27, 6.49, 7.92, 7.35, -1.41, 4.13, -6.78, -2.27, -2.26, -2.46, -2.7790429599640123, -1.35, 0.01, 1.35, -2.64, -0.56, 0.77, 0.24, -2.21, -1.46, 1.38, 2.73, -1.31, 0.8, 2.15, 1.61, -4.571041630036876, -4.24, 0.12, -2.876813216376432, 20.08, -1.0, -0.56, 4.77, -4.81, -2.39, -1.17, -2.47, 8.14, 4.62, 2.31, 2.71, -1.39, -6.94, 6.89, 6.87, -2.27, 7.25, -4.54, -4.08, 1.83, -8.37, 13.81, 5.51, 8.28, -8.11, -2.8, 1.33, -2.65, -0.57, 0.76, 0.23, -6.88, -4.08, -3.93, -1.88, -0.56, -1.09, -0.15, 2.13, 3.5, 2.95, -2.2, -2.25, -2.24, 1.34, 0.8, -2.31, -2.39, -2.06, 7.3, -5.75, -7.19, -1.75, -2.03, -3.4513625517990287, -0.53, -2.54, -2.29, -1.81, -0.31, -1.65, -3.02, 0.66, -4.34, -3.48], ['291', -2.27, 0.11, 0.11122171562045875, 0.1, -1.48, -0.08, -0.17588474204017085, -0.27, -0.04, -1.27, -1.27, -1.05, -1.21, -0.88, -2.22, -0.51, -0.47, -1.44, 0.15, -0.22, -1.13, -1.04, 0.26, -1.19, -0.41, -0.63, 0.03265839499311246, 0.22, 0.07011904761904762, 0.39, -0.96, 0.76, 0.8, -0.18, 1.43, 1.06, 0.14, 0.23, 1.55, 0.08, -0.44, -0.22506380078382657, -0.22, -0.16, 0.16, -1.18, 0.54, 0.58, -0.4, 1.3071355564861205, 0.84, -0.08034527076293904, 0.01, 1.32, -0.15, -0.24, 0.15, -0.62, -0.17, -0.06, 0.33, -1.02, 0.7, 0.74, -0.24, 1.3871802721088435, 1.0, 0.08, 0.17, 1.49, 0.02, -0.85, -0.39, -1.34, 0.37, 0.41, -0.56, 1.04, 0.67, -0.25, -0.16, 1.16, -0.31, -0.03, -3.76, 3.82, 0.97, 1.74, 1.78, 0.79, 2.42, 2.04, 1.1338701615844473, 1.2, 2.54, 1.05, -1.58, -0.76, 0.04, -0.93, 0.66, 0.29, -0.62, -0.53, 0.78, -0.68, 0.22, -0.78, -1.1298229965745161, -0.35, -0.69, -0.05, -0.8, -0.97, 0.62, 0.26, -0.66, -0.57, 0.74, -0.72, -0.28, 0.23307674813036727, 1.61, 1.24, 0.31, 0.41, 1.73, 0.25, -2.76, -2.97, 0.22, -0.78, -4.588897959183674, -0.08, -0.07, -0.14, 0.14, 0.08, -1.11, -0.93, 2.07, 0.71, 0.32, -1.16, -0.25, -1.03, 1.08, 1.03, -0.35, -0.08, -0.71, -1.07, 0.53, -2.45, 0.11, 1.58, 2.37, -2.08, -1.41, -0.37, -1.28, -1.19, 0.12, -1.34, -1.01, -1.05, -0.91, -0.82, 0.49, -0.98, -0.14, 0.09, 1.41, -0.06, 0.12013513867085306, -0.11, -0.23, 1.32, -0.16, -0.35, -0.42, -0.26, 0.77, -1.12, -0.63, -0.57, -0.73, -1.53, -1.45, 0.07, -0.01, 0.11, -0.44, -0.11, -0.08, -2.37, -1.02, -0.61], ['292', 3.82, 0.58, 0.12, 0.3821428571428573, 0.76, 0.33, 1.6, 0.72, 1.28, 0.56, -0.98, -0.05806550195835902, -0.39, -0.15, -0.61, -0.68, 0.66, 0.41, -1.56, -0.47, 1.67, 0.74, -0.47, 0.31, 0.94, 0.84, 1.55, 0.72, 0.6, 0.83, 0.37, 0.3, 1.65, 1.4, -0.59, 0.51, 2.67, 1.73, 0.51, 1.3, 0.55, 2.75, 0.82, -0.13, 0.11, -0.35, -0.42, 0.92, 0.67, -1.3, -0.21, 1.93, 1.0938655564790019, 0.4214285714285715, 0.57, 0.59, 1.02, 1.78, 1.160952380952381, 0.95, 0.24, -0.22, -0.29, 1.05, 0.8, -1.17, -0.08, 2.06, 1.13, -0.08, 0.7, 1.12, 0.71, -0.46, -0.53, 0.81, 0.56, -1.41, -0.32, 1.82, 0.89, -0.32, 0.46, 1.77, 2.35, -2.29, 1.17, -0.0694795918367347, 1.27, 1.02, -0.96, 0.14, 2.29, 1.35, 0.14, 0.92, 2.23, 1.25, 1.35, 1.1, -0.88, 0.21, 2.36, 1.43, 0.21, 1.0, 0.12, 1.3, -0.81, 0.41, 0.59, 0.12, -0.1, -0.25, -2.2, -1.12, 1.0, 0.14030501944728757, -1.12, -0.35, -0.09, 0.15, -1.96, -0.88, 1.25, 0.33, -0.88, -0.1, 0.8689583699631245, 0.45, -0.02, -0.06, 6.59, 0.1, 0.11, -0.21, 0.24, 0.1, 0.28, 0.5, -2.04, -0.8, -0.42, 1.86, 0.35, 1.23, -1.28, -1.26, 0.4, -0.4, 0.81, 0.53, -0.3, -0.25, -2.04, 0.13, 0.25, 2.09, 2.15, 1.1, 3.27, 2.33, 1.1, 1.9, 1.22, 1.0301587301587303, 2.15, 1.21, 0.0, 0.78, -1.09, -0.91, -2.1, -1.33, 1.24, 1.51, -0.18, -1.2, -0.42, 0.42, 0.33, 0.65, -1.58, -0.43, 1.57, 0.15, 0.7810935020800125, 1.03, 0.78, 0.15, 0.03, 0.37, 0.14, 0.68, 0.335957527023814, -0.26, 1.3830376647162361, -0.29], ['293', 5.93, 0.75, 0.05, -0.18, 1.9, 0.59, 1.36, 0.96, 1.68, 0.34, -1.48, -1.12, -1.53, -0.34, 0.72, -0.32, 0.017142857142857144, -0.16, 1.35, -2.32, 0.9, -0.57, -1.24, -0.39, 1.71, 2.22, 1.85, 0.37, -0.05, 1.16, 2.23, 1.18, 1.4914285714285713, 1.34, 2.87, -0.85, 2.42, 0.93, 0.24, 1.11, 0.6374684253532109, 2.1449361992161733, 1.47, -0.42, 0.79, 1.86, 0.81, 1.11, 0.96, 2.5, -1.21, 2.068065468086443, 0.56, -0.13, 0.74, 0.13, 1.16, 1.12, 1.56, 1.9, 1.21, 2.28, 1.23, 1.54, 1.39, 2.93, -0.8, 2.6334211542425834, 0.98, 0.4553389784818358, 1.16, 1.07, 0.68, 1.06, 0.02, 0.32, 0.17, 1.69, -1.99, 1.25, -0.23, -0.91, -0.05, 1.98, 4.42, -4.46, -0.38, -1.02, -0.73, -0.88, 0.63, -3.01, 0.19, -1.27, -1.95, -1.1, 3.06, 0.66, 0.3, 0.15, 1.67, -2.01, 1.22, -0.25, -0.93, -0.07, 0.86, 0.68, -1.63, 0.79, 0.94, 0.7, 0.35, -0.15, 1.37, -2.3, 0.92, -0.55, -1.23, -0.37, 0.97, 0.5, 1.52, -2.15, 1.07, -0.4, -1.08, -0.22, 1.76, 0.48, -0.3, 0.943186783623568, 6.05, 0.18, -0.06, -0.84, 0.81, 0.43, 0.96, 0.71, -5.31, -1.53, -0.81, 2.94, 0.41, 2.43, -2.47, -2.37, 0.78, -1.23, 1.57, 0.88, -0.44, 1.07, -9.29, -0.75, -1.14, 5.293809523809524, -1.0, -3.62, -0.44, -1.89, -2.56, -1.72, 2.37, 2.7201587301587304, 3.3, 1.79, 1.1, 1.97, -0.56, -1.46, -2.13, -1.28, 1.74, 1.88, 0.91, -0.68, 0.18, 0.81, 0.76, 0.9225760496238784, -4.66, -0.61, 4.6, 1.75, 1.47, 1.6, 0.86, 0.58, 0.36, 0.54, 0.39, 0.06, 0.73, 2.46, 2.92, 0.3730167737073973], ['294', 3.64, 0.18, 0.4012217156204588, 0.05, 0.8129790809910595, 0.46, 1.2441152579598291, 0.93, 0.94, 3.73, 3.08, 2.558992063492063, 3.1, 2.4, 3.45, 3.21, 2.6599999999999997, 3.37, 7.7, 1.9966428571428572, 3.9, 3.33, 3.17, 3.36, 0.77, 0.64, 0.63, -0.52, 0.02, -0.66, 0.36, 0.13, -0.43, 0.28, 4.48, -1.06, 0.79, 0.24, 0.09, 0.27, 0.26, 2.08, 1.16, 0.54, -0.14, 0.88, 0.65, 0.09, 0.81, 5.03, -0.55, 1.32, 0.76, 0.61, 0.8, 0.14, 1.13, 1.43, 0.97, 0.61, -0.68, 0.34, 0.11, -0.45, 0.27, 4.46, -1.08, 0.77, 0.22, 0.2353389784818358, 0.25, 0.88, 1.3, 1.03, 0.79, 0.23, 0.95, 5.17, -0.4, 1.46, 0.9, 0.76, 0.94, 1.08, 1.55, -1.5, 0.27, -0.23, -0.79, -0.08, 4.11, -1.42, 0.43, -0.12, -0.27, -0.09, 0.19, 0.5, -0.56, 0.16, 4.35, -1.19, 0.67, 0.11, -0.04, 0.15, 0.43, 0.51, 0.15, 0.58, 0.49, 0.61, 1.07, 0.72, 4.94, -0.63, 1.23, 0.68, 0.53, 0.71, 0.39, 0.35, 4.18, -1.34, 0.51, -0.05, -0.18428571428571427, -0.01, 0.47, 0.55, 0.05, 0.59, 0.47, 0.1, 0.02, -1.44, 1.41, 0.72, 0.53, 0.5561635321120495, -3.3, -1.14, -0.6, 1.84, 0.4, 1.63, -1.74, -1.76, 0.57, -2.1, 1.14, -0.22, 0.12, 3.21, -3.08, -2.12, -3.24, 3.25, -3.68, -5.3, -3.53, -4.06, -4.2, -4.03, 1.71, 1.71, 1.87, 1.31, 1.16, 1.35, -0.16, -0.55, -0.7, -0.52, 0.98, 1.01, 0.39, -0.15, 0.03, 0.52, 0.61, 0.94, -1.26, -0.1, 1.24, 0.91, 0.31, 0.54, 0.18, 0.61, 0.65, 0.59, 0.58, 0.8, 0.36, 0.81, 0.81, -0.58], ['295', -0.38, -0.23, 0.011221715620458745, -0.12, -1.09, 0.29, 1.78, -0.02, -0.17, -0.77, -0.2, -1.45, -0.19, -0.58, 0.38, -0.34, -1.09, -0.64, 0.07, 1.01, -1.12, -0.87, -1.16, -1.2, 0.0, 0.18, -0.5373416050068875, -1.25, 0.01, -0.39, 0.58, -0.14, -0.9, -0.45, 0.27, 1.21, -0.92, -0.67, -0.96, -1.0, -0.29, -1.77, 0.7, 1.28, 0.88, 1.86, 1.13, 0.3992789115646258, 0.82, 1.54, 2.490714285714286, 0.34, 0.59, 0.39714285714285713, 0.26, 0.0, 0.07, 0.0, -0.61, -0.57, -0.39, 0.57, -0.14, -0.9, -0.45, 0.26, 1.2, -0.93, -0.68, -0.97, -1.01, 0.06, -0.18, 0.97, 0.25, -0.51, -0.06, 0.66, 1.6, -0.54, -0.28, -0.58, -0.62, -0.61, 1.01, -1.05, -1.14, -0.71, -1.47, -1.02, -0.31, 0.62, -1.49, -1.24, -1.53, -1.57, -0.62, -0.43, -0.76, -0.31, 0.41, 1.35, -0.79, -0.53, -0.83, -0.87, -0.28, -0.46, 0.62, 0.31, 0.25, 0.22, 0.33, 0.5865993906886765, 1.18, 2.12, -0.03, 0.23, -0.07, -0.051415316116934326, 0.0, -0.12, 0.72, 1.66, -0.48, -0.22, -0.52, -0.56, 0.04, 0.1, -0.013962821121959568, -0.45, -2.36, -0.22, -0.13, -0.65, 0.71, 0.34, -0.2859337265331848, -0.28, 3.32, -0.61, -0.28, -0.15, 0.26307978986877906, 0.63, -0.87, -0.94, 0.3, -1.1, 0.63, -1.01, 0.26, 0.92, 3.46, -0.51, -0.94, -3.28, -0.5096213151927438, 0.94, -1.19, -0.93, -1.23, -1.27, 0.91, -1.75, -2.1, -1.85, -2.14, -2.18, 0.36, 0.26, -0.04, -0.08, -0.18, -0.45, 0.1, -0.3, -0.34, 0.29, 0.23, 0.02, 1.63, 0.39, -1.84, 0.08, -0.34, 0.4, -0.04, -0.22, 0.19, 0.31, 0.05, 0.6, 0.44, -2.29, -0.36, 0.03], ['296', -1.04, -1.24, 0.03, -0.01, -0.26, 0.5, 0.21, 0.84, 0.2, 0.95, 0.18, 0.61, -0.16, -0.7, -0.31, 2.3, 0.41, 0.87, 3.32, 1.4, 1.04, 0.42, 0.19, 0.3, -1.08, 0.49937141458889195, 0.77, 0.43, -0.34, -0.87, -0.49, 2.12, 0.24, 0.69, 3.14, 1.22, 0.86, 0.24, 0.01, 0.17384172319783917, 0.92, 1.1549361992161733, 0.34, -0.76, -1.3, -0.91, 1.68, -0.19, 0.26, 2.7, 0.78, 0.458065468086443, -0.18, -0.42, -0.3, 0.96, 0.21, 0.32, 0.1, 1.11, -0.54, -0.15, 2.46, 0.58, 1.03, 3.49, 1.56, 1.2, 0.58, 0.35, 0.46, 0.46, 1.66, 0.39, 3.02, 1.1816609275411798, 1.58, 4.05, 2.11, 1.75, 1.13, 0.89, 1.01, 0.51, 2.3, -2.31, 1.3066982383853203, 2.62, 0.73, 1.18, 3.65, 1.71, 1.36, 0.74, 0.5, 0.62, -2.96, -1.31, -1.84, -1.4, 1.0, -0.88, -1.23, -1.83, -2.06, -1.95, -0.04, -1.1606317967746538, 0.0, 0.5315981806829014, 0.69517906963434, 0.39, 0.53, 0.45, 2.9, 0.98, 0.62, 0.01, -0.22, -0.11, 0.49, 0.08, 2.44, 0.53, 0.17, -0.44, -0.67, -0.56, 1.15, 1.17, -0.06, 0.69, -8.78, 0.19, 0.0, -0.13, 0.09246232339089482, 0.04, 0.49, 1.69, 0.76, -0.98, -0.47, -0.45, 0.68, 1.52, -1.55, -1.49, 0.48, -0.21, 0.99, 0.8, -0.32523473571575323, 1.63, -3.4, -1.11, -1.62, -0.89, -2.3, -1.87, -2.21, -2.81, -3.03, -2.92, 1.48, -0.44, -0.35, -0.96, -1.19, -1.08, -0.09, -0.61, -0.84, -0.73, 0.21, 0.5184535464535467, 0.53, -0.23, -0.047751244684983665, 0.51, 0.51, 0.98, -1.36, 0.05, 1.27, 0.83, 0.8, 0.7604317111459968, 0.11, 0.87, -0.03, 0.64, 0.79, 0.14, 0.65, -0.72, 1.23, 0.52], ['297', 0.29, 0.17, 0.04, 0.04, 0.97, -0.1, 1.0641152579598292, 0.59, 0.97, 0.49, -0.82, -0.51, 1.63, -0.38, -0.45, -0.4, 0.25, 0.32, 1.23, -1.63, 0.58, 0.25, -0.06, 0.52, 1.49, 1.19, 1.31, 0.3, 2.46, 0.44, 0.37, 0.4233503401360544, 1.07, 1.14, 2.07, -0.82, 1.4, 1.07, 0.8688796134390452, 1.35, 0.55, 0.27, 1.01, 2.1536589811608606, 0.13, 0.13081502957527658, 0.1264030612244898, 0.77, 0.83, 1.8571355564861205, -1.12, 1.128065468086443, 0.76, 0.46, 1.04, 0.39, 0.65, 0.37, 0.49, -1.12, -1.98, -2.04, -1.99, -1.36, -1.29, -0.39, -3.2, -1.03, -1.36, -1.65, -1.08, 0.76, 0.87, -0.07, -0.02, 0.63, 0.7, 1.62, -1.25, 0.96, 0.63, 0.33, 0.91, 1.09, 1.62, -1.66, 0.94, 0.05, 0.7, 0.77, 1.69, -1.18, 1.03, 0.7, 0.4, 0.98, 4.66, 0.89, 0.65, 0.72, 1.64, -1.23, 0.98, 0.65, 0.35, 0.93, 0.17, 0.95, 0.47, 0.1, 0.2751790696343399, -0.04, 0.24, 0.07, 1.0869325674325676, -1.87, 0.33, 0.0, -0.3, 0.28, 0.24, 0.17, 0.91, -1.94, 0.26, -0.07, -0.37, 0.21, 0.73, 0.39, 0.1, 0.23, 14.207619047619048, 0.01, 0.0, 0.0, -0.02, 0.0, 0.12, 2.7361635321120494, -4.22, -0.21, -0.13, 0.18, 0.09, 0.26, -0.42, -0.34, 0.1, 0.06, 0.19, -0.48, 0.3147652642842468, 0.78, -2.11, -0.59, -0.78, 4.23, -0.74, -2.83, -0.65, -0.98, -1.27, -0.7, 0.3, 2.15, 2.24, 1.9, 1.6, 2.19, -0.09, -0.33, -0.63, -0.05, 0.89, 0.86, 0.24, -0.3, 0.28, 0.11, 0.16, 0.63, -0.63, 0.54, 0.61, 1.27, 1.44, 0.54, 0.58, 0.98, 0.11455285983857427, -1.05, 0.63, -1.26, -0.04, 3.08, 2.4330376647162364, 0.25], ['298', 1.37, -0.28, 0.0, -0.17, -0.4, -0.41, -0.6658847420401709, 0.02, -0.38, 1.05, 0.81, 1.42, 1.34, 0.43, 1.5, 0.42, 1.59, 1.17, 1.6, 1.6, 1.21, 1.53, 1.61, 1.44, -1.04, 0.08, 0.23, 0.6, 0.53, -0.38, 0.68, -0.39, 0.77, 0.36, 0.78, 0.78, 0.39, 0.71, 0.79, 0.63, 0.22, -2.0150638007838264, -0.37, -0.08, -0.98, 0.08, -0.99, 0.17, -0.24, 0.18, 0.17, -0.21, 0.11, 0.19, 0.02, -0.07, -0.07, -0.52, -0.28, -0.29, -0.9, 0.16, -0.91, 0.24, -0.17, 0.25, 0.25, -0.14, 0.18, 0.26, 0.1, -0.73, 0.62, 1.07, -0.01, 1.16, 0.74, 1.17, 1.16, 0.78, 1.1, 1.18, 1.01, -0.55, -1.72, 1.69, -0.41330176161467985, -1.07, 0.09, -0.32, 0.1, 0.09, -0.29, 0.03, 0.11, -0.06, -0.74, 0.63, 1.17, 0.75, 1.18, 1.17, 0.78, 1.1124285714285715, 1.19, 1.02, -0.19, 0.63, -0.21427628811695995, -0.26, -0.39, -0.16, -0.54, -0.41, 0.01, 0.0, -0.38, -0.06, 0.02, -0.15, -0.64, -0.12, 0.42, 0.42, 0.03, 0.35, 0.43, 0.27, -0.32, -0.23, -0.2, -0.25, -1.34, -0.36, -0.35, -0.17, 0.2, 0.08, -1.29, 0.1, 1.0, 0.51, 0.27, 0.69, -0.24, -0.89, 0.87, 0.83, -0.26, -0.23, -0.53, 1.44, -0.71, -1.63, 4.72, 1.1, 1.65, -1.11, -0.54, 0.0, -0.39, -0.07, 0.01, -0.15, -0.8, -0.54, -0.38, -0.06, 0.02, -0.15, -0.16, 0.32, 0.4, 0.23, -0.42, -0.39, -0.47, 0.08, -0.09, -0.27, -0.28, 0.10257604962387837, 2.31, -0.47980037304250067, -2.36, -0.03, 0.14, -0.55, -0.17, 0.22, -0.07, -0.69, 0.55, -0.73, -0.39, -0.54, 0.32, -0.49], ['299', 2.98, 0.43, -0.32877828437954126, 0.38, 1.04, -0.011580376326240524, -0.44588474204017087, -0.1, -0.96, -0.25, 1.31, 0.06, 0.65, -1.2, 0.1, -2.46, 0.11, -0.12, -1.48, -1.52, -0.77, 0.43, 0.79, -0.17, -0.79, 0.68, -1.4973416050068875, -1.23, -0.64, -2.47, -1.1321800287049086, -3.71, -1.18, -1.4, -2.75, -2.79, -2.05, -0.87, -0.51, -1.4061582768021608, 0.12, -1.29, -0.31, 0.59, -1.0921246055531768, 0.03, -2.52, 0.05, -0.18, -1.538347866419295, -1.58, -0.83, 0.36, 0.72, -0.23, -0.5, -0.35, -0.22, -0.62, -0.89, -1.84, -0.55, -3.09, -0.54, -0.77, -2.12, -2.16, -1.41, -0.23, 0.13, -0.81, -0.6, 0.96, 1.31, -1.27, 1.33, 1.1, -0.28, -0.33, 0.44, 1.64, 2.01, 1.0935596417251208, -1.28, -2.54, 2.47, -0.30330176161467987, -2.55, 0.02, -0.21, -1.57, -1.62, -0.86, 0.33, 0.69, -0.26, 1.24, 2.27, 2.63, 2.4, 1.0, 0.96, 1.73, 2.95, 3.32, 2.35, 0.05, 2.29, 0.89, -0.2, -0.38, -0.02, -0.3590429599640126, -0.23, -1.59, -1.63, -0.88, 0.31, 0.67, -0.28, -0.64, -0.13, -1.36, -1.41, -0.65, 0.54, 0.9, -0.05, -1.16, -1.49, 0.6360371788780403, -0.19681321637643204, 2.43, 0.11, 0.4, -0.56, 0.621720125812563, 0.2788101710076211, -0.07, 0.52, -2.58, 0.44, 0.18, 1.52, 0.08, -0.56, 0.66, 0.62, -0.22, -0.77, -0.39, -3.21, 1.61, -1.19, 2.93, 0.66, 1.02, 2.62, 1.25, 0.2871787775716348, 0.72, 1.93, 2.3, 1.33, -0.65, 1.3, 0.77, 1.98, 2.34, 1.38, 0.53, 1.2, 1.57, 0.61, -0.92, -1.33, -0.67, 0.36, -0.59, -0.18, -0.19, -0.05, 1.45, 0.07, -1.36, 0.17, -0.52, -1.02, -0.94, 0.05, 0.08, 0.2, -0.06, -0.09, -0.08, 0.0, -0.43, -0.33], ['300', -6.47, 0.31, -0.13877828437954126, 0.43, -2.0070209190089403, -1.78, -1.6358847420401708, -3.58, -3.0406219456129895, -3.25, 1.3803184712113286, -1.42, -1.12, 0.16, 0.4642857142857143, -1.42, -1.1328571428571428, -3.02, -2.95, -0.09, -4.0, -1.4, -0.15, -2.18, -3.75, -2.34, -4.37, -2.56, -2.26, -1.0, -0.7, -2.56, -2.32, -4.14, -4.07, -1.24, -5.11, -2.54, -1.31, -3.32, -2.98, -4.065063800783826, -1.650696767518196, 0.31, 1.6, 1.91, 0.01, 0.25, -1.62, -1.54, 1.36, -2.61, 0.02, 1.29, -0.77, -4.09, -3.98, -3.68, -3.18, -2.15, 1.29, 1.6, -0.3, -0.05, -1.92, -1.85, 1.05, -2.91, -0.29, 0.98, -1.08, -4.45, -3.4, 0.3, -1.57, -1.33, -3.17, -3.1, -0.24, -4.15, -1.56, -0.31, -2.34, -4.12, -8.17, 8.28, -3.6533017616146797, -1.86, -1.62, -3.46, -3.39, -0.54, -4.406129838415552, -1.85, -0.61, -2.63, -0.84, -1.86, 0.24, -1.63, -1.55, 1.35, -2.62, 0.01, 1.4211089783232642, -0.78, -0.07885812600098302, -1.79, -1.52427628811696, -1.7, -2.05, -1.33, -2.1, -1.87, -1.79, 1.2997126881055456, -2.86, -0.23, 1.03, -1.02, -1.71, -0.24, 0.07, 3.02, -1.01, 1.7857995496566925, 2.96, 0.86, -3.23, -3.6, 0.66, -1.84, -1.66, -0.82, -0.43, 1.21, -1.2, -0.63, -0.73, -3.45, 6.35, 3.32, 1.72, -3.28, -1.22, -5.09, 5.04, 5.08, -1.69, 1.83, -3.38, -5.16, 2.51, -6.26, 11.05, 4.21, 6.28, -6.34, -0.31, 2.95, -1.08, 1.59, 2.88, 0.78, -5.07, -3.16, -3.91, -1.32, -0.06, -2.1, 0.78, 2.7, 4.01, 1.89, -3.09, -3.61, -1.87, 1.27, -0.79, -1.63, -1.72, -3.37, 5.54, -1.99, -5.66, -2.46, -2.27, -3.1, -2.04, -1.99, -0.88, -1.28, -0.82, -1.52, -1.09, -3.48, -2.76, -1.66], ['301', -3.58, 0.25, 0.011221715620458745, 0.02, 0.0, 0.38, 1.26, 0.09, 0.39, -3.2192857142857143, -3.61, -3.79, -4.1, -3.94, -4.840234693877551, -2.04, -3.8342857142857145, -3.15, -5.368518140589569, -2.7192857142857143, -3.62, -3.58, -3.63, -3.85, 0.67, -0.12, 0.4326583949931125, -0.18, -0.4891666666666667, -0.34, -1.44, 1.63, -0.25, 0.48, -1.84, 0.92, -0.01, 0.04, -0.02, -0.25, 0.9, 0.35, 0.59, -0.32, -0.15, -1.26, 1.82, -0.07, 0.66, -1.66, 1.1, 0.18, 0.22, 0.16, -0.06, 0.69, -0.15, 0.3, 0.53, 0.92, 0.17, -0.94, 2.15, 0.25, 0.99, -1.34, 1.43, 0.5, 0.8674648526077097, 0.49, 0.26943877551020406, -0.21, 0.75, -1.11, 1.98, 0.09, 0.82, -1.5, 1.26, 0.33, 0.37, 0.32, 0.1435596417251207, 0.42, 1.25, -1.27, 1.87, 3.12, 1.2, 1.95, -0.4, 2.583744771101914, 1.45, 1.5, 1.44, 1.21, -2.12, -1.1326334687834372, -1.86, -1.14, -3.41, -0.7, -1.62, -1.57, -1.63, -1.85, -0.07, -1.22, 0.0, 0.5815981806829015, 0.5351790696343399, 0.54, 0.66, 0.73, -1.59, 1.17, 0.24, 0.29, 0.23, 0.01, 0.41, -0.07, -2.3, 0.44, -0.3013969800041226, -0.44, -0.5, -0.72, 0.77, 0.73, -0.11, 0.48, -5.94, 0.09, -0.0642857142857143, -1.24, 1.27, 0.61, 0.53, -0.68, 1.03, -1.04, -0.52, -1.8, 0.46, 1.52, -1.59, -1.53, 0.573290804863853, -1.94, 1.04, 0.27, -0.14, 1.84, -1.28, -1.29, -2.02, -0.99, 2.28, 2.81, 1.86, 1.91, 1.85, 1.62, 1.57, -0.51, -0.9164625850340137, -0.87, -0.93, -1.15, 0.41, 0.04, -0.01, -0.24, 0.43, 0.32, 0.37, -0.06, -0.28, 0.52, 0.52, 0.11257604962387836, -0.91, 0.38, 1.01, 0.68, 0.7, 0.43, -0.22, 0.44, 0.47, 0.47, 0.63, 0.57, 0.65, -0.46, 1.23, 0.49301677370739727], ['302', 0.94, 0.48, 0.02, -0.18, 1.22, 0.5, 0.6141152579598291, 0.8017205965359587, 0.79, 2.72, 1.66, 2.62, 1.87, 3.06, 1.7, 2.18, 2.55, 2.72, 2.79, 2.0, 2.94, 1.66, 2.33, 2.05, 0.64, 0.16, 1.0726583949931126, 0.94, 0.2, 1.37, 0.04, 0.51, 0.87, 1.04, 1.11, 0.33, 1.25, 0.0, 0.66, 0.38, 0.26, 0.75, 0.1, -0.73, 0.42, -0.9, -0.43, -0.07, 0.1, 0.17, -0.61, 0.3, -0.94, -0.28, -0.56, 1.53, 0.7, 0.8078279728097839, 0.58, 0.9192452470658775, 1.17, -0.16, 0.3, 0.67, 0.84, 0.91, 0.13, 1.213421154242583, -0.2, 0.46, 0.18, 0.54, -0.32, -1.32, -0.85, -0.49, -0.32, -0.01252355184498033, -1.03, -0.12, -1.35, -0.7, -0.98, 1.15, 1.18, -1.16, 1.01, 0.47, 0.84, 1.01, 1.07, 0.29, 1.21, -0.04, 0.62, 0.34, 0.59, 0.53, 0.36, 0.53, 0.6015238095238095, -0.18, 0.74, -0.51, 0.15, -0.13, 0.03, 0.44, -1.08, 0.49, 0.52, 0.41, 0.17, 0.17, 0.24, -0.54, 0.37, -0.87, -0.21, -0.49, 1.0, 0.0, 0.07, -0.71, 0.21, -1.03, -0.38, -0.66, -0.19, -0.38, -0.1, 0.37, 1.82, 0.28, 0.2, -0.1, 0.07, 0.03, 0.22, 0.69, -1.3194817511227284, -1.0, -0.47, 0.54, 0.52, 1.43, -1.43, -1.54, 0.48, -0.09, 0.95, 1.81, -0.92, 0.46, -0.27, -0.36, -0.46, 1.4, -0.07, -0.7751904761904762, 0.14, -1.1, -0.45, -0.73, 1.45, 0.71, 0.92, -0.33, 0.33, 0.05, -0.21, -1.24, -0.58, -0.86, 0.68, 1.1684535464535466, 1.04, 0.66, 0.38, 0.47, 0.5443963012752908, 0.88, -3.24, -0.48, 3.7892806122448977, 0.49, 0.83, 0.38, -0.28, 0.59, 0.0, 0.7, 0.34, 0.83, 0.66, 0.0, 0.74, -0.21], ['303', -3.2, 0.32, 0.05122171562045875, 0.01, 0.26, 0.2, 0.45, 0.72, 0.63, 0.68, 0.47, -0.27, -1.02, 0.52, -0.54, 1.38, 0.95, 0.71, -1.66, 1.19, 0.77, 0.08, 0.04, -0.47, 1.3, 0.32937141458889196, 0.21, -0.73, -1.48, 0.05, -1.0, 0.9, 0.48, 0.24, -2.12, 0.72, 0.3, -0.39, -0.42, -0.94, 0.7, 0.0, 0.95, -0.76, 0.79, -0.27, 1.65, 1.22, 0.98, -1.4, 1.46, 1.04, 0.34, 0.31, -0.21, -0.04, 0.44, 0.51, 1.02, 1.72, 1.6631047225355606, 0.49, 2.42, 1.99, 1.75, -0.64, 2.23, 1.81, 1.11, 1.08, 0.56, 0.79, 0.16, -1.05, 0.85, 0.43, 0.19, -2.17, 0.67, 0.25, -0.44, -0.48, -0.99, 0.01, 1.69, -1.79, 1.23, 1.9205204081632652, 1.5017857142857143, 1.25, -1.13, 1.73, 1.31, 0.62, 0.58, 0.06, -1.99, -0.68, -0.42, -0.66, -3.0, -0.18, -0.6, -1.28, -1.32, -1.82, -0.06, -0.48063179677465384, 3.25, 0.46, 0.0, -0.02, -0.18819052351387078, -0.24, -2.58, 0.24, -0.17, -0.86, -0.9, -1.3514153161169342, 0.62, -0.02, -2.35, 0.48, 0.06, -0.5042004503433073, -0.66, -1.17, 0.76, 0.84, 0.16, 0.55, -5.57, 0.13, 0.14, -0.98, 1.1117201258125629, 0.5188101710076211, 0.0, 1.9661635321120494, 0.89, -0.95, -0.46, -1.65, 0.44, 1.42, -1.43, -1.32, 0.46, -1.29, 0.9498783572413152, 0.32, -0.16, 0.6607142857142857, -1.85, -0.45, -0.65, -0.9, 2.38, 2.9, 2.47, 1.8172970521541951, 1.73, 1.21, 1.37, -0.5, -0.41, -1.1, -1.13, -1.64, -0.09, -0.69, -0.72, -1.23, 0.57, 0.43, 0.61, -0.03, -0.55, 0.43, 0.45, 0.74, -1.95, 2.25, 2.01, 0.24, 0.9, 0.64, -0.51, 0.0, 0.1, 0.3, 0.42, 0.31, 1.16, -0.57, 0.94, 0.74], ['304', -2.26, 0.35, 0.11, 0.13, -0.39, -0.1, -1.0158847420401709, -0.14, -0.73, -1.34, 0.16, -0.54, -1.05, -0.83, -1.73, -0.87, -1.67, -1.51, 2.59, -1.51, -1.74, -0.96, -1.62, -1.48, 0.6, -0.38, -1.4673416050068875, -0.7, -1.21, -0.99, -1.8321800287049088, -1.03, -1.83, -1.67, 2.42, -1.67, -1.9, -1.12, -1.78, -1.64, -0.2, -1.94, -0.81, -0.52, -0.29, -1.2, -0.33, -1.14, -0.98, 3.14, -0.98, -1.21, -0.32613444352099813, -1.09, -0.94, -0.14, -0.07, 0.59, -0.73, -0.29, 0.22, -0.69, 0.19, -0.63, -0.46, 3.68, -0.46, -0.7, 0.1, -0.57, -0.43, 0.48, -0.51, -0.91, -0.04, -0.85, -0.69, 3.45, -0.68, -0.92, -0.13, -0.79, -0.65, -1.23, 0.66, -0.6, 0.4366982383853202, 0.88, 0.06, 0.23, 4.4, 0.23, -0.01, 0.79, 0.12, 0.26, 0.52, -0.48, -0.82, -0.65, 3.48, -0.65, -0.89, -0.09, -0.76, -0.62, -0.06, -0.56, -0.04, 0.07, 0.07517906963433994, 0.1, 0.34, 0.17, 4.33, 0.17, -0.07, 0.73, 0.06, 0.2, -0.37, 0.17, 4.16, 0.0, -0.24, 0.56, -0.11, 0.03, -0.04, -0.02, 0.29, 0.19, 1.57, -0.01, 0.0, 0.04, 0.0, -0.03, -0.34, -1.13, -0.25, -0.15, -0.07, -1.18, -0.21, 0.17, -0.29, -0.19, 0.05, 0.03, 0.1, -1.69, 0.89, 1.01, -2.18, -0.71, -0.96, 0.31, -3.83, -3.99, -4.22, -3.45, -4.1, -3.96, 0.17, 0.17, -0.24, 0.56, -0.11, 0.03, 0.41, 0.8, 0.13, 0.27, -0.77, -0.97, -0.39, -0.67, -0.53, 0.07, 0.09, -0.13, -1.16, -0.38, 1.16, -0.39, 0.8, 0.28, 0.14, 0.05, -0.27, 0.29, -0.93, 0.15, 0.14, 1.52, 0.29, 0.18], ['305', -1.99, -0.33, 0.05122171562045875, 0.0, -0.04, -0.11158037632624052, 0.44, -0.59, -0.31, -0.95, -0.91, -1.6, -0.29, -0.34, -1.01, -0.61, -0.52, -0.83, -3.2, -1.16, -1.23, -1.57, -1.11, -0.66, -0.28, -0.52, -0.00734160500688754, -0.69, 0.63, 0.58, -0.1, 0.3, 0.4, 0.08, -2.31, -0.25, -0.32, -0.66, -0.2, 0.25, -0.49, -1.0050638007838266, 0.65, 1.33, 1.28, 0.6, 1.0, 1.1, 0.78, -1.63, 0.45, 0.37, 0.03, 0.5, 0.95, -0.54, -0.59, -0.98, -0.54, -0.67, -0.05, -0.7192006802721088, -0.33, -0.23, -0.55, -2.92, -0.87, -0.94, -1.29, -0.82, -0.38, -0.1, -0.62, -0.67, -0.27, -0.18, -0.49, -2.87, -0.82, -0.89, -1.23, -0.77, -0.32, -0.38, 0.21, -0.25, 0.05, 0.4, 0.5, 0.18, -2.21, -0.15, -0.22, -0.57, -0.1, 0.35, -2.26, -0.26263346878343713, 0.1, -0.22, -2.6, -0.55, -0.62, -0.96, -0.49, -0.05, -0.08, -0.38, 0.61, -0.4, 0.08, -0.88, -0.44, -0.32, -2.7, -0.64, -0.72, -1.06, -0.59, -0.15, 0.66, -0.06692325186963273, -2.39, -0.33, -0.4, -0.74, -0.28, 0.17, 0.13, 0.0, -0.06, -0.26, -6.67, 0.1, 0.0, 2.9, -2.84, -1.44, 0.75, -0.17, -0.32, 0.8, 0.42, -1.0, -0.07, -1.21, 1.16, 1.19, -0.356709195136147, 4.22, -0.78, 0.49, -0.23, -1.25, 0.1527091836734694, 0.83, 1.37, 0.39, 2.32, 2.11, 2.04, 1.68, 2.16, 2.62, -1.24, 0.21, -0.07, -0.42, 0.05, 0.5, 0.28, -0.35, 0.12, 0.57, -0.29, -0.38, 0.63, 0.47, 0.92, -0.39, -0.39, -0.53, 0.27, 0.46, -0.33, -0.05, -0.2, 0.15, 0.5227868514969317, 0.2, -1.35, -0.62, 0.21, -0.13, -0.3, 0.62, -0.44, -0.24], ['306', 4.25, 0.14, 0.02, -0.07, 0.61, -0.05, 0.07, 0.07, 0.4, -0.10291156462585038, -0.81, -1.16, 1.05, -1.31, -1.4757142857142858, -2.6, -0.61, -0.56, -2.03, -0.9974455782312925, -0.03, -0.48, -0.75, -0.2, 1.0, 1.099371414588892, 0.3026583949931125, -0.35, 1.88, -0.5, -0.68, -1.8, 0.18, 0.25, -1.22, -0.52, 0.79, 0.33, 0.07, 0.62, 0.84, 0.7549361992161734, 0.62, 2.24, -0.15, -0.33, -1.46, 0.53, 0.61, -0.88, -0.17, 1.15, 0.68, 0.42, 0.97, 0.64, 0.42, -0.21, 0.39, -1.58, -2.34, -2.51, -3.61, -1.67, -1.59, -3.04, -2.35, -1.06, -1.52, -1.78, -1.24, 0.12, 0.77, -0.18, -1.31, 0.68, 0.76, -0.73, -0.02, 1.3, 0.84, 0.57, 1.12, 0.28, 0.43, -0.44, 0.95, -1.13, 0.86, 0.94, -0.55, 0.16, 1.48, 1.01, 0.75, 1.3, 4.59, 2.11, 2.01, 2.09, 0.6255850340136054, 1.31, 2.64, 2.17, 1.9, 2.46, 0.01, 2.11, -1.12, -0.04, 0.02, -0.14, 0.09, 0.08, -1.4, -0.69, 0.62, 0.16, -0.11, 0.44, -0.21, 0.01, -1.47, -0.77, 0.54, 0.20579954965669267, -0.19, 0.36, 0.49, 0.55, -0.07, -0.04, 13.52, 0.04, 0.05, 0.77, -0.75, -0.38, -1.19, 1.26, -1.58, 0.12, 0.03, 2.31, -0.3, -0.11, 0.0, 0.13, -0.02, 1.27, -0.07, -0.24, 0.1547652642842468, 0.26, 1.2006513605442177, -0.17, -0.29, 1.61, 1.51, 0.71, 2.04, 1.57, 1.31, 1.86, -0.08, 0.79, 1.32, 0.85, 0.59, 1.14, -0.52, -0.46, -0.72, -0.18, 0.44, 0.25, -0.06, -0.26, 0.28, 0.07208003431405688, -0.05, 0.14, 0.67, -0.89, -0.59, 0.07, 1.19, 0.2, 0.55, 0.34, -0.16, -0.86, -0.29, -0.57, -0.35, 3.1202406343656346, 1.93, 0.62], ['307', 5.131428571428571, -6.06, -2.47, 0.34, -2.15, -3.84, -4.15, -7.21, -5.86, -4.56, 4.350608843537414, -1.3, 2.46, 4.17, 1.3371428571428572, -7.799285714285714, 1.19, -0.37942857142857145, -4.49, -0.45, -4.69, 1.9, 3.57, 0.67, -6.37, -4.4, -8.52, -5.4, -1.8, -0.16, -2.89, -11.63, -3.02, -4.52, -8.46, -4.59, -8.65, -2.34, -0.73, -3.52, -4.22, -7.35, -3.3, 3.8, 5.54, 2.65, -6.568956349206349, 2.52, 0.93, -3.24, 0.8607142857142857, -3.44, 3.24, 4.93, 1.99, -5.57, -5.6499999999999995, -5.78, -5.81, -6.85, 1.67, -1.11, -9.799999999999999, -1.24, -2.77, -6.78, -2.84, -6.98, -0.4903418367346939, 1.09, -1.75, -8.72, -8.38, -2.73, -11.426705782312926, -2.86, -4.36, -8.32, -4.44, -8.51, -2.18, -0.57, -3.3064403582748794, -7.98, -22.21, 22.31, -5.8, -9.0, -0.13, -1.67, -5.74, -1.75, -5.93, 0.57, 2.22, -0.64, 2.51, 3.52, 10.378571428571428, 8.05, 3.59, 7.97, 3.37, 10.52, 12.33, 9.18, -4.35, 3.5, -7.25, -4.92, -5.58, -4.78, -5.68, -1.55, -5.62, -1.62, -5.81, 0.7, 2.36, -0.52, -6.05, -4.2, -4.13, -0.08, -4.33, 2.28, 4.042857142857143, 1.05, -8.66, -5.98, -0.75, -6.16, 5.1, -8.9796768707483, -7.28, 9.334285714285715, -8.66, -4.31, -5.08, -12.13, 8.36, 10.021428571428572, 4.954547619047619, 2.635221088435374, -3.6, -15.56, 16.117142857142856, 14.994285714285715, -4.92, 13.507142857142858, -9.85, -5.21, 2.63, -17.13, 28.92, 11.37, 17.15, -8.37, -0.07, 4.23, -0.21, 6.69, 8.45, 5.4, -14.83, -4.12, -4.26, 2.36, 4.040857142857143, 1.7685714285714287, 0.14, 6.91, 8.67, 5.8585714285714285, -6.05, -6.97, -6.33, 1.64, -1.21, -4.95, -5.32, -7.24, 14.53, -7.55, -14.36, -5.76, -6.64, -7.85, -2.81, -5.21, -4.11, -2.4, -3.82, -3.93, -5.19, -6.76, -9.7, -6.94], ['308', 1.31, 0.68, -0.038778284379541256, 0.08, 0.25, 1.05, 0.8741152579598291, 0.41, 1.15, 1.37, -0.28, 0.58, 2.37, 1.74, 0.8, -0.09, 0.91, 1.21, 2.21, 0.4, 1.497335482087359, 0.35, 0.41, 0.25, 1.0, 0.739371414588892, 1.65, 0.86, 2.65, 2.02, 1.08, 0.19, 1.19, 1.49, 2.5, 0.68, 1.74, 0.63, 0.69, 0.53, 0.3374684253532108, 1.0249361992161734, 0.78, 1.78, 1.15, 0.22, -0.67, 0.33, 0.62, 1.62, -0.1788095238095238, 0.87, -0.13613444352099813, -0.17, -0.33, -0.12, 0.92, 0.46, 1.66, -0.98, -0.62, -1.53, -2.4, -1.43, -1.13, -0.15, -1.92, -0.726578845757417, -1.97, -1.92, -2.07, 1.75, -0.37, -0.92, -1.8, -0.82, -0.52, 0.47, -1.31, -0.27, -1.36, -1.31, -1.46, 1.15, 3.06, -3.02, 0.56, -0.88, 0.11, 0.41, 1.4, -0.39, 0.66, -0.44, -0.39, -0.54, 4.41, 1.46, 1.0, 1.3, 2.31, 0.49, 1.55, 0.44, 0.5, 0.34, 0.29, 1.55, 1.52, 1.08, 1.03, 0.97, 0.46, 0.3, 1.29, -0.5, 0.55, -0.55, -0.42401213658444736, -0.5914153161169343, 0.94, 0.16, 0.99, -0.8, 0.25, -0.85, -0.79, -0.95, 0.94, 0.51, 0.11, 0.48, 8.924476190476192, -0.05, 0.14, -1.53, 1.54, 0.8, 0.16406627346681524, 0.96, -1.86, -2.06, -1.05, 0.7, 1.61, 2.95, -2.85, -3.16, 1.02, -2.23, 2.08, -0.27, 0.13, 1.4, -4.23, -0.93, -1.45, 1.81, -0.83, -1.77, -0.74, -1.82, -1.77, -1.92, 3.2, 0.96, 1.05, -0.05, 0.01, -0.15, -0.09, -1.09, -1.04, -1.19, 1.09, 1.43, 1.01, 0.06, -0.1, 1.05, 0.89, 0.64, -2.14, 0.9, 2.05, 0.26, 0.57, 0.96, -0.16, 0.41, 1.0, 1.11, 2.46, 1.8, 1.195957527023814, -1.35, 0.46, 0.26], ['309', -5.53, 1.06, -0.31877828437954125, -0.4078571428571427, 1.53, 3.39, 3.33, 4.95, 4.03, 3.810714285714286, -0.99, 0.7, -0.46, -0.3, -0.14, 7.0, -0.05, 2.95, 0.44, 1.05, 3.87, -0.6069251700680272, -1.14, -0.28, 4.75, 2.75, 4.882658394993112, 1.8284685082657772, 0.53, 0.69, 0.86, 8.07, 0.95, 3.98, 1.44, 2.06, 4.91, 0.46, -0.15, 0.71, 3.01, 5.28, 3.090204081632653, -1.15, -1.0, -0.83, 6.26, -0.75, 2.24, -0.26, 0.35, 3.15, -1.31, -1.8142857142857143, -0.6691712018140588, 3.26, 2.6, 4.81, 5.2, 4.29, 0.16, 0.33, 7.5, 0.42, 3.43, 0.91, 1.52, 4.35, -0.15, -0.68, 0.18, 6.37, 4.13, 0.17, 7.33, 0.26, 3.27, 0.75, 1.36, 4.19, -0.31, -0.84, 0.02, 4.5650595238095235, 12.41, -13.77, 3.95, 7.15, 0.09, 3.09, 0.58, 1.19, 4.01, -0.39428571428571424, -1.0, -0.15, -0.64, -2.98, -6.59, -3.777880952380952, -6.13, -5.56, -2.93, -7.12, -7.61, -6.158571428571428, 0.62, -2.96, 3.54, 3.91, 4.11, 3.69, 3.86, 3.0, 0.49, 1.1105357142857144, 3.92, -0.57, -0.4614285714285715, -0.23, 4.19, 0.83, -2.44, -1.84, 0.899562358276644, -3.46, -3.98, -3.14, 4.43, 3.12, -2.16, 4.05, -1.49, 2.12, 1.03, -8.34, 8.35, 4.17, 3.05, 4.38, -4.961283898641042, -7.75, -3.85, -2.7, 2.93, 11.89, -11.69, -11.55, 3.93, -12.34, 7.81, 1.92, -1.19, 11.31, 20.58, 1.91, 1.86, 5.47, 3.36, 0.61, 3.42, -1.05, -1.5687142857142857, -0.72, 11.36, 2.73, 2.79, -1.65, -2.17, -1.33, -0.06, -4.32, -4.587142857142857, -4.0, 4.06, 4.39, 4.45, -0.53, 0.33, 3.84, 3.81, 5.13, -3.24, 3.88, 3.5, 4.02, 4.42, 5.01, 0.87, 3.6, 3.82, 2.5, 3.2409523809523813, 3.7, 4.11, 3.75, 6.34, 4.26], ['310', 11.188571428571429, 0.19, 0.13122171562045873, 0.05, 1.67, 0.84, 1.8641152579598292, 2.28, 2.08, 1.7370884353741496, -1.34, -0.89, -0.33, -0.7, -0.73, 0.23, 0.13, 0.71, -0.73, -0.43, 2.42, 1.76, 0.38, 0.07, 2.53, 1.98, 2.66, 0.46, 1.03, 0.65, 0.62, 1.59, 1.49, 2.08, 0.6377619047619048, 0.92, 3.81, 3.15, 1.75, 1.43, 1.11, 3.34, 2.19, 0.5736589811608608, 0.19, 0.16, 1.13, 1.02, 1.61, 0.16, 0.46, 3.34, 2.68, 1.28, 0.97, 1.53, 1.47, 1.36, 1.85, 1.62, -0.38, -0.4, 0.55, 0.45, 1.04, -0.3990476190476191, -0.10976190476190477, 2.75, 2.1, 0.7127347454133168, 0.4, 2.45, 2.0, -0.03, 0.94, 0.83, 1.4232142857142855, -0.02, 0.27, 3.14, 2.5614285714285714, 1.09, 0.78, 2.37, 2.69, -2.72, 2.03, 0.96, 0.86, 1.44, 0.0, 0.3, 3.17, 2.51, 1.572517006802721, 0.81, 4.31, 1.06, -0.1, 0.48, -0.95, -0.66, 2.19, 1.5563946608946608, 0.15, -0.15, 0.7, 1.09, 0.8, 0.91, 0.86, 0.995673518650032, 1.16, 0.5813469387755101, -0.85, -0.56, 2.29, 1.63, 0.25, -0.05, -0.24, 0.58, -1.1663144197072766, -1.13, 1.709562358276644, 1.05, -0.32, -0.63, 1.16, 1.14, 0.31603717887804045, 0.91, 8.52, 0.4, 0.35, -1.88, 1.961720125812563, 0.94, 0.81, 1.7, -3.49, -1.84, -0.9, 5.59, 0.36, 2.73, -2.76, -2.69, 0.9, -2.83, 1.79, 0.25, -0.13, 3.5, -4.68, -2.35, -3.46, 3.46, 2.03, 0.3, 3.17, 2.51, 1.12, 0.8, 2.7631678995607567, 1.8643542330685188, 2.86, 2.21, 0.82, 0.51, -1.11, -0.64, -1.99, -2.29, 2.340135138670853, 2.09, -0.47, -1.36, -1.66, 1.03, 0.91, 2.18, -2.31, 0.87, 2.31, 1.52, 1.4211825396825397, 0.9, -0.31, 1.03, 0.81, 0.27, 0.22, 0.84, 1.21, 3.31, 2.37, 1.25], ['311', 8.06, 0.48, 0.19, 0.02, 0.38, 1.08, 1.02, 2.33, 1.3, 1.8, 0.74, 0.38, -0.15, -0.4, -0.69, -0.2792857142857143, 0.44, 1.5505714285714287, 3.76, 0.9, 2.31, 0.7230748299319728, 0.15, 0.81, 1.46, 1.58, 1.05, -0.24153149173422278, -0.89, -1.13, -1.42, -1.02, -0.3, 0.8, 3.0, 0.16, 1.56, -0.02, -0.59, 0.07, 1.53, 1.4749361992161734, 1.41, -0.53, -0.78, -1.06, -0.66, 0.06, 1.16, 3.37, 0.52, 1.92, 0.34, -0.23, 0.43, 1.8, 1.42, 1.44, 1.76, 1.95, -0.25, -0.53, -0.13, 0.6, 1.7, 3.92, 1.06, 2.47, 0.88, 0.3, 0.96, 2.36, 2.21, -0.27535714285714286, 0.12, 0.85, 1.95, 4.18, 1.31, 2.72, 1.13, 0.55, 1.21, 1.19, 4.56, -4.474, 2.5008709226619943, 0.41, 1.14, 2.25, 4.48, 1.6016746031746032, 3.02, 1.42, 0.84, 1.5, 4.2, 2.08, 0.73, 1.83, 4.06, 1.19, 2.6, 1.01, 0.43, 1.09, 0.4, 2.02, 1.81, 1.17, 1.21, 1.14, 1.35, 1.1, 3.31, 0.46, 1.86, 0.28, -0.29, 0.36, 1.08, 0.25, 2.18, -0.64, 0.75, -0.6842004503433073, -1.38, -0.73, 1.52, 1.1, 0.29, 0.88, 12.64, 0.13, 0.15, -2.44, 2.43, 1.22, 0.39, 2.35, -1.82, -2.41, -1.17, 4.1, 0.813079789868779, 3.57, -3.78, -3.6, 1.18, -3.78, 2.38, 1.98, -0.98, 4.09, -10.73, -2.76, -4.18, 1.8, -1.9, -2.76, -1.4, -2.93, -3.49, -2.85, 3.57, 0.89, 1.5441925889236814, -0.18, -0.75, -0.09, -0.5, -1.55, -2.11, -1.47, 1.29, 1.25, 1.07, -0.57, 0.08, 1.22, 1.16, 2.13, -5.02, 1.61, 5.13, 2.2, 1.24, 1.65, 0.66, 0.79, 1.21, 1.34, 0.76, 0.81, 0.98, 4.1, 1.78, 1.14], ['312', -3.94, -0.24, -0.08877828437954126, 0.16, -1.47, -1.59, -2.3, -1.91, -2.11, -1.28, 1.28, 0.78, -0.21, 1.17, 0.29, -0.15, -0.49, -0.97, -3.37, 2.03, -1.78, -0.34, 0.4, -0.53, -1.42, -1.58, -2.53, -0.49, -1.47, -0.11, -0.98, -1.41, -1.75, -2.22, -4.6, 0.74, -3.02, -1.6, -0.87, -1.79, -0.81, -2.935063800783827, -2.0497959183673466, -0.98, 0.39, -0.49, -0.92, -1.26, -1.73, -4.12, 1.24, -2.54, -1.11, -0.38, -1.31, -0.6, -0.89, -2.4, -1.95, -1.08, 1.38, 0.49, 0.06, -0.28, -0.76, -3.17, 2.24, -1.58, -0.13, 0.61, -0.33, -2.42, -2.43, -0.88, -1.31, -1.65, -2.12, -4.5, 0.85, -2.92, -1.49, -0.77, -1.69, -2.57, -4.44, 4.44, -1.57, -0.4294795918367347, -0.77, -1.25, -3.65, 1.74, -2.06, -0.62, 0.11, -0.82, -2.25, -1.062633468783437, -0.34, -0.82, -3.23, 2.18, -1.64, -0.19, 0.6911089783232642, -0.39, -0.33, -1.13, -1.01, -1.22, -1.48, -0.88, -0.8, -0.48, -2.9, 2.54, -1.3, 0.15, 0.89, -0.04, -0.94, -0.32, -2.43, 3.03, -0.82, 0.64, 1.38, 0.44, -1.47, -1.35, 0.08, -0.8, -6.76, -0.25, -0.34, 0.98, -0.96, -0.47, -0.69, -2.77, 6.59, 2.45, 1.23, -1.93, -0.82, -3.63, 3.7, 3.67, -1.22, 1.5, -2.44, -2.18, 1.1, -2.44, 11.59, 1.62, 2.43, -6.33, 2.16, 5.6, 1.8472132867132867, 3.14, 3.9, 3.1057617128436457, -3.65, -3.25, -3.5958074110763185, -2.32, -1.6, -2.52, 0.5, 1.47, 2.22, 1.27, -1.8998648613291471, -2.41, -0.95, 0.74, -0.2, -1.23, -1.14, -1.87, 6.4, -0.53, -6.63, -2.63, -2.38, -1.68, -0.93, -0.8599225974772193, -0.58, -1.2, -0.84, -1.14, -0.75, -2.85, -2.9, -0.5], ['313', 7.854285714285714, 0.59, 0.22122171562045873, 0.48, 0.78, 0.53, 0.5641152579598292, 1.04, 0.89, 1.69, 0.78, 0.46, 0.68, 0.26, 0.44, -0.38, 0.51, 0.94, -2.96, 0.87, 2.01, 0.49104421768707485, 1.26, 1.0, 2.37, 1.29, 0.9, -0.32, -0.1, -0.52, -0.34, -1.15, -0.27, 0.16, -3.7, 0.09, 1.22, -0.33, 0.48, 0.26384172319783916, 0.7674684253532109, 0.55, 1.22, 0.22, -0.2, -0.02, -0.83, 0.05, 0.48, -3.4, 0.41, 1.54, -0.01, 0.8971428571428572, 0.54, 0.86, 2.33, 0.88, 0.48, 1.0, -0.42, -0.24, -1.05, -0.17, 0.26, -3.61, 0.19, 1.32, -0.23, 0.57, 0.32, 0.64, 1.43, 0.18, -0.63, 0.25, 0.68, -3.2, 0.61, 1.75, 0.19, 1.0, 0.74, 0.88, 1.49, -1.46, 1.24, -0.81, 0.07, 0.5, -3.38, 0.43, 1.56, 0.01, 0.82, 0.56, 4.91, 2.07, 0.89, 1.32, -2.59, 1.25, 2.4, 0.83, 1.64, 1.39, 0.7, 2.09, 2.26, 0.75, 0.53, 1.2, 1.17, 0.43, -3.45, 0.35, 1.49, -0.06, 1.3685714285714285, 0.49, 1.21, 0.74, -3.86, -0.07, 1.06, -0.49, 0.32, 0.06, 0.88, 0.8, 0.71, 0.97, 14.397619047619049, 0.34, 0.14, -2.72, 2.72, 1.36, 0.86, 1.84, -1.62, -1.52, -0.78, 3.829285714285714, 0.69, 2.5, -2.4, -2.27, 0.76, -4.18, 1.52, -1.74, 0.79, 3.48, -6.48, -2.48, -3.45, 1.66, 4.78, 3.94, 5.11, 3.5, 4.34, 4.08, 2.3, 0.81, 1.13, -0.42, 0.39, 0.13, -0.31, -1.53, -0.73, -0.99, 1.010135138670853, 0.6, 1.24, 0.81, 0.55, 0.82, 0.83, 1.02, -3.31, 2.33, 3.4, 1.18, 0.7, 0.42, -0.25, 1.1, 0.97, 0.78, 0.930952380952381, 0.64, 0.68, 3.04, 2.171595238095238, 0.98], ['314', -0.31, -0.08, 0.0, 0.02, -1.44, 0.08, -0.16, -0.41, -0.3, 0.31, 0.41, 0.64, 0.42, 1.31, 0.19, 0.22, 0.41, 0.14, 4.89, 4.01, -0.01, -0.23, -0.55, -0.5, -0.46, -0.49, -0.1, 0.23, 0.01, 0.9, -0.22, -0.19, -0.01, -0.27, 4.46, 3.58, -0.42, -0.63, -0.95, -0.91, 0.52, 0.014936199216173434, -0.33, -0.22, 0.67, -0.44, -0.42, -0.23, -0.5, 4.22, 3.35, -0.65, -0.86, -1.18, -1.14, -0.27, -0.3, -0.22, -0.15, -0.11, 0.89, -0.22, -0.2, -0.01, -0.28, 4.46, 3.58, -0.256578845757417, -0.64, -0.96, -0.91, 0.2, -0.99, -1.1, -1.08, -0.9, -1.16, 3.533095238095238, 2.66, -1.31, -1.52, -1.83, -1.79, -0.29, 2.34, -2.29, 0.11, 0.02, 0.6399013605442176, -0.06, 4.69, 3.81, -0.2, -0.42, -0.74, -0.69, -1.4, 0.09, 0.19, -0.08, 4.66, 3.79, -0.23, -0.44, -0.76, -0.72, 0.27, 0.06, 3.96, 0.32, 0.26, 0.36, -0.1, -0.27, 4.47, 3.59, -0.41, -0.63, -0.95, -0.9, 0.49, 0.17, 4.75, 3.87, -0.15, -0.36, -0.68, -0.64, 1.31, 0.59, -0.07, 0.08, -4.04, 0.05, 0.0, -0.69, 0.69, 0.39, -0.32, -0.99, 6.95, -0.53, -0.29, -0.15, 0.49, 1.0, -0.95, -0.95, 0.32, -1.09, 0.62, 0.19, -0.1, -0.34, 0.68, 0.15, 0.33, -7.06, -4.37, -0.84, -4.67, -4.88, -5.18, -5.14, 0.94, -3.56, -3.87, -4.07, -4.38, -4.34, 0.32, -0.22, -0.54, -0.49, -0.39, -0.39, 0.54, -0.32, -0.28, 0.31, 0.27, -0.31, 0.01, 2.34, -0.06, -0.49, -1.29, 0.86, 0.05, 0.22, 0.34, 0.47, 0.48, 0.62, 0.895957527023814, -1.11, -2.21, 0.43], ['315', 0.43, -0.45, 0.17, -0.17, 0.25, 0.49, -1.325884742040171, 0.63, 0.92, -0.05, -1.52, 0.64, -1.2, -0.59, -1.39, 0.14, -0.6, -0.21, -0.34, -0.34633673469387755, 0.37, -0.33, -1.09, -0.28, 0.84, 0.32, 1.49, 2.2, 0.33, 0.94, 0.13, 1.69, 0.94, 1.34, 1.2, 1.17, 1.92, 1.21, 0.43, 1.26, 0.3874684253532108, 1.66, -0.4906967675181959, -1.83, -1.23, -2.02, -0.5, -1.23, -0.84, -0.98, -1.01, -0.27, -0.96, -1.73, -0.92, 1.1, 0.24, 0.69, 1.66, 1.16, 0.61, -0.2, 1.35, 0.61, 1.0, 0.86, 0.84, 1.58, 0.88, 0.1, 0.93, -0.35, 0.54, -0.81, 0.73, -0.01, 0.39, 0.25, 0.22, 0.96, 0.27, -0.51, 0.31, 1.7289098639455782, 3.03, -2.88, 1.36, 1.55, 0.81, 1.2, 1.06, 1.04, 1.78, 1.08, 0.3, 1.1840077275244505, 0.05, -0.19, -0.74, -0.3269047619047619, -0.48, -0.51, 0.23, -0.46, -1.23, -0.42, 0.19, -0.17, 2.56, 0.67, 0.71, 0.705673518650032, 0.55, 0.39134693877551024, 0.26, 0.23, 0.97, 0.27, -0.5, 0.32, 0.35, 0.16, -0.14, -0.17, 0.57, -0.12, -0.89, -0.07, 1.31, 1.14, -0.36, 0.38, 0.13, 0.04, 0.14, -1.7, 1.69, 0.84, 1.12, 1.38, -0.7, -1.31, -0.66, 0.23, 0.32, 2.12, -1.96, -2.08, 0.67, -2.47, 1.35, 0.95, -0.53, 1.63, -4.33, -1.04, -1.56, 0.74, 0.29, -0.03, 0.71, 0.02, -0.75, 0.06, 2.11, 0.32, 0.74, 0.05, -0.73, 0.09, -0.42, -0.69, -1.46, -0.64, 0.94, 1.51, 0.28, -0.77, 0.05, 0.78, 0.63, 0.64, -2.15, 1.48, 2.35, 0.54, 0.7, 1.06, 0.82, 0.53, 0.77, 0.67, 0.26, 0.62, 0.23, 0.23, 0.14, -0.08], ['316', 0.58, 1.27, -0.20877828437954127, 0.12, 0.99, 1.48, 1.2741152579598292, 1.58, 1.73, -0.51, -2.07, -2.68, -1.32, -1.97, -1.1, -2.041439909297052, -2.97, -1.49, -1.21, -0.93, 0.14733548208735894, -1.92, -1.9, -3.03, 2.75, 0.63, 1.6326583949931126, -0.62, 0.77, 0.11, 0.99, -0.29, -0.91, 0.59, 0.88, 1.17, 2.23, 0.16, 0.2688796134390452, -0.98, 0.77, 1.3349361992161735, 2.23, 1.4, 0.74, 1.62, 0.3464030612244898, -0.29, 1.22, 1.51, 1.8, 2.8980654680864433, 0.79, 0.8, -0.36, -0.14, 1.54, 1.7, 1.48, 0.82, -0.66, 0.22, -1.05, -1.67, -0.18, 0.11, 0.5239757335335068, 1.45, -0.61, -0.59, -1.73, 3.39, 1.49, 0.88, -0.4, -1.02, 0.48, 0.77, 1.06, 2.12, 0.05, 0.06, -1.09, 1.4, 4.66, -4.69, 0.6, -1.27, -1.88, -0.4, -0.11, 0.18, 1.22, -0.82, -0.81, -1.95, 1.02, 1.9, -0.62, 0.89, 1.18, 1.47, 2.53, 0.45, 0.47, -0.69, 0.87, 1.91, 3.13, 1.78, 1.52, 2.24, 2.53, 1.52, 1.81, 2.1, 3.17, 1.08, 1.09, -0.07, 1.6, 1.0, 0.29, 0.57, 1.63, -0.43, -0.42, -1.56, 1.7618280382942038, 2.13, 0.05, 2.82, 2.01, 0.75, 0.48, -5.45, 5.45, 2.7, 1.52, 2.63, -0.6, -3.56, -1.78, 0.35, 1.0330797898687791, 5.76, -5.71, -5.31, 1.75, -8.17, 3.51, -1.38, 0.7, 7.61, -4.46, -4.99, -7.56, 0.8738095238095238, 0.71, 0.6171787775716348, 1.34, -0.72, -0.7, -1.84, 5.36, 0.42, 1.05, -1.0, -0.98, -2.12, -0.62, -2.02, -2.01, -3.14, 1.7, 1.55, 1.44, 0.01, -1.13, 1.64, 2.0, 1.46, -2.2, 3.4101996269574992, 1.89, 2.2, 2.11, 1.42, -1.15, 2.28, 2.19, 1.07, 0.06, 1.46, 2.6, 3.25, 2.74, 3.41], ['317', -2.88, -0.85, 0.011221715620458745, 0.14, -0.55, 0.1, -1.73, -0.96, 0.0, -1.75, -2.06, -1.28, -0.3960867348791511, -0.23, -1.29, -1.4, -1.25, -1.75, -1.09, -1.75, -1.31, -1.52, -1.27, -1.28, -0.33, -0.29, 0.32, 0.8, 1.64, 1.87, 0.79, 0.68, 0.83, 0.32, 0.9907142857142857, 0.32, 0.77, 0.55, 0.81, 0.8, -0.25, 0.45, -0.48, 0.83, 1.06, -0.02, -0.12, 0.03, -0.48, 0.19, -0.48, -0.03, -0.25, 0.01, 0.0, 0.0, 0.42, -0.44, 0.52, -1.3, 0.23, -0.84, -0.95, -0.8, -1.3, -0.64, -1.3, -0.86, -1.07, -0.82, -0.82, -0.77, -1.52, -1.07, -1.17, -1.02, -1.52, -0.86, -1.52, -1.08, -1.3, -1.04, -1.05, 0.14, -1.12, 1.1, -0.46, -0.11, 0.04, -0.46, 0.21, -0.46, -0.02, -0.23, 0.02, 0.02, -3.04, -0.35, 0.15, -0.35, 0.31, -0.35, 0.09, -0.12, 0.13, 0.12, -0.02, -0.46, 1.24, -0.1384018193170985, -0.10482093036566006, -0.21, -0.5, -0.5, 0.16, -0.5, -0.06, -0.27, -0.02, -0.03, -0.33, 0.0, 0.67, 0.0, 0.45, 0.23, 0.49, 0.48, -0.79, -0.82, 0.3, -0.48, -9.03, 0.06, -0.06, 0.54, -0.56, -0.28, 0.08, -0.34, 0.08, 0.37, 0.13, -1.43, -0.06, -0.52, 0.43, 0.53, -0.14670919513614705, 0.86, -0.37, -1.72, 0.87, -1.46, 1.05, 0.95, 1.5, -0.14, -0.66, -0.66, -0.22, -0.43, -0.18, -0.19, -0.55, 0.0, 0.45, 0.23, 0.48, 0.48, -0.44, -0.22, 0.04, 0.03, 0.0, 0.28, -0.23, 0.25, 0.25, -0.18, -0.22, -0.88, 0.13, 0.0, -0.18, -1.042736189475567, -0.23, -0.48, 0.06278685149693167, -0.17, 0.03, 0.1, 0.19, -0.11, -0.48, -1.5, -1.07, -0.5], ['318', -3.31, 0.45, -0.02, -0.18, 0.65, 0.10841962367375949, 1.64, 0.1, 0.34, 0.03, -0.17, -1.21, 0.17, 0.25, -0.71, 1.64, -0.72, -0.05, -2.71, -1.17, -0.43266451791264104, -0.06, -0.83, -0.5, -0.41, 0.0, 0.2, -1.04, 0.34, 0.42, -0.54, 1.81, -0.55, 0.13, -2.55, -1.0, -0.3, 0.11, -0.66, -0.33, 0.4, 0.07, 1.26, 1.4, 1.48, 0.51, 2.89, 0.5, 1.18, -1.52, 0.04, 0.75, 1.16, 0.39, 0.73, -0.18, -0.21, 0.40782797280978395, 0.03, -0.14, 0.08, -0.88, 1.47, -0.89, -0.21, -2.88, -1.2160242664664933, -0.64, -0.23, -1.0, -0.66, -0.14, -0.22, -0.96, 1.39, -0.97, -0.29, -2.95, -1.41, -0.72, -0.31, -1.07, -0.74, 0.27, 2.55, -2.6, 0.7866982383853202, 2.37, -0.01, 0.67, -2.01, -0.46, 0.24, 0.65, -0.12, 0.27400772752445063, -2.69, -1.58, -2.32, -1.66, -4.28, -2.76, -2.08, -1.67, -2.43, -2.1, -0.06, -1.63, 1.15572371188304, 0.49, 0.54, 0.535673518650032, 0.76, 0.68, -2.0, -0.45, 0.25, 0.66, -0.11, 0.23, 0.12, 0.07, -2.67, -1.12, -0.43, -0.02, -0.78, -0.45, 0.97, 0.89, -0.38, 0.713186783623568, -7.99, 0.29, 0.07, -0.89, 0.971720125812563, 0.39, -0.08, 1.19, -2.48, -0.99, -0.52, -1.73, 0.15, 1.46, -1.46, -1.51, 0.5, -1.27, 0.99, 2.04, -1.03, 2.27, -4.02, -1.5, -2.23, 2.52, 2.82, 1.59, 2.3, 2.72, 1.94, 2.28, 1.48, 1.21, 0.7, 1.12, 0.34, 0.68, 0.5, 0.41, -0.36, -0.02, 0.36, 0.17, 0.09, -0.77, -0.43, 0.52, 0.56, 0.02, -2.07, 1.1, 2.1, 0.66, 1.26, 0.86, 0.34, 0.99, 0.47, -0.38, 0.23, 0.06, 0.615957527023814, 0.78, 1.84, 1.03], ['319', 0.1, 0.3, 0.13122171562045873, -0.14, 0.05, 0.23, 0.9241152579598292, 0.73, 1.12, 1.61, 0.63, 0.73, 0.53, 1.48, 0.74, 2.15, 1.09, 1.01, 8.25, 2.016979591836735, 2.02, 1.11, 0.67, 0.94, -0.28, 0.37, 0.97, 0.1, -0.1, 0.84, 0.1, 1.51, 0.45, 0.37, 7.57, 1.785112244897959, 1.38, 0.47, 0.03, 0.3, 2.4, 3.0049361992161736, 0.86, -0.2, 0.74, 0.0, 1.4, 0.35, 0.27, 7.46, 1.23, 1.308065468086443, 0.37, -0.07, 0.2, 0.07, 0.38, 1.54, 0.79, 1.07, 0.94, 0.21, 1.61, 0.55, 0.47, 7.68, 1.43, 1.48, 0.58, 0.13, 0.4, 1.52, 0.12, -0.73, 0.66, -0.39, -0.47, 6.67, 0.49, 0.53, -0.36, -0.8, -0.54, 1.73, 2.48, -2.4640000000000004, 0.86, 1.4, 0.34, 0.27, 7.45, 1.423744771101914, 1.27, 0.37, -0.07, 0.2, -2.217904761904762, -0.53, -1.04, -1.12, 5.97, -0.17, -0.13, -1.02, -1.45, -1.19, 0.36, -0.39063179677465387, -0.37, 0.46, 0.35, 0.68, 0.51, -0.08, 7.09, 0.88, 0.92, 0.03, -0.41, -0.15, 0.65, 0.59, 7.17, 0.96, 1.0, 0.1, -0.34, -0.07, -0.28, -0.53, -0.13, 0.9, -6.93, 0.65, 0.36, -1.29, 1.28, 0.63, 0.76, 0.14, 0.76, -0.96, -0.49, 0.07, -0.12, 1.57, -1.58, -1.4, 0.45, -2.04, 0.94, 2.97, -1.46, 1.56, -4.13, -1.1, -1.6, -0.8, -6.14, -5.8, -5.75, -6.59, -7.0, -6.76, 1.4, -0.36, 0.04, -0.85, -1.28, -1.02, -0.4, -0.89, -1.33, -1.06, 1.04, 1.22, 0.49, -0.44, -0.17, 0.5, 0.57, 0.85, -1.96, 0.13, 2.15, -0.03, 0.37, 0.93, 0.27, 0.95, 0.6, 0.32, -0.86, -0.03, 0.66, 0.6, -0.61, 1.05], ['320', 3.3242857142857143, 0.11, 0.08, 0.04, -0.2270209190089404, 0.75, 1.74, 0.44, 0.6, -0.29, -0.25, -1.65, 0.42, -0.66, -0.27, -1.67, -0.77, -0.59, -0.14, -0.43, -0.36, -0.7, -0.51, -0.9848833725798009, -0.11, 0.21, -0.04, -1.4, 0.67, -0.41, -0.01, -1.1049642857142856, -0.52, -0.33, 0.12, -0.18, -0.11, -0.45, -0.26, -0.88, -0.15, 0.58, 1.38, 2.11, 1.01, 1.41, -0.02, 0.9, 1.08, 1.54, 1.24, 1.31, 1.0538655564790018, 1.16, 0.53, 0.63, 0.29, 0.45, 0.51, -0.71, -1.08, -0.68, -2.08, -1.19, -1.0, -0.55, -0.85, -0.6165788457574171, -1.12, -0.93, -1.55, 1.17, 0.37, 0.4, -1.02, -0.11, 0.07, 0.7774764481550197, 0.23, 0.3, -0.04, 0.15, -0.48, 0.34, 0.78, -0.8, -0.03, -1.41, -0.5, -0.32, 0.3657885487528346, -0.16, -0.09, -0.44, -0.25, -0.87, 1.48, 1.4, 0.91, 1.1, 1.56, 1.26, 1.33, 0.98, 1.18, 0.54, 0.19, 1.42, 3.56, 0.49, 0.47, 0.47, 0.48, 0.19, 0.64, 0.34, 0.41, 0.07, 0.26, -0.37, 0.48, 0.29, 0.45, 0.16, 0.23, -0.12, 0.07, -0.55, 0.28, 0.37, -0.11, 0.39, 4.29, 0.12, 0.2, -0.6, 0.58, 0.3, 0.47, 0.69, -0.52, -0.98, -0.46, 1.3, 0.32, 1.36, -1.45, -1.44, 0.48, -0.98, 0.94, 0.51, -0.23, 1.37, -0.18, -0.85, -1.34, 0.14, -0.16, -0.29, -0.22, -0.57, -0.38, -1.0, 1.45, 0.14, 0.07, -0.27, -0.09, -0.71, 0.07, -0.34, -0.15, -0.78, 0.56, 0.58, 0.41, 0.19, -0.44, 0.45, 0.44, 0.52, 0.16, 2.92, -1.15, 0.94, 0.82, 0.22, -0.62, 0.6, 0.58, 0.09, 0.27, 0.11, 0.85, 0.49, 0.39, 0.17], ['321', 0.81, -0.23, -0.009847101690729465, 0.02, -0.45, 0.39, 1.74, 0.0, 0.87, 0.23, -0.45, -1.4, 0.27, 1.46, 0.5, -0.07, 0.08, 0.24, -0.93, 1.33, 0.61, -0.29, -0.07, -0.81, 0.83, -0.14, 0.68, -0.95, 0.73, 1.93, 0.96, 0.38, 0.54, 0.69, -0.48, 1.8, 1.07, 0.16, 0.38, -0.36, 0.04, 0.65, 1.65, 1.7, 2.91, 1.93, 1.35, 1.51, 1.66, 0.5771355564861204, 2.78, 2.04, 1.13, 1.35, 0.6, 0.5600628463056766, 0.14, 1.14, 0.54, -0.05, 1.19, 0.23, -0.34, -0.19, -0.04, -1.2, 1.06, 0.34, -0.56, -0.34, -1.08, -0.22, -1.22, -0.95, -1.52, -1.36, -1.21, -2.36, -0.13, -0.84, -1.73, -1.51, -2.24, 0.69, 1.06, -1.07, -0.27, -0.57, -0.42, -0.26, -1.43, 0.83, 0.11, -0.79, -0.57, -1.3, -0.92, 0.3, 0.15, 0.31, -0.86, 1.41, 0.68, -0.22, 0.0, -0.74, 0.04, 0.33, 0.22, 0.36, 0.43, 0.35, 0.14, 0.15, -1.01, 1.25, 0.53, -0.37, -0.15, -0.89, 0.45, -0.01, -0.9063144197072766, 1.1, 0.37, -0.4042004503433073, -0.31, -1.04, -0.22, -0.51, 0.12, 0.3, -3.27, 0.12, 0.03, 0.32, -0.21, -0.13, 0.0, -1.3, 2.16, -0.75, -0.36, 0.37, 0.38, 1.12, -1.02, -1.06, 0.35, 0.38, 0.73, -0.43, 0.23, 0.53, -1.72, -0.3, -0.49, -2.14, 1.17, 2.29, 1.55, 0.64, 0.87, 0.12, 1.12, -1.09, -0.72, -1.61, -1.39, -2.12, -0.38, -0.9, -0.68, -1.41, 0.82, 0.68, 0.52, 0.22, -0.52, 0.4720800343140569, 0.38, -0.05, -0.21, 0.4401996269574993, 0.12, 0.54, 0.33, 0.3, -0.74, 0.26, -0.46, 0.57, 0.12, 1.03, 1.04, -0.79, 0.05, 2.48], ['322', -0.37, -0.77, 0.0, 0.1, -1.75, -0.42158037632624057, -0.7158847420401708, -1.1382794034640413, -1.19, -0.8, 1.2, -0.21, 0.07, 0.31, 1.07, -0.3, 0.23, -0.78, 5.03, 2.15, -0.91, -0.26, 0.79, -0.13, -0.81, -1.24, -1.9373416050068875, -1.39, -1.11, -0.87, -0.12, -1.48, -0.95, -1.95, 3.79, 0.94, -2.08, -1.44, -0.4, -1.31, -3.05, -2.92, -0.59, 0.29, 0.52, 1.29, -0.09, 0.45, -0.57, 5.25, 2.36, -0.7, -0.05, 1.0, 0.08, -0.45, -1.32, -2.6, -0.76, -0.87, 0.3431047225355606, 1.0, -0.37, 0.16, -0.85, 4.95, 2.07, -0.99, -0.34, 0.71, -0.21, -1.15, -1.11, 0.76, -0.61, -0.08, -1.08, 4.7, 1.83, -1.22, -0.57, 0.47, -0.44, -1.93, -4.43, 4.38, -1.85, -1.36, -0.83, -1.83, 3.91, 1.07, -1.96, -1.32, -0.28, -1.1359922724755493, -1.08, -0.5, 0.54, -0.48, 5.34, 2.46, -0.61, 0.04, 1.09, 0.17, -0.2, -0.49, -2.38, -0.77, -0.84, -0.67, -1.03, -1.01, 4.78, 1.91, -1.14, -0.5, 0.55, -0.3114153161169343, -0.57, -0.03, 5.85, 2.95, -0.14, 0.52, 1.57, 0.65, -1.57, -1.51, 0.27603717887804047, -0.81, -3.11, -0.28, -0.28, 1.74, -1.74, -0.88, -0.32, -1.5, 5.77, 1.52, 0.78, -0.22, -0.23692021013122094, -2.21, 2.22, 2.28, -0.76, 2.8, -1.53, -1.34, 0.64, -3.07, 7.08, 1.98, 3.11, -5.69, -5.55, -2.74, -5.66, -5.04, -4.04, -4.91, -2.34, -2.89, -3.0, -2.36, -1.33, -2.23, 0.11, 0.66, 1.72, 0.79, -1.24, -1.31, -0.54, 1.05, 0.13, -0.78, -0.6956036987247092, -1.22, 3.58, -1.66, -3.61, -0.9, -1.01, -1.58, -0.91, -0.56, -0.77, -0.42, -0.01, -0.11, -0.67, -1.02, -2.05, -0.9], ['323', 7.08, 0.06, -0.23877828437954127, 0.05, 0.65, -0.17, 0.71, 0.4, -0.12, 0.77, 1.52, -0.17, -0.07, 1.39, 0.69, -0.3792857142857143, 1.06, 1.3205714285714287, 1.48, 0.27, 0.87, 0.8730748299319728, 1.15, 0.75, 0.23, 0.27, -0.73, -1.67, -1.57, -0.13, -0.82, -1.87, -0.44857142857142857, -0.2, -0.03, -1.23, -0.64, -0.64, -0.37, -0.76, 0.73, -0.74, 0.95, 0.1, 1.56, 0.86, -0.1889563492063492, 1.23, 1.49, 1.66, 0.44476190476190475, 1.04, 1.05, 1.32, 0.9250476190476191, 0.6700628463056766, 1.0842857142857143, 0.38, -0.32, 0.84, 1.46, 0.76, 0.3385714285714286, 1.13, 1.39, 1.56, 0.34, 0.94, 0.94, 1.22, 0.82, 1.31, -0.61, -0.69, -1.3133418367346938, -0.32, -0.07, 0.1, -1.1, -0.52, -0.51, -0.24, -0.63, -0.66, -0.85, 0.87, 0.09, -1.06, 0.37, 0.63, 0.79, -0.42, 0.18, 0.2757142857142857, 0.46, 0.06, 1.932095238095238, 1.16, 1.4528571428571428, 1.71, 1.88, 0.65, 1.25, 1.502816996495568, 1.54, 1.13, -0.66, 1.21, 0.65, -0.12, -0.37, 0.05, -0.28, 0.25, 0.42, -0.79, -0.19, -0.19, 0.08, -0.31, -0.02, -0.54, 0.17, -1.04, -0.45, -0.44, 0.41999999999999993, -0.56, -0.49, -0.13, -0.26, -0.29, 4.0, -0.1319304505018789, -0.47, -0.63, 0.55, 0.33, 0.0, 1.12, -1.1, 0.27, 0.14142857142857143, 3.51, -0.25, -0.38, 0.36, 0.38, -0.11, -0.8, -0.24, -0.7516093450200592, 0.48, -0.84, -2.95, 0.56, 0.97, 1.07, -0.7, -1.2, -0.61, -0.6, -0.33, -0.73, -0.31, 0.5, 0.6, 0.6, 0.9298095238095239, 0.48, -0.09, 0.01, 0.28, -0.12, -0.11, -0.51, -0.1, 0.27, -0.12, -0.11, -0.15, 0.52, -1.5, 0.38, 1.18, -0.31, -0.7, -0.37, -0.4, -0.53, 0.0, 0.43, -0.79, 0.43, 0.03, -0.38, -0.44, -0.57], ['324', -1.5, -0.19, 0.1, -0.06, -0.4, 0.19841962367375948, 1.17, -0.69, 0.05, -1.31, -1.08, -2.25, -0.39, -0.74, 0.3, -1.07, -1.82, -1.4, -2.68, -1.34, -1.66, -1.48, -1.61, -1.83, -0.54, -1.05, -0.24, -1.19, 0.7, 0.34, 1.39, 0.01, -0.75, -0.32, -1.62, -0.27, -0.5155463299214309, -0.41, -0.53, -0.76, -0.9, -0.9450638007838266, 0.96, 1.91, 1.55, 2.61, 1.21, 0.44, 0.87, -0.43, 0.93, 0.6, 0.79, 0.66, 0.44, -0.41, -0.29, 0.37, 0.55, -0.93, -0.35, 0.69, -0.69, -1.43, -1.01, -2.3, -0.96, -1.28, -1.1, -1.22, -1.44, -0.3, -0.58, 1.04, 0.09665816326530619, -1.09, -0.66, -1.95, -0.61, -0.93, -0.75, -0.87, -1.1, -0.18, 0.97, -1.03, -1.61, -1.37, -2.11, -1.69, -2.97, -1.64, -1.96, -1.78, -1.9, -2.12, -2.51, -0.24, -0.75, -0.33, -1.62, -0.27, -0.6, -0.42, -0.54, -0.76, 0.06, -0.25, 0.83, 0.24, 0.30517906963433994, 0.38567351865003197, 0.51, 0.43, -0.88, 0.48, 0.16, 0.34, 0.22, -0.01, 0.09, 0.09, -1.3, 0.06, -0.27, 0.035799549656692686, -0.21, -0.43, 0.48, 0.57, -0.07, 0.41, -7.41, 0.11, 0.13, -0.38, 0.39, 0.23881017100762114, 0.16, -0.8, -0.07, -0.45, -0.24, -0.74, 0.32, 0.69, -0.79, -0.67, 0.22, -0.59, 0.5298783572413152, 0.25, -0.15, 1.53, -1.25, -1.04, -1.56, 0.07380952380952381, 1.4, 1.37, 1.04, 1.23, 1.1, 0.87, 0.6808051948051949, 0.03, -0.32, -0.14, -0.27, -0.49, 0.36, 0.18, 0.06, -0.17, 0.05, -0.08, 0.17, -0.13, -0.35, 0.24, 0.28, -0.69, -0.86, 0.5, 0.98, 0.0, -0.11, 0.3, -0.22, 0.43, 0.25, 0.27, 0.37, 0.11, 0.52, -1.53, -0.12, 1.3130167737073972], ['325', -2.51, -0.06, 0.02, -0.24, 0.18, -0.05, -4.53, -0.97, -1.18, -0.36, 0.05, 3.4, 0.26, 0.26, 0.98, -0.6, 1.02, 0.02, -0.45, -0.07, -0.01, -0.18, -0.03, 0.19, -0.24, -0.33, -0.41, 3.35, 0.21, 0.22, 0.93, -0.65, 0.97, -0.03, -0.48223809523809524, -0.12, -0.06, -0.23, -0.08, 0.14, -1.0745146341753484, -0.8350638007838266, -3.64, -3.04, -3.03, -2.34, -3.87, -2.3, -3.27, -3.72, -3.36, -3.3, -3.46, -3.32, -3.11, -1.0, -0.8, -0.15, -0.49, -0.62, 0.11310472253556063, 0.72, -0.85, 0.76, -0.24, -0.709047619047619, -0.33, -0.27, -0.43, -0.29, -0.07, -0.78, -0.62, 0.71, -0.86, 0.75, -0.25, -0.71, -0.34, -0.27, -0.44, -0.3, -0.08, -0.61, -1.29, 1.25, -1.33, -1.5594795918367348, 0.04, -0.95, -1.42, -1.04, -0.98, -1.15, -1.0, -0.78, -1.27, 0.3173665312165629, 1.63, 0.62, 0.15, 0.53, 0.59, 0.42, 0.57, 0.79, -0.46, 0.24, -1.51, -0.31, -0.31, -0.53, -1.37, -0.99, -1.46, -1.08, -1.02, -1.19, -1.04, -0.7614153161169342, -0.2, -0.38, -0.47, -0.09, -0.03, -0.19, -0.05, 0.41217743764172343, -0.91, -1.29, -0.11, -0.98, -3.74, -0.4264527417027417, -0.04, 1.12, -1.06, -0.55, -0.64, -1.0, 0.46, 0.61, 0.34, -1.28, -0.26, -0.91, 0.81, 1.02, -0.31, 1.6, -0.74, -1.26, 0.4547652642842468, -4.03, 0.28, 2.69, 3.99, -0.47286904761904763, 0.09, 0.38, 0.44, 0.28, 0.42, 0.64, -1.03, -0.29, 0.06, -0.1, 0.04, 0.26, -0.35, -0.17, -0.02, 0.2, -1.23, -0.41, -0.18, 0.15, 0.37, -0.33, -0.49, -0.7274239503761217, 0.5, -1.45, -0.55, -0.88, -0.1, -0.33, 0.22, -1.08, -0.46, -0.1, -0.2, -0.07, -0.55, -2.01, -0.98, -0.88], ['326', 2.43, 0.7, -0.15877828437954128, -0.24, 0.4529790809910596, 1.01, 1.5541152579598292, 0.83, 1.01, 0.81, -0.66, -0.04, -0.56, 0.34, 0.86, 0.54, -0.11, 0.56, 4.47, 0.23071428571428573, 0.43, 1.7, -0.6, -0.13, 1.49, 0.88, 1.47, 0.62, 0.09, 1.0, 1.52, 1.2, 0.54, 1.22, 5.16, 0.8907142857142857, 1.09, 2.38, 0.05, 0.53, 0.93, 0.94, 0.85, -0.53, 0.38, 0.89, 0.58, -0.08, 0.6, 4.51, 0.27, 0.47, 1.74, -0.57, -0.09, 0.8500628463056766, 0.72, 0.94, 1.16, 1.4592452470658774, 1.0131047225355607, 1.43, 1.11, 0.45, 1.13, 5.06, 0.8, 1.0, 2.28, -0.04, 0.44, 0.5, 0.47, 0.51, 0.2, -0.46, 0.22, 4.11, -0.11, 0.09, 1.36, -0.94, -0.47, 1.35, 3.43, -3.2971666666666666, -0.05, -0.31, -0.96, -0.29, 3.58, -0.62, -0.42, 0.84, -0.9974829931972791, -0.9259922724755494, 1.89, 0.27, -0.65, 0.02, 3.91, -0.31, -0.11, 1.16, -1.14, -0.67, 0.16, 0.33, 1.07, 1.01, 1.06, 0.87, 0.93, 0.68, 4.59, 0.35, 0.55, 1.82, -0.49, -0.02, -0.79, 0.3030767481303673, 3.89, -0.33, -0.13, 1.14, -1.1542857142857141, -0.69, 1.65, 0.49, -0.37, 0.64, 3.71, -0.1, -0.02, -0.79, 0.8, 0.4, 0.34, 2.52, -1.17, -1.99, -1.0, 1.19, 0.66, 2.87, -2.89, -2.9, 1.0, -1.26, 2.05, 1.31, -0.68, 2.76, -6.94, -1.92, -2.77, 1.15, -3.5, -4.06, -3.87, -2.65, -4.86, -4.4, 3.03, 0.58, 0.2, 1.47, -0.83, -0.36, 0.38, 1.27, -1.03, -0.56, 1.05, 1.4184535464535466, -0.88, -2.27, -1.8, 1.07, 0.97, 0.73, -3.43, 1.45, 3.45, 1.89, 1.5, 1.42, 0.48, 0.92, 0.4845528598385743, 0.92, 0.14, 1.48, 0.94, 1.61, 1.77, 1.67], ['327', 0.17, 0.06, 0.22, -0.15, -0.09, 0.39, 0.03, 0.05172059653595872, -0.05, -0.84, -0.1, -1.1, -1.01, -0.72, -1.09, -1.11, -0.71, -0.81, 0.54, -0.52, -0.98, -1.17, -1.3, -1.04, 0.72, 0.21, -0.73, -1.0, -0.91, -0.62, -0.99, -1.01, -0.61, -0.71, 0.65, -0.42, -0.88, -1.06, -1.2, -0.94, 0.0, -1.49, 0.27, 0.09, 0.38, 0.01, -0.01, 0.39, 0.29, 1.66, 0.59, 0.12, -0.07, -0.2, 0.06, -0.54, 1.11, 0.0, -0.11, 0.18, 0.29, -0.09, -0.1, 0.3, 0.2, 1.57, 0.49, 0.03, -0.16, -0.3, -0.04, 0.35, -0.11, -0.37, -0.39, 0.01, -0.09, 1.28, 0.2, -0.26, -0.45, -0.58, -0.32, -0.62, 1.07, -1.07, 0.26, -0.02, 0.38, 0.29, 1.66, 0.58, 0.12, -0.07, 0.24251700680272095, 0.05, 0.68, 0.3573665312165629, 0.4, 0.3, 1.68, 0.6, 0.13, -0.05, -0.19, 0.07, 0.01, 0.27, 0.4, 0.11, 0.29, -0.11, -0.12, -0.1, 1.27, 0.19, -0.27, -0.45, -0.59, -0.27141531611693437, 0.37, -0.02, 1.37, 0.38224471370562696, -0.17, -0.36, -0.49, -0.24, 0.34, -0.15, -0.16, 0.03, 1.86, 0.05, -0.07, 1.63, -1.44, -0.7, 0.18, 0.37, 0.6, -0.23, -0.15, 0.07, 0.05, 0.2, -0.34, -0.36, 0.11, 2.15, 0.21, 1.71, -0.88, -0.01360430839002269, -2.67, 0.26, 0.45, -0.6, -1.37, -0.7328212224283652, -1.52, -1.7, -1.84, -1.58, 0.39, -0.32, -0.46, -0.65, -0.78, -0.53, 0.15, -0.19, -0.32, -0.07, -0.03, -0.44, 0.33, -0.14, 0.12, 0.09, 0.08, 0.02, -1.21, 0.21, 1.24, 0.7172638105244333, 0.3, 0.47, 0.26, 0.3, -0.69, 0.54, -0.21, 0.05, 0.295957527023814, 0.13, 0.58, -0.18], ['328', 6.37, 1.05, 0.92, -0.32, 2.17, 2.41, 2.1941152579598295, 4.28, 3.65, 3.38, -2.19, 1.09, -0.24, -0.84, -1.41, 1.07, -0.46, 1.123469387755102, 2.19, -0.02, 5.13, -0.45, -0.49, 0.21, 4.43, 3.88, 5.7, 3.35, 2.0, 1.38, 0.8, 3.33, 1.77, 3.38, 4.48, 2.22, 7.490760683760684, 1.78, 1.74, 2.45, 3.56, 6.48, 2.27, -1.31, -1.91, -2.47, -0.02, -1.42071768707483, 0.03, 1.09, -1.09, 4.0, -1.52, -1.56, -0.87, 2.36, 4.44, 3.53, 3.23, 3.63, -0.61, -1.17, 1.31, -0.22, 1.35, 2.43, 0.22, 5.38, -0.22, -0.25, 0.45, 4.6, 4.26, -0.57, 1.93, 0.39, 1.97, 3.06, 1.1491309523809523, 6.03, 0.39, 0.36, 1.06, 5.02, 10.76, -10.89, 4.86, 2.51, 0.97, 2.56, 3.65, 1.41, 6.64, 1.597142857142857, 0.93, 1.64, 3.02, 2.29, -1.51, 0.04, 1.1, -1.08, 4.02, -1.51, -1.54, -0.85, 1.96, 2.29, 3.17, 2.86, 2.91, 2.97, 3.85, 1.57, 2.65, 0.44, 5.61, 0.0, -0.03, 0.67, 3.69, 2.24, 1.06, -1.12, 3.98, -1.55, -1.58, -0.89, 3.96, 4.67, 0.13, 3.36, 6.17, 1.13, 0.88, -6.18, 6.17, 3.09, 2.48, 5.41, -6.64, -5.77, -2.89, 3.11, 2.06, 8.83, -8.7, -8.5, 2.84, -9.27, 5.76, 2.99, -1.51, 11.77, -10.43, -7.7, -11.45, 6.81, 1.17, -1.8328212224283653, 2.88, -2.58, -2.62, -1.94, 8.64, 3.4, 5.15, -0.43, -0.47, 0.23, -1.67, -5.31, -5.35, -4.69, 3.68, 4.34, 3.85, -0.03, 0.66, 2.95, 3.004396301275291, 4.31, -5.31, 4.19, 5.42, 3.67, 4.3210935020800125, 3.968637448200971, 0.7, 3.01, 2.68, 1.36, 1.89, 2.39, 3.17, 4.91, 7.18, 3.13], ['329', 0.62, 0.04, -0.49, 0.2, -0.2, 0.38, 0.64, 1.15, 1.15, 1.8, 0.07, 0.57, 0.7, 1.29, 0.04, 1.69, 0.97, 1.59, 3.55, 1.86, 2.15, 1.51, 1.3, 1.73, 1.08, 0.51, 1.73, 0.49, 0.63, 1.22, -0.03, 1.61, 0.9, 1.52, 3.47, 1.79, 2.08, 1.43, 1.23, 1.66, 1.05, 2.45, 1.23, 0.13, 0.72, -0.45918497042472345, 1.11, 0.4, 1.02, 2.961652133580705, 1.29, 1.58, 0.93, 0.8271428571428572, 1.16, 1.15, 1.69, 1.44, 0.87, 1.1792452470658776, 0.59, -0.66, 0.98, 0.27, 0.89, 2.83, 1.15, 1.44, 0.8, 0.6, 1.03, 0.14, 0.5, -1.2253571428571428, 0.39, -0.32, 0.29, 2.22, 0.56, 0.85, 0.21, 0.01, 0.43, 1.6, 2.12, -2.15, 1.76, 1.65, 0.93, 1.55, 3.51, 1.82, 2.12, 1.47, 1.26, 1.7440077275244505, -0.51, 0.11, -0.71, -0.09, 1.83, 0.17, 0.46, -0.18, -0.38, 0.04, 0.13, 0.13244557823129252, 0.88, 0.63, 0.56, 0.76, 0.83, 0.62, 2.55, 0.88, 1.17, 0.53, 0.33, 0.8185846838830657, 0.24, 0.21, 2.173685580292723, 0.26, 0.7286030199958774, -0.09, -0.28, 0.14, 0.2189583699631245, 0.34, 0.44, 0.53, -1.71, 0.01, -0.66, -1.62, 1.73, 0.61, 0.06, 2.85, -0.09, -1.22, -0.61, 0.25, 0.11, 1.85, -1.93, -1.81, 0.11, -2.53, 1.26, -1.14, 0.58, 2.5, -3.34, -1.68, -2.47, 0.04, -1.68, -1.63, -1.34, -1.97, -2.17, -1.75, 1.84, -0.06, 0.29, -0.35, -0.55, -0.13, -0.34, -0.64, -0.83, -0.41, 1.2, 1.22, 0.29, -0.2, 0.22, 0.6, 0.66, 1.12, -1.55, 0.4, 1.42, 0.5172638105244333, 0.46, 0.49, 0.42, 0.03, 0.5, -0.59, -0.5, -0.03, 0.07, 0.58, 1.46, 0.33], ['330', 0.41, 0.0, 0.24122171562045874, 0.19, -0.3, 0.14, -1.2158847420401708, -0.9482794034640413, -0.55, -3.51, -2.75, -2.98, -3.07, -2.81, -2.29, -3.53, -3.38, -3.44, -0.71, -2.53, -3.762664517912641, -3.46, -4.1, -3.82, 0.29, -0.21, -0.78, -0.23, -0.33, -0.06, 0.47, -0.79, -0.64, -0.7, 2.1, 0.23, -1.07, -0.72, -1.2811203865609546, -1.1, -0.38, -1.5950638007838267, -0.55, -0.09, 0.17, 0.71, -0.56, -0.41, -0.47, 2.34, 0.46, -0.811934531913557, -0.49, -1.15, -0.87, -0.14, -0.59, -0.9, -0.79, -0.45, 0.27, 0.8, -0.47, -0.32, -0.2773949338599383, 2.43, 0.55, -0.75, -0.4, -1.06, -0.78, -1.67, -0.72, 0.53, -0.74, -0.59, -0.65, 2.16, 0.28, -1.01, -0.67, -1.33, -0.9864403582748793, -0.85, 1.33, -1.4, -1.24, -1.26, -1.11, -1.17, 1.62, -0.24832539682539684, -1.54, -1.19, -1.85, -1.57, -0.44, 0.02, 0.15, 0.09, 2.92, 1.03, -0.28, 0.07, -0.59, -0.31, -0.06, -0.03, 1.34572371188304, 0.17, 0.26, 0.02, -0.13, -0.06, 2.76, 0.88, -0.43, -0.08, -0.74, -0.46, -0.07, -0.08, 2.82, 0.94, -0.37, -0.02, -0.68, -0.4, 1.04, 0.67, 0.3460371788780404, 0.02, -1.41, 0.13, -0.03, -0.15, 0.1, 0.06, 0.14, 0.39, 1.89, -0.39, -0.19, 0.2, 0.05, 0.48, -0.49, -0.45, 0.18, -0.31, 0.33, -2.021609345020059, 1.084765264284247, -0.45, 0.06, 0.24, 0.43, -1.98, -2.82, -1.84, -3.11, -2.7283894557823127, -3.403248299319728, -3.13, 0.48, -1.0, -1.29, -0.95, -1.6, -1.32, 0.3, 0.35, -0.31, -0.03, -0.58, -0.82, -0.05, -0.66, -0.38, 0.16, 0.11, -0.97, -0.48, 1.48, 0.57, 0.15726381052443328, -0.17, 0.61, 0.29, 0.3100774025227807, 0.1, 0.09, -0.2, 0.17462624382472908, 0.33, -1.57, 0.07, 0.46], ['331', 3.79, 2.18, 0.25122171562045875, -0.19, 0.52, 1.7, 2.63, 1.69, 1.12, 2.48, 1.82, 0.52, 0.79, 1.41, -0.95, 1.65, -0.21, 1.73, 6.53148185941043, 1.12, 2.36, 1.69, 0.31, 0.91, 0.83, 1.259371414588892, 0.65, -1.28, -1.01, -0.4, -2.72, -0.17, -1.99, -0.09, 4.61, -0.69, 0.53, -0.13, -1.48, -0.8561582768021608, 1.93, 0.79, 2.149303232481804, 0.27, 1.057875394446823, -1.46, 1.12, -0.73, 1.2, 5.97, 0.6, 1.83, 1.16, -0.21, 0.38, 0.4, 1.06, 1.18, 1.12, 1.67, 0.62, -1.73, 0.85, -0.99, 0.93, 5.68, 0.33, 1.56, 0.89, -0.48, 0.11, 2.13, 1.05, -2.33, 0.23, -1.6, 0.31, 5.03, -0.29, 0.94, 0.28, -1.09, -0.5, 0.33, 6.15, -6.06, 3.46, 2.62, 0.75, 2.7, 7.54, 2.09, 3.34, 2.66, 1.27, 1.9240077275244507, 1.49, 0.8973665312165628, -1.83, 0.08, 4.79, -0.52, 0.7, 0.04, -1.1788910216767359, -0.73, 0.85, 0.86, 1.99, 1.71, 1.65, 1.79, 2.69, 1.94, 6.74, 1.33, 2.58, 1.9603050194472875, 0.52, 1.12, 0.99, 0.74, 4.71, -0.6, 0.62, -0.04, -1.4, -0.81, 2.18, 2.72, 0.24603717887804044, 1.85, 4.83, 0.36, 0.21, -4.53, 4.57, 2.3, 2.53, 1.37, -2.72, -3.44, -1.74, 1.91, 1.34, 5.07, -5.1, -4.89, 1.72, -6.83, 3.42, 2.6, -1.31, 8.12, -15.54, -5.38, -8.02, 2.63, -3.79, -5.07, -3.9, -4.53, -5.83, -5.27, 5.17, 1.34, 1.23, 0.56, -0.8, -0.21, 0.11, -0.66, -2.01, -1.42, 1.192795351473923, 0.57, 0.78, -1.36, -0.77, 1.69, 1.79, 1.72, -8.15, 2.48, 8.28802380952381, 1.92, 0.99, 2.16, 0.6627868514969316, 1.85, 2.16, 1.81, 1.12, 1.2, 1.56, 2.19, 1.13, 0.37], ['332', 1.42, -0.11, 0.17122171562045874, 0.0, 0.97, 0.84, 1.11, 0.72, 0.43, 0.99, 0.47, 0.47899206349206347, -0.02, 0.41, 0.39, 0.37, -0.69, 0.57, 7.87, -1.49, 0.35, 0.01, 0.12, 0.05, 0.24, 0.54, 0.52, 0.0, -0.49, -0.06, -0.08, -0.09, -1.15, 0.21725890414440846, 7.36, -1.95, -0.04554632992143094, -0.46, -0.35, -0.42, -0.05, 0.40493619921617346, 0.52, -0.49, -0.06, -0.07, -0.09, -1.15, 0.11, 7.37, -1.95, -0.11, -0.46, -0.34, -0.42, -0.38, 1.54, 0.97, 0.52, 1.01, 0.5331047225355606, 0.42, 0.4, -0.67, 0.6, 7.89, -1.47, 0.38, 0.03, 0.14, 0.07, 0.38, 0.57, -0.02, -0.04, -1.1, 0.16, 7.43, -1.89, -0.06, -0.4, -0.29, -0.36, 0.61, 2.7, -2.76, 0.59, -0.02, -1.08, 0.18, 7.45, -1.6862552288980859, -0.04, -0.39, -0.27, -0.34, 0.37, 0.6873665312165629, -1.06, 0.2, 7.46, -1.86, -0.02, -0.37, -0.25, -0.33, 0.53, 0.63, 3.14, 0.96, 0.89, 1.1, 1.6909570400359875, 1.27, 8.62, -0.81, 1.05, 0.7, 0.8959878634155526, 0.74, 0.7, 0.41, 7.25, -2.05, -0.22, -0.56, -0.45, -0.52, 1.0, 1.25, 0.08603717887804044, 1.04, 1.15, 0.35, 0.25, -2.8, 2.81, 1.41, 0.45, 1.3761635321120496, -5.022241020883878, -1.92, -0.96, 0.79, 0.53, 2.970596861471862, -2.83, -2.84, 0.98, -4.24, 1.95, 0.5883906549799409, -0.23, 4.96, -4.7, -3.32, -5.03, 5.13, -6.38, -8.67, -6.97, -7.29, -7.18, -7.25, 2.89, 2.51, 1.87, 1.52, 1.64, 1.56, 0.63, -0.35, -0.23, -0.3, 0.47, 0.45, 0.98, 0.11, 0.04, 0.99, 1.1143963012752909, 0.82, -3.28, 2.28, 3.57, 0.87, 1.41, 0.86, -0.07, 1.22, 1.28, 0.44, -0.2566666666666667, 1.14, 1.025957527023814, 0.37, 1.71, 1.06], ['333', -16.58, -2.44, -0.77, 0.51, -3.42, -4.18, -2.705884742040171, -7.14, -4.23, -7.18, -2.04, -4.81, 0.05, -0.41, -0.8957142857142857, -4.311439909297052, -3.4771428571428573, -5.462517573696145, -6.28, -1.27, -8.22, -4.56, -3.32, -3.35, -6.12, -6.28, -5.25, -2.83, 2.13, 1.67, 1.16, -2.64, -1.47, -3.82, -4.33, 0.79, -6.31, -2.5, -1.31, -1.34, -4.82, -4.36, -2.49, 5.11, 4.63, 4.11, 0.21104365079365078, 1.4, -1.02, -1.54, 3.72, -3.58, 0.26, 1.57, 1.53, -4.69, -3.7799999999999994, -6.91, -4.88, -7.22, -0.45, -0.95, -4.47, -3.53, -5.83, -6.32, -1.32, -8.27, -4.61, -3.37, -3.4, -9.46, -6.8, -0.5, -4.176705782312926, -3.09, -5.4, -5.9, -0.87, -7.85, -4.18, -2.93, -2.96, -5.13, -13.79, 11.37, -6.34, -3.76, -2.6, -4.93, -5.43, -0.37, -7.39, -3.6842857142857146, -2.44, -2.47, -7.72, -2.67, 1.8285714285714285, -1.21, -1.73, 3.52, -3.76, 0.07, 1.37, 1.34, -1.44, -2.69, -5.48, -4.01, -3.87, -4.32, -3.83, -2.38, -2.9, 2.29, -4.91, -1.12, 0.17, 0.13, -2.71, -1.48, -0.53, 4.79, -2.59, 1.29, 2.6928571428571426, 2.58, -4.1, -2.4, 0.4, -4.34, -15.19, -2.0396768707482993, -1.24, 9.164285714285715, -8.57, -4.28, -0.92, -11.12, 11.68, 8.251428571428571, 4.064547619047619, -8.41, -2.84, -12.3, 12.967142857142857, 12.344285714285714, -4.03, 13.357142857142858, -8.03, -8.53, 4.15, -11.68, 22.44, 7.75, 11.54, -12.15, -0.96, 5.34, -2.07, 1.83, 3.15, 3.12, -12.14, -5.99, -7.04, -3.34, -2.08, -2.0185714285714282, 1.13, 3.98, 5.34, 5.538571428571428, -4.41, -4.74, -2.74, 1.3, 1.27, -3.96, -4.03, -7.3, 11.03, -5.29, -11.18, -6.05, -6.66, -3.99, -0.03, -4.34, -4.0, -2.81, -2.49, -3.08, -3.96, -7.61, -8.94, -3.38], ['334', 1.18, -0.12, -0.1, 0.25, 0.04, -0.24, -0.31, -0.07, -0.07, -0.8629115646258504, -1.87, -0.6406751700680272, 0.23, -0.64, -1.0, -1.73, -1.11, -1.38, -1.13, -1.37, -1.13, -1.45, -1.675694768399324, -1.21, 0.29, 0.78, 0.57, 1.24, 2.14, 1.25, 0.88, 0.14, 0.77, 0.5, 0.75, 0.51, 0.75, 0.43, 0.09, 0.67, -0.99, -0.24, -0.66, 0.89, 0.01, -0.35, -1.08, -0.46, -0.73, -0.48, -0.72, -0.48, -0.8, -1.13, -0.56, -0.2, -1.2, -0.4, -0.29, -1.53, -0.87, -1.23, -1.95, -1.34, -1.61, -1.35, -1.6, -1.35, -1.68, -2.0, -1.231743720565149, 0.6436060011417155, -0.67, -0.36, -1.09, -0.47, -0.74, -0.49, -0.73, -0.49, -0.81, -1.14, -0.57, 0.13, 0.75, -0.74, -0.30912907733800593, -0.74, -0.11, -0.39, -0.13, -0.37, -0.13, -0.45, -0.78, -0.21, 2.99, 0.5073665312165629, 0.63, 0.35, 0.61, 0.36, 0.61, 0.28, -0.05, 0.53, 0.09, 0.46, 1.24, -0.16, -0.01, -0.2, -0.12819052351387078, -0.27, -0.01, -0.26, -0.01, -0.34, -0.67, -0.1, 0.27, 0.07, 0.26, 0.01, 0.26, -0.07, -0.4, 0.17, -0.09, -0.47, 0.21, -0.05, 8.29, 0.25, 0.14, 1.56, -1.54, -0.81, 1.66, -0.64, -0.07, 0.35, 0.17, 0.61, 0.0, -0.61, 0.61, 0.57, -0.21, 2.43, -0.36, -1.25, 0.59, -0.54, 3.34, 0.35, 0.44, 0.06, -0.18, -0.25, 0.0, -0.28838945578231295, -0.66, -0.08, -0.55, 0.06, 0.25, -0.08, -0.41, 0.16, -0.18, -0.33, -0.65, -0.08, -0.12, 0.04, 0.14, -0.33, 0.31224875531501634, -0.19, -0.11, -0.12, 2.73, 1.64, -2.55, -0.36, -0.5088174603174603, 0.48, 0.57, 0.48, -0.41, 0.08, 0.59, -0.87, -0.1, -0.19, -0.93, 0.37], ['335', 4.68, -0.48, -0.04, 0.12, -0.49, -0.87, -0.38588474204017087, -1.06, -0.7, -1.1, -0.07, -0.99, 0.17, 0.72, -0.98, -2.04, -0.26, -0.92, 1.851481859410431, -0.02, -0.85, -0.74, -0.28, -0.41, -1.29, -0.88, -1.03, -0.92, 0.24, 0.79, -0.91, -1.97, -0.19, -0.85, 1.91, 0.05, -0.78, -0.67, -0.21, -0.2961582768021609, -0.06, -1.7650638007838266, -0.11, 1.18, 1.72, 0.01, -1.06, 0.74, 0.07, 2.861652133580705, 0.98, 0.168065468086443, 0.26, 0.72, 0.58, -0.42, -0.61, -0.98, -0.52, -1.27, 0.54, -1.15, -2.21, -0.43, -1.09, 1.66, -0.19, -1.03, -0.91, -0.45, -0.59, -0.7, -1.8, -1.68, -2.74, -0.97, -1.62, 1.12, -0.73, -1.56, -1.44, -0.99, -1.12, -1.23, -2.18, 2.13, -0.08330176161467984, -1.07, 0.73, 0.06, 2.85, 0.97, 0.13, 0.25, 0.71, 0.57, 0.4912233560090703, 1.047366531216563, 1.82, 1.15, 3.96, 2.07, 1.21, 1.33, 1.8, 1.66, -0.15, 0.93, -0.5, -0.8, -0.79, -0.73, -0.84, -0.66, 2.11015873015873, 0.24, -0.59, -0.48, -0.02, -0.15, -0.15346392892821453, -0.18, 2.78, 0.91, 0.07, 0.18, 0.65, 0.51, -1.11, -1.22, 0.20603717887804043, -0.7, 0.61, 0.03, 0.0, 1.49, -1.51, -0.75, 0.07406627346681526, -1.1938364678879505, 2.04, 1.62, 0.81, 2.35, -0.64, -2.43, 2.44, 2.35, -0.8, 2.3, -1.59, -1.1, 0.5747652642842468, -2.46, 5.36, 1.63, 2.46, -2.13, -2.88, -1.82, -2.64, -2.53, -2.08, -2.21, -2.42, -1.08, -0.83, -0.72, -0.26, -0.4, -0.25, 0.12, 0.58, 0.44, -0.65, -0.79, -0.36, 0.6532337781266354, 0.32, -0.79, -0.79, -1.01, 2.5, -0.5, -2.53, -1.56, -1.09, -0.82, -0.14, -0.81, -0.77, -0.75, -1.09, -0.28, -0.68, -1.8497593656343654, -2.01, -1.42], ['336', 4.03, -0.4, -0.36, 0.08, 0.62, -1.08, -0.71, -1.55, -2.05, -2.23, 0.68, -1.1392857142857142, -0.86, -1.62, -1.89, -2.06, -0.83, -1.75, -2.38, -2.08, -2.6, -1.0, -2.42, -1.1, -1.2, -0.35, -2.9, -1.81, -1.53, -2.29, -2.55, -2.73, -1.5, -2.42, -3.05, -2.728642857142857, -3.27, -1.67, -3.08, -1.78, -0.88, -1.7350638007838266, -1.1, 0.29, -0.49, -0.75, -0.93, 0.32285714285714284, -0.61, -1.26, -0.95, -1.48, 0.14, -1.2742857142857142, 0.04, -2.25, -1.04, -2.73, -2.86, -1.39, -0.77, -1.04, -1.21, 0.03, -0.9, -1.5228197278911566, -1.24, -1.76, -0.14, -1.57, -0.25, -1.67, 0.02571428571428569, -0.27, -0.44, 0.81, -0.13, -0.77, -0.47, -1.0, 0.6642857142857143, -0.81, 0.53, -2.51, -0.44, 0.53, -0.35, -0.18, 1.08, 0.17, -0.51, -0.2, -0.73, 0.91, -0.54, 0.8, 1.54, -0.18, 1.26, 0.32, -0.33, -0.03, -0.56, 1.08, -0.37, 0.97, -0.57, -0.16764311878597596, 0.86, -1.03, -0.96, -1.15, -1.42, -0.93, -1.57, -1.27, -1.79, -0.17, -1.6, -0.28, -1.4, -0.49, -0.3963144197072767, -0.34, -0.87, 0.76, -0.68, 0.65, 0.7, -0.85, 0.42, -1.47, 3.02, 1.17, 0.97, 2.33, -2.26, -1.12, -2.25, -1.91, 0.43, 2.06, 1.03, 2.21, -1.39, -3.14, 3.15, 3.01, -1.0, 3.47, -2.01, -1.5, 0.73, -4.27, 3.28, 3.0328571428571425, 4.1814285714285715, -0.28, 0.15, 0.3, -0.23, 1.461610544217687, -0.04, 1.31, -2.93, -0.15, -0.53, 1.11, -0.34, 1.0, 0.38, 1.65, 0.27, 1.54, -2.03, -2.55, -1.25, -1.43, -0.11, -0.99, -1.07, -1.58, 1.66, 0.29, -1.72, -0.42, -1.18, 0.19, 1.35, -1.3, -1.08, -1.09, -1.34, -1.48, -1.14, -0.4, -1.06, -1.2], ['337', 10.69, 2.9, -1.0587782843795412, 0.53, 0.68, -2.19, -2.39, -2.76, -3.83, -1.4529115646258504, 2.980608843537415, 1.08, 1.35, -0.8339200680272107, 2.07, -4.34, 0.46, -1.07, -1.61, -3.31, -2.62, -2.9769251700680273, 1.43, 0.26, -2.5214063389924735, -0.39, -4.697341605006888, -1.84, -1.5491666666666668, -3.99, -0.87, -7.1, -2.43, -3.92, -4.45, -6.1, -5.43, -5.7, -1.49, -2.63, -2.87, -6.33, -2.95, 0.27, -2.2, 0.99, -5.36, -0.30134863945578233, -2.12, -2.66, -4.34, -3.66, -4.01, 0.35, -0.81, -1.9, -3.7, -1.85, -3.69, -3.21, -2.46, 0.71, -5.62, -0.87, -2.38, -2.92, -4.6, -3.92, -4.27, 0.08, -1.08, -4.66, -0.7685714285714286, 3.25, -3.24, 1.6816609275411798, 0.08, -0.48, -2.19, -1.5, -1.86, 2.6, 1.42, -5.41, -8.31, 7.91, -3.9, -6.29, -1.58, -3.065714285714286, -3.61, -5.28, -4.6, -4.864285714285715, -0.63, -1.78, 3.88, 2.55, 5.03, 3.43, 2.8505714285714285, 1.7028571428571428, 1.8, 1.43, 6.04, 4.81, -1.04, 2.54, -5.36, -1.9, -1.88, -1.58, -2.36, -1.52, -2.07, -3.76, -3.07, -3.43, 0.96, -0.2, 0.81, -0.85, -0.55, -2.27, -1.57, -1.93, 2.52, 1.34, -4.32, -4.640438775510204, 0.61, -0.95, 7.72, -0.93, -0.8, 3.19, -3.19, -1.62, -1.55, -5.65, -2.98, 3.86, 1.92, 5.26, -1.16, -5.74, 5.87, 5.84, -1.92, 4.81, -3.78, 0.28, 0.02, -7.19, -4.93, -0.27, -0.06, 2.53, -0.3, -1.73, -1.02, -1.39, 3.09, 1.9, -5.69, 1.45, 0.71, 0.34, 4.900857142857143, 4.338571428571429, 0.74, -0.37, 4.16, 2.96, -3.73, -5.11, 1.11, 4.54, 3.34, -1.94, -1.89, -2.86, 6.04, -3.04, -7.28, -0.62, -1.07, -3.29, -1.15, -2.29, -1.46, -1.73, -0.03, -2.11, -2.16, -0.84, 0.48, -2.07], ['338', 3.83, -0.3, 0.12, -0.03, 0.45, 0.92, 0.6641152579598292, 1.25, 1.06, -1.02, -2.77, -1.47, -2.73, -2.38, -1.7, -2.35, -2.83, -1.47, 0.66, -1.04, -0.57, -0.8, -2.08, -2.18, 1.25, 1.45, 1.8, 1.34, 0.05, 0.4, 1.1, 0.44, -0.06, 1.34, 3.53, 1.78, 2.27, 2.03, 0.71, 0.61, 1.68, 1.8149361992161734, 0.46, -1.28, -0.93, -0.24, -0.89, -1.38, 0.0, 2.16, 0.43, 0.91, 0.7738655564790019, -0.62, -0.72, 0.83, 0.86, -0.74, 1.09, 1.76, 0.35, 1.05, 0.39, -0.1, 1.29, 3.507180272108844, 1.7302380952380951, 2.22, 1.98, 0.67, 0.56, 0.93, 1.4, 0.7, 0.04, -0.46, 0.94, 3.12, 1.37, 1.86, 1.62, 0.31, 0.21, 1.35, 3.351742947528662, -3.19, 0.7366982383853201, -0.66, -1.14, 0.24, 2.41, 0.67, 1.16, 0.92, -0.38, -0.49, 1.29, 1.36, -0.49, 0.9, 3.08, 1.34, 1.82, 1.59, 0.28, 0.17, 0.48, 1.35, -0.07, 0.5615981806829015, 0.98517906963434, 1.08, 1.86, 1.4, 3.59, 2.0397126881055456, 2.5057782534925392, 2.09, 0.77, 0.67, -0.24346392892821456, 0.46, 2.16, 0.43, 0.91, 0.68, -0.62, -0.72, 0.84, 1.09, 0.24, 1.2, 3.81, 0.12, -0.06, -2.53, 2.54, 1.3088101710076212, -2.44, 1.9961635321120494, -0.06, -1.96, -1.0, 1.92, 0.57, 2.91, -2.91, -2.91, 0.97, -3.87, 1.9698783572413152, 1.13, -0.56, 5.47, -10.92, -3.75, -5.55, 0.1, -1.67, -1.7, -1.22, -1.45, -2.72, -2.83, 2.88, 0.02, 0.48, 0.25, -1.04, -1.15, -0.45, -0.23, -1.52, -1.62, 1.1, 1.4, -0.22, -1.29, -1.39, 0.51, 0.61, 1.15, -6.42, 1.1, 6.27, 0.89, 0.29, 1.08, -0.11, 1.29, 1.04, 0.46, 0.26, 1.39, 1.19, 0.14, 0.2, 1.69], ['339', 3.3, 0.32, 0.47, -0.07, 0.5, 1.38, 1.91, 3.83, 2.21, 4.06, 0.52, 3.04, 1.01, 0.13, -0.56, 3.21, 2.26, 1.94, 7.21, 3.53, 4.88, 1.55, 0.93, 2.14, 3.0, 3.05, 3.5626583949931123, 2.51, 0.49, -0.23681006295292, -1.07, 2.68, 1.74, 1.42, 6.66, 3.0, 4.34, 1.03, 0.42, 1.62, 4.01, 2.76, 0.99, -1.97, -2.82, -3.49, 0.17, -0.75, -1.06, 4.05, 0.48, 1.79, -1.45, -2.04, -0.87, 2.53, 2.87, 1.5, 2.08, 3.02, -0.87, -1.55, 2.18, 1.24, 0.93, 6.15, 2.5, 3.83, 0.54, -0.07, 1.12, 3.99, 3.93, -0.68, 3.08, 2.13, 1.81, 7.08, 3.4, 4.74, 1.42, 0.8, 2.01, 3.88, 8.45, -8.35, 4.64, 3.79, 2.83, 2.51, 7.81, 4.11, 5.46, 2.12, 1.5, 2.71, 1.28, 0.83, -0.92, -1.23, 3.88, 0.31, 1.62, -1.61, -2.21, -1.04, 2.04, 0.81, 2.5257237118830402, 1.58, 1.73, 1.45, 1.76, -0.31, 4.84, 1.24, 2.56, -0.7, -1.3, -0.12, 2.25, 2.08, 5.17, 1.55, 2.88, -0.39, -0.99, 0.19, 3.89, 3.06, -0.1, 1.98, 2.5, 1.11, 0.73, -2.54, 2.5, 1.28, 0.4, 4.04, -0.99, -3.15, -1.59, 1.69, 0.66, 4.980596861471861, -4.84, -4.71, 1.59, -3.91, 3.17, 3.76, -1.88, 5.25, -14.99, -3.5, -5.19, 1.02, -2.94, -3.44, -2.18, -5.29, -5.86, -4.73, 4.82, 0.52, 1.3, -1.91, -2.51, -1.34, -0.78, -3.17, -3.76, -2.61, 2.41, 2.88, 2.48, -0.61, 0.58, 1.61, 1.65, 3.66, -7.49, 2.41, 7.41, 1.76, 1.54, 3.1, 1.19, 1.97, 1.29, 1.12, 0.14, 0.76, 1.88, 3.15, 2.9, 1.24], ['340', 1.88, -0.14, -0.03, 0.23, 0.06, 0.05, -1.23, 0.01, -0.32, 0.42, 0.5903184712113286, 1.49, 1.24, 0.11, 0.75, 0.82, 0.33, 0.25, 4.16, -0.41, 0.68, 0.69, 0.62, 1.16, -0.85, 0.5, 0.04, 1.1001785714285715, 1.2676746031746031, -0.27, 0.37, 0.44, -0.05, -0.13, 3.76, -0.79, 0.29, 0.31, 0.24, 0.77, -0.13, 0.15, -1.05, -0.25, -1.36, -0.72, -0.65, -1.14, -1.22, 2.63, -1.87, -0.8, -0.78, -0.85, -0.32, -0.78, -0.46, 0.61, 0.23, -0.7307547529341225, -1.11, -0.48, -0.41, -0.9, -0.97, 2.89, -1.62, -0.55, -0.54, -0.61, -0.08, 1.13, 0.31, 0.64, 0.72, 0.22, 0.5793027210884354, 4.05, -0.52, 0.57, 0.5814285714285714, 0.52, 1.05, -0.2, -0.52, 0.46, -0.32912907733800595, 0.07, -0.4082142857142857, -0.5, 3.38, -1.15, -0.07, -0.06, -0.13, 0.4, 0.992095238095238, -0.4, -0.49, -0.57, 3.31, -1.22, -0.15, -0.13, -0.2, 0.33, 0.36, -0.37, -1.74427628811696, -0.08, 0.02, -0.21, 0.09, -0.08, 3.82, -0.74, 0.35, 0.36, 0.29, 0.83, -0.19, 0.17, 3.9, -0.66, 0.42, 0.44, 0.37, 1.1421774376417235, 0.14, 0.14, 0.55, -0.09, 2.77, 0.2, 0.01, -0.53, 0.53, 0.26, 1.39, -1.55, -1.79, 0.21, 0.1, 1.03, -0.27, -0.28, 0.3, 0.26, -0.08, -0.79, -0.18, -2.52, 1.23, 0.2, -0.08, -0.17, -0.23, 1.74, -3.59, -4.39, -3.34, -3.33, -3.39, -2.88, -0.26, 0.83, 1.09, 1.11, 1.04, 1.57, -0.25, 0.022884928563499992, -0.05, 0.48, -0.36, -0.04, -0.27, -0.07, 0.46, 0.022080034314056876, -0.07, -0.07, -0.05, -1.42, 0.04, -0.16, -0.14, -0.2, 0.53, -0.11, 0.88, -0.33, -0.37, -0.61, -0.73, 0.63, -0.32, -0.64], ['341', 1.03, 0.12, 0.07122171562045874, 0.08, 0.07, -0.13, -1.18, -0.23, -0.12, -0.92, -1.31, 0.05, -0.95, -0.38, -0.9, -1.05, -1.27, -0.89, -0.28, -1.42, -0.45, -1.15, -0.98, -1.24, 0.42, 0.18, 0.4, 1.38, 0.37, 0.94, 0.41, 0.27, 0.04, 0.42, 1.05, -0.11, 0.8707606837606837, 0.17, 0.33, 0.07, -0.06, 0.95, -0.97, -1.0, -0.43, -0.95, -1.1, -1.32, -0.95, -0.33, -1.47, -0.5, -1.2, -1.04, -0.9891712018140588, -0.07, 0.08, -0.87, -0.09, 0.03, 0.57, 0.05, -0.1, -0.32, 0.06, 0.68, -0.47, 0.5, -0.2, -0.03, -0.3, 0.3, -0.54, -0.52, -0.67, -0.89, -0.51, 0.1, -1.04, -0.07, -0.77, -0.61, -0.87, 0.38, 0.23, -0.16, -0.02, -0.14, -0.37, 0.01, 0.63, -0.52, 0.46, -0.25, -0.08, -0.34, 0.11, 0.13, -0.23, 0.16, 0.77, -0.37, 0.6, -0.1, 0.06, -0.2, 0.161141873999017, 0.17, 0.11, -0.04, -0.01, 0.03, 0.36, 0.38, 1.0, -0.15, 0.83, 0.13, 0.29, 0.03, 0.19, -0.03, 0.62, -0.53, 0.44, -0.26, -0.09, -0.36, 0.31, 0.58, 0.18, 0.35, 0.4, -0.03, 0.07, 0.0, 0.07, 0.01, 0.34, -0.25, -0.92, 0.01, 0.03, 0.57, 0.07, -0.11, 0.05, 0.1, -0.05, -0.13, -0.09, -1.14, 0.59, 0.88, 1.55, -0.72, -0.97, 0.91, -0.64, -1.14, -0.17, -0.87, -0.71, -0.97, -0.13, 0.51, 0.98, 0.27, 0.44, 0.17, -0.47, -0.7, -0.53, -0.8, -0.15, 0.02, 0.23, 0.17, -0.1, -0.03, 0.06, -0.26, 1.03, 0.09, -0.99, -0.2627361894755667, -0.12, 0.07, -0.26, -0.22, -0.13, 0.22, -0.22, -0.06, 0.33, -0.17, 0.24, 0.53], ['342', -3.32, -2.45, -0.26, -0.61, 0.14, 1.14, 1.22, 0.16, 2.25, 0.74, -1.99, -0.57, -0.94, 0.11, 1.64, 0.61, 0.83, 0.51, 1.015862135879993, 0.26, 1.54, 1.44, 1.0, -0.2, 0.09, -0.66, 2.78, 1.45, 1.07, 2.14, 3.71, 2.65, 2.88, 2.55, 2.88, 2.29, 3.6, 3.5, 3.05, 1.83, -2.58, 6.59, 1.31, -0.37, 0.69, 2.23, 1.19, 1.41, 1.09, 1.42, 0.8984761904761904, 2.13, 2.02, 1.58, 0.38, -0.21, -0.28, -2.69, 1.68, 1.69, 1.06, 2.6, 1.56, 1.79, 1.46, 1.79, 1.21, 2.5, 2.4159625850340136, 2.115338978481836, 0.75, 0.09, 0.62, 1.53, 0.5, 0.72, 0.4, 0.73, 0.15, 1.43, 1.33, 0.89, -0.31, 4.27, -1.97, 0.91, -0.89, -1.02, -0.8, -1.11, -0.79, -1.36, -0.1, -0.2, -0.63, -1.81, 0.05, 0.12, 0.22, -0.1, 0.22, -0.35, 0.93, 0.82, 0.38, -0.8, 0.24, 0.12, -0.19, 0.92, 0.67, 0.81, -0.1, -0.32, 0.0, -0.57, 0.7, 0.6, 0.16, -1.02, -0.42, 0.22, 0.32, -0.25, 1.02, 0.92, 0.48, -0.71, -0.82, -0.43, -1.34, -0.38, 0.06, -1.38, -0.9, -0.88, 0.93, 0.46, 0.07, -0.25, -0.83, -1.2114285714285715, -0.865452380952381, -1.75, 1.39, 1.97, -2.2600000000000002, -2.1057142857142854, 0.94, -1.29, 1.86, 4.36, -2.17, -0.39, 3.39, 0.02, 0.06, 0.82, -0.1, -0.57, 0.7, 0.6, 0.16, -1.02, 2.78, 0.47, 1.28, 1.18, 0.7408571428571429, -0.46, -0.79, -0.1, -0.54, -1.71, 2.57, 3.37, -0.69, -0.43, -1.61, 0.93, 0.69, -0.03, 1.77, 0.74, -3.05, 1.34, 0.72, -0.26, -1.18, 1.18, 0.45, 2.0, 1.14, 1.87, 0.93, -0.94, -1.3, 1.11], ['343', 0.23, 0.4, 0.09122171562045875, -0.04, 0.18, 0.2784196236737595, 0.51, -0.31, -0.46, -0.91, -0.72, -0.53, -0.91, -1.02, -0.03, -0.66, -0.86, -0.84, -1.37, -0.62, -1.36, -0.64, -0.81, -1.47, -0.26, -0.17, -0.19, 0.19, -0.19, -0.3, 0.7, 0.06, -0.14, -0.12, -0.65, 0.1, -0.64, 0.09, -0.08, -0.75, -0.33, -1.3150638007838267, -0.38, -0.38, -0.49, 0.51, -0.13, -0.33, -0.31, -0.84, -0.09, -0.83, -0.11, -0.27, -0.94, -1.25, 0.27, -0.31, -0.2, 0.0, -0.11, 0.89, 0.25, 0.05, 0.07, -0.46, 0.29, -0.45, 0.28, 0.11, -0.57, 0.83, 0.11, 1.0, 0.36, 0.16, 0.18, -0.36, 0.4, -0.34, 0.38, 0.22, -0.46, -0.53, -0.36, 0.31, -0.88, -0.5419125667872351, -0.83, -0.81, -1.34, -0.59, -1.33, -0.61, -0.77, -1.44, 1.05, -0.25, -0.2, -0.18, -0.71, 0.04, -0.7, 0.02, -0.14, -0.82, -0.06, -0.35, 0.79, 0.18, 0.04, 0.28, -0.05, 0.02, -0.51, 0.24, -0.5, 0.22, 0.06, -0.62, -0.043463928928214546, -0.07, -0.53, 0.22, -0.52, 0.2, 0.04, -0.64, 0.04, -0.12, 0.11, 0.06, 3.03, 0.02, -0.13, -0.91, 0.94, 0.48, -0.28, 0.4061635321120495, 0.47, -0.37, -0.2, 0.04, -0.47, 0.63, -0.55, -0.5, 0.17, -1.44, 0.34, -1.07, 0.52, -0.09, 1.92, 0.05, 0.09, -0.5461904761904762, 0.47, 0.76, 0.02, 0.74, 0.57, -0.1, 0.51, -0.29, -0.74, -0.02, -0.18, -0.86, 0.45, 0.73, 0.56, -0.12, -0.44, -0.44, -0.28, -0.17, -0.84, 0.19, 0.13, -0.25, 0.94, 0.8, -0.93, 0.25, 0.3, -0.11, -0.67, 0.46, 0.35, -0.46, -1.15, 0.42, 0.57, 0.28, 0.38, 0.3], ['344', 3.92, 0.49, 0.17122171562045874, -0.09, 1.07, 0.66, 1.2541152579598291, 1.75, 1.4293780543870107, 1.89, 0.74, 0.53, 0.35, 1.45, -0.6, 0.44, 0.68, 1.28, -1.19, -0.23, 2.26, 0.92, 0.62, 0.57, 2.03, 1.48, 1.14, -0.21, -0.38857142857142857, 0.7, -1.33, -0.3, -0.06, 0.54, -1.91, -0.96, 1.52, 0.18, -0.11, -0.16, 2.1574684253532106, 1.67, 1.35, -0.18, 0.91, -1.13, -0.09, 0.15, 0.75, -1.71, -0.76, 1.72, 0.39, 0.09, 0.04, 1.6, 1.88, 1.4, 1.09, 1.54, 1.09, -0.95, 0.09, 0.33, 0.93, -1.53, -0.58, 1.91, 0.5859625850340136, 0.2727347454133169, 0.22, 2.36, 0.44, -2.02, -0.99, -0.75, -0.16, -2.6, -1.65, 0.81, -0.51, -0.81, -0.86, 1.28, 3.51, -3.5, 2.51, 1.05, 1.29, 1.9, -0.59, 0.37, 2.89, 1.54, 1.24, 1.18, 2.27, 1.44, 0.24, 0.84, -1.62, -0.67, 1.82, 0.48, 0.18, 0.13, 0.88, 1.46, 2.200104651162791, 1.01, 1.0, 1.1, 1.2, 0.6, -1.86, -0.91, 1.7457782534925395, 0.24, -0.06, -0.11, 0.84, 0.6, -2.44, -1.5, 0.97, -0.35, -0.65, -0.7, 1.33, 1.12, 0.01, 1.16, 6.71, 0.15, 0.17, -2.76, 2.68, 1.33, 0.11, 2.64, -4.06, -2.11, -1.0, 2.04, 0.28, 3.03, -3.04, -3.03, 1.0, -4.03, 2.0, 1.56, -0.82, 3.54, -13.39, -2.37, -3.57, 4.13, 3.12, 0.97, 3.5, 2.14, 1.84, 1.78, 2.99, 2.13, 2.5, 1.16, 0.86, 0.81, -0.37, -1.31, -1.6, -1.65, 1.39, 1.38, 0.96, -0.3, -0.35, 1.04, 1.1143963012752909, 1.77, -7.83, 2.100199626957499, 8.01, 1.197263810524433, 1.4611825396825397, 1.26, -0.05, 0.77, 1.27, 0.43, -0.11, 0.77, 1.31, 1.64, 2.38, 1.12], ['345', 2.54, -0.47, -0.05, 0.2, 0.26, -0.37, -0.8758847420401709, -0.94, -0.52, 0.49, 1.21, 0.8, 1.79, 2.08, 2.41, -0.15, 1.39, 0.42, 0.06, 0.11, 0.49, 1.06, 0.49, 1.32, 0.04, -0.5, -0.71, -0.4, 0.58, 0.86, 1.19, -1.34, 0.18, -0.78, -1.13, -1.09, -0.71, -0.15, -0.71, 0.11, -1.14, -1.72, -0.31, 0.98, 1.27, 1.6, -0.94, 0.58, -0.37, -0.73, -0.69, -0.31, 0.26, -0.31, 0.52, -0.03, -0.68, 0.08, -0.57, -1.28, 0.28, 0.61, -1.91, -0.4, -1.34, -1.7, -1.66, -1.28, -0.72, -1.28, -0.46, -0.98, -1.55, 0.33, -2.18, -0.68, -1.62, -1.97, -1.93, -1.55, -1.0, -1.55, -0.74, -0.73, -0.25, 0.22, -1.88, -2.5, -1.0, -1.94, -2.3, -2.25, -1.88, -1.32, -1.88, -1.07, 0.96, 0.64, 1.54, 0.58, 0.21, 0.26, 0.64, 1.21, 0.7811089783232642, 1.47, -0.04, 0.66, -1.05, -0.48, -0.37, -0.67, -0.88, -0.95, -1.31, -1.26, -0.88, -0.32, -0.88, -0.06, -0.2534639289282145, 0.07, -0.36, -0.32, 0.07, 0.63, 0.07, 0.89, -0.35, -0.62, -0.09, -0.84, 2.85, -0.07, -0.14, 1.44, -1.41, -0.71, 0.54, -0.98, -0.81, 0.94, 0.46, 1.3, -0.11, -1.4, 1.48, 1.44, -0.47, 2.11, -0.96, -2.11, 1.03, -2.62, -0.69, 1.78, 2.63, 0.7, 0.43, 0.04, 0.43, 1.0, 0.7496385796742939, 1.26, -1.46, 0.38, 0.38, 0.95, 0.38, 1.21, 0.0, 0.56, 0.0, 0.83, -0.61, -0.55, -0.56, -0.56, 0.26, -0.49, -0.57, -0.86, -0.62, -1.25, 0.32, -0.97, -0.93, 0.0, 0.83, -0.55, -0.52, -0.38, 1.1402244897959184, -0.76, -0.82, -1.3, -1.08, -1.5], ['346', 0.49, -0.69, 0.04, 0.06, -0.95, 0.94, -0.18588474204017086, -0.08, 1.04, 0.8321428571428571, -0.95, 0.27, 0.92, 1.0670238095238096, 1.49, 1.11, 0.15, 0.51, -0.53, 0.83, 1.25, -1.1, -0.48, 0.95, 0.82, 0.11, 1.8, 1.23, 1.89, 2.03, 2.46, 2.08, 1.12, 1.47, 0.43, 1.8, 2.22, -0.15, 0.48, 1.92, 0.26, 0.95, 0.57, 0.65, 0.79, 1.21, 0.84, -0.07072108843537415, 0.24, -0.79, 0.57, 0.98, -1.37, -0.75, 0.68, -0.07, 0.31, -0.08, 1.25, -0.08, 0.14, 0.56, 0.19, -0.76, -0.41, -1.44, -0.08, 0.32, -2.01, -1.39, 0.03, 0.2736060011417156, -0.22, 0.42, 0.05, -0.9, -0.38017346938775515, -1.57, -0.22, 0.18, -2.14, -1.53, -0.11, 1.45, 3.28, -3.3, -0.64, -0.37, -1.31, -0.9642857142857143, -1.99, -0.64, -0.24, -2.55, -1.94, -0.53, -1.56, -0.27, -0.95, -0.6, -1.62, -0.27, 0.13, -2.19, -1.4388910216767359, -0.16, 0.13, -0.26, 1.12, 0.33, 0.71, -0.08, 0.68, 0.35, -0.68, 0.68, 1.09, -1.26, -0.64, 0.79, 1.71, 0.3830767481303673, -1.03, 0.33, 0.74, -1.6, -0.98, 0.44, 1.5, 1.55, 0.09, 0.67, -4.63, 0.23, 0.07, 1.56, -1.57, -0.79, 0.44, -1.43, 0.06, -0.68, -0.36, 0.16, 0.62, 0.99, -0.89, -1.12, 0.32, 2.46, 0.61, -0.64, 0.32, 2.04, -3.28, -1.407142857142857, -2.08, 0.2656150793650793, 1.37, 1.37, 1.78, -0.58, 0.05, 1.48, 0.91, 0.0, 0.41, -1.92, -1.31, 0.11, -0.41, -2.32, -1.71, -0.29, 1.05, 1.25, 1.96, 0.63, 2.07, 0.26, 0.28, -0.07, -3.01, 0.92, 2.99, 0.8, 0.0, 1.32, 1.44, 0.81, -0.54, 0.7, 1.22, 0.26462624382472905, -0.11, 0.64, -0.96, 0.42], ['347', 1.71, 0.83, 0.02, -0.42, 1.38, 1.04, 2.6341152579598295, 1.14, 1.13, 0.18, -1.9, -1.44, -2.34, -0.54, -1.16, 0.33071428571428574, -1.64, 0.47748242630385496, 0.53, -1.69, 0.27, -0.23, -0.83, -1.1, 1.08, 0.76, 2.1626583949931124, 0.48, -0.45, 1.39, 0.8178199712950912, 2.28, 0.27, 2.11, 2.48, 0.22, 2.22, 1.71, 1.1, 0.82, 1.08, 0.9349361992161734, 1.65, -0.92, 0.91, 0.28, 1.8, -0.21, 1.62, 1.99, -0.26, 1.749654729237061, 1.23, 0.62, 0.34, -0.14, -0.62, 0.78, 1.18, 2.59, 1.84, 1.21, 2.74, 0.72, 2.56, 2.94, 0.66, 2.68, 2.17, 1.55, 1.27, 1.01, 0.73, -0.62, 0.8807142857142857, -1.1, 0.71, 1.08, -1.16, 0.82, 0.32, -0.28, -0.56, 1.6, 2.68, -2.7, 1.3966982383853201, 1.51, -0.48, 1.34, 1.71, -0.54, 1.45, 0.95, 0.34, 0.06, 0.06, -0.15, -1.97, -0.17, 0.19, -2.02, -0.06, -0.3171830035044322, -1.16, -1.43, 0.14, -0.07, 0.9, 1.1815981806829015, 1.03, 1.2456735186500318, 1.85, 1.83, 2.2, -0.05, 1.95, 1.44, 0.83, 0.54, 0.14, 0.02, 0.37, -1.85, 0.11, -0.39, -0.98, -1.26, 0.84, 1.17, -0.78, 1.42, 0.08, 0.12, 0.07, -2.49, 2.51, 1.3188101710076212, -2.37, 1.94, -4.1, -2.18, -1.16, 0.87, 0.53, 3.35, -3.25, -3.35, 1.1832908048638529, -3.77, 2.24, 4.57, -2.32, 5.56, -4.21, -3.69, -5.51, 4.09, -0.34, -2.21, -0.25, -0.75, -1.35, -1.62, 3.4131678995607566, 1.91, 2.0, 1.49, 0.88, 0.6, -0.09, -0.5, -1.1, -1.38, 1.15, 1.23, 0.41, -0.6, -0.8077512446849837, 1.182080034314057, 1.11, 1.05, -2.25, 1.28, 2.3, 1.89, 1.91, 1.02, -0.28, 1.94, 1.07, 0.58, 0.22, 0.58, 1.3, 2.83, 2.66, 1.65], ['348', 1.63, 0.49, 0.3412217156204588, -0.04, 0.61, 1.51, 1.34, 1.24, 1.76, 3.22, 0.74, 2.5819344980416408, 1.633913265120849, 2.66, 1.93, 3.31, 1.01, 2.62, 5.97, 1.92, 3.357335482087359, 2.06, 1.62, 2.01, 1.42, 2.33, 2.4926583949931125, 1.63, 0.82, 1.9, 1.18, 2.55, 0.27, 1.86, 5.635702380952381, 1.17, 2.56, 1.31, 0.87, 1.25, 1.01, 3.76, 0.82, -0.8, 0.27, -0.44, 0.9, -1.24071768707483, 0.23, 3.5971355564861205, -0.45, 0.91, -0.32, -0.10857142857142854, -0.37, 0.69, 1.33, 0.15, 2.04, 1.63, 1.08, 0.36, 1.71, -0.55, 1.04, 4.34, 0.35, 1.72, 0.49, 0.06, 0.43, 0.96, 0.55, -0.71, 0.63, -1.61, -0.04, 3.22, -0.72, 0.64, -0.59, -1.01, -0.64, 2.22, 4.62, -4.62, 1.27, 1.35, -0.9, 0.68, 3.96, -0.01, 1.36, 0.13, -0.3, 0.07, 1.74, -0.08, -2.22, -0.66, 2.58, -1.34, 0.01, -1.21, -1.63, -1.26, 0.65, -0.06, 1.81, 1.6, 1.39, 1.8, 2.19, 1.59, 4.91, 0.9, 2.28, 1.04, 0.61, 0.99, 1.13, 0.59, 3.26, -0.68, 0.68, -0.55, -0.97, -0.6, 2.31, 2.74, 0.07, 2.02, 5.47, 0.1, -0.07, -4.12, 4.122462323390895, 2.07, 0.66, 0.7, -2.43, -3.22, -1.64, 0.78, 0.88, 4.85, -4.67, -4.7, 1.643290804863853, -6.21, 3.22, 0.48, -0.24, 6.46, -7.74, -4.39, -6.51, 2.42, -2.59, -3.82, -2.5, -3.69, -4.1, -3.74, 4.83, 1.28, 1.37, 0.13, -0.29, 0.08, -0.09, -1.22, -1.64, -1.27, 1.81, 2.15, 1.14, -0.43, -0.05, 1.6, 1.68, 1.13, -5.79, 1.6711163791806698, 5.78, 1.85, 1.84, 1.57, 0.38, 1.7, 2.1, 1.15, 0.46, 1.2, 1.19, 3.1202406343656346, 2.25, 2.23], ['349', -0.03, -0.12, -0.3098471016907295, 0.07, 0.84, -0.08, -0.04588474204017083, -0.71, -0.24, -0.55, 0.0, -1.35, 0.013913265120848936, -0.71, 0.27, -0.98, -0.47, -0.48, -1.5, -2.23, -0.41, -1.32, -0.91, -0.63, -1.03, 0.55, -0.5173416050068875, -1.35, -0.05, -0.71, 0.27, -0.98, -0.47, -0.48, -1.4992857142857143, -2.23, -0.41, -1.32, -0.91, -0.5761582768021608, -0.44, 1.43, 0.81, 1.32, 0.66, 1.65, 0.38, 0.89, 0.89, -0.15, -0.89, 0.95, 0.03, 0.45, 0.74, -0.07, -0.58, -1.49, -0.72, -0.42075475293412246, -0.66, 0.33, -0.93, -0.42, -0.43, -1.3413219954648525, -2.18, -0.36, -1.27, -0.86, -0.57, -1.26, 0.16, 0.99, -0.28, 0.24, 0.23, -0.8, -1.53, 0.3, -0.62, -0.07690451810094656, 0.08, -0.45, 1.03, -1.06, -0.82, -1.25, -0.75, -0.75, -1.77, -2.306255228898086, -0.69, -1.59, -1.19, -0.8459922724755494, 2.19, 0.44, 0.51, 0.51, -0.52, -1.26, 0.57, -0.34, 0.07, 0.36, -0.03, 0.48, 0.42572371188304003, -0.04, 0.18517906963433994, -0.22432648134996808, -0.08, 0.0, -1.03, -1.76, 0.06, -0.85, -0.44, -0.15, 0.6, -0.08, -1.03, -1.76, 0.06, -0.85, -0.44, -0.15, 0.47, 1.43, 0.12, -0.15, 4.46, -0.2419304505018789, -0.42, 0.77, -0.76, -0.41, -0.32593372653318475, 0.08025974025974027, -3.53, 0.1, 0.05, 0.03, 0.28, -0.24, 0.23, 0.19, -0.05, 1.21, -0.13, -0.25, 0.09, -0.12, 1.2, 0.15, 0.09, 3.46, 0.96, -0.74, 1.1, 0.18, 0.59, 0.89, -0.22, 1.72, 1.86, 0.93, 1.35, 1.64, -0.14, -0.91, -0.5, -0.21, -0.19, -0.53, 0.78, 0.41, 0.7, -0.04, -0.07, -0.6074239503761216, 0.6, -0.2498003730425007, -0.75, -0.18, 0.01, 0.37, 0.29, -0.77, -0.44, 0.01, 0.57, 0.37, 0.07, 0.4, 0.6, 0.07], ['350', -1.99, -0.44, -0.17877828437954127, 0.17, -0.31, 0.19, -0.74, -0.95, -0.72, -0.83, -0.21, -0.38, -0.06, 0.48, -0.19, -0.67, -0.55, 0.13, 2.59, -0.19, -1.0, -0.19, -0.3956947683993239, -0.49, -1.26, -1.21, -0.62, -0.17, 0.15, 0.69, 0.02, -0.46, -0.34, 0.35, 2.81, 0.02, -0.79, 0.02, -0.28, -0.28, -0.76, -0.47, -0.45, 0.32, 0.86, 0.19, -0.29, -0.17, 0.52, 2.99, 0.19, -0.62, 0.19, -0.11, -0.11, -0.14993715369432348, -1.34, -1.5021720271902161, -1.2, -0.77, 0.54, -0.12920068027210885, -0.61, -0.49, 0.19, 2.65, -0.12976190476190477, -0.95, -0.14, -0.43, -0.43, -1.25, -1.3, -0.2497721088435375, -1.14, -1.02, -0.34, 2.11, -0.67, -1.47, -0.67, -0.97, -0.96, -0.48, -0.97, 1.0, -0.64, -0.48, -0.36, 0.33, 2.79, 0.0, -0.81, 0.0, -0.3, -0.3, -2.64, -0.16, 0.12, 0.81, 3.3159047619047617, 0.48, -0.34, 0.7228169964955679, 0.18, 0.18, -0.82, -0.14, 1.33, -0.13, -0.14, -0.24, -0.28, 0.69, 3.16, 0.36, -0.46, 0.36, 0.06, 0.06, -0.7, -0.96, 2.46, -0.32, -1.13, -0.33, -0.62, -0.62, -0.43, 0.33, -0.08, -0.38, -5.12, -0.4796768707482993, -0.3, 0.82, -0.88, -0.41, -0.2, -0.66, 1.38, 0.35, 0.14, -0.95, 0.37, -0.58, 0.56, 0.34, -0.13, 1.16, -0.27, -0.98, 0.45, -0.83, 9.49, 0.53, 0.81, -1.39, -3.34, -2.71, -3.51, -2.72, -3.01, -3.0, -0.36, -0.64, -0.81, 0.0, -0.3, -0.3, 0.18, 0.82, 0.52, 0.52, -0.66, -0.79, -0.64, -0.3, -0.29, 0.09208003431405688, -0.18, -1.02, 4.75, 0.17, -4.86, -1.3, -0.06, -0.34, 0.0, 0.06, -0.34, 0.61, 0.58, -0.17, -0.34, -2.2, -0.42, -0.14], ['351', 0.88, 0.0, 0.17122171562045874, -0.04, 0.18, 0.39, 0.9841152579598291, -0.1, 0.28, 0.23, -0.2, 0.17, -0.07, 1.5, -1.22, 0.15, -0.13, 0.23, -1.22, -0.02, 0.21733548208735892, 0.53, 0.29, -0.12, 0.04, 0.51, 0.42, 0.37, 0.13, 1.7, -0.9721800287049088, 0.35, 0.07, 0.42, -1.03, 0.17, 0.37, 0.72, 0.49, 0.08, 0.8, 0.6749361992161734, 0.05, -0.24, 1.32, -1.39, -0.02, -0.3, 0.05, -1.39, -0.2, 0.0, 0.35, 0.12, -0.29, -0.41, 0.19, -0.86, 0.26, 0.3, 1.57, -1.15, 0.22, -0.06, 0.3, -1.15, 0.05, 0.25, 0.6, 0.36, -0.05, -0.15, -1.25, -2.68, -1.33, -1.6, -1.25, -2.68, -1.5, -1.3, -0.96, -1.19, -1.59, 0.33, -0.06, 0.05, 1.460870922661994, 1.39, 1.11, 1.46, 0.23578854875283461, 1.21, 1.41, 1.77, 1.53, 1.12, 1.12, 0.08, -0.27, 0.08, -1.37, -0.17, 0.03, 0.38, 0.14, -0.27, 0.0, 0.05, -0.25, 0.2515981806829015, 0.18, 0.31, 0.35, 0.35, -1.1, 0.1, 0.3, 0.65, 0.42, 0.01, -0.25, 0.053076748130367266, -1.45, -0.25, -0.05, 0.3, 0.06, -0.34, -0.39, -0.48, 0.04, 0.29, 3.19, -0.03, 0.07, -0.51, 0.54, 0.25, 0.29, 1.04, -0.47, -0.4, -0.21, 0.44, -0.11, 0.54, -0.55, -0.58, 0.19, -0.76, 0.44, 0.31, -0.12, 1.05, -3.15, -0.72, -1.12, 0.52, 1.47, 1.21, 1.42, 1.77, 1.53, 1.12, 0.58, 0.25, 0.2, 0.55, 0.31, -0.09, 0.05, 0.35, 0.11, -0.29, 0.24, 0.37, -0.3, -0.23, -0.64, 0.22, 0.26, -0.07, 0.29, 0.06, -0.33, 0.15, 0.51, -0.06, -0.41, 0.35, 0.42, 0.14, -0.82, 0.06, 0.34, 0.84, 0.66, 0.7730167737073972], ['352', 11.16, 0.74, 0.8112217156204587, -0.45, 3.17, 2.9184196236737594, 3.05, 6.77, 5.59, 6.21, -1.89, 2.401934498041641, 0.94, -0.99, -0.49, 4.52, 0.57, 4.5, 5.19, 2.49, 8.27, 1.67, 0.23, 3.23, 7.5, 3.98, 8.26, 4.18, 2.88, 0.92, 1.43, 6.54, 2.51, 6.52, 7.230714285714286, 4.47, 10.36, 3.64, 2.17, 5.22, 4.53, 8.1, 3.92, -1.24, -3.12, -2.63, 2.27, -1.6, 2.25, 2.93, 0.7096666666666667, 5.93, -0.52, -1.93, 1.01, 5.21, 6.43, 4.94, 3.98, 5.22, -1.91, -1.41, 3.55, -0.37, 3.53, 4.22, 1.54, 7.26, 0.73, -0.7, 2.27, 6.79, 7.27, 0.51, 5.57, 1.57, 5.54, 6.25, 3.52, 9.35, 2.69, 1.23, 4.26, 8.048909863945578, 16.38, -16.33, 6.73, 5.03, 1.06, 5.01, 5.71, 3.0, 8.8, 2.17, 0.72, 3.74, 1.93, 1.61, -3.78, -0.02, 0.64, -1.94, 3.6426265373526934, -2.73, -4.1, -1.23, 1.5911418739990169, 1.66, 5.57, 3.44, 3.76, 3.31, 5.61, 3.91, 4.6, 1.92, 7.66, 1.1, -0.33, 2.65, 4.1, 1.64, 0.67, -1.92, 3.61, -2.7, -4.08, -1.21, 5.59, 5.78, 0.17, 4.75, 3.82, 1.97, 1.15, -6.1, 6.05, 3.04, 1.83, 7.19, -7.2, -6.85, -3.46, 5.57, 2.13, 10.55, -10.5, -10.32, 3.43, -9.09, 6.87, 6.64, -3.28, 16.77, -26.49, -11.15, -16.6, 7.02, 0.96, -2.57, 2.92, -3.35, -4.72, -1.87, 10.27, 3.62, 5.63, -0.8, -2.21, 0.72, -1.9, -6.09, -7.42, -4.65, 5.61, 6.11, 4.46, -1.42, 1.53, 3.4, 3.6, 6.78, -13.22, 4.91, 13.33, 5.44, 4.23, 5.96, 2.99, 4.780077402522781, 3.35, 0.87, 2.46, 1.98, 2.965957527023814, 9.05, 6.743037664716236, 4.46], ['353', -3.39, 1.04, -0.008778284379541255, 0.07, 0.06, 0.52, -0.5, 0.31, 0.72, 0.56, 0.09031847121132863, 0.42, -0.49, 0.71, 0.29, 1.06, 0.33, 0.49, 0.36, -0.25, 1.12, 1.04, 0.3543052316006761, -0.49, 1.33, 0.28, 0.68, 0.5401785714285715, -0.37, 0.83, 0.41, 1.19, 0.45, 0.61, 0.48, -0.13, 1.25, 1.16, 0.38, -0.37, 0.6174684253532109, 2.0, 0.14, -0.91, 0.29, -0.13, 0.64, -0.09, 0.07, -0.07, -0.67, 0.7, 0.62, -0.16, -0.91, 0.55, 0.45, 0.15, 0.75, 1.06, 1.21, 0.78, 1.56, 0.82, 0.98, 0.85, 0.24, 1.62, 1.54, 0.75, 0.0, 0.93, -0.15, -0.42, 0.35, -0.38, -0.22, -0.3469047619047619, -0.96, 0.41, 0.33, -0.45, -1.19, 1.05, 1.02, -1.02, 0.27, 0.77, 0.04, 0.2, 0.07, -0.54, 0.83, 0.75, -0.03, -0.78, -0.71, -0.5, -0.73, -0.57, -0.7, -1.3, 0.06, -0.02, -0.79, -1.54, -0.05, -0.49, -0.16, 0.61, 0.47, 0.7, 0.23, 0.16, 0.03, -0.58, 0.8, 0.71, -0.07, -0.7514153161169344, 0.39, 0.12307674813036727, -0.13, -0.74, 0.63, 0.55, -0.23, -0.97, 0.13, 0.32, 0.04, 0.25, -1.87, 0.07, 0.17, -1.76, 1.78, 0.91, 0.89, -0.5, -1.4494817511227285, -1.23, -0.64, -1.67, 0.49, 1.85, -1.79, -1.8, 0.62, -2.68, 1.24, -0.27, 0.13, 0.71, -1.7, -0.5, -0.74, 1.5738095238095238, 0.21, -0.61, 0.77, 0.68, -0.1, -0.84, 1.87, 0.82, 1.38, 1.3, 0.51, -0.24, -0.56, -0.08, -0.86, -1.6, 0.27, 0.36, -0.47, -0.77, -1.52, 0.17, 0.06, 0.12, -0.33, 0.43019962695749936, 0.39, -0.03, 0.64, 0.3, -0.75, 0.58, 0.63, 0.78, 0.08, 0.61, 1.06, -0.39, 0.35, 0.67], ['354', -7.13, -0.22, -0.19877828437954126, -0.17, -0.05, 1.22, -0.41, -0.6982794034640413, 0.32, -1.13, -2.29, -0.92, -1.76, -0.58, 0.59, 1.65, -0.57, -1.21, -3.38, -1.51, -1.402664517912641, -0.67, -2.47, -1.57, 0.6, -0.27, 1.18, 1.4, 0.54, 1.75, 2.94, 4.03, 1.76, 1.1, -1.12, 0.79, 0.87, 1.66, -0.18, 0.73, -1.8345146341753484, 1.33, -0.20979591836734693, -0.7588025325038829, 0.35, 1.52, 2.6, 0.36, -0.29, -2.478347866419295, -0.6, -0.53, 0.25, -1.56, -0.66, -2.0476426685347184, -1.76, -2.77, 0.48, 0.64, 1.2, 2.38, 3.47, 1.8814285714285712, 0.55, -1.65, 0.25, 0.32, 1.1114285714285714, -0.72, 0.19, -1.11, -0.56, 1.17, 2.24, 0.01, -0.4701734693877551, -2.82, -0.94, -0.87, -0.08857142857142856, -1.9, -1.0, 0.98, 2.82, -2.95, -1.71, 1.06, -1.15, -1.79, -3.94, -2.09, -2.02, -1.25, -3.04, -2.15, -0.94, -2.74, -2.18, -2.82, -4.95, -3.11, -3.04, -2.2775714285714286, -4.05, -3.17, -0.19, -2.78, -0.08427628811695997, 0.08, 0.73, 0.24567351865003195, -0.57, -0.65, -2.83, -0.95, -0.88, -0.1, -1.91, -1.01, -0.43, 0.08, -2.2, -0.3, -0.23, 0.55, -1.27, -0.37, 1.44, -0.26, -0.26, -0.18, -1.9, -0.5196768707482994, -0.75, 1.52, -1.57, -0.78, -3.31, -0.59, -0.66, -1.29, -0.67, -2.27, 1.02, 1.4905968614718617, -1.49, -1.9, 0.68, 2.49, 1.31, 2.98, -1.52, -1.64, -0.59, 1.25, 1.76, 0.64, 2.650378684807256, 1.93, 2.01, 2.81, 0.94, 1.87, 1.78, 0.39, 0.07, 0.86, -0.97, -0.06, 0.32, 0.78, -1.04, -0.13, 0.37, 0.9, -0.47, -1.81, -0.91, 0.62, 0.43, -1.03, -0.32, 0.37, 0.17, 0.79, 0.4411825396825397, 1.37, 0.92, 0.85, -0.47, 1.3952979520479523, 0.51, 0.82, 0.45, -0.69, -0.7184047619047619, 1.52], ['355', 0.88, 0.4, 0.16015289830927054, 0.11, 0.53, -0.1, 0.41, 0.02, -0.17, 1.14, 1.42, 0.93, 1.59, 1.48, 0.31, 1.16, 1.01, 1.06, -1.09, 0.85, 0.67, 1.2, 1.37, 1.3, -0.12, 0.03, -0.28, -0.48, 0.17, 0.06, -1.09, -0.26, -0.4, -0.35, -2.47, -0.56, -0.73, -0.21, -0.04, -0.12, 0.15, -0.28, 0.2, 0.65, 0.54, -0.61, 0.22, 0.08, 0.13, -2.0, -0.08, -0.26, 0.27, 0.44, 0.36, -0.65, -0.37, 0.26, -0.17, -0.45, -0.11, -1.26, -0.43, -0.57, -0.52, -2.531321995464853, -0.73, -0.9, -0.38, -0.21, -0.29, -0.73, -0.33, -1.15, -0.32, -0.46, -0.41, -2.53, -0.62, -0.79, -0.27, -0.1, -0.17, -0.2, -0.69, 0.69, 0.8566982383853201, 0.84, 0.7, 0.75, -1.39, 0.53, 0.36, 0.89, 1.06, 0.98, 0.18, 0.05736653121656289, -0.14, -0.09, -2.22, -0.31, -0.48, 0.05, 0.22, 0.14, 0.02, 0.0, 0.13, 0.0, 0.05, -0.06, 0.12, 0.05, -2.08, -0.16, -0.33, 0.19, 0.36, 0.29, -0.04, 0.07, -2.13, -0.22, -0.39, 0.14, 0.31, 0.23, -0.67, -0.71, 0.11, 0.08, 0.3, 0.1, 0.13, 0.76, -0.7475376766091052, -0.3511898289923789, 0.14, 0.93, -0.51, -0.02, 0.03, 0.45, 0.16, 0.0, -0.07, -0.06, 0.03, 1.15, 0.08, -1.31, 0.67, 0.33, -7.56, -0.21, -0.26, 0.6, 2.25, 1.95, 1.78, 2.32, 2.49, 2.41, 0.04, 0.29, -0.17, 0.36, 0.52, 0.45, 0.46, 0.53, 0.69, 0.62, -0.12, -0.08154645354645335, -0.07, 0.17, 0.09, 0.03, 0.03, 0.06257604962387836, -4.66, 0.0, 4.65, 0.23, 0.52, -0.23, -0.07, 0.54, -0.46, 0.03, 0.42, 0.09, -0.16, 0.35, -0.02, 0.26], ['356', 0.23, -0.37, -0.2, 0.05, -0.21, -0.42, -0.54, 0.14, -0.48, -0.22, 0.04, -0.28, 0.21, -0.17, 0.39, -0.02, -0.08, 0.25, 4.4, 0.43, -0.3426645179126411, -0.08, 0.47, 0.35, -0.57, -0.71, -0.22734160500688755, -0.31, 0.17, -0.2, 0.36, -0.05, -0.12, 0.21, 4.37, 0.39, -0.42, -0.12, 0.44, 0.32, -2.0, -0.6850638007838266, 0.05, 0.49, 0.11, 0.67, 0.26, 0.2, 0.53, 4.69, 0.71, -0.11, 0.2, 0.75, 0.63, -0.75, 0.31, 0.13, -0.63, -0.43, -0.38, 0.18, -0.23, -0.29, 0.04, 4.19, 0.22, -0.59, -0.29, 0.26, 0.14, -0.61, -0.06, 0.5607142857142857, 0.15, 0.09, 0.42, 4.58, 0.59, -0.22, 0.08, 0.64, 0.52, -0.45, -1.53, 1.75, -0.61, -0.41, -0.47, -0.14, 4.0, 0.04, -0.77, -0.47, 0.08, -0.04, -1.15, -0.21, -0.06, 0.27, 4.42, 0.45, -0.37, 0.1728169964955679, 0.49, 0.37, -0.22, 0.17, -0.82, -0.41, -0.42482093036566004, -0.34, -0.14, 0.33, 4.49, 0.51, -0.3, 0.0, 0.56, 0.43, -0.28, -0.47, 4.15, 0.18, -0.63, -0.33, 0.23, 0.1, -2.3, -0.93, 0.05, -0.13, -4.29, 0.03, -0.08, -0.36, 0.37, 0.23, -0.4, -0.75, -0.16, 0.61, 0.39, -0.11, -0.15, -1.0885238095238097, 0.89, 0.75, -0.35, -0.95, -0.84, -1.0, 0.47, -0.31, -6.17, 0.35, 0.0, -1.37, -4.43, -3.81, -4.59, -4.3, -3.76, -3.88, -0.92, -0.65, -0.81, -0.51, 0.05, -0.08, 0.16, 0.3, 0.86, 0.74, -0.49, -0.51, -0.14, 0.56, 0.44, -0.43, -0.43, -0.07742395037612165, -1.41, -0.84, 1.11, 0.11, -1.09, -0.69, -0.12, -0.27, 0.21, -0.9, 1.05, -0.67, -0.57, -1.06, -1.56, -1.61], ['357', -2.92, -0.52, 0.22122171562045873, 0.14, -1.51, -2.8, -1.8758847420401707, -3.3, -3.33, -3.84, 1.1, -1.76, -0.23, 0.12, -1.27, -3.49, -0.67, -3.29, -2.29, -1.53, -4.85, -0.78, -0.9256947683993239, -1.09, -3.26, -2.560628585411108, -4.89, -2.83, -1.32, -0.97, -2.35, -4.54, -1.76, -4.35, -3.35, -2.6, -5.89, -1.86, -2.1, -2.17, -2.602531574646789, -6.22, -1.920696767518196, 1.55, 1.91, 0.49, -1.76, 1.11, -1.56, -0.54, 0.24, -3.15, 1.0, 0.75, 0.68, -1.63, -3.38, -1.88, -2.46, -3.62, 0.35, -1.039200680272109, -3.27, -0.44, -3.06, -2.06, -1.3, -4.63, -0.55, -0.79, -0.86, -4.47, -3.96, -1.39, -3.61, -0.79, -3.41, -2.4, -1.64, -4.97, -0.9, -1.14, -1.21, -5.16, -8.09, 8.17, -2.6, -2.24, 0.61, -2.04, -0.7842114512471654, -0.25, -3.62, 0.5, 0.26, 0.18, -0.9, -0.36, 2.92, 0.21, 1.25, 2.04, -1.41, 2.81, 2.56, 2.48, -0.47, -0.38, -3.28427628811696, -2.68, -2.57, -2.6443264813499683, -3.19, -2.64, -1.63, -0.86, -4.21, -0.11, -0.35, -0.43, -2.76, -0.57, 1.04, 1.82, -1.61, 2.6, 2.35, 2.27, -2.8281719617057965, -3.05, 0.21, -2.81, -1.76, -0.5677486640343783, -0.61, 4.68, -4.72, -2.371189828992379, -0.19, -4.19, 4.56, 5.33, 2.66, -1.39, -2.5, -7.96, 7.96, 8.01, -2.63, 7.06, -5.25, -1.4, 0.73, -9.5, 17.62, 6.39, 9.49, -4.59, -1.59, 0.78, -2.62, 1.54, 1.3, 1.3857617128436457, -7.886832100439243, -2.35, -3.38, 0.76, 0.51, 0.44, 1.06, 4.28, 4.03, 3.95, -3.079864861329147, -3.88, -3.09, -0.24, -0.32, -2.71, -2.64, -3.48, 8.84, -3.22, -8.53, -2.95, -3.32, -2.771362551799029, -0.08, -2.5599225974772195, -2.17, -2.38, -2.43, -2.85, -2.78, -2.88, -3.54, -2.06], ['358', 3.93, -0.9, 0.13, -0.02, -0.52, 0.2, 0.8141152579598292, -0.05, -0.39, 0.3970884353741497, 0.36, -0.77, 0.28, -0.05, -0.28, -1.04, 0.53, 0.03, 1.66, 1.83, -0.44, 0.13, 0.89, -0.26, 0.49, -0.45, -0.41, -1.13, -0.08, -0.41, -0.64, -1.4, 0.17, -0.33, 1.3, 1.47, -0.8, -0.23, 0.53, -0.5761582768021608, -0.55, -1.98, 0.730204081632653, 1.06, 0.73, 0.49, -0.27, 1.31, 0.81, 2.45, 2.63, 0.33, 0.91, 1.67, 0.51, 0.04, 0.08, 1.07, -0.25, -0.33, -0.33, -0.56, -1.32, 0.25, -0.25, 1.38, 1.55, -0.72, -0.15, 0.61, -0.54, 1.37, 0.0, -0.23, -0.99, 0.58, 0.08, 1.71, 1.88, -0.39, 0.18, 0.94, -0.22, -1.0, -1.86, 1.77, 0.23, -0.6719125667872351, 0.81, 0.31, 1.95, 2.12, -0.16, 0.41, 1.17, 0.02, 1.66, 1.0773665312165628, 1.59, 1.08, 2.73, 2.91, 0.61, 1.18, 1.95, 0.79, -0.01, 1.02, -0.67, 0.2, 0.02, 0.16, -0.57, -0.5, 1.13, 1.3, -0.9593197278911564, -0.4, 0.36, -0.79, -0.18, -0.08, 1.63, 1.8, -0.47, 0.1, 0.86, -0.29, -1.86, -2.03, 0.17, -0.63, 3.28, -0.21, 0.07, -1.04, 1.05, 0.32, -0.51, -1.18, 3.62, -0.31, -0.16, 1.91, 0.65, 0.31, -0.29, -0.7, -0.32, -1.57, 0.39, -0.91, 0.48, -1.64, -2.93, 1.11, 1.58, -3.69, -1.68, 0.17, -2.07, -1.51, -0.76, -1.9, 0.53, -1.85, -2.23, -1.68, -0.93, -2.06, 0.39, 0.57, 1.33, 0.18, -0.43, -0.73, -0.18, 0.76, -0.39, 0.14, 0.04, 0.05, -1.44, -0.5898003730425007, 1.4165238095238095, -0.75, -1.11, -0.93, -1.14, -0.3, 0.1, -0.06, -0.06, -0.18, 0.22, -1.26, -1.3, -0.06], ['359', -0.46, 0.33, 0.13122171562045873, -0.3, 0.28, 0.85, -0.13588474204017084, 1.22, 0.65, 0.55, -0.61, 1.38, -0.96, -0.43, -0.89, 0.85, -0.76, 0.85, -2.02, -0.78, 0.43, -1.15, -1.19, -0.5, 0.59, 0.85, 1.16, 2.0, -0.36, 0.18, -0.29, 1.47, -0.15, 1.46, -1.42, -0.17, 1.04, -0.55, -0.59, 0.1, 1.17, 0.83, -0.6206967675181959, -2.31, -1.78, -2.24, -0.52, -2.11, -0.52, -3.35, -2.13, -0.94, -2.49, -2.53, -1.85, 0.35, 0.55, 0.86, 1.08, 1.52, 0.54, 0.07, 1.83, 0.21, 1.83, -1.07, 0.18, 1.4, -0.19, -0.23, 0.46, 1.2, 0.98, -0.46, 1.29, -0.33, 1.28, -1.6, -0.35, 0.86, -0.73, -0.76, -0.07, 1.17, 4.95, -4.91, 1.48669823838532, 1.76, 0.14, 1.76, -1.14, 0.11, 1.33, -0.26, -0.3, 0.39, 0.39, -0.3, -1.6, 0.0, -2.85, -1.62, -0.42, -1.99, -2.02, -1.34, -0.029020408163265305, -0.31, 2.4157237118830404, 1.08, 1.3, 0.79, 1.31, 1.62, -1.27, -0.02, 1.2, -0.4, -0.35401213658444736, 0.26, 1.42, -0.3, -2.85, -1.62, -0.42, -1.8542004503433074, -2.02, -1.34, 1.57, 1.39, -0.23, 1.18, 1.22, -0.26, 0.07, -1.34, 1.32, 0.67, 0.43, 0.77, -2.52, -2.11, -1.09, -0.2, 0.56, 3.320596861471862, -3.16, -3.26, 1.08, -1.92, 2.16, 1.45, -0.95, 3.9, -6.0, -2.65, -3.86, 2.57, 2.62, 1.27, 2.5, 0.89, 0.85, 1.55, 3.26, 1.34, 1.22, -0.37, -0.41, 0.28, 0.12, -1.5671150714365, -1.61, -0.93, 0.72, 1.01, 1.72, -0.04, 0.66, 1.09, 1.1, 1.27, -3.2, 2.2311163791806696, 3.26, 1.0572638105244332, 2.13, 1.76, 0.7, 0.68, 0.77, 0.5, 0.67, 0.53, 1.05, 1.71, 2.09, 0.83], ['360', -4.66, -0.29, 0.19122171562045873, 0.23, -1.18, -0.19, -0.45, -0.47, -1.09, -1.02, 0.38, -0.08, -0.87, -1.16, -0.63, -0.85, 0.37, -0.86, -1.92, 1.51, -1.73, -0.88, -0.76, -0.84, -0.88, -0.95, -1.4, -0.46, -1.25, -1.54, -1.01, -1.23, -0.01, -1.24, -2.3, 1.12, -2.1, -1.25, -1.13, -1.22, -0.6, -1.1450638007838265, -0.95, -0.7188025325038829, -1.09, -0.55, -0.77, 0.45, -0.79, -1.85, 1.59, -1.65, -0.7061344435209982, -0.68, -0.76, -0.08, -0.39, -1.23, -1.31, -0.15, -0.29, 0.25, 0.03, 1.26, 0.01, -1.06, 2.4, -0.86, 0.0, 0.12, 0.03, -0.2763939988582844, 0.14, 0.54, 0.32, 1.55, 0.3, -0.77, 2.7, -0.57, 0.29, 0.41, 0.33, -1.47, -1.04, 0.97, -0.4, -0.22, 1.0, -0.24, -1.31, 2.15, -1.11, -0.25, -0.13, -0.21, -2.03, -0.17, 1.23, -0.02, -1.08, 2.38, -0.88, -0.03, 0.09, 0.01, -0.26, -0.15, -1.3, -0.32, -0.39, -0.37, -1.3890429599640124, -1.23, -2.29, 1.13, -2.09, -1.24, -1.12, -1.21, 0.12653607107178547, -0.10692325186963274, -1.07, 2.482244713705627, -0.87, -0.01, 0.11, 0.03, -0.76, -1.12, 0.12, -0.75, -6.13, 0.13, 0.06, 0.21, -0.25, -0.12, 0.45, 0.3, 5.01, 0.63, 0.38, -2.38, -0.09, -1.12, 1.05, 1.01, -0.33, 0.49, -0.65, -1.79, 0.88, -4.13, -0.18, 2.76, 4.13, -4.87, 0.92, 3.5, 0.2, 1.07, 1.19, 1.11, -0.98, -2.49, -3.19, -2.35, -2.23, -2.31, 0.72, 0.87, 0.99, 0.9, -1.08, -1.24, -0.15, 0.12, 0.11224875531501632, -0.33, -0.45, -0.42, 0.47, -1.21, -0.66, -0.43, -1.32, -0.27, -0.08, -0.67, -0.08, 0.01, -0.03, -0.3, -0.18, -1.72, -1.81, -0.02], ['361', 4.91, 0.01, -0.12, 0.47, -0.23, -1.47, -0.6, -2.42, -2.12, -2.05, 1.65, -1.68, 0.42, 0.5170238095238096, -0.16, -3.559285714285714, 0.25, -1.1294285714285712, -0.83, -0.01, -2.28, 0.35, -0.15, 0.68, -2.85, -1.68, -3.65, -3.28, -1.22, -1.12, -1.78, -5.13, -1.38, -2.74, -2.45, -1.64, -3.87, -1.29, -1.78, -0.96, -1.11, -3.42, -0.38, 2.13, 2.23, 1.55, -1.91, 1.96, 0.56, 0.86, 1.7, -0.61, 2.06, 1.55, 2.4, -0.89, -1.41, -1.8980521152823784, -2.16, -2.46, 0.1, -0.57, -3.96, -0.17, -1.54, -1.24, -0.42, -2.69, -0.07, -0.57, 0.26, -2.64, -2.55, -0.67, -4.05, -0.11051058745176379, -1.63, -1.34, -0.52, -2.78, -0.17, -0.67, 0.17, -3.46, -5.95, 5.861428571428572, -1.9, -3.41, 0.41, -0.97, -0.68, 0.15, -2.13, 0.51, 0.0, 0.84, 2.75, 1.57, 3.95, 2.52, 2.83, 3.68, 1.33, 4.05, 3.53, 4.4, -1.07, 1.61, -2.83, -1.82, -1.96, -1.84, -2.29, -1.37, -1.08, -0.26, -2.53, 0.1, -0.4, 0.43, -2.2, -0.93, 0.3, 1.13, -1.17, 1.49, 0.99, 2.0721774376417237, -2.37, -1.17, 0.86, -2.27, 5.47, -0.13, 0.0, 3.88, -3.94, -1.94, -0.71, -2.75, 4.07, 3.72, 1.82, 2.38, -1.11, -5.66, 5.66, 5.57, -1.83, 5.83, -3.66, -5.46, 2.73, -6.88, 9.96, 4.59, 6.92, -3.9228690476190478, -1.23, 0.83, -1.46, 1.19, 0.69, 1.53, -5.5, -2.04, -2.27, 0.36, -0.15, 0.69, 0.24, 2.69, 2.18, 3.03, -2.18, -2.63, -2.39, -0.5, 0.33, -1.86, -1.91, -2.32, 4.82, -3.23, -4.58, -2.03, -1.99, -1.9, 0.84, -2.55, -1.55, -0.83, -1.02, -1.91, -2.71, -1.81, -2.68, -3.39], ['362', 0.92, 0.37, 0.26122171562045876, 0.36, -0.65, 0.02, -0.13588474204017084, -0.7, -0.99, 0.05, 1.6, 0.35, -1.11, -1.74, 1.05, -0.01, 0.32, 0.23, -3.45, 0.46, -0.04, 0.63, 0.44, 1.06, -1.15, 0.21, -1.53, -1.23, -2.67, -3.29, -0.54, -1.58, -1.26, -1.35, -4.97, -1.12, -1.61, -0.95, -1.14, -0.53, 0.54, -2.76, -0.3, -1.46, -2.08, 0.7, -0.3590816326530612, 0.009278911564625847, -0.12, -3.79, 0.11476190476190476, -0.39, 0.28, 0.7214285714285714, 0.71, -0.14, 0.47, -1.52, -1.199047619047619, 1.17, -0.64, 2.19, 1.12, 1.45, 1.36, -2.37, 1.59, 1.09, 1.76, 1.57, 2.2, -0.98, 1.82, 2.84, 1.76, 2.1, 2.01, -1.74, 2.25, 1.74, 2.41, 2.22, 2.85, -1.81, -1.22, 1.2, -0.99, -1.0494795918367348, -0.72, -0.81, -4.46, -0.58, -1.08, -0.42, -0.61, 0.01, 2.55, 0.06, 0.33, 0.24, -3.45, 0.47, -0.03, 0.64, 0.45, 1.07, -0.008858126000982985, 0.02, -1.68, -0.13, -0.18, 0.0, -0.27, 0.04659939068867647, -3.77, 0.14, -0.35931972789115646, 0.31, 0.12, 0.74, -0.31, -0.18, -3.68, 0.23, -0.27, 0.4, 0.21, 0.83, -0.73, -1.03, 0.51, -0.52, 5.08, 0.05, 0.29, 0.19, -0.25, -0.1, 0.38, -1.36, 0.78, 0.21, 0.07, 0.44, -0.39, -0.36, 0.3, 0.27, -0.11, 0.27, -0.18, -2.24, 1.164765264284247, -0.93, -1.01, 0.61, 0.82, -0.7, 3.950378684807256, 4.06, 3.54, 4.23, 4.04, 4.68, -0.32, -0.41, -0.5, 0.17, -0.02, 0.6, 0.09, 0.67, 0.48, 1.1, -1.02, -1.46, -0.58, -0.19, 0.43, -0.1, -0.09, -0.6, -0.41, -2.0, 0.27, 0.73, 0.5510935020800125, -0.39, 0.62, -0.15, 0.11, -0.33, -0.47523809523809524, 0.38, -1.0, 2.66, 0.013037664716236297, -2.24], ['363', -0.29, -0.21, -0.12984710169072947, 0.18, -0.3, -0.17, 0.69, -0.59, -0.51, -0.25, 1.47, -1.05, 0.27, 0.27, 0.57, -0.45, 0.04, 0.03, -0.95, -0.05, -0.57, -0.25, 0.07, -0.35, -0.44, 0.01, -1.7, -2.48, -1.18, -1.19, -0.89, -1.89, -1.41, -1.42, -2.38, -1.5, -2.01, -1.7, -1.38, -1.7461582768021608, -0.13, -1.14, 0.81, 1.34, 1.4978753944468233, 1.63, 0.61, 1.1, 1.09, 0.1, 1.01, 0.48, 0.81, 1.13, 0.71, -1.52, -0.29, 0.22, 0.0, -0.52, -0.01, 0.29, -0.72, -0.24, -0.24, -1.22, -0.32, -0.676578845757417, -0.52, -0.21, -0.62, -0.98, -0.52, 0.3, -0.71, -0.23, -0.23, -1.21, -0.32, -0.84, -0.52, -0.2, -0.62, -1.37, -0.48, 0.41, -0.81, -1.01, -0.53, -0.53, -1.51, -0.61, -1.13, -0.81, -0.5, -0.91, 0.35, 0.2, 0.49, 0.48, -0.5, 0.4, -0.12, 0.2, 0.52, 0.1, -0.17, 0.22, -0.56, -0.26, -0.17, -0.26, -0.29, -0.01, -0.99, -0.09, -0.61, -0.29, 0.03, -0.3314153161169343, -0.09, -0.28, -0.98, 0.012244713705627006, -0.6, -0.28, 0.04, -0.38, -0.12, -0.1, 0.27, 0.23318678362356798, 0.98, -0.02, 0.0, 0.99, -1.02, -0.49, 0.2, -0.8497402597402597, 0.3, 0.46, 0.27, -0.12, 0.003079789868779062, -0.77, 0.71, 0.79, -0.26, 1.42, -0.53, -1.24, 0.61, -0.88, 2.76, 0.5, 0.75, -0.3, 0.7, 0.91, 0.38, 0.7, 1.03, 0.6, -0.72, -0.2, -0.52, -0.2, 0.12, -0.3, 0.32, 0.32, 0.64, 0.22, -0.45, -0.83, 0.0, 0.32, -0.1, -0.26, -0.21, -0.65, 1.6, -0.59, -1.44, -0.23, -0.79, -0.32, -0.42, -0.25, -0.24, -0.05, -0.12, -0.23, 0.1, 1.64, -0.41, -0.18], ['364', -0.69, -0.32, 0.05122171562045875, 0.07, -0.1170209190089404, 0.85, 1.0041152579598291, 1.41, 0.48, 0.85, 0.47, 0.42, 0.46, -0.51, -2.7, 1.14, 0.87, 0.67, -3.77, 1.47, 0.71, 1.27, -0.42, 1.08, 0.48, 0.54, 0.38, -0.05, 0.0, -0.97, -3.15, 0.67, 0.4, 0.21, -4.22, 1.0, 0.24, 0.8, -0.89, 0.61, 2.01, -0.5250638007838266, 0.43, 0.05, -0.92, -3.1, 0.72, 0.46, 0.26, -4.17, 1.05, 0.29, 0.9438655564790018, -0.84, 0.67, 0.68, 0.74, 0.66, 0.73, 0.38, -0.96, -3.15, 0.67, 0.41, 0.21, -4.21, 1.01, 0.25, 0.81, -0.88, 0.62, 0.94, 1.36, -2.21, 1.65, 1.39, 1.19, -3.28, 1.99, 1.22, 1.79, 0.08, 1.6, 0.37, 2.9, -2.92, 3.65, 3.95, 3.67, 3.47, -1.1, 4.29, 3.51, 4.08, 2.34, 3.89, -2.4, -0.29, -0.26, -0.46, -4.85, 0.33, -0.42, 0.13, -1.54, -0.05, 0.03, -0.36, -2.09, 0.36, 0.78, -0.14, -0.02, -0.2, -4.6, 0.6, -0.16, 0.4, -1.29, 0.21, -0.41, 0.17, -4.41, 0.8, 0.04, 0.59, -1.09, 0.6521774376417234, 0.74, 0.45, 0.23, 0.32, -7.08, 0.0, -0.14, 1.55, -1.54, -0.76, -0.45, 2.18, 1.37, -0.73, -0.35, -0.31, 0.71, 1.02, -1.01, -1.11, 0.36, 2.3, 0.77, -0.33, 0.14, -0.12, -3.4, 0.0, 0.13, -1.27, 4.8, 5.45, 4.65, 5.24, 3.47, 5.04, 1.08, -0.62, -0.75, -0.2, -1.87, -0.38, 0.14, 0.56, -1.13, 0.37, 0.58, 0.53, -0.42, -1.67, -0.19, 0.36, 0.3, 1.44, -0.98, -1.86, 1.03, -1.0, 0.77, 1.28, 1.52, 1.2, -0.69, 0.32, 1.78, 0.55, -0.23, 0.46024063436563456, 2.9, -0.33], ['365', -5.08, 0.04, -0.028778284379541254, 0.09, -1.06, -0.11, 0.6700361663652803, -0.41, -0.2, -0.15, 0.28, -1.14, 0.66, 1.25, 0.46, 1.46, 0.45, -0.23, -0.56, 2.33, -0.55, -0.35, 0.41, 0.42, -1.14, -0.87, -0.43, -1.4098214285714286, 0.3846428571428572, 1.10318993704708, 0.18, 1.18, 0.17, -0.51, -0.84, 2.05, -0.83, -0.63, 0.13, 0.13, -0.42, -1.19, 1.189303232481804, 1.82, 2.41, 1.61, 2.63, 1.61, 0.92, 0.58, 3.51, 0.59, 0.79, 1.56, 1.57, -0.42, 0.04, 0.15, -0.6, -0.81, 0.58, -0.2, 0.8, -0.21, -0.88, -1.21, 1.66, -1.21, -1.01, -0.25, -0.21581519274376415, 1.45, -1.38, -0.78, 0.21, -0.78, -1.46, -1.79, 1.07, -1.78, -1.58, -0.83, -0.82, -0.64, -1.5, 1.49, -0.61, 1.0, 0.0, -0.68, -1.01, 1.87, -1.01, -0.81, -0.05, -0.04, -3.2679047619047616, -1.512633468783437, -0.99, -1.67, -1.99, 0.86, -1.99, -1.79, -1.04, -1.03, 0.07, -1.61, -3.589822996574516, -0.47, -0.52482093036566, -0.39, -0.5381905235138708, -0.68, -1.01, 1.87, -1.0, -0.8, -0.05, -0.04, -0.09, 0.07, -0.33, 2.57, -0.33, -0.13, 0.64, 0.64, -0.49, -0.04, 0.15603717887804044, -0.65, -9.63, -0.03, -0.09, 1.5, -1.52, -0.73, -0.43, -1.8297402597402599, 4.84, 0.94, 0.45, -2.51, 0.3, -1.47, 1.49, 1.36, -0.46, 2.22, -0.93, -0.42, 0.18, -1.84, 5.97, 1.29, 1.79, -4.88, 0.41, 2.91, 0.01, 0.21, 0.97, 0.98, -1.46, -2.43, -2.82, -2.63, -1.8712346938775508, -1.8785714285714286, 0.4, 0.2, 0.97, 0.97, -0.22, -0.42, 0.2, 0.76, 0.77, -0.47, -0.51, -0.38, 3.65, -2.45, -3.65, -1.84, -1.16, -0.56, 0.01, -0.48, -0.63, 0.24, 0.53, -0.15, -0.57, -3.48, -2.07, -0.61], ['366', -2.89, -0.35, 0.011221715620458745, 0.23, -1.19, -0.31158037632624047, -0.6858847420401708, -1.45, -1.16, -1.92, -0.36, -1.72, -1.35, -0.8, 0.91, -1.46, -1.31, -1.97, -0.89, -1.04, -2.37, -0.93, -0.6356947683993238, -1.73, -1.1, -0.540628585411108, -1.5373416050068875, -1.36, -0.99, -0.29681006295292, 1.3278199712950913, -1.11, -0.96, -1.62, -0.54, -0.68, -2.02, -0.57, -0.37, -1.38, -1.4, -1.41, -0.21, 0.38, 0.94, 2.67, 0.26, 0.41, -0.26, 0.84, 0.69, -0.67, 0.8938655564790019, 1.0, -0.02, -1.45, -1.13, -0.75, -1.25, -0.58, 0.56, 2.28, -0.12, 0.03, -0.63, 0.46, 0.31, -1.04, 0.42, 0.62, -0.39, -1.6763939988582846, -1.14, 1.72, -0.67, -0.3705105874517638, -1.19, 0.14747644815501967, -0.24, -1.59, -0.13, 0.06, -0.94, -1.71, -3.26, 3.22, -2.7633017616146796, -2.35, -2.2, -2.85, -1.78, -1.93, -3.25, -1.82, -1.62, -2.61, -0.77, -0.3926334687834371, 0.15, -0.52, 0.8866683673469387, 0.43, -0.93, 0.54, 0.74, -0.27, -0.12, -0.41, -1.69, -0.42, -0.62, -0.23, -0.61, -0.66, 0.43, 0.28, -1.07, 0.39, 0.59, -0.42, -0.8334639289282145, 0.05, 1.1, 0.95, -0.41, 1.06, 1.26, 0.24, -0.68, -0.54, 0.06, -0.37, -2.16, -0.24, -0.21, -0.26, 0.24, 0.13, -0.29, -1.43, 1.8, 0.8, 0.38, -1.4, -0.38692021013122097, -1.29, 1.27, 1.23, -0.44, -0.39, -0.86, -3.33, 1.68, -1.76, 4.31, 1.19, 1.77, -1.7, -1.04, -0.15, -1.49, -0.04, 0.16, -0.85, -1.25, -0.89, -1.35, 0.11, 0.31, -0.7, 0.46, 1.48, 1.68, 0.66, -1.14, -1.56, -1.0, 0.3932337781266354, -0.81, -0.42, -0.44, -1.41, 2.03, -1.35, -2.05, -0.11, -0.7989064979199876, -1.2, -1.01, -0.58, 0.3, -0.47, -0.56, -0.29, -0.19, -1.13, -1.15, -0.27], ['367', 5.21, 0.56, 0.07122171562045874, 0.03, 0.99, 1.25, 0.6, 2.16, 1.69, 2.39, 0.7303184712113286, 1.82, 1.26, 0.13, -0.9, 1.28, 0.86, 1.85, 2.46, 1.87, 3.04, 1.21, 0.95, 1.33, 2.49, 2.27, 1.87, 1.3, 0.74, -0.39, -1.4, 0.76, 0.34, 1.32, 1.94, 1.35, 2.51, 0.69, 0.44, 0.81, 2.21, 1.95, 0.56, -0.56, -1.66, -2.67, -0.54, -0.95, 0.02, 0.63, 0.05, 1.19, -0.6, -0.85, -0.49, 1.9800628463056764, 1.93, 1.16, 2.03, 1.12, -1.11, -2.12, 0.02, -0.39, 0.58, 1.19, 0.61, 1.76, 0.09295748299319728, -0.3, 0.07, 1.13, 2.26, -1.02, 1.15, 0.73, 1.71, 2.33, 1.74, 2.91, 1.08, 0.82, 1.2, 1.7, 4.0, -3.96, 3.32, 2.19, 1.77, 2.77, 3.39, 2.79, 3.97, 2.13, 1.87, 2.24, 3.57, 1.11, -0.41, 0.56, 1.17, 0.59, 1.74, -0.06, -0.32, 0.05, 0.6, 1.18, 2.48, 1.14, 1.22, 1.24, 1.52, 0.98, 1.59, 1.01, 2.16, 0.35, 0.09, 0.46, 1.17, 0.54, 0.61, 0.03, 1.17, -0.62, -0.88, -0.51, 1.35, 1.13, 0.23, 1.76, 10.77, 0.6, 0.9428571428571428, -1.79, 1.71, 0.87, 0.52, 1.41, -1.05, -2.33, -1.17, 2.58, 0.49, 3.69, -3.58, -3.37, 1.14, -2.66, 2.3, 0.25, -0.1, 4.48, -8.49, -3.0, -4.53, 0.97, -0.07, -0.58, 0.56, -1.22, -1.47, -1.11, 3.46, 0.51, 1.14, -0.65, -0.9, -0.54, -0.62, -1.77, -2.02, -1.66, 1.76, 1.88, 1.17, -0.26, 0.11, 1.12, 1.29, 2.04, -4.9, 2.44, 5.0, 2.73, 2.23, 1.43, 0.37, 1.97, 0.99, 0.26529795204795226, 0.29, 0.49, 1.05, 4.74, 3.3, 1.05], ['368', -0.08, 0.42, -0.07984710169072946, -0.01, -0.29, 0.08, 0.5, 0.71, 0.37, 0.43, 0.52, -0.06, 0.11, -0.03, -0.61, 0.87, 0.6, 0.31, 1.55, 1.55, 0.39, 0.36, 0.06, 0.41, 0.8, 0.23937141458889197, -0.09, -0.58, -0.42, -0.55, -1.0721800287049086, 0.34, 0.07, -0.21, 1.03, 1.02, -0.13, -0.17, -0.46, -0.11, 2.24, 0.4808975626058773, 0.5, 0.17, 0.03, -0.55, 0.93, 0.66, 0.37, 1.62, 1.61, 0.45, 0.42, 0.12, 0.47, 0.9900628463056765, 0.22, 0.87, 0.52, 0.33, -0.14, -0.72, 0.76, 0.49, 0.21, 1.4671802721088434, 1.44, 0.28, 0.25, -0.05, 0.31, 0.75, 0.47, -0.58, 0.9, 0.63, 0.34, 1.59, 1.58, 0.42, 0.39, 0.09, 0.45, -0.1, 1.0, -1.03, 1.05, 1.49, 1.22, 0.93, 2.18, 2.17, 1.01, 0.98, 0.67, 1.03, -0.81, -0.43, -0.27, -0.55, 0.68, 0.68, -0.47, -0.5, -0.8, -0.45, 0.19, -0.42, 1.31, 0.1, 0.19517906963433995, 0.10567351865003197, -0.16, -0.28, 0.95, 0.95, -0.21, -0.24, -0.54, -0.12141531611693432, 0.17, 0.17307674813036728, 1.24, 1.23, 0.08, 0.05, -0.25, 0.1, 0.51, 0.57, -0.1, 0.0, -2.58, -0.08, -0.14, 0.03, -0.04, 0.0, 0.98, -0.09383646788795053, 1.92, -0.18, -0.12, -0.07, -0.04, 0.28, -0.39, -0.25, 0.11, 0.02, 0.19, 1.06, -0.55, -0.56, 0.83, 0.36, 0.57, -1.94, -1.1, -0.01, -1.15, -1.18, -1.48, -1.12, 0.28, -1.09, -1.14, -1.17, -1.47, -1.12, 0.05, -0.03, -0.33, 0.02, 0.36, 0.22, 0.08, -0.3, 0.06, 0.11, 0.04, 0.77, -0.19, 0.5, -0.19, 0.6872638105244333, -0.13, 0.38, 0.36, -0.25, -0.21978021978021978, 0.16, -0.14, 0.694626243824729, 0.02, -0.6697593656343656, -0.51, -0.18], ['369', 2.85, 0.3, -0.29, 0.26, 0.35, -0.49, -0.35, 0.62, -0.62, -0.56, 0.46, 0.1, -0.34, -1.16, -1.75, -2.319285714285714, -1.17, -0.5594285714285715, -0.35, -0.4, -0.56, -1.3738418367346938, -0.17, -0.22, -0.18, 0.67, -1.02, -0.36, -0.79, -1.61, -2.19, -2.76, -1.62, -1.02, -0.8, -0.85, -1.02, -1.84, -0.62, -0.68, 1.06, -0.68, -0.66, -0.43, -1.26, -1.84, -2.3989563492063493, -1.27, -0.66, -0.44, -0.5, -0.66, -1.49, -0.26, -0.32, 0.68, 0.9157142857142857, 0.0, -0.94, -0.23, -0.82, -1.41, -1.9857142857142858, -0.84, -0.23, -0.01, -0.06, -0.23, -1.06, 0.17273474541331685, 0.11, 0.47, 0.6, -0.59, -1.18, -0.01, 0.6, 0.82, 0.77, 0.6, -0.24, 1.0, 0.95, -0.97, 1.01, -1.1, 1.2, -0.58, 0.59, 1.2, 1.42, 1.37, 1.2, 0.44571428571428573, 1.61, 1.55, 1.82, 1.8, 1.18, 1.8, 2.02, 1.97, 1.8, 0.95, 2.2, 2.15, -0.11, 1.83, 1.44, 0.12, 0.23, 0.21, 0.61, 0.61, 0.83, 0.78, 0.61, -0.23, 1.02, 0.96, 0.69, 0.0, 0.22, 0.17, 0.0, -0.83, 0.5985714285714285, 0.34, 0.11, 0.73, 0.5, 0.54, 5.34, -0.2496768707482993, -0.22, -1.18, 1.2, 0.28, 0.39, -0.56, 0.35, -0.28857142857142853, 0.3082806122448981, 1.48, -0.24, 0.56, -0.3771428571428571, -0.3042857142857143, -0.49, -1.69, 0.21, -2.56, 1.31, 1.81, -0.8172908163265306, -1.18, -1.84, -0.51, -0.22, -0.05, -0.22, -1.05, 0.18, 0.12, 0.46, -0.17, -0.17, -1.0, 0.23, 0.18, 0.0, -0.83, 0.4, 0.34142857142857147, -0.63, -0.96, 0.84, 1.24, 1.19, 0.07, 0.32, 0.62, -0.41, 0.97, 0.33, -0.22, 0.05, -0.4, -0.06, -0.38, -0.28, -1.07, -1.48, -0.71, -0.34, 1.11, 1.38, 0.23], ['370', -1.62, 1.26, 0.25, -0.18, 1.01, 1.12, 0.9641152579598291, 2.12, 2.23, 1.35, -1.74, 0.35, -1.3, -2.26, -0.21, 1.6711360544217686, -0.8, 0.47020578231292515, 6.41, 0.01, 2.39, 0.51, -0.67, 0.0, 2.12, 2.33, 3.14, 2.13, 0.45, -0.53, 1.56, 3.44, 0.96, 2.22, 8.29, 1.78, 4.2, 2.29, 1.09, 1.8138417231978392, 1.46, 4.274936199216174, 0.990204081632653, -1.65, -2.6, -0.56, 1.28, -1.14, 0.08, 6.03, -0.34, 2.03, 0.15, -1.02, -0.35, 1.6900628463056764, 1.94, 1.7, 2.51, 2.69, -0.97, 1.11, 2.97, 0.51, 1.76, 7.81, 1.33, 3.74, 1.83, 0.64, 1.32, 2.23, 3.6914285714285713, 2.1, 3.98, 1.5, 2.76, 8.87, 2.32, 4.76, 2.8314285714285714, 1.62, 2.31, 3.18, 5.47, -5.48, 1.56, 1.85, -0.59, 0.65, 6.63, 0.4137447711019141, 2.61, 0.72, -0.46, 0.21, -0.21, -0.28, -2.39, -1.18, 4.7, -1.6, 0.74, -1.11, -2.27, -1.61, 0.74, -0.28, 1.81, 0.79, 1.23, 1.31, 2.16, 1.24, 7.26, 0.81, 3.21, 1.31, 0.12, 0.8, 0.17653607107178546, 0.91, 5.94, -0.43, 1.94, 0.07, -1.1, -0.44, 2.18, 1.98, -0.08, 1.4, -0.44, 0.31, 0.21, -2.71, 2.75, 1.38, -2.37, 1.47, -2.68, -2.5, -1.27, -0.82, 0.58, 3.97, -3.9, -3.83, 1.26, -4.15, 2.57, 2.73, -1.38, 6.42, -3.73, -4.25, -6.46, 2.6171309523809523, -4.75, -6.01, -3.77, -5.55, -6.65, -6.02, 3.81, 1.34, 2.38, 0.5, -0.68, -0.01, -1.02, -1.84, -2.99, -2.34, 2.13, 2.84, 0.84, -1.17, -0.5, 1.31, 1.36, 2.03, -2.35, 1.89, 2.18, 2.16, 1.62, 2.03, 0.68, 1.74, 1.12, 0.12, 0.51, 1.15, 1.35, 3.4, 2.51, 1.62], ['371', -0.38, 0.0, 0.09122171562045875, 0.05, -0.89, -0.11, -0.4558847420401708, 0.07, -0.19, -0.23, -0.09939115646258503, -0.18, -0.52, -0.85, 0.28, -0.4, 0.13, -0.08, 4.49, 1.19, -0.09, -0.13, 0.14, 0.08, -0.47, -0.11, -0.12, -0.07, 0.007674603174603278, -0.73, 0.39, -0.2897142857142857, 0.24, 0.04, 4.61, 1.3, 0.03, -0.01, 0.25, 0.19, -1.04, -0.25506380078382657, -0.05, -0.25880253250388296, -0.67, 0.46, -0.22, 0.31, 0.1, 4.68, 1.37, 0.09, 0.05, 0.32, 0.26, -0.17, -0.38, 0.48, 0.29, 0.29, -0.33, 0.8, 0.11, 0.65, 0.44, 5.04, 1.8339757335335067, 0.44, 0.39, 0.66, 0.6, 0.55, 0.62, 1.13, 0.45, 0.98, 0.77, 5.39, 2.05, 0.77, 0.73, 0.99, 0.93, -0.18, -0.91, 0.95, -0.51, -0.68, -0.15, -0.35, 4.21, 0.9, -0.36, -0.4, -0.14, -0.2, 0.38, 0.17, 0.54, 0.33, 4.92, 1.6, 0.32, 0.28, 0.54, 0.49, -0.23, 0.12, -1.38, -0.07840181931709851, -0.14, -0.09, -0.36, -0.21, 4.36, 1.05, -0.21, -0.26, 0.01, -0.05, -0.08, -0.16, 4.58, 1.26, -0.01, -0.05, 0.21, 0.16, -0.45, -0.48, 0.27, -0.14, 1.27, -0.09, -0.15, 0.37, -0.23827987418743707, -0.18, 0.14, -0.68, 2.71, 0.27, 0.11, -0.2, 0.16307978986877908, -0.35, 0.37, 0.33, -0.07670919513614705, 0.49, -0.24, -1.14, 0.56, -1.07, -1.12, 0.71, 1.04, -2.344384920634921, -4.52, -3.17, -4.38, -4.42, -4.17, -4.22, -0.34, -1.4, -1.26, -1.3, -1.04, -1.09, -0.15, -0.04, 0.22, 0.17, -0.15, -0.02, -0.11, 0.26, 0.21, -0.11, -0.11, 0.14, -0.52, -1.16, 0.58, -0.17, -0.29, -0.37, -0.05, 0.14, -0.07, -0.2, 0.05, 0.25, -0.31, -0.38, -0.8584047619047619, -0.79], ['372', 9.71, 0.0, 0.04, -0.03, 1.29, 0.58, 0.75, 1.18, 0.87, 0.4453571428571429, -0.6, -0.5606751700680271, -1.19, -0.1, -1.64, -2.05, -0.75, 0.11, -0.5, -1.55, 0.64, 0.31, -0.83, -0.75, 0.95, 1.32, 0.98, 0.03, -0.6, 0.5, -1.05, -1.45, -0.15, 0.71, 0.1, -0.96, 1.25, 0.91, -0.23, -0.15, 1.5, 0.55, 0.96, -0.5388025325038829, 0.47, -1.08, -1.48, -0.17, 0.69, 0.08, -0.98, 1.22, 0.89, -0.26, -0.18, 0.77, 1.91, 0.88, 1.36, 1.59, 1.11, -0.45920068027210886, -0.86, 0.45, 1.32, 0.7, -0.23602426646649322, 1.86, 1.52, 0.37, 0.45, 1.69, 0.48, -1.54, -1.95, -0.65, 0.21, -0.4, -1.45, 0.75, 0.41, -0.73, -0.65, 0.59, 2.89, -2.93, 2.0966982383853203, -0.41, 0.91, 1.79, 1.17, 0.09, 2.33, 1.99, 0.83, 0.91, 3.24, 2.47, 1.33, 2.3053350340136056, 1.58, 0.5, 2.75, 2.4, 1.24, 1.32, 0.28, 2.44, 2.53, 0.82, 0.82, 0.87, 1.13, 0.86, 0.25, -0.81, 1.4, 1.06, -0.08, -0.01, 0.26, 0.27, -0.61, -1.66, 0.53, 0.2, -0.94, -0.86, 0.68, 0.68, 0.02, 0.99, 9.72, 0.05, -0.03, -1.51, 1.47, 0.72, 0.25406627346681526, 0.8, -3.8094817511227284, -1.65, -0.89, 4.77, 0.34, 2.45, -2.61, -2.51, 0.82, -2.25, 1.67, 0.97, -0.51, 3.42, -2.17, -2.33, -3.37, 4.04, 0.88, -1.06, 1.15, 0.81, -0.33, -0.26, 2.51, 1.9601587301587302, 2.23, 1.89, 0.74, 0.81, -0.27, -0.33, -1.46, -1.39, 0.89, 0.89, 0.07, -1.13, -0.9877512446849838, 0.84, 0.86, 1.13, -1.16, 1.72, 1.28, 1.78, 1.18, 1.21, 0.08, 0.95, 0.7, 0.42, 0.24, 0.68, 1.14, 2.55, 1.88, 2.1], ['373', 1.5, -0.25, -0.31877828437954125, -0.01, 0.83, 0.54, 0.07411525795982916, 0.72, 0.07, -1.34, -1.24, -1.5, -1.66, -2.46, -2.96, -1.28, -2.6, -1.06, 0.11, -3.08, -1.75, -2.69, -2.13, -1.73, 0.48, -0.36, -0.1, -0.26, -0.42, -1.23, -1.73, -0.04, -1.37, 0.19, 1.37, -1.86, -0.51, -1.47, -0.9, -0.49, 1.1574684253532108, 0.0, 0.16, -0.16, -0.97, -1.48, 0.22, -1.12, 0.45, 1.64, -1.6, -0.25, -1.21, -0.64, -0.23, 0.52, 0.25, 0.78, 0.73, 0.32, -0.82, -1.32, 0.38, -0.96, 0.7126050661400617, 1.8, -1.45, -0.09, -1.05, -0.48, -0.07, 0.33, 1.15, -0.51, 1.21, -0.15, 1.44, 2.64, -0.64, 0.73, -0.24, 0.34, 0.75, -0.48, 2.53, -2.6, 1.69669823838532, 1.72, 0.36, 1.96, 3.16, -0.13, 1.25, 0.27, 0.85, 1.27, 0.0, 0.017366531216562897, -1.33, 0.23, 1.41, -1.82, -0.47, -1.43, -0.86, -0.45, -0.39, -0.06, 0.72, 0.68, 0.6, 0.86, 1.29, 1.59, 2.79, -0.49, 0.88, -0.09, 0.48, 0.9, 1.3, -0.29, 1.18, -2.05, -0.7, -1.65, -1.09, -0.68, 0.89, 1.34, -0.13, 1.21, 0.03, 0.13225133596562166, -0.62, -2.19, 2.23, 1.1, 1.01, 0.69, -3.55, -1.35, -0.67, 0.72, 0.04, 2.04, -2.13, -1.93, 0.69, -3.25, 1.39, 0.45, -0.31, 3.88, -1.96, -2.51, -3.83, 3.55, -1.45, -3.19, -1.86, -2.8, -2.24, -1.84, 2.01, 1.8, 1.38, 0.4, 0.98, 1.4, 0.41, -0.96, -0.39, 0.02, 0.0927953514739229, 0.14, 1.39, 0.57, 0.99, 0.63, 0.69, 0.69, -0.96, 1.0101996269574993, 1.1, 0.31, 0.4611825396825397, 0.81, 0.42, 0.68, 1.23, 0.38, 0.01, 0.3846262438247291, 0.39, 1.37, 1.14, 0.56], ['374', 0.79, -0.99, 0.12, -0.11, -0.81, 0.33841962367375944, 1.39, 0.44, 0.1, 0.65, 0.01, -0.26, 0.29, -1.74, 0.06, 0.5, 0.52, 0.64, 2.135862135879993, 1.66, 0.23733548208735894, 0.98, -0.08, 0.62, 0.37, 0.14, 0.6726583949931124, -0.27, 0.28, -1.75, 0.05, 0.5, 0.51, 0.63, 1.96, 1.65, 0.19, 0.97, -0.08, 0.61, 0.3, -0.06506380078382656, 0.91, 0.55, -1.48, 0.32, 0.77, 0.78, 0.91, 2.23, 1.93, 0.46, 1.24, 0.19, 0.88, 0.07, 0.44, -0.07, -0.61, 0.43924524706587753, -2.02, -0.22, 0.22, 0.23, 0.36, 1.67, 1.37, -0.08, 0.69, -0.36, 0.33, -0.82, 2.43, 1.83, 2.29, 2.3, 2.43, 3.77, 3.46, 1.98, 2.77, 1.7, 2.4, 0.0, 1.6, -1.61, 0.59, 0.44, 0.46, 0.58, 1.9, 1.6, 0.14, 0.92, -0.14, 0.56, 2.84, 0.14, 0.01, 0.14, 1.45, 1.15, -0.3, 0.47, -0.58, 0.12, -0.02, 0.16, 0.38, 0.15, 0.33, -0.03, 0.13, 0.12, 1.44, 1.14, -0.32, 0.46, -0.59, 0.1, -0.45, 0.01, 1.31, 1.01, -0.44, 0.34, -0.71, -0.02, 0.34, 0.17, -0.26, 0.13, 8.22, 0.0, -0.07, 0.46, -0.4, -0.21, -0.66, 0.54, 1.92, -0.26, -0.13, 0.4, -0.32, 0.38, -0.39, -0.41, 0.13, 0.62, 0.29, 1.63, -0.81, 0.44, 0.93, -0.24, -0.4, -1.85, -1.29, -0.3, -1.73, -0.97, -2.0, -1.32, 0.35, -0.99, -1.43, -0.67, -1.71, -1.02, 0.45, 0.78, -0.28, 0.42, 0.11, -0.34, -0.33, -1.04, -0.36, 0.16, 0.22439630127529087, 0.5, 0.27, 0.24, -0.23, 0.88, -0.08, 0.72, 0.7, 0.12, -0.15, -0.17, -0.31, 0.25, 0.03, 2.9, 0.43, -0.35], ['375', -2.67, -0.06, 0.21, 0.15, 0.19, 0.51, 0.32, 1.23, 0.68, 1.51, 0.82, 1.21, 0.68, 0.33, 0.4742210884353741, 2.29, 1.1271428571428572, 1.43, 2.24, 0.87, 1.48, -0.08, -0.55, 1.3, 1.1685936610075265, 1.47, 0.68, 0.39, -0.14, -0.49, -0.78, 1.45, 0.26, 0.6, 1.41, 0.05, 0.65, -0.9, -1.36, 0.47, 0.92, 1.09, 0.29020408163265304, -0.53, -0.87, -1.16, 1.06, -0.13, 0.21, 1.02, -0.34, 0.26, -1.28, -1.75, 0.08, 1.6023573314652815, 0.82, 0.78, 0.88, 0.82, -0.35, -0.64, 1.6, 0.4, 0.74, 1.55, 0.19, 0.79, -0.76, -1.219795918367347, 0.61, 0.9, 1.17, -0.29, 1.95, 0.75, 1.1, 1.91, 0.54, 1.14, -0.41, -0.88, 0.97, 1.13, 5.05, -5.2, 1.47, 2.25, 1.04, 1.39, 2.2, 0.83, 1.44, -0.12, -0.59, 1.26, -1.06, -0.76, -1.18, -0.84, -0.05, -1.38, -0.79, -2.32, -2.78, -0.97, 0.36, -0.76, -0.08, 0.19, 0.4, 0.19, 0.42, 0.34, 1.14, -0.21, 0.39, -1.16, -1.62, 0.21, 0.46, 0.08, 0.8, -0.55, 0.05, -1.49, -1.917142857142857, -0.13, 3.04, 3.07, 0.39, 1.07, -3.29, 1.468069549498121, 0.9628571428571429, -1.49, 1.45, 0.73, -2.11, 0.0, -1.31, -1.67, -0.81, -1.33, 0.11, 2.61, -2.58, -2.49, 0.81, -2.19, 1.61, -0.74, 0.37, 2.77, -2.34, -1.79, -2.84, 1.2, -0.72, -1.34, -0.75, -2.27, -2.73, -0.92, 2.4, 0.63, 0.6, -0.95, -1.41, 0.42, 0.03, -1.54, -2.0, -0.18, 0.61, 0.89, 1.59, -0.47, 1.38, 0.75, 0.85, 0.97, -1.01, 0.65, 0.59, 0.95, 1.18, 2.07, 1.86, 0.96, 0.96, -0.34, 0.17, 0.47, 0.21, 2.2, 1.16, -0.23], ['376', 2.87, 0.0, -0.08, -0.03, 0.64, 0.53, 1.144115257959829, 1.34, 1.45, 1.62, -0.26, 0.36, 0.73, 0.75, 0.36, 1.69, 0.71, 1.31, 1.71, 2.02, 2.29, -0.1, 0.95, 0.63, 1.28, 0.76, 1.89, 0.63, 0.99, 1.02, 0.63, 1.96, 0.98, 1.58, 1.98, 2.29, 2.644453670078569, 0.17, 1.21, 0.9, 0.53, 2.0800621118012423, 1.25, 0.36, 0.39, -0.01, 1.32, 0.35, 0.94, 1.34, 1.64, 1.9480654680864429, -0.46, 0.58, 0.27, 0.8, 1.01, 1.4, 1.38, 0.89, 0.03, -0.25515323205954743, 0.96, -0.01, 0.58, 0.98, 1.28, 1.56, -0.82, 0.22, -0.09, 0.86, 0.86, -0.39, 0.93, -0.04, 0.55, 0.95, 1.25, 1.53, -0.85, 0.19, -0.12, 1.94, 2.1, -2.07, 1.26, 1.33, 0.35, 0.95, 1.35, 1.65, 1.93, -0.46, 0.58, 0.27, 0.15, -0.07, -0.96, -0.37, 0.02, 0.32, 0.59, -1.76, -0.73, -1.04, 0.12, -0.01, 0.16, 0.56, 0.62, 0.51, 0.91, 0.59, 1.0, 1.29, 1.57, -0.8, 0.23, -0.08, 1.82, 0.31, 0.4, 0.7, 0.97, -1.39, -0.36, -0.67, 0.77, 0.86, 0.15603717887804044, 0.88, 0.3, 0.03, 0.0, -0.64, 0.61, 0.3, 0.13, 3.1102597402597403, 0.72, -1.13, -0.57, 1.4, 0.53, 1.77, -1.73, -1.7, 0.55, -1.0, 1.07, 0.3, -0.14, 2.77, -5.3, -1.82, -2.79, -0.88, -0.09, 0.3, 0.57, -1.78, -0.76, -1.06, 1.69, -0.38, 0.27, -2.07, -1.05, -1.36, -0.66, -2.34, -1.32, -1.62, 1.37, 1.49, 1.72, 1.05, 0.73, 0.58, 0.63, 1.42, -2.56, 0.51, 2.58, 1.11, 0.9, 0.67, -0.31, 0.55, 0.22, 0.3, 0.67, 0.66, 0.98, 1.03, 0.96, 0.89], ['377', 2.53, 0.69, -0.08, -0.13, 1.95, 0.99, 0.024115257959829165, 1.62, 0.91, 1.46, 0.39, 1.94, -0.39, -0.28, 0.87, 0.55, 0.11, 1.22, -2.58, -1.56, 1.93, -0.42, 0.89, 0.41, 1.62, 2.04, 1.07, 1.54, -0.7598809523809524, -0.67, 0.48, 0.16, -0.27, 0.83, -2.96, -1.94, 1.53, -0.8, 0.5, 0.02, 1.01, 2.6849361992161733, -0.47, -2.28, -2.18, -1.05, -1.36, -1.79, -0.71, -4.428347866419295, -3.44, -0.01, -2.31, -1.03, -1.5, 1.13, 1.54, 0.63, 1.3, 1.86, 0.11, 1.27, 0.94, 0.5, 1.7126050661400618, -2.2, -1.18, 2.33, -0.03, 1.282734745413317, 0.8, 2.43, 1.75, 1.16, 0.83, 0.39, 1.5, -2.31, -1.29, 2.21, -0.14, 1.17, 0.69, 1.12, 1.83, -1.94, 0.58, -0.32, -0.75, 0.34, -3.42, -2.42, 1.2152352330209475, -1.28, 0.01, -0.46, 2.49, 0.91, -0.44, 0.67, -3.11, -2.1, 1.37, -0.96, 0.33, -0.14, 0.48, 0.92, 0.41, 1.22, 1.02, 1.44, 1.35, 1.11, -2.69, -1.67, 1.81, -0.53, 0.77, 0.29, 1.87, 0.24, -3.75, -2.75, 0.7, -1.62, -0.33, -0.8, 0.11, 0.28, -0.26, 1.43, 5.21, -0.03, -0.37, -2.68, 2.7, 1.37, 0.57, 3.79, -5.6794817511227285, -2.43, -1.27, 1.23, 0.41, 3.64, -3.68, -3.61, 1.2, -4.14, 2.4, 2.43, -1.19, 3.99, -8.62, -2.77, -3.97, 5.883809523809524, 4.15, 1.04, 4.63, 2.532096371882086, 3.56, 3.06, 3.57, 3.07, 3.55, 1.17, 2.49, 2.0, -0.46, -2.3, -1.02, -1.49, 0.89, 1.39, 1.88, 1.31, 0.82, 1.2, 1.28, 1.52, -4.24, 1.56, 4.35, 1.96, 2.95, 0.57, -0.48, 1.46, 1.53, 0.39, 0.83, 0.49, 1.05, 2.15, 4.5130376647162365, 1.06], ['378', 1.35, -0.12, 0.09122171562045875, -0.05, 0.1, 0.65, 0.19, 1.26, 1.27, 1.42, -0.81, 0.81, 0.63, 0.02, 0.26, 0.94, 1.01, 0.84, -4.22, 0.85, 2.16, 1.12, 0.64, 1.18, 1.66, 0.46, 2.2826583949931125, 1.63, 1.45, 0.84, 1.08, 1.77, 1.83, 1.66, -3.439285714285714, 1.68, 3.0644536700785694, 1.94, 1.46, 2.0, 0.95, 2.45, 0.61, -0.17, -0.78, -0.54, 0.14, 0.2, 0.03, -4.99, 0.05, 1.34, 0.31, -0.16, 0.37, 0.87, 1.21, 1.32, 0.75, 0.78, -0.61, -0.37, 0.31, 0.37, 0.21, -4.82, 0.22, 1.52, 0.48, 0.01, 0.54, 1.23, 1.4, 0.24, 0.92, 0.99, 0.82, -4.24, 0.83, 2.14, 1.09, 0.62, 1.16, 2.01, 2.12, -2.09, 1.15, 0.68, 0.74, 0.57, -4.47, 0.7837447711019141, 1.89, 0.85, 0.37, 0.91, 0.68, 0.47, 0.06, -0.1, -5.12, -0.09, 1.2, 0.17, -0.3, 0.23, 0.58, 0.48, 0.8, 0.44, 0.54, 0.33, 0.41, -0.17, -5.18, -0.15, 1.14, 0.11, -0.36, 0.17, 0.3, 0.57, -5.02, 0.01, 1.31, 0.27, -0.2, 0.5821774376417235, 0.51, 0.31, 0.08, 0.21, 1.91, 0.05, -0.2, -0.36, 0.3, 0.15, 0.39, 1.37, -1.1, -0.9, -0.48, 0.66, 0.09, 1.38, -1.41, -1.31, 0.44, -0.59, 0.9, 0.9183906549799409, -0.42, 1.16, -4.77, -0.84, -1.21, 1.19, 5.89, 5.3, 6.66, 5.57, 5.08, 5.64, 1.34, 0.56, 1.29, 0.26, -0.21, 0.32, -0.72, -1.02, -1.48, -0.96, 1.24, 1.53, 0.3, -0.47, 0.06, 0.47, 0.41, 1.18, -0.75, 0.66, 0.63, 0.52, 1.09, 0.848637448200971, 0.53, 0.72, 0.55, 0.0, -0.09, 0.2, 0.24, 1.34, 1.81, -0.02], ['379', 5.8, 0.52, 0.04015289830927054, -0.2, 1.86, 1.2, 0.5741152579598292, 1.0, 0.99, 0.73, -0.35, 0.51, 0.4, -0.6, 0.22, -1.11, -0.1, 0.6454705215419502, 0.21, -2.68, 0.93, 0.6370289115646258, -0.42, 0.13, 1.4, 0.71, 1.09, 0.87, 0.76, -0.25, 0.57, -0.76, 0.26, 0.89, 0.56, -2.34, 1.29, 0.7, -0.06, 0.49, 1.37, 1.7249361992161734, 0.22, -0.028802532503882913, -1.11, -0.29, -1.61, -0.61, 0.02, -0.3, -3.18, 0.41, -0.17, -0.93, -0.38, 0.07, 0.38, 1.25, 1.09, 0.33, -1.0, -0.18, -1.5, -0.49, 0.13, -0.19, -3.07, 0.683421154242583, -0.06, -0.82, -0.25056122448979595, 1.5, 1.34, 0.82, -0.51, 0.51, 1.14, 0.81, -2.1, 1.53, 0.94, 0.18, 0.74, 1.21, 3.09, -3.11, 0.52, -1.32, -0.31, 0.32, -0.01, -2.89, 0.71, 0.12, -0.64, -0.08, 1.82, 1.86, 1.02, 1.66, 1.3315238095238096, -1.59, 2.06, 1.46, 0.7, 1.26, 0.21, 1.83, 0.33, 0.95, 1.08, 0.77, 0.83, 0.63, 0.3, -2.59, 1.02, 0.43, -0.32, 0.23, 0.17, 0.2, -0.32, -3.2, 0.39, -0.2, -0.95, -0.4, 1.27, 1.54, -0.25, 1.01, 5.27, 0.1, 0.07, -0.93, 0.94, 0.47, -1.71, 1.17, -6.98, -1.91, -1.0, 2.91, 0.75, 2.84, -2.81, -2.84, 0.95, -1.49, 1.89, 0.89, -0.46, 2.5, -7.059348639455782, -1.73, -2.57, 6.9, 0.53, -2.88, 0.72, 0.13, -0.63, -0.07, 2.82, 3.51, 3.71, 3.3471428571428574, 2.33, 2.89, -0.19, -0.58, -1.33, -0.78, 0.96, 1.07, 0.4, -0.75, -0.2, 0.95, 0.92, 0.89, -4.08, 0.43, 3.86, 1.24, 1.82, 1.16, 0.56, 1.47, 0.8645528598385742, 0.74, 0.39, 0.47, 0.6, 1.78, 1.61, 1.36], ['380', -28.17857142857143, -0.37, 0.15122171562045875, -0.15, -1.35, 0.61, 0.6441152579598292, 2.23, 1.11, 1.81, 1.06, 1.05, -0.55, 0.02, -0.18, 7.230714285714286, 0.92, 1.52, 2.2, 1.45, 1.99, 2.1270289115646257, 0.45, -0.12, 1.45, -0.62, 0.74, -0.01, -1.5798809523809525, -1.03, -1.23, 6.1, -0.14, 0.45, 1.137761904761905, 0.39, 0.92, 0.76, -0.61, -1.17, 2.88, 1.44, 0.75, -1.5763410188391391, -1.02, -1.21, 6.354266594516595, 0.17865136054421765, 0.47, 1.13, 0.4, 0.93, 0.77, -0.59, -1.16, 0.99, 3.16, 2.29, 0.75, 2.37, 0.57, 0.37, 7.82, 1.48, 2.08, 2.76, 2.01, 2.56, 2.39, 1.0, 0.43, 1.97, 1.8, -0.19, 7.21, 0.91, 1.51, 2.18, 1.44, 1.98, 1.81, 0.43, -0.07644035827487929, 1.11, 3.61, -3.52, 1.99, 7.42, 1.1, 1.7, 2.38, 1.63, 2.17, 2.01, 0.6385238095238095, 0.06, -5.8, -5.05, -5.88, -5.32, -4.69, -5.39, -4.88, -4.797183003504432, -6.32, -6.85, 0.65, -5.07, 1.93572371188304, 0.93, 0.5, 0.47, 0.88, 0.59, 1.26, 0.53, 1.06, 0.9, -0.47, -1.03, -0.04, 0.29, 0.9136855802927233, -0.07, 0.47, 0.3, -1.06, -1.62, 1.64, 0.84, -0.36, 1.25, -11.682380952380951, 0.28, 0.15, -2.61, 2.64, 1.33, 0.23, 0.77, -0.38224102088387807, -1.75, -0.91, -14.094778911564626, 0.69, 2.87, -2.7, -2.64, 0.93, -3.95, 1.85, 2.77, -1.33, 3.69, 0.65, -2.3885714285714283, -3.7542857142857144, 0.66, -0.38, -0.73, -0.2, -0.3543095238095238, -1.71, -2.26, 2.61, 0.35, 0.53, 0.37, -0.99, -1.55, -0.18, -0.16, -1.51, -2.07, 1.19, 0.94, -0.02, -1.35, -1.91, 0.37, 0.43, 2.0, 0.2, 2.34, -0.32, 0.53, 0.08, 1.35, -0.57, 1.24, 1.18, 0.2, 1.25, 0.35, 1.93, 0.45, -0.46, 1.89], ['381', -1.09, -0.17, -0.3, -0.01, -0.29, -0.07, -3.4, -1.2, -1.06, -0.55, 0.21, 1.63, 0.99, 0.16, 1.38, -0.23, -0.43, -0.26, -0.038518140589569164, -0.28, -0.51, 0.03, -0.38, -0.11, -3.7, -0.36, -0.76, 1.42, 0.78, -0.05, 1.17, -0.44, -0.64, -0.47, -0.26, -0.49, -0.72, -0.18, -0.59, -0.32, -0.83, -0.9, -2.15, -0.63, -1.2821246055531768, -0.25, -1.83, -2.03, -1.86, -1.66, -1.89, -2.11, -1.58, -1.98, -1.72, -0.91, -0.99, -0.87, -0.52, -1.53, -0.82, 0.39, -1.2, -1.41, -1.24, -1.03, -1.26, -1.48, -0.95, -1.35, -1.09, -0.66, -0.71, 1.22, -0.39, -0.59, -0.42, -0.21, -0.45, -0.67, -0.13, -0.54, -0.2264403582748793, -0.59, -0.49, 0.45, -1.8733017616146799, -1.59, -1.79, -1.62, -1.41, -1.64, -1.87, -1.34, -1.73, -1.48, -1.19, -0.33, -0.2, -0.03, 0.18, -0.06, -0.28, 0.26, -0.15, 0.11, -0.18, -0.26, -0.6, -0.23, -0.26, -0.19, -0.12, 0.17, 0.38, 0.15, -0.08, 0.46, 0.05, 0.32, -0.66, -0.29, 0.21, -0.03, -0.25, 0.29, -0.12, 0.14, 0.09, 0.22276190476190477, 0.02, -0.49, -3.2922619047619044, 0.21, 0.27, 0.4, -0.43, -0.2, -0.97, -1.22, 0.58, 0.43, 0.21, -0.55, -0.34, -0.72, 0.78, 0.69, -0.22, 0.6, -0.49, -0.64, 0.34, -0.34, 0.3, 0.12, 0.28, -0.48, -0.5, -0.23, -0.46, 0.08, -0.32, -0.06, -0.69, -0.27, -0.22, 0.31, -0.09, 0.17, -0.04, 0.54, 0.13, 0.4, -0.99, -0.33, -0.58, -0.4, -0.14, -0.22, -0.25, -1.25, 0.37, -0.57, -0.44, -0.32, -0.66, -0.18, 0.26, -0.293994794887652, -0.28, 0.8, -1.13, -0.27, -0.44, -0.73, -0.91, -0.93], ['382', -3.52, -0.57, 0.04, 0.12, -1.01, -0.46, -1.1, -1.68, -1.26, -1.7, -0.15, -0.9, -0.09, 1.31, -0.46, -0.56, -1.08, -1.2, 1.28, -0.33, -2.07, -1.3, -0.49, -1.1, -0.26140633899247345, -1.2, -1.5273416050068875, -0.75, 0.06, 1.46, -0.32, -0.42, -0.93, -1.06, 1.875702380952381, -0.18, -1.93, -1.15, -0.35, -0.95, -1.55, -2.2, -0.81, 0.82, 2.23, 0.44, 0.34, -0.18, -0.31, 2.2, 0.58, -1.18, -0.4, 0.41, -0.2, -0.9, -1.48, -1.4, -1.07, -1.62, 1.4, -0.38, -0.48, -0.99, -1.12, 1.37, -0.24, -1.99, -1.21, -0.4072652545866831, -1.01, -1.01, -2.97, -1.75, -1.85, -2.35, -2.48, -0.03, -1.62, -3.34, -2.57, -1.78, -2.38, -1.87, -3.17, 3.23, -1.25, -0.1, -0.61, -0.74, 1.75, 0.13, -1.62, -0.84, -0.03, -0.64, -2.15, -1.15, -0.52, -0.64, 1.85, 0.24, -1.52, -0.74, 0.07, -0.54, -0.66, -1.127643118785976, -0.35, -0.49, -0.56, -0.47, -0.63, -0.13, 2.38, 0.75, -1.01, -0.22, 0.59, -0.02, -0.47, -0.51, 2.51, 0.88, -0.88, -0.09, 0.72, 0.1, -1.23, -0.9, 0.14, -0.58, -6.67, -0.63, -0.47, 0.48, -0.49, -0.29, -0.26, -2.5838364678879504, 2.79, 0.99, 0.51, -1.73, -0.15, -1.57, 1.49, 1.48, -0.49, 0.75, -1.02, -2.2, 1.09, -1.96, 6.0, 1.31, 2.01, -2.7, -2.94, -1.59, -3.31, -2.54, -1.75, -2.35, -1.41, -1.38, -1.75, -0.97, -0.16, -0.77, 0.38, 0.79, 1.61, 0.99, -1.2, -1.54, -0.41, 0.81, 0.2, -0.47, -0.56, -1.6174239503761216, 3.78, -0.79, -3.76, -0.63, -1.22, -1.22, -0.61, -0.48, -0.28, -0.07, 0.17, 0.0, -0.61, -0.64, -1.8, -0.35], ['383', 2.97, 0.5, -0.30877828437954125, -0.3, 2.11, 0.81, 0.9141152579598292, 1.4, 0.78, 3.04, 2.13, 2.56, 2.02, 2.69, 1.84, 2.87, 1.36, 2.71, 5.01, 1.28, 3.19, 1.71, 1.43, 1.53, 1.79, 1.1, 0.9, 0.42, -0.11, 0.55, -0.28, 0.73, -0.75, 0.57, 2.82, -0.83, 1.04, -0.4, -0.68, -0.58, 0.7, 0.77, 0.47, -0.53, 0.13, -0.7, 0.3, -1.17, 0.15, 2.39, -1.25, 0.61, -0.82, -1.1, -1.0, 0.91, 1.35, 0.72, 0.56, 1.0, 0.66, -0.17, 0.84, -0.64, 0.68, 2.94, -0.72, 1.15, -0.3, -0.58, -0.47, 1.66, 0.34, -0.83, 0.17, -1.3, 0.02, 2.26, -1.38, 0.48, -0.95, -1.23, -1.13, 0.89, 4.4, -4.38, 1.21669823838532, 1.01, -0.47, 0.85, 3.11, -0.55, 1.32, -0.12, -0.4, -0.3, 1.18, 0.17, -1.47, -0.16, 2.08, -1.55, 0.31, -1.12, -1.4, -1.3, 0.2, 0.2, 2.18, 1.04, 1.01, 1.11, 1.66, 1.33, 3.6, -0.08, 1.8, 0.35, 0.14598786341555264, 0.17, 1.26, 0.32, 2.24, -1.39, 0.46, -0.8442004503433073, -1.25, -0.8978225623582765, 1.75, 1.63, 0.0, 1.07, 2.23, 0.2, 0.14, -2.66, 2.66, 1.35, 0.6, 2.33, -3.399481751122728, -2.2, -1.09, 1.54, 0.39, 3.25, -3.22, -3.24, 1.06, -4.07, 2.09, 0.62, -0.31, 4.99, -6.6, -3.33, -4.95, 3.44, -1.88, -3.56, -1.74, -3.14, -3.41, -3.31, 3.19, 1.74, 2.0241925889236816, 0.43, 0.15, 0.25, -0.14, -1.3411214088935783, -1.7, -1.6, 0.82, 1.0084535464535467, 1.3, -0.28, -0.18, 1.192080034314057, 1.09, 1.27, -3.24, 1.11, 3.22, 1.63, 1.3, 1.59, 0.17278685149693168, 1.13, 1.2845528598385743, 0.7, 0.15, -0.06, 1.49, 2.15, 2.05, 2.82], ['384', 0.86, -0.19, -0.14877828437954127, 0.14, -0.8570209190089404, -0.24, -0.88, -0.49, -1.09, -0.05, 1.27, 0.92, 0.32, 0.63, 0.47, 0.65, 0.68, 0.27, -2.87, 1.63, -0.37, 0.01, 0.43, 0.48, -0.25, -0.52, -1.3, -0.34, -0.93, -0.63, -0.7221800287049088, -0.6, -0.58, -0.98, -4.08, 0.36, -1.62, -1.24, -0.7311203865609548, -0.77, -0.11, -2.3, -0.96, -0.59, -0.29, -0.44, -0.26, -0.24, -0.64, -3.75, 0.71, -1.28, -0.9, -0.49, -0.43, -0.29993715369432344, -0.11571428571428577, -0.45, -0.92, -0.37, 0.3, 0.15, 0.33, 0.36, -0.05, -3.18, 1.4339757335335068, -0.69, -0.31, 0.11, 0.16, -0.1, -0.68, -0.15, 0.03, 0.05, -0.35, -3.47, 1.0, -0.99, -0.61, -0.2, -0.14, -1.48, -1.43, 1.37, -0.53, 0.18, 0.2117857142857143, -0.2, -3.33, 1.15, -0.84, -0.47, -0.05, 0.01, -0.23, -0.7, 0.03, -0.38, -3.5, 0.97, -1.02, -0.64, -0.22, -0.17, -0.36, -0.58, -3.01, -0.5, -0.42, -0.5, -0.73, -0.41, -3.53, 0.95, -1.05, -0.67, -0.25, -0.2, -0.14, -0.32, -3.13, 1.36, -0.64, -0.26, 0.16, 0.21, -0.64, -0.66, 0.21, -0.7, -0.55, -0.13, -0.2, 1.67, -1.7, -0.84, -0.42, -1.2638364678879506, 3.26, 1.03, 0.49, 0.44, 0.03, -1.48, 1.4, 1.43, -0.49, 2.56, -0.98, -2.1, 1.03, -2.15, 5.05, 1.42, 2.24, -3.34, 2.9, 4.63, 2.57, 2.96, 3.4, 3.45, -1.51, -1.66, -1.97, -1.6, -1.18, -1.13, 0.38448979591836735, 0.38, 0.81, 0.86, -1.11, -1.25, -0.06, 0.42, 0.47, -0.48, -0.53, -0.52, 1.95, -2.07, -2.08, -0.46, -1.03, -0.48, 0.05, -0.3, -0.68, 0.2, 0.3, -0.35, -0.53, 0.79, -1.87, -0.36], ['385', -1.8, 0.18, 0.4112217156204588, -0.23, 0.67, -0.33, -1.7558847420401709, -0.42, -0.8, 0.13, 1.44, 1.02, 0.22, 0.88, 1.96, 0.19, 0.52, 0.15, -0.49, -1.35, 0.19, 0.4, 0.28, 0.15, -0.28, 0.43, -1.3, -0.41, -1.2, -0.55, 0.51, -1.23, -0.91, -1.27, -1.8992857142857142, -2.75, -1.23, -1.02, -1.14, -1.27, -1.05, -1.5650638007838267, -0.89, -0.79, -0.14, 0.93, -0.82, -0.5, -0.86, -1.49, -2.34, -0.82, -0.61, -0.73, -0.86, -0.5, 0.46, 3.03, -0.57, -0.09, 0.66, 1.74, -0.03, 0.3, -0.07, -0.7, -1.56, -0.03, 0.18, 0.06, -0.07, 0.48, -0.75, 1.07, -0.68, -0.36, -0.72, -1.35, -2.21, -0.2381462585034016, -0.47, -0.59, -0.72, -1.16, -0.57, 0.58, -1.8, -1.6519125667872352, -1.41, -1.77, -2.4, -3.24, -1.73, -1.53, -1.65, -1.77, -0.55, -0.06, 0.33, -0.04, -0.67, -1.53, 0.0, 0.21, 0.09, -0.04, 0.0, -0.06, 0.83, -0.28, 0.26, -0.81, -0.39, -0.37, -1.0, -1.86, -0.33, -0.12, -0.16401213658444735, -0.37, -0.05, -0.03, -0.64, -1.5, 0.04956235827664399, 0.25, 0.13, 0.0, 0.52, 0.72, -0.26396282112195957, -0.41, -1.27, 0.2480695494981211, 0.22, 4.17, -4.2, -2.11, 0.61, -1.28, -3.04, 0.55, 0.27, -0.83, 0.65, -0.86, 0.91, 0.8, -0.28, 6.2, -0.53, 2.29, -1.1, -1.22, -5.56, 0.72, 1.11, 2.94, 0.61, -0.86, 0.68, 0.89, 0.77, 0.64, -0.83, 1.49, 1.56, 1.77, 1.65, 1.52, -0.07, 0.21, 0.09, -0.04, -4.11, -5.19, -0.28, -0.12, -0.25, -0.25, -0.85, -2.56, -2.65, 0.54, 2.47, -0.27, 0.68, -0.08136255179902908, -0.13, -0.3599225974772193, -2.34, 0.93, 1.21, 0.38, -0.03, -0.72, 0.7030376647162363, -0.42], ['386', 2.39, -0.22, -0.30877828437954125, -0.07, 0.55, -0.45, 0.54, -0.63, -0.13, -0.17, -0.39, 0.29, 0.43, 0.57, -0.33, -0.42, 0.82, -0.22, -0.84, -1.48, -0.03, 0.9, 0.4, 0.31, -0.78, -1.08, 0.23, 0.68, 0.82, 0.96, 0.06, -0.02, 1.22, 0.18, -0.45, -1.1, 0.36, 1.29, 0.8, 0.7, 0.0, 0.67, -0.44979591836734695, 0.14, 0.28, -0.62, -0.7, 0.53, -0.5, -1.13, -1.76, -0.32, 0.61, 0.11, 0.02, -0.91, -0.77, -0.39, -0.35007142857142853, -0.59, 0.14, -0.76, -0.84, 0.39, -0.64, -1.26, -1.9, -0.46, 0.47, -0.03, -0.12, 0.05, -0.73, -0.9, -0.98, 0.25, -0.78, -1.4, -2.04, -0.4469183673469388, 0.33, -0.17, -0.20644035827487928, 0.47, -1.94, 1.89, 0.17, -0.08, 1.5899013605442176, 0.12, -0.51, -1.15, 0.3, 1.23, 0.74, 0.64, -2.8, 0.25, 1.24, 0.30533503401360546, -0.43, -1.07, 0.39, 1.32, 0.82, 0.73, -0.08, 0.3, -1.28, -0.37, -0.37, -0.47, -0.98, -1.03, -1.65, -2.28, -0.84, 0.08, -0.42, -0.51, -1.15, 0.05, -0.63, -1.27, 0.19, 1.12, 0.62, 0.52, -0.66, -0.49, 0.21603717887804044, -0.74, -8.4, -0.43, -0.47, 0.37, -0.41, -0.19, -2.62, -0.23, -2.62, 0.71, 0.39, 1.19, -0.37, -1.05, 1.15, 1.15, -0.38, 0.58, -0.63, 0.76, -0.4, -2.88, -3.76, 1.98, 2.94, 2.5771309523809522, 0.68, -0.65, 0.82, 1.75, 1.25, 1.16, -1.09, 1.34, 1.47, 2.42, 1.91, 1.82, -0.14, 0.93, 0.43, 0.34, -0.08, -0.04, -1.05, -0.49, -0.59, -0.35, -0.44, -0.56, -1.01, -1.07, 1.1314285714285712, -0.4327361894755667, -0.04, -0.56, -0.09, -0.97, 0.01, -0.23, -0.38, -0.61, -0.47, -1.1, 0.43, -0.17], ['387', -5.61, 0.62, -0.05877828437954126, -0.19, 0.49, 1.29, 1.0641152579598292, 0.8, 1.97, 1.2, -2.28, 0.2, -0.09, 0.47, 0.7, 3.42, 0.45, 1.18, 4.831481859410431, 0.3, 1.86, 0.13, -0.45, -0.2, 1.63, 1.52, 3.6026583949931124, 2.55, 2.25, 2.82, 3.05, 5.83, 2.8, 3.55, 7.27, 2.64, 4.24, 2.47, 1.87, 2.13, 1.03, 3.84, 1.0, -0.29, 0.27, 0.49, 3.21, 0.24, 0.97, 4.6, 0.09, 1.65, -0.08, -0.66, -0.41, -0.97, 0.99, 1.63, 1.66, 1.29, 0.56, 0.79, 3.51, 0.6185714285714285, 1.27, 4.91, 0.39, 1.95, 0.22, -0.37, -0.11, 0.9, 0.73, 0.23, 2.93, -0.02, 0.7, 4.32, -0.17, 1.8218537414965983, -0.34, -0.92, -0.67, 3.17, 4.35, -4.24, 0.5, 2.7, -0.25, 0.48, 4.09, -0.4, 1.15, -0.57, -1.1414761904761903, -0.9, -1.27, -2.14, -2.87, -2.16, 1.35, -3.01, -1.51, -3.18, -3.74, -3.5, 0.471141873999017, -2.14, 0.73, 1.31, 1.34, 1.18, 0.75, 0.73, 4.35, -0.15, 1.4, -0.32, -0.9, -0.65, 1.07, 0.07307674813036727, 3.59, -0.87, 0.67, -1.04, -1.62, -1.37, 1.19, 0.71, -0.27, 0.88, -2.63, 0.87, -0.11, -2.66, 2.63, 1.34, 0.37, 0.48, -1.59, -2.67, -1.31, -2.84, 0.71, 3.84, -3.87, -3.96, 1.31, -4.03, 2.62, 2.13, -1.06, 2.37, -6.39, -1.5, -2.23, 1.85, -3.44, -4.31, -2.82, -4.47, -5.03, -4.624238287156354, 3.99, 0.9, 1.56, -0.17, -0.75, -0.5, -0.64, -1.7, -2.27, -2.02, 1.94, 2.28, 1.08, -0.58, -0.33, 1.3, 1.27, 0.83, -3.27, 0.34, 3.2421428571428574, 1.15, 1.56, 1.67, 0.25, 1.6200774025227807, 1.36, 0.82, 1.49, 0.67, 1.41, 0.6502406343656345, 2.12, 0.83], ['388', -2.27, -0.98, -0.04, -0.23, -0.32, -0.86, -1.1658847420401708, -1.29, -1.96, -1.17, 1.37, 0.12, -1.41, 0.64, 0.05, -0.9, 1.07, -0.95, -0.63, 0.07, -1.932664517912641, 0.53, 0.25, -0.14, -0.69, -2.23, -2.4673416050068875, -1.2294545454545454, -2.74, -0.72, -1.242180028704909, -2.23, -0.29, -2.29, -1.97, -1.28, -3.29, -0.83, -1.1, -1.49, -0.43, -4.075063800783826, -1.29, -1.53, 0.52, -0.07, -1.02, 0.95, -1.07, -0.75, -0.05, -2.09, 0.41, 0.14, -0.26, -0.53, -0.07, -0.55, -1.82, 0.24, 2.08, 1.48, 0.52, 2.52, 0.47, 0.8, 1.5, -0.57, 1.97, 1.69, 1.29, -1.07, -1.8, -0.59, -1.53, 0.43, -1.58, -1.26, -0.57, -2.59, -0.11, -0.38, -0.78, -2.67, -4.46, 4.47, -1.18330176161468, -0.95, 1.02, -1.0, -0.68, 0.02, -2.02, 0.48, 0.21, -0.19, -2.62, -0.28, 1.99, -0.05, 0.27, 0.97, -1.08, 1.44, 1.16, 0.76, -0.42, -0.1506317967746538, -1.86427628811696, -1.35, -1.26, -1.53, -2.22, -1.9986530612244897, -1.68, -1.0, -3.01, -0.54, -0.81, -1.2, -1.75, -0.22, 0.33, 1.03, -1.03, 1.49, 1.22, 0.82, -1.48, -1.54, -0.39, -2.09, -5.09, -0.48, -0.39, 3.58, -3.59, -1.81, -1.48, -1.22, 2.45, 2.69, 1.37, -1.15, -0.56, -4.28, 4.24, 4.02, -1.34, 5.37, -2.69, 1.1183906549799407, -0.48, -6.64, 7.48, 4.43, 6.57, -2.44, -0.55, 0.7, -1.35, 1.16, 0.89, 0.49, -3.9891948051948054, -1.24, -2.04, 0.46, 0.19, -0.21, 0.82, 2.55, 2.27, 1.87, -1.97, -2.35, -1.69, -0.27, -0.67, -1.32, -1.46, -1.21, 3.91, -1.48, -3.8, -1.67, -1.26, -1.42, -0.4, -1.94, -1.79, -0.64, -0.22, -1.14, -1.03, -2.62, -1.94, -2.0569832262926027], ['389', 1.84, 0.44, 0.44, -0.14, 1.09, 1.52, 1.19, 1.0, 2.52, 1.21, -2.95, 0.24, -0.72, 0.88, -0.42, -0.32, -0.89, 0.45, 0.62, -0.77, 1.77, 0.02, -0.11, 0.27, 1.99, 2.28, 4.29, 3.408468508265777, 2.3, 3.95, 2.61, 2.7133503401360546, 2.12, 3.51, 3.69, 2.25, 4.86, 3.07, 2.92, 3.32, 0.12, 5.16, 0.97, -0.96, 0.64, -0.65, -0.56, -1.13, 0.21, 0.39, -1.0, 1.53, -0.21, -0.35, 0.03, 0.66, 0.74, -0.31, 2.24, 1.94, 1.61, 0.31, 0.4, -0.17, 1.18, 1.36, -0.05, 2.51, 0.75, 0.61, 1.0, 0.13, 0.32, -0.8697721088435375, -1.2, -1.76, -0.43, -0.25, -1.64, 0.88, -0.85, -0.99, -0.6, 4.6, 4.01, -4.2, 1.63, 0.09, -0.48, 0.87, 1.04, -0.36, 2.19, 0.44, 0.3, 0.69, 2.4, 1.54, -0.57, 0.78, 0.95, -0.44, 2.1, 0.35, 0.21, 0.6, 0.95, 1.53, 1.04, 1.52, 1.51, 1.61, 2.12, 1.35, 1.53, 0.12, 2.68, 0.92, 0.78, 1.17, 1.19, 0.75, 0.17, -1.21, 1.31, -0.43, -0.56, -0.18, 1.8, 2.11, -0.02, 2.17, 4.89, 0.3580695494981211, -0.14, -3.28, 3.19, 1.63, 1.09, 1.56, -3.71, -3.05, -1.5385714285714287, 0.93, 1.53, 4.61, -4.680000000000001, -4.65, 1.5, -4.78, 3.03, 2.99, -1.47, 6.22, -5.952619047619048, -4.19, -6.19, 3.59, 0.58, -1.39, 1.14, -0.6, -0.73, -0.35, 4.52, 1.99, 2.56, 0.8, 0.66, 1.05, -0.10349829931972804, -1.72, -1.85, -1.4685714285714286, 2.49, 2.96, 1.18, -0.14, 0.25, 1.5, 1.62, 1.18, -2.94, 1.57, 3.11, 1.81, 2.09, 1.32, 0.39, 2.26, 1.87, 1.07, 1.47, 1.03, 0.93, 2.53, 2.46, -0.23], ['390', 3.11, 0.53, 0.06, -0.28, 0.22, 1.0, 1.14, 2.33, 1.86, 3.54, 0.84, 2.68, 1.6, 0.84, 1.47, 3.42, 1.44, 3.48, 5.61, 4.17, 4.08, 2.72, 1.51, 3.06, 1.5485936610075264, 1.03, 2.67, 1.822860544217687, 0.75, 0.0, 0.62, 2.56, 0.6, 2.62, 4.73, 3.3, 3.21, 1.86, 0.66, 2.2, 1.3, 2.4849361992161736, 0.840204081632653, -1.05, -1.78, -1.17, 0.72, -1.2, 0.79, 2.86, 1.46, 1.37, 0.04, -1.13, 0.38, 1.35, 1.36, 1.88, 2.07, 1.91, -0.74, -0.12, 1.79, -0.15, 1.86, 3.95, 2.53, 2.44, 1.1, -0.08, 1.44, 1.88, 2.67, 0.62, 2.55, 0.59, 2.62, 4.72, 3.3, 3.2, 1.86, 0.66, 2.2535596417251207, 2.61, 5.49, -5.48, 2.04, 1.92, -0.03, 1.98, 4.08, 2.66, 2.57, 1.23, 0.04, 1.57, 0.76, 0.11, -1.91, 0.06, 2.12, 0.72, 0.64, -0.68, -1.84, -0.35, -0.1, 0.12235688121402405, 2.22, 1.21, 1.43, 1.13, 2.06, 2.01, 4.11, 2.69, 2.59, 1.26, 0.07, 1.59, 0.55, 0.10307674813036727, 2.05, 0.66, 0.57, -0.74, -1.9, -0.16782256235827656, 1.99, 2.13, -0.03, 1.87, 2.11, 0.08, 0.31, -2.04, 2.03, 1.01, 0.22, 3.2202597402597406, 1.24, -2.5, -1.22, 1.58, 0.85, 3.88, -3.81, -3.66, 1.22, -3.07, 2.45, 1.94, -1.25, 6.23, -6.44, -4.17, -6.13, -1.27, -1.96, -1.36, -1.45, -2.74, -3.88, -2.41, 3.61, -0.61, -0.09, -1.39, -2.55, -1.06, -0.52, -1.3, -2.46, -0.98, 1.86, 2.36, 0.79, -1.18, 0.40224875531501636, 1.25, 1.37, 2.5, -3.32, 3.05, 3.17, 1.53, 0.88, 1.99, 1.53, 1.49, 1.22, 1.2652979520479524, 0.5, 1.29, 0.46, 2.4, 0.31, 1.09], ['391', -1.84, 0.92, -0.028778284379541254, -0.06, -0.5, 0.13, -0.21, 0.04, -0.4, -0.15, 1.0503184712113285, 0.1, -0.88, -1.38, -0.42, 0.52, -0.63, -0.08, 0.85, -0.39, -0.61, -0.61, -0.3, -0.96, 0.21, -0.19, -0.98, -0.73, -1.7, -2.2, -1.25, -0.32, -1.45, -0.91, 0.01, -1.21, -1.43, -1.44, -1.12, -1.78, -0.81, -0.20506380078382658, -0.25, -0.98, -1.48, -0.44918497042472344, 0.41, -0.73, -0.18, 0.74, -0.49, -0.71, -0.71, -0.4, -1.06, 0.33, 0.14, -0.36, -0.55, 0.74, -0.5, 0.46, 1.41, 0.25, 0.81, 1.74, 0.5, 0.28, 0.27, 0.59, -0.08, -1.15, 1.25, 0.97, 1.92, 0.76, 1.32, 2.26, 1.01, 0.78, 0.78, 1.1, 0.43, -0.65, 0.65, -0.72, 0.27, 0.94, -0.21, 0.35, 1.28, 0.04, -0.18, -0.19, 0.13, -0.54, -1.53, -0.66, -1.14, -0.59, 0.33, -0.9, -1.12, -1.12, -0.81, -1.46, 0.02, -0.67, 1.13572371188304, 0.15, 0.26517906963433996, 0.26, 0.5518094764861292, 0.56, 1.49, 0.25, 0.03, 0.02, 0.34, -0.33, 0.35, -0.07, 0.92, -0.31, -0.53, -0.54, -0.22, -0.88, 0.08, -0.03, -0.29, 0.67, -4.6, 0.28, 0.17, -0.14, 0.08, 0.06, 1.06, 0.23, -0.51, -0.3, -0.21, -0.87, 0.31, 0.53, -0.51, -0.6, 0.14, -0.16, 0.52, 1.08, -0.54, 1.52, -3.48, -1.09, -1.38, 0.5, -0.99, -1.22, -1.44, -1.45, -1.13, -1.79, 0.52, 0.24, -0.22, -0.23, 0.09, -0.57, 0.906501700680272, -0.01, 0.31, -0.35, -0.45, -0.57, 0.47, 0.32, -0.35, 0.19, 0.26, 0.14, -1.18, 1.3301996269574994, 0.97, 0.0, 0.6, 0.15, -0.66, 0.72, 0.06, -0.17, 0.23, 0.05, 0.81, 0.93, 1.38, 1.62], ['392', 5.9, 0.48, -0.05, 0.0, 1.3129790809910595, 0.6, 1.67, 1.21, 1.39, 0.9253571428571429, -1.41, -0.55, -0.61, 0.75, -0.79, 0.23, 1.15, 0.91, 0.85, -1.66, 0.91, -0.13, -0.64, 2.76, -0.44, 0.35, 2.3, 0.87, 0.81, 2.19, 0.63, 1.66, 2.6, 2.36, 2.29, -0.25, 2.35, 1.3, 0.78, 4.273841723197839, 1.14, 3.1, 1.619303232481804, -0.06, 1.3, -0.24, 0.78, 1.71, 1.47, 1.4, -1.12, 1.47, 0.42, -0.1, 3.33, 0.98, 0.18, 0.91, 0.6, 1.5592452470658775, 1.37, -0.18, 0.85, 1.78, 1.53, 1.47, -1.05, 1.53, 0.48, -0.03, 3.39, 2.7, 0.11, -1.53, -0.51, 0.4, 0.17, 0.1, -2.39, 0.16, -0.87, -1.38, 2.0, 2.6189098639455786, 3.29, -3.37, 1.66, 1.03, 1.96, 1.72, 1.65, -0.87, 1.71, 0.67, 0.15, 3.58, 0.86, 0.63, 0.92, 0.68, 0.62, -1.88, 0.68, -0.36, -0.87, 2.52, -0.02, 0.64, 1.21, 0.03, 0.65, -0.69, -0.29, -0.24, -0.3, -2.78, -0.24, -1.27, -1.78, 1.59, 0.84, -0.05, -0.06, -2.55, 0.0, -1.04, -1.54, 1.83, 1.81, 2.35, 0.17, -0.38, 1.4, 0.56, 0.07, 3.24, -3.37, -1.65, 0.45, 3.6, -5.08, -0.12, -0.04, 2.88, 0.63, -0.16, 0.18, -0.2, 0.05, 4.96, 0.15, -2.041609345020059, 1.08, -0.95, 0.82, 0.49, 0.76, 5.11, 0.01, -2.49, 0.06, -0.97, -1.48, 1.9, 0.12, 2.56, 2.61, 1.55, 1.03, 4.49, -0.05, -1.03, -1.54, 1.83, 1.44, 2.08, 0.99, -0.51, 2.89, 0.0, -0.12, 1.12, 0.32, 0.0, -0.17, -0.36, 0.35, 1.51, 3.43, 0.54, -0.82, 0.34, 1.14, 0.28, -1.85, 0.17, -1.74, -2.2], ['393', 1.45, 0.34, 0.09122171562045875, -0.22, 0.0, -0.15, 0.45411525795982915, 0.67, 0.77, -0.05, -0.61, -0.7, -0.39, -0.47, -1.36, -0.21, -0.36, -0.2, -0.86, 0.06, 0.48733548208735894, 0.53, -0.85, -0.47, 1.51, 0.94, 0.56, -0.1, 0.22, 0.14, -0.7021800287049088, 0.4, 0.24, 0.41, -0.25, 0.67, 1.07, 1.14, -0.25, 0.18384172319783917, 0.27, 1.7949361992161734, 0.66, 0.32, 0.24, -0.66, 0.5, 0.34, 0.51, -0.15, 0.77, 1.17, 1.24, -0.15, 0.24, 0.8, 0.3, 0.15, 0.73, 0.34, -0.08, -0.98, 0.18, 0.02, 0.19, -0.47, 0.45, 0.85, 0.92, -0.47, -0.08, 0.5, 0.42, -0.9, 0.26, 0.11, 0.27, -0.39, 0.54, 0.93, 1.0, -0.39, 0.01, 0.98, 2.05, -2.04, 1.33, 1.17, 1.01, 1.18, 0.51, 1.45, 1.84, 1.92, 0.52, 0.91, 0.34, 0.16, -0.15, 0.01, -0.6484761904761905, 0.28, 0.67, 0.74, -0.64, -0.25, 0.23, 0.18, 2.45, 0.21, 0.61, -0.22, 0.31, 0.16, -0.49, 0.43, 0.82, 0.9, -0.49, -0.1, -0.29, 0.15, -0.66, 0.27, 0.66, 0.73, -0.65, -0.26, 1.01, 0.9, -0.04, 0.4, 0.97, 0.03, 0.0, 0.53, -0.5275376766091052, -0.26, 1.4240662734668152, 1.3561635321120495, 0.22, -0.45, -0.18, 0.78, 0.553079789868779, 0.7, -0.66, -0.63, 0.2, 0.78, 0.46, 1.79, -0.89, 0.92, 0.0, -0.67, -0.87, -0.26, 0.81, 0.93, 1.32, 1.4, 0.0, 0.4, 0.64, -0.12, 0.39, 0.46, -0.92, -0.53, -0.51, 0.07, -1.3, -0.92, 0.77, 0.76, -0.58, -1.37, -0.99, 0.23, 0.28439630127529086, 0.66, -0.66, 1.5, 0.77, 0.5272638105244333, 0.83, 0.81, 0.46278685149693166, 0.36, -0.75, 0.37, 1.35, -0.07, 0.49595752702381396, 1.12, 0.87, 0.0], ['394', -7.48, -0.71, -0.2787782843795412, 0.21, -1.78, -1.37, 0.07411525795982916, -3.92, -4.12, -1.09, 3.94, 0.71, 1.85, 3.53, 2.6342857142857143, 1.25, 1.13, -0.8, -2.76, 2.02, -1.92, 0.32, 0.5, 0.875116627420199, -4.96, -3.770628585411108, -4.84, -3.11, -2.01, -0.39, -1.26, -2.59, -2.7, -4.56, -6.45, -1.8286428571428572, -5.64, -3.48, -3.31, -3.09, -4.55, -3.89, -1.789795918367347, 1.13, 2.81, 1.9, 0.54, 0.42, -1.5, -3.45, 1.3, -2.62, -0.39, -0.21, 0.02, -2.46, -4.15, -2.54, -4.42, -2.89, 1.66, 0.77, -0.59, -0.7, -2.6, -4.53, 0.17, -3.7, -1.5, -1.33, -1.09, -2.3, -4.47, -0.88, -2.21, -2.32, -4.19, -6.08, -1.46, -5.27, -3.1, -2.94, -2.71, -4.71, -4.66, 4.67, -3.63, -1.34, -1.45, -3.34, -5.25, -0.59, -4.43, -2.25, -2.08, -1.85, -4.06, -2.32, -0.12, -2.03, -3.97, 0.76, -3.14, -0.92, -0.75, -0.51, -0.38, -2.35, -2.65, -1.5684018193170985, -1.51, -1.86, -2.2, -1.92, -3.85, 0.88, -3.02, -0.8, -0.63, -0.4, -1.41, -0.29, -1.98, 2.84, -1.13, 1.13, 1.31, 1.55, -1.63, -1.91, 0.35, -2.25, -11.87, -0.16, 0.06, 3.55, -3.6, -1.8, -0.44, -3.36, 6.23, 3.17, 1.62, -3.89, -0.67, -4.98, 5.03, 4.89, -1.64, 5.4, -3.29, -1.47, 0.68, -6.52, 4.45, 4.23, 6.41, -6.4, 1.72, 4.92, 0.86, 3.17, 3.35, 3.6, -4.91, -3.05, -3.87, -1.67, -1.49, -1.26, 0.85, 2.29, 2.47, 2.71, -1.91, -1.98, -1.41, 0.18, 0.41, -1.59, -1.65, -2.73, 6.5, -3.99, -7.12, -2.7, -3.3, -1.58, 0.24, -1.53, -1.63, -0.73, -0.55, -0.99, -1.81, -4.28, -4.46, -2.19], ['395', 0.18, -0.23, -0.10877828437954125, 0.17, -0.48, -0.31, 0.05, -1.23, -0.73, -3.26, -2.35, -3.58, -2.19, -2.58, -1.25, -3.68, -2.37, -3.17, -5.53, -1.98, -3.56, -2.3, -2.33, -2.14, -2.29, -0.5706285854111081, -0.93, -1.26, 0.16, -0.23, 1.13, -1.37, -0.02, -0.84, -3.25, 0.38, -1.24, 0.05, 0.02, 0.22, -0.44, -1.7891024373941227, 0.33, 1.44, 1.04, 2.42, -0.11, 1.26, 0.43, -2.02, 1.66, 0.02, 1.33, 1.3, 1.5, -0.14, -0.21, -1.06, 0.06, -1.09, -0.39, 0.97, -1.52, -0.18, -1.0, -3.41, 0.22, -1.4, -0.11, -0.14, 0.06, -0.96, -0.7, 1.36, -1.14, 0.21, -0.61, -3.03, 0.61, -1.01, 0.28, 0.26, 0.45, -0.9373265306122449, -2.6, 2.55, -2.04, -2.47, -1.13, -1.95, -4.33, -0.74, -2.34, -1.06, -1.09, -0.9, 0.27, 0.44, 1.36, 0.53, -1.91, 1.77, 0.13, 1.44, 1.41, 1.61, -0.16, 0.49, 0.13, -0.65, -0.68, -0.67, -0.91, -0.82, -3.23, 0.4, -1.22, 0.07, 0.04, 0.2985846838830657, -1.0, -0.1, -2.43, 1.23, -0.4, 0.9, 0.87, 1.07, -0.3, 0.0, 0.23, -0.7, 1.1, -0.03, 0.0, 1.59, -1.57, -0.78, -1.27, -1.79, 2.63, 1.3, 0.68, 0.07, -0.07, -1.86, 1.89, 1.93, -0.65, 2.32, -1.31, -2.04, 0.98, -2.68, 2.65, 1.71, 2.45, -2.56, 2.4, 3.75, 2.08, 3.42, 3.39, 3.59, -2.01, -1.31, -1.61, -0.33, -0.35, -0.16, 0.31, 1.31, 1.28, 1.48, -0.65, -0.76, -0.98, -0.03, 0.17, -0.65, -0.7, -1.26, 3.75, -0.45, -3.77, -1.01, -1.67, -0.96, 0.19, -0.58, -0.63, 0.44, -0.05, -0.27, -1.15, -2.24, -2.27, -1.46], ['396', 2.42, 0.18, 0.2, 0.13, -0.42, 0.55, 0.89, 1.6, 1.3, 0.59, -1.22, -0.23, -1.22, -1.29, -0.31, 0.23, -0.67, 0.28, 0.95, 1.01, 1.297335482087359, 0.01, -0.64, -0.59, 1.16, 0.869371414588892, 1.83, 1.01, 0.0, -0.07, 0.92, 1.47, 0.55, 1.51, 2.2, 2.25, 2.51, 1.25, 0.59, 0.64, 1.13, 1.4449361992161733, 0.82, -1.0, -1.06, -0.08, 0.46, -0.45, 0.5, 1.18, 1.24, 1.49, 0.24, -0.42, -0.36, 1.42, 1.33, 0.82, 1.17, 1.83, -0.07, 0.92, 1.47, 0.55, 1.6126050661400617, 2.4896933106575965, 2.25, 2.6734211542425825, 1.25, 0.58, 0.64, 1.07, 1.9, 0.99, 1.54, 0.62, 1.58, 2.27, 2.33, 2.58, 1.32, 0.66, 0.71, 1.76, 3.22, -3.22, 0.9, 0.54, -0.37, 0.59, 1.26, 1.32, 1.57, 0.32, -0.33, -0.28, 0.17, 0.36, -0.9, 0.04, 0.72, 0.77, 1.02, -0.22, -0.87, -0.82, 0.18, 0.31, 3.62, 0.72, 0.78, 0.82, 1.3418094764861292, 0.95, 1.64, 1.69, 1.95, 0.69, 0.03, 0.08, 0.55, 0.31, 0.68, 0.73, 0.98, -0.26, -0.91, -0.86, 0.66, 0.61, 0.0, 1.19, 0.56, 0.43, 0.21, -2.16, 2.17, 1.09, 0.31, 1.86, 0.81, -1.43, -0.73, 1.27, -0.01, 2.38, -2.27, -2.16, 0.73, -3.26, 1.47, 1.2583906549799408, -0.57, 3.79, -5.86, -2.51, -3.69, -0.83, -0.36, 0.05, 0.3, -0.93, -1.58, -1.53, 2.2108051948051948, -0.41, 0.3941925889236815, -0.98, -1.63, -1.58, -0.66, -1.23, -1.88, -1.83, 1.45, 1.43, 0.58, -0.65, -0.6, 0.71, 0.8, 1.61, -2.97, 2.98, 2.99, 0.61, 0.94, 1.24, 0.05, 0.56, 1.11, -0.06, -0.41, 0.14, 1.265957527023814, 1.43, 1.26, 1.58], ['397', 2.67, -0.12, 0.1, 0.21214285714285727, -0.72, -0.09, -0.25, -0.79, -0.34, -0.21, 0.06, 0.26, 0.22, 0.99, 0.51, -0.68, 0.88, -0.24, -0.36, 2.21, 0.07, 0.5130748299319728, -0.01, 0.16, -0.78, -0.5, -0.27, 0.2, 0.16, 0.93, 0.45, -0.74, 0.82, -0.3, -0.42, 2.15, 0.01, 0.45, -0.07, 0.1, -0.22, -0.57, -0.47, -0.03, 0.73, 0.26, -0.94, 0.63, -0.49, -0.61, 1.9507142857142856, -0.19, 0.25, -0.27, -0.1, 0.0, 0.06, -0.47, -0.23, -0.43, 0.76, 0.29, -0.9, 0.66, -0.46, -0.58, 1.98, -0.16, 0.29, -0.24, -0.07, -0.46, -1.1885714285714286, -0.47, -1.66, -0.1, -1.2067857142857144, -1.33, 1.21, -0.91, -0.47, -0.99, -0.82, -0.36, -0.87, 0.86, -0.72, -1.19, 0.37, -0.75, -0.87, 1.69, -0.44, 0.0, -0.52, -0.35, -0.54, 0.47, 1.58, 0.45, 0.33, 2.92, 0.76, 1.2, 0.68, 0.85, -0.09, 0.45, -0.64, -0.28, -0.28, -0.54, -1.09, -1.11, -1.23, 1.32, -0.81, -0.37, -0.89, -0.72, -0.82, 0.02, -0.12, 2.46, 0.31, 0.75, 0.23, 0.4, -0.68, -1.56, -0.45, -0.86, -1.18, -0.18, -0.19, 1.61, -1.65, -0.81, -1.28, -0.75, 4.6, 0.54, 0.39, 1.5, 0.16, -1.01, 1.05, 0.77, -0.27, 2.4, -0.55, 2.32, -1.13, -3.07, 6.27, 2.2142857142857144, 3.2314285714285713, -4.82, 0.15, 2.58, 0.43, 0.87, 0.35128571428571426, 0.52, -0.74, -2.37, -2.1, -1.67, -2.18, -2.01, -0.28, 0.44, 0.15285714285714286, 0.09, -0.35, -0.41, -0.72, -0.32676622187336457, -0.35, -0.47, -0.41, -0.75, 3.197142857142857, -0.56, -3.25, -0.73, 0.03, -0.2, 0.17, -0.79, -0.61, -0.16, 0.04, 0.12, -0.37, -2.03, -1.05, -1.02], ['398', 1.09, 0.19, 0.09122171562045875, -0.45, 1.59, 1.04, 1.03, 1.09, 0.87, 1.07, -0.17, 0.18, -0.36, -0.77, 0.69, 0.92, -0.22, 0.72, -0.49, -0.21, 1.42, 0.49, 0.74, -0.51, 1.59, 1.41, 1.2826583949931125, 0.35, -0.19, -0.6, 0.87, 1.1, -0.05, 0.89, -0.32, -0.04, 1.5907606837606838, 0.67, 0.91, -0.2961582768021609, 0.5, 1.21, 0.89, -0.54, -0.95, 0.51, 0.74, -0.4, 0.54, -0.67, -0.39, 1.24, 0.31, 0.56, -0.69, 1.28, 0.45, 0.14, 0.88, 1.44, -0.41, 1.06, 1.29, 0.14, 1.08, -0.14, 0.15, 1.78, 0.86, 1.1, -0.15, 0.6, 1.86, 1.48, 1.71, 0.56, 1.5, 0.28, 0.56, 2.21, 1.27, 1.52, 0.26, 1.23, 1.16, -1.16, 0.38, 0.23, -0.91, 0.02, -1.18, -0.9, 0.72, -0.2, 0.04, -1.19, 0.93, 0.15, -1.13, -0.2, -1.4, -1.13, 0.49, -0.42, -0.18, -1.42, 0.32, 0.21, 1.26, 1.08, 0.86517906963434, 1.5356735186500319, 1.3, 0.94, -0.28, 0.01, 1.64, 0.72, 0.96, -0.29, 0.61, 0.35, -1.2, -0.92, 0.8786030199958773, -0.22, 0.02, -1.22, 0.17, 0.42, -0.66, 1.45, 2.0, 0.54, 0.27, -2.58, 2.5324623233908947, 1.28, 0.13, 1.6902597402597401, -2.74, -2.16, -1.09, 0.49, 0.49, 3.41, -3.4, -3.28, 1.133290804863853, -3.91, 2.2398783572413152, 1.49, -0.74, 3.93, -6.22, -2.63, -3.89, 2.61, 1.58, 0.28480952380952385, 1.92, 0.99, 1.24, -0.01, 3.32, 1.29, 1.64, 0.71, 0.95, -0.3, -0.34, -0.91, -0.67, -1.9, 1.1101351386708531, 0.98, 0.58, 0.24, -1.0, 1.12, 1.18, 1.0825760496238783, -3.15, 1.04, 3.1, 1.32, 2.34, 0.34, -1.24, 1.31, 1.0, 0.1, 0.48, 1.49, 1.59, 2.13, 2.67, 1.51], ['399', -4.36, 1.46, 0.04, -0.16, 0.33, 0.82, 1.44, 0.02, -0.07, 0.5, -0.56, 0.23, -0.62, 0.16, 0.13, 2.28, -0.82, 0.43, -0.88, 0.06, 0.86, -0.1, -0.54, -0.65, -3.11, -1.0, 1.07, 0.8005454545454546, -0.05, 0.73, 0.7, 2.86, -0.25, 1.0, 0.12570238095238095, 0.63, 1.43, 0.46, 0.03, -0.08, -0.88, 0.69, 0.26, -0.85, -0.07, -0.1, 2.04, -1.05, 0.2, -1.11, -0.17, 0.62, -0.34, -0.77, -0.88, -0.03, -2.23, -2.04, -0.53, 1.12, 0.78, 0.75, 2.91, -0.2, 1.1526050661400618, -0.27, 0.68, 1.48, 0.51, 0.08, -0.03, -0.26, 0.33, -0.04, 2.11, -0.98, 0.27, -1.04, -0.1, 0.69, -0.27, -0.7, -0.81, 0.82, 2.82, -2.9, 0.37, 2.15, -0.94, 0.3, -1.01, -0.06832539682539683, 0.73, -0.23, -0.66, -0.78, -2.15, -1.74, -3.03, -1.8, -3.09, -2.17, -1.39, -2.33, -2.75, -2.86, 0.09, -1.76, 1.95, 0.96, 0.89, 1.08, 1.32, 1.26, -0.07, 0.88, 1.69, 0.72, 0.28, 0.17, 0.53, 0.06, -1.31, -0.37, 0.42, -0.54, -0.97, -1.08, 1.3, 1.14, -0.25, 1.27, -6.37, 0.11, 0.04, -2.76, 2.81, 1.428810171007621, 0.28, 1.29, -1.04, -1.93, -0.97, -2.21, 0.46, 2.75, -2.79, -2.89, 0.97, -4.26, 1.94, 2.37, -1.18, 3.96, -6.51, -2.62, -3.96, 1.0, 1.39, 0.95, 1.75, 0.78, 0.6696385796742939, 0.23, 2.89, 0.44, 0.8, -0.16, -0.6, -0.71, -0.36, -0.96, -1.38, -1.49, 1.032795351473923, 1.01, 0.6, -0.43, -0.54, 0.93, 1.02, 0.49, -3.11, 1.84, 3.11, 1.0, 1.56, 1.04, -0.11, 1.11, 1.2, 0.08, 0.7316666666666667, 0.8, 1.15, 1.38, 2.29, 1.24], ['400', -4.13, 1.15, 0.32122171562045876, -0.34, 0.3, 1.82, 1.414115257959829, 2.64, 1.88, 3.32, 0.89, 2.31, 1.67, 0.46, 0.85, 5.34, -0.42, 2.25, 5.46, 1.07, 3.28, 1.08, 0.11, 1.06, 2.34, 1.6993714145888918, 2.41, 1.41, 0.77, -0.43, -0.04, 4.41, -1.3, 1.34, 4.53, 0.18, 2.434453670078569, 0.19, -0.77, 0.16, 1.77, 2.1649361992161733, 0.99, -0.63, -1.81, -1.42, 2.96, -2.67, -0.06, 3.08, -1.21, 0.94, -1.2, -2.15, -1.23, 0.5, 1.6, 2.05, 2.16, 1.63, -1.19, -0.8, 3.62, -2.05, 0.57, 3.74, -0.59, 1.58, -0.57, -1.53, -0.6, 3.6, 2.85, 0.39, 4.86, -0.88, 1.78, 4.98, 0.61, 2.8, 0.62, -0.34, 0.6, 2.28, 9.31, -9.26, 2.4508709226619945, 4.45, -1.27, 1.38, 4.57, 0.21, 2.4, 0.23, -0.74, 0.2, -0.7, -1.92, -5.47, -2.94, 0.12, -4.06, -1.96, -4.04, -4.97, -4.07, 0.95, -1.93, 3.47, 2.3, 2.62, 2.255673518650032, 3.831809476486129, 2.68, 5.91, 1.5, 3.71, 1.51, 0.54, 1.49, 2.09, 1.06, 3.15, -1.15, 1.01, -1.14, -2.09, -1.16, 3.21, 3.67, 0.22, 3.15, -1.55, 1.18, 0.87, -4.63, 4.67, 2.37, 1.96, 3.13, -4.41, -4.61, -2.34, -2.15, 1.86, 7.12, -7.23, -6.76, 2.3, -7.0, 4.59, 2.74, -1.33, 11.35, -10.33, -7.49, -11.18, 4.46, -2.03, -4.17, -2.08, -4.16, -5.08, -4.18, 6.81, 2.23, 2.18, 0.01, -0.95, -0.01, 0.05, -2.12, -3.06, -2.15, 2.0601351386708533, 2.48, 2.22, -0.96, -0.03, 2.26, 2.47, 2.74, -5.19, 3.7, 5.19, 2.3, 2.08, 3.21, 0.94, 2.55, 2.14, 1.56, 1.72, 2.29, 2.325957527023814, 2.74, 3.47, 2.97], ['401', -1.88, 0.0, -0.07877828437954125, 0.12, -0.9, 0.19, 0.69, -0.06, 0.31, -0.17, 0.37, -1.02, 0.19, 0.27, -0.41, -0.85, 0.28, 0.19, 1.59, -0.07, -0.03, -0.81, -0.24, -0.31, 0.17, 0.16937141458889196, -0.54, -1.39, -0.18, -0.1, -0.78, -1.22, -0.1, -0.18, 1.21, -0.44, -0.4, -1.18, -0.61, -0.68, -0.13, -1.07, 0.860204081632653, 1.22, 1.31, 0.61, 0.17, 1.31, 1.23, 2.64, 0.96, 1.0, 0.22, 0.78, 0.72, -0.4376426685347185, -0.25, 0.08, 0.42, -0.36, 0.08, -0.6, -1.04, 0.09, 0.0, 1.4, -0.25, -0.22, -1.0, -0.43, -0.5, -0.41, -0.44, -0.68, -1.12, 0.0, -0.08, 1.32, -0.34, -0.3, -1.08, -0.52, -0.58, -0.3, 0.65, -0.65, 0.25, -0.44, 0.69, 0.61, 2.01, 0.35, 0.38, -0.4, 0.17, 0.11, -0.02, 0.69, 1.14, 1.05, 2.47, 0.79, 0.83, 0.04, 0.61, 0.55, -0.25, 0.71, 0.19572371188304005, -0.14, 0.0, -0.41, -0.44, -0.08, 1.31, -0.34, -0.31, -1.0196949805527125, -0.52, -0.58, 0.53, -0.36, 1.4, -0.26, -0.22, -1.0, -0.44, -0.5, -0.08, -0.13, 0.38, -0.57, 0.03, -0.19, -0.35, 0.52, -0.59, -0.2411898289923789, -0.08, 0.28, 0.4205182488772715, 0.31, 0.19, -0.94, -0.15, -0.6, 0.67, 0.49, -0.15, 0.94, -0.32, -0.2, 0.08, -1.37, 7.1, 0.9, 1.41, -0.35, -1.73, -1.63, -1.6, -2.36, -1.81, -1.87, -0.49, -0.1, 0.03, -0.74, -0.18, -0.24, -0.14, -0.78, -0.21, -0.28, 0.19, 0.07, 0.64, 0.57, 0.5, -0.21, -0.21, 0.12, 3.45, 0.09019962695749935, -3.36, -0.46, -1.1488174603174601, 0.08, -0.06, -0.68, -0.23, -0.09, -0.28, 0.27, 0.14, -1.15, -1.9884047619047618, 0.15], ['402', 2.15, 0.84, 0.69, -0.07, 0.87, 1.29, 0.76, 1.9917205965359586, 1.8893780543870107, 0.99, -0.94, 0.471934498041641, -0.6860867348791511, -2.04, -1.77, 0.08, -0.72, -0.36, 1.14, -1.27, 2.087335482087359, -1.96, -1.48, 0.24, 3.76, 1.89, 1.9826583949931125, 1.23, 0.19, -1.11, -0.7721800287049088, 1.03, 0.23, 0.59, 2.1, -0.33, 3.02, -1.03, -0.54, 1.2338417231978391, 1.42, 1.6, 0.71, -1.02, -2.31, -2.04, -0.2, -0.99, -0.63, 0.86, -1.54, 1.77, -2.23, -1.75, 0.2808287981859412, 1.31, 1.71, 1.46, 1.48, 1.75, -1.3, -1.03, 0.83, 0.03, 0.39, 1.9, -0.52, 2.82, -1.22, -0.73, 1.0, 1.85, 3.1, 0.28, 2.16, 1.35, 1.72, 3.25, 0.79, 4.18, 0.08, 0.58, 2.33, 2.33, 7.17, -7.08, 2.8466982383853203, 1.88, 1.07, 1.43, 2.96, 0.7037447711019141, 3.88, -0.2, 0.3, 2.04, 2.5, 0.91, -0.79, -0.44, 1.06, -1.34, 1.97, -2.04, -1.55, 0.16, 1.23, 0.94, 2.41, 1.55, 2.1, 1.08, 1.72, 0.36, 1.87, -0.3602873118944545, 2.79, -1.25, -0.6940121365844474, 0.96, 3.0265360710717855, 1.35, 1.5, -0.91, 2.598603019995877, -1.4842004503433075, -1.12, 0.6, 3.35, 2.54, -0.06, 1.75, 4.94, 1.4, 0.8, -1.45, 1.49, 0.71, 2.58, 3.2, -4.55, -3.1, -1.6, 1.05, 1.27, 4.83, -4.76, -4.67, 1.55, -2.38, 3.12, 1.74, -0.85, 5.18, -7.23, -3.51, -5.05, 4.47, -0.15, -2.38, 0.9, -3.07, -2.59, -0.89, 4.72, 2.29, 3.3635374149659865, -0.7, -0.21, 1.53, -1.04, -3.93, -3.45, -1.77, 1.79, 1.88, 3.01, 0.5, 2.3222487553150164, 1.57, 1.58, 2.01, -3.7, 2.03, 3.77, 0.9172638105244333, 3.03, 2.5, 1.74, 1.05, 1.2, 1.07, 2.93, 1.16, 0.75, 2.72, 3.75, 0.3], ['403', -4.38, 0.95, 0.04015289830927054, 0.1, -0.3, 0.44, 1.52, 0.02, 0.19, -1.29, -1.7, -1.77, -0.07, -2.02, -0.85, 0.29, -1.5, -1.5, -3.9, -0.71, -1.33, -1.94, -1.71, -1.94, -0.78, 0.64, 0.42, -0.07, 1.6808333333333332, -0.33, 0.86, 2.03, 0.2, 0.2, -2.24, 1.0, 0.37, -0.24, -0.01, -0.24, 0.05, -0.12993788819875776, 0.49, 1.811197467496117, -0.25, 1.0108150295752765, 2.1, 0.28, 0.27, -2.17, 1.08, 0.478065468086443, -0.17, 0.07, -0.17, 0.42, -0.55, 0.6, 0.15, -1.22, -1.95, -0.78, 0.36, -1.43, -1.43, -3.83, -0.64, -1.26, -1.87, -1.64, -1.87, 0.02, 0.75, 1.2, 2.36, 0.53, 0.53, -1.92, 1.34, 0.7, 0.08, 0.32, 0.08, 0.37, 0.95, -0.98, -0.44, 1.15, -0.65, -0.66, -3.08, 0.14, -0.49, -1.1, -0.86, -1.1, -1.92, -1.58, -1.78, -1.776904761904762, -4.17847619047619, -1.0, -1.62, -2.22, -1.99, -2.22, 0.08, -1.47, -0.54, 0.36, 0.37, 0.38567351865003197, 0.2109570400359874, 0.0, -2.4398412698412697, 0.8, 0.17, -0.45, -0.21, -0.45, 0.52, 0.22, -2.44, 0.8, 0.17, -0.44, -0.21, -0.44, -0.03, -0.05, 0.28, 0.35, -5.92, 0.06, 0.07, -0.72, 0.67, 0.34, -1.09, 1.40025974025974, 1.16, -0.7, -0.35, -2.34, 0.22, 1.09, -1.09, -1.07, 0.35, -1.11, 0.69, -1.17, 0.56, 0.6707142857142857, 0.0, -0.46, -0.74, -1.17, 2.72, 3.32, 2.67, 2.04, 2.28, 2.2057617128436457, 1.02, -0.5798412698412698, -0.62, -1.24, -1.0, -1.24, 0.04, -0.62, -0.38, -0.61, 0.23, 0.27, 0.66, 0.24, 0.0, 0.35, 0.34, 0.07, -0.1, 0.07, 0.08, 0.12, 0.5410935020800125, 0.43, -0.24, 0.41, -0.06, 0.12, 0.11, 0.88, 0.745957527023814, 1.6, 0.7030376647162363, 0.93], ['404', -0.16, 0.18, 0.18122171562045875, -0.02, 1.28, 0.04, 0.16, 0.67, 0.76, 0.24, -0.55, -0.41, 1.55, -0.94, -1.9, 0.17, 0.56, 0.19, -0.65, -2.45, 0.24, 1.7960714285714285, 1.2, -0.21, 1.39, 0.85, 0.8, 0.14, 2.11, -0.39, -1.35, 0.72, 1.11, 0.75, -0.09, -1.91, 0.8, 2.36, 1.77, 0.34, 0.66, -0.1, 0.66, 1.97, -0.53, -1.49, 0.58, 0.97, 0.61, -0.23, -2.04, 0.66, 2.21, 1.62, 0.2, 0.12006284630567655, 0.43, 1.01, 0.85, -1.28, -2.45, -3.39, -1.36, -0.97, -1.33, -2.16, -3.93, -1.116578845757417, 0.24, -0.34, -1.73, 1.19, 1.19, -0.97, 1.11, 1.51, 1.14, 0.3, -1.52, 1.19, 2.76, 2.16, 0.74, 0.63, -2.72, 2.69, 2.18, 2.1, 2.5, 2.13, 1.28, -0.56, 2.18, 3.76, 3.16, 1.72, 0.872095238095238, 0.08, 0.39, 0.03, -0.81, -2.61, 0.08, 1.62, 1.04, -0.37, 0.16, 0.04, -2.49, 0.06, -0.31, 0.45, -0.31, -0.36, -1.2, -2.99, -0.31, 1.23, 0.64, -0.76, -1.22, 0.05, -0.84, -2.64, 0.05, 1.59, 1.01, -0.4, -1.36, -1.41, 0.15, -0.08, 2.87, 0.1, 0.08, -1.81, 1.81, 0.9, -0.28, 1.23, -5.67, -0.19, -0.11, -0.11, -0.32, 0.22, -0.19, -0.28, 0.09, -2.71, 0.25987835724131525, 0.61, -0.3, -0.94, 1.28, 0.77, 0.91, 5.66, 0.9, -1.81, 0.9, 2.45, 2.179638579674294, 0.44, 0.26, 2.76, 2.76, 4.35, 3.74, 2.29, 0.0, 1.54, 0.96, -0.45, 0.7, 0.73, -1.52, -0.58, -1.97, 0.08, 0.03, 0.68, -0.14, 0.0, 0.14, 0.71, 0.12, -0.95, -1.4, 0.3, 0.78, -0.45, -0.06666666666666667, -0.21, 0.45, 0.34, 0.55, 0.34], ['405', 2.59, 0.66, 0.0, -0.28538095238095235, -0.1, 0.21, 0.4741152579598292, -0.09, 0.67, -0.93, -1.55, -1.17, -1.41, -1.4, 0.73, -1.18, -2.47, -1.2, -1.99, -1.41, -0.39, -2.02, -2.3, -1.49, 0.63, 0.52, 0.6626583949931124, 0.39, 0.14, 0.16, 2.32, 0.38, -0.93, 0.36, -0.44, 0.15, 1.18, -0.47, -0.76, 0.07, -0.38, 1.3949361992161733, 0.25, -0.24, -0.22, 1.93, -0.01, -1.31, -0.03, -0.82, -0.24, 0.7996547292370609, -0.85, -1.14, -0.31, 0.69, -0.31, -0.14805211528237844, 0.45, 0.49, 0.12310472253556064, 2.18, 0.24, -1.07, 0.22, -0.58, 0.0, 1.04, -0.61, -0.9, -0.07, 0.54, 0.47, 2.16, 0.22, -1.09, 0.2, -0.6, -0.01, 1.02, -0.63, -0.91, -0.09, 0.99, 3.58, -3.66, -1.65, -1.9, -3.18, -1.92, -2.7, -2.13, -1.12, -2.73, -3.01, -2.2, 0.5012233560090703, 0.25, -1.3, -0.02, -0.81, -0.23, 0.8, -0.84, -1.13, -0.31, 0.28, 0.26, -0.33, 0.65, 0.62, 0.67, 1.58, 1.3, 0.5, 1.09, 2.13, 0.47, 0.18, 1.0685846838830657, 0.88, 0.27, -0.79, -0.21, 0.82, -0.82, -1.11, -0.29, 1.36, 1.6, -0.31, 0.77, 0.71, 0.12, 0.28, -1.72, 1.78, 0.9, 0.55, -0.31, -0.93, -1.32, -0.66, 1.3, 0.19, 1.95, -1.95, -1.96, 0.64, -2.56, 1.28, 2.78, -1.37, 4.77, 0.34, -3.25, -4.7, 0.87, 1.08, 0.59, 1.63, -0.03, -0.32, 0.51, 1.97, 0.49, 1.03, -0.61, -0.9, -0.08, -0.54, -1.5411214088935783, -1.91, -1.1, 0.64, 0.72, 1.11, -0.29, 0.54, 0.65, 0.7, -0.22, -6.23, 0.65, 6.25, 0.97, 0.74, 1.4, 0.83, 0.34, 0.8002197802197802, 0.09, -0.12, 0.14, 0.56, 2.9, 1.53, 0.52], ['406', -11.77, 0.0, -0.08, -0.08, -0.74, -0.02, -0.67, 0.52, -0.65, 0.1, 1.03, 1.44, -0.34, 0.89, -0.3, 4.37, 0.5, 0.02, -2.24, 0.64, -0.5, 0.0, -0.17, -0.18, 0.4, -0.03, -0.93, 0.41, -1.35, -0.14, -1.32, 3.31, -0.53, -1.0, -3.229285714285714, -0.39, -1.51, -1.02, -1.19, -1.2, 0.33, -0.48, -1.33, -1.75, -0.55, -1.72, 2.89, -0.93, -1.4, -3.63, -0.79, -1.91, -1.42, -1.4928571428571429, -1.6, 1.24, 1.09, 1.71, -0.11, 0.44, 1.23, 0.04, 4.73, 0.84, 0.4626050661400617, -1.8013219954648525, 0.98, -0.16, 0.34, 0.16, 0.16, 2.02, -0.78, -1.18, 3.45, -0.39, -0.86, -3.1, -0.25, -1.2169183673469388, -0.88, -1.05, -1.0064403582748793, -0.72, 0.81, -0.83, 0.4, 4.69, 0.8, 0.32, -1.94, 0.94, -0.2, 0.3, 0.13, 0.12, -3.58, -4.1, -3.71, -4.17, -6.33, -3.58, -4.67, -4.19, -4.36, -4.36, 0.09, -4.17, 3.29, 0.0, 0.03, 0.0, -0.4, -0.48, -2.72, 0.14, -0.99, -0.5, -0.67, -0.68, 0.18, 0.07, -2.26, 0.62, -0.34139698000412266, -0.02, -0.19, -0.2, 0.58, 0.53, 0.03, 0.08, -10.58204761904762, 0.2, 0.17, -0.03, -0.01, 0.0, -0.3, -0.15, 1.06, 0.0, -0.02, -5.73, 0.27, 0.05, -0.05, -0.02, -0.01, 0.0, 0.02, 1.28, -0.65, -1.2, -2.0, 0.85, 1.22, -1.16, 2.39, 2.94, 1.78, 2.29, 2.4296385796742936, 2.1, 0.0, -0.54, -1.13, -0.64, -0.81, -0.81, 0.6, 0.5, 0.33, 0.32, -0.63, -0.47, 0.1, -0.17, -0.18, 0.0, -0.01, 0.51, -3.27, 2.01, 3.18, -1.57, -0.59, 0.27, -0.01, -0.08, 0.0, 0.56, 0.7702244897959184, -0.11, 0.28, -1.7, -1.26, -0.72], ['407', -2.11, -0.3, 0.08015289830927054, -0.12, -0.44, 0.81, 0.36, 0.56, 0.68, -0.57, -1.76, -0.52, -1.05, -1.24, -1.11, -0.36, -1.64, -0.85, 0.42, -0.16, -0.23, -0.79, -1.28, -0.91, 0.91, 0.63, 1.2, 1.26, 0.71, 0.53, 0.66, 1.42, 0.11, 0.92, 2.22, 1.63, 1.55, 0.99, 0.5788796134390451, 0.86, 0.8574684253532109, 1.7949361992161734, -0.05, -0.54, -0.72, -0.59, 0.16, -1.13, -0.33, 0.95, 0.36, 0.29, -0.27, -0.77, -0.39, 0.5900628463056766, 0.28, 0.29, 0.25, 0.49, -0.18, -0.05, 0.71, -0.6, 0.21, 1.49, 0.91, 0.83, 0.27, -0.23, 0.15, 0.98, 0.67, 0.13, 0.89, -0.41, 0.39, 1.68, 1.09, 1.02, 0.46, -0.05, 0.33, 1.33, 1.72, -1.75, 0.5766982383853202, 0.76, -0.54, 0.26, 1.55, 0.96, 0.88, 0.32, -0.18, 0.2, 0.02, -0.22, -1.29, -0.5, 0.78, 0.2, 0.12, -0.43, -0.93, -0.55, 0.28, -0.24, 0.68, 0.87, 0.65, 1.075673518650032, 1.09, 0.81, 2.1, 1.51, 1.44, 0.87, 0.44598786341555263, 0.8085846838830657, 0.2, 0.28, 1.28, 0.7, 0.62, 0.1957995496566927, -0.44, -0.06, 0.47, 0.69, -0.27, 0.55, 0.24, 0.1, 0.03, -3.28, 3.26, 1.64, -0.12, 0.52, 0.8277589791161221, -1.77, -0.87, -1.01, 0.42, 2.68, -2.71, -2.68, 0.87, -4.94, 1.76, 1.72, -0.86, 3.22, -5.13, -2.22, -3.16, -0.77, -0.99, -0.58, -0.4527867132867132, -1.2, -1.7, -1.33, 2.7, -0.41, -0.07, -0.63, -1.13, -0.75, -0.34, -0.56, -1.05, -0.68, 0.67, 0.8, 0.21, -0.5, -0.12, 0.89, 0.86, 0.57, -3.15, 0.02, 3.14, 0.94, 0.76, 0.72, 0.38, 0.58, 1.7, 0.39, 0.29, 1.16, 0.34, 1.75, 0.74, 0.53], ['408', 3.41, -0.08, -0.14877828437954127, 0.16, -1.45, -0.05, -0.49, -0.61, 0.0, -0.13, -0.33, 0.15, 0.93, 1.77, 1.0, -0.29, -0.33, 0.17, 1.27, 1.37, 0.48, 0.91, -0.13, -0.34, -1.55, -0.3, 0.19, 0.48, 1.26, 2.1, 1.33, 0.04, 0.0, 0.5, 1.6, 1.7, 0.81, 1.24, 0.19, -0.01, -0.75, 0.9749361992161734, -0.28, 0.77, 1.61, 0.84, -0.44, -0.48, 0.02, 1.11, 1.22, 0.33, 0.75, -0.28, -0.49, 0.25006284630567654, -0.71, -0.93, -0.01, -1.05, 0.83, 0.07, -1.2, -1.24, -0.75, 0.34, 0.44, -0.44, -0.02, -1.05, -1.25, -2.1, -1.87, -0.75, -2.02, -2.06, -1.57, -0.49, -0.39, -1.26, -0.84, -1.87, -2.07, 0.42, 0.67, -0.62, -1.12, -1.27, -1.31, -0.82, 0.5057885487528346, 0.37, -0.51, -0.09, -1.12, -1.32, 1.31, 0.2273665312165629, -0.04, 0.46, 1.56, 1.66, 0.77, 1.2, 0.15, -0.05, -0.22, 0.2, -0.09, 0.05, -0.16, 0.24, 0.2, 0.5, 1.6, 1.7, 0.81, 1.24, 0.2, -0.01, -0.9, -0.3, 1.1, 1.2, 0.31, 0.74, -0.3, -0.51, -0.09, 0.91, 0.09, -0.14, 2.64, -0.03, -0.02, -1.11, 1.08, 0.55, 0.86, -1.1797402597402598, 2.8787161013589584, -0.13, -0.05, 1.73, -0.16, 0.11, -0.08, -0.17, 0.1, -1.58, 0.1, -0.28, 0.13, 0.49, 0.8686904761904761, -0.46, -0.57, -2.85, -1.38, 0.1, -0.78, -0.36, -1.38, -1.58, 0.25, -1.48, -0.88, -0.46, -1.48, -1.68, -0.61, 0.43, -0.61, -0.81, 0.0, 0.21, -1.03, -1.03, -1.23, 0.02, 0.09, -0.79, 0.46, 0.16, -0.96, -0.27, -1.36, 0.0, -0.2, 0.3, 0.75, 0.23, -0.49, -0.23, 0.2, -0.78, -1.55, 1.0930167737073972], ['409', 5.44, 0.21, 0.29, -0.17, 1.32, 3.36, 2.4941152579598294, 5.13, 4.14, 3.63, -2.33, 1.0393248299319728, 0.34, -1.04, -1.56, 1.9, -0.8, 2.58, 4.85, 3.07, 4.52, 0.26, -0.81, 1.49, 5.29, 3.6, 6.132658394993112, 3.44, 2.73, 1.32, 0.8, 4.33, 1.56, 5.03, 7.35, 5.53, 7.02, 2.66, 1.55, 3.963841723197839, 3.39, 5.0, 2.57, -0.68, -2.05, -2.56, 0.86, -1.81, 1.54, 3.78, 2.02, 3.46, -0.76, -1.82, 0.46, 5.25, 4.55, 3.29, 3.89, 3.28, -1.37, -1.88, 1.56, -1.14, 2.24, 4.49, 2.72, 4.17, -0.07, -1.15, 1.15, 5.0, 4.72, -0.52, 2.97, 0.24, 3.66, 5.95, 4.15, 5.62, 1.32, 0.23, 2.6135596417251206, 5.36, 12.29, -12.37, 5.260870922661994, 3.51, 0.76, 4.2, 6.5, 4.69, 6.17, 1.85, 0.75, 3.1, 4.98122335600907, 1.7, -2.65, 0.67, 2.89, 1.14, 2.632626537352693, -1.61, -2.66, -0.4, 1.26, 1.9493682032253463, 4.6, 3.21, 3.38517906963434, 3.09, 4.47, 3.41, 5.7, 3.9, 5.37, 1.08, -0.01, 2.32, 3.3, 1.02, 2.21, 0.47, 1.89, -2.26, -3.31, -1.06, 4.33, 5.05, 0.37, 3.84, 9.37, 0.5803231292517006, 0.81, -5.78, 5.78, 2.91, 1.61, 5.15, -1.0094817511227283, -6.49, -3.21, 2.84, 2.0, 9.880596861471862, -9.66, -9.61, 3.19, -8.77, 6.37, 2.45, -1.19, 13.35, -14.71, -8.9, -13.33, 1.14, -1.16, -1.7, -0.31, -4.37, -5.4, -3.2, 9.6, 0.54, 1.41, -2.72, -3.76, -1.53, -0.85, -4.07, -5.1, -2.9, 4.32, 4.63, 3.35, -1.07, 1.23, 3.22, 3.29, 5.1, -7.43, 4.26, 7.65, 4.41, 4.27, 4.5586374482009715, 2.33, 4.3, 2.96, 1.93, 1.74, 2.54, 2.1, 7.83, 4.61, 2.12], ['410', 2.09, 0.62, 0.09122171562045875, -0.17, 0.28, 0.93, 0.22, 1.39, 1.3093780543870106, 2.22, 0.92, 2.16, 0.94, 0.8, 1.04, 1.86, 1.91, 2.52, -1.79, 1.74, 2.45, 3.7130748299319727, 1.41, 1.94, 1.39, 1.07, 1.28, 1.23, 0.02, -0.12, 0.11, 0.93, 0.98, 1.7072589041444086, -2.69, 0.81, 1.594453670078569, 2.76, 0.48, 1.0, 1.1, 2.41, 0.05, -1.2, -1.33, -1.1, -0.3, -0.24, 0.35, -3.87, -0.41, 0.28, 1.52, -0.74, -0.22, 1.65, 0.75, 1.12, 1.09, 1.27, -0.13, 0.1, 0.91, 0.97, 1.57, -2.7, 0.8, 1.5, 2.75, 0.46, 0.99, 1.56, 1.41, 0.6502278911564625, 1.05, 1.1, 1.71, -2.57, 0.93, 1.64, 2.89, 0.6, 1.12, 1.57, 1.71, -1.59, 1.17, 0.81, 0.87, 1.47, -2.8, 0.7, 1.4, 2.65, 0.37, 0.89, 0.71, 0.35, 0.05, 0.66, -3.58, -0.11, 0.58, 1.82, -0.44, 0.08, -0.39, 0.46, -0.34, 0.66, 0.58, 0.45, 0.3, 0.6, -3.63, -0.17, 0.53, 1.76, -0.5, 0.02, -1.2, -0.3, -4.21, -0.76, -0.07, 1.16, -1.09, -0.57, 0.11, -0.31, -0.17, -0.64, 2.04, -0.36, 0.23, -0.4, 0.41, 0.22, 0.13, 2.44, -0.96, -1.25, -0.64, 1.02, 0.3430797898687791, 1.9, -1.96, -1.95, 0.65, -0.63, 1.36, -0.07160934502005914, -0.16, 0.88, -3.37, -0.6, -0.94, 0.97, 4.08, 3.6, 4.32, 5.6, 3.25, 3.79, 2.0, 0.47, 0.7, 1.94, -0.33, 0.19, -0.23, 1.23, -1.02, -0.5, 1.19, 1.32, -1.44, -2.22, -1.71, 0.62, 0.5, 1.39, -1.76, -0.32, 1.7021428571428572, 0.82, 1.2010935020800126, 0.8, 0.52, 0.71, 0.28, 0.8, 0.1, 0.84, 0.28, 1.03, 1.31, -0.05], ['411', -1.3, -0.59, -0.10877828437954125, -0.03, -1.18, -0.71, -4.9, -1.97, -1.33, -2.82, -1.75, -0.77, -1.68, -0.29, -0.94, -2.111439909297052, -1.76, -2.19, -1.21, -1.55, -2.16, -1.57, -1.34, -1.92, -1.67, -0.87, -1.09, 0.99, 0.08, 1.49, 0.82, -0.69, 0.6328571428571429, -0.45, 0.55, 0.21, -0.41, 0.18, 0.42, -0.17, -1.68, -1.74, -2.06, -0.91, 0.49, -0.17, -1.67, -0.99, -1.43, -0.44, -0.78, -1.4, -0.8, -0.57, -1.16, -1.0, -0.76, -0.862172027190216, -1.01, -1.16, 1.41, 0.75, -0.76, -0.08, -0.52, 0.47, 0.13, -0.49, 0.11, 0.34, -0.25, -1.38, -2.54, -0.6592857142857144, -2.1485714285714286, -1.48, -1.91, -0.93, -1.26, -1.88, -1.29, -1.06, -1.64, -1.36, -4.07, 4.06, -1.9, -1.5, -0.82, -1.26, -0.27, -0.61, -1.23, -0.64, 0.05251700680272092, -0.99, -1.34, -0.4, 0.69, 0.24, 1.2415238095238095, 0.9, 0.28, 0.88, 1.11, 0.52, -0.61, -0.45, -2.01, -0.93, -1.03, -0.8, -1.08, -0.44, 0.55, 0.21, -0.41, 0.19, 0.42, -0.17, -1.28, -0.65, 1.0, 0.66, 0.03, 0.63, 0.87, 0.27, -1.09, -1.18, -0.22, -1.11, -3.8578571428571427, -0.96, -1.09, 1.59, -1.64, -0.85, -1.4, -2.49, 2.57, 1.83, 0.9745476190476191, -0.66, -0.67, -2.75, 2.8, 2.74, -0.92, 2.5, -1.83, -1.69, 0.83, -3.26, 10.0, 2.16, 3.25, -2.54, -1.63, -0.34, -0.96, -0.36, -0.13, -0.72, -2.74, -1.29, -0.62, -0.03, 0.21, -0.38, -0.68, 0.6, 0.84, 0.24, -1.34, -1.12, -1.27, 0.24, -0.35, -0.9, -0.96, -2.08, 5.86, -1.72, -5.67, -1.11, -1.53, -1.5, -0.59, -0.89, -0.79, -0.3, -0.47, -0.6, -0.92, -1.77, -2.05, -0.89], ['412', -1.51, 0.35, 0.08, -0.18, 0.48, 0.25, 0.21, 0.26, 0.33, 1.66, 0.58, 2.69, 1.96, -0.04, 1.5, 2.04, 1.4, 1.57, -1.17, 0.61, 2.21, 1.93, 1.16, 1.6, 0.37, 0.31937141458889196, 1.08, 2.1, 1.38, -0.61, 0.92, 1.46, 0.82, 0.98, -1.73, 0.04, 1.62, 1.35, 0.58, 1.02, 0.62, 1.12, -1.0, -0.71, -2.65, -1.15, -0.63, -1.25, -1.09, -3.75, -2.02, -0.47, -0.74, -1.49, -1.05, 0.39, 0.51, 0.14, 0.08, -0.29, -1.96, -0.45, 0.08, -0.55, -0.39, -3.052819727891156, -1.32, 0.24, -0.03, -0.79, -0.35, -0.75, 1.7, 1.5407142857142857, 2.08, 1.44, 1.6, -1.13, 0.65, 2.25, 1.97, 1.2, 1.64, 1.16, 1.05, -1.09, 0.16, 0.53, -0.1, 0.06, -2.63, -0.88, 0.69, 0.42, -0.34, 0.1540077275244506, -0.69, -0.37, -0.63, -0.47, -3.15, -1.4, 0.16, -0.11, -0.87, -0.43, 0.09, -0.44, 0.21, 0.17, 0.27, 0.09, 0.26, 0.16, -2.53, -0.78, 0.8, 0.52, -0.24, 0.2, -0.22, 0.15307674813036726, -2.69, -0.94, 0.8086030199958774, 0.36, -0.4, 0.04, 0.91, 0.78, -0.27, 0.22, -2.37, 0.05, -0.03, -0.26, 0.31, 0.15, 0.2, -0.11, -2.17, -0.37, -0.16, -0.75, -0.07, 0.48, -0.58, -0.51, 0.17, -0.44, 0.35, 1.61, -0.77, 0.75, -2.97, -0.48, -0.8, 2.09, 2.86, 1.8, 3.42, 3.14, 2.35, 2.81, 0.5, 1.04, 1.59, 1.31, 0.54, 0.99, -0.53, -0.27, -1.03, -0.59, 0.3, 0.84, -0.26, -0.76, -0.32, 0.16, 0.19, 0.31, -1.56, -0.23, 1.64, 0.5372638105244333, 0.6610935020800125, 0.5, 0.44, 0.1, 0.15, -0.08, -0.35, 0.04, 0.06, 0.86, 2.27, 0.42], ['413', 3.007142857142857, -0.58, 0.13122171562045873, 0.26, 0.88, -0.52, 0.28, 0.57, 0.7, -0.83, -1.72, -1.29, -0.9, -1.26, -1.96, -0.98, -0.33, -1.2, -0.46, -1.75, -0.02, -1.18, -0.84, -0.54, 1.09, -0.46, 0.9, 0.44, 0.83, 0.47, -0.24, 0.76, 1.41, 0.53, 1.28, -0.03, 1.73, 0.55, 0.9, 1.2, 0.38, 1.22, 0.4602040816326531, 0.39, 0.03, -0.68, 0.32, 0.97, 0.09, 0.9371355564861203, -0.47, 1.28, 0.11, 0.45, 0.76, 0.2, 0.91, 1.44, 1.0, 0.07, -0.36, -1.07, -0.08, 0.57, -0.3, 0.45, -0.85, 0.89, -0.28, 0.06, 0.36, 0.56, 0.43, -0.71, 0.29, 0.94, 0.06, 0.81, -0.49, 1.25, 0.08, 0.43, 0.73, 0.62, 0.52, -0.51, 1.15, 1.0, 1.66, 0.78, 1.53, 0.22, 1.98, 0.8, 1.14, 1.45, 0.35, 0.15, 0.65, -0.22, 0.52, -0.78, 0.96, -0.2, 0.14, 0.44, 0.26, 0.16, -1.54, -0.21, -0.16, -0.21432648134996807, -0.5, -0.87, -0.13, -1.42, 0.3106802721088435, -0.85, -0.51, -0.21, 0.1, 0.37, 0.75, -0.56, 1.19, 0.02, 0.36, 0.67, -0.21, -0.98, 0.5, -0.46, 0.61, 0.15, 0.42, -0.59, 0.63, 0.31, -0.1, 1.41, -1.83, 0.41, 0.22, 1.871438775510204, -0.28, -0.63, 0.64, 0.75, -0.22, -0.8, -0.44, -1.41, 0.74, -1.51, 3.5, 1.0, 1.43, 1.86, -0.3516360544217687, -1.29, 0.44, -0.72, -0.38, -0.08, -0.5468321004392431, 0.93, 1.76, 0.58, 1.3394625850340136, 1.23, -0.81, -1.16, -0.82, -0.52, 0.74, 0.86, 0.35, 0.35, 0.65, -0.23, -0.27, 0.61, 1.68, -1.31, -1.88, -0.73, 0.11, 0.01, 0.3, -1.77, 0.54, 0.015297952047952229, -0.27, -0.62, -0.29, -1.67, 0.31, 0.77], ['414', -1.9, -0.17, -0.04877828437954125, -0.14, -0.24, 0.55, 1.15, 0.51, 0.06, 0.94, 0.63, 0.3, 0.9, 1.02, 0.7, 1.33, 0.0, 1.04, -0.93, 1.27, 0.55, 0.65, -0.42, 0.06, -0.11, -0.18, 0.34265839499311246, -0.33, 0.26, 0.38, 0.07, 0.69, -0.63, 0.4, -1.55, 0.63, -0.09, 0.02, -1.05, -0.57, -0.15, 0.4249361992161734, 0.64, 0.6, 0.72, 0.4, 1.03, -0.3, 0.74, -1.22, 0.97, 0.25, 0.35, -0.72, -0.24, 0.24, 0.14, 0.43, 0.3, 0.04, 0.11, -0.2, 0.43, -0.89, 0.14, -1.81, 0.37, -0.35, -0.25, -1.31, -0.83, 1.57, -0.07, -0.31, 0.31, -1.0, 0.02, -1.92, 0.25, -0.46, -0.36, -1.43, -0.95, 0.03, 3.8, -3.83, 0.24, 0.62, -0.7, 0.34, -1.62, 0.56, -0.15, -0.05, -1.12, -0.64, -0.86, -0.38, -1.31, -0.29, -2.23, -0.06, -0.77, -0.67, -1.73, -1.25, 0.09, -0.26063179677465376, 1.4, 0.8715981806829014, 0.89, 0.825673518650032, 0.94, 1.04, -0.93, 1.27, 0.55, 0.65, -0.43, 0.06, 0.38, -0.1, -1.95, 0.23, -0.49, -0.38, -1.45, -0.97, 1.2, 0.91, -0.13, 0.93, -2.6, -0.26, -0.26, -0.7, 0.67, 0.37, -0.4, -0.07, 0.67, -1.6, -0.82, -0.88, 0.72, 2.38, -2.35, -2.38, 0.81, -1.02, 1.61, 1.04, -0.51, 2.82, -0.38, -1.83, -2.81, -0.61, 1.89, 2.22, 1.49, 1.59, 0.51, 1.0, 2.42, -0.32, -0.72, -0.61, -1.67, -1.19, 0.39, 0.11288492856349999, -0.97, -0.48, 0.19, 0.24845354645354667, 0.29, -1.07, -0.59, 0.8, 0.83, 0.44257604962387836, -0.19, 1.16, 0.13, 1.02, 0.98, 1.37, 0.49, 0.92, 0.3345528598385743, 0.9, 0.45, 0.82, 0.965957527023814, -0.49, 1.59, 1.08], ['415', -2.6, -0.29, 0.13122171562045873, -0.13, 0.78, 0.9, 0.49411525795982914, 0.26, 0.37, -0.61, -0.7993911564625851, -1.28, -1.22, -0.65, -0.84, -0.6, -1.5, -0.97, -11.0, -1.93, -0.43, -1.85, -1.44, -1.72, 0.09, 0.12, 0.21, -0.47, -0.41, 0.17, -0.03, 0.22, -0.69, -0.16, -10.27, -1.13, 0.38, -1.04, -0.64, -0.91, -0.05, 1.9608975626058773, 0.68, 0.06, 0.64, 0.44, 0.69, -0.22, 0.31, -9.85, -0.67, 0.85, -0.58, -0.07285714285714287, -0.45, -0.01993715369432346, 0.0, 0.26, 0.47, 0.62, 0.6831047225355606, 0.38, 0.63, -0.28, 0.25, -9.9, -0.72, 0.8, -0.64, -0.23, -0.5, 0.61, 0.04, -0.2, 0.05, -0.86, -0.33, -10.42, -1.29, 0.22, -1.21, -0.8, -1.08, 0.88, 2.57, -2.63, 0.24, 0.25, -0.66, -0.13, -10.25, -1.1, 0.41, -1.01, -0.6, -0.88, -0.38, -0.01, -0.91, -0.38, -10.47, -1.35, 0.16, -1.26, -0.85, -1.13, 0.62, 0.06, 2.79, 0.78, 0.93, 0.59, 0.9009570400359874, 0.53, -9.65, -0.44, 1.08, -0.36, 0.05, -0.22, 1.19, 0.36, -10.13, -0.97, 0.54, -0.89, -0.48, -0.75, 0.95, 0.85, -0.15, 0.72, -1.17, 0.14, 0.13, -0.74, 0.74, 0.4088101710076211, 0.63, 1.09, -2.6, -1.57, -0.81, -1.29, 0.78, 2.45, -2.3, -2.31, 0.833290804863853, -1.08, 1.57, 0.45, -0.26, 2.7, -2.59, -1.91, -2.64, 2.6, 11.68, 10.517178777571635, 11.88, 10.29, 10.74, 10.43, 2.4208051948051947, 1.35, 1.53, 0.09, 0.5, 0.22, -0.18, -1.42, -1.02, -1.29, 0.37, 0.56, 1.26, 0.41, 0.14, 0.84, 0.8, 0.29, -2.14, 1.84, 2.29, 0.35, 1.26, 0.85, -0.28, 0.55, 0.29, 1.1, 0.64, 1.15, 1.13, 0.44, 2.04, 1.49], ['416', 4.501428571428571, -0.63, -0.08, -0.13, 0.49, 0.48, 1.45, 0.75, 0.79, -0.05, -1.16, -0.74, -0.75, -0.48, -1.2, -0.33, -0.23, -0.35, 0.78, -1.15, 0.27, -0.02, -1.16, -0.74, 0.84, 0.969371414588892, 1.12, 0.42, 0.42, 0.69, -0.04, 0.84, 0.94, 0.83, 1.96, 0.01, 1.524453670078569, 1.15, 0.0, 0.42, 0.26, 1.99, 0.7, 0.0, 0.4378753944468231, -0.46, 0.42, 0.52, 0.4, 1.53, -0.41, 1.02, 0.73, -0.42, 0.0, 0.37, 0.76, 0.95, 0.78, 0.7, 0.27, -0.45, 0.42, 0.52, 0.4, 1.54, -0.41, 1.02, 0.73, -0.42, 0.0, 0.45, 0.43, -0.72, 0.15, 0.25, 0.13, 1.26, -0.68, 0.75, 0.46, -0.69, -0.21644035827487929, 1.24, 2.66, -2.7, 1.19669823838532, 0.88, 0.98, 0.86, 2.0, 0.05, 1.48, 1.19, 0.04, 0.46, 2.83, 0.28, 0.1, -0.02, 1.11, -0.82, 0.6, 0.5528169964955679, -0.83, -0.42, 0.43, 0.24, 3.05, 0.65, 0.82, 0.43567351865003195, 0.18, -0.11, 1.01, -0.92, 0.5, 0.21, -0.93, -0.51, 0.14, 0.29, 1.13, -0.81, 0.62, 0.33, -0.82, -0.4, 1.0189583699631244, 0.65, -0.08, 0.26, 8.541102040816327, 0.15, 0.02, -0.51, 0.52, 0.30881017100762115, -0.63, 1.96, -2.23, -1.25, -0.65, 2.6014387755102044, 0.25, 1.95, -1.88, -1.88, 0.63, -0.77, 1.27, 1.56, -0.76, 0.58, -3.25, -0.44, -0.62, 2.21, -0.82, -1.91, -0.5, -0.79, -1.92, -1.51, 1.9, 1.1101587301587303, 1.44, 1.14, -0.01, 0.41, -0.32, -0.29, -1.42, -1.01, 0.83, 0.92, -0.03, -1.14, -0.72, 0.64, 0.53, 0.76, -0.66, 2.08, 0.66, 0.52, 1.06, 1.12, 0.42, 0.82, 0.31, 0.11, 0.5, 0.37, 0.7, 1.2, 0.87, -0.05], ['417', -4.34, -1.12, -0.09, 0.08, -0.96, -1.03, -1.825884742040171, -2.03, -1.95, -3.62, -1.57, -2.28, -0.12, -1.65, -0.99, -1.56, -2.68, -3.3, -3.85, -2.41, -3.78, -3.18, -2.4, -1.98, -2.32, -2.61, -2.08, -0.72, 1.48, -0.08, 0.6, 0.02, -1.12, -1.76, -2.31, -0.85, -2.24, -1.63, -0.84, -0.42, -1.27, -2.59, -1.37, 2.21, 0.65, 1.32, 0.75, -0.4, -1.05, -1.61, -0.13, -1.53, -0.92, -0.12, 0.3, -0.41, -0.86, -1.86, -2.369047619047619, -3.51, -1.53, -0.87, -1.44, -2.56, -3.087394933859938, -3.74, -2.29, -3.66, -3.06, -2.28, -1.87, -1.65, -2.0, 0.67, 0.1, -1.04, -1.68, -2.24, -0.77, -2.006918367346939, -1.56, -0.76, -0.34, -1.96, -3.42, 3.39, -2.66, -0.57, -1.71, -2.34, -2.89, -1.44, -2.82, -2.21, -1.43, -1.01, -4.05, -2.1, -1.14, -1.78, -2.33, -0.87, -2.26, -1.65, -0.86, -0.44, -0.35, -2.12, -1.78, -1.09, -1.01, -1.23, -0.97, -0.64, -1.21, 0.27, -1.13, -0.52, 0.28, 0.7685846838830657, -0.48, -0.27692325186963274, -0.57, 0.92, -0.480437641723356, 0.13, 0.94, 1.36, -1.08, -0.5, 0.19, -1.09, -12.24, -0.08, -0.07, 2.2, -2.2, -1.08, 0.2, -1.17, 2.53, 2.09, 1.09, -2.19, -0.41, -3.29, 3.26, 3.21, -1.06, 3.27, -2.19, -1.38, 0.68, -2.9, 6.6, 2.08, 2.8, -2.55, 0.24, 1.5, 0.08, 0.7, 1.51, 1.94, -3.29, -1.24, -1.4, -0.79, 0.01, 0.44, 0.16, 0.62, 1.43, 1.86, -1.94, -2.09, -0.46, 0.8, 1.23, -1.12, -1.12, -1.88, 3.91, -1.82, -3.97, -1.65, -2.0, -1.25, 0.43, -1.01, -1.02, -0.32, -0.06, -0.54, -1.67, -2.87, -2.86, -1.18], ['418', -0.13, 0.07, -0.2, -0.11, -0.96, -0.3315803763262405, -0.51, -0.66, -0.24, -1.3029115646258504, -2.16, -1.11, -1.75, -1.62, -0.14, -1.34, -1.59, -1.75, -3.69, 0.84, -1.84, -1.84, -1.88, -1.98, -0.78, -0.29, 0.42, 1.08, 0.42, 0.55, 2.06, 0.84, 0.58, 0.42, -1.56, 3.07, 0.32, 0.33, 0.29, 0.19, -0.75, -0.8850638007838266, -0.65, -0.65, -0.52, 0.98, -0.23, -0.49, -0.65, -2.61, 1.97, -0.74, -0.73, -0.78, -0.88, -0.21, -0.54, -0.7, 0.06, 0.0, 0.13, 1.640799319727891, 0.42, 0.16, 0.0, -1.97, 2.64, -0.09, -0.08, -0.13, -0.23, -0.25, -0.13, 1.5, 0.29, 0.03, -0.13, -2.1, 2.5, -0.23, -0.22, -0.26, -0.36, 0.13, 0.18, -0.28, -1.61, -1.2, -1.45, -1.61, -3.55, 1.173744771101914, -1.7, -1.69, -1.74, -1.84, -1.29, -0.3426334687834371, -0.26, -0.42, -2.38, 2.2, -0.4473734626473065, -0.51, -0.55, -0.65, -0.11, -0.39, 2.39, -0.34, -0.28, -0.3, -0.16, -0.16, -2.13, 2.47, -0.0742217465074606, -0.25, -0.29, -0.39, 0.08, 0.053076748130367266, -1.97, 2.64, -0.09, -0.08, -0.13, -0.23, 0.61, 0.78, -0.11, 0.05, -4.02, 0.04, 0.16, 0.86, -0.84, -0.42, -0.79, -0.66, 5.07, 0.69, 0.4, -0.03, -0.31, -1.07, 1.12, 1.11, -0.35, 1.26, -0.7, 1.12, -0.56, -0.29, -0.94, 0.24, 0.46, -5.12, 2.0, 4.7, 1.91, 1.92, 1.87, 1.77, -0.95, -2.57, -2.66, -2.65, -2.7, -2.79, 0.09, 0.01, -0.04, -0.14, -0.33, 0.0, 0.08, -0.05, -0.14, -0.35, -0.32, -0.64, -0.28, 1.85, 0.22, -0.28, -0.91, 0.13, -0.1, -0.36, -0.91, -0.06, -0.6, 0.2, 0.23, -1.4, -0.81, -0.26], ['419', -1.77, -0.36, -0.2, 0.07, -1.96, -1.04, -1.61, -2.46, -2.12, -2.82, 0.51, -1.44, -1.5060867348791511, -0.16, -0.83, -2.33, -1.32, -2.53, -2.35, -0.25, -3.07, -1.96, -1.79, -1.44, -2.18, -1.5106285854111081, -3.31, -1.94, -2.07, -0.66, -1.33, -2.82, -1.82, -3.03, -2.85, -0.75, -3.56, -2.45, -2.29, -1.94, -1.86, -2.72, -1.4, -0.13, 1.3, 0.62, -0.9, 0.12, -1.11, -0.93, 1.21, -1.65, -0.52, -0.36, 0.0, -0.76, -1.36, -2.88, -2.32, -1.27, 1.44, 0.7507993197278912, -0.77, 0.26, -0.8773949338599383, -0.8, 1.4639757335335069, -1.52, -0.39, -0.23, 0.13, -2.83, -2.67, -0.68, -2.18, -1.16, -2.38, -2.2, -0.1, -2.92, -1.8, -1.64, -1.29, -2.75, -3.11, 3.07, -2.0, -1.51, -0.49, -1.71, -1.53, 0.59, -2.26, -1.13, -0.97, -0.61, -2.24, -0.4226334687834371, 1.03, -0.21, -0.03, 2.13, -0.76, 0.38, 0.55, 0.91, -0.33, -0.42, 0.89, -1.15, -1.15, -1.15, -1.52, -1.0934006093113235, -1.05, 1.08, -1.78, -0.65, -0.48, -0.13, -0.76, -0.29, 0.19, 2.34, -0.55, 0.59, 0.76, 1.12, -1.45, -1.44, -0.2839628211219596, -1.34, -6.58, -0.46, -0.65, 2.65, -2.72, -1.35, 0.27, -4.3, 5.08, 2.21, 1.13, -0.91, -1.01, -3.45, 3.39, 3.45, -1.13, 4.01, -2.28, -1.06, 0.47, -4.48, 13.09, 3.02, 4.42, -5.15, -0.47, 2.15, -0.73, 0.41, 0.58, 0.93, -3.42, -2.57, -2.83, -1.71, -1.55, -1.2, 0.26, 1.15, 1.32, 1.68, -2.19, -2.5, -0.88, 0.17, 0.52, -1.12, -1.17, -2.31, 6.74, 0.09, -6.72, -1.55, -1.48, -1.04, 0.36, -0.4, -1.04, -1.03, -0.82, -1.36, -1.39, -1.87, -2.99, -1.27], ['420', 2.73, 0.42, 0.26, 0.01, 0.3429790809910596, 0.58, 1.214115257959829, 0.95, 1.02, 0.94, -0.02, 0.13, 0.12, 0.67, 0.41, 0.4, 0.2, 0.66, 2.6, 0.09, 0.99, 0.81, -0.23, 0.1, 0.35, 0.14, 0.9926583949931125, 0.2684685082657772, 0.14, 0.69, 0.43, 0.42, 0.23, 0.68, 2.62, 0.12, 1.01, 0.83, -0.21, 0.16384172319783916, 0.92, 1.69, 0.820204081632653, -0.01, 0.54, 0.28, 0.27, 0.08, 0.53, 2.47, -0.03, 0.86, 0.68, -0.36, -0.02, 0.41, 0.49, 0.91, 1.01, 0.82, 0.55, 0.29, 0.28, 0.08, 0.54, 2.48, -0.03, 0.87, 0.69, -0.35, -0.02, 1.06, 0.27, -0.26, -0.27, -0.46, -0.01, 1.92, -0.57, 0.32, 0.14, -0.9, -0.57, 1.33, 3.13, -3.2, 0.53, -0.01, -0.21, 0.25, 2.18, -0.32, 0.57, 0.4, -0.64, -0.31, 0.21, 0.54, -0.19, 0.26, 2.19, -0.3, 0.59, 0.41, -0.63, -0.3, 0.25, 0.55, 3.01, 0.64, 0.73, 0.62, 0.8118094764861292, 0.45, 2.39, -0.11, 0.78, 0.6, -0.43, -0.04141531611693433, 0.13, 0.28, 1.93, -0.56, 0.33, 0.15, -0.89, -0.56, 1.81, 1.77, 0.03, 0.81, 0.3, 0.28, 0.34, -1.45, 1.43, 0.7888101710076211, 0.78, 2.11, -1.71, -1.35, -0.65, 1.31, 0.06, 2.02, -2.05, -2.09, 0.65, -2.36, 1.28, 0.59, -0.34, 2.15, -3.68, -1.53, -2.28, 1.7, -1.6016360544217687, -2.44, -1.3727867132867133, -1.75, -2.76, -2.44, 1.91, 0.85, 0.89, 0.72, -0.33, 0.01, -0.05, -0.18, -1.21, -0.88, 1.02, 1.18, 0.13, -1.03, -0.7, 0.63, 0.72, 1.01, -3.19, 2.25, 3.11, 0.19, 0.81, 1.2586374482009708, 0.33, 0.94, 0.73, -0.02, -0.23, 0.31, 0.84, 0.14, 1.75, 0.25], ['421', 0.48, 0.05, -0.06877828437954125, 0.2, -0.07, -1.09, -2.72, -1.58, -2.28, -1.52, 1.34, 0.85, -0.98, 0.31, 0.03, -1.67, -0.35, -1.12, -2.77, -0.47, -2.16, -0.87, -0.15, -0.48, -1.06, -0.890628585411108, -2.82, -0.48, -2.29, -1.01, -1.29, -2.97, -1.66, -2.42, -4.05, -1.78, -3.45, -2.18, -1.47, -1.8, -1.13, -5.315063800783826, -2.34, -1.81, -0.53, -0.81, -2.5, -1.18, -1.95, -3.59, -1.3, -2.98, -1.71, -0.99, -1.32, -1.2, -1.11, -0.83, -1.79, -0.54, 1.3, 1.02, -0.7, 0.64, -0.14, -1.81, 0.52, -1.19, 0.11, 0.84, 0.5, -1.4, -1.82, -0.28, -1.98, -0.65, -1.43, -3.07, -0.78, -2.46, -1.18, -0.32690451810094656, -0.79, -3.36, -3.46, 3.38, -1.54, -1.7, -0.37, -1.15, -2.8, -0.49, -2.19, -0.9, -0.18, -0.51, 0.41, 0.16, 1.35, 0.56, -1.12, 1.23, -0.49, 0.81, 1.55, 1.21, -0.41, 0.19, 1.51, -0.88, -0.74, -0.97, -1.18, -0.78, -2.43, -0.12, -1.82, -0.53, 0.2, -0.14, -0.46, -0.4, -1.67, 0.66, -1.05, 0.25, 0.98, 0.64, -1.78, -1.28, 0.17, -0.83, 1.13, -0.09, 0.27, 1.98, -1.97, -1.0, 0.55, -1.58, 2.1, 1.64, 0.89, 0.3, -0.63, -2.62, 2.65, 2.58, -0.84, 2.94, -1.7, -2.54, 1.24, -3.49, 9.12, 2.33, 3.49, -1.9828690476190476, 1.3083639455782314, 2.37, 0.8272132867132869, 1.95, 2.7, 2.35, -2.53, -1.05, -1.7, -0.41, 0.32, -0.02, 0.66, 1.31, 2.06, 1.71, -2.197204648526077, -2.48, -0.65, 0.73, 0.39, -0.83, -0.88, -1.53, 5.1, -0.12, -5.23, -0.62, -0.15, -1.37, -0.34, -0.96, -0.86, -0.69, 0.21, -1.37, -1.04, -1.1, -0.46, -1.3], ['422', -0.06, 0.0, -0.008778284379541255, -0.05, 0.01, -0.04, 0.014115257959829165, 0.0, -0.01, 0.05, -0.03, 0.05, 0.02, -0.07, 0.08, 0.05, -0.04, 0.03, 0.0, 0.05, 0.11733548208735894, 0.07, 0.24, 0.01, 0.16, -0.04, 0.12265839499311246, 0.09, 0.06, -0.04, 0.16781997129509119, 0.09, -0.01, 0.06, 0.03, 0.09, 0.11, 0.1, 0.28, 0.08384172319783915, 0.0, 0.014936199216173434, 0.0, -0.03, -0.13, 0.03, 0.0, -0.1, -0.02, -0.05, 0.0, 0.04806546808644298, 0.02, 0.19, -0.04, 0.03, 0.07, 0.08, 0.06, 0.03, -0.1, 0.06, 0.03, -0.07, 0.0, -0.02, 0.03, 0.05, 0.05, 0.22, -0.01, -0.03, 0.13, 0.16, 0.13, 0.03, 0.1, 0.07, 0.13, 0.15, 0.14, 0.32, 0.13355964172512072, 0.0, -0.42, 0.34, 0.00669823838532016, -0.03, -0.13, -0.05, -0.08, -0.03, 0.0, -0.01, 0.16, -0.07, -0.18, 0.0, -0.1, -0.03, -0.05, 0.0, 0.02, 0.02, 0.19, -0.04, 0.11, 0.0, 0.07572371188304003, 0.01, -0.06, 0.13567351865003197, 0.1718094764861292, 0.07, 0.14693256743256752, 0.1, 0.12, 0.11, 0.29, 0.10858468388306568, 0.06, 0.02, -0.03, 0.03, 0.05, 0.04, 0.22, -0.02, 0.0, 0.04, 0.07, 0.11, 0.0, 0.02, 0.0, -0.1, 0.15, 0.14881017100762112, 0.0, 0.0, 0.07, 0.0, 0.0, 0.0, 0.11, 0.12, -0.11, -0.04, 0.02, -0.26, -0.01, 0.16, -0.11, 0.23, 0.01, -0.15, -0.31, -0.04, 0.05, 0.06, 0.08, 0.07, 0.25, 0.01, 0.04, 0.0, 0.02, 0.02, 0.19, -0.04, -0.02, -0.01, 0.17, -0.07, 0.04, 0.02, -0.02, 0.17, -0.06, 0.02, -0.01, 0.0, -0.09, 0.15019962695749933, 0.06, 0.06, -0.14, -0.19, -0.23, -0.08, -0.03, 0.0, 0.0, 0.04, 0.04, 0.02, 0.06, 0.03], ['423', -1.52, 2.0214285714285714, 0.07, 0.01, 0.44, -0.01, 1.82, 0.07, -0.17, -0.95, -0.18, -2.6, -1.78, -0.37, -1.26, -1.01, -1.34, -1.13, -3.4, -2.53, -1.15, -1.57, -1.28, -1.54, -0.25, 0.48, -0.78, -2.43, -1.61, -0.19, -1.08, -0.84, -1.16, -0.95, -3.23, -2.36, -0.98, -1.4, -1.1, -1.37, 0.08, -1.42, 1.69, 0.84, 2.29, 1.38, 1.63, 1.29, 1.51, -0.8183478664192949, 0.07119047619047619, 1.48, 1.05, 1.35, 1.08, -0.14, -0.08, -0.47, -0.53, 0.84, 1.44, 0.53, 0.78, 0.45, 0.67, -1.65, -0.76, 0.64, 0.21, 0.51, 0.24, -0.25, -0.59, -0.8753571428571428, -0.65, -0.97, -0.76, -3.04, -2.17, -0.79, -1.21, -0.91, -1.18, -0.8395238095238095, 1.54, -1.55, 0.31, 0.25, -0.06821428571428571, 0.13, -2.17, -1.29, 0.11, -0.32, 0.010976190476190473, -0.29, 0.74, 0.06, -0.33, -0.12, -2.41, -1.53, -0.0773734626473065, -0.56, -0.27, -0.54, 0.2, -0.05, 2.85, 0.43, 0.35, 0.58, 0.39, 0.21, -2.09, -1.21, 0.19, -0.17969498055271244, 0.06, -0.21, 1.1, 0.18, -2.3, -1.42, -0.03, -0.45, -0.15, -0.42, 0.58, 0.61, 0.11, 0.52, 2.09, 0.82, 0.83, -0.99, 1.05, 0.5, 4.1, 0.87, -3.2, -0.84, -0.42, -0.73, 0.67, 1.27, -1.19, -1.21, 0.41, -1.5, 0.86, -0.12, 0.1447652642842468, 1.18, -5.07, -0.86, -1.18, 3.2, 2.53, 0.9, 2.33, 1.89, 2.2, 1.92, 1.24, 1.62, 1.41, 0.98, 1.290857142857143, 1.0114285714285713, 0.2, -0.42, -0.13, -0.4, 0.010135138670853056, -0.7, 0.63, 0.3, 0.03, 0.42, 0.48, 0.07, -3.14, 2.1, 3.32, 0.17, -0.06, 0.33, -0.27, 0.28, 0.25, 0.61, 0.77, 0.83, 0.6, 0.3, 0.12, 0.2], ['424', 6.1, 1.26, 0.16, -0.08, 0.94, 0.87, 1.894115257959829, 2.08, 1.28, 4.11, 2.230608843537415, 3.47, 2.39, 2.54, 2.35, 1.91, 2.71, 3.77, 4.39, 3.32, 5.0, 2.58, 2.83, 2.96, 2.47, 1.759371414588892, 1.85, 1.22, 0.16, 0.31, 0.13, -0.31, 0.48, 1.51, 2.12, 1.08, 2.72, 0.35, 0.6, 0.72, 0.78, 2.44, 0.62, -1.04, -0.9, -1.08, -1.51, -0.73, 0.29, 0.89, -0.14, 1.48, -0.86, -0.62, -0.48495238095238097, 1.44, 1.09, 2.02, 1.17, 1.68, 0.15, -0.03, -0.47, 0.31, 1.35, 1.96, 0.92, 2.55, 0.18, 0.43, 0.56, 2.84, 1.53, -0.18, -0.62, 0.16, 1.2, 1.8, 0.76, 2.4, 0.03, 0.28, 0.4, 1.68, 3.58, -3.6, 1.72, -0.44, 0.35, 1.38, 1.99, 0.95, 2.613870161584447, 0.22, 0.9225170068027209, 0.59, 0.86, 2.16, 0.79, 1.83, 2.44, 1.39, 3.04, 0.66, 0.91, 1.03, 0.41, 2.1923568812140237, 1.06572371188304, 1.23, 1.11, 1.36, 1.36, 1.03, 1.64, 0.6, 2.23, -0.13, 0.12, 0.24, 1.46, 0.33, 0.6, -0.43, 1.19, -1.0242004503433073, -0.9, -0.78, 0.93, 1.04, -0.14, 1.26, 2.12, 0.21, 0.17, -2.56, 2.51, 1.27, 1.78, 0.85, -1.38, -2.46, -1.23, 3.44, 1.22, 3.64, -3.74, -3.7, 1.24, -3.77, 2.47, 1.37, -0.6652347357157532, 3.86, -10.36, -2.75, -4.05, 1.39, -0.27, -1.02, 0.59, -1.74, -1.49, -1.37, 3.53, 0.76, 1.62, -0.72, -0.48, -0.36, -0.85, -2.31, -2.07, -1.95, 1.37, 1.49, 1.5, 0.25, 0.37, 1.24, 1.26, 2.06, -5.55, 1.2001996269574993, 2.54, 1.82, 1.1, 1.25, 0.12, 1.17, 1.12, 1.67, 1.01, 1.23, 1.12, 0.98, 1.68, 0.85], ['425', 2.41, 0.29, 0.08, 0.14, 0.59, -0.18, -0.6858847420401708, -0.44, -0.02, 0.9, 1.6, 1.5293248299319728, 1.26, 1.22, 1.02, 1.03, 1.53, 1.0, -4.42, 1.63, 0.77, 0.45, 1.32, 1.475116627420199, 0.13, 0.11, -0.6573416050068874, -0.08, -0.34, -0.37, -0.57, -0.57, -0.07, -0.47274109585559154, -5.93, 0.02, -0.82, -1.13, -0.28, -0.27, 0.51, 0.4808975626058773, -0.61, -0.26, -0.29, -0.49, -0.49, 0.01, -0.51, -5.85, 0.11, -0.74, -1.05, -0.2, -0.19, -0.35, 0.27, -0.74, 0.42, -0.35, -0.03, -0.23, -0.23, 0.27, -0.25, -5.6, 0.37, -0.48, -0.79, 0.06, 0.07, -0.55, -0.32, -0.2, -0.2, 0.3, -0.22, -5.5669047619047625, 0.7191309523809524, -0.45, -0.76, 0.09, 0.1, -0.44, -0.67, 0.65, -0.12, 0.0, 0.5, -0.02, -5.38, 0.7937447711019141, -0.25, -0.57, 0.29, 0.3, 1.09, -0.12, 0.5, -0.02, -5.39, 0.6, -0.25, -0.57, 0.29, 0.3, -0.23, 0.029368203225346196, -1.46427628811696, -0.11840181931709852, -0.16482093036566006, -0.16, -0.62, -0.52, -5.86, 0.1, -0.75, -1.06, -0.21, -0.2, 0.29, -0.1, -5.37, 0.62, -0.23, -0.55, 0.31, 0.32, -0.11, -0.55, 0.31603717887804045, -0.39, 3.45, 0.1, 0.26, 0.48, -0.46, -0.24, 0.02, -0.95, 1.36, 0.33, 0.15, 1.17, 0.07, -0.27940313852813836, 0.5, 0.5, -0.11670919513614705, 0.65, -0.35, -1.04, 0.49, -1.86, 2.4, 1.16, 1.77, -1.41, 5.57, 6.33, 5.43, 5.09, 6.0, 6.01, -0.46, -0.71, -0.84, -1.16, -0.31, -0.3, 0.13, -0.32, 0.54, 0.55, -0.06, 0.0, 0.45, 0.86, 0.87, -0.12, -0.2, -0.52, 2.22, -1.78, -2.14, -0.28, -0.07, -0.41, 0.01, -0.46, 0.0, 0.34, 0.32, -0.59, -0.42, 0.18, 0.23, -0.07], ['426', -52.74, 0.11, 0.04, 0.12, 0.18, -0.4, -0.5958847420401708, -1.2, -0.49, -1.9, -1.13, -1.9, -1.35, -0.57, -0.52, -1.16, -1.36, -1.21, -2.58, -1.57, -2.03, -0.6240578231292517, 0.67, -1.72, -0.08140633899247347, -1.58, -0.77, -0.77, -0.23, 0.57, 0.62, -0.03, -0.23, -0.08, -1.46, -0.44, -0.91, 0.4, 1.82, -0.59, -0.8525315746467891, -2.5950638007838265, 0.0, 0.55, 1.35, 1.4, 0.75, 0.55, 0.7, -0.7, 0.34, -0.14, 1.18, 2.6557142857142857, 0.18, -0.09993715369432345, -1.19, -1.18, -0.06, -0.55, 0.8, 0.85, 0.2, 0.0, 0.15, -1.24, -0.22, -0.69, 0.63, 2.05, -0.37, -1.1, -1.34, 0.05, -0.5885714285714285, -0.8, -0.65, -2.02, -1.01, -1.47, -0.17, 1.25, -1.16, -0.95, -6.34, 6.55, -1.38, -0.64, -0.8282142857142857, -0.69, -2.07, -1.05, -1.52, -0.22, 1.2, -1.2, -1.97, -0.6726334687834371, -0.2, -0.05, -1.44, -0.41, -0.88, 0.43, 1.85, -0.56, -0.66, -0.73, -1.39427628811696, -0.5, -0.85, -0.13, -0.54, 0.15, -1.24, -0.21, -0.68, 0.63, 2.6885714285714286, -0.36, -1.14, -0.69, -1.38, -0.36, -0.83, 0.48, 1.91, -0.51, -3.1, -2.52, 0.11, -0.28, -3.59, -0.61, -0.22, -0.8, 0.8, 0.41, -0.95, -0.9, 0.64, 0.95, 0.49, -2.74, -0.16, -1.45, 1.45, 1.5, -0.47, -1.06, -0.95, -2.39, 1.2, -1.69, 2.83, 1.06, 1.53, -0.77, 0.7, 1.04, 0.56, 1.89, 3.34, 0.89, -1.45, -0.33, -0.47, 0.84, 2.27, -0.15, 0.14, 1.32, 2.76, 0.32, -0.42, -0.76, -1.17, 1.42, -0.99, -0.56, -0.43, -1.25, 1.35, -0.95, -1.21, -1.08, -0.59, -2.55, -2.37, -1.22, 0.55, -0.13, -0.01, -0.09, -0.18, -1.04, -0.5, -0.93], ['427', 0.57, 0.0, 0.4712217156204588, 0.07, 0.19, -0.21158037632624052, 0.22411525795982914, 0.47, 0.47, -1.01, -1.73, -1.59, -1.23, -2.09, -1.21, -2.32, -1.34, -1.13, 0.52, -0.99, -0.67, -1.5, -0.84, -0.91, 0.33, 1.549371414588892, 0.73, 0.14, 0.51, -0.37, 0.53, -0.6, 0.39, 0.62, 2.29, 0.75, 1.08, 0.23, 0.9, 0.84, 0.45, -0.14506380078382658, 0.59, 0.36, -0.3421246055531769, 0.38, -0.74, 0.25, 0.47, 2.14, 0.6, 0.94, 0.09, 0.76, 0.69, 0.83, -0.73, -0.68, 0.27, 0.22, -0.7668952774644393, 0.02, -1.1, -0.11, 0.11, 1.77, 0.24, 0.57, -0.27, 0.39, 0.33, 0.29, 1.11, 0.9, -0.23, 0.77, 0.99, 2.67, 1.12, 1.46, 0.61, 1.28, 1.21, 0.5, -0.64, 0.55, 0.2, -1.12, -0.13, 0.09, 1.75, 0.22, 0.55, -0.29, 0.37, 0.3, 0.37, 1.34, 1.0, 1.22, 2.9, 1.35, 1.69, 0.84, 1.51, 1.44, 0.12, 1.28, -0.17, -0.09, -0.11, 0.07567351865003197, 0.34, 0.22, 1.88, 0.35, 0.68, -0.16, 0.51, 0.44, 0.37, 0.12, 1.66, 0.13, 0.46, -0.38, 0.29, 0.22, -0.33, -0.32, 0.38, 0.11, 1.31, 0.05354725829725827, 0.07, -0.16, 0.2, 0.09, -0.08, 1.3461635321120495, -0.01, 0.06, 0.08, 0.37, -0.27, -0.19, 0.21, 0.29, -0.1, -0.35, -0.2, -0.5, 0.26, 0.99, 1.94, -0.66, -1.07, -0.022869047619047622, -1.52, -1.5, -1.18, -2.01, -1.35, -1.42, -0.28, -0.02, 0.33, -0.51, 0.15, 0.09, -0.35, -0.84, -0.18, -0.24, 0.49, 0.36, 0.5872746849074344, 0.67, 0.6722487553150163, -0.05, -0.06, 0.37, 1.06, -0.35, -1.05, 0.26726381052443327, 0.36, -0.17, -0.07, -0.27, 0.04, -0.55, -0.4, 0.06, -0.1, 1.13, 0.6, -0.06], ['428', 3.12, 0.36, -0.04, -0.21, 0.64, 0.55, 1.6, 0.75, 1.24, 0.47, -0.96, -1.05, 0.1, -0.52, 1.14, -0.31, -0.41, 0.27, 0.68, -0.7763367346938775, 0.87, 0.13, -0.23, -0.34, 1.41, 1.36, 1.45, -0.08, 1.08, 0.45, 2.13, 0.66, 0.56, 1.24, 1.66, 0.17, 1.85, 1.1, 0.74, 0.63, -0.06, 2.58, 1.53, 1.16, 0.54, 2.21, 0.74, 0.64, 1.33, 1.75, 0.25, 1.968065468086443, 1.19, 0.82, 0.71, 0.27, 0.45, 0.71, 0.41, 0.37, -0.62, 1.04, -0.42, -0.51, 0.16, 0.58, -0.9, 0.76, 0.02, -0.33, -0.44, 0.94, 0.99, 1.67, 0.2, 0.1, 0.79, 1.2, -0.29, 1.39, 0.65, 0.29, 0.18, 2.05, 1.65, -1.63, -0.6233017616146799, -1.44, -1.54, -0.86, -0.45, -1.92, -0.27, -1.0, -1.36, -1.47, 3.15, 0.78, -0.1, 0.58, 1.0, -0.49, 1.18, 0.44, 0.08, -0.03, 0.21, 0.77, 2.890104651162791, 0.65, 0.70517906963434, 0.685673518650032, 0.88, 0.68, 1.1, -0.39, 1.29, 0.54, 0.18, 0.07, 0.29, 0.2, 0.41, -1.06, 0.6, -0.14, -0.5, -0.61, 0.58, 0.58, -0.4, 0.84, 9.54, 0.12, -0.09, -2.16, 2.18, 1.09, -0.52, 0.58, -2.54, -1.36, -0.66, 1.59, -0.04, 2.0905968614718615, -1.86, -1.97, 0.683290804863853, -3.21, 1.3, 2.02, -1.01, 2.62, -1.11, -1.79, -2.62, 2.54, -0.21, -1.47, 0.19, -0.55, -0.91, -1.02, 1.96, 1.28, 1.68, 0.93, 0.57, 0.46, -0.4, -0.74, -1.09, -1.2, 1.16, 1.16, 0.34, -0.36, -0.47, 0.62, 0.64, 0.8, -0.51, 2.82, 0.31, 1.447263810524433, 0.92, 0.7, -0.11, 0.9, 1.19, -0.03, -0.11, -0.3, 0.81, 2.29, 1.47, 0.6830167737073972], ['429', 1.04, 0.31, -0.48877828437954124, -0.1, 0.06, 0.64, 0.014115257959829165, 0.7, 0.64, 1.39, 0.58, 1.62, 0.99, 1.07, 1.9, 1.61, 0.32, 0.81, 1.61, 2.23, 1.53, -0.22, 0.75, 0.81, 0.27, -0.12, 0.81, 1.1484685082657773, 0.41, 0.49, 1.31, 1.02, -0.26, 0.22, 1.03, 1.64, 0.95, -0.8, 0.17, 0.23, -0.5025315746467891, 0.9649361992161734, -0.22, -0.62, -0.54, 0.28, -0.01, -1.28, -0.8, 0.0, 0.6, -0.08, -1.81, -0.85, -0.79, 1.3, 0.0, -0.68, 0.67, 0.4, 0.08, 0.9, 0.62, -0.66, -0.18, 0.62, 1.23, 0.54, -1.2, -0.24, -0.18, 0.37, 0.32, 0.82, 0.53, -0.74, -0.26, 0.54, 1.15, 0.46, -1.28, -0.32, -0.26, 0.97, 1.88, -1.88, -0.5, -0.28, -1.55, -1.07, -0.28, 0.33, -0.36, -2.08, -1.12, -1.07, -0.97, -0.21, -1.27, -0.79, 0.0, 0.61, -0.08, -1.8, -0.85, -0.79, 0.54, -0.19, 2.4957237118830404, 0.55, 0.67, 0.46, 1.07, 0.49, 1.29, 1.9, 1.21, -0.54, 0.43, 0.49, 1.49, 0.58, 0.8, 1.41, 0.72, -1.02, -0.05, 0.0, 1.23, 1.88, -0.04, 1.03, -3.26, 0.22, -0.8, 0.08, -0.1, -0.04, 0.62, 3.57, 1.54, -1.1, -0.57, 0.57, 0.6, 1.76, -1.67, -1.55, 0.54, 0.09, 1.09, 1.31, -0.73, 3.23, -7.53, -2.21, -3.24, -1.45, -0.22, 0.9371787775716347, -0.08, -1.8, -0.85, -0.79, 1.66, -0.82, -0.68, -2.4, -1.45, -1.39, -0.14, -1.7271150714365, -0.77, -0.71, 0.59, 0.87, 1.62, 0.97, 1.03, 0.57, 0.51, 0.74, -3.73, 2.02, 4.16, 0.65, -0.27, 0.64, 0.13278685149693165, 0.86, 0.0, 1.05, 1.23, 1.11, 0.58, -0.09, -0.35, 1.18], ['430', 1.24, -0.31, -0.1, -0.13, 0.62, 0.02, 0.45, 0.55, 0.0, -0.87, -0.2, -0.9, -0.75, -0.42, -1.01, -0.75, -1.27, -0.92, 2.02, -2.09, -1.05, -0.9, -1.35, -0.66, 0.57, 0.29, -0.67, -0.69, -0.55, -0.22, -0.81, -0.55, -1.07, -0.72, 2.22, -1.89, -0.85, -0.7, -1.15, -0.45, 0.16, 0.18493619921617344, 0.02, 0.15, 0.48, -0.11, 0.15, -0.38, -0.03, 2.94, -1.21, -0.16, -0.01, -0.46, 0.24, 0.2, 0.31, 1.77, -0.23, -0.12, 0.33, -0.26, 0.0, -0.53, -0.17, 2.79, -1.35, -0.3, -0.16, -0.61, 0.09, 0.49, -0.45, -0.16977210884353744, -0.33, -0.85, -0.5, 2.45, -1.68, -0.63, -0.48, -0.93, -0.23, -0.03, 1.19, -1.15, 0.14, 0.26, -0.27, 0.09, 3.06, -1.09, -0.04, 0.11, -0.35, 0.36, -0.91, -0.12, -0.53, -0.17, 2.79, -1.35, -0.24737346264730647, -0.16, -0.61, 0.09, -0.16, -0.06, -1.12, 0.38, 0.31, 0.44, 0.4, 0.35, 3.33, -0.83, 0.39577825349253937, 0.37, -0.004012136584447365, 0.62, 0.05, 0.05, 2.97, -1.18, -0.13, 0.02, -0.43, 0.27, 0.37, 0.48, -0.34, 0.4, -2.56, 0.21806954949812107, 0.0, -1.4, 1.46, 0.73, 0.31406627346681526, 0.89, -2.49, -0.78, -0.37, 0.62, 0.07, 1.1, -1.1, -1.11, 0.37, -2.23, 0.76, 0.68, -0.35, 1.14, -0.68, -0.77, -1.17, 2.34, -2.83, -3.7028212224283656, -3.01, -2.86, -3.3, -2.62, 1.1, 1.25, 1.06, 1.21, 0.76, 1.47, 0.18, 0.15, -0.3, 0.4, 0.09, 0.11, 0.03, -0.45, 0.25, 0.35, 0.41, 0.58, -0.22, -0.66, 0.36, 0.14, 0.46, 0.48, 0.7, 0.5, 0.74, 0.22, -0.33, 0.45, -0.22, 0.81, 0.83, -0.24], ['431', 0.09, 0.53, 0.13122171562045873, 0.0, 0.36, 0.34, 1.0841152579598292, 0.74, 0.7, 1.28, 0.52, 0.9, 1.03, 0.15, 1.36, 0.97, 0.82, 1.2377619047619046, 0.31, 0.51, 1.23, 0.97, 0.47, 0.6, 1.6, 0.64, 0.76, 0.38, 0.51, -0.36, 0.84, 0.45, 0.3, 0.68, -0.21, -0.01, 0.71, 0.45, -0.04, 0.08, -0.65, 1.56, 0.37, 0.12, -0.74, 0.46, 0.07, -0.08, 0.3, -0.59, -0.39, 0.33, 0.07, -0.43, -0.3, 0.83, 0.72, 0.63, 0.53, 0.25, -0.87, 0.34, -0.05, -0.2, 0.18, -0.71, -0.51, 0.21, -0.05, -0.55, -0.42, 0.19, 1.13, 1.2246428571428571, 0.82, 0.67, 1.05, 0.16, 0.36, 1.08, 0.82, 0.32, 0.45, 1.1, 2.33, -2.33, -0.08, -0.39, -0.54, -0.16, -1.04, -0.84, -0.13, -0.39, -0.88, -0.76, 0.4226190476190476, 0.3, -0.15, 0.23, -0.66, -0.46, 0.26, 0.0, -0.5, -0.37, -0.07, 0.3024455782312925, -0.73427628811696, 0.46, 0.7, 0.23, 0.46, 0.38, -0.5, -0.31, 0.41, 0.15, -0.34, -0.16141531611693433, 0.34, 0.08, -0.88, -0.69, 0.03, -0.23, -0.72, -0.6, 1.06, 1.2, -0.15, 0.33, 1.26, 0.2, 0.14, 0.39, -0.46, -0.2, 1.14, 2.36, -1.48, -0.93, -0.49, 0.05, 0.79, 1.38, -1.4, -1.41, 0.46, 0.48, 0.89, 0.62, -0.29, 1.4, -4.61, -0.9, -1.45, 1.57, 0.97, 0.2, 0.92, 0.66, 0.16, 0.29, 1.29, 0.77, 0.72, 0.46, -0.04, 0.12571428571428572, 0.05, -0.26, -0.75, -0.63, 0.66, 0.77, 0.31, -0.49, -0.37, 0.46, 0.47, 0.66, -3.21, -0.09, 3.35, 0.03, 1.05, 0.8, 0.12, 0.43, -0.54, 0.83, 1.2, 0.76, 0.68, 0.26, 0.57, 0.63], ['432', 2.96, -0.03, 0.05122171562045875, 0.19, -0.69, -0.08, -0.12588474204017086, -0.26, -0.55, -0.66, 0.41, -0.66, -0.18, -0.53, 0.04, -1.21, -0.09, -0.63, 0.4, 0.21, -0.86, 0.35, 0.02, -0.07, -0.45, -0.41, -1.0373416050068875, -1.07, -0.59, -0.94, -0.37, -1.61, -0.5, -1.04, -0.01, -0.2, -1.27, -0.06, -0.39, -0.48, 0.17548536582465155, -3.2, 0.0, 0.48, 0.12, 0.7, -0.55, 0.57, 0.02, 1.06, 0.87, -0.18193453191355702, 1.02, 0.69, 0.59, -0.27, 0.11, 0.07, -0.22, -0.47, -0.35, 0.23, -1.03, 0.1, -0.45, 0.59, 0.4, -0.5165788457574171, 0.54, 0.21, 0.12, -0.12, -0.12, 0.58, -0.68, 0.45, -0.1, 0.94, 0.75, -0.33, 0.89, 0.56, 0.47, -1.5, -1.75, 1.78, -0.7, -1.25, -0.13, -0.67, 0.36, 0.17, -0.9, 0.31, -0.02, -0.11, -0.15, 0.637366531216563, 1.13, 0.58, 1.63, 1.44, 0.4126265373526935, 1.58, 1.25, 1.15, 0.05, 0.58, -1.43427628811696, -0.3, -0.43, -0.2, -0.57, -0.55, 0.49, 0.3, -0.78, 0.44, 0.11, 0.02, -0.95, -0.02, 1.04, 0.85, -0.23, 0.99, 0.66, 0.57, -0.33, 0.2, 0.2, -0.706813216376432, -0.39, 0.08, 0.24, 0.19, -0.06827987418743707, -0.05118982899237888, -0.32, -0.46, 1.74, 0.53, 0.24, 1.49, 0.11, -0.68, 0.85, 0.81, -0.29, 0.23, -0.57, -0.8, 0.38, -1.8, -0.97, 1.16, 1.86, -1.66, -1.05, -0.19, -1.26, -0.05, -0.37, -0.47, -0.85, -0.7356457669314812, -1.07, 0.14, -0.19, -0.28, 0.21, 1.22, 0.9, 0.8, -0.55, -0.81, -1.0, -0.32, -0.42, -0.3, -0.34, -0.23742395037612163, -0.83, -1.54, 0.7, -0.87, -1.41, -0.68, -0.09, -0.29, -0.07, 0.54, -0.41, 0.43, -0.59, -1.65, -2.86, -1.2], ['433', -2.32, -1.34, 0.0, -0.24, 0.37, -0.44, 0.7141152579598291, 0.0, 0.28, 1.3470884353741497, 1.22, 0.691934498041641, 0.58, 0.66, 1.86, 1.43, 1.74, 0.74, -2.89, 0.26, 1.21, 1.95, 2.15, 1.24, 0.44, -1.17, -0.32, -0.72, -0.6091666666666666, -0.55, 0.63, 0.2, 0.51, -0.48, -4.06, -0.95, -0.01, 0.72, 0.92, 0.02, -0.64, 2.17, 0.4, 0.09, 0.17, 1.36, 0.93, 1.24, 0.24, -3.36, -0.22880952380952382, 0.71, 1.45, 1.65, 0.74, -0.44, 0.22, -1.16, -0.13, 0.32, 0.08, 1.3848467679404526, 0.84, 1.15, 0.16, -3.45, -0.32, 0.62, 1.36, 1.56, 0.65, -0.49, 0.24, 1.19, 0.76, 1.07, 0.08, -3.52, -0.4, 0.54, 1.28, 1.48, 0.57, 0.83, -3.23, 3.29, -0.95, -0.43, -0.12, -1.1, -4.66, -1.57, -0.64, 0.09, 0.28, -0.61, -0.47, -0.52, 0.31, -0.68, -4.25, -1.15, -0.22, 0.52, 0.8511089783232642, -0.19, 0.12097959183673469, -0.57, -4.09, -0.53, -0.69, -0.59, -0.83, -0.98, -4.55, -1.45, -0.52, 0.21, 0.47598786341555266, -0.49, -1.02, 0.16, -3.6, -0.47, 0.47, 1.21, 1.4, 0.5, -1.8610416300368755, -1.7, -0.71, -1.26, -1.58, -0.15, -0.07, 0.19, -0.23, -0.17, -0.58, 1.08, -1.21, 0.95, 0.54, -1.16, -0.11, -1.94, 1.96, 1.59, -0.52, 0.26, -1.03, 1.5, -0.84, -2.48, -0.19, 1.57, 2.56, 1.29, 3.9, 3.24, 4.22, 4.98, 5.18, 4.25, -1.6, 0.64, 0.94, 1.69, 2.2994625850340134, 0.9814285714285714, -0.3, 0.74, 0.93, 0.03, 0.26, 0.31, -1.03, 0.19, -0.6277512446849837, -0.61, -0.7, -0.09, -0.93, -2.92, 0.96, -0.85, -0.85, -1.22, -0.89, -1.48, -0.11, -0.12, 0.16, -0.11, -0.34, -1.64, -1.85, -0.88], ['434', -2.95, 0.59, 0.011221715620458745, 0.0, -0.61, 1.03, -0.07, 0.72, 0.77, 1.26, 0.27, 1.56, 0.55, 1.14, 0.26, 2.4, -0.03, 1.2, 0.99, 1.1, 1.44, 0.57, 0.04, -0.18, 0.68, 0.72, 0.99, 1.28, 0.29, 1.01318993704708, -0.01, 2.13, -0.3, 0.93, 0.72, 0.83, 1.17, 0.3, -0.22, -0.45, 1.94, 1.3, -0.3, -0.99, -0.4, -1.28, 0.83, -1.56, -0.35, -0.56, -0.44, -0.12, -0.97, -1.49, -1.71, 1.09, 1.1, 0.67, 1.03, 0.7, 0.59, -0.3, 1.84, -0.58, 0.64, 0.43, 0.55, 0.88, 0.01, -0.51, -0.73, 1.08, 0.11, -0.88, 1.24, -1.16, 0.05, -0.15, -0.032285714285714286, 0.29, -0.57, -1.09, -1.31, 1.4, 3.45, -3.25, 1.0366982383853203, 2.14, -0.29, 0.94, 0.73, 0.85, 1.18, 0.31, -0.21, -0.44, -1.93, -1.12, -2.38, -1.18, -1.38, -1.27, -0.94, -1.79, -2.3, -2.53, 0.24, -1.13, 1.85, 1.07, 1.15, 1.08, 1.29, 1.23, 1.02, 1.14, 1.47, 0.6, 0.08, -0.15, 0.78, 0.06, -0.21, -0.09, 0.24, -0.62, -1.14, -1.37, 1.02, 1.169561224489796, 0.07, 1.43, -5.57, 0.08, 0.02, -2.14, 2.14, 1.1088101710076212, 0.75, 0.18, -0.27, -2.12, -1.04, -1.48, 0.8, 3.19, -3.23, -3.19, 1.06, -3.24, 2.12, -0.21, 0.12, 3.71, -9.67, -2.43, -3.71, 0.31, 0.26, 0.11, 0.44, -0.42, -0.94, -1.16, 3.25, 0.15, 0.33, -0.53, -1.05, -1.27, -0.18, -0.86, -1.37, -1.6, 0.85, 1.05, 0.68, -0.52, -0.6777512446849837, 1.07, 1.1, 0.62, -5.17, 1.95, 5.25, 1.69, 1.31, 1.21, -0.23, 1.66, 0.71, 0.5, 0.87, 1.06, 1.44, 0.98, 1.97, 1.57], ['435', -1.93, -0.55, 0.25122171562045875, -0.04, -0.55, -0.16, -0.69, -0.91, -0.78, -1.34, -0.88, -0.92, -0.82, -0.41, -0.05, -0.19143990929705207, -1.23, -1.14, -2.46, -0.62, -1.67, -1.6, -0.72, -1.23, -0.31, -0.03, -0.47, -0.04, 0.06, 0.47, 0.83, 0.6850357142857143, -0.36, -0.27, -1.59, 0.26, -0.8, -0.73, 0.16, -0.35, -1.16, -2.11, -0.43, 0.1911974674961171, 0.6878753944468231, 0.88, 0.42, -0.31, -0.22, -1.55, 0.31, -0.76, -0.68, 0.21, -0.31, -0.28, -0.59, -0.47, -0.79, -0.53, 0.41, 0.77, 0.31, -0.42, -0.33, -1.66, 0.20023809523809524, -0.86, -0.79, 0.10273474541331684, -0.41, -0.83, -0.94, 0.36, -0.1, -0.82, -0.74, -2.06, -0.21, -1.27, -1.19, -0.31, -0.82, -1.43, -1.51, 1.4793333333333334, -1.29, -0.45, -1.18, -1.09, -2.41, -0.56, -1.62, -1.55, -0.66, -1.1159922724755493, 2.84, -0.84, -0.73, -0.64, -1.96, -0.11, -1.17, -1.1, -0.21, -0.72, -0.21, -0.96, 1.09, -0.15, -0.24, -0.04, -0.11, 0.09, -1.24, 0.62, -0.45, -0.37, 0.52, 0.01, 0.22, -0.2, -1.33, 0.53, -0.53, -0.33420045034330736, 0.43, -0.08, -0.96, -1.11, -0.23, -0.11, 8.07, -0.14, -0.21, 0.0, 0.01, -0.02, 0.43, -1.57, 1.53, 0.37, 0.6182806122448982, -0.89, 0.04, -0.49, 0.49, 0.51, -0.15, 0.0, -0.29, 0.17, -0.14, -0.43, 2.992107142857143, 0.28, 0.45, -1.44, 1.14, 1.89, 0.81, 0.88, 1.78, 1.26, -0.51, -0.73, -1.06, -0.99, -0.1, -0.61, 0.33, 0.07, 0.97, 0.45, -0.85, -1.04, 0.26, 0.89, 0.38, -0.13, -0.12, -1.02, 1.11, 0.61, -1.14, -0.04, -0.11, -0.63, -0.51, -0.4, 0.35, -0.06, 0.39, -0.46, -0.12, 1.41, 0.32, 0.65], ['436', -0.64, -0.29, 0.03, 0.03, 0.48, 0.35, 0.0, 0.4, 0.79, 1.49, 0.5, 1.25, 1.06, 2.17, 0.48, 1.2, 0.88, 1.43, -1.33, 0.98, 1.9, 0.87, 1.19, 1.44, -0.33, 0.85, 1.0226583949931125, 0.75, 0.56, 1.66, -0.01, 0.7, 0.38, 1.0472589041444085, -1.82, 0.48, 1.4, 0.37, 0.69, 0.9738417231978392, 0.05, 1.5549361992161734, 0.24, -0.19, 0.9, -0.76, 0.04052947845804987, -0.37, 0.18, -2.55, -0.27, 0.64, -0.37, -0.06, 0.18, -0.27, 0.37, -0.04, 1.88, 0.43, 1.09, -0.57, 0.14, -0.18, 0.37, -2.37, -0.08, 0.84, -0.18, 0.13, 0.37, -0.02, -0.66, -1.65, -0.94, -1.26, -0.72, -3.42, -1.16, -0.26, -1.27, -0.8169045181009466, -0.71, 1.09, 1.04, -1.13, 1.0, 0.72, 0.39, 0.94, -1.81, 0.49, 1.41, 0.39, 0.7, 0.95, 1.57, 0.29, -0.32, 0.23, -2.51, -0.23, 0.69, -0.3036053391053391, -0.01, 0.23, 0.06, 0.32, 1.4, 0.31, 0.37, 0.28, 0.61, 0.55, -2.19, 0.1, 1.02, 0.0, 0.31, 0.55, 0.56, 0.06, -2.476314419707277, -0.45, 0.46, -0.55, -0.24, 0.0, 0.19, 0.53, 0.08, 0.49, 4.59, 0.18, 0.2, -0.41, 0.4, 0.22, 0.45, 0.56, -1.12, -0.62, -0.29, -0.32, 0.17, 0.9, -0.99, -0.95, 0.32, -0.59, 0.63, -0.09, 0.06, 1.8, -0.75, -1.29, -1.89, 1.07, 2.86, 2.34, 3.28, 2.23, 2.56, 2.8, 0.93, 0.51, 0.92, -0.1, 0.21, 0.46, -0.4, -1.01, -0.7, -0.46, 0.93, 1.22, 0.62, 0.31, 0.56, 0.4220800343140569, 0.35, 0.44, -0.68, 0.88, 0.66, 0.43, 1.04, 0.3, 0.24, 0.21, 0.51, 0.21, 0.12, -0.16, 0.06, 0.27, 2.23, 0.55], ['437', 1.18, -0.18, 0.08, 0.12, -0.56, -0.17, -0.14, -0.9, -0.83, -1.03, 0.03, -0.84, -0.4, -0.17, 0.71, -1.88, -0.68, -0.96, -2.64, -1.09, -1.6, -0.52, -0.16, -0.39, -1.08, -0.63, -1.0273416050068875, -0.8694545454545455, -0.43, -0.2, 0.68, -1.9, -0.71, -0.98, -2.67, -1.12, -1.63, -0.55, -0.19, -0.41, -1.38, -1.45, -0.19, 0.44, 0.67, 1.56, -1.05, 0.16, -0.12, -1.82, -0.25, -0.77, 0.32, 0.68, 0.46, -0.56, -0.8, -0.97, -0.38, -0.63, 0.23, 1.12, -1.48, -0.28, -0.56, -2.25, -0.69, -1.21, -0.12, 0.24, 0.01, -0.54, -0.86, 0.88, -1.71, -0.51, -0.79, -2.47, -0.6008690476190477, -1.43, -0.35, 0.01, -0.22, -1.17, -2.2, 2.22, -1.73, -2.57, -1.39, -1.66, -3.33, -1.79, -2.3, -1.23, -0.87, -1.09, 0.34, 0.86, 1.22, 0.94, -0.78, 0.8, 0.28, 1.38, 1.8911089783232642, 1.52, -0.03, 0.84, 0.25, -0.41, -0.45, -0.31, -0.35, -0.28, -1.97, -0.41, -0.92, 0.16, 0.52, 0.3, -0.38, -0.07, -1.7, -0.13, -0.65, 0.44, 0.8, 0.58, -0.85, -0.88, 0.23, -0.18, 1.3, -0.02, 0.03, 0.27, -0.31, -0.16, 0.13, -2.6, -0.15, 0.83, 0.36, 0.58, -0.21692021013122098, -1.22, 1.12, 1.18, -0.42, 0.38, -0.81, -1.11, 0.54, -1.03, 5.06, 0.76, 1.08, 0.05, 1.65, 1.59, 1.07, 2.18, 2.546751700680272, 2.31, -1.24, 0.06, -0.52, 0.57, 0.94, 0.71, 0.58, 1.1, 1.46, 1.23, -0.78, -0.99, -0.4227253150925656, 0.36, 0.14, -0.4, -0.4, -0.8174239503761216, 2.83, 0.3403332627840632, -2.84, -0.72, -0.53, -0.791362551799029, -0.22, -0.34, 0.07, -0.23, -0.31, -0.4, -0.65, 0.02, 0.03, -0.32], ['438', -3.11, 1.0, -0.12, 0.24, 0.25, -0.06158037632624053, 1.87, 0.32, 0.53, 0.99, 0.79, 0.0, 1.33, -0.65, 0.92, 1.32, 1.35, 1.07, 2.97, -0.9, 1.06, 0.76, 1.05, 1.15, -0.04, 0.32, 0.2, -0.79, 0.54, -1.28681006295292, 0.13, 0.53, 0.56, 0.28, 2.16, -1.68, 0.27, -0.03, 0.26, 0.36, 0.0, 0.99, 1.0, 1.34, -0.65, 0.93, 1.33, 1.36, 1.07, 2.97, -0.9, 1.07, 0.77, 1.06, 1.15, 0.07, -0.22, -0.67, 0.33, -0.34, -1.96, -0.41, -0.01, 0.02, -0.26, 1.61, -2.21, -0.27, -0.56, -0.28, -0.18, 0.48, 1.66, 1.59, 1.99, 2.02, 1.73, 3.64, 0.0691309523809524, 1.73, 1.42, 1.72, 1.81, 0.68, -0.07, 0.0, 0.0708709226619941, 0.4, 0.43, 0.14, 2.02, -1.81, 0.14, -0.16, 0.13, 0.27400772752445063, -0.76, -0.33, 0.03, -0.25, 1.62, -2.2, -0.26, -0.55, -0.27, -0.17, 0.0, -0.34, -0.37, -0.89, -0.92, -0.82, -0.36, -0.28, 1.59, -2.23, -0.29, -0.58, -0.3, -0.2, -1.14, -0.01692325186963274, 1.88, -1.95, 0.0, -0.1742004503433073, -0.01, 0.08, 0.04, 0.42, 0.4060371788780404, 0.2, -2.32, 0.15, -0.14, 0.31, -0.39, -0.18, -2.08, -0.33, -3.65, 0.54, 0.25, -1.53, -0.28, -0.75, 0.74, 0.77, -0.24, 0.46, -0.48, -0.96, 0.48, 1.48, 5.66, -1.09, -1.46, 3.73, -1.92, -3.76, -1.85, -2.14, -1.853248299319728, -1.76, -0.74, 1.91, 1.98, 1.68, 1.97, 2.07, -0.07, -0.3, -0.01, 0.09, 0.58, 0.45845354645354663, 0.23, 0.29, 0.38, -0.28, -0.10560369872470916, 0.33, 3.39, 0.3, -3.4, -0.1027361894755667, -0.08, -0.06, 0.1, -0.06, -0.07, -0.67, -0.46, -0.63, -0.074042472976186, -0.4, -0.14, 0.36], ['439', 4.62, 0.13, 0.13, -0.2, 0.03, 0.43, 1.0841152579598292, -0.35, 1.05, -0.4, -1.5196815287886714, -2.03, -0.48, -0.37, -0.38, -1.78, -1.7028571428571428, -0.93, -2.54, -2.08, -0.01, -0.37, -1.16, -1.3378253968253968, 0.08, 0.96, 1.35, -0.31, 1.2714285714285714, 1.38, 1.38, -0.05, -0.01, 0.81, -0.82, -0.36, 1.75, 1.39, 0.58, 0.44384172319783916, 0.43, 2.03, 1.66, 1.59, 1.7, 1.69, 0.2764030612244898, 0.3, 1.13, -0.51, -0.05, 2.06, 1.7, 0.89, 0.71, -0.87, -0.49, -1.6, 0.19, 0.07, 0.11, 0.1, -1.31, -0.5985714285714286, -0.45, -1.7803066893424033, -1.61, 0.47, 0.1259625850340136, -0.69, -0.87, -0.15, -0.03, -0.009285714285714286, -0.9733418367346938, -1.37, -0.56, -2.1669047619047617, -1.72, 0.36, 0.0, -0.8, -0.97, 1.19, 1.85, -1.85, -0.03, -1.41, -1.37, -0.56, -2.17, -1.71, 0.36, 0.01, -0.79, -0.97, 1.1812233560090704, 1.4, 0.04, 0.86, -0.77, -0.31, 1.79, 1.44, 0.63, 0.45, 0.35, 1.3, 0.43, 0.88, 0.94, 1.05, 1.36, 0.82, -0.81, -0.35, 1.75, 1.39, 0.59, 0.41, -0.11, 0.53, -1.62, -1.16, 0.92, 0.57, -0.031428571428571445, -0.41, 1.47, 1.62, -0.29, 1.24, 2.02, 0.04, 0.15, -2.31, 2.33, 1.17, 0.53, -0.67, -3.35, -1.75, -0.89, 2.45, 0.43, 2.9, -2.74, -2.72, 0.88, -3.47, 1.79, 2.83, -1.38, 4.1, -0.16, -2.79, -4.08, 3.39, 2.19, 0.47, 2.59, 2.23, 1.41, 1.23, 2.61, 1.71, 2.11, 1.75, 0.94, 0.76, -0.36773809523809525, -0.35, -1.15, -0.6785714285714286, 1.07, 0.61, -0.04, -0.8, -0.98, 0.81, 0.97, -0.17, 0.0, 1.29, -0.15, 1.73, 0.57, 0.77, -0.18, 1.75, 1.17, 0.1, 0.18, 0.87, 0.95, 2.02, 0.93, 1.54], ['440', 2.49, -0.01, 0.05122171562045875, -0.21, 0.11, 0.04, 1.424115257959829, 1.05, 0.52, 0.92, 0.35, 0.241934498041641, 1.24, -0.44, 0.14, 0.25, 0.7, 0.72, 0.92, 0.67, 0.83, 1.66, 0.73, 0.97, 0.78, 0.84, 0.58, -0.3, 0.89, -0.79, -0.2, -0.09, 0.35, 0.38, 0.58, 0.32, 0.48076068376068376, 1.31, 0.39, 0.62, 0.8, -0.48, 0.88, 1.1936589811608609, -0.48, 0.1, 0.21, 0.66, 0.68, 0.88, 0.63, 0.79, 1.62, 0.69, 1.2308287981859412, 0.87, 0.75, 0.08, 0.86, -0.31, -1.66, -1.08, -0.97, -0.53, -0.51, -0.31, -0.56, -0.4, 0.42, -0.5, -0.27, 2.31, 1.37, 0.59, 0.7, 1.15, 1.17, 1.37, 1.12, 1.28, 2.11, 1.18, 1.42, 0.13, 0.25, -0.34, 0.78, 0.11, 0.56, 0.58, 0.78, 0.53, 0.69, 1.52, 0.59, 0.82, 2.68, 0.67, 0.44, 0.47, 0.67, 0.41, 0.58, 1.41, 0.48, 0.71, 0.22, 0.66, -1.73, 0.23, 0.34, 0.06, 0.22, 0.02, 0.22, -0.03, 0.13, 0.96, 0.03, 0.3285846838830657, -0.75, 0.2, 0.2, -0.05, 0.11, 0.93, 0.01, 0.24, 0.7, 0.48, -0.23, 0.02, 8.12, 0.02, -0.07, -0.46, 0.46, 0.23, -0.29, 0.11, -0.48, -0.48, -0.2, 1.24, 0.22, 0.69, -0.77, -0.74, 0.24, -0.66, 0.48, 1.33, -0.65, 0.62, -3.75, -0.35, -0.71, 0.45, 0.0, -0.25, -0.09, 0.73, -0.19, 0.04, 0.63, 0.25, 0.16, 0.99, 0.06, 0.3, 0.09, 0.83, -0.1, 0.13, 0.51, 0.39, -0.73, -0.92, -0.68, 0.14, 0.22, 0.99, -1.92, -0.73, 1.88, -0.29, 0.62, 0.19, 0.23, 0.26, -0.1, 0.6, 0.08, 0.79, -0.04, 0.63, 0.63, -0.06], ['441', -4.94, 0.19, 0.011221715620458745, -0.24, -0.10702091900894042, 1.31, 0.6941152579598292, 1.75, 2.14, 0.63, -1.54, -0.2, -0.48, -1.78, -0.05, 1.49, -0.31, 0.24, 2.92, -0.84, 1.59, -0.42, -1.79, -0.62, 2.0, 1.46, 2.21, 1.36, 1.07, -0.24, 1.52, 3.08, 1.25, 1.8, 4.547761904761905, 0.71, 3.17, 1.14, -0.25, 0.93, 1.26, 4.97, 0.84, -0.28, -1.58, 0.16, 1.7, -0.11, 0.44, 3.12, -0.64, 1.79, -0.22, -1.59, -0.42, 1.34, 1.87, 1.78, 2.2699285714285713, 1.12, -1.3, 0.44, 1.98, 0.17, 0.72, 3.41, -0.36, 2.08, 0.06, -1.31, -0.14, 0.82, 2.45, 1.76, 3.33, 1.49, 2.05, 4.78, 0.96, 3.42, 1.38, -0.01, 1.18, 3.3, 6.37, -6.3, 0.68, 1.54, -0.27, 0.28, 2.96, -0.79, 1.7952352330209473, -0.37, -1.74, -0.57, -0.48, -0.85, -1.78, -1.24, 1.4, -2.3, 0.09, -1.88, -3.23, -2.08, 0.49, -0.89, 0.42572371188304003, 1.46, 1.77, 1.05, 0.95, 0.55, 3.24, -0.53, 2.0857782534925393, -0.11, -1.48, -0.25141531611693435, 1.1265360710717855, 0.4, 2.67, -1.07, 1.35, -0.65, -2.02, -0.85, 2.23, 1.93, -0.29, 1.04, -0.92, 0.46, 0.35, -1.73, 1.74, 0.85, 0.05, 2.82, -2.87, -2.95, -1.45, -2.53, 1.24, 4.2, -4.18, -4.29, 1.47, -2.57, 2.92, 2.15, -1.05, 2.79, -9.91, -1.86, -2.76, 2.93, -2.22, -3.65, -1.29, -3.24, -4.57, -3.44, 4.41, 1.48, 2.44, 0.42, -0.96, 0.22, -0.94, -1.98, -3.32, -2.17, 2.17, 2.57, 1.1472746849074344, -1.37, -0.2, 1.38, 1.31, 1.58, -5.17, 0.45, 5.12, 1.13, 1.86, 2.47, 1.19, 1.58, 0.83, 0.95, 1.55, 1.88, 1.26, 0.84, 0.91, 0.86], ['442', 1.49, 0.32, -0.22877828437954126, 0.04, 1.09, 0.15, -0.8358847420401708, -1.05, -2.12, -1.06, 1.68, -0.67, -1.21, -0.62, -0.23, -1.39, -1.55, -0.86, 0.7114818594104309, -2.83, -1.11, -1.58, -1.39, -1.11, -1.44, 0.07, -2.7, -2.31, -2.84, -2.11681006295292, -1.88, -3.02, -3.18, -2.5, -0.97, -4.44, -2.74, -3.21, -3.02, -2.75, -1.1, -3.0450638007838267, -0.39, -0.54, 0.05, 0.45, -0.72, -0.88, -0.19, 1.38, -2.17, -0.44, -0.92, -0.72, -0.44, -0.82, -1.91, -0.6, -2.52, 0.15, 0.6, 0.99, -0.18, -0.34, 0.35, 1.93, -1.64, 0.1, -0.38, -0.18, 0.1, -0.36, -0.45, 0.39, -0.78, -0.94, -0.25, 1.32, -2.23, -0.49, -0.97, -0.77, -0.5, -2.49, 0.98, -1.03, -0.8033017616146798, -1.16, -1.32, -0.64, 0.92, -2.61, -0.88, -1.36, -1.16, -0.89, 2.36, 0.33, -0.16, 0.53, 2.11, -1.46, 0.28, -0.2, 0.0, 0.28, -0.13, 0.33, 1.41, 0.2, 0.33, 0.20567351865003197, 0.5, 0.7, 2.28015873015873, -1.3, 0.45, -0.03, 0.16, 0.44, 0.61, -0.2, 1.57, -1.99, -0.25, -0.6042004503433073, -0.53, -0.25, 0.08, 0.08, 0.08, 0.46, 4.75, 0.11, 0.21, -0.17, 0.16, 0.07, 0.94, -0.24, -3.83, -0.33, -0.17, 0.84, -0.04, 0.6514761904761905, -0.65, -0.49, 0.19, -0.23, 0.33, 0.09, 0.0, 1.45, -2.47, -1.02, -1.46, 3.86, -1.74, -3.5, -1.79, -2.26, -2.07, -1.79, 0.53, 1.82, 1.77, 1.29, 1.48, 1.77, 0.05, -0.48, -0.28, 0.0, -0.27, -0.59, 0.53, 0.2, 0.48, 0.17, 0.27, 0.02, -1.07, 0.61, 1.3, 0.5, 0.95, 0.33, 0.28, 0.33, 0.04, -0.29, -0.12, -0.03, 0.05, 1.7, 1.31, -0.11], ['443', -0.76, -0.56, 0.011221715620458745, 0.01, 0.11, 0.12, -0.59, 0.29, -0.08, -0.29, 0.19, 0.09, -0.02, -1.63, -0.61, -0.33, -0.26, -0.39, 1.36, -0.06, -0.42, 0.61, -0.26, 0.22, 0.68, -0.11, -0.48, -0.1, -0.21, -1.82, -0.8, -0.52, -0.45, -0.58, 1.17, -0.25, -0.61, 0.42, -0.44, 0.04, 0.17, -0.47, -0.38, -0.11, -1.72, -0.7, -0.42, -0.35, -0.48, 1.27, -0.15, -0.51, 0.51, -0.35, 0.13, 0.21, -0.34, 0.48, 0.71, -0.27, -1.61, -0.59, -0.31, -0.25, -0.37, 1.38, -0.04, -0.4, 0.63, -0.24, 0.24, 0.32, 1.36, 1.03, 1.32, 1.39, 1.26, 3.04, 1.6, 1.23, 2.27, 1.4, 1.89, -0.52, 0.01, 0.09, 0.3666982383853202, 0.28, 0.35, 0.23, 1.98, 0.56, 0.19, 1.23, 0.36, 0.84, 0.97, 0.04, 0.07, -0.06, 1.7, 0.27, -0.09, 0.94, 0.08, 0.56, 0.21, 0.03, 0.65, 0.08, 0.19, 0.07567351865003197, -0.03, -0.13, 1.63, 0.2, -0.16, 0.87, 0.01, 0.49, -0.79, 0.1, 1.75, 0.33, -0.03, 1.1257995496566926, 0.13, 0.62, 0.18, 0.11, -0.18, 0.09, 2.91, 0.01, 0.05, 0.0, -0.02, -0.02, -0.03, 0.32, 0.45, -0.15, -0.09, -0.38, 0.04, 0.22, -0.26, -0.21, 0.07, -0.08, 0.14, 0.59, -0.24, -0.07, -3.45, 0.03, 0.05, -0.37, -1.63, -1.4, -1.76, -0.74, -1.59, -1.12, 0.22, -0.23, -0.36, 0.7557142857142858, -0.2, 0.28, 0.13, 1.03, 0.17, 0.65, 0.02, 0.04, -0.89, -0.86, -0.38, 0.09, 0.07, 0.4525760496238784, -2.01, 0.3711163791806698, 2.03, 0.25, 0.17, -0.03, 0.48, -0.14, 0.15, 0.53, -0.24, 0.34, -0.51, 0.26, 0.26, 0.34], ['444', 1.57, -1.29, -0.06877828437954125, -0.05, -0.57, -0.53, -3.31, -1.13, -0.8506219456129893, -0.65, -0.05, 1.31, -0.45, 2.63, 0.89, -1.39, 0.12, -0.34, 0.87, 1.11, 0.0, 1.5, -0.98, 0.04, -0.35, 0.25, -0.61, 1.36, -0.4, 2.68, 0.94, -1.35, 0.17, -0.29, 0.92, 1.16, 0.05, 1.55, -0.94, 0.09, -1.85, 0.0, -1.94, -1.73, 1.31, -0.41, -2.67, -1.17, -1.63, -0.43, -0.2, -1.29, 0.19, -2.27, -1.25, -0.72, -1.36, -0.14, -0.91, -0.21, 3.1, 1.35, -0.95, 0.57, 0.11, 1.32, 1.57, 0.45, 1.96, -0.54, 0.49, 0.26, -3.2, -1.7, -3.92, -2.45, -2.9, -1.72, -1.48, -2.57, -1.11, -3.53, -2.52, -0.51, 0.15, -0.22, -1.53, -2.27, -0.76, -1.22, -0.02, 0.22, -0.88, 0.6, -1.86, -0.84, 2.75, 0.75, 1.54, 1.07, 2.3, 2.54, 1.41, 2.93, 0.41, 1.46, -0.42, 0.78, -2.36, -0.45, -0.3, -0.69, -0.78, -0.46, 0.75, 0.99, -0.12, 1.37, -1.11, -0.08, -1.94, -0.32, 1.21, 1.46, 0.34, 1.85, -0.65, 0.38, 0.18, 0.05956122448979598, -0.04, -0.57, 8.17, -0.35, -0.57, 0.63, -0.61, -0.31, -0.07, -1.38, 3.38, 0.88, 0.42, 0.78, -1.36, -1.32, 1.39, 1.37, -0.44, 0.91, -0.88, -1.22, 0.62, -2.29, 1.94, 1.48, 2.28, -3.44, -1.51, 0.24, -0.86, 0.62, -1.84, -0.82, -1.24, -1.75, -1.1, 0.38, -2.07, -1.06, -0.66, 1.5, -0.99, 0.04, -0.97, -0.69, -2.12, -2.45, -1.43, -0.42, -0.52, -1.19, 1.36, -1.85, -0.9107193877551023, -0.22, -0.1, 0.33, 1.04, -0.24, -0.08, -1.56, -1.33, -1.31, -0.7, -0.58, 0.15, -0.47], ['445', 2.74, -0.2, -0.17, 0.01, 0.18, -0.36, 0.4841152579598291, -1.08, -0.26, -0.25, 0.33, -0.5506751700680272, 0.76, 1.55, 1.68, -0.08, 0.24, -0.08, 0.91, -0.4, 0.16733548208735893, 1.88, 0.92, 0.39, -0.64, -0.96, -0.5473416050068876, -0.89, 0.43, 1.21, 1.35, -0.4, -0.09, -0.41, 0.58, -0.73, -0.19, 1.55, 0.58, 0.06, -1.12, 0.34493619921617347, 0.31, 1.33, 2.12, 2.26, 0.49, 0.81, 0.48, 1.49, 0.16, 0.7, 2.46, 1.5871428571428572, 0.96, -0.3876426685347185, -1.26, -0.78, -0.98, -1.0, 0.78, 0.92, -0.83, -0.51, -0.83, 0.15, -1.15, -0.62, 1.11, 0.16, -0.37, -0.83, -1.77, 0.14, -1.5367057823129253, -1.28, -1.6, -0.62, -1.92, -1.39, 0.33, -0.62, -1.14, 0.18, -3.53, 3.53, -1.9, -1.73, -1.42, -1.73, -0.76, -2.05, -1.52, 0.2, -0.75, -1.27, 1.04, -0.18, 0.32, -0.01, 0.99, -0.33, 0.21, 1.96, 1.1311089783232642, 0.47, -0.14, -0.23, 0.0, -0.6, -0.86, -0.42, -0.49, -0.32, 0.67, -0.64, -0.11, 1.64, 0.67, 0.15, -1.99, -0.17, 1.0, -0.32, 0.22, 1.96, 1.0, 0.47, -1.1781719617057962, -1.76, -0.13, -0.91, 1.92, -0.43, -0.29, -0.92, 0.9, 0.46, -0.74, -0.46, -0.5, 1.22, 0.62, 1.34, -0.58, -1.8, 1.91, 1.83, -0.61, -1.32, -1.44, 0.46, -0.2, -1.42, 3.62, 0.96, 1.36, 0.4, -1.1416360544217685, -1.3, -0.77, 0.96, 0.0, -0.52, -1.87, 0.15, 0.54, 2.5371428571428574, 1.32, 0.79, -0.39, 1.74, 0.78, 0.26, -0.19, -0.36, -2.09, -0.95, -1.46, -0.4779199656859431, -0.65, -1.05, 1.84, -0.28, -1.85, -1.96, -1.45, -1.16, -0.52, -1.56, 0.64, -0.29, -0.35, -0.92, -0.64, -2.03, -0.65, -0.71], ['446', -0.75, 0.51, 0.07015289830927054, -0.07, -0.25, -0.3, 1.61, 1.36, 0.56, 1.35, 1.27, 0.64, 0.84, 0.28, -1.88, 0.68, 0.48, 1.33, 2.08, 1.87, 1.22, 0.31, 0.15, 0.32, -0.04, 0.16, 0.11265839499311246, -0.63, -0.43, -0.97, -3.11, -0.58, -0.78, 0.06, 0.8, 0.59, -0.05, -0.95, -1.11, -0.93, 1.99, 1.6849361992161733, 0.71, 0.2, -0.35, -2.5, 0.04, -0.16, 0.69, 1.43, 1.23, 0.58, -0.33, -0.49, -0.31, 0.06, 0.5, 2.74, 0.41, 0.52, -0.55, -2.69, -0.15, -0.35, 0.49, 1.2471802721088434, 1.03, 0.38, -0.52, -0.68, -0.51, 0.82, 1.07, -2.16, 0.39, 0.2, 1.04, 1.79, 1.58, 0.93, 0.02, -0.14, 0.04, 0.78, 3.18, -3.27, 3.3, 2.61, 2.4, 3.27, 4.03, 3.82, 3.16, 2.23, 2.06, 2.25, -0.04, 0.67, -0.2, 0.65, 1.39, 1.18, 0.54, -0.37, -0.53, -0.35, 0.0, 0.63, 2.58, 0.61, 0.65, 0.72, 0.87, 0.85, 1.59, 1.38, 0.74, -0.17, -0.33, -0.15, 0.83, 0.02, 0.74, 0.53, -0.11, -1.01, -1.17, -0.99, 1.18, 1.2, 0.0, 1.343186783623568, -0.24, 0.04, 0.05, -2.39, 2.43, 1.24, -0.15, -0.19, 1.17, -1.24, -0.64, -0.29, 0.83, 1.82, -1.88, -1.92, 0.6, -3.7, 1.23, 0.4, -0.25, 2.6, -8.33, -1.85, -2.62, -1.07, -0.71, -0.2, -0.84, -1.73, -1.89, -1.72, 1.79, -0.5098412698412699, -0.64, -1.53, -1.69, -1.52, 0.13, -0.9, -1.06, -0.88, 0.56, 0.6, 1.05, -0.16, 0.09224875531501633, 0.61, 0.71, 1.35, -5.0, 2.28, 4.72, 0.86, -0.66, 1.21, 0.18, 0.39, 0.03, 1.31, 0.62, 1.07, 1.03, -0.74, -1.08, 1.06], ['447', -8.49, 0.36, 0.05122171562045875, 0.08, -0.29, 0.37, 0.6541152579598292, 0.57, 0.61, -0.1, -0.63, -1.08, -0.36, -0.56, -0.89, 1.32, -0.65, -0.28, -2.81, -0.62, -0.01, -1.24, -1.21, -0.23, 0.56, -0.11, 0.53, -0.45, 0.27, 0.07, -0.27, 1.96, -0.02, 0.35, -2.2, 0.01, 0.62, -0.61, -0.59, 0.4, 0.89, 1.2, 0.98, 0.73, 0.53, 0.18, 2.43, 0.43, 0.81, -1.76, 0.46, 1.08, -0.16, -0.14, 0.86, 0.89, 0.55, 0.0, 0.61, 0.32924524706587754, -0.2, -0.54, 1.68, -0.29, 0.08, -2.47, -0.26, 0.35, -0.88, -0.86, 0.13, -0.13, 0.45, -0.34, 1.89, -0.09, 0.28, -2.27, -0.07, 0.55, -0.69, -0.5269045181009466, 0.33, 0.69, 3.05, -2.96, 0.8008709226619941, 2.24, 0.25, 0.62, -1.94, 0.28, 0.89, -0.35, -0.32, 0.67, -1.72, -1.41, -1.94, -1.58, -4.08, -1.92, -1.32, -2.53, -2.5, -1.53, 0.19, -1.42, 0.1, 0.43, 0.56, 0.26, 0.55, 0.37, -2.18, 0.22971268810554554, 0.8157782534925394, -0.59, -0.4940121365844473, 0.42, 1.05, 0.17, -2.54, -0.34, 0.27, -0.96, -0.94, 0.05, 0.46, 0.24, 0.13, 0.51, -5.2, 0.0, 0.05, -0.14, 0.11, 0.07, 0.29, 1.1961635321120496, -0.97, -0.91, -0.44, -4.22, 0.42, 1.36, -1.31, -1.31, 0.44, -0.2, 0.85, 0.27, -0.14, 1.72, 0.85, -1.1, -1.61, 1.1, 2.79, 2.26, 2.88, 1.62, 1.65, 2.66, 1.35, 0.52, 0.61, -0.62, -0.6, 0.39, -0.09, -1.23, -1.2, -0.22, -0.4, -0.33, 1.2372746849074343, 0.02, 1.02, 0.44, -0.28, -0.2974239503761216, 0.5, -0.19, -0.58, 0.64, 0.58, 1.12, 1.0, 0.34, 0.2, 0.55, 0.28, 0.2, 0.13, -0.09, 0.51, -0.16], ['448', -1.22, -0.18, -0.06, 0.23, -0.2, -0.02, 1.25, -0.31, -0.36, 0.9370884353741497, 0.970608843537415, -0.41, 0.41, 0.6, 0.76, 0.91, 0.57, 0.36, 1.66, 0.37, 0.35, 0.03, 0.87, 0.2, -0.57, -0.48, -0.42734160500688756, -1.35, -0.54, -0.35, -0.1421800287049088, -0.05, -0.39, -0.47274109585559154, 0.7, -0.58, -0.6, -0.92, -0.09, -0.75, 0.28, -1.06, 0.9, 0.82, 1.02, 1.17, 1.32, 0.98, 0.78, 2.08, 0.78, 0.77, 0.44, 1.28, 0.62, -0.9, 0.54, -0.22, -0.74, 0.15924524706587756, 0.19, 0.35, 0.5, 0.16, -0.05, 1.25, -0.04, -0.06, -0.38, 0.46, -0.21, -0.35, -0.11, 0.16, 0.3, -0.04, -0.24, 1.05, -0.23, -0.25, -0.57, 0.26, -0.4, -0.92, -1.11, 1.15, -0.23330176161467986, 0.15, -0.19, -0.39, 0.9, -0.39, -0.4, -0.72, 0.11, -0.55, -0.87, -0.41, -0.34, -0.54, 0.75, -0.54, -0.4873734626473065, -0.87, -0.04, -0.7, 0.16, -0.45, 2.61, 0.03, -0.11, 0.16, -0.0790429599640126, -0.2, 1.09, -0.2, -0.21, -0.53, 0.3, -0.36, 0.4, 0.13, 1.29, 0.0, -0.01, -0.33, 0.5, -0.16, -0.67, -0.35, 0.62, -0.08, -2.34, 0.0, 0.07, -0.94, 0.96, 0.47, -0.44, -1.28, -0.24, -0.08, -0.03, -0.56, 0.3, -0.01, -0.09, -0.17, 0.03, -1.33, 0.04, -1.06, 0.51, -0.38, 16.84, 0.28, 0.36, 0.24, -1.15, -1.27, -1.29, -1.6, -0.78, -1.44, 0.09, 0.12, -0.01, -0.34, 0.5, -0.16, 0.14, -0.32, 0.51, -0.15, -0.32, -0.83, 0.46, 0.84, 0.17, 0.06, 0.11439630127529085, -0.24, 7.56, 1.490333262784063, -7.7, 0.37, -0.73, -0.38, -0.66, 0.01, 0.3, 0.15, 0.63, 0.32, 0.29, 0.12, -1.29, 0.11], ['449', 3.584285714285714, -0.03, 0.13122171562045873, 0.1, 1.42, 0.8, 0.5641152579598292, 1.35, 1.33, 1.5, -0.14, 0.93, 1.78, 0.27, -0.04, 0.49, 0.62, 1.29, -1.67, -0.16, 1.947335482087359, 0.83, 0.96, 0.9, 1.73, 1.39, 1.65, 1.08, 1.93, 0.41, 0.1, 0.63, 0.77, 1.43, -1.53, -0.01, 2.06, 0.97, 1.1, 1.04, 0.79, 3.03, 0.56, 0.84, -0.66, -0.97, -0.44, -0.31, 0.35, -2.58, -1.08, 0.9980654680864429, -0.11, 0.02, -0.04, 0.7, 1.62, 2.217827972809784, 0.99, -0.28, -1.49, -1.79, -1.27, -1.14, -0.49, -3.4, -1.91, 0.12, -0.94, -0.81, -0.8605612244897959, 1.2436060011417156, 1.23, -0.2953571428571429, 0.22, 0.35, 1.01, -1.94, -0.42, 1.64, 0.55, 0.69, 0.62, 2.04, 1.59, -1.58, 1.54, 0.53, 0.66, 1.33, -1.63, -0.12, 1.95, 0.87, 1.0, 0.94, 1.7, 1.01, 0.13, 0.79, -2.15, -0.64, 1.41, 0.33, 0.47, 0.4, 0.15, 0.99, 0.22572371188304005, 0.84, 0.77, 0.9, 0.9418094764861292, 0.66, -2.28, -0.77, 1.28, 0.2, 0.33, 0.27, 0.61, 0.21, -2.92, -1.43, 0.62, -0.46, -0.33, -0.39, 0.4618280382942037, 0.45, 0.04, 0.86, 5.04, 0.32, 0.4, -2.33, 2.38, 1.19, 1.23, 0.23, -3.26, -1.64, -0.87, 1.6, 0.69, 2.53, -2.55, -2.49, 0.84, -3.56, 1.66, 0.03, -0.02, 2.62, -2.77, -1.79, -2.59, 3.26, 3.23, 1.54, 3.64, 2.54, 2.68, 2.61, 2.52, 1.66, 2.07, 0.98, 1.12, 1.05, -0.4, -1.07, -0.94, -1.0, 1.27, 1.52, 0.67, 0.13, 0.07, 0.84, 0.8, 1.31, -1.71, 0.3, 1.86, 1.27, 1.34, 0.54, -0.06, 0.61, 1.5, 0.37, 0.95, 0.61, 0.6, 1.8, 1.93, 0.44], ['450', 1.66, 0.38, 0.12, -0.04, 0.18, 0.56, 1.0041152579598291, 1.51, 1.2, 1.64, 0.46, 0.691934498041641, 0.57, -0.26, 0.24, 1.39, 0.44, 1.41, 2.91, 0.16, 1.96, 0.53, 0.64, 0.87, 1.72, 0.57, 1.2026583949931124, 0.02, 0.11, -0.72, -0.22, 0.92, -0.03, 0.95, 2.43, -0.3, 1.49, 0.07, 0.18, 0.4, 0.73, 0.8449361992161734, 1.14, 0.08, -0.74, -0.25, 0.89, -0.05, 0.92, 2.41, -0.33, 1.46, 0.04, 0.15, 0.38, 0.49, 1.67, 0.99, 1.22, 1.1392452470658776, -0.82, -0.33, 0.81, -0.13, 0.84, 2.32, -0.41, 1.38, -0.04, 0.07, 0.3, 1.85, 1.9, 0.5, 1.65, 0.7, 1.68, 3.17, 0.42, 2.22, 0.79, 0.9, 1.13, 0.94, 2.7, -2.63, 1.42669823838532, 1.15, 0.2, 1.17, 2.66, -0.08, 1.72, 0.29, 0.4, 0.63, -0.44, 0.25, -0.94, 0.03, 1.5, -1.21, 0.56, -0.84, -0.73, -0.51, 0.4, 0.24, 1.9001046511627906, 0.73, 0.68, 0.73, 1.19, 0.97, 2.46, -0.28, 1.52, 0.1, 0.2, 0.43, 1.09, 0.27307674813036725, 1.47, -1.24, 0.54, -0.87, -0.76, -0.29782256235827664, 0.87, 1.33, 0.24, 0.91, -1.55, 0.44, 0.62, -1.65, 1.8017201258125628, 0.84, 1.25, 2.96, -2.75, -1.39, -0.72, 0.82, 0.31, 2.14, -2.12, -2.16, 0.71, -2.45, 1.4, 0.47, -0.23, 3.65, -12.89, -2.49, -3.65, 2.81, -1.23, -2.67, -0.92, -2.31, -2.2, -1.98, 2.14, 1.47, 1.8, 0.37, 0.48, 0.71, -0.32, -1.4, -1.29, -1.07, 1.24, 1.29, 1.1, 0.11, 0.34, 0.76, 0.74, 1.62, -6.51, 1.55, 6.68, 0.49, 0.71, 0.99, 0.23, 1.0, 0.57, 0.43, -0.14, 0.78, 0.76, 0.04, 1.2415952380952382, 0.65], ['451', -12.94, -0.19, -0.5, 0.15, -3.29, -0.89, -0.25, -0.83, -0.88, -1.86, -0.96, -1.43, -0.66, -1.0, -0.88, 1.41, -0.54, -1.7, 2.7, 3.14, -2.03, -2.46, -2.13, -0.85, -1.24, -1.96, -0.8773416050068876, -0.4671394557823129, 0.3, -0.04, 0.07, 2.39, 0.42, -0.75, 3.700714285714286, 4.14, -1.0055463299214311, -1.52, -1.18, 0.11, -0.65, -2.17, -0.24069676751819596, 0.77, 0.44, 0.55, 2.88, 0.9, -0.28, 4.19, 4.63, -0.61, -1.05, -0.71, 0.58, -0.72, -1.04, -0.15, -1.19, -1.2, -0.33, -0.22, 2.09, 0.12, -1.04, 3.39, 3.83, -1.37, -1.4825351473922903, -1.47, -0.19, -1.67, -0.87, 0.11, 2.43, 0.46, -0.71, 3.74, 4.18, -1.04, -1.48, -1.14, 0.15, -1.1, 0.34, -0.33, -0.98, 2.32, 0.35, -0.82, 3.62, 4.06, -1.15, -1.59, -1.25, 0.04, -2.52, -3.22, -1.93, -2.9646649659863944, 1.27, 1.71, -3.39, -3.793605339105339, -3.49, -2.23, -0.25, -3.33, -2.66, -0.82, -0.57, -1.21, -1.32, -1.16, 3.26, 3.7, -1.49, -1.93, -1.59, -0.31, 0.56, -0.10692325186963274, 4.48, 4.92, -0.1613969800041227, -0.77, -0.44, 0.86, 0.16, 0.0, 0.06, -1.29, -7.6, -0.47, -0.48, 2.9, -2.9, -1.4111898289923788, -0.11, 0.17, 9.38, 1.61, 0.87, -6.5, -0.37, -2.73, 2.72, 2.49, -0.82, 4.31, -1.65, -2.63, 1.3, -3.95, 1.2, 2.66, 3.87, -9.52, -4.44, 0.43, -4.61, -5.03, -4.7, -3.46, -2.47, -4.84, -5.01, -5.43, -5.11, -3.87, 0.18, -0.44, -0.1, 1.2, -0.94, -1.08, 0.62, 0.34, 1.65, -0.85, -0.92, -0.92, 0.66, -2.39, -0.72, -0.3227361894755667, -2.59, 0.28, 1.31, -0.91, -1.41, -0.17470204795204777, -0.63, 0.15, -1.01, -1.17, -3.95, -0.83], ['452', -0.12, -0.12, 0.011221715620458745, 0.0, 0.1329790809910596, -0.04, -0.81, -0.87, -0.95, -0.33, 0.540608843537415, 0.69, 0.76, -0.06, 1.43, -0.11, 0.17, -0.06, -0.23, -0.53, -0.95, 1.36, 0.39, 0.05, -1.07, -0.89, -0.86, 0.16054545454545455, 0.23, -0.59, 0.9, -0.64, -0.36, -0.59, -0.75, -1.06, -1.47, 0.82, -0.14, -0.43615827680216085, -1.09, -2.77, -1.01, 0.07, -0.5821246055531769, 0.74, -0.8, -0.52, -0.74, -0.91, -1.21, -1.610345270762939, 0.66, -0.29, -0.64, -1.42, -0.51, -0.28217202719021606, -0.95, -1.08, -0.82, 0.67, -0.87, -0.59, -0.82, -0.98, -1.29, -1.7, 0.59, -0.37, -0.71, -1.25, -0.27, 1.5, -0.05, 0.23, 0.0, -0.16, -0.47, -0.88, 1.42, 0.45, 0.11, -1.17, -2.028257052471338, 2.22, -1.70330176161468, -1.53, -1.25, -1.48, -1.64, -1.94, -2.35, -0.08, -1.03, -1.37, -1.44, -0.22, 0.28, 0.05, -0.11, -0.42, -0.83, 1.47, 0.51, 0.16, -0.3090204081632653, -0.23, 0.09572371188304005, -0.2, -0.19, -0.2843264813499681, -0.42819052351387077, -0.23, -0.39, -0.7, -1.11, 1.19, 0.22, -0.12, -1.38, -0.21692325186963274, -0.16, -0.47, -0.89, 1.42, 0.45, 0.11, -1.2, -0.95, 0.03, -0.76, -4.27, 0.0, -0.07, 0.5, -0.4082798741874371, -0.25, 0.45, -0.4, -0.2, 0.53, 0.22, -0.03, 0.49, -0.65, 0.67, 0.62, -0.2, 0.81, -0.43, -0.61, 0.27, -1.51, 2.38, 0.97, 1.5, 0.44, -0.1, -0.31, -0.72, 1.58, 0.62, 0.27, -0.63, 0.21, -0.42, 1.9, 0.93, 0.58, 0.62, 2.32, 1.35, 1.0, -0.98, -1.06, -1.66, -0.95, -1.29, -0.22, -0.35, -0.86, 0.79, -0.43, -0.9634761904761905, -0.53, 0.08, -0.72, -0.34, -1.15, -0.28, 0.47, 0.47, 0.3646262438247291, -0.38, -1.56, -0.11, -0.37], ['453', -4.54, -0.3, -0.38877828437954126, -0.12, -0.77, -0.18, 0.9, -0.1, -0.27, -0.52, 0.24, -0.52, -1.17, -0.69, -0.65, 1.3, -0.84, -0.44, 0.2, 1.44, -0.662664517912641, -0.49, -0.29, -1.04, 0.04, -0.88, -0.76, -0.76, -1.41, -0.94, -0.9, 1.05, -1.08, -0.69, -0.04, 1.19, -0.94, -0.73, -0.54, -1.28, 0.02, -0.83, 0.0, -0.6463410188391392, -0.18, -0.14, 1.83, -0.33, 0.07, 0.72, 1.97, -0.18, 0.03, 0.22, -0.524952380952381, -0.47, -0.43, 0.0, -0.05, 0.66, 0.48, 0.52, 2.5, 0.33, 0.73, 1.38, 2.64, 0.47, 0.69, 0.88, 0.13, 0.06, 0.18, 0.04, 2.01, -0.15, 0.25, 0.9, 2.15, 0.0, 0.21, 0.4, -0.35, -0.86, -0.25, 0.26, 0.14, 1.97, -0.19, 0.21, 0.86, 2.303744771101914, 0.11523523302094742, 0.17, 0.36852380952380953, -0.39, -3.31, -1.79, -2.11, -1.72, -1.09, 0.14, -1.97, -1.77, -1.57, -2.31, -0.01, -1.75, 0.64, 0.01, -0.13, 0.24567351865003195, 0.33, 0.4, 1.0501587301587303, 2.3, 0.14, 0.36, 0.55, -0.2, 0.07, -0.07, 0.65, 1.982244713705627, -0.26, -0.04, 0.15, -0.6, -0.15, 0.16, -0.15, 0.12, -10.09, 0.0, -0.48, 0.01, -0.03, -0.01, -0.02, -0.87, 3.81, 0.0, -0.03, -2.27, 0.1, 0.021476190476190475, 0.0, -0.03, 0.01, -0.03, 0.03, 1.228390654979941, -0.56, 0.93, -2.25, -0.65, -0.98, -3.77, -0.72, 1.24, -0.9, -0.69, -0.49, -1.24, 0.0, -1.93, -2.11, -1.9, -1.71, -2.45, 0.18, 0.21, 0.41, -0.35, -0.3, -0.32, -0.03, 0.2, -0.56, 0.02, 0.04, 0.0, -1.17, 0.45, 1.13, -0.08, -1.03, -0.22, -0.75, 0.17, 0.1, 0.27, 0.33, 0.2, 0.53, -1.16, -1.76, 1.19], ['454', -1.44, 0.03, 0.16, 0.06, -1.01, -0.63, 0.07411525795982916, -0.95, -0.72, -1.15, 0.03, -0.84, -0.69, -0.07, -0.91, -0.47, 0.02, -1.12, -1.8, 0.53, -1.21, -0.68, -0.34, -1.29, -0.3, -0.5, -1.18, -0.8771394557823129, -0.7253571428571428, -0.11, -0.94, -0.5, -0.02, -1.16, -1.84, 0.49, -1.25, -0.71, -0.38, -1.32, -0.05, -3.14, -0.31, 0.15, 0.78, -0.07, 0.38, 0.87, -0.28, -0.97, 1.38, -0.341934531913557, 0.17, 0.51, -0.45, -0.8399371536943234, -0.47, -1.5580521152823785, 0.29, -0.46, 0.62, -0.22, 0.22, 0.71, -0.43, -1.12, 1.23, -0.53, 0.01, 0.35, -0.6, -0.96, -1.08, -0.84, -0.4, 0.09, -1.05, -1.73, 0.6, -1.14, -0.61, -0.1369045181009466, -1.22, -1.89, -2.29, 2.2, -0.24, 0.44, 0.93, -0.21, -0.9, 1.45, -0.31, 0.23, 0.57, -0.3259922724755494, -1.46, -0.68, 0.49, -0.66, -1.34, 1.0, -0.75, -0.21, 0.13, -0.82, -0.09, -0.7, -1.65, -0.46, -0.58, -0.32, -1.16, -1.14, -1.82, 0.51, -1.23, -0.6396949805527123, -0.36, -1.31, -0.44, -0.03, -0.43631441970727664, 1.67, -0.09, 0.45, 0.79, -0.17, -1.32, -1.54, 0.01, -0.59, -4.2, -0.03, 0.09, 0.81, -0.82, -0.43, 0.07, -1.07, 3.18, 0.97, 0.47, -0.65, -0.3, -1.34, 1.4, 1.5, -0.47, 1.19, -0.93, -0.44, 0.24, -3.49, 1.0486904761904763, 2.3, 3.52, -3.28, 0.67, 2.37, 0.6, 1.14, 1.49, 0.52, -1.35, -1.67, -1.73, -1.2, -0.86, -1.81, 0.07, 0.54, 0.88, -0.08, -0.75, -1.07, -0.47, 0.34, -0.62, -0.48, -0.49, -0.85, 2.39, -1.04, -2.61, -0.44, -0.5, -0.81, -0.95, -0.38, -0.9397802197802197, -0.15, -0.11, -0.22, 0.14, -1.12, -1.76, -0.36], ['455', -0.49, 0.03, 0.12, -0.06, -0.09, 0.51, 0.7, 0.17, 0.74, -0.33, -0.67, -0.94, -0.1, -0.74, -0.7, -0.55, -0.73, -0.43, 1.66, -0.38, -0.05, -1.54, -1.31, 0.29, 0.65, 0.33, 0.35, -0.27, 0.57, -0.06, -0.03, 0.13, -0.06, 0.24, 2.34, 0.29, 0.62, -0.87, -0.64, 0.96, 0.3774684253532108, 2.03, 0.62, 0.85, 0.21, 0.24, 0.4, 0.22, 0.52, 2.63, 0.57, 0.9, -0.5061344435209981, -0.37, 1.24, -0.29993715369432344, 0.31, 0.67, 0.4, -0.22, -0.63, -0.6, -0.44, -0.63, -0.33, 1.76, -0.28, 0.05, -1.44, -1.21, 0.39, 0.18, 0.41, 0.03, 0.19, 0.01, 0.31, 2.6574764481550197, 0.36, 0.69, -0.81, -0.58, 1.03, 1.08, 2.38, -2.29, 0.38, 0.16, -0.03, 0.27, 2.38, 0.33, 0.65, -0.84, -0.61, 1.0, 0.04, 0.22, -0.18, 0.12, 2.22, 0.17, 0.49, -1.0, -0.77, 0.84, 0.0, 0.22, 2.57572371188304, 0.18, 0.56, -0.28, 0.4, 0.3, 2.4, 0.35, 0.68, -0.82, -0.59, 1.02, 1.09, 0.1, 2.1, 0.05, 0.38, -1.11, -0.88, 0.72, 0.92, 1.2, -0.18, 0.09, 0.08, 0.1, 0.04, 1.91, -1.91, -0.94, 0.44, -0.51, 0.0, -0.43, -0.19, -0.28, 0.41, 0.48, -0.41, -0.41, 0.18, 2.68, 0.38, 0.85, -0.46, 1.21, -0.76, -0.81, -1.2, -0.07, -1.95, -1.9951904761904762, -1.68, -3.15, -2.92, -1.35, 0.59, 0.05, 0.32, -1.17, -0.93, 0.67, -0.27, -1.49, -1.26, 0.34, 0.72, 0.73, 1.23, 0.23, 1.85, 0.22, 0.16, 0.19, -0.98, 1.0701996269574994, 1.2, -0.08, 0.7, 1.0, 1.62, 0.93, -0.52, 0.0, 0.75, 0.28, -0.61, 1.09, 0.95, -2.19], ['456', -1.67, -0.03, 0.12, 0.14, 0.18, -0.72, -1.4858847420401708, -1.12, -1.33, 0.12, 1.89, 1.61, 0.74, 0.97, 1.55, -0.02, 0.98, -0.03, -1.41, 0.72, -0.10266451791264107, 0.24, 0.59, 0.59, -1.7, -1.23, -1.74, -0.28, -1.12, -0.9, -0.34, -1.87, -0.9, -1.88, -3.23, -1.15, -1.915546329921431, -1.62, -1.28, -1.28, -1.52, -1.46, -1.46, -0.85, -0.62, -0.06, -1.6, -0.62, -1.61, -2.97, -0.88, -1.691934531913557, -1.35, -1.01, -1.0, -0.52, -1.37, -0.48, -0.76, -0.62, 0.23, 0.9048467679404526, -0.75, 0.23, -0.6673949338599383, -2.13, 0.10397573353350675, -0.88, -0.5, -0.16, -0.15, -1.73, -0.85, 0.57, -0.98, 0.0, -0.99, -2.36, -0.25, -1.1, -0.73, -0.38, -0.38, -1.55, -1.46, 1.43, -1.4, -1.54, -0.56, -1.55, -2.91, -0.81, -1.66, -1.29, -0.95, -0.94, -0.45, 0.14, 0.99, -0.01, -1.39, 0.73, -0.12, 0.26, 0.6, 0.6, 0.02, 0.13, -0.24, -0.68, -0.65, -0.704326481349968, -0.85, -0.99, -2.36, -0.25, -1.11, -0.73, -0.38, -0.3214153161169343, -0.08, 0.15, -1.38, 0.75, -0.11, 0.27, 0.62, 0.62, -0.62, -0.57, 0.13, -0.73, -1.28, -0.1, 0.0, 1.96, -1.96, -0.97, 0.0, -1.83, 1.17, 1.4, 0.72, -0.81, -0.36, -2.06, 2.27, 2.05, -0.69, 2.9, -1.36, -1.45, 0.74, -2.6, 3.57, 1.75, 2.57, -1.17, 1.55, 2.15, 1.28, 1.67, 2.02, 2.02, -2.04, -0.59, -0.85, -0.47, -0.13, -0.13, 0.26, 0.38, 0.73, 0.73, -1.25, -1.02, -0.12, 0.34, 0.35, -0.7, -0.69, -1.14, 1.54, -0.43980037304250064, -1.62, -0.99, -1.2, -0.46, 0.0, -0.84, -1.08, -0.31, -0.3, -0.31, -0.46, -1.89, -1.74, -0.16], ['457', 1.48, -0.72, 0.3412217156204588, 0.03, 0.0, 0.17, -0.015884742040170832, 0.84, 0.1, 0.86, 0.81, 0.75, 1.44, -0.38, -1.34, 1.29, 0.39, 0.6, 2.8, 1.74, 1.13, 1.21, 0.41, 0.86, -0.14, -0.22, 0.05, -0.06, 0.63, -1.18, -2.13, 0.47, -0.41, -0.21, 1.97, 0.93, 0.32, 0.4, -0.39, 0.05, 0.58, -1.0450638007838267, 0.11, 0.7711974674961171, -1.12, -2.08, 0.53, -0.36, -0.15, 2.03, 0.99, 0.38, 0.46, -0.2528571428571429, 0.11, 0.37, -0.94, 0.25, -0.12, -0.57, -1.8, -2.74, -0.15, -1.03, -0.83, 1.34, 0.3, -0.14657884575741703, -0.23, -1.01, -0.57, -0.15639399885828442, 1.25, -0.96, 1.67, 0.78, 0.98, 3.19, 2.13, 1.52, 1.6, 0.8, 1.25, 0.37, 1.24, -1.21, 2.23, 2.66, 1.76, 1.96, 4.19, 3.13, 2.5, 2.59, 1.78, 2.23, 0.27, -0.42, -0.88, -0.68, 1.49, 0.45, -0.16, -0.07, -0.86, -0.42, 0.25, -0.44, 0.7201770034254836, 0.16, 0.29, 0.08, 0.47, 0.2, 2.39, 1.35, 0.73, 0.82, 0.02, 0.47, -0.25, 0.26, 2.19, 1.14, 0.53, 0.61, -0.18, 0.26, 1.39, 1.57, 0.02, 0.52, 0.74, 0.5, 0.01, 0.31, -0.31, -0.16, 0.31, 1.11, 1.82, -0.33, -0.18, 0.84, 0.0, 0.5914761904761905, -0.48, -0.4, 0.16, 0.39, 0.31, -0.58, 0.24, 1.38, -3.43, -0.88, -1.34, -1.68, -1.88, -1.02, -1.62, -1.54, -2.32, -1.88, 0.46, -0.87, -0.6, -0.52, -1.31, -0.87, -0.26, 0.08, -0.71, -0.26, 0.1, 0.27, -0.35, -0.79, -0.35, 0.24, 0.27439630127529085, 0.78, -1.54, 0.75, 1.52, 0.32, 0.47, 0.5286374482009709, 0.5227868514969317, 0.7300774025227806, -0.12, 0.09, 0.06, 0.08462624382472905, 0.085957527023814, 0.27, -0.27, 0.88], ['458', -4.2, -0.56, -0.45, 0.18, -1.3, -0.99, -1.98, -2.05, -1.94, -2.4492857142857143, -0.69, -0.9, -0.44, -1.1, -0.25, -1.22, -1.67, -2.37, -3.42, -0.81, -2.92, -1.58, -1.29, -2.18, -2.22, -0.67, -1.77, -0.22, 0.25, -0.41, 0.44, -0.54, -0.99, -1.7, -2.75, -0.12, -2.25, -0.9, -0.6, -1.5, -1.86, -2.9850638007838266, -1.56, 0.47, -0.2, 0.65, -0.32, -0.78, -1.48, -2.54, 0.09, -2.04, -0.69, -0.3028571428571429, -0.9691712018140588, -1.6, -2.27, -2.5, -2.0, -2.02, -0.66, 0.18079931972789115, -0.79, -1.24, -1.95, -2.7103066893424037, -0.38, -2.5, -1.15, -0.85, -1.75, -2.05, -1.37, 0.85, -0.12, -0.58, -1.135765306122449, -2.35, 0.29, -1.84, 0.16000000000000003, -0.19, -1.09, -2.29, -3.31, 3.36, -2.2, -0.97, -1.42, -2.12, -3.17, -0.56, -2.67, -1.33, -1.04, -1.93, 1.98, -1.25, -0.46, -1.17, -2.23, 0.41, -1.72, -0.37, -0.07, -0.97, -0.04885812600098299, -1.24, 0.33, -0.85, -1.02, -0.66, -0.79, -0.71, -1.78, 0.88, -1.27, 0.15030501944728758, 0.39, -0.51, -0.74, -0.026923251869632736, -1.07, 1.6, -0.5504376417233561, 0.81, 1.11, 0.2, -1.0710416300368755, -1.2, 0.33603717887804047, -0.75, 5.617738095238095, -0.26, 0.07, 1.43, -1.41, -0.72, -0.36, -4.11, 3.13, 1.65, 0.87, -2.09, -0.68, -2.56, 2.55, 2.6, -0.85, 2.23, -1.72, -2.8, 1.39, -2.37, 4.97, 1.71, 2.31, -3.38, 1.0, 2.7, 0.52, 1.9, 2.21, 1.29, -2.53, -1.65, -2.13, -0.78, -0.48, -1.38, 0.49, 1.38, 1.68, 0.77, -1.95, -1.96, -0.88, 0.3, -0.6, -0.81, -0.86, -2.04, 2.72, -0.29, -2.55, -0.22, -1.0, -1.18, -0.9, -0.97, -0.83, -0.59, -0.67, -0.91, -0.28, 0.25, -1.15, -0.14], ['459', -1.87, -0.13, 0.21, -0.09, 0.43, 0.53, 0.30411525795982913, 0.62, 0.98, 0.33, -1.62, 0.07, -0.56, 1.56, -0.15, 0.24, -1.35, -0.2, -2.86, -0.52, 0.42, -0.49, -0.45, -1.06, 1.15, 1.13, 2.0126583949931125, 1.72, 1.08, 3.23, 1.49, 1.89, 0.27, 1.44, -1.25, 1.12, 2.08, 1.16, 1.19, 0.57, 0.5, 3.2249361992161734, 0.26, -0.63, 1.48, -0.23, 0.17, -1.42, -0.27, -2.93, -0.59, 0.35, -0.56, -0.53, -1.13, 0.21, 1.1, 1.42, 0.43, 0.89, 2.13, 0.41, 0.8, -0.8, 0.36, -2.31, 0.04, 0.98, 0.07, 0.1, -0.51, 0.78, -1.21, -1.68, -1.3, -2.87, -1.73, -4.35, -2.05, -1.12, -2.01, -1.98, -2.58, 2.18, 2.68, -2.66, 0.5166982383853201, 0.4, -1.2, -0.05, -2.71, -0.37, 0.58, -0.33, -0.3, -0.91, 1.88, 0.09, -1.59, -0.44, -3.09, -0.76, 0.18, -0.72, -0.69, -1.3, 0.5, 0.09, 1.86, 1.2315981806829015, 0.82517906963434, 1.68, 1.71, 1.17, -1.52, 0.84, 1.8, 0.88, 0.91, 0.29, 0.84, 0.5830767481303673, -2.66, -0.32, 0.63, -0.28, -0.25, -0.86, 1.21, 1.49, -0.04, 1.61, 5.53, 0.21, 0.19, -4.91, 4.86, 2.44, 0.28, 0.34, -1.6, -2.35, -1.18, -1.0, 0.56, 3.63, -3.68, -3.42, 1.2132908048638529, -7.19, 2.399878357241315, 1.67, -0.82, 5.140714285714285, -7.49, -3.47, -5.08, 1.65, 3.28, 2.4, 3.37, 2.44, 2.47, 1.84, 3.49, 0.86, 0.95, 0.04, 0.07, -0.55, -0.09, -0.9, -0.87, -1.48, 0.99, 1.2, 0.82, 0.03, -0.58, 1.15, 1.26, 0.66, -4.84, 1.66, 5.05, 1.86, 0.37, 0.79, -0.61, 0.22, 2.62, 0.62, 0.46, 0.97, 1.41, 1.78, 1.9215952380952381, 1.74], ['460', -4.19, -0.21571428571428575, -0.43877828437954125, -0.5, -0.42, -0.83, -3.57, -2.0, -1.64, -2.33, -1.06, 0.43, -0.29, -0.08, 0.02726190476190476, -1.42, -1.15, -1.62, -0.96, -3.6, -2.46, -1.2269251700680273, -0.65, -1.22, -0.62, -1.69, -1.28, 1.5, 0.78, 1.0, 1.1, -0.36, -0.09, -0.57, 0.11, -2.57, -1.41, -0.09000000000000001, 0.42, -0.16, -1.47, 0.08006211180124224, -2.74, -0.72, -0.5, -0.4, -1.84, -1.57, -2.04, -1.38, -4.01, -2.87, -1.65, -0.4385714285714286, -1.63, -1.7, -2.36, -1.56, -1.06, -2.04, 0.22, 0.32, -1.13, -0.86, -1.33, -0.66, -3.32, -2.17, -0.94, -0.36, -0.92, -2.36, -2.25, 0.5202278911564625, -1.35, -1.08, -1.55, -0.88, -3.53, -2.38, -1.16, -0.57, -1.14, -1.5949404761904762, -4.44, 4.48, -2.35, -1.44, -1.18, -1.65, -0.98, -3.426255228898086, -2.48, -1.1642857142857144, -0.67, -1.1859922724755494, -3.62, -0.92, 0.27, -0.20788095238095236, 0.47, -2.21, -1.05, 0.19, 0.78, 0.21, -1.04, -0.95, -1.81, -1.11, -1.24, -0.91, -1.19, -0.48, 0.2, -2.48, -1.32, -0.08, 0.51, -0.06, -0.11, -0.72, 0.68, -2.01, -0.85, 0.4, 0.99, 0.42, -1.18, -0.4, -0.66, -1.05, -10.622047619047619, -1.11, -1.13, 1.9, -1.94, -0.94, -2.01, -0.62, -2.34, 2.21, 1.14, -2.12, -0.34, -3.37, 3.58, 3.33, -1.06, 2.89, -2.21, -0.39, 0.16, -3.53, 8.56, 2.4742857142857146, 3.6514285714285712, 2.42, -1.38, -2.67, -1.52, -0.28, 0.326625850340136, -0.26, -3.15, 1.3201587301587303, 1.19, 2.7071428571428573, 3.07, 2.48, 0.13, 1.26, 1.892857142857143, 1.27, -3.18, -3.4, -1.11, 0.59, 0.02, -1.64, -1.65, -3.33, 4.37, -2.18, -4.36, -1.67, -1.13, -1.69, -0.57, -1.61, -1.18, -0.29, -0.039047619047619046, -0.48, -1.13, -4.27, -1.43, -1.13], ['461', -0.04, -0.92, -0.1, 0.05, 0.1029790809910596, -1.18, -3.8799638336347195, -1.45, -1.79, -0.79, 0.04, 2.37, 1.42, 0.74, 0.47, -0.94, 0.22, -0.05, -0.75, -1.3, -0.62, -0.25, 0.59, 0.53, -3.0, -1.26, -0.84, 2.32, 1.38, 0.7, 0.43, -0.99, 0.18, 0.017258904144408435, -0.79, -1.34, -0.66, -0.3, 0.6388796134390452, 0.49, -2.83, -0.3891024373941227, -3.09, -0.92, -1.59, -1.85, -3.23, -2.1, -2.36, -3.04, -3.58, -2.92, -2.56, -1.74, -1.79, -0.66, -1.97, -0.35217202719021606, -1.16, -2.19, -0.67, -0.94, -2.33, -1.19, -1.45, -2.14, -2.69, -2.01, -1.65, -0.83, -0.88, -1.5, -1.53, -0.27, -1.67, -0.52, -0.79, -1.48, -2.03, -1.35, -0.99, -0.16, -0.1564403582748793, -1.03, -3.84, 3.8, -1.26, -1.41, -0.25, -0.52, -1.22, -1.76, -1.09, -0.72, 0.11, 0.06, -0.24, 0.15, 1.17, 0.9, 0.19, -0.36, 0.33, 0.69, 1.54, 1.49, -0.8, 0.16, -1.79, -1.07, -1.05, -1.12, -1.01, -0.27, -0.97, -1.52, -0.84, -0.47, 0.36, 0.31, -0.62, -0.74, -0.7, -1.25, -0.57, -0.2, 0.64, 0.58, -1.07, -0.86, -0.1, -0.92, -0.76, -0.48, -0.48, 2.01, -2.04, -1.03, -0.65, -2.1738364678879503, -1.01, 2.15, 1.06, 0.0, -0.76, -3.18, 3.04, 3.19, -1.06, 3.11, -2.14, -1.56, 0.81, -2.97, 5.62, 2.06, 3.05, 0.98, -0.05, -0.56, 0.13, 0.5, 1.34, 1.29, -3.18, 0.51, 0.69, 1.06, 1.91, 1.85, -0.18, 0.37, 1.21, 1.16, -1.84, -1.06, -0.54, 0.84, 0.79, -1.08, -1.08, -1.56, 3.31, -1.03, -3.38, -1.66, -0.61, -1.37, -0.05, -1.41, -0.85, -0.94, -0.59, -1.08, -1.32, -1.56, -1.15, -0.67], ['462', -4.7785714285714285, -0.81, -0.23877828437954127, -0.08, -0.45, -0.2, -0.79, -1.14, -0.43, -0.7946428571428571, -0.13, -0.34, 1.27, 0.67, 0.19, 0.1, 1.17, -0.34, 2.14, -0.74, -0.95, 1.75, 2.3, -0.59, 0.47, -1.6, -0.73, -0.2, 1.4, 0.8, 0.32, 0.24, 1.3, -0.21, 2.28, -0.61, -0.82, 1.89, 2.44, -0.46, 0.61, 0.16089756260587734, -0.529795918367347, 1.61, 1.01, 0.52, 0.44, 1.512857142857143, -0.01, 2.49, -0.4088095238095238, -0.62, 2.1, 2.65, -0.26, 0.0, -0.81, -1.22, 0.32, -2.11, -0.59, -1.07, -1.15, -0.1, -1.59, 0.86, -1.98, -2.19, 0.48, 1.02, -1.84, -0.08, -0.8742857142857143, -0.48, -0.56, 0.5, -1.01, 1.46, -1.4, -1.61, 1.73, 1.62, -1.25, -0.8510901360544217, -8.25, 8.24, -1.05, -0.08947959183673469, 0.98, -0.53, 1.95, -0.93, -1.14, 1.56, 2.11, -0.78, -2.63, -0.97, 1.07, -0.45, 2.04, -0.84, -1.05, 1.65, 2.2, -0.69, -0.47, -0.87, -2.35, -0.74, -1.01, -0.55, -2.01, -1.5, 0.96, -1.89, -2.1, 0.58, 1.12, -1.74, -2.55, -0.52, 2.5, -0.4, -0.61, 2.1, 2.66, -0.25, -3.84, -3.63, 0.16, -1.27, -5.24, -0.01, 0.21428571428571427, 1.08, -1.12, -0.57, -2.41, -0.81, 0.31, 1.47, 0.78, -2.2947789115646255, -0.31, -2.54, 2.46, 2.1, -0.76, 1.78, -1.45, 0.71, -0.36, -6.12, 5.23, 4.104285714285715, 6.325714285714286, -0.33, -2.94, -2.82, -3.03, -0.38, 0.16, -2.68, -2.24, -0.13, -0.22, 2.51, 3.07, 0.15, 0.09, 2.73, 3.9157142857142855, 0.37, -0.48, -0.68, -2.57, 0.54, -2.3, -0.86, -0.86, -1.12, 2.65, -2.06, -2.58, -2.18, -1.65, -3.1, -2.83, -0.46, -0.29, 0.3, 0.18, 0.0, -0.27, -3.43, -2.63, -0.82], ['463', -3.03, -0.09, 0.011221715620458745, 0.19, -2.29, -0.24158037632624055, -0.31, -0.74, -0.49, 0.33, 0.48, 1.04, 1.22, 0.88, 1.4, 0.86, 1.05, 0.35, 2.8, 2.39, 0.22733548208735893, 0.55, 1.11, 0.77, -1.06, -0.51, -0.15, 0.55, 0.74, 0.4, 0.91, 0.38, 0.57, -0.12, 2.310714285714286, 1.9, -0.29, 0.07, 0.62, 0.29, -0.38, -0.43506380078382656, -0.7, 0.18, -0.16, 0.36, -0.18, 0.02, -0.67, 1.75, 1.34, -0.84, -0.48, 0.07, -0.26, -1.0, -0.61, 0.07, -0.06, -0.88, -0.34, 0.17, -0.36, -0.17, -0.7573949338599383, 1.56, 1.15, -1.02, -0.67, -0.12, -0.44, -1.05, -0.54, 0.51, -0.02, 0.18, -0.52, 1.91, 1.49, -0.68, -0.33, 0.23, -0.1, -0.44, -2.17, 2.13, -1.05, -0.53, -0.34, -1.03, 1.39, 0.98, -1.19, -0.83, -0.29, -0.61, -0.32, -0.52, 0.2, -0.5, 1.93, 2.132857142857143, -0.66, -0.31, 0.25, -0.08, -0.01, -0.59, -1.68, -0.29, -0.52482093036566, -0.09, -0.72, -0.6886530612244898, 1.73, 1.32, -0.86, -0.5, 0.05, -0.28, -0.15346392892821453, -0.02, 2.693685580292723, 2.02, -0.16, 0.19, 0.75, 0.42, -1.73, -1.7972380952380953, 0.41, -0.86, -0.722047619047619, -0.13, -0.07, 0.3, -0.32, -0.14, -0.26, -1.37, 4.14, 0.61, 0.3, -1.49, -0.11, -0.88, 0.92, 0.9, -0.28, 0.46, -0.63, -1.92, 0.99, -2.11, -0.81, 1.46, 2.12, -3.98, -2.4, -0.4, -2.54, -2.19, -1.65, -1.97, -0.9, -2.01, -2.14, -1.79, -1.249142857142857, -0.9314285714285715, 0.14, 0.36, 0.91, 0.58, -0.46, -0.32, -0.22, 0.55, 0.22, -0.31, -0.39, -0.5574239503761216, 0.22, -1.35, -0.6, -1.2, -0.59, -0.77, -0.25721314850306837, -0.2999225974772193, -0.07, 0.17, -0.55, 0.35, -0.354042472976186, -2.28, -0.89, -0.75], ['464', -1.13, 1.35, 0.42122171562045874, 0.09, 0.6629790809910596, 0.67, 1.5641152579598292, 0.7, 1.0593780543870106, 0.59, -0.24, -0.19, -1.28, 1.12, -0.74, 0.3, -0.59, 0.24, -1.27, -0.75, 0.28, 0.48, -0.44, 0.78, 1.24, 0.52, 0.83, 0.05, -1.05, 1.36, -0.4421800287049088, 0.54, -0.35, 0.48, -1.03, -0.51, 0.52, 0.72, -0.2, 1.02, 1.58, 1.9849361992161734, 0.78, -1.1, 1.31, -0.47918497042472347, 0.49, -0.4, 0.43, -1.08, -0.56, 0.498065468086443, 0.67, -0.25, 0.97, 0.94, 1.45, 1.02, 0.69, 1.89, 2.43, 0.55, 1.61, 0.7, 1.54, 0.02, 0.54, 1.58, 1.79, 0.85, 2.09, 0.55, -0.53, -1.84, -0.81, -1.69, -0.87, -2.36, -1.84, -0.83, -0.63, -1.54, -0.33, 1.17, 2.83, -2.89, 1.34, 1.05, 0.15, 0.99, -0.53, -0.01, 1.02, 1.23, 0.3, 1.5840077275244506, -0.34, 0.28, -0.89, -0.06, -1.57, -1.05, -0.03, 0.18, -0.74, 0.48, 0.43, 0.32, 1.74, 0.8, 1.06, 0.5, 1.18, 0.9665993906886764, -0.68, -0.16, 0.87, 1.08, 0.15, 1.38, 0.27, 0.35, -1.5, -0.98, 0.04, 0.24, -0.68, 0.54, 1.2089583699631243, 1.37, 0.27603717887804047, 0.6, -1.02, 0.23, 0.41, -1.0, 0.95, 0.5, 0.8240662734668153, 0.56, -2.72, -1.56, -0.82, -0.53, 0.41, 2.24, -2.33, -2.44, 0.8, -1.51, 1.56, -0.32, 0.19, 3.46, -1.89, -2.37, -3.48, 2.74, 1.88, 0.53, 1.56, 1.811610544217687, 0.84, 2.08, 2.37, 1.34, 1.03, 1.24, 0.31, 1.54, 0.31, 0.2, -0.71, 0.51, 0.98, 0.79, 0.1, -0.92, 0.3, 0.82, 0.76, 0.63, -0.39, 1.25, 0.42, 0.93, 1.77, 1.03, 1.23, 1.0600774025227806, 0.53, 0.67, 1.1, 1.29, -0.2, 2.13, 3.13, -0.82], ['465', 1.49, -1.57, 0.2912217156204588, -0.28, 0.97, 0.7384196236737595, 2.2141152579598296, 0.8, 1.29, 1.94, 0.78, 0.2393248299319728, 1.48, 1.59, 0.93, 2.01, 0.51, 1.83, -0.12, -0.32, 2.0, 2.81, 0.75, 0.67, 0.81, 1.62, 1.1826583949931124, -0.54, 0.7, 0.81, 0.15, 1.22, -0.26, 1.05, -0.89, -1.09, 1.22, 2.02, -0.03, -0.11, 1.29, 2.61, 1.7, 1.25, 1.36, 0.69, 1.77, 0.28, 1.6, -0.35, -0.55, 1.77, 2.57, 0.52, 0.44, 0.1, 0.15, 0.81, 0.8, 0.44, 0.1, -0.55, 0.52, -0.96, 0.34, -1.59, -1.7797619047619049, 0.51, 1.31, -0.72, -0.8, 0.9, 0.34, -0.65, 0.41, -1.06, 0.24, -1.69, -1.88, 0.41, 1.2, -0.83, -0.91, 1.84, 2.79, -2.72, 1.0, 1.07, -0.41, 0.9, -1.04, -1.24, 1.07, 1.87, -0.17, -0.26, 0.98, -0.07, -1.46, -0.17, -2.0544149659863944, -2.29, 0.0, 0.79, -1.23, -1.31, -0.02, -0.11, 1.57, 0.8715981806829014, 0.93, 0.8, 1.41, 1.31, -0.64, -0.83, 1.48, 2.28, 0.23, 0.15, -0.82, 0.15307674813036726, -1.92, -2.12, 0.17, 0.96, -1.06, -1.14, 1.82, 1.43, -0.59, 1.34, 3.09, 0.14, -0.1, -2.19, 2.15, 1.09, -0.69, 1.74, -4.44, -1.65, -0.85, 0.74, -0.08, 2.47, -2.46, -2.45, 0.863290804863853, -3.27, 1.6998783572413152, 2.46, -1.27, 4.26, -1.42, -2.9, -4.24, 4.62, 2.06, -0.2, 2.13, 2.94, 0.88, 0.79, 2.4608051948051948, 2.27, 2.33, 3.14, 1.08, 1.0, -0.07, 0.8788785911064217, -1.23, -1.31, 1.27, 1.21, -0.85, -2.0, -2.08, 0.78, 0.93, 0.72, 0.84, 1.95, -0.73, 1.3472638105244332, 1.78, 1.18, -0.08, 1.35, 0.87, -0.10470204795204777, -0.42, 0.09, 1.26, 2.12, 3.04, 1.66], ['466', 8.66, 0.95, 0.26122171562045876, -0.12, 3.89, 1.85, 2.3041152579598294, 3.68, 3.47, 5.28, -0.16, 3.53, 2.79, 0.41, 2.24, 2.38, 2.23, 4.62, 4.66, -1.35, 6.75, 3.06, 3.18, 3.59, 3.68, 2.83, 5.482658394993113, 3.7, 2.960119047619048, 0.57, 2.457819971295091, 2.55, 2.4, 4.79, 4.83, -1.19, 6.92, 3.23, 3.34, 3.75, 2.32, 7.524936199216174, 1.68, -0.72, -3.02, -1.25, -1.11, -1.26, 1.05, 1.09, -4.71, 3.11, -0.46, -0.34, 0.05, 2.37, 2.67, 3.3, 2.2, 2.42, -2.32, -0.54, -0.39, -0.54, 1.78, 1.82, -4.02, 3.86, 0.32965816326530617, 0.38, 0.78, 4.03, 4.85, 1.82, 1.97, 1.82, 4.2, 4.24, -1.75, 6.761853741496599, 2.8671428571428574, 2.76, 3.16, 5.92, 6.01, -5.82, 3.0066982383853205, 0.14052040816326533, -0.01, 2.33, 2.37, -3.5, 4.42, 0.81, 0.92, 1.3740077275244507, 3.09, 2.83, -0.15, 2.19, 2.23, -3.64, 4.27, 0.66, 0.78, 1.18, 0.73, 2.89, 3.94, 2.11, 2.0, 2.31, 2.98, 2.4765993906886763, 2.38, -3.5, 4.42, 0.81, 0.93, 1.32, 1.89, 0.63, 0.04, -5.7, 2.04, -1.49, -1.38, -0.99, 2.0, 2.11, 0.03, 2.76, 9.27, 0.1, 0.02, -5.32, 5.29, 2.65, 0.28, 4.43, -13.65, -4.17, -2.11, 4.17, 1.18, 6.19, -6.22, -6.34, 2.12, -7.91, 4.13, 3.08, -1.52, 8.85, -8.74, -5.9, -8.74, 12.95, 0.59, -5.74, 2.0, -1.53, -1.42, -1.03, 6.41, 6.71, 8.21, 4.47, 4.59, 5.0, -1.38, -3.46, -3.35, -2.97, 3.51, 4.13, 2.15, 0.11, 0.51, 1.98, 2.334396301275291, 3.64, -5.34, 3.8, 5.39, 2.5218948994148556, 2.33, 2.03, 0.39, 3.08, 2.54, 1.55, 0.35, 1.55, 1.7159575270238139, 3.71, 3.53, 3.59], ['467', -8.035714285714285, -0.34, 0.11015289830927054, 0.2, -1.12, -0.18, -1.13, -1.74, -0.36, -1.92, -1.09, -2.08, -0.32, -0.89, -0.99, 1.8810714285714285, -1.3, -1.85, -3.41, 0.39, -1.87, -1.81, -1.29, -2.13, -0.8, -1.55, -0.8073416050068876, -1.0, 0.78, 0.2, 0.1, 3.0, -0.21, -0.6527410958555916, -2.35, 1.5, -0.715546329921431, -0.73, -0.2, -1.06, -0.08, -0.48, 0.17, 1.8, 1.21, 1.12, 4.05, 0.8, 0.24, -1.36, 2.53, 0.21, 0.28, 0.81, -0.05, -1.68, -0.86, -1.36, 0.0, -1.6, -0.58, -0.67, 2.21, -0.98, -1.53, -3.1, 0.71, -1.56, -1.5, -0.97, -1.82, -3.2, -1.03, -0.1, 3.236658163265306, -0.41, -0.96, -2.54, 1.3, -0.99, -0.93, -0.4, -1.25, -0.56, -1.94, 1.92, -0.94, 2.9, -0.31, -0.87, -2.45, 1.4, -0.89, -0.83, -0.3, -1.16, -4.73, -3.73, -3.12, -3.66, -5.19, -1.46, -3.68, -3.593605339105339, -3.11, -3.94, -0.07, -3.81, 0.0, -0.43, -0.53, -0.33, -0.5581905235138708, -0.56, -2.14, 1.71, -0.58, -0.52, 0.01, -0.85, -0.11, -0.07, -1.59, 2.28, -0.03, 0.04, 0.57, -0.29, -1.54, -0.95, 0.44, -0.6, -14.15, 0.04, 0.11, 0.4, -0.4, -0.2, -0.29, -1.21, 4.56, 0.87, 0.46, -4.385357142857143, 0.03, -1.45, 1.46, 1.37, -0.41, 0.7, -0.89, -2.76, 1.36, -1.82, 0.0, 1.26, 1.83, -4.42, 1.55, 3.94, 1.59, 1.701610544217687, 2.2, 1.32, -1.3, -2.3, -2.26, -2.2, -1.67, -2.52, -0.04, 0.06, 0.6, -0.26, -0.34, -0.36, -0.022725315092565576, 0.53, -0.33, -0.41, -0.49, -1.43, -0.32, 0.04033326278406317, 0.28, -1.75, -1.64, -0.64, -0.86, -0.67, -0.56, 0.15, 0.25, 0.07, 0.305957527023814, -2.75, -2.18, -0.36], ['468', 1.49, 0.65, -0.4, 0.21, 0.2929790809910596, -0.22, -2.91, 0.17, -0.02, 0.86, 0.4, 1.34, 0.45, 1.12, 0.76, -0.08, 0.69, 0.73, 5.22, -0.52, 2.21, -0.02, 0.47, 0.68, 0.09, 0.33, 0.46, 0.94, 0.05, 0.72, 0.36, -0.47, 0.3, 0.34, 4.81, -0.91, 1.8, -0.41, 0.08, 0.28, -0.26, -1.3350638007838267, -0.47, -0.88, -0.21, -0.57, -1.4, -0.64, -0.6, 3.83, -1.83, 0.86, -1.34, -0.86, -0.65, 0.64, -0.74, 0.07, -0.3, 0.41, 0.67, 0.32, -0.52, 0.25, 0.29, 4.76, -0.9597619047619047, 1.75, -0.46, 0.03, 0.23, 0.02, -0.26, -0.36, -1.19, -0.42, -0.38, 4.307476448155019, -1.62, 1.07, -1.13, -0.64, -0.44, 0.15, 1.12, -1.02, 0.1, -0.83, -0.07, 0.5971428571428571, 4.43, -1.27, 1.43, -0.77, -0.29, -0.08, 1.5, 0.94, 0.77, 0.81, 5.3, -0.44, 2.28, 0.06, 0.55, 0.75, 0.22, 1.1, 1.73, 0.07, 0.14, 0.09567351865003196, 0.1709570400359874, 0.04, 4.5, -1.2, 1.5, -0.7, -0.22, -0.02, 1.01, 0.12, 4.46, -1.24, 1.46, -0.74, -0.26, -0.06, 0.14, 0.0, 0.58, 0.543186783623568, 4.677738095238095, 0.13, 0.07, 0.68, -0.71, -0.36, 0.88, 0.08, -2.62, -0.17, -0.07, 0.83, 0.29, -0.02, -0.18, -0.24, 0.09, 0.99, 0.07, -1.14, 0.51, 0.7963956916099773, 5.18, -0.38, -0.51, 2.72, -4.15, -5.45, -2.87, -4.98, -4.52, -4.32, 0.41316789956075695, 1.38, 2.73, 0.5, 0.99, 1.2, -1.32, -2.17, -1.7, -1.49, -0.03, 0.06, 0.88, 0.49, 0.7622487553150162, 0.07, 0.12, 0.18, 2.44, 1.37, -2.44, 0.23, -0.11, 0.39, 0.21, 0.12, -0.41, -0.4, 0.72, 0.74, 0.18, 0.08, -0.13, -0.05], ['469', -4.6, -0.68, 0.0, 0.14, -1.0, -0.53, -0.71, -1.57, -0.68, -3.41, -1.99, -3.8, -2.15, -1.53, -1.86, -2.97, -2.4, -3.57, -1.15, -1.67, -3.54, -2.13, -2.235694768399324, -3.09, -0.9414063389924735, -1.44, -1.45, -1.85, -0.17, 0.46, 0.12, -1.0066496598639456, -0.42, -1.62, 0.85, 0.32, -1.59, -0.15, -0.35, -1.12, -0.48253157464678914, -1.41, 0.4, 1.71, 2.35, 2.01, 0.86, 1.45, 0.24, 2.75, 2.21, 0.298065468086443, 1.73, 1.53, 0.74, -0.5, -0.65, -0.13217202719021603, -1.0, -1.29, 0.63, 0.29, -0.84, -0.26, -1.45, 1.02, 0.49, -1.42, 0.02, -0.18, -0.96, -1.26, -1.91, -0.34, -1.46, -0.88, -2.07, 0.38, -0.14, -2.04, -0.61, -0.81, -1.58, -1.32, -2.92, 2.99, -1.5433017616146798, -1.13, -0.55, -1.74, 0.72, 0.2, -1.71, -0.28, -0.48, -1.25, -1.73, -0.45, 0.59, -0.62, 1.87, 1.34, -0.59, 0.86, 0.66, -0.12, 0.22, -0.44, -1.79, -0.69, -0.87, -0.534326481349968, -1.0390429599640125, -1.2, 1.28, 0.7505357142857143, -1.17, 0.27, 0.07, -0.7, -1.24, 0.16, 2.51, 1.97, 0.03, 1.49, 1.29, 0.5, -1.49, -1.63, -0.16, -1.03, -5.23, -0.2196768707482993, -0.17, 0.26, -0.28, -0.13, -0.7, -2.38, 3.49, 1.39, 0.72, -2.33, -0.15, -2.2, 2.21, 2.29, -0.7, 0.63, -1.4, -0.48, 0.23, -3.129285714285714, -16.57, 2.05, 3.13, -3.64, -2.28, -0.52, -2.42, -0.99, -1.19, -1.96, -2.06, -1.77, -1.9, -0.47, -0.67, -1.44, 0.14, 1.46, 1.26, 0.47, -0.71, -1.12, -1.31, -0.2, -0.8977512446849837, -0.7, -0.78, -1.51, 3.27, -1.49, -3.37, -1.6981051005851444, -2.33, -1.11, -0.77, -1.28, -0.17, 0.09, -0.29, -0.12, -0.34, -3.17, -3.38, -0.63], ['470', -0.55, 1.15, 0.011221715620458745, -0.07, 0.15, 0.03, 1.62, -0.01, 0.22, 0.4, 0.23, -0.28, -0.36, 0.77, 0.37, 0.87, 0.08, 0.3, 1.8, 0.28, 0.16, -0.4, 0.18, -0.26, 0.53, -0.07, 0.16, -0.52, -0.59, 0.54, 0.14, 0.63, -0.15, 0.07, 1.57, 0.04, -0.07, -0.64, 0.03887961343904518, -0.5, -0.36, -0.34, 0.68, -0.07, 1.06, 0.66, 1.15, 0.37, 0.59, 2.09, 0.56, 0.45, -0.12, 0.46, 0.02, -0.26, -0.65, -2.41, -0.43, 0.76, 1.13, 0.73, 1.23, 0.44, 0.66, 2.17, 0.64, 0.52, -0.05, 0.54, 0.09, -0.48, -0.37, -0.4, 0.09, -0.69, -0.47, 1.02, -0.49, -0.61, -1.17, -0.59, -1.03, 0.15, 0.99, -0.98, 0.03, 0.5, -0.29, -0.07, 1.43, -0.09, -0.21, -0.77, -0.19, -0.63, -1.54, -0.46, -0.78, -0.56, 0.93, -0.58, -0.7, -1.26, -0.68, -1.12, 0.1, -0.41, 1.74, 0.28, 0.19, 0.4, 0.32, 0.22, 1.72, 0.2, 0.2557782534925394, -0.49, 0.09, -0.35, 0.9765360710717854, 0.1, 1.5, -0.02, 0.038603019995877313, -0.7, -0.12, -0.56, 0.38, 0.13, 0.04, 0.43, -4.45, -0.06, -0.11, -0.42, 0.42, 0.21, 0.12, 0.82, -0.21948175112272847, -0.54, -0.29, -0.3, 0.25, 0.81, -0.79, -0.86, 0.26, -0.59, 0.54, 0.78, -0.42, 0.95, -3.77, -0.68, -0.93, 0.28, -1.38, -1.5, -1.61, -2.17, -1.6, -2.03, 0.82, 0.12, -0.12, -0.68, -0.1, -0.54, 0.24, -0.57, 0.01, -0.43, 0.2227953514739229, 0.08, 0.8972746849074344, 0.58, 0.14, 0.27, 0.29, 0.04, -2.13, 1.54, 2.18, 0.13, 0.36, 0.22043171114599686, -0.36721314850306835, 0.27, 0.07, 0.83, 0.18, -0.22, 0.67, -0.13, 0.89, 0.48], ['471', -1.75, 0.02, 0.20015289830927055, -0.04, -1.0, 1.03, 0.9641152579598291, 0.9117205965359587, 1.6, 1.14, -0.59, 0.08, 0.69, 0.77, 0.08, 1.78, 0.18, 0.56, -0.24, 0.76, 1.697335482087359, 0.5, 0.74, 0.31, 2.18, 0.96, 1.74, 0.67, 1.28, 1.37, 0.67, 2.38, 0.77, 1.16, 0.36, 1.36, 2.27, 1.1, 1.34, 0.91, 1.31, 2.44, 1.06, 0.61, 0.69, 0.0, 1.7, 0.1, 0.48, -0.21286444351387962, 0.69, 1.59, 0.43, 0.67, 0.23, 0.99, 1.33, 1.0, 1.54, 0.45, 0.08, -0.6, 1.08, -0.51, -0.13, -0.92, 0.07, 0.97, -0.18, 0.06, -0.37, 0.99, 0.37, -0.68, 1.0, -0.59, -0.2, -1.0, -0.01, 0.89, -0.26, -0.02, -0.45, 2.02, 0.9, -0.91, 1.06, 1.7, 0.1, 0.48, -0.32, 0.68, 1.58, 0.42, 0.67, 0.23, 0.35, -0.63, -1.57, -1.19, -1.98, -1.0, -0.11, -1.25, -1.01, -1.44, 0.6, -0.73, 0.16, 0.85, 0.78, 0.95, 0.96, 0.38, -0.41, 0.58, 1.49, 0.33, 0.57, 0.13, 0.63, 0.58, -0.79, 0.2, 1.1, -0.06, 0.18, -0.25, 0.29, 0.87, 0.17, 0.89, 0.58, 0.33, 0.42, -2.36, 2.39, 1.19, 0.55, 0.31, -0.73, -1.66, -0.88, -0.85, 0.44, 2.61, -2.62, -2.56, 0.86, -3.49, 1.7, 0.11, 0.03476526428424678, 2.88, -8.55, -1.96, -2.86, 0.69, 1.38, 1.0, 1.91, 0.74, 0.98, 0.55, 2.66, 0.38, 0.9, -0.26, -0.02, -0.45, -0.52, -1.14, -0.9, -1.33, 1.682795351473923, 1.65, 0.63, 0.24, -0.19, 0.87, 0.89, 0.89, -4.25, 0.5, 4.33, 1.16, 1.04, 0.39, -0.43, 1.56, 1.18, 0.55, 0.15, 0.37, 0.83, 1.76, 0.84, 0.66], ['472', -6.98, 0.13, -0.25, 0.11, -1.04, -1.5, -1.29, -2.25, -2.48, -2.24, 0.66, -1.02, -0.35608673487915105, -0.41, 0.49, -1.3, -0.34, -1.48, -3.86, 0.49, -3.162664517912641, 0.39, -0.3, -0.5, -2.28, -2.45, -2.88, -1.66, -1.07, -1.06, -0.16, -1.94, -0.99, -2.12, -4.04429761904762, -0.17, -3.83, -0.27, -0.96, -1.15, -2.7, -3.3, -1.24, 0.6, 0.61, 1.52, -0.28, 0.68, -0.47, -2.87, 1.52, -2.21, 1.42, 0.72, 0.52, -0.8199371536943234, -2.44, -3.1, -3.01, -1.83, 0.01, 0.92, -0.88, 0.08, -1.06, -3.45, 0.92, -2.79, 0.81, 0.12, -0.08, -3.12, -1.84, 0.91, -0.89, 0.07, -1.07, -3.47, 0.9, -2.8, 0.8, 0.11, -0.03644035827487928, -3.33, -5.78, 5.83, -2.72, -1.78, -0.83, -1.96, -4.33, 0.0, -3.67, -0.1, -0.79, -0.99, -2.34, -0.8826334687834371, 0.97, -0.19, -2.6, 1.81, -1.93, 1.7, 1.0, 0.81, -0.67, -0.93, -2.61, -1.54, -1.56, -1.54, -1.8381905235138707, -1.14, -3.53, 0.83, -2.87, 0.73, 0.04, -0.16, -2.52, -0.77, -2.42, 2.0, -1.75, 1.89, 1.19, 0.99, -2.31, -2.26, -0.04, -1.596813216376432, -4.62, -0.22, -0.16, 2.76, -2.78, -1.4, -1.26, -1.88, 5.27, 3.07, 1.55, -3.54, -0.93, -4.56, 4.63, 4.56, -1.466709195136147, 4.25, -3.07, -1.57, 0.77, -5.72, 8.58, 3.85, 5.71, -5.292869047619047, 1.68, 4.52, 0.69, 4.42, 3.7, 3.5, -4.52, -2.72, -3.67, -0.1, -0.79, -0.98, 0.99, 3.798878591106422, 2.99, 2.79, -2.6, -3.05, -2.62, -0.69, -0.88, -1.53, -1.61, -2.2, 4.16, -2.53, -4.2, -1.42, -2.02, -1.94, -0.2, -1.68, -1.23, -0.99, -0.38, -1.75, -1.75, -1.29, -1.86, -1.85], ['473', 2.3, 0.25, 0.18122171562045875, -0.14, 0.3329790809910596, 0.3, 0.97, 0.37, -0.35, 2.89, 3.56, 2.48, 2.14, 3.39, 1.94, 2.29, 1.14, 2.66, 2.44, 2.41, 1.87, 2.18, 1.644305231600676, 2.15, 0.12, 0.49, -0.65, -1.04, -1.37, -0.17, -1.56, -1.23, -2.33, -0.87, -1.08, -1.11, -1.63, -1.33, -1.94, -1.36, 0.17, -2.5050638007838266, 0.4, -0.33, 1.057875394446823, -0.52, -0.19, -1.31, 0.18, -0.04, -0.07, -0.5803452707629391, -0.29, -0.91, -0.32, 0.0, -0.24, 0.13, -0.24, 0.73, 1.22, -0.2, 0.14, -0.98, 0.51, 0.29, 0.26, -0.26, 0.04, -0.58, 0.01, 0.23, -0.48, -1.4, -1.06, -2.17, -0.71, -0.92, -0.95, -1.47, -1.17, -1.78, -1.2, -1.08, 3.49, -3.53, 0.93, 0.34, -0.78, 0.7, 0.49, 0.46, -0.07, 0.24, -0.39, 0.21, -0.04, 0.59, -1.12, 0.36, 0.15, 0.12, -0.41, -0.1, -0.72, -0.13, 0.28, 0.63, 3.6, 0.61, 0.72, 0.56, 1.73, 1.5, 1.28, 1.25, 0.72, 1.03, 0.4, 1.0585846838830657, 0.9265360710717855, 0.27307674813036725, 0.04368558029272332, -0.24, -0.77, -0.46, -1.08, -0.49, 2.0189583699631246, 1.98, -0.19396282112195956, 1.17, -0.29, 0.26, 0.13, -1.05, 1.03, 0.5788101710076211, 0.43, 0.52, -0.88, -1.3, -0.6, 1.25, 0.39, 1.8914761904761903, -1.9, -1.8, 0.6, -1.55, 1.24, 0.92, -0.5, 5.09, -3.79, -3.43, -5.18, 0.9, 0.44, -0.03, -0.55, -0.25, -0.87, -0.28, 1.79, 0.47, -0.38580741107631855, -0.22, -0.84, -0.25, 1.0, 0.31, -0.32, 0.28, -0.36, -0.76, 0.69, -0.62, -0.03, 0.59, 0.71, 0.43, -3.95, 2.62, 3.85, 0.4918948994148555, 0.54, 1.32, 0.6, 0.7200774025227806, 0.52, 0.3, 0.43, 0.42, 0.72, 2.86, 1.38, 1.25], ['474', -0.72, 0.41, 0.12, -0.1, 0.11, 0.1484196236737595, 0.24411525795982916, 0.09, -0.16, -0.08, 0.19, 0.05, 0.61, 0.67, -0.56, -0.14, -0.72, -0.1, 1.35, -0.66, -0.28, -0.53, -1.22, -0.48, -0.91, 0.36, -0.27, -0.14, 0.41, 0.48, -0.75, -0.33, -0.91, -0.29, 1.16, -0.85, -0.47, -0.72, -1.41, -0.67, 0.39, -0.38, -0.13, 0.56, 0.63, -0.6, -0.18, -0.77, -0.15, 1.3, -0.71, -0.301934531913557, -0.58, -1.2357142857142858, -0.53, 6.07, 0.42, 0.017827972809783946, 0.05, -0.68, 0.07, -1.15, -0.74, -1.32, -0.7, 0.74, -1.26, -0.88, -1.13, -1.82, -1.08, -0.41, -0.75, -1.22, -0.8, -1.38, -0.77, 0.67, -1.33, -0.95, -1.19, -1.88, -1.15, -0.23, 2.8, -2.83, 0.48, 0.42, -0.16, 0.46, 1.92, -0.11, 0.28, 0.03, -0.67, 0.07, 0.0, 0.06, -0.58, 0.03, 1.49, -0.53, -0.15, -0.39, -1.09, -0.35, -0.04, 0.07, 0.76, 0.38, 0.46, 0.29567351865003194, 0.64, 0.62, 2.09, 0.06, 0.44, 0.19, -0.51, 0.24, 0.35, 0.07307674813036727, 1.46, -0.56, -0.17043764172335601, -0.42, -1.12, -0.38, 0.92, 1.16, -0.09, 0.53, 0.01, 0.05, 0.04, -1.06, 1.1417201258125629, 0.51, 0.16, -0.18, -1.18, -0.75, -0.36, -0.35, -0.57, 1.14, -1.16, -1.12, 0.37, -1.55, 0.76, 0.83, -0.41, 1.91, -4.38, -1.29, -1.98, 1.23, -1.41, -1.99, -1.61, -1.86, -2.54, -1.6442382871563543, 1.12, 0.59, 0.39, 0.14, -0.56, 0.18, 0.2, -0.25, -0.94, -0.2, -0.1, -0.06, 0.45, -0.7, 0.04, 0.37, 0.42, 0.20257604962387837, -2.05, 0.8, 2.12, 0.2, 0.83, 1.16, 0.75, 0.58, 0.59, -0.67, -1.04, -0.23, 0.41, 0.29, 0.85, 0.13], ['475', -4.772857142857143, -0.07, -0.04, 0.18, -1.52, -1.12, 0.5, -1.29, -0.63, -1.04, 0.61, -1.8, -0.58, 0.55, 0.39, 0.42, 0.29, -0.85, 2.45, 2.3, -1.32, -1.04, 0.4, 0.26, -1.83, -1.35, -1.64, -2.39, -1.18, -0.06, -0.22, -0.19, -0.31, -1.45, 1.83, 1.67, -1.92, -1.64, -0.21, -0.35, -1.06, -0.19, 0.7702040816326531, 1.24, 2.39, 2.23, 2.26, 2.13, 0.96, 4.33, 4.17, 0.48, 0.77, 2.24, 2.1, -0.57, -0.5, -0.84, -1.25, -0.46, 1.14, 0.98, 1.0, 0.88, -0.27, 3.05, 2.89, -0.75, -0.46, 0.99, 0.85, -1.31, -1.58, -0.16, -0.13, -0.25, -1.39, 1.89, 1.74, -1.86, -1.58, -0.15, -0.29, -1.04, -3.71, 3.73, -1.43, 0.03, -0.1, -1.24, 2.05, 1.9, -1.71, -1.43, 0.01, -0.13, -3.54, -1.45, -0.12, -1.26, 2.02, 1.87, -1.73, -1.45, -0.02, -0.16, 0.061141873999016993, -1.5, -0.31, -1.09, -0.93, -1.24, -1.33, -1.0034006093113235, 2.15, 1.99, -1.61, -1.33, 0.11, -0.03, -0.08, -0.19, 3.33, 3.17, -0.48, -0.19, 1.26, 1.12, -1.53, -1.16, 0.35, -0.99, -10.61, -0.03, 0.14, 3.65, -3.63, -1.83, -0.21, -2.27, 6.38, 2.19, 1.1, -2.3747789115646256, -0.55, -3.35, 3.21, 3.33, -1.1, 5.45, -2.18, -1.22, 0.58, -3.89, 2.26, 2.57, 3.83, -6.28, -3.41, -0.15, -3.68, -3.41, -2.0, -2.14, -3.26, -3.26, -3.54, -3.26, -1.85, -1.99, 0.29, 0.29, 1.75, 1.6, -0.61, -1.07, 0.0, 1.46, 1.32, -1.07, -1.09, -1.35, 0.95, -0.39, -1.17, -0.96, -0.56, -1.44, -0.14, -1.09, -1.56, -0.32, 0.12022448979591838, -1.03, -1.3, -0.66, -0.37, -1.36], ['476', 5.09, 0.8, 0.011221715620458745, -0.1, 0.64, 0.56, 0.0, 1.4, 0.54, -0.03, -0.36, 0.801934498041641, -1.35, -2.18, -1.97, -0.84, -0.22, -0.22, 1.57, -0.8, 0.48, -0.18, -0.6, 0.03, 2.0, 1.49, 0.33, 0.96, -1.0, -1.83, -1.62, -0.49, 0.13, 0.13, 1.93, -0.45, 0.84, 0.18, -0.25, 0.38, 0.52, 1.77, -0.62, -1.94, -2.76, -2.55, -1.43, -0.82, -0.82, 0.971652133580705, -1.39, -0.12, -0.78, -1.19, -0.57, 1.11, 1.01, 0.15, 0.83, 1.34, -0.84, -0.62, 0.52, 1.15, 1.14, 2.96, 0.56, 1.86, 1.19, 0.76, 1.4, 1.0, 2.2, 0.22, 1.37, 2.0, 2.0, 3.83, 1.41, 2.72, 2.04, 1.61, 2.26, 0.87, 1.26, -1.29, 1.98, 1.15, 1.78, 1.78, 3.61, 1.19, 2.5, 1.82, 1.39, 2.04, 3.92, 0.82, 0.63, 0.62, 2.43, 0.04, 1.33, 0.67, 0.24, 0.88, 0.26, 0.9593682032253462, -0.73, 0.53, 0.52, 0.51, 0.19, 0.0, 1.8, -0.58, 0.7, 0.04, -0.38, 0.25, 0.11, 0.2, 1.8, -0.58, 0.7, 0.04, -0.38, 0.25, 0.38, 0.0, 0.12, 0.22, 11.79, 0.02, -0.02, -1.62, 1.63, 0.82, -0.06, 1.3661635321120496, -1.45, -1.02, -0.55, 2.51, 0.2, 1.61, -1.62, -1.55, 0.54, -2.4, 1.06, 0.26, -0.055234735715753214, 0.64, -3.65, -0.44, -0.61, 1.47, -1.57, -2.33, -1.07, -1.72, -2.14, -1.52, 1.51, 0.78, 1.29, 0.62, 0.2, 0.83, -0.5, -0.66, -1.07, -0.45, 0.57, 0.72, 0.15, -0.42, 0.21, 0.55, 0.47, 1.4425760496238782, -1.69, -0.68, 1.67, 1.2, 1.05, 0.58, 0.63, 0.34, 0.81, 0.19, 0.08, 0.59, -0.06, 3.63, 1.42, -0.28], ['477', -1.49, 0.06, 0.05122171562045875, 0.05, -0.14, 0.82, 1.79, 0.29, 1.26, 1.2, 0.3, -0.18, 0.64, 0.47, 1.15, 1.41, 0.25, 1.23, 0.1, 1.17, 1.1, 0.31, 0.32, 0.76, 1.67, 0.14, 0.9, -0.48, 0.33, 0.17, 0.85, 1.1, -0.05, 0.92, -0.2, 0.87, 0.8, 0.01, 0.02, 0.45, -0.86, 1.9700621118012422, 1.38, 0.81, 0.65, 1.33, 1.59, 0.43, 1.4, 0.28, 1.35, 1.28, 0.49, 0.5, 0.94, 0.85, 0.51, 0.52, 0.78, 0.56, -0.17, 0.51, 0.77, -0.38, 0.59, -0.53, 0.6539757335335068, 0.46, -0.32, -0.32, 0.12, 0.76, 0.73, 0.68, 0.93, -0.22, 0.75, -0.37, 0.7, 0.63, -0.16, -0.15, 0.29, 1.61, 2.34, -2.24, 0.05, 0.3480874332127649, -0.89, 0.08, -1.04, 0.2137447711019141, -0.04, -0.83, -0.82, -0.39, -0.34, -0.2, -1.14, -0.18, -1.29, -0.23, -0.3, -1.08, -1.07, -0.64, 0.04, -0.17, 0.89, 0.73, 0.71, 0.76, 0.9509570400359874, 0.97, -0.14984126984126983, 0.91, 0.85, 0.06, 0.07, 0.5585846838830657, 0.78, -0.02, -1.11, -0.05, -0.12, -0.9, -0.9, -0.46, 0.86, 0.83, 0.04, 0.8, -0.84, 0.11, 0.0, -1.62, 1.63, 0.82, 0.54, 0.34, -0.01, -1.4, -0.69, -0.75, 0.75, 2.18, -2.12, -2.17, 0.74, -2.43, 1.46, -0.39, 0.19, 2.82, -4.59, -1.86, -2.77, 0.0, 1.1, 1.07, 1.0, 0.21, 0.22, 0.66, 2.16, 0.03, -0.07, -0.85, -0.84, -0.41, 0.1, -0.78, -0.78, -0.34, 1.26, 1.32, 0.89, 0.01, 0.44, 0.73, 0.75, 0.31, -2.73, 1.0501996269574994, 2.69, 1.19, 0.74, 0.88, 0.44, 0.67, 1.06, 0.41, 0.93, 0.39, 0.44, 0.0, 1.33, -0.01], ['478', 3.22, -0.08, -0.17877828437954127, 0.08, -0.33, -0.6115803763262405, -0.71, -1.88, -1.79, -1.61, 1.58, -0.41, -0.11, -0.08, 0.38, -3.39, -0.41, -1.89, -2.3, -1.47, -2.63, -1.14, 0.26, -0.75, -1.85, -0.61, -3.14, -1.96, -1.66, -1.63, -1.18, -4.89, -1.96, -3.42, -3.81, -3.0, -4.149239316239316, -2.68, -1.3, -2.246158276802161, -1.66, -2.3550638007838267, -1.2, 0.3, 0.34, 0.8, -2.99, 0.0, -1.169454081632653, -1.89, -1.06, -2.23, -0.73, 0.67, -0.34, -0.9299371536943234, -1.75, -1.5321720271902162, -1.0, -1.5, 0.04, 0.49, -3.28, -0.3, -1.6773949338599383, -2.19, -1.36, -2.52, -1.03, 0.37, -0.64, -2.44, -1.53, 0.46, -3.31, -0.34, -1.82, -2.22, -1.4, -2.56, -1.07, 0.33, -0.67, -2.14, -4.91, 4.68, -1.98, -3.75, -0.79, -2.26, -2.67, -1.85, -3.0, -1.52, -0.12, -1.12, 1.71, 1.84, 3.08, 1.55, 1.13, 1.98, 0.78, 2.32, 3.77, 2.73, 0.21, 1.87, -1.79427628811696, -0.6584018193170985, -0.85, -0.584326481349968, -1.2, -1.3434006093113235, -1.89, -1.06, -2.23, -0.73, 0.67, -0.33, -0.46, 0.29, -0.41, 0.43, -0.76, 0.8857995496566927, 2.19, 1.17, -2.5, -2.53, -0.33, -0.8, 3.48, -0.56, -0.36, 0.51, -0.48, -0.26, -0.47, -1.21, 0.45775897911612196, 1.42, 0.73, 1.68, -0.12, -2.21, 2.25, 2.12, -0.73, 0.78, -1.45, -0.92, 0.46, -3.79, 2.73, 2.45, 3.54, -0.2, 0.7, 0.84, -0.35, 1.18, 2.61, 1.59, -2.2, -0.14, -1.18, 0.33, 1.75, 0.74, 1.05, 1.53, 2.97, 1.94, -1.83, -1.95, -0.47, 1.41, 0.4, -0.73, -0.79, -1.82, 1.46, -2.05, -1.49, -0.98, -0.82, -1.86, -1.0, -1.46, -0.23, 0.39529795204795226, 0.18, -0.66, -0.87, -0.72, -0.88, -1.3769832262926027], ['479', 3.21, 1.04, -0.04, 0.05, -0.41, -0.6015803763262405, -1.11, -0.9, -0.77, -1.55, -0.28, -1.55, -1.21, -0.09, -0.38, -2.14, -0.69, -1.47, -1.29, -0.44, -1.44, -1.52, -0.73, -0.69, -0.5314063389924735, -0.35, -1.27, -1.27, -0.94, 0.19, -0.1, -1.86, -0.41, -1.2, -1.01, -0.17, -1.16, -1.24, -0.45, -0.42, -0.26, -0.77, 0.0, 0.34, 1.48, 1.18, -0.6, 0.87, 0.39054591836734703, 0.26, 1.12, 0.11, 0.03, 0.83, 0.87, -0.28, 0.3, -0.68, -0.55, -0.34, 1.14, 0.84, -0.94, 0.53, -0.27, -0.08, 0.78, -0.23, -0.31, 0.49, 0.52, -1.46, -1.46, -0.3, -2.05, -0.6, -1.39, -1.2, -0.36, -1.35, -1.43, -0.65, -0.61, -1.36, -2.0, 2.19, -1.17, -1.76, -0.3, -1.1, -0.91, -0.06, -1.06, -1.14, -0.35, -0.2559922724755494, 2.78, 0.6, 1.48, 0.68, 0.87, 1.73, 0.71, 0.64, 1.44, 1.48, -0.16, 0.61, -1.67427628811696, -0.71, -0.71, -0.74, -0.87, -0.79, -0.61, 0.24, -0.76, -0.83, -0.05, -0.01, -0.01, -0.01692325186963274, 0.19, 1.04, 0.04, -0.04, 0.75, 0.79, -0.85, -0.66, 0.05, -0.82, 8.17, 0.05, 0.1, 2.06, -2.04, -1.0, 0.42, 0.29, 2.22, 1.44, 0.75, 1.68, -0.46, -2.09, 2.15, 2.17, -0.71, 3.1, -1.41, -1.49, 0.74, -2.56, 4.750651360544218, 1.83, 2.71, -2.15, -0.26, 0.85, -0.15, -0.23, 0.5966255411255412, 0.6, -2.2, -1.1098412698412699, -1.0, -1.08, -0.29, -0.25, -0.11, -0.08, 0.72, 0.76, -0.79, -1.2, -0.03, 0.8, 0.83, -0.6379199656859431, -0.74, -0.89, 2.65, -1.9196667372159368, -2.64, -1.39, -0.31, -0.82, 0.04, -0.89, -1.06, -0.31, -0.34, -0.58, -0.86, 0.1, -1.05, -1.15], ['480', 1.65, 0.0, 0.3412217156204588, -0.06, 0.61, -0.29, 0.43, 0.55, 0.5793780543870106, 0.23, -0.67, 0.32, -0.27, 0.11, -0.44, -0.31, 0.68, -0.1, -2.42, -1.88, 0.32, 0.19, -0.8, 0.72, 1.04, 0.689371414588892, 0.91, 1.0, 0.4, 0.79, 0.23, 0.36, 1.36, 0.58, -1.76, -1.22, 1.0, 0.86, -0.13, 1.4, 1.22, 1.04, -0.08, -0.59, -0.2, -0.6891849704247235, -0.63, 0.36, -0.42, -2.72, -2.19, 0.0, -0.13, -1.12, 0.4, 0.6900628463056766, 1.85, 0.22, 0.68, 0.51, 0.39, -0.17, -0.04, 0.95, 0.17, -2.15, -1.4960242664664933, 0.59, 0.46, -0.53, 1.0, 0.4336060011417156, 0.12, -0.56, -0.42, 0.56, -0.21, -2.53, -2.0, 0.2, 0.07, -0.92, 0.61, 0.69, 1.98, -2.07, 0.7166982383853202, 0.13, 1.12, 0.34, -1.98, -1.45, 0.77, 0.63, -0.36, 1.2240077275244505, -1.75, 0.54, 0.99, 0.21, -2.11, -1.58, 0.63, 0.5, -0.5, 1.03, 0.38, 0.53, -1.31, 0.12, 0.42, -0.36432648134996803, -0.44, -0.77, -3.07, -2.54, -0.34931972789115645, -0.49, -1.47, 0.04, 0.11, 0.33, -2.32, -1.79, 0.42, 0.29, -0.71, 0.82, 0.97, 0.63, 0.38603717887804045, -0.34, -6.09, 0.18, -0.2, 1.21, -1.31, -0.63, -0.69, 0.7, -4.25, -0.14, -0.09, 0.84, 0.15, 0.3, -0.32, -0.32, 0.13, 1.95, 0.23, -0.53, 0.24, -1.32, -1.91, 0.94, 1.43, 4.15, 2.71, 0.54, 2.8, 2.67, 1.65, 3.21, 0.33, 2.16, 2.25, 2.11, 1.1, 2.65, -0.09, -0.13, -1.12, 0.4, 0.55, 0.55, 0.13727468490743444, -0.99, 0.53, 0.1, 0.06439630127529085, 0.49, -1.17, -0.99, 1.18, -0.15, 1.6, 1.05, 1.54, -0.43, -0.48, -0.03, 0.45, -0.08, -0.404042472976186, 0.13, 1.7930376647162363, -0.79], ['481', -6.64, -0.28, -0.27, 0.09, -1.31, -1.6815803763262405, -1.4458847420401708, -3.76, -3.1, -5.36, -0.37, -3.41, -2.23, -1.64, -1.56, -2.73, -3.26, -4.95, -3.12, -3.8130204081632653, -6.38, -3.21, -2.69, -4.48, -3.28, -2.73, -4.977341605006887, -3.05, -1.87, -1.27, -1.2, -2.37, -2.9, -4.59, -2.76, -3.5, -6.04, -2.85, -2.32, -4.13, -2.73, -5.68, -2.02, 1.301197467496117, 1.83, 1.9808150295752764, 0.7, 0.15, -1.279454081632653, 0.3, -0.47, -3.08, 0.2, 0.75, -1.12, -2.13, -2.34, -1.92, -2.67, -3.2, 0.61, 0.69, -0.51, -1.05, -2.78, -0.91, -1.66, -4.25, -1.0, -0.46, -2.3, -3.53, -3.78, 0.08, -1.11, -1.65, -3.36, -1.5, -2.26, -4.83, -1.6, -1.07, -2.89, -4.38, -7.35, 7.3, -3.86, -1.19, -1.72, -3.44, -1.58, -2.34, -4.9, -1.67, -1.14, -2.9159922724755494, -4.32, -2.7, -0.54, -2.28, -0.4, -1.16, -3.76, -0.49, 0.04, -1.8, -0.47, -2.65, -2.15427628811696, -1.92, -2.06, -1.7543264813499682, -2.17, -1.75, 0.14, -0.62, -3.23, 0.05, 0.59, -1.27, -2.1, -0.43, 1.92, 1.14, -1.51, 1.83, 2.38, 0.49, -1.93, -1.51, -0.1, -2.18, -12.62, -0.5, -0.36, 3.01, -3.017537676609105, -1.53, -0.55, -5.22, 3.1, 3.89, 1.92, -3.42, -1.19, -5.9085238095238095, 5.8, 5.81, -1.94, 4.55, -3.85, -1.97, 1.05, -6.45, 5.04, 4.32, 6.13, -3.07, -2.31, -0.77, -3.37, -0.1, 0.45, -1.41, -5.79, -1.56, -2.63, 0.68, 1.22, -0.65, 1.1, 3.39, 3.95, 2.03, -2.98, -3.71, -2.22, 0.54, -1.32, -1.96, -1.92, -3.63, 2.78, -2.0698003730425008, -2.93, -2.7127361894755664, -3.48, -2.75, -1.85, -2.1199225974772196, -1.58, -1.09, -1.33, -1.39, -0.92, -4.85, -4.77, -0.95], ['482', 1.07, 0.3, -0.20877828437954127, 0.1, -0.17, -0.3, -0.84, -0.16, -1.15, 0.49535714285714283, 1.73, 1.23, 0.51, 0.97, 0.37, 0.92, 0.6, 0.23, -0.85, 1.12, 0.43, 0.66, 1.17, 0.41217460317460314, -1.1, -0.9, -1.28, -0.49, -1.2, -0.74, -1.34, -0.8, -1.11, -1.48, -2.54, -0.6, -1.28, -1.05, -0.56, -1.3, -0.11, -2.3450638007838265, -0.79, -0.71, -0.25, -0.85, -0.31, -0.62, -0.99, -2.06, -0.11, -0.79, -0.56, -0.06, -0.81, -0.61, -0.48, -1.95, -1.19, -0.08, 0.46, -0.15, 0.4, 0.09, -0.28, -1.36, 0.6, -0.08, 0.15, 0.65, -0.1, 1.17, -0.54, -0.17977210884353745, -0.06, -0.37, -0.74, -1.81, 0.14, -0.54, -0.31, 0.19, -0.56, -1.92, -1.4, 1.44, 0.07, 0.55, 0.23, -0.14, -1.21, 0.75, 0.06, 0.29, 0.8, 0.05, -1.55, -0.48, -0.31, -0.68, -1.75, 0.2, -0.48, -0.25, 0.25, -0.5, 0.18, -0.4, -0.04427628811695997, -0.32, -0.5, -0.06, -0.17, -0.37, -1.44, 0.51, -0.17, 0.06, 0.56, -0.13141531611693433, -0.34, 0.2, -1.08, 0.88, 0.2, 0.43, 0.93, 0.18, -0.08, -0.09, -0.01, 0.13, -4.65, 0.09354725829725827, 0.0, -0.12, 0.08, 0.03, -0.01, 0.8, 1.3, 0.61, 0.28, 0.53, -0.24, -0.83, 0.86, 1.02, -0.3, -0.19, -0.61, -0.44, 0.19, -0.53, 1.69, 0.3, 0.53, -1.26, 1.3, 1.98, 1.29, 1.53, 2.03, 1.27, -0.92, -0.67, -0.68, -0.45, 0.05, -0.7, 0.0, 0.23, 0.73, -0.02, -1.067204648526077, -1.28, -0.23, 0.5, -0.25, -0.32, -0.25, -0.11, 1.07, 0.21, -1.06, -0.53, -0.94, -0.72, -0.6672131485030683, -0.48, 0.06, -0.41, -0.01, 0.0, 0.105957527023814, -1.44, -0.9, 0.53], ['483', 1.8842857142857141, -0.54, -0.04, 0.02, -0.89, 0.12, -0.21588474204017086, 0.13, 1.05, -0.31, -1.9, -0.7, -0.56, -0.33, -0.16, -0.87, -0.2, -1.5494285714285714, 1.79, 2.49, 0.29733548208735894, -1.1, -0.68, -0.67, 0.8, -0.1, 1.62, 1.22, 1.37, 1.6, 1.77, 1.05, 1.73, 0.36, 3.76, 4.47, 2.2, 0.82, 1.25, 1.25, -0.03, 2.34, 0.5993032324818041, 0.15, 0.37, 0.54, -0.17, 0.5, -0.85, 2.51, 3.22, 0.97, -0.4, 0.03, 0.03, 1.62, 0.15, 0.0, 0.81, 0.25, 0.22, 0.4, -0.32, 0.36, -1.0, 2.36, 3.06, 0.83, -0.54, -0.12, -0.12, -0.0063939988582844, 0.03, 0.17, -0.54, 0.13, -1.22, 2.13, 2.83, 0.6, -0.77, -0.34, -0.34, 2.21, 1.61, -1.61, -0.14, -0.71, -0.04, -1.39, 1.96, 2.66, 0.43, -0.94, -0.51, -0.51, 0.54, 0.57, 0.67, -0.6778809523809525, 2.69, 3.39, 1.14, -0.23, 0.2, 0.2, 0.96, 0.54, 0.74, 0.26, 0.43, 0.07, -0.1, -1.35, 2.0, 2.7, 0.47, -0.9, -0.47, -0.47, 0.68, 1.26, 3.6436855802927233, 4.1, 1.84, 0.46, 0.89, 0.89, 0.3, 0.93, 0.09, -0.06, 1.2277380952380952, 0.31, 0.21, 0.44, -0.52, -0.48, -0.14, -0.34, 5.45, -0.49, -0.26, 0.81, 0.47, 0.77, -0.74, -0.74, -0.26, 1.01, 0.47, 0.93, -0.54, -0.3, -1.05, 0.17, 0.24, -5.42, -2.06, 0.69, -1.5, -2.84, -2.42, -2.42, 0.78, -2.73, -2.17, -3.5, -3.09, -3.09, -0.57, -1.36, -0.94, -0.93, 1.0, 1.52, 0.8, 0.43, 0.43, 0.22, 0.24, 0.04, -0.23, 0.66, 0.39, -0.71, -0.8, 0.37, 0.07278685149693166, 0.03, -0.45, -0.06, -0.38, -0.34, 0.37, -0.49, -0.2, 1.02], ['484', 5.91, 1.35, 0.46, -0.06, 2.0929790809910593, 1.28, 1.67, 1.41, 1.96, 0.76, -1.55, -0.94, -0.2, -0.26, -1.29, -0.55, -0.84, 0.28, 2.0, -2.08, 1.23, -0.23, -0.67, -0.97, 1.37, 1.55, 2.3826583949931126, 0.63, 1.38, 1.31, 0.26, 1.03, 0.73, 1.87, 3.61, -0.53, 2.83, 1.35, 0.9, 0.6338417231978392, 1.36, 3.13, 1.71, 0.74, 0.68, -0.36, 0.39, 0.1, 1.23, 2.96, -1.15, 2.19, 0.72, 0.27, -0.04, 0.48, 0.9, 0.79, 1.67, 0.96, -0.06, -1.1, -0.35, -0.64, 0.49, 2.2, -1.88, 1.43, -0.03, -0.47, -0.77, 2.1, 1.03, -1.03, -0.28, -0.58, 0.55, 2.27, -1.82, 1.5, 0.04, -0.41, -0.71, 2.55, 4.0, -3.95, 2.08, 0.76, 0.4717857142857143, 1.6, 3.33, -0.79, 2.56, 1.08, 0.63, 0.33, 2.58, 1.3873665312165628, -0.29, 0.83, 2.56, -1.54, 1.79, 0.32, -0.12, -0.43, 1.06, 1.31, 1.43, 1.6115981806829016, 1.4451790696343398, 1.69, 1.6818094764861293, 1.13, 2.86, -1.25, 2.09, 0.62, 0.17, -0.07141531611693433, 0.79, 0.48, 1.71, -2.36, 0.94, -0.51, -0.95, -1.25, 1.33, 1.43, 0.08, 1.51, 7.46, 0.18, 0.34, -3.78, 3.79, 1.89, 0.56, 1.0861635321120495, -5.83, -3.1, -1.54, 2.98, 0.56, 4.61, -4.7, -4.68, 1.54, -5.68, 3.07, 1.01, -0.53, 4.86, -11.72, -3.25, -4.8, 5.75, -1.21, -3.99, -0.75, -2.18, -2.61, -2.91, 4.69, 2.9, 3.38, 1.89, 1.44, 1.13, -0.46, -1.3511214088935783, -1.88, -2.17, 1.94, 2.3, 0.99, -0.44, -0.75, 1.54, 1.53, 1.38, -6.89, 1.93, 6.92, 2.09, 1.84, 1.44, -0.3, 1.55, 2.2, 1.16, -0.01, 0.8746262438247291, 1.75, 2.25, 2.75, 1.96], ['485', 4.95, 0.18, -0.19, -0.17, 0.92, -0.05, 1.47, -0.25, 0.34, 0.35, 0.19, -1.21, 0.73, 1.39, 0.11, -0.64, 0.9, 1.06, -1.37, 0.12, 0.76, 0.97, 0.46, 0.25, 0.08, -0.1, 0.16, -1.4, 0.53, 1.2, -0.09, -0.83, 0.7, 0.86, -1.56, -0.07, 0.57, 0.78, 0.3688796134390452, 0.10384172319783916, 0.1, -1.0250638007838266, 1.58, 1.96, 2.797875394446823, 1.33, 0.58, 2.13, 2.29, -0.16, 1.35, 2.028065468086443, 2.21, 1.69, 1.47, -0.7699371536943234, 0.55, 0.19, 0.0, -0.38, 0.66, -0.61, -1.36, 0.17, 0.33, -2.08, -0.6, 0.04, 0.25, -0.26, -0.47, -0.1, -1.03, -1.27, -2.01, -0.49, -0.33, -2.73, -1.26, -0.62, -0.41, -0.92, -1.13, 0.0, -0.37, 0.32, 0.27669823838532015, -0.75, 0.79, 0.95, -1.48, 0.01, 0.66, 0.87, 0.36, 0.14, 0.47, 0.99, 1.55, 1.71, -0.74, 0.77, 1.41, 1.62, 1.11, 0.89, -0.44, 0.95, -0.73427628811696, -0.05, -0.08, -0.03, -0.54, 0.16, -2.25, -0.77, -0.13, 0.08, -0.43, -0.64, -0.59, -0.7, -2.4, -0.93, -0.29, -0.08, -0.59, -0.8, 0.59, 0.18, -0.34, -0.27, 1.48, -0.15, 0.07, -0.25, 0.21, 0.13, 0.17, -0.97, -0.42, 0.1, 0.06, 2.5, -0.01, -0.18, 0.28, 0.19, 0.003290804863852956, -0.31, -0.1, 1.18, -0.6, -1.62, 5.05, 1.04, 1.53, 0.7956150793650794, 1.74, 1.51, 2.17, 2.38, 1.86, 1.64, -0.15, 0.23, 0.64, 0.85, 0.34, 0.13, -0.41, 0.21, -0.3, -0.51, 0.31, 0.06, -0.62, -0.51, -0.72, -0.06, -0.1, -0.27, 2.76, -0.4, -2.8, -0.13, -0.17, -0.11, -0.21, -0.39, 0.08, 0.08, 0.12, -0.02, 0.1, -0.43, 0.55, -0.68], ['486', -2.65, 0.7614285714285715, 0.7412217156204587, -0.12, 1.04, 2.01, 1.0741152579598292, 2.29, 2.26, 2.18, -0.84, 0.58, 0.57, -0.23602380952380952, 0.8, 5.75, -1.06, 1.49, 0.66, -1.29, 2.71, -0.54, -1.8, 0.09, 3.31, 1.48, 3.05, 1.43, 1.42, 0.61, 1.65, 6.64, -0.23, 2.34, 1.51, -0.45, 3.57, 0.3, -0.97, 0.94, 1.34, 2.8949361992161733, 1.6, -0.01, -0.81, 0.22, 5.14, -1.63, 0.9, 0.08, -1.85, 2.12, -1.11, -2.36, -0.48, 0.92, 2.22, 1.89, 2.31, 1.6, -0.8, 0.23, 5.15, -1.62, 0.91, 0.09, -1.85, 2.13, -1.1, -2.35, -0.47, 3.3, 2.42, 1.04, 6.0, -0.6805105874517637, 1.7332142857142856, 0.9, -1.05, 2.95, -0.3, -1.57, 0.33, 2.5, 11.23, -11.32, 1.37, 4.91, -1.85, 0.68, -0.14, -2.07, 1.89, -1.33, -2.58, -0.6459922724755494, -0.67, -3.37, -6.44, -4.03, -4.82, -6.65, -2.88, -5.95, -7.14, -5.35, 0.81, -3.38, 3.62, 2.38, 2.75, 2.28, 3.28, 2.58, 1.74, -0.22, 3.81, 0.53, -0.74, 1.17, 2.63, 0.69, -0.82, -2.73, 1.2, -1.99, -3.24, -1.37, 5.23, 5.45, 0.28, 3.13, -1.25, 0.92, 0.64, -4.07, 4.05, 2.01, 1.35, 2.08, -7.04, -4.74, -2.44, -1.24, 1.74, 7.5, -7.5, -7.16, 2.36, -6.16, 4.76, 2.55, -1.26, 9.95, -6.62, -6.71, -9.92, 6.8, 1.52, -1.93, 2.04, -1.19, -2.44, -0.56, 7.12, 3.5201587301587303, 4.05, 0.76, -0.52, 1.4, -0.51, -3.16, -4.39, -2.54, 2.33, 2.42, 2.73, -1.27, 0.63, 2.42, 2.55, 2.23, -3.04, 3.32, 3.22, 2.31, 3.21, 4.06, 1.93, 2.6, 2.02, 1.55, 1.13, 2.09, 2.09, 3.89, 5.08, 3.38], ['487', -4.29, -0.06, -0.5687782843795413, 0.29, -1.48, -1.15, -1.36, -2.31, -3.69, -1.94, 2.59, 3.01, 0.37, -0.23, 1.13, -0.87, -1.03, -1.46, -1.62, -1.09, -3.28, -1.95, 0.034305231600676125, -1.52, -3.06, -1.0, -4.42, 0.41, -1.7423253968253969, -2.75, -1.42, -3.37, -3.54, -3.96, -4.1, -3.59, -5.73, -4.43, -2.58, -4.01, -2.7625315746467893, -5.245063800783826, -4.81, -2.478802532503883, -3.14, -1.82, -3.76, -3.93, -4.34, -4.49, -3.98, -6.11, -4.81, -2.98, -4.4, -0.28, -3.36, -1.62, -2.36, -2.31, -0.6, 0.7507993197278912, -1.24, -1.4, -1.83, -1.98, -1.46, -3.65, -2.3067380952380954, -0.43, -1.89, -2.3, -1.72, 1.3746428571428573, -0.64, -0.81, -1.24, -1.39, -0.87, -3.06, -1.72, 0.30309548189905344, -1.3, -4.39, -4.53, 4.52, -3.0033017616146798, -1.98, -2.14, -2.57, -2.72, -2.2, -4.37, -3.04, -1.18, -2.62, -2.32, -1.09, -0.17, -0.6, -0.76, -0.23, -2.44, -1.09, 0.81, -0.66, -0.63, -1.06, -1.71, -1.19, -1.31, -1.01, -0.92, -0.3034006093113235, -0.59, -0.06, -2.27, -0.92, 0.99, -0.49, -0.19, -0.4369232518696327, -0.15, 0.38, -1.85, -0.49, 1.43, -0.06, -0.98, -0.46, 0.06, -0.92, -4.5, -0.71, -0.5, 1.45, -1.41, -0.7, -0.52, -3.41, 1.87, 2.38, 1.17, -2.16, -0.34, -3.42, 3.47, 3.6, -1.17, 2.21, -2.36, -5.09, 2.55, -2.66, 8.93, 1.84, 2.72, -1.97, -0.33, 0.53, -1.7, -0.34, 1.58, 0.1, -3.56, -0.86, -2.21, -0.86, 1.05, -0.43, 1.39, 1.38, 3.34, 1.82, -3.6, -3.29, 0.0, 1.93, 0.43, -1.22, -1.15, -2.34, 4.39, -0.72, -4.56, -2.84, -2.9, -1.89, -1.46, -1.17, -0.87, -0.35, 0.17, -0.77, -0.43, -4.79, -3.76, -0.35], ['488', 1.12, -0.45, -0.038778284379541256, 0.16, 0.02, -0.94, -0.9, -0.63, -0.51, -1.74, -1.52, -0.74, -0.86, -0.86, -2.37, -1.64, -1.52, -1.61, -1.96, -1.45, -1.6, -1.92, -1.65, -1.25, 0.0, -0.91, -0.22, 0.79, 0.6908333333333334, 0.8131899370470801, -0.86, -0.12, 0.0, -0.09, -0.44, 0.07, -0.08, -0.41, -0.13, 0.27, -0.38, -0.41, -1.0, -0.03880253250388291, -0.12, -1.63, -0.9, -0.79, -0.87, -1.22, -0.71, -0.8603452707629391, -1.19, -0.91, -0.51, -0.34, -0.75, -0.91, -0.44, -0.88, 0.0, -1.52, -0.79, -0.67, -0.6573949338599383, -1.0013219954648527, -0.59, -0.75, -1.07, -0.79, -0.4, -1.86, -0.88, -1.52, -0.79, -0.67, -0.76, -1.11, -0.59, -0.75, -1.07, -0.79, -0.39, -0.43, -0.41, 0.41, 0.64, 0.74, 0.86, 0.77, 0.42, 0.94, 0.78, 0.46, 0.74, 1.14, 0.35, -0.02263346878343711, 0.12, 0.03, -0.32, 0.19, 0.04, -0.28, -0.01, 0.39, -0.15, -0.12, 0.53, -0.63, -0.77, -0.53, -0.22, -0.09, -0.44, 0.07, -0.08, -0.33969498055271247, -0.12, 0.27, -0.12, -0.13, -0.35, 0.16, 0.01, -0.31, -0.03, 0.36, 0.03, -0.07, 0.22, -0.48, 1.06, 0.13, 0.1, 1.06, -1.06, -0.53, -2.03, -0.9, 0.63, 1.29, 0.67, 0.58, -0.32, -2.0, 1.99, 1.94, -0.66, 1.65, -1.32, -1.54, 0.73, -0.64, -1.33, 0.44, 0.65, -0.58, 0.22, 0.52, 0.36, 0.04, 0.32, 0.72, -1.94, -0.29, -0.16, -0.48, -0.2, 0.2, -0.14, -0.32, -0.04, 0.36, -0.49, -0.29, 0.19, 0.28, 0.68, -0.71, -0.64, -0.57, -0.97, 0.03019962695749935, 0.94, -1.12, -1.86, -0.09, 0.4, -0.87, -0.48, -0.25, -0.3, -0.98, -0.49, -1.1, -1.5084047619047618, -0.37], ['489', -4.43, 0.34, 0.09122171562045875, 0.13, 1.02, 1.52, 1.0441152579598292, 1.3, 1.59, 2.05, 0.35, 0.77, 1.93, 0.48, 0.91, 3.26, 0.3, 1.75, 2.36, -0.39, 2.48, 1.0570289115646259, 1.15, 0.27, 2.47, 1.7093714145888919, 1.7, 0.42, 1.58, 0.14, 0.57, 2.91, -0.04, 1.4, 2.01, -0.73, 2.13, 0.41, 0.81, -0.08, 1.08, 2.500897562605877, 1.28, 1.16, -0.28, 0.15, 2.48, -0.46, 0.97, 1.59, -1.14, 1.7, -0.01, 0.38, -0.5, 0.4, 1.25, 1.36, 1.1, 0.11, -1.43, -1.0, 1.31, -1.6, -0.18, 0.42, -2.28, 0.54, -1.15, -0.77, -1.64, 1.36, 1.56, 0.43, 2.77, -0.18, 1.26, 1.87, -0.86, 2.143081632653061, 0.28, 0.67, -0.21, 1.64, 2.56, -2.59, 1.13, 2.33, -0.6, 0.83, 1.44, -1.29, 1.55, -0.13428571428571429, 0.24, -0.64, -1.58, -1.18, -2.87, -1.456904761904762, -0.87, -3.54, -0.76, -2.42, -2.04, -2.9, 0.3009795918367347, -1.08, 2.7457237118830404, 1.4, 1.01, 1.8, 1.74, 1.44, 2.05, -0.69, 2.345778253492539, 0.46, 0.85, -0.04, 1.27, 0.3, 0.61, -2.1, 0.729562358276644, -0.97, -0.58, -1.45, 0.62, 0.99, 0.41, 1.56, -3.24, -0.12, 0.05, -4.08, 4.042462323390895, 2.02, 0.71, 2.24, -4.96, -2.67, -1.43, -2.21, 0.89, 4.16, -4.23, -4.15, 1.4, -6.06, 2.73, -2.49, 1.25, 5.16, -7.24, -3.5, -5.2, 4.96, -0.31, -2.69, 0.11, -1.57, -1.18, -1.884238287156354, 4.1, 2.45, 2.88, 1.15, 1.55, 0.66, -0.42, -1.68, -1.29, -2.16, 1.63, 1.68, 1.28, 0.39, -0.49, 1.41, 1.42, 1.2925760496238783, -3.59, 2.19, 3.52, 1.2772638105244332, 1.7, 0.968637448200971, -0.88, 1.12, 2.13, 1.35, 0.57, 0.69, 1.78, 1.59, 2.883037664716236, 1.69], ['490', 7.2, 0.03, -0.02, 0.2, 0.91, 0.56, -0.5558847420401708, 0.87, 0.78, 0.18, -1.07, 0.18, -0.45, 0.03, -0.12, -1.69, -0.14, -0.06, -0.99, -1.6, 0.72, 0.17, -0.22, -0.15, 1.12, 1.29, 1.26, 1.3784685082657773, 0.62, 1.11, 0.96, -0.6266496598639456, 0.94, 1.02, 0.08, -0.54, 1.81, 1.25, 0.86, 0.93, 0.98, 2.9949361992161734, 0.0, -0.63, -0.15, -0.3, -1.87, -0.32, -0.24, -1.17, -1.78, 0.54, -0.02, -0.4, -0.33, 0.76, 1.41, 1.04, 0.24, 0.64, 0.48, 0.33, -1.25, 0.31, 0.4, -0.54, -1.16, 1.343421154242583, 0.62, 0.24, 0.3, 1.04, 0.15, -0.15, -1.72, -0.17, -0.09, -1.02, -1.63, 0.69, 0.14, -0.24, -0.18, 1.58, 0.99, -1.06, 0.33669823838532015, -1.57, -0.02, 0.06, -0.87, -1.48, 0.84, 0.29, -0.09, -0.03, 3.82, 1.91, 1.58, 1.66, 0.71, 0.09, 2.5126265373526935, 1.89, 1.5, 1.57, 0.25, 1.97, 1.51, 0.39, 0.34, 0.45, 0.32, 0.08, -0.85, -1.47, 0.86, 0.31, -0.08, -0.01, 0.03, 0.29307674813036727, -0.94, -1.55, 0.78, 0.22, -0.16, 0.15217743764172342, 0.14, 0.12, 0.36, 0.32, 11.41, 0.1, -0.17, -0.94, 0.92, 0.47, 0.27, 0.15616353211204947, -3.42, -0.76, -0.43, 3.53, 0.17, 1.3, -1.21, -1.17, 0.39, -1.41, 0.8, -1.14, 0.6047652642842468, 0.95, -4.36, -0.65, -0.95, 3.47, 1.5103786848072562, -0.62, 1.73, 1.17, 0.78, 0.85, 1.24, 1.8201587301587303, 2.36, 1.8, 1.41, 1.48, -0.53, -0.55, -0.93, -0.86, 0.8, 0.93, 0.10727468490743443, -0.38, -0.31, 0.42, 0.42, 0.83, -2.57, 1.07, 2.54, 0.85, 0.78, 0.4, 0.07, 0.44, 0.6445528598385742, 0.37, -0.19, 0.1, 0.33, 1.24, 0.73, 0.05], ['491', 4.05, 0.19, 0.44122171562045875, 0.05, 0.44, 1.21, 0.17411525795982916, 1.98, 1.59, 1.3470884353741497, -2.18, 0.11, -0.04, -0.78, -1.0457142857142858, -0.06, 0.8214285714285714, -0.05, 0.78, 0.09366326530612246, 1.47, -1.05, -0.12, -0.73, 1.11, 1.12, 3.15, 2.3405454545454543, 2.19, 1.43, 1.16, 2.1702857142857144, 2.41, 2.18, 3.03, 2.3, 3.73, 1.16, 2.11, 1.48, 2.187468425353211, 1.6649361992161733, 0.79, -0.14, -0.88, -1.15, -0.17, 0.07, -0.16, 0.67, -0.04, 1.36, -1.16, -0.22, -0.83, 0.45, 0.52, 1.13, 1.67, 0.93, -0.74, -1.01, -0.02, 0.21, -0.02, 0.82, 0.11, 1.5, -1.01, -0.08, -0.69, 1.86, 1.69, -0.27, 0.72, 0.96, 0.73, 1.57, 0.86, 2.26, -0.27, 0.67, 0.05, 2.5, 3.06, -3.02, 1.96, 1.0, 1.24, 1.0, 1.85, 1.13, 2.54, 0.0, 0.94, 0.32, 0.96, 0.96, 0.24, 0.01, 0.84, 0.13, 1.53, -0.99, -0.06, -0.67, 0.86, 0.93, 1.66, 0.95, 0.98, 1.01, 0.72, -0.23, 0.6, -0.11, 1.28, -1.1696949805527124, -0.29, -0.8514153161169343, 1.72, 0.95, 0.84, 0.12, 1.52, -1.0, -0.0642857142857143, -0.68, 0.21, 0.9, 0.36603717887804044, 1.1, 1.84, 0.66, 0.01, -0.98, 0.97, 0.48, -0.98, 3.09, -1.56, -2.02, -0.96, 2.02, 1.06, 2.83, -2.85, -2.93, 0.95, -1.35, 1.95, 0.61, -0.28, 2.14, -5.39, -1.4, -2.27, 1.66, 0.11, -0.71, 0.68, -1.82, -0.89, -1.5, 2.97, 0.82, 1.39, -1.12, -0.19, -0.8, -0.11349829931972805, -2.48, -1.56, -2.16, 1.65, 2.18, 1.97, 0.94, 0.32, 0.98, 1.0, 1.95, -2.83, 2.34, 2.68, 1.35, 0.83, 1.02, -0.61, 0.91, 0.5202197802197802, 1.14, 1.23, 1.23, 1.64, 1.03, 1.09, 1.04], ['492', -1.05, -0.66, -0.12, 0.21, -0.8, -0.1, 0.17411525795982916, 0.21172059653595873, 0.15, 0.06, 0.27, -0.67, 1.52, -0.13, -0.27, 0.25, 0.87, 0.68, -1.22, 1.14, 0.09, -0.08405782312925174, -0.22, 0.55, 0.29, -0.16, -0.21, -0.94, 1.25, -0.4, -0.53, -0.02, 0.6, 0.41, -1.49, 0.86, -0.18, -0.47, -0.49, 0.28, -0.25, 0.5149361992161734, 0.74, 2.21, 0.54, 0.4, 0.92, 1.55, 1.35, -0.56, 1.82, 0.76, 0.47, 0.45, 1.23, 0.0, -0.09, 0.42, 0.4, -1.44, -1.63, -1.76, -1.26, -0.64, -0.83, -2.7, -0.38, -1.42, -1.7, -1.72, -0.96, 0.7436060011417156, 0.19, -0.14, 0.38, 1.0616609275411797, 0.81, -1.09, 1.27, 0.22, -0.07, -0.09, 0.68, 0.0, 0.26, -0.36, 0.3308709226619941, 0.52, 1.14, 0.95, -0.96, 1.41, 0.35, 0.07, 0.04, 0.82, -2.06, -0.18, 0.62, 0.43, -1.46, 0.89, -0.16, -0.45, -0.47, 0.3, -0.64, -0.17, -0.99, -0.39, -0.18, -0.69, -0.8, -0.19, -2.07, 0.26, -0.78, -1.06, -1.08, -0.32, 0.18, -0.61, -1.88, 0.46, -0.59, -0.87, -0.9, -0.12, 0.07895836996312448, -0.2, 0.47, -0.81, -6.04, -0.08, 0.06, 1.4, -1.39, -0.67, -0.23, -1.65, 2.15, 0.7, 0.37, -0.48, 0.19, -1.36, 1.29, 1.05, -0.36, 2.0, -0.69, -2.52, 1.25, -2.34, 4.53, 1.6, 2.34, -2.2, 1.3, 2.39, 1.32, 1.03, 1.01, 1.79, -0.99, -1.06, -1.04, -1.32, -1.34, -0.58, -0.02, -0.29, -0.31, 0.47, 0.21, 0.03, 0.26, -0.02, 0.75, -0.33, -0.44, 0.16, 1.75, -1.52, -2.22, -1.0, -0.86, 0.29, 0.78, -0.66, -0.58, -0.09, 0.55, -0.39537375617527093, -0.49, -3.43, -1.18, -1.08], ['493', -3.89, -0.13, -0.15, 0.26, -2.03, -0.79, -1.0158847420401709, -3.09, -2.12, -2.62, 1.1, -0.68, 0.703913265120849, 0.27, 2.29, -2.73, -1.32, -1.7, -1.23, -0.19, -3.19, -1.41, -0.76, -1.11, -1.83, -0.93, -3.68, -1.76, -0.46, -0.6768100629529199, 1.17, -3.79, -2.39, -2.77, -2.31, -1.27, -4.24, -2.48, -1.84, -2.18, -3.4925315746467893, -1.8450638007838267, -1.95, 1.33, 0.96, 3.0608150295752767, -2.0389563492063494, -0.6007210884353742, -1.03, -0.56, 0.5, -2.52, -0.73, -0.08, -0.43, -1.45, -2.11, -2.21, -1.44, -3.1607547529341224, -0.36, 1.64, -3.35, -1.94, -2.33, -1.86, -0.82, -3.8, -2.04, -1.39, -1.74, -2.24, -2.89, 2.01, -2.99, -1.58, -1.97, -1.5, -0.46, -3.45, -1.68, -1.03, -1.38, -2.9, -5.04, 5.11, -4.8, -4.9, -3.52, -3.9, -3.44, -2.42, -5.35, -3.61, -2.98, -3.32, 1.15, 0.11, 1.45, 1.05, 1.5415238095238095, 2.61, -0.47, 1.35, 2.03, 1.67, -1.04, 0.13, -2.5798953488372094, -0.98, -0.98, -0.984326481349968, -1.32, -0.39, 0.08, 1.14, -1.89, -0.039694980552712436, 0.57, 0.21, -1.27, -0.93, 0.48, 1.54, -1.51, 0.3, 0.96, 0.61, -2.08, -1.55, 0.38, -1.27, 2.36, -0.3796768707482993, -0.04, 2.48, -2.51, -1.27, -0.95, -4.8, 4.84, 2.14, 1.08, -2.04, 0.13, -3.15, 3.19, 3.09, -1.05, 3.76, -2.0, -3.18, 1.64, -3.96, 8.22, 2.54, 3.87, -4.81, -1.41, 1.06, -1.98, -0.18, 0.48, 0.13, -3.1, -2.44, -2.9964625850340134, -1.23, -0.57, -0.92, 0.58, 1.83, 2.51, 2.15, -2.07, -2.2, -1.23, 0.66, 0.31, -0.7879199656859431, -1.06, -3.29, 4.09, -2.6, -4.24, -2.1, -1.29, -1.88, -0.35, -1.89, -1.2, 0.17, -0.06, 0.31, -1.53, -2.2297593656343655, -2.17, -1.6269832262926027], ['494', 0.1, 0.01, -0.08, 0.15, 0.1, -0.49, -1.22, -0.31, 0.33, -0.51, -1.8, 0.03, 0.0, -1.42, 1.27, -1.06, 0.54, -0.08942857142857143, 0.56, -0.01, 0.29, -1.16, -0.25, 0.38, -0.12, -0.13, 1.32, 1.87, 1.83, 0.39, 3.187819971295091, 0.75, 2.39, 1.74, 2.41, 1.83, 2.13, 0.65, 1.58, 2.23, -1.24, 1.25, -0.54, 0.041197467496117086, -1.46, 1.24, -1.1, 0.51, -0.13, 0.53, -0.04, 0.25, -1.2, -0.28, 0.355047619047619, 0.07, 0.07, 0.13194788471762156, 0.43, -0.51, -1.42, 1.28, -1.06, 0.55, -0.09, 0.5871802721088435, 0.0, 0.29, -1.16, -0.25, 0.38, -0.51, 0.93, 2.74, 0.36, 2.1494894125482364, 1.35, 2.02, 1.44, 1.74, 0.26, 1.19, 1.8835596417251208, 1.07, -0.86, 0.83, -1.76, -2.31, -0.72, -1.35, -0.7, -1.066255228898086, -0.97, -2.41, -1.5, -0.88, 0.28, 0.56, 1.63, 0.98, 1.65, 1.07, 1.4326265373526936, 0.1428169964955679, 0.82, 1.46, -0.25, 0.52, -0.69, -0.57, -0.5, -0.69, -1.05, -0.63, 0.02, -0.55, -0.26, -1.7, -0.79, -0.16, 0.63, -0.42, 0.66, 0.09, 0.38, -1.07, 0.0657142857142857, 0.47, -0.38, -0.88, 0.23, -0.76, 0.53, 0.04, 0.14, 1.83, -1.79, -0.87, 0.13, -1.14, 1.09, 1.18, 1.028280612244898, 0.25, -0.56, -1.77, 1.71, 1.84, -0.56, 2.62, -1.11, -0.84, 0.44, -3.01, -0.29, 2.1, 3.02, -0.97, -1.07, -0.57, -0.28, -1.72, -0.81, -0.18, -1.67, -0.5, 0.29, -1.16, -0.24, 0.39, -0.79, -1.45, -0.54, 0.09, 0.34, 0.62, 0.66, 0.92, 1.56, -0.4, -0.64, -0.35, -0.18, -1.06, 0.29, -0.83, 0.53, -0.26, 0.63, -0.97, -0.96, -0.87, -0.3, -0.55, -0.89, -1.04, 0.15, -0.79], ['495', -2.12, 0.0, 0.46, 0.06, -0.14, -0.38, 0.18, 0.09172059653595872, -0.56, 1.46, 1.89, 2.4293248299319727, 2.1, 1.44, 1.15, 2.25, 1.15, 1.47, 2.57, 2.53, 1.23, 1.07, 1.93, 1.605116627420199, -0.64, -1.24, -0.39734160500688753, 0.51, 0.2, -0.44, -0.73, 0.35, -0.73, -0.41, 0.66, 0.62, -0.65, -0.81, 0.03, -0.43, 0.24, 0.63, -0.94, -0.31, -0.95, -1.24, -0.16, -1.24, -0.92, 0.15, 0.11, -1.16, -1.31, -0.48, -0.94, -0.5, -0.21, -0.44, -0.33, -0.63, -0.65, -0.94, 0.15, -0.93, -0.62, 0.46, 0.42, -0.85, -1.01, -0.11173538366395512, -0.63, 0.01360600114171559, 0.02, -0.29, 0.8, -0.29, 0.03, 1.11, 1.07, -0.21, -0.37, 0.48, 0.02, -0.7, -0.89, 0.92, 0.31, 1.1780874332127649, 0.01, 0.32, 1.41, 1.37, 0.08, -0.07, 0.7785238095238095, 0.31, -1.7, -0.78, -1.08, -0.76, 0.31, 0.27, -1.0, -1.15, -0.32, -0.78, 0.03, -0.84, 1.67, -0.24, -0.36, 0.015673518650031963, 0.3009570400359874, 0.32, 1.4, 1.36, 0.08, -0.08, 0.76, 0.3, 0.22, -0.01, 1.08, 1.04, -0.24, -0.39, 0.45, -0.01, -1.01, -0.27, 0.28, 0.17, -5.08, 0.03, -0.06, 0.43, -0.45, -0.2, 0.0, -0.24, 2.1, 0.46, 0.23, -0.99, -0.5, -0.68, 0.62, 0.79, -0.25, 0.56, -0.49, 0.1, -0.06, 0.89, 2.22, -0.7, -0.95, -1.98, -1.08, -0.04, -1.3, -1.46, -0.63, -1.08, -0.74, -0.9056457669314812, -1.26, -1.42, -0.59, -1.04, 0.22, -0.16, 0.69, 0.22, -0.56, -0.41, 0.38, 0.84, 0.38, -0.25, -0.16, 0.0, 1.15, 1.34, -1.09, -0.33, -0.53, -0.46, -0.46, -0.14, -0.15, -0.46, -0.89, 0.03, 0.0, -1.23, -0.69, 0.25], ['496', -5.95, 0.0, -0.03984710169072946, 0.06, -0.5070209190089403, -1.07, -1.6158847420401707, -2.138279403464041, -2.03, -3.18, 0.04, -2.08, -1.2, -0.75, -0.19, -2.7, -1.47, -2.85, -5.89, -1.96, -3.432664517912641, -1.61, -2.04, -1.78, -1.69, -1.48, -3.22, -2.11, -1.2191666666666667, -0.79, -0.23, -2.74, -1.51, -2.89, -5.93, -2.0, -3.51, -1.65, -2.08, -1.82, -1.82, -3.84, -1.13, 0.9711974674961171, 1.35, 1.93, -0.64, 0.62, -0.79, -3.9, 0.12, -1.391934531913557, 0.47, 0.04, 0.3, -1.06, -1.59, -1.92, -1.35, -2.01, 0.45, 1.02, -1.52, -0.28, -1.67, -4.75, -0.77, -2.3, -0.42, -0.85, -0.59, -1.8, -2.45, 0.57, -1.97, -0.72, -2.12, -5.18, -1.22, -2.74, -0.87, -1.29, -1.04, -2.81, -3.59, 3.64, -3.0, -2.52, -1.29, -2.67, -5.72, -1.78, -3.29, -1.43, -1.85, -1.6, -2.88, -0.49, 1.27, -0.15, -3.28, 0.76, -0.78, 1.12, 0.69, 0.95, -0.42, -0.48, -2.57, -1.05, -1.04, -1.14, -1.73, -1.4, -4.49, -0.5, -2.03, -0.14, -0.57, -0.32, -1.53, -0.28692325186963274, -3.13, 0.92, -0.63, 1.28, 0.84, 1.1, -0.78, -1.3, 0.04, -1.48, -8.87, -0.03, 0.23, 1.95, -2.02, -0.98, -0.09, -2.67, 2.45, 2.05, 1.04, -2.99, -1.01, -3.2, 3.19, 3.17, -1.05, 2.93, -2.09, -1.51, 0.76, -5.33, 4.58, 3.47, 5.21, -2.28, 2.88, 4.18, 2.58, 4.55, 4.1, 4.535761712843646, -3.1, -1.24, -1.54, 0.35, -0.08, 0.18, 0.3, 1.92, 1.48, 1.74, -1.91, -2.26, -1.59, -0.43, -0.17, -1.03, -1.13, -2.13, 3.99, -1.76, -4.05197619047619, -1.84, -0.3, -1.17, 0.26, -1.31, -0.79, -1.6, -0.66, -0.94, -1.42, -2.58, -0.78, -1.58], ['497', 0.43, 0.0, -0.25877828437954126, 0.1, 0.23, -0.38, -0.49588474204017086, -1.31, -0.65, -0.9, -0.19, -0.59, -0.47, -0.22, 0.95, -0.65, -0.4, -0.73, -1.45, -0.18, -1.03, -0.36, -0.15, -0.83, -0.85, -0.7, -0.71, -0.3998214285714286, -0.28, -0.03, 1.14, -0.46, -0.21, -0.54, -1.27, 0.01, -0.84, -0.17, 0.04, -0.64, -0.99, -1.71, -0.31, 0.12, 0.37, 1.54, -0.06, 0.19, -0.14, -0.87, 0.41, -0.45, 0.23, 0.44, -0.24, -0.82, -0.86, -1.44, -0.56, -0.43, 0.26, 1.43, -0.17, 0.08, -0.26, -0.98, 0.29, -0.56, 0.11, 0.32, -0.36, -1.71, -0.68, 1.17, -0.43, -0.18, -0.51, -1.24, 0.04, -0.82, -0.14, 0.07, -0.61, -1.03, -1.96, 1.89, -1.83, -1.58, -1.33, -1.66, -2.38, -1.12, -1.96, -1.3, -1.09, -1.76, -0.52, -0.25, 0.25, -0.08, -0.81, 0.47, -0.39, 0.29, 0.5, -0.18, -0.05, -0.3, -1.66427628811696, -0.28, -0.37, -0.19, -0.5, -0.33, -1.06, 0.22, -0.64, 0.04, 0.32598786341555264, -0.43, -0.6, -0.17, -0.73, 0.55, -0.13139698000412267, 0.37, 0.58, -0.1, -0.68, -0.81, 0.34, -0.34, -1.36, 0.0, -0.1, 0.36, -0.3675376766091052, -0.15118982899237887, -0.28, -0.71, 1.33, 0.54, 0.26, 0.18, -0.36, -0.79, 0.77, 0.75, -0.21670919513614706, 0.56, -0.47012164275868484, -1.87, 0.93, -1.4, 0.43, 0.86, 1.53, -1.36, 0.56, 1.29, 0.43, 1.11, 1.32, 0.64, -0.6768321004392431, -0.72, -0.85, -0.18, 0.03, -0.65, 0.14, 0.68, 0.89, 0.21, -0.61, -0.75, -0.54, 0.21, -0.39775124468498363, -0.25, -0.23, -1.24, 0.29, -0.59, -0.33, -0.92, 0.41, -0.75, -0.68, -0.32, -0.14, -0.06, -0.47, -0.61, -0.07, -0.95, 0.97, 0.16], ['498', 0.83, -1.24, 0.05122171562045875, 0.3, -1.23, -1.42, -1.6358847420401708, -1.9, -1.82, -1.53, 0.02, -0.62, 1.13, 0.75, 0.29, -2.62, 0.74, -1.17, 2.19, -0.3, -1.59, 0.27, 0.34, 0.47, -1.05, -1.53, -1.55, -0.64, 1.1, 0.73, 0.27, -2.6366496598639455, 0.72, -1.2, 2.17, -0.33, -1.62, 0.25, 0.32, 0.45, -1.8125315746467892, -3.64, -0.92, 1.75, 1.38, 0.91, -2.02, 1.36, -0.56, 2.82, 0.31, -0.99, 0.89, 0.96, 1.1, -1.17, -0.4, -1.67, -2.25, -2.63, -0.37, -0.83, -3.7, -0.38, -2.28, 1.05, -1.41, -2.69, -0.84, -0.78, -0.64, -2.36, -2.27, -0.46, -3.35, -0.01, -1.91, 1.43, -1.05, -2.33, -0.48, -0.41, -0.28, -2.29, -5.37, 5.28, -1.82, -2.9, 0.45, -1.46, 1.9, -0.59, -1.88, -0.02, 0.05, 0.18, 1.18, 1.12, 3.45, 1.48, 4.94, 2.38, 1.05, 2.97, 3.04, 3.18, -0.48, 1.03, -3.44, -1.43, -1.51, -1.5, -2.25, -1.9, 1.44, -1.04, -2.32, -0.46, -0.3240121365844474, -0.26, -1.67, -0.36, 3.41, 0.88, -0.42, 1.47, 1.53, 1.67, -1.84, -1.85, 0.07, -1.98, 3.9, -0.52, -0.35, 2.71, -2.8, -1.38, -0.75, -2.14, 2.4, 2.88, 1.41, 0.36, -0.996920210131221, -4.52, 4.53, 4.28, -1.44, 4.21, -2.84, -2.25, 1.04, -6.74, 13.503125850340135, 4.52, 6.78, -2.37, -3.64, -2.44, -3.71, -1.88, -1.8087142857142857, -1.68, -4.31, -1.23, -1.3, 0.58, 0.64, 0.78, 0.06, 1.9, 1.96, 2.1, -1.75, -2.23, -1.8, 0.06, 0.2, -1.44, -1.6, -1.7674239503761218, 7.11, -3.2398003730425007, -7.02, -1.86, -1.61, -1.86, 0.14, -1.99, -1.2, -0.69, -1.18, -0.84, -2.0, -1.2, -2.45, -2.09], ['499', 9.254285714285714, -0.9, -0.04, 0.07, -0.2, 0.02, 1.174115257959829, 0.98, 0.58, 1.99, 1.24, 0.54, 1.51, 0.4, 0.8, 1.1610714285714285, 2.65, 1.72, 5.24, 3.04, 2.3, 2.9870289115646256, 1.96, 1.71, -0.38, 0.38, 0.7726583949931125, -0.7, 0.26, -0.83, -0.44, -0.08, 1.39, 0.5872589041444084, 3.95, 1.78, 1.04, 1.43, 0.7, 0.46, 1.31, 0.22, 1.45, 0.97, -0.14, 0.26, 0.62, 2.1, 1.18, 4.68, 2.49, 1.75, 2.14, 1.4442857142857142, 1.16, -0.55, 0.24, 1.21, 0.46, 0.47, -1.1, -0.7, -0.35, 1.12, 0.21, 3.67, 1.51, 0.77, 1.16, 0.44, 0.19, 0.62, 1.59, 0.4, 0.76, 2.24, 1.32, 4.82, 2.63, 1.89, 2.28, 1.55, 1.3, 0.47, -0.1, 0.11, 1.18, 0.36, 1.83, 0.92, 4.41, 2.23, 1.6552352330209474, 1.88, 1.15, 0.9, 1.05, 0.82, 1.47, 0.56, 4.04, 1.86, 1.12, 1.51, 0.79, 0.54, 0.22, 0.84, -1.16, 0.05, -0.06, 0.05, -0.64, -0.9, 2.53, 0.38, -0.34, 0.04, -0.67, -0.8614153161169343, -0.69, 0.26, 3.46, 1.3, 0.56, 0.95, 0.23, -0.02, 0.04, -0.3, 0.4660371788780404, -0.54, 3.25, 0.14, 0.35, -1.09, 1.1, 0.56, -0.02, -0.72, 1.94, -0.12, -0.03, 4.469285714285714, -0.05, 0.01, 0.06, -0.1, 0.10329080486385296, -1.79, 0.07, -0.43, 0.22, -1.94, 1.51, 1.22, 1.89, -2.04, -3.09, -2.09, -2.8, -2.42, -3.12, -3.36, 0.18, -1.02, -0.72, -0.34, -1.05, -1.29, -0.3, 0.38, -0.33, -0.58, 0.61, 0.46, -0.68, -0.72, -0.96, 0.05, -0.03, 0.93, 0.32, -0.3, -0.34, -0.03273618947556672, -0.74, 0.03, -0.24, -0.37, 0.42, 0.13, -0.6, 0.39, 0.28, -0.09, -1.83, 0.89], ['500', -0.74, -0.25, 0.13122171562045873, -0.7, -0.36, -0.55, -0.015884742040170832, -0.6, -0.23, -0.42, -0.14, 0.4, 0.08, -0.09, -0.22, -0.65, 0.2, -0.11, 2.73, -0.24, -0.43266451791264104, 0.61, -0.24, -0.59, -0.4, -0.21, -0.2573416050068875, 0.54, 0.22, 0.05, -0.022180028704908802, -0.51, 0.33, 0.03, 2.87, -0.1, -0.33, 0.75, -0.1, -0.4061582768021609, -0.1, -0.7350638007838266, -0.82, -0.32, -0.49, -0.62, -1.04, -0.2, -0.5, 2.32, -0.64, -0.841934531913557, 0.21, -0.64, -0.99, 0.47, 0.22, -0.08, 0.06, -0.5, -0.17, -0.3, -0.73, 0.12, -0.19, 2.64, -0.32, -0.55, 0.53, -0.32, -0.67, -0.18, -0.34, -0.13, -0.56, 0.28, -0.02, 2.82, -0.15, -0.38, 0.7, -0.15, -0.4564403582748793, -0.42, -0.6, 0.66, -0.16330176161467985, -0.43, 0.42, 0.11, 2.95, -0.02, -0.25, 0.83, -0.02, -0.37, -0.89, 0.22, 0.85, 0.54, 3.39, 0.41, 0.18, 1.26, 0.41, 0.06, -0.36, 0.19, -0.26427628811695997, -0.43, -0.19, -0.13432648134996805, -0.62, -0.3, 2.53, -0.43, -0.66, 0.41, -0.44, -0.79, 0.12, -0.32, 2.83, -0.13, -0.36, 0.71, -0.14, -0.49, -0.59, -0.53, -0.06, -0.3, 0.2, -0.1, 0.0, 0.44, -0.56, -0.23, -0.29, -2.71, 0.37, 0.83, 0.38, -0.21, -0.04, -1.29, 1.25, 1.11, -0.45, 0.76, -0.84, 0.27, -0.2, -1.66, -0.8, 0.82, 1.73, -0.29, -3.07, -2.89, -3.11, -2.06, -2.89, -3.23, -1.17, -0.19, -0.23, 0.85, 0.0, -0.35, 0.05, 1.08, 0.23, -0.12, -0.26, 0.19, -1.03, -0.84, -1.19, -1.05, -0.41, -0.35, 0.09, -0.5798003730425006, 0.17, 0.27, -0.93, -0.18, -0.35, -0.42, -0.31, -0.37, -0.31, -0.5, 0.17, -0.47, -1.24, -0.11], ['501', -1.71, -0.18, 0.25122171562045875, 0.04, -1.02, -0.3, 0.22, -0.15, -0.45, -0.48, -0.67, -0.64, 0.54, 1.4, -1.0, 0.08, 0.02, -0.65, 0.62, 1.5, -0.3, -0.27, -0.03, 0.55, 0.13, -0.6, 0.2, 0.14846850826577718, 1.22, 2.09, -0.33, 0.7633503401360544, 0.7, 0.02, 1.3, 2.18, 0.37, 0.41, 0.65, 1.23, 0.06, -0.89, 0.17, 1.19, 2.06, -0.36, 0.72, 0.66, -0.01, 1.27, 2.15, 0.368065468086443, 0.38, 0.62, 1.2, 0.21, 0.08, 0.91, -1.11, -1.01, 0.9531047225355607, -1.53, -0.46, -0.52, -1.19, 0.07, 0.95, -0.84, -0.81, -0.57, 0.01, 2.31, -1.85, -2.37, -1.31, -1.36, -2.02, -0.77, 0.09, -1.68, -1.64, -1.41, -0.84, -0.44, -1.61, 1.51, 0.53, 1.09, 1.03, 0.35, 1.63, 2.52, 0.71, 0.74, 0.98, 1.56, -1.21, -0.55, -0.06, -0.73, 0.54, 1.42, -0.38, -0.34, -0.11, 0.47, -0.14, -0.56, -2.41, -0.3, -0.35, -0.31, -0.49, -0.67, 0.6, 1.48, -0.32, -0.28, -0.05, 0.5885846838830657, -0.29, 0.18, 1.28, 2.16, 0.35, 0.39, 0.63, 1.21, -0.32, -0.11, 0.26, -0.52, -3.53, 0.03, 0.1, -0.32, 0.3, 0.14, -0.13, -1.52, 3.78, 0.64, 0.31, -0.86, -0.64, -0.87, 0.9, 0.93, -0.3, -0.46, -0.6, 0.8283906549799409, -0.37, -1.39, 4.627380952380952, 0.91, 1.42, -3.73, -1.09, 0.87, -0.91, -0.88, -0.64, -0.07, -0.9, -1.94, -1.77, -1.74, -1.5, -0.93, -0.18, 0.03, 0.27, 0.85, -0.46, -0.67, -0.21, 0.24, 0.82, -0.3, -0.33, -0.13, 2.49, -2.23, -2.59, -0.46, -1.01, -0.45, 0.58, -0.11, 0.5945528598385743, -0.32, -0.81, -0.31, -1.02, 0.63, -1.19, -0.4], ['502', -1.99, 0.15, -0.04, 0.07, 0.11, -0.28, -1.1458847420401708, -0.26, -0.8, 0.27, 0.99, 0.69, 0.37, 0.87, 0.43, 0.06107142857142857, 1.19, 0.17, -3.18, 0.38, 0.25, 0.98, 1.19, 0.82, -0.63, -0.6, -0.6773416050068874, -0.3, -0.61, -0.11, -0.55, -0.92, 0.2, -0.81, -4.12, -0.61, -0.73, 0.0, 0.2, -0.11615827680216084, 0.26, -1.5350638007838266, -0.41, -0.31, 0.18, -0.25, -0.63, 0.5, -0.51, -3.84, -0.31, -0.43, 0.29, 0.5, 0.14, -0.4, -0.99, -0.62, -0.94, -0.1, 0.5, 0.060799319727891155, -0.31, 0.81, -0.2, -3.54, 0.0, -0.12, 0.61, 0.81, 0.45, -0.14, -0.59, -0.44, -0.81, 0.32, -0.69, -4.01, -0.49, -0.4669183673469388, 0.11, 0.31, -0.05, -1.33, -2.39, 2.36, -0.16, -0.37, 0.76, -0.26, -3.59, -0.05, -0.18, 0.55, 0.75, 0.39, -1.13, 0.22, 1.13, 0.12, -3.23, 0.32, 0.19, 0.93, 1.13, 0.77, 0.121141873999017, 0.12, -1.65, -0.47, -0.55, -0.5, -0.9, -1.0, -4.32, -0.8, -0.93, -0.2, 0.0, -0.36, -0.67, 0.1, -3.34, 0.292244713705627, 0.08, 0.81, 1.01, 0.65, -1.55, -1.58, 0.08, -0.73, -3.93, 0.13, 0.14, 1.02, -1.01, -0.49, -0.07, 0.1, 0.23, 0.93, 0.5, -0.99, -0.04692021013122094, -1.51, 1.55, 1.55, -0.48, 1.67, -0.95, -0.6, 0.3147652642842468, -2.75, 0.76, 1.82, 2.67, -0.18, 3.56, 3.67, 3.54, 4.3, 4.51, 4.13, -1.38, -0.1, -0.12, 0.61, 0.81, 0.45, 0.02, 0.73, 0.93, 0.57, -0.75, -0.84, -0.7, 0.2, -0.16, -0.5, -0.5156036987247091, -0.26, 1.97, -1.67, -2.05, -0.7, 0.44, -0.9, -0.36, -1.1, -0.6, -0.44, -0.08, -0.21, -0.54, 0.23, 0.61, -0.8], ['503', -1.31, 0.0, -0.08, 0.19, -0.25, -0.32, 0.88, -1.03, -0.98, 0.05, 1.32, 0.36, 1.61, 1.62, 0.48, 0.46, 0.82, 0.0, -3.55, -0.04, -0.54, 1.36, 1.64, 0.38, -1.61, -0.82, -1.25, -0.95, 0.29, 0.29, -0.82, -0.84, -0.49, -1.3, -4.8, -1.34, -1.83, 0.04, 0.32, -0.93, 0.66, -1.1050638007838267, -0.31, 1.25, 1.25, 0.12, 0.11, 0.46, -0.36, -3.89, -0.4, -0.89, 1.0838655564790018, 1.27, 0.02, -1.1, -0.71, -0.73, -0.98, -1.54, 0.0, -1.11, -1.13, -0.78, -1.59, -5.08, -1.63, -2.12, -0.26, 0.02, -1.22, -1.14, -1.54, -1.12, -1.13, -0.78, -1.59, -5.08, -1.63, -2.12, -0.26, 0.02, -1.22, -1.42, -3.6, 3.58, -0.43, -0.02, 0.34, -0.48, -4.01, -0.52, -1.02, 0.87, 1.15, -0.0459922724755494, -1.71, -0.41, 0.35, -0.46, -3.9894285714285718, -0.5, -1.0, 0.89, 1.17, -0.09, 0.231141873999017, -0.36, -1.57, -0.45, -0.56, -0.28, -0.77, -0.82, -4.33, -0.8594642857142857, -1.35, 0.53, 0.81, -0.44, -1.16, 0.10307674813036727, -3.55, -0.04, -0.5304376417233561, 1.36, 1.64, 0.38, -1.18, -1.34, 0.17, -0.34, -5.47, -0.01, 0.07, 0.48, -0.43, -0.22, -0.44, -1.01, -0.19, 0.88, 0.4, -0.67, -0.08, -1.31, 1.21, 1.34, -0.43, 0.67, -0.86, -1.52, 0.75, -2.27, 15.02, 1.5, 2.21, 0.24, 3.73, 3.64, 3.12, 5.08, 5.38, 4.07, -1.33, 0.09, -0.5, 1.4, 1.68, 0.42, 0.59, 1.9, 2.19, 0.92, -0.96, -1.19, -1.29, 0.28, -0.96, -0.48, -0.42, -0.96, 7.65, -1.77, -7.81, -1.59, -0.05, -1.56, -1.24, -0.64, -0.32, 0.12, -0.06, 0.11, -0.33, -2.55, 0.57, 0.35], ['504', 3.65, -1.46, 0.23, -0.24, 0.14, 0.33, 1.2900361663652804, 0.18, 0.43, -1.32, -1.93, -2.23, -1.64, -2.18, -1.04, -2.91, -1.33, -1.55, 1.96, -2.57, -0.67, -1.24, -1.45, -1.85, 0.01, -0.28, 0.63, -0.3, 0.3, -0.25, 0.9, -1.0, 0.61, 0.5072589041444084, 3.96, -0.65, 1.28, 0.71, 0.49, 0.08, -0.12, 1.51, 0.93, 0.6, 0.05, 1.21, -0.7, 0.92, 0.69, 4.28, -0.35, 1.59, 1.01, 0.8, 0.39, 0.12006284630567655, 0.24, 0.57, 0.17, 0.33, -0.55, 0.61, -1.3, 0.32, 0.09, 3.66, -0.94, 0.98, 0.41, 0.19, -0.21, 0.6336060011417156, 0.88, 1.16, -0.75, 0.87, 0.64, 4.23, -0.4, 1.54, 0.96, 0.74, 0.34, 1.03, 0.611742947528662, -0.38, -0.28, -1.89, -0.29, -0.52, 3.03, -1.54, 0.38, -0.2, -0.41, -0.81, -0.027904761904761904, 1.65, 1.63, 1.4, 5.02, 0.36, 2.31, 1.73, 1.51, 1.1, 0.28, 1.6424455782312923, 0.5, 0.29, 0.28, 0.29567351865003194, 0.01, -0.23, 3.33, -1.26, 0.66, 0.09, -0.12, -0.53, -0.08, 0.24, 3.57, -1.03, 0.89, 0.32, 0.1, -0.3, 0.61, 0.45, -0.25, 0.37318678362356794, 0.0, 0.13, 0.05, -0.44, 0.46, 0.23, 0.36, 0.76, -2.62, -0.48, -0.27, 1.86, 0.35, 0.82, -0.72, -0.85, 0.27, -0.7, 0.53, 3.108390654979941, -1.52, 0.06, 0.72, -0.03, -0.05, 2.67, -3.21, -4.44, -2.58, -3.13, -3.34, -3.73, 0.8, 1.28, 1.95, 1.37, 1.15, 0.74, -0.65, -0.57, -0.78, -1.18, 0.63, 0.69, -0.08, -0.22, -0.62, 0.25, 0.24, 0.22257604962387836, 0.4, -0.1, -0.35, -0.03, 0.16, 0.21863744820097092, -0.4, 0.0, 0.32, 0.15, 0.87, 0.29, 0.54, -0.94, 0.58, 0.43], ['505', -3.94, 0.63, 0.041221715620458746, -0.07, -0.5, 0.92, 1.07, 0.5817205965359588, 1.25, 0.27, -1.31, -0.52, -0.25, -1.51, 0.86, 1.27, -0.95, -0.02, 0.27, 0.65, -0.11, -0.42, -1.44, -0.7, 1.56, 0.04, 1.6326583949931126, 0.8, 1.07, -0.2, 2.19, 2.61, 0.36, 1.31, 1.6, 1.98, 1.22, 0.9, -0.14, 0.62, -0.07, 2.1749361992161735, 0.79, 0.27, -1.0, 1.38, 1.8, -0.43, 0.5, 0.79, 1.18, 0.41, 0.1, -0.93, -0.18, 0.19, -0.5, 0.22, 1.51, 0.52, -1.26, 1.11, 1.52, -0.7, 0.23, 0.52, 0.9, 0.14, -0.17, -1.2, -0.45, 0.41, 1.81, 2.4, 2.82, 0.57, 1.51, 1.81, 2.19, 1.42, 1.11, 0.07, 0.82, 2.05, 4.48, -4.45, -0.58, 0.41, -1.79, -0.87, -0.58, -0.2, -0.95, -1.26, -2.28, -1.54, -2.17, -0.99, -2.19, -1.28, -0.99, -0.61, -1.36, -1.67, -2.68, -1.94, 0.36, -0.8406317967746538, 3.39, 0.97, 1.0, 0.89, 1.23, 0.94, 1.23, 1.62, 0.85, 0.54, -0.5, 0.25, 0.67, 0.29, 0.29, 0.67, -0.09, -0.4, -1.42, -0.68, 1.12, 1.4227619047619047, 0.14, 0.98, -6.35, 0.22, 0.2, -2.01, 2.01, 1.0, 0.72, -0.31, 0.67, -1.91, -0.97, -1.99, 0.5030797898687791, 2.98, -2.7, -2.87, 0.99, -3.01, 1.95, 0.4, -0.2, 3.58, -8.25, -2.47, -3.63, -0.67, 0.0, 0.38, -0.38, -0.6483894557823129, -1.71, -0.97, 2.9, -0.38, -0.75, -1.06, -2.08, -1.34, 0.38, -0.31, -1.34, -0.59, 1.28, 1.59, 0.7772746849074343, -1.03, -0.28, 0.95, 1.0643963012752908, 0.5, -4.2, 2.21, 4.27, 0.71, 0.76, 1.74, 0.76, 0.66, 1.12, 0.6, 0.06, 0.79, 0.98, -0.71, 0.58, 1.0], ['506', 1.61, 1.11, -0.17, -0.11, -0.24, 0.24, 1.1, -0.08, 0.29, 0.19, 0.72, -0.6592857142857144, 0.62, -0.53, 0.41, 0.38, -0.73, -0.23, -0.69, 0.38, -0.2, -1.91, -1.43, 0.04511662742019901, 0.72, 1.29, -0.53, -1.38, -0.11, -1.25, -0.32, -0.34, -1.44, -0.95, -1.41, -0.34, -0.92, -2.61, -2.14, -0.81, 0.74, -0.37506380078382656, 0.86, 1.29, 0.13, 1.07, 1.05, -0.06, 0.43, -0.03, 1.05, 0.46, -1.25, -0.78, 0.57, 0.13006284630567655, 0.53, 0.35, 0.33, -0.43, -1.14, -0.21, -0.24, -1.34, -0.85, -1.3, -0.24, -0.82, -2.51, -2.04, -0.71, 0.0, 0.72, 0.94, 0.92, -0.2, 0.3, -0.16, 0.92, 0.33, -1.38, -0.91, 0.44, -0.04, 4.38, -4.42, -0.21, -0.02, -1.13, -0.64, -1.09, -0.03, -0.61, -2.3, -1.83, -0.5, 0.29, -0.19, -1.1, -0.61, -1.07, 0.0, -0.5173734626473064, -2.28, -1.81, -0.48, 0.69, -0.19, 2.55, 0.51, 0.76, 0.37, 0.92, 0.5, 0.03, 1.11, 0.53, -1.19, -0.71, 0.63, 2.02, 0.42, -0.46, 0.61, 0.03, -1.68, -1.2, 0.14, 0.69, 0.44, -0.09, 1.07, 0.68, 0.48, 0.42, -0.44, 0.44, 0.21, 1.29, -0.55, 0.417758979116122, -0.96, -0.54, 0.8, 0.38, 1.81, -1.77, -1.56, 0.54, -0.64, 1.06, 1.87, -0.97, 2.68, -3.08, -1.86, -2.67, -0.4, 0.89, 1.08, 0.49, -1.22, -0.75, 0.6, 1.55, -0.19, -0.58, -2.28, -1.81, -0.47, 0.39, -1.71, -1.23, 0.11, 0.27, -0.08, 2.14, 0.48, 1.85, 0.49, 0.63, 0.0, -1.62, 1.78, 1.53, 0.68, 0.31, 1.65, 1.36, 0.12, 0.47, -0.06, 0.75, 0.34, 0.29, -0.1, 1.44, 0.63], ['507', 2.84, -0.72, -0.028778284379541254, -0.05, -1.06, -0.35, -0.9358847420401708, -1.06, -0.87, -0.09, 0.74, 0.63, 1.35, 1.58, 0.63, -0.32, 0.92, -0.06, -2.85, 1.58, -0.31, 0.74, 1.38, 0.38, -0.21, -1.44, -0.7873416050068875, -0.11, 0.61, 0.84, -0.11, -1.06, 0.18, -0.8, -3.57, 0.83, -1.04, 0.0, 0.63, -0.36, -0.47, -1.99, -0.71, 0.72, 1.1178753944468232, 0.0, -0.94, 0.3, -0.68, -3.46, 0.95, -0.93, 0.12, 0.75, -0.25, -0.37, -1.28, -0.23217202719021607, -0.73, -1.42, 0.23, -0.71, -1.65, -0.42, -1.39, -4.15, 0.23, -1.64, -0.6, 0.03, -0.96, -0.8, -1.64, -0.94, -1.88, -0.65, -1.62, -4.37, 0.0, -1.86, -0.83, -0.2, -1.19, -1.24, -3.78, 3.76, -0.71, -0.95, 0.29, -0.68, -3.46, 1.143744771101914, -0.93, 0.11, 0.75, -0.1959922724755494, -2.2673809523809525, 0.3173665312165629, 1.25, 0.26, -2.54, 1.91, 0.08262653735269351, 1.07, 1.71, 0.7, -0.02, 0.23, -1.45427628811696, -0.72, -0.91, -0.59, -1.0, -0.97, -3.74, 0.65, -1.22, -0.18, 0.45, -0.54, -0.81, -0.02, -2.8, 1.64, -0.25, 0.8, 1.44, 0.44, -1.35, -0.16, -0.22, -0.94, -4.51, -0.13, 0.0, 0.84, -0.85, -0.4, -0.25, -0.11, 3.37, 1.42, 0.67, 1.47, -0.28, -2.17, 2.21, 2.13, -0.7, 1.14, -1.4, 1.31, -0.66, -2.97, 0.29, 1.99, 2.94, -3.34, 2.85, 4.56, 2.62, 3.7, 4.36, 3.33, -2.05, -1.64, -1.86, -0.82, -0.2, -1.19, 0.22, 1.05, 1.69, 0.68, -0.92, -1.0, -0.82, 0.63, -0.36, -0.69, -0.76, -0.95, 0.09, -1.17, -0.19, -0.47, -1.57, -1.45, -0.99, -0.44, -0.43, -0.32, -0.3, -0.51, -0.46, -1.03, -2.41, -0.9269832262926028], ['508', -0.33, 0.23, 0.13122171562045873, -0.02, -0.61, -0.05, -0.46, -1.25, 0.14, -0.8278571428571428, -0.67, -1.1410079365079364, -0.36, 0.25, 1.43, -0.69, -0.75, -0.75, -2.47, 0.37, -0.79, -1.49, -1.17, -1.34, -0.76, -0.67, -0.12734160500688754, -0.48, 0.32, 0.93, 2.167819971295091, -0.02, -0.08, 0.03725890414440844, -1.81, 1.05, -0.12, -0.82, -0.5, -0.6261582768021609, -1.34, -0.7150638007838266, 0.32, 0.8, 1.43, 2.61, 0.47, 0.41, 0.41, -1.33, 1.54, 0.37, -0.34, -0.02, -0.19, -0.1, -1.5, -1.62, 0.11, -0.48, 0.62, 1.79, -0.33, -0.39, -0.4, -2.12, 0.73, -0.43, -1.13, -0.81, -0.98, -1.02, -1.09, 1.17, -0.94, -1.0, -1.01, -2.72, 0.11, -1.04, -1.74, -1.42, -1.5364403582748793, 0.06, 0.9, -1.02, -2.1933017616146797, -2.09, -2.14, -2.15, -3.84, -1.04, -2.19, -2.87, -2.56, -2.73, -2.68, -0.14, -0.06, -0.06, -1.79, 1.07, -0.1, -0.8, -0.48, -0.65, 0.03, -0.19, 1.4101046511627906, 0.07, 0.11, 0.05, -0.09, -0.01, -1.74, 1.12, -0.04, -0.74, -0.43, -0.59, 0.72, -0.08, -1.73, 1.13, -0.04, -0.6142004503433073, -0.42, -0.59, 0.46, 0.16, -0.06, 0.03318678362356798, -7.85, 0.02, 0.12, -0.15, 0.14, 0.07, 0.37, -1.49, 2.46, -0.13, -0.09, -0.12, 0.4, 0.17, -0.15, -0.16, 0.12329080486385297, -0.17, 0.12, 0.78, -0.4, -0.18, -3.95, 0.14, 0.1, -2.46, 1.68, 2.91, 1.72, 1.01, 1.33, 1.16, 0.2, -1.0656457669314812, -1.15, -1.85, -1.53, -1.7, -0.04, -0.7, -0.38, -0.55, 0.08, 0.04, 0.66, 0.32, 0.15, 0.09, 0.08, -1.19, -2.55, 0.40111637918066984, 2.43, -0.36, -0.66, 0.34, -0.17, -0.56, 0.0, 0.42, 0.8, 0.16, 0.51, -1.81, -1.01, 0.3330167737073973], ['509', -1.13, 0.06, 0.011221715620458745, 0.16, 0.78, 0.8284196236737595, -0.06, -0.39, 0.66, -0.18, -1.15, -0.72, 0.47, -0.45, 0.58, 0.46, -1.02, -0.43, -5.43, -0.95, -0.25, 0.6, 0.27, -0.74, 0.74, 0.27, 0.98, 0.43, 1.64, 0.71, 1.75, 1.63, 0.13, 0.73, -4.33, 0.2, 0.91, 1.77, 1.43, 0.41, -0.18, -0.21, 0.55, 1.2, 0.28, 1.31, 1.19, -0.3, 0.3, -4.74, -0.23, 0.47, 1.33, 1.0, -0.02, 0.76, 0.23, -0.8, 0.67, -0.64, -0.91, 0.11, -0.01, -1.48, -0.89, -5.88, -1.41, -0.72, 0.13, -0.2, -1.21, -0.94, 0.27, 1.03, 0.91, -0.58, 0.02, -5.01, -0.5, 0.19, 1.05, 0.71, -0.3, 0.77, -0.9382570524713382, 1.06, -0.75, -0.12, -1.59, -1.0, -5.98, -1.52, -0.83, 0.02, -0.31, -1.32, -1.0187766439909298, -0.5526334687834371, -1.47, -0.88, -5.86, -1.4, -0.71, 0.14, -0.19, -1.2, 0.23, -0.59, -0.82, 0.66, 0.38, 0.93, 0.85, 0.6, -4.46, 0.07, 0.77, 1.64, 1.3, 0.28, -0.8434639289282145, 0.25, -5.03, -0.52, 0.17, 1.03, 0.7, -0.32, -0.36, -0.14, 0.58, 0.77, -4.05, 0.23, 0.2, -2.62, 2.59, 1.31, -0.96, -0.63, -1.72, -1.3, -0.62, -0.53, 0.29, 2.05, -1.91, -2.03, 0.68, -3.95, 1.33, -0.6, 0.26, 2.52, 1.56, -1.72, -2.62, 1.5938095238095238, 5.56, 4.74, 5.48, 6.38, 6.03, 4.96, 2.0931678995607568, 0.78, 0.7, 1.56, 1.22, 0.21, 0.08, 0.86, 0.52, -0.49, 0.6, 0.59, -0.77, -0.33, -1.2577512446849837, 0.64, 0.67, -0.2874239503761216, 0.94, 0.51, -0.97, 0.39, 0.66, -0.44, -1.01, 1.68, 1.66, -0.08, 0.32, 0.19, 0.57, -0.23, 0.92, 1.17], ['510', -7.99, -0.78, 0.01, 0.2, -1.57, -1.0, -2.76, -1.99, -2.44, -1.74, 1.29, 1.1789920634920634, -0.26, -0.23, -0.1, -0.06, 0.21, -1.51, -1.74, 0.6, -2.21, -1.07, -0.23, -0.45, -1.16, -2.15, -2.99, -0.11, -1.53, -1.5, -1.37, -1.33, -1.06, -2.77, -2.99, -0.68, -3.45, -2.33, -1.5, -1.6761582768021608, -1.48, -2.98, -2.88, -1.42, -1.39, -1.26, -1.20359693877551, -0.9107210884353741, -2.66, -2.88, -0.57, -3.34, -2.22, -1.38, -1.61, -1.22, -1.63, -1.99, -2.35, -1.48, 0.03, 0.16, 0.21, 0.48, -1.25, -1.48, 0.86, -1.95, -0.81, 0.04, -0.19, -2.16, -1.51, 0.13, 0.17, 0.44, -1.29, -1.51, 0.83, -1.98, -0.84, 0.0, -0.23, -2.8, -3.94, 4.02, -1.64, 0.04, 0.32, -1.41, -1.64, 0.7, -2.11, -0.97, -0.13, -0.35, -4.9, -1.68, 0.27, -1.46, -1.68, 0.65, -2.15, -1.01, -0.17, -0.4, -0.41, -1.74, -1.31, -1.08, -0.98, -1.25, -1.95, -1.72, -1.95, 0.38, -2.42, -1.28, -0.44, -0.67, -0.64, -0.23, -0.23, 2.14, -0.7, 0.45, 1.31, 1.08, -1.16, -1.46, 0.31, -1.33, -14.62, -0.29, -0.14, 3.27, -3.31, -1.64, -0.27, -2.4, 4.66, 2.15, 1.07, -4.02, -0.26, -3.3, 3.32, 3.15, -1.08, 4.78, -2.16, -2.15, 1.11, -5.77, 9.04, 3.83, 5.7, -4.55, 0.0, 2.38, -0.47, 0.68, 1.54, 1.31, -3.25, -2.32, -2.78, -1.66, -0.82, -1.04, 0.48, 1.16, 2.02, 1.79, -2.37, -2.53, -0.68, 0.85, 0.62, -1.05, -1.2, -2.14, 5.57, -1.37, -5.64, -1.59, -1.43, -1.52, -0.23, -0.8, -1.46, -0.15, -0.01, -0.53, -1.29, -2.57, -2.34, -1.41]], 'figimage': <function figimage at 0x3195140>, 'jet': <function jet at 0x3198848>, 'figaspect': <function figaspect at 0x3183938>, 'Line2D': <class 'matplotlib.lines.Line2D'>, 'exp2': <ufunc 'exp2'>, 'imshow': <function imshow at 0x3197398>, 'axhline': <function axhline at 0x31968c0>, 'bool8': <type 'numpy.bool_'>, 'colormaps': <function colormaps at 0x31961b8>, 'msort': <function msort at 0x236d5f0>, 'alltrue': <function alltrue at 0x21da2a8>, 'zeros': <built-in function zeros>, 'identity': <function identity at 0x21dbde8>, 'False_': False, 'ispower2': <function ispower2 at 0x2c522a8>, 'LogFormatterExponent': <class 'matplotlib.ticker.LogFormatterExponent'>, 'ihfft': <function ihfft at 0x24090c8>, 'nansum': <function nansum at 0x236cb18>, 'bool_': <type 'numpy.bool_'>, '_i78': u'train.shape', '_44': (200, 198), 'inexact': <type 'numpy.inexact'>, 'distances_along_curve': <function distances_along_curve at 0x2c53c08>, 'broadcast': <type 'numpy.broadcast'>, 'copyto': <built-in function copyto>, 'amin': <function amin at 0x21da5f0>, 'arctanh': <ufunc 'arctanh'>, 'typecodes': {'All': '?bhilqpBHILQPefdgFDGSUVOMm', 'Complex': 'FDG', 'AllFloat': 'efdgFDG', 'Integer': 'bhilqp', 'UnsignedInteger': 'BHILQP', 'Float': 'efdg', 'Character': 'c', 'Datetime': 'Mm', 'AllInteger': 'bBhHiIlLqQpP'}, 'number': <type 'numpy.number'>, 'savetxt': <function savetxt at 0x23fb410>, 'copy': <function copy at 0x236c500>, 'int_': <type 'numpy.int64'>, '_i69': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'std': <function std at 0x21daaa0>, 'segments_intersect': <function segments_intersect at 0x2c51848>, 'not_equal': <ufunc 'not_equal'>, 'fromfunction': <function fromfunction at 0x21dbb18>, 'Figure': <class 'matplotlib.figure.Figure'>, 'tril_indices_from': <function tril_indices_from at 0x230db18>, 'double': <type 'numpy.float64'>, 'require': <function require at 0x21c2758>, 'predicted_probs': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.073016773707397273, 0.0, 0.0], 'triplot': <function triplot at 0x3197d70>, 'headers': array(['O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8', 'O9', 'O10', 'O11',\n       'O12', 'O13', 'O14', 'O15', 'O16', 'O17', 'O18', 'O19', 'O20',\n       'O21', 'O22', 'O23', 'O24', 'O25', 'O26', 'O27', 'O28', 'O29',\n       'O30', 'O31', 'O32', 'O33', 'O34', 'O35', 'O36', 'O37', 'O38',\n       'O39', 'O40', 'O41', 'O42', 'O43', 'O44', 'O45', 'O46', 'O47',\n       'O48', 'O49', 'O50', 'O51', 'O52', 'O53', 'O54', 'O55', 'O56',\n       'O57', 'O58', 'O59', 'O60', 'O61', 'O62', 'O63', 'O64', 'O65',\n       'O66', 'O67', 'O68', 'O69', 'O70', 'O71', 'O72', 'O73', 'O74',\n       'O75', 'O76', 'O77', 'O78', 'O79', 'O80', 'O81', 'O82', 'O83',\n       'O84', 'O85', 'O86', 'O87', 'O88', 'O89', 'O90', 'O91', 'O92',\n       'O93', 'O94', 'O95', 'O96', 'O97', 'O98', 'O99', 'O100', 'O101',\n       'O102', 'O103', 'O104', 'O105', 'O106', 'O107', 'O108', 'O109',\n       'O110', 'O111', 'O112', 'O113', 'O114', 'O115', 'O116', 'O117',\n       'O118', 'O119', 'O120', 'O121', 'O122', 'O123', 'O124', 'O125',\n       'O126', 'O127', 'O128', 'O129', 'O130', 'O131', 'O132', 'O133',\n       'O134', 'O135', 'O136', 'O137', 'O138', 'O139', 'O140', 'O141',\n       'O142', 'O143', 'O144', 'O145', 'O146', 'O147', 'O148', 'O149',\n       'O150', 'O151', 'O152', 'O153', 'O154', 'O155', 'O156', 'O157',\n       'O158', 'O159', 'O160', 'O161', 'O162', 'O163', 'O164', 'O165',\n       'O166', 'O167', 'O168', 'O169', 'O170', 'O171', 'O172', 'O173',\n       'O174', 'O175', 'O176', 'O177', 'O178', 'O179', 'O180', 'O181',\n       'O182', 'O183', 'O184', 'O185', 'O186', 'O187', 'O188', 'O189',\n       'O190', 'O191', 'O192', 'O193', 'O194', 'O195', 'O196', 'O197',\n       'O198', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10',\n       'I11', 'I12', 'I13', 'I14', 'I15', 'I16', 'I17', 'I18', 'I19',\n       'I20', 'I21', 'I22', 'I23', 'I24', 'I25', 'I26', 'I27', 'I28',\n       'I29', 'I30', 'I31', 'I32', 'I33', 'I34', 'I35', 'I36', 'I37',\n       'I38', 'I39', 'I40', 'I41', 'I42', 'I43', 'I44', 'I45', 'I46',\n       'I47', 'I48', 'I49', 'I50', 'I51', 'I52', 'I53', 'I54', 'I55',\n       'I56', 'I57', 'I58', 'I59', 'I60', 'I61', 'I62', 'I63', 'I64',\n       'I65', 'I66', 'I67', 'I68', 'I69', 'I70', 'I71', 'I72', 'I73',\n       'I74', 'I75', 'I76', 'I77', 'I78', 'I79', 'I80', 'I81', 'I82',\n       'I83', 'I84', 'I85', 'I86', 'I87', 'I88', 'I89', 'I90', 'I91',\n       'I92', 'I93', 'I94', 'I95', 'I96', 'I97', 'I98', 'I99', 'I100',\n       'I101', 'I102', 'I103', 'I104', 'I105', 'I106', 'I107', 'I108',\n       'I109', 'I110', 'I111', 'I112', 'I113', 'I114', 'I115', 'I116',\n       'I117', 'I118', 'I119', 'I120', 'I121', 'I122', 'I123', 'I124',\n       'I125', 'I126', 'I127', 'I128', 'I129', 'I130', 'I131', 'I132',\n       'I133', 'I134', 'I135', 'I136', 'I137', 'I138', 'I139', 'I140',\n       'I141', 'I142', 'I143', 'I144', 'I145', 'I146', 'I147', 'I148',\n       'I149', 'I150', 'I151', 'I152', 'I153', 'I154', 'I155', 'I156',\n       'I157', 'I158', 'I159', 'I160', 'I161', 'I162', 'I163', 'I164',\n       'I165', 'I166', 'I167', 'I168', 'I169', 'I170', 'I171', 'I172',\n       'I173', 'I174', 'I175', 'I176', 'I177', 'I178', 'I179', 'I180',\n       'I181', 'I182', 'I183', 'I184', 'I185', 'I186', 'I187', 'I188',\n       'I189', 'I190', 'I191', 'I192', 'I193', 'I194', 'I195', 'I196',\n       'I197', 'I198', 'I199', 'I200', 'I201', 'I202', 'I203', 'I204',\n       'I205', 'I206', 'I207', 'I208', 'I209', 'I210', 'I211', 'I212',\n       'I213', 'I214', 'I215', 'I216', 'I217', 'I218', 'I219', 'I220',\n       'I221', 'I222', 'I223', 'I224', 'I225', 'I226', 'I227', 'I228',\n       'I229', 'I230', 'I231', 'I232', 'I233', 'I234', 'I235', 'I236',\n       'I237', 'I238', 'I239', 'I240', 'I241', 'I242', 'I243', 'I244'], \n      dtype='|S10'), '_iii': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'xlabel': <function xlabel at 0x3195a28>, 'typeNA': {<type 'numpy.float16'>: 'Float16', <type 'numpy.int16'>: 'Int16', 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, <type 'numpy.timedelta64'>: 'Timedelta64', <type 'numpy.uint8'>: 'UInt8', 'c16': 'Complex64', <type 'numpy.datetime64'>: 'Datetime64', 'D': 'Complex64', <type 'numpy.int8'>: 'Int8', 'H': 'UInt16', 'L': 'UInt64', <type 'numpy.void'>: 'Void0', <type 'numpy.bool_'>: 'Bool', 'd': 'Float64', 'h': 'Int16', 'l': 'Int64', <type 'numpy.unicode_'>: 'Unicode0', 'c32': 'Complex128', <type 'numpy.string_'>: 'String0', 'Timedelta64': <type 'numpy.timedelta64'>, 'b1': 'Bool', 'M8': 'Datetime64', 'String0': <type 'numpy.string_'>, <type 'numpy.object_'>: 'Object0', 'I': 'UInt32', '?': 'Bool', 'Void0': <type 'numpy.void'>, <type 'numpy.complex256'>: 'Complex128', 'G': 'Complex128', 'O': 'Object0', 'UInt8': <type 'numpy.uint8'>, 'S': 'String0', <type 'numpy.complex128'>: 'Complex64', 'UInt64': <type 'numpy.uint64'>, 'g': 'Float128', <type 'numpy.complex64'>: 'Complex32', 'Float16': <type 'numpy.float16'>, <type 'numpy.float128'>: 'Float128', 'Bool': <type 'numpy.bool_'>, 'u8': <type 'numpy.uint64'>, <type 'numpy.float64'>: 'Float64', 'u4': <type 'numpy.uint32'>, 'Unicode0': <type 'numpy.unicode_'>, 'u1': <type 'numpy.uint8'>, 'u2': <type 'numpy.uint16'>, 'Datetime64': <type 'numpy.datetime64'>, 'Int8': <type 'numpy.int8'>, <type 'numpy.float32'>: 'Float32', 'B': 'UInt8', 'F': 'Complex32', 'c8': 'Complex32', 'Int64': <type 'numpy.int64'>, 'Complex32': <type 'numpy.complex64'>, 'V': 'Void0', <type 'numpy.uint64'>: 'UInt64', 'b': 'Int8', 'f': 'Float32', 'm8': 'Timedelta64', <type 'numpy.int64'>: 'Int64', 'f16': 'Float128', 'UInt32': <type 'numpy.uint32'>, 'f2': 'Float16', 'f4': 'Float32', 'f8': 'Float64', 'Complex128': <type 'numpy.complex256'>, <type 'numpy.uint64'>: 'UInt64', 'Object0': <type 'numpy.object_'>, 'Int16': <type 'numpy.int16'>, <type 'numpy.int64'>: 'Int64', 'Float64': <type 'numpy.float64'>, 'UInt16': <type 'numpy.uint16'>, 'Float32': <type 'numpy.float32'>, 'i8': <type 'numpy.int64'>, <type 'numpy.uint32'>: 'UInt32', 'i1': <type 'numpy.int8'>, 'i2': <type 'numpy.int16'>, 'M': 'Datetime64', 'i4': <type 'numpy.int32'>, 'Q': 'UInt64', 'U': 'Unicode0', <type 'numpy.int32'>: 'Int32', 'e': 'Float16', 'i': 'Int32', 'm': 'Timedelta64', 'q': 'Int64', <type 'numpy.uint16'>: 'UInt16', 'Float128': <type 'numpy.float128'>}, '_i11': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', 'lastObserved': array([[ 2.78,  0.77,  0.1 , ...,  3.25,  3.05,  1.55],\n       [-4.62,  0.06, -0.22, ...,  0.52, -0.56,  0.33],\n       [ 0.02,  0.13,  0.18, ..., -0.47,  0.91,  0.97],\n       ..., \n       [-0.33,  0.23,  0.12, ..., -1.81, -1.01,  0.26],\n       [-1.13,  0.06,  0.  , ..., -0.23,  0.92,  1.17],\n       [-7.99, -0.78,  0.01, ..., -2.57, -2.34, -1.41]]), 'getbuffer': <built-in function getbuffer>, 'xcorr': <function xcorr at 0x3197e60>, 'slogdet': <function slogdet at 0x238cb90>, 'clip': <function clip at 0x21da0c8>, 'tripcolor': <function tripcolor at 0x3197cf8>, '_i27': u'trainInput.shape', 'half': <type 'numpy.float16'>, 'normal': <built-in method normal of mtrand.RandomState object at 0x7f399f841690>, '_i126': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', 'savez_compressed': <function savez_compressed at 0x23fb230>, 'TickHelper': <class 'matplotlib.ticker.TickHelper'>, 'isinteractive': <function isinteractive at 0x3194410>, 'eigvals': <function eigvals at 0x238c758>, 'seed': <built-in method seed of mtrand.RandomState object at 0x7f399f841690>, 'triu_indices_from': <function triu_indices_from at 0x230dc08>, 'conjugate': <ufunc 'conjugate'>, 'clim': <function clim at 0x3196320>, 'array2string': <function array2string at 0x21db050>, 'alterdot': <built-in function alterdot>, 'cross_validation': <module 'sklearn.cross_validation' from '/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc'>, 'asfortranarray': <function asfortranarray at 0x21c26e0>, 'binary_repr': <function binary_repr at 0x21dbc08>, 'angle': <function angle at 0x236c6e0>, '_78': (510, 55, 442), '_i9': u'len(targets)', 'randint': <built-in method randint of mtrand.RandomState object at 0x7f399f841690>, '_i7': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(trainOutput), n_folds=63, indices=False)', '_i6': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(train), n_folds=63, indices=False)', '_i5': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', 'linalg': <module 'numpy.linalg' from '/usr/local/lib/python2.7/dist-packages/numpy/linalg/__init__.pyc'>, 'apply_over_axes': <function apply_over_axes at 0x2374b18>, '_i2': u'ls', '_i1': u'cd /home/lane/Kaggle/03\\\\ Predicting\\\\ Stock\\\\ Prices/', 'yoda': array([ 0.        ,  0.22      ,  0.        ,  0.        ,  0.22      ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.1       ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.02714286,  0.        ,  0.01714286,\n        0.        ,  0.1       ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.02714286,  0.        ,  0.        ,  0.01714286,\n        0.        ,  0.        ,  0.61571429,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.61571429,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.02714286,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.1       ,  0.        ,  0.        ,\n        0.02714286,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.22      ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.02714286,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.61571429,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.1       ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.22      ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.61571429,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'figlegend': <function figlegend at 0x3194de8>, 'ERR_LOG': 5, 'right_shift': <ufunc 'right_shift'>, 'take': <function take at 0x21d16e0>, 'rollaxis': <function rollaxis at 0x21c2c08>, 'set_state': <built-in method set_state of mtrand.RandomState object at 0x7f399f841690>, 'solve': <function solve at 0x238c500>, 'FixedFormatter': <class 'matplotlib.ticker.FixedFormatter'>, 'boxplot': <function boxplot at 0x3196c08>, 'SecondLocator': <class 'matplotlib.dates.SecondLocator'>, 'spectral': <function spectral at 0x3198b18>, 'get_numarray_include': <function get_numarray_include at 0x23691b8>, 'trace': <function trace at 0x21d1de8>, 'Artist': <class 'matplotlib.artist.Artist'>, 'any': <function any at 0x21da320>, 'Button': <class 'matplotlib.widgets.Button'>, 'who': <function who at 0x2369578>, 'compress': <function compress at 0x21da050>, 'NullFormatter': <class 'matplotlib.ticker.NullFormatter'>, 'histogramdd': <function histogramdd at 0x236c2a8>, '_i88': u'test.shape', '_i89': u'y.shape', 'beta': <built-in method beta of mtrand.RandomState object at 0x7f399f841690>, 'amap': <function amap at 0x2c51d70>, 'multiply': <ufunc 'multiply'>, '_i81': u'X.shape', 'mask_indices': <function mask_indices at 0x230da28>, 'detrend_none': <function detrend_none at 0x2c4f7d0>, '_i84': u'test.shape', 'amax': <function amax at 0x21da578>, 'numCols': 442, '_66': (510, 55, 198), 'subplot': <function subplot at 0x3195500>, 'logical_not': <ufunc 'logical_not'>, 'dist_point_to_segment': <function dist_point_to_segment at 0x2c517d0>, 'trainingDays': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510], '_i75': u'traincv.shape', '_i74': u'traincv', '_i77': u'train[traincv]', '_i76': u'testcv.shape', '_i71': u'cv', 'nbytes': {<type 'numpy.float16'>: 2, <type 'numpy.string_'>: 0, <type 'numpy.float128'>: 16, <type 'numpy.uint64'>: 8, <type 'numpy.int16'>: 2, <type 'numpy.timedelta64'>: 8, <type 'numpy.object_'>: 8, <type 'numpy.float64'>: 8, <type 'numpy.int64'>: 8, <type 'numpy.uint8'>: 1, <type 'numpy.datetime64'>: 8, <type 'numpy.complex256'>: 32, <type 'numpy.float32'>: 4, <type 'numpy.uint32'>: 4, <type 'numpy.int8'>: 1, <type 'numpy.void'>: 0, <type 'numpy.complex128'>: 16, <type 'numpy.uint64'>: 8, <type 'numpy.int32'>: 4, <type 'numpy.bool_'>: 1, <type 'numpy.unicode_'>: 0, <type 'numpy.complex64'>: 8, <type 'numpy.int64'>: 8, <type 'numpy.uint16'>: 2}, 'exp': <ufunc 'exp'>, '_ih': ['', u\"get_ipython().magic(u'cd /home/lane/Kaggle/03\\\\\\\\ Predicting\\\\\\\\ Stock\\\\\\\\ Prices/')\", u\"get_ipython().system(u'ls -F --color ')\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(train), n_folds=63, indices=False)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(trainOutput), n_folds=63, indices=False)', u'len(trainOutput)', u'len(targets)', u'len(target)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'trainInput.shape', u'trainOutput.shape', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:197] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:198] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'trainInput[509,54,243]', u'trainInput[509,54,244]', u'trainInput[509,54,243]', u'fullInput[509,54,244+197]', u'train            = np.zeros((510,55,244+198))\\ntrain[:,:,0:198] = trainOutput\\ntrain[:,:,198:]  = trainInput', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(target[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'trainOutput.shape', u'len(trainOutput[0])', u'target.shape', u'target.shape', u'trainInput.shape', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput(:,-1,:)', u'lastObserved = trainOutput[:,-1,:]\\nlastObserved.shape', u'target.shape', u'normTarget   = target - lastObserved[:target.shape[0],:]', u'normTarget.shape', u'target.shape', u'plot(normTarget[:,0])', u'plot(normTarget[:,197])', u'hist(normTarget[:,197])', u'hist(normTarget)', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1)))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1)))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1))', u'yoda.shape', u'normTarget.shape', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-2,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((200*198,1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True)', u\"yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,4)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,6)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nyaxis('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',norm=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',normed=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\nderiv.shape', u'normTarget.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'len(target)', u'cv', u'for i in cv:\\n    print i', u'for i,j in cv:\\n    print i,j', u'traincv', u'traincv.shape', u'testcv.shape', u'train[traincv]', u'train.shape', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201,:]\\ntest  = X[201:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201]\\ntest  = X[201:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'train.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:200]\\ntest  = X[200:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'y.shape', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'train.shape', u'test.shape', u'yoda = X.reshape((X.shape[0],1))', u'yoda.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock].reshape((deriv.shape[0],1))\\ny     = normTarget[:,stock]\\ntrain = X[:200,:]\\ntest  = X[200:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'predicted_probs.shape', u'len(predicted_probs)', u'len(predicted_probs[0])', u'lastObserved[:,stock].shape', u'pred = predicted_probs + lastObserved[200:,stock]', u'pred = predicted_probs + lastObserved[200:,stock]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape[2]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'numStocks', u'type(predicted_probs)', u'yoda = np.asarray(predicted_probs)\\nyoda.shape', u'yoda = np.asarray(predicted_probs)\\nluke = np.zeros((310,198))\\nluke[:,0] = yoda', u'pred[0]', u'## Fit Random Forest and generate predictions\\nnumStocks   = trainOutput.shape[2]\\nperformance = []\\npred        = np.zeros((310,numStocks))\\nfor stock in xrange(numStocks):\\n    \\n    # get stock-specific features\\n    X     = deriv[:,stock].reshape((deriv.shape[0],1))\\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n\\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n\\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import smtplib', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import pybrain', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random\\nimport smtplib\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=500, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=25, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'sheet.shape', u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection'], 'axvspan': <function axvspan at 0x3196a28>, 'FuncFormatter': <class 'matplotlib.ticker.FuncFormatter'>, 'dot': <built-in function dot>, 'int0': <type 'numpy.int64'>, 'pylab': <module 'matplotlib.pylab' from '/usr/local/lib/python2.7/dist-packages/matplotlib/pylab.pyc'>, '_i23': u'trainOutput.shape', 'WE': WE, '_i121': u'import pybrain', 'longfloat': <type 'numpy.float128'>, 'draw_if_interactive': <function wrapper at 0x325c410>, 'rayleigh': <built-in method rayleigh of mtrand.RandomState object at 0x7f399f841690>, 'text': <function text at 0x31981b8>, 'random': <module 'random' from '/usr/lib/python2.7/random.pyc'>, 'demean': <function demean at 0x2c4f6e0>, 'random_integers': <built-in method random_integers of mtrand.RandomState object at 0x7f399f841690>, 'datetime': <module 'datetime' from '/usr/lib/python2.7/lib-dynload/datetime.so'>, 'colors': <function colors at 0x3196140>, 'stackplot': <function stackplot at 0x3197a28>, '_i124': u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", 'locator_params': <function locator_params at 0x3198320>, '_67': (510, 198), '_i125': u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', 'find': <function find at 0x2c51050>, '_i20': u'train            = np.zeros((510,55,244+198))\\ntrain[:,:,0:198] = trainOutput\\ntrain[:,:,198:]  = trainInput', 'pause': <function pause at 0x3194578>, 'randn': <built-in method randn of mtrand.RandomState object at 0x7f399f841690>, 'errstate': <class 'numpy.core.numeric.errstate'>, 'title': <function title at 0x3195938>, 'FPE_UNDERFLOW': 4, '_i108': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_8': 510, '_i113': u'type(predicted_probs)', 'frexp': <ufunc 'frexp'>, 'savefig': <function savefig at 0x3194e60>, 'PolarAxes': <class 'matplotlib.projections.polar.PolarAxes'>, 'DAILY': 3, 'center_matrix': <function center_matrix at 0x2c51500>, '_65': <matplotlib.text.Text object at 0x92e02d0>, 'smtplib': <module 'smtplib' from '/usr/lib/python2.7/smtplib.pyc'>, 'SHIFT_OVERFLOW': 3, 'over': <function over at 0x31952a8>, 'complex256': <type 'numpy.complex256'>, 'plotfile': <function plotfile at 0x31965f0>, '_i96': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock].reshape((deriv.shape[0],1))\\ny     = normTarget[:,stock]\\ntrain = X[:200,:]\\ntest  = X[200:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'get': <function getp at 0x2a9d1b8>, 'luke': array([[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.22,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       ..., \n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ]]), 'NZERO': -0.0, 'ceil': <ufunc 'ceil'>, 'ones': <function ones at 0x21c2410>, 'add_newdoc_ufunc': <built-in function add_newdoc_ufunc>, 'X': array([[  0.04    ,   1.5     ,   2.      , ...,   0.439681,   0.074476,\n          0.142166],\n       [ -0.11    ,   0.789473,  19.      , ...,   0.767666,   0.147196,\n          0.272029],\n       [ -0.08    ,   0.5     ,  12.      , ...,   0.216333,   0.062503,\n          0.062272],\n       ..., \n       [  0.27    ,   0.323529,  34.      , ...,   0.179467,   0.085557,\n          0.083333],\n       [  0.      ,   0.294117,  17.      , ...,   0.195387,   0.076333,\n          0.062539],\n       [  0.31    ,   1.6     ,   5.      , ...,   1.05697 ,   0.411582,\n          0.452769]]), 'count_nonzero': <built-in function count_nonzero>, 'target': array([[ 2.53,  1.03,  0.12, ...,  3.69,  3.56,  2.03],\n       [-4.95,  0.18, -0.24, ...,  1.22, -0.04,  0.38],\n       [ 0.16,  0.  ,  0.2 , ..., -0.04,  1.3 ,  1.61],\n       ..., \n       [-1.02,  1.53,  0.62, ...,  3.85,  4.87,  2.06],\n       [ 0.43,  0.12, -0.08, ..., -0.59, -0.67,  0.2 ],\n       [ 0.11,  0.  ,  0.29, ...,  0.48,  2.58,  0.47]]), '_108': <matplotlib.text.Text object at 0x918f1d0>, 'gray': <function gray at 0x31986e0>, 'qr': <function qr at 0x238c6e0>, 'bar': <function bar at 0x3196aa0>, '_102': 310, 'median': <function median at 0x236d668>, '_i99': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'geterr': <function geterr at 0x21dd140>, 'convolve': <function convolve at 0x21c2a28>, 'twiny': <function twiny at 0x31956e0>, 'logistic': <built-in method logistic of mtrand.RandomState object at 0x7f399f841690>, 'weibull': <built-in method weibull of mtrand.RandomState object at 0x7f399f841690>, 'x': array([ 0.004,  0.02 ,  0.004,  0.002,  0.002,  0.006,  0.002,  0.002,\n        0.008,  0.   ,  0.002,  0.   ,  0.   ,  0.   ,  0.002,  0.004,\n        0.   ,  0.006,  0.002,  0.012,  0.018,  0.006,  0.004,  0.002,\n        0.012,  0.026,  0.006,  0.02 ,  0.012,  0.   ,  0.002,  0.002,\n        0.   ,  0.004,  0.008,  0.002,  0.006,  0.   ,  0.   ,  0.012,\n        0.006,  0.01 ,  0.012,  0.004,  0.006,  0.012,  0.012,  0.   ,\n        0.01 ,  0.002,  0.006,  0.008,  0.014,  0.   ,  0.   ,  0.006,\n        0.008,  0.004,  0.018,  0.008,  0.01 ,  0.002,  0.   ,  0.006,\n        0.   ,  0.016,  0.018,  0.   ,  0.004,  0.004,  0.004,  0.008,\n        0.01 ,  0.012,  0.004,  0.002,  0.004,  0.01 ,  0.002,  0.006,\n        0.006,  0.004,  0.004,  0.004,  0.03 ,  0.008,  0.   ,  0.006,\n        0.004,  0.008,  0.   ,  0.014,  0.03 ,  0.01 ,  0.004,  0.004,\n        0.016,  0.004,  0.002,  0.004,  0.   ,  0.002,  0.004,  0.008,\n        0.002,  0.004,  0.   ,  0.006,  0.004,  0.004,  0.006,  0.002,\n        0.016,  0.004,  0.032,  0.012,  0.   ,  0.01 ,  0.   ,  0.002,\n        0.   ,  0.   ,  0.016,  0.002,  0.004,  0.008,  0.008,  0.   ,\n        0.002,  0.004,  0.01 ,  0.006,  0.002,  0.002,  0.006,  0.002,\n        0.006,  0.004,  0.008,  0.   ,  0.006,  0.002,  0.004,  0.   ,\n        0.002,  0.006,  0.006,  0.   ,  0.   ,  0.   ,  0.002,  0.016,\n        0.004,  0.028,  0.002,  0.004,  0.002,  0.   ,  0.002,  0.01 ,\n        0.002,  0.   ,  0.002,  0.002,  0.   ,  0.012,  0.002,  0.   ,\n        0.016,  0.004,  0.   ,  0.006]), 'isreal': <function isreal at 0x23017d0>, 'where': <built-in function where>, 'rcParamsDefault': RcParams({'agg.path.chunksize': 0,\n          'animation.avconv_args': '',\n          'animation.avconv_path': 'avconv',\n          'animation.bitrate': -1,\n          'animation.codec': 'mpeg4',\n          'animation.convert_args': '',\n          'animation.convert_path': 'convert',\n          'animation.ffmpeg_args': '',\n          'animation.ffmpeg_path': 'ffmpeg',\n          'animation.frame_format': 'png',\n          'animation.mencoder_args': '',\n          'animation.mencoder_path': 'mencoder',\n          'animation.writer': 'ffmpeg',\n          'axes.axisbelow': False,\n          'axes.color_cycle': ['b', 'g', 'r', 'c', 'm', 'y', 'k'],\n          'axes.edgecolor': 'k',\n          'axes.facecolor': 'w',\n          'axes.formatter.limits': [-7, 7],\n          'axes.formatter.use_locale': False,\n          'axes.formatter.use_mathtext': False,\n          'axes.grid': False,\n          'axes.hold': True,\n          'axes.labelcolor': 'k',\n          'axes.labelsize': 'medium',\n          'axes.labelweight': 'normal',\n          'axes.linewidth': 1.0,\n          'axes.titlesize': 'large',\n          'axes.unicode_minus': True,\n          'axes.xmargin': 0,\n          'axes.ymargin': 0,\n          'axes3d.grid': True,\n          'backend': 'Agg',\n          'backend.qt4': 'PyQt4',\n          'backend_fallback': True,\n          'contour.negative_linestyle': 'dashed',\n          'datapath': '/usr/local/lib/python2.7/dist-packages/matplotlib/mpl-data',\n          'docstring.hardcopy': False,\n          'examples.directory': '',\n          'figure.autolayout': False,\n          'figure.dpi': 80,\n          'figure.edgecolor': 'w',\n          'figure.facecolor': '0.75',\n          'figure.figsize': [8.0, 6.0],\n          'figure.frameon': True,\n          'figure.max_open_warning': 20,\n          'figure.subplot.bottom': 0.1,\n          'figure.subplot.hspace': 0.2,\n          'figure.subplot.left': 0.125,\n          'figure.subplot.right': 0.9,\n          'figure.subplot.top': 0.9,\n          'figure.subplot.wspace': 0.2,\n          'font.cursive': ['Apple Chancery',\n                           'Textile',\n                           'Zapf Chancery',\n                           'Sand',\n                           'cursive'],\n          'font.family': 'sans-serif',\n          'font.fantasy': ['Comic Sans MS',\n                           'Chicago',\n                           'Charcoal',\n                           'ImpactWestern',\n                           'fantasy'],\n          'font.monospace': ['Bitstream Vera Sans Mono',\n                             'DejaVu Sans Mono',\n                             'Andale Mono',\n                             'Nimbus Mono L',\n                             'Courier New',\n                             'Courier',\n                             'Fixed',\n                             'Terminal',\n                             'monospace'],\n          'font.sans-serif': ['Bitstream Vera Sans',\n                              'DejaVu Sans',\n                              'Lucida Grande',\n                              'Verdana',\n                              'Geneva',\n                              'Lucid',\n                              'Arial',\n                              'Helvetica',\n                              'Avant Garde',\n                              'sans-serif'],\n          'font.serif': ['Bitstream Vera Serif',\n                         'DejaVu Serif',\n                         'New Century Schoolbook',\n                         'Century Schoolbook L',\n                         'Utopia',\n                         'ITC Bookman',\n                         'Bookman',\n                         'Nimbus Roman No9 L',\n                         'Times New Roman',\n                         'Times',\n                         'Palatino',\n                         'Charter',\n                         'serif'],\n          'font.size': 12,\n          'font.stretch': 'normal',\n          'font.style': 'normal',\n          'font.variant': 'normal',\n          'font.weight': 'normal',\n          'grid.alpha': 1.0,\n          'grid.color': 'k',\n          'grid.linestyle': ':',\n          'grid.linewidth': 0.5,\n          'image.aspect': 'equal',\n          'image.cmap': 'jet',\n          'image.interpolation': 'bilinear',\n          'image.lut': 256,\n          'image.origin': 'upper',\n          'image.resample': False,\n          'interactive': False,\n          'keymap.all_axes': 'a',\n          'keymap.back': ['left', 'c', 'backspace'],\n          'keymap.forward': ['right', 'v'],\n          'keymap.fullscreen': ('f', 'ctrl+f'),\n          'keymap.grid': 'g',\n          'keymap.home': ['h', 'r', 'home'],\n          'keymap.pan': 'p',\n          'keymap.quit': ('ctrl+w', 'cmd+w'),\n          'keymap.save': ('s', 'ctrl+s'),\n          'keymap.xscale': ['k', 'L'],\n          'keymap.yscale': 'l',\n          'keymap.zoom': 'o',\n          'legend.borderaxespad': 0.5,\n          'legend.borderpad': 0.4,\n          'legend.columnspacing': 2.0,\n          'legend.fancybox': False,\n          'legend.fontsize': 'large',\n          'legend.frameon': True,\n          'legend.handleheight': 0.7,\n          'legend.handlelength': 2.0,\n          'legend.handletextpad': 0.8,\n          'legend.isaxes': True,\n          'legend.labelspacing': 0.5,\n          'legend.loc': 'upper right',\n          'legend.markerscale': 1.0,\n          'legend.numpoints': 2,\n          'legend.scatterpoints': 3,\n          'legend.shadow': False,\n          'lines.antialiased': True,\n          'lines.color': 'b',\n          'lines.dash_capstyle': 'butt',\n          'lines.dash_joinstyle': 'round',\n          'lines.linestyle': '-',\n          'lines.linewidth': 1.0,\n          'lines.marker': 'None',\n          'lines.markeredgewidth': 0.5,\n          'lines.markersize': 6,\n          'lines.solid_capstyle': 'projecting',\n          'lines.solid_joinstyle': 'round',\n          'mathtext.bf': 'serif:bold',\n          'mathtext.cal': 'cursive',\n          'mathtext.default': 'it',\n          'mathtext.fallback_to_cm': True,\n          'mathtext.fontset': 'cm',\n          'mathtext.it': 'serif:italic',\n          'mathtext.rm': 'serif',\n          'mathtext.sf': 'sans\\\\-serif',\n          'mathtext.tt': 'monospace',\n          'patch.antialiased': True,\n          'patch.edgecolor': 'k',\n          'patch.facecolor': 'b',\n          'patch.linewidth': 1.0,\n          'path.effects': [],\n          'path.simplify': True,\n          'path.simplify_threshold': 0.1111111111111111,\n          'path.sketch': None,\n          'path.snap': True,\n          'pdf.compression': 6,\n          'pdf.fonttype': 3,\n          'pdf.inheritcolor': False,\n          'pdf.use14corefonts': False,\n          'pgf.debug': False,\n          'pgf.preamble': [''],\n          'pgf.rcfonts': True,\n          'pgf.texsystem': 'xelatex',\n          'plugins.directory': '.matplotlib_plugins',\n          'polaraxes.grid': True,\n          'ps.distiller.res': 6000,\n          'ps.fonttype': 3,\n          'ps.papersize': 'letter',\n          'ps.useafm': False,\n          'ps.usedistiller': False,\n          'savefig.bbox': None,\n          'savefig.directory': '~',\n          'savefig.dpi': 100,\n          'savefig.edgecolor': 'w',\n          'savefig.extension': 'png',\n          'savefig.facecolor': 'w',\n          'savefig.format': 'png',\n          'savefig.frameon': True,\n          'savefig.jpeg_quality': 95,\n          'savefig.orientation': 'portrait',\n          'savefig.pad_inches': 0.1,\n          'svg.embed_char_paths': True,\n          'svg.fonttype': 'path',\n          'svg.image_inline': True,\n          'svg.image_noscale': False,\n          'text.antialiased': True,\n          'text.color': 'k',\n          'text.dvipnghack': None,\n          'text.hinting': True,\n          'text.hinting_factor': 8,\n          'text.latex.preamble': [''],\n          'text.latex.preview': False,\n          'text.latex.unicode': False,\n          'text.usetex': False,\n          'timezone': 'UTC',\n          'tk.pythoninspect': False,\n          'tk.window_focus': False,\n          'toolbar': 'toolbar2',\n          'verbose.fileo': 'sys.stdout',\n          'verbose.level': 'silent',\n          'webagg.open_in_browser': True,\n          'webagg.port': 8988,\n          'webagg.port_retries': 50,\n          'xtick.color': 'k',\n          'xtick.direction': 'in',\n          'xtick.labelsize': 'medium',\n          'xtick.major.pad': 4,\n          'xtick.major.size': 4,\n          'xtick.major.width': 0.5,\n          'xtick.minor.pad': 4,\n          'xtick.minor.size': 2,\n          'xtick.minor.width': 0.5,\n          'ytick.color': 'k',\n          'ytick.direction': 'in',\n          'ytick.labelsize': 'medium',\n          'ytick.major.pad': 4,\n          'ytick.major.size': 4,\n          'ytick.major.width': 0.5,\n          'ytick.minor.pad': 4,\n          'ytick.minor.size': 2,\n          'ytick.minor.width': 0.5}), 'fftsurr': <function fftsurr at 0x2c518c0>, 'SHIFT_UNDERFLOW': 6, 'argmax': <function argmax at 0x21d1b18>, 'minorticks_on': <function minorticks_on at 0x3195de8>, 'prctile': <function prctile at 0x2c51230>, 'deprecate_with_doc': <function <lambda> at 0x2369410>, 'imsave': <function imsave at 0x3196500>, 'polyder': <function polyder at 0x238ce60>, 'LogFormatterMathtext': <class 'matplotlib.ticker.LogFormatterMathtext'>, 'imread': <function imread at 0x3196488>, 'close': <function close at 0x3194b90>, 'DayLocator': <class 'matplotlib.dates.DayLocator'>, 'Formatter': <class 'matplotlib.ticker.Formatter'>, 'is_string_like': <function is_string_like at 0x29927d0>, 'contour': <function contour at 0x3196d70>, 'rad2deg': <ufunc 'rad2deg'>, 'isnan': <ufunc 'isnan'>, 'autoscale': <function autoscale at 0x3198488>, 'firstLine': ['fileId', 'O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8', 'O9', 'O10', 'O11', 'O12', 'O13', 'O14', 'O15', 'O16', 'O17', 'O18', 'O19', 'O20', 'O21', 'O22', 'O23', 'O24', 'O25', 'O26', 'O27', 'O28', 'O29', 'O30', 'O31', 'O32', 'O33', 'O34', 'O35', 'O36', 'O37', 'O38', 'O39', 'O40', 'O41', 'O42', 'O43', 'O44', 'O45', 'O46', 'O47', 'O48', 'O49', 'O50', 'O51', 'O52', 'O53', 'O54', 'O55', 'O56', 'O57', 'O58', 'O59', 'O60', 'O61', 'O62', 'O63', 'O64', 'O65', 'O66', 'O67', 'O68', 'O69', 'O70', 'O71', 'O72', 'O73', 'O74', 'O75', 'O76', 'O77', 'O78', 'O79', 'O80', 'O81', 'O82', 'O83', 'O84', 'O85', 'O86', 'O87', 'O88', 'O89', 'O90', 'O91', 'O92', 'O93', 'O94', 'O95', 'O96', 'O97', 'O98', 'O99', 'O100', 'O101', 'O102', 'O103', 'O104', 'O105', 'O106', 'O107', 'O108', 'O109', 'O110', 'O111', 'O112', 'O113', 'O114', 'O115', 'O116', 'O117', 'O118', 'O119', 'O120', 'O121', 'O122', 'O123', 'O124', 'O125', 'O126', 'O127', 'O128', 'O129', 'O130', 'O131', 'O132', 'O133', 'O134', 'O135', 'O136', 'O137', 'O138', 'O139', 'O140', 'O141', 'O142', 'O143', 'O144', 'O145', 'O146', 'O147', 'O148', 'O149', 'O150', 'O151', 'O152', 'O153', 'O154', 'O155', 'O156', 'O157', 'O158', 'O159', 'O160', 'O161', 'O162', 'O163', 'O164', 'O165', 'O166', 'O167', 'O168', 'O169', 'O170', 'O171', 'O172', 'O173', 'O174', 'O175', 'O176', 'O177', 'O178', 'O179', 'O180', 'O181', 'O182', 'O183', 'O184', 'O185', 'O186', 'O187', 'O188', 'O189', 'O190', 'O191', 'O192', 'O193', 'O194', 'O195', 'O196', 'O197', 'O198'], 'get_xyz_where': <function get_xyz_where at 0x2c51668>, 'irr': <function irr at 0x23fe050>, 'sctypeDict': {0: <type 'numpy.bool_'>, 1: <type 'numpy.int8'>, 2: <type 'numpy.uint8'>, 3: <type 'numpy.int16'>, 4: <type 'numpy.uint16'>, 5: <type 'numpy.int32'>, 6: <type 'numpy.uint32'>, 7: <type 'numpy.int64'>, 8: <type 'numpy.uint64'>, 9: <type 'numpy.int64'>, 10: <type 'numpy.uint64'>, 11: <type 'numpy.float32'>, 12: <type 'numpy.float64'>, 13: <type 'numpy.float128'>, 14: <type 'numpy.complex64'>, 15: <type 'numpy.complex128'>, 16: <type 'numpy.complex256'>, 17: <type 'numpy.object_'>, 18: <type 'numpy.string_'>, 19: <type 'numpy.unicode_'>, 20: <type 'numpy.void'>, 21: <type 'numpy.datetime64'>, 'unicode': <type 'numpy.unicode_'>, 23: <type 'numpy.float16'>, 'cfloat': <type 'numpy.complex128'>, 'longfloat': <type 'numpy.float128'>, 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, 'unicode_': <type 'numpy.unicode_'>, 'complex': <type 'numpy.complex128'>, 'timedelta64': <type 'numpy.timedelta64'>, 'uint16': <type 'numpy.uint16'>, 'c16': <type 'numpy.complex128'>, 'float32': <type 'numpy.float32'>, 'complex256': <type 'numpy.complex256'>, 'D': <type 'numpy.complex128'>, 'H': <type 'numpy.uint16'>, 'void': <type 'numpy.void'>, 'unicode0': <type 'numpy.unicode_'>, 'L': <type 'numpy.uint64'>, 'P': <type 'numpy.uint64'>, 'half': <type 'numpy.float16'>, 'void0': <type 'numpy.void'>, 'd': <type 'numpy.float64'>, 'h': <type 'numpy.int16'>, 'l': <type 'numpy.int64'>, 'p': <type 'numpy.int64'>, 'c32': <type 'numpy.complex256'>, 22: <type 'numpy.timedelta64'>, 'O8': <type 'numpy.object_'>, 'Timedelta64': <type 'numpy.timedelta64'>, 'object0': <type 'numpy.object_'>, 'b1': <type 'numpy.bool_'>, 'float128': <type 'numpy.float128'>, 'M8': <type 'numpy.datetime64'>, 'String0': <type 'numpy.string_'>, 'float16': <type 'numpy.float16'>, 'ulonglong': <type 'numpy.uint64'>, 'i1': <type 'numpy.int8'>, 'uint32': <type 'numpy.uint32'>, '?': <type 'numpy.bool_'>, 'Void0': <type 'numpy.void'>, 'complex64': <type 'numpy.complex64'>, 'G': <type 'numpy.complex256'>, 'O': <type 'numpy.object_'>, 'UInt8': <type 'numpy.uint8'>, 'S': <type 'numpy.string_'>, 'byte': <type 'numpy.int8'>, 'UInt64': <type 'numpy.uint64'>, 'g': <type 'numpy.float128'>, 'float64': <type 'numpy.float64'>, 'ushort': <type 'numpy.uint16'>, 'float_': <type 'numpy.float64'>, 'uint': <type 'numpy.uint64'>, 'object_': <type 'numpy.object_'>, 'Float16': <type 'numpy.float16'>, 'complex_': <type 'numpy.complex128'>, 'Unicode0': <type 'numpy.unicode_'>, 'uintp': <type 'numpy.uint64'>, 'intc': <type 'numpy.int32'>, 'csingle': <type 'numpy.complex64'>, 'datetime64': <type 'numpy.datetime64'>, 'float': <type 'numpy.float64'>, 'bool8': <type 'numpy.bool_'>, 'Bool': <type 'numpy.bool_'>, 'intp': <type 'numpy.int64'>, 'uintc': <type 'numpy.uint32'>, 'bytes_': <type 'numpy.string_'>, 'u8': <type 'numpy.uint64'>, 'u4': <type 'numpy.uint32'>, 'int_': <type 'numpy.int64'>, 'cdouble': <type 'numpy.complex128'>, 'u1': <type 'numpy.uint8'>, 'complex128': <type 'numpy.complex128'>, 'u2': <type 'numpy.uint16'>, 'f8': <type 'numpy.float64'>, 'Datetime64': <type 'numpy.datetime64'>, 'ubyte': <type 'numpy.uint8'>, 'm8': <type 'numpy.timedelta64'>, 'B': <type 'numpy.uint8'>, 'uint0': <type 'numpy.uint64'>, 'F': <type 'numpy.complex64'>, 'bool_': <type 'numpy.bool_'>, 'uint8': <type 'numpy.uint8'>, 'c8': <type 'numpy.complex64'>, 'Int64': <type 'numpy.int64'>, 'Int8': <type 'numpy.int8'>, 'Complex32': <type 'numpy.complex64'>, 'V': <type 'numpy.void'>, 'int8': <type 'numpy.int8'>, 'uint64': <type 'numpy.uint64'>, 'b': <type 'numpy.int8'>, 'f': <type 'numpy.float32'>, 'double': <type 'numpy.float64'>, 'UInt32': <type 'numpy.uint32'>, 'clongdouble': <type 'numpy.complex256'>, 'str': <type 'numpy.string_'>, 'f16': <type 'numpy.float128'>, 'f2': <type 'numpy.float16'>, 'f4': <type 'numpy.float32'>, 'int32': <type 'numpy.int32'>, 'int': <type 'numpy.int64'>, 'longdouble': <type 'numpy.float128'>, 'Complex128': <type 'numpy.complex256'>, 'single': <type 'numpy.float32'>, 'string': <type 'numpy.string_'>, 'q': <type 'numpy.int64'>, 'Int16': <type 'numpy.int16'>, 'Float64': <type 'numpy.float64'>, 'longcomplex': <type 'numpy.complex256'>, 'UInt16': <type 'numpy.uint16'>, 'bool': <type 'numpy.bool_'>, 'Float32': <type 'numpy.float32'>, 'string0': <type 'numpy.string_'>, 'longlong': <type 'numpy.int64'>, 'i8': <type 'numpy.int64'>, 'int16': <type 'numpy.int16'>, 'str_': <type 'numpy.string_'>, 'I': <type 'numpy.uint32'>, 'object': <type 'numpy.object_'>, 'M': <type 'numpy.datetime64'>, 'i4': <type 'numpy.int32'>, 'singlecomplex': <type 'numpy.complex64'>, 'Q': <type 'numpy.uint64'>, 'string_': <type 'numpy.string_'>, 'U': <type 'numpy.unicode_'>, 'a': <type 'numpy.string_'>, 'short': <type 'numpy.int16'>, 'e': <type 'numpy.float16'>, 'i': <type 'numpy.int32'>, 'clongfloat': <type 'numpy.complex256'>, 'm': <type 'numpy.timedelta64'>, 'Object0': <type 'numpy.object_'>, 'int64': <type 'numpy.int64'>, 'Float128': <type 'numpy.float128'>, 'i2': <type 'numpy.int16'>, 'int0': <type 'numpy.int64'>}, 'xticks': <function xticks at 0x3195cf8>, 'hist': <function hist at 0x3197230>, 'bivariate_normal': <function bivariate_normal at 0x2c515f0>, 'NINF': -inf, 'min_scalar_type': <built-in function min_scalar_type>, 'geometric': <built-in method geometric of mtrand.RandomState object at 0x7f399f841690>, 'normTarget': array([[-0.25,  0.26,  0.02, ...,  0.44,  0.51,  0.48],\n       [-0.33,  0.12, -0.02, ...,  0.7 ,  0.52,  0.05],\n       [ 0.14, -0.13,  0.02, ...,  0.43,  0.39,  0.64],\n       ..., \n       [ 1.4 ,  0.26,  0.09, ...,  1.32,  0.72,  0.22],\n       [-0.54,  0.3 , -0.04, ..., -0.37, -0.02, -0.14],\n       [ 0.95,  0.18,  0.17, ...,  0.12,  0.37,  0.05]]), 'sort_complex': <function sort_complex at 0x236c7d0>, 'nested_iters': <built-in function nested_iters>, 'concatenate': <built-in function concatenate>, 'ERR_DEFAULT2': 521, '_i48': u'yoda = normTarget.reshape((200*198,1))', '_i49': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1]+1,0))', 'vdot': <built-in function vdot>, 'bincount': <built-in function bincount>, 'num2epoch': <function num2epoch at 0x307faa0>, '_i46': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-2,0))', 'sctypes': {'int': [<type 'numpy.int8'>, <type 'numpy.int16'>, <type 'numpy.int32'>, <type 'numpy.int64'>], 'float': [<type 'numpy.float16'>, <type 'numpy.float32'>, <type 'numpy.float64'>, <type 'numpy.float128'>], 'uint': [<type 'numpy.uint8'>, <type 'numpy.uint16'>, <type 'numpy.uint32'>, <type 'numpy.uint64'>], 'complex': [<type 'numpy.complex64'>, <type 'numpy.complex128'>, <type 'numpy.complex256'>], 'others': [<type 'bool'>, <type 'object'>, <type 'str'>, <type 'unicode'>, <type 'numpy.void'>]}, 'transpose': <function transpose at 0x21d19b0>, 'add_newdocs': <module 'numpy.add_newdocs' from '/usr/local/lib/python2.7/dist-packages/numpy/add_newdocs.pyc'>, '_i42': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1))', '_i41': u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1)))', 'detrend_linear': <function detrend_linear at 0x2c4f848>, 'corrcoef': <function corrcoef at 0x236d0c8>, 'fromregex': <function fromregex at 0x23fb488>, 'vector_lengths': <function vector_lengths at 0x2c53b90>, 'vectorize': <class 'numpy.lib.function_base.vectorize'>, 'set_printoptions': <function set_printoptions at 0x21dac08>, '_i43': u'yoda.shape', '_i44': u'normTarget.shape', 'trim_zeros': <function trim_zeros at 0x236c848>, 'WEEKLY': 2, 'cos': <ufunc 'cos'>, '_37': (array([   3.,   11.,   42.,  112.,   26.,    4.,    0.,    0.,    0.,    2.]), array([-2.12 , -1.478, -0.836, -0.194,  0.448,  1.09 ,  1.732,  2.374,\n        3.016,  3.658,  4.3  ]), <a list of 10 Patch objects>), 'vlines': <function vlines at 0x3197de8>, 'detrend': <function detrend at 0x2c4f668>, 'arccosh': <ufunc 'arccosh'>, 'DateFormatter': <class 'matplotlib.dates.DateFormatter'>, 'equal': <ufunc 'equal'>, 'display': <function display at 0x1d4c848>, '_i39': u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1))', 'cumprod': <function cumprod at 0x21da758>, 'LinAlgError': <class 'numpy.linalg.linalg.LinAlgError'>, 'float_': <type 'numpy.float64'>, 'deprecate': <function deprecate at 0x23692a8>, 'vander': <function vander at 0x230d938>, '_i31': u'target.shape', 'geterrobj': <built-in function geterrobj>, '_i33': u'normTarget.shape', 'interactive': <function interactive at 0x2a006e0>, '_i35': u'plot(normTarget[:,0])', 'clf': <function clf at 0x3194cf8>, '_i37': u'hist(normTarget[:,197])', 'prepca': <function prepca at 0x2c511b8>, 'wald': <built-in method wald of mtrand.RandomState object at 0x7f399f841690>, 'fromiter': <built-in function fromiter>, 'prctile_rank': <function prctile_rank at 0x2c51488>, '_i29': u'lastObserved = trainOutput(:,-1,:)', 'cm': <module 'matplotlib.cm' from '/usr/local/lib/python2.7/dist-packages/matplotlib/cm.pyc'>, 'tril': <function tril at 0x230d848>, 'poly': <function poly at 0x2377b90>, 'loglog': <function loglog at 0x3197410>, '_i100': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'bitwise_or': <ufunc 'bitwise_or'>, '_i102': u'len(predicted_probs)', '_i103': u'len(predicted_probs[0])', 'figtext': <function figtext at 0x3195050>, 'norm_flat': <function norm_flat at 0x2c51f50>, '_i3': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', '_i107': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', 'tricontourf': <function tricontourf at 0x3197c80>, 'diff': <function diff at 0x236c5f0>, 'cohere': <function cohere at 0x3196c80>, 'normpdf': <function normpdf at 0x2c4fed8>, 'AutoLocator': <class 'matplotlib.ticker.AutoLocator'>, 'iterable': <function iterable at 0x236c1b8>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x2728f10>, 'get_include': <function get_include at 0x2369140>, 'pv': <function pv at 0x23fbe60>, 'tensordot': <function tensordot at 0x21c2b18>, 'piecewise': <function piecewise at 0x236c410>, 'rfftn': <function rfftn at 0x2409410>, 'invert': <ufunc 'invert'>, 'UFUNC_PYVALS_NAME': 'UFUNC_PYVALS', 'fftpack_lite': <module 'numpy.fft.fftpack_lite' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.so'>, 'sinc': <function sinc at 0x236d578>, 'numRows': 55, 'SHIFT_INVALID': 9, 'ubyte': <type 'numpy.uint8'>, 'axis': <function axis at 0x31959b0>, '_i47': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]+1,0))', 'matrix_rank': <function matrix_rank at 0x238caa0>, 'degrees': <ufunc 'degrees'>, 'pi': 3.141592653589793, 'numpy': <module 'numpy' from '/usr/local/lib/python2.7/dist-packages/numpy/__init__.pyc'>, '__doc__': 'Automatically created module for IPython interactive environment', 'empty': <built-in function empty>, 'fig': <matplotlib.figure.Figure object at 0xaa97ad0>, 'find_common_type': <function find_common_type at 0x21bfe60>, 'random_sample': <built-in method random_sample of mtrand.RandomState object at 0x7f399f841690>, 'longest_ones': <function longest_ones at 0x2c51140>, 'irfft2': <function irfft2 at 0x2409578>, 'arcsin': <ufunc 'arcsin'>, 'sctypeNA': {<type 'numpy.float16'>: 'Float16', <type 'numpy.int16'>: 'Int16', 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, <type 'numpy.timedelta64'>: 'Timedelta64', <type 'numpy.uint8'>: 'UInt8', 'c16': 'Complex64', <type 'numpy.datetime64'>: 'Datetime64', 'D': 'Complex64', <type 'numpy.int8'>: 'Int8', 'H': 'UInt16', 'L': 'UInt64', <type 'numpy.void'>: 'Void0', <type 'numpy.bool_'>: 'Bool', 'd': 'Float64', 'h': 'Int16', 'l': 'Int64', <type 'numpy.unicode_'>: 'Unicode0', 'c32': 'Complex128', <type 'numpy.string_'>: 'String0', 'Timedelta64': <type 'numpy.timedelta64'>, 'b1': 'Bool', 'M8': 'Datetime64', 'String0': <type 'numpy.string_'>, <type 'numpy.object_'>: 'Object0', 'I': 'UInt32', '?': 'Bool', 'Void0': <type 'numpy.void'>, <type 'numpy.complex256'>: 'Complex128', 'G': 'Complex128', 'O': 'Object0', 'UInt8': <type 'numpy.uint8'>, 'S': 'String0', <type 'numpy.complex128'>: 'Complex64', 'UInt64': <type 'numpy.uint64'>, 'g': 'Float128', <type 'numpy.complex64'>: 'Complex32', 'Float16': <type 'numpy.float16'>, <type 'numpy.float128'>: 'Float128', 'Bool': <type 'numpy.bool_'>, 'u8': <type 'numpy.uint64'>, <type 'numpy.float64'>: 'Float64', 'u4': <type 'numpy.uint32'>, 'Unicode0': <type 'numpy.unicode_'>, 'u1': <type 'numpy.uint8'>, 'u2': <type 'numpy.uint16'>, 'Datetime64': <type 'numpy.datetime64'>, 'Int8': <type 'numpy.int8'>, <type 'numpy.float32'>: 'Float32', 'B': 'UInt8', 'F': 'Complex32', 'c8': 'Complex32', 'Int64': <type 'numpy.int64'>, 'Complex32': <type 'numpy.complex64'>, 'V': 'Void0', <type 'numpy.uint64'>: 'UInt64', 'b': 'Int8', 'f': 'Float32', 'm8': 'Timedelta64', <type 'numpy.int64'>: 'Int64', 'f16': 'Float128', 'UInt32': <type 'numpy.uint32'>, 'f2': 'Float16', 'f4': 'Float32', 'f8': 'Float64', 'Complex128': <type 'numpy.complex256'>, <type 'numpy.uint64'>: 'UInt64', 'Object0': <type 'numpy.object_'>, 'Int16': <type 'numpy.int16'>, <type 'numpy.int64'>: 'Int64', 'Float64': <type 'numpy.float64'>, 'UInt16': <type 'numpy.uint16'>, 'Float32': <type 'numpy.float32'>, 'i8': <type 'numpy.int64'>, <type 'numpy.uint32'>: 'UInt32', 'i1': <type 'numpy.int8'>, 'i2': <type 'numpy.int16'>, 'M': 'Datetime64', 'i4': <type 'numpy.int32'>, 'Q': 'UInt64', 'U': 'Unicode0', <type 'numpy.int32'>: 'Int32', 'e': 'Float16', 'i': 'Int32', 'm': 'Timedelta64', 'q': 'Int64', <type 'numpy.uint16'>: 'UInt16', 'Float128': <type 'numpy.float128'>}, 'imag': <function imag at 0x23016e0>, 'sctype2char': <function sctype2char at 0x21bf1b8>, 'singlecomplex': <type 'numpy.complex64'>, 'SHIFT_DIVIDEBYZERO': 0, 'sort': <function sort at 0x21d1a28>, 'standard_t': <built-in method standard_t of mtrand.RandomState object at 0x7f399f841690>, '_i40': u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1)))', 'csv2rec': <function csv2rec at 0x2c527d0>, 'MachAr': <class 'numpy.core.machar.MachAr'>, 'apply_along_axis': <function apply_along_axis at 0x2374aa0>, 'new_figure_manager': <function new_figure_manager at 0x3186f50>, 'tight_layout': <function tight_layout at 0x3195848>, 'array_repr': <function array_repr at 0x21db398>, '_i105': u'pred = predicted_probs + lastObserved[200:,stock]', 'reciprocal': <ufunc 'reciprocal'>, 'frompyfunc': <built-in function frompyfunc>, 'rot90': <function rot90 at 0x230d5f0>, 'dstack': <function dstack at 0x2374c80>, 'float64': <type 'numpy.float64'>, 'traincv': array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True, False, False, False, False, False, False,\n       False, False], dtype=bool), 'Annotation': <class 'matplotlib.text.Annotation'>, 'colorbar': <function colorbar at 0x31962a8>, 'cast': {<type 'numpy.float16'>: <function <lambda> at 0x21bf230>, <type 'numpy.string_'>: <function <lambda> at 0x21bf2a8>, <type 'numpy.float128'>: <function <lambda> at 0x21bf320>, <type 'numpy.uint64'>: <function <lambda> at 0x21bf398>, <type 'numpy.int16'>: <function <lambda> at 0x21bf410>, <type 'numpy.timedelta64'>: <function <lambda> at 0x21bf488>, <type 'numpy.object_'>: <function <lambda> at 0x21bf500>, <type 'numpy.float64'>: <function <lambda> at 0x21bf578>, <type 'numpy.int64'>: <function <lambda> at 0x21bf5f0>, <type 'numpy.uint8'>: <function <lambda> at 0x21bf668>, <type 'numpy.datetime64'>: <function <lambda> at 0x21bf6e0>, <type 'numpy.complex256'>: <function <lambda> at 0x21bf758>, <type 'numpy.float32'>: <function <lambda> at 0x21bf7d0>, <type 'numpy.uint32'>: <function <lambda> at 0x21bf848>, <type 'numpy.int8'>: <function <lambda> at 0x21bf8c0>, <type 'numpy.void'>: <function <lambda> at 0x21bf938>, <type 'numpy.complex128'>: <function <lambda> at 0x21bf9b0>, <type 'numpy.uint64'>: <function <lambda> at 0x21bfa28>, <type 'numpy.int32'>: <function <lambda> at 0x21bfaa0>, <type 'numpy.bool_'>: <function <lambda> at 0x21bfb18>, <type 'numpy.unicode_'>: <function <lambda> at 0x21bfb90>, <type 'numpy.complex64'>: <function <lambda> at 0x21bfc08>, <type 'numpy.int64'>: <function <lambda> at 0x21bfc80>, <type 'numpy.uint16'>: <function <lambda> at 0x21bfcf8>}, '_i94': u'yoda = X.reshape((X.shape[0],1))', 'gumbel': <built-in method gumbel of mtrand.RandomState object at 0x7f399f841690>, 'rfft2': <function rfft2 at 0x2409488>, 'eig': <function eig at 0x238c8c0>, 'packbits': <built-in function packbits>, 'issctype': <function issctype at 0x21b8de8>, 'mgrid': <numpy.lib.index_tricks.nd_grid object at 0x236f910>, 'vonmises': <built-in method vonmises of mtrand.RandomState object at 0x7f399f841690>, 'ushort': <type 'numpy.uint16'>, 'normTarget_vector': array([[-0.25],\n       [ 0.26],\n       [ 0.02],\n       ..., \n       [ 0.12],\n       [ 0.37],\n       [ 0.05]]), 'Polygon': <class 'matplotlib.patches.Polygon'>, 'helper': <module 'numpy.fft.helper' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/helper.pyc'>, 'empty_like': <built-in function empty_like>, '_75': (200,), '_74': array([False, False, False, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), '_77': array([[[ 0.      ,  0.      ,  0.      , ...,  0.160672,  0.054283,\n          0.060093],\n        [ 1.61    ,  0.12    ,  0.12    , ...,  0.246306,  0.448241,\n          0.377197],\n        [ 1.12    ,  0.31    ,  0.12    , ...,  0.281271,  0.484713,\n          0.431599],\n        ..., \n        [ 0.9     ,  0.19    ,  0.07    , ...,  0.119027,  0.084617,\n          0.074685],\n        [ 0.87    ,  0.22    ,  0.08    , ...,  0.122028,  0.058538,\n          0.080691],\n        [ 0.83    ,  0.25    ,  0.08    , ...,  0.125018,  0.043205,\n          0.088569]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.405808,  0.188892,\n          0.209284],\n        [ 0.95    , -0.18    ,  0.15    , ...,  0.42738 ,  0.348119,\n          0.34322 ],\n        [ 1.04    , -0.18    ,  0.15    , ...,  0.463135,  0.439758,\n          0.449271],\n        ..., \n        [ 0.87    , -0.01    ,  0.1     , ...,  0.447247,  0.132313,\n          0.208433],\n        [ 0.83    ,  0.      ,  0.05    , ...,  0.445714,  0.153232,\n          0.138243],\n        [ 0.97    , -0.05    ,  0.05    , ...,  0.445714,  0.155649,\n          0.138243]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.934708,  0.084538,\n          0.154596],\n        [ 2.75    ,  0.25    ,  0.      , ...,  0.859673,  0.675959,\n          0.553122],\n        [ 2.22    ,  0.24    ,  0.      , ...,  0.800801,  0.754047,\n          0.652951],\n        ..., \n        [ 6.09    , -0.13    ,  0.      , ...,  0.717239,  0.111535,\n          0.55109 ],\n        [ 6.22    , -0.13    ,  0.      , ...,  0.712795,  0.116218,\n          0.388987],\n        [ 5.75    , -0.17    ,  0.      , ...,  0.715292,  0.152665,\n          0.252609]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.199729,  0.051769,\n          0.117898],\n        [-3.29    ,  0.04    ,  0.24    , ...,  0.349317,  0.77501 ,\n          0.659621],\n        [-3.53    ,  0.06    ,  0.37    , ...,  0.460716,  1.013778,\n          0.894228],\n        ..., \n        [-2.21    ,  1.33    ,  0.5     , ...,  0.221407,  0.051251,\n          0.160312],\n        [-2.25    ,  1.27    ,  0.54    , ...,  0.203557,  0.054283,\n          0.14087 ],\n        [-2.42    ,  1.27    ,  0.53    , ...,  0.185629,  0.059889,\n          0.054874]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.52827 ,  0.128219,\n          0.104881],\n        [ 0.17    , -0.06    ,  0.      , ...,  0.520413,  0.180665,\n          0.150702],\n        [ 0.59    , -0.12    , -0.06    , ...,  0.520859,  0.288167,\n          0.243676],\n        ..., \n        [ 0.97    , -0.24    , -0.08    , ...,  0.296868,  0.023381,\n          0.264344],\n        [ 0.82    , -0.24    , -0.08    , ...,  0.297405,  0.037417,\n          0.211529],\n        [ 0.97    , -0.18    , -0.04    , ...,  0.298542,  0.037238,\n          0.132077]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.31634 ,  0.082624,\n          0.108628],\n        [-0.71    ,  0.26    ,  0.74    , ...,  0.307045,  0.20775 ,\n          0.205129],\n        [-1.06    ,  0.19    ,  0.74    , ...,  0.31471 ,  0.277897,\n          0.274672],\n        ..., \n        [-1.04    , -0.08    ,  0.12    , ...,  0.184709,  0.06532 ,  0.16    ],\n        [-0.95    , -0.19    ,  0.12    , ...,  0.178122,  0.028284,\n          0.152315],\n        [-0.84    , -0.18    ,  0.12    , ...,  0.173413,  0.054283,\n          0.123063]]]), 'einsum': <built-in function einsum>, '_71': sklearn.cross_validation.KFold(n=200, n_folds=63), '_70': 200, 'signbit': <ufunc 'signbit'>, 'cond': <function cond at 0x238ca28>, 'chisquare': <built-in method chisquare of mtrand.RandomState object at 0x7f399f841690>, 'conj': <ufunc 'conjugate'>, 'asmatrix': <function asmatrix at 0x236dc80>, 'floating': <type 'numpy.floating'>, 'flatiter': <type 'numpy.flatiter'>, 'bitwise_xor': <ufunc 'bitwise_xor'>, 'WeekdayLocator': <class 'matplotlib.dates.WeekdayLocator'>, '_34': (200, 198), 'fabs': <ufunc 'fabs'>, 'Locator': <class 'matplotlib.ticker.Locator'>, 'generic': <type 'numpy.generic'>, 'reshape': <function reshape at 0x21d1758>, 'to': 'lanemcintosh@gmail.com', 'NaN': nan, 'cross': <function cross at 0x21c2cf8>, 'sqrt': <ufunc 'sqrt'>, 'show_config': <function show at 0x20f9b18>, 'longcomplex': <type 'numpy.complex256'>, 'poly_between': <function poly_between at 0x2c53938>, 'pad': <function pad at 0x23fec08>, 'split': <function split at 0x2374de8>, 'getp': <function getp at 0x2a9d1b8>, 'floor_divide': <ufunc 'floor_divide'>, '__version__': '1.7.1', 'format_parser': <class numpy.core.records.format_parser at 0x226ebb0>, 'nextafter': <ufunc 'nextafter'>, 'exponential': <built-in method exponential of mtrand.RandomState object at 0x7f399f841690>, 'dedent': <function dedent at 0x2994938>, 'polyval': <function polyval at 0x238cf50>, 'infty': inf, 'flipud': <function flipud at 0x230d578>, 'i0': <function i0 at 0x236d488>, 'permutation': <built-in method permutation of mtrand.RandomState object at 0x7f399f841690>, 'disconnect': <function disconnect at 0x3194c80>, 'iscomplexobj': <function iscomplexobj at 0x2301848>, 'sys': <module 'sys' (built-in)>, 'average': <function average at 0x236c320>, '_exit_code': 0, 'setdiff1d': <function setdiff1d at 0x236c140>, 'psd': <function psd at 0x31976e0>, 'mafromtxt': <function mafromtxt at 0x23fb5f0>, 'bartlett': <function bartlett at 0x236d1b8>, 'polydiv': <function polydiv at 0x238d1b8>, 'numStocks': 198, 'drange': <function drange at 0x307d140>, 'safe_eval': <function safe_eval at 0x2369938>, 'ifft': <function ifft at 0x23fee60>, 'cov': <function cov at 0x236cde8>, 'greater_equal': <ufunc 'greater_equal'>, 'i': 243, 'Tester': <class 'numpy.testing.nosetester.NoseTester'>, 'trapz': <function trapz at 0x236d7d0>, 'PINF': inf, 'rec_drop_fields': <function rec_drop_fields at 0x2c52500>, 'recfromtxt': <function recfromtxt at 0x23fb668>, 'setp': <function setp at 0x31948c0>, 'In': ['', u\"get_ipython().magic(u'cd /home/lane/Kaggle/03\\\\\\\\ Predicting\\\\\\\\ Stock\\\\\\\\ Prices/')\", u\"get_ipython().system(u'ls -F --color ')\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(train), n_folds=63, indices=False)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(trainOutput), n_folds=63, indices=False)', u'len(trainOutput)', u'len(targets)', u'len(target)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'trainInput.shape', u'trainOutput.shape', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:197] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:198] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'trainInput[509,54,243]', u'trainInput[509,54,244]', u'trainInput[509,54,243]', u'fullInput[509,54,244+197]', u'train            = np.zeros((510,55,244+198))\\ntrain[:,:,0:198] = trainOutput\\ntrain[:,:,198:]  = trainInput', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(target[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'trainOutput.shape', u'len(trainOutput[0])', u'target.shape', u'target.shape', u'trainInput.shape', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput(:,-1,:)', u'lastObserved = trainOutput[:,-1,:]\\nlastObserved.shape', u'target.shape', u'normTarget   = target - lastObserved[:target.shape[0],:]', u'normTarget.shape', u'target.shape', u'plot(normTarget[:,0])', u'plot(normTarget[:,197])', u'hist(normTarget[:,197])', u'hist(normTarget)', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1)))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1)))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1))', u'yoda.shape', u'normTarget.shape', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-2,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((200*198,1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True)', u\"yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,4)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,6)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nyaxis('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',norm=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',normed=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\nderiv.shape', u'normTarget.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'len(target)', u'cv', u'for i in cv:\\n    print i', u'for i,j in cv:\\n    print i,j', u'traincv', u'traincv.shape', u'testcv.shape', u'train[traincv]', u'train.shape', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201,:]\\ntest  = X[201:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201]\\ntest  = X[201:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'train.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:200]\\ntest  = X[200:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'y.shape', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'train.shape', u'test.shape', u'yoda = X.reshape((X.shape[0],1))', u'yoda.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock].reshape((deriv.shape[0],1))\\ny     = normTarget[:,stock]\\ntrain = X[:200,:]\\ntest  = X[200:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'predicted_probs.shape', u'len(predicted_probs)', u'len(predicted_probs[0])', u'lastObserved[:,stock].shape', u'pred = predicted_probs + lastObserved[200:,stock]', u'pred = predicted_probs + lastObserved[200:,stock]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape[2]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'numStocks', u'type(predicted_probs)', u'yoda = np.asarray(predicted_probs)\\nyoda.shape', u'yoda = np.asarray(predicted_probs)\\nluke = np.zeros((310,198))\\nluke[:,0] = yoda', u'pred[0]', u'## Fit Random Forest and generate predictions\\nnumStocks   = trainOutput.shape[2]\\nperformance = []\\npred        = np.zeros((310,numStocks))\\nfor stock in xrange(numStocks):\\n    \\n    # get stock-specific features\\n    X     = deriv[:,stock].reshape((deriv.shape[0],1))\\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n\\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n\\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import smtplib', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import pybrain', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random\\nimport smtplib\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=500, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=25, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'sheet.shape', u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection'], 'y': array([-0.25, -0.33,  0.14,  0.64, -0.07, -0.22, -0.67, -0.86,  0.3 ,\n        0.29,  0.04,  0.97,  0.36,  0.51, -0.49, -0.09,  0.53, -1.21,\n        2.27,  2.77, -0.52,  0.  ,  0.88,  0.29,  0.46,  0.9 ,  0.05,\n        0.33, -2.03,  0.43,  0.68,  0.56, -0.69, -1.95,  0.05, -0.7 ,\n       -0.47, -0.29,  0.68,  0.19,  0.87, -0.02,  0.38,  0.21, -0.36,\n        0.  , -0.55,  0.89, -0.14, -0.24, -2.89, -0.2 , -1.47, -1.58,\n       -0.86, -0.56, -0.13, -0.27, -0.07,  0.16, -1.16, -0.25,  0.65,\n        0.34,  0.34,  3.43,  0.41,  0.05,  0.1 ,  0.48,  0.1 , -0.63,\n       -2.05,  0.85,  0.57,  0.23,  0.2 ,  0.13,  0.88, -1.5 , -0.65,\n        0.09,  0.95, -0.72, -2.65, -0.09,  0.04,  0.36,  2.23, -0.33,\n       -0.02, -0.05,  1.37,  0.86,  0.04,  2.78, -0.76, -4.44, -0.15,\n        0.28, -0.99,  0.66,  0.19, -1.3 , -1.45, -0.52, -0.95,  0.27,\n       -3.92,  0.46, -0.5 , -0.17,  1.65,  3.24,  1.18,  0.55,  0.23,\n       -0.03, -0.43, -0.51,  0.08,  0.04, -1.49,  1.15, -0.77,  0.  ,\n       -0.26,  1.78,  0.99, -0.95, -0.76, -0.41, -0.14,  1.34,  0.15,\n       -1.35, -0.18, -0.21,  0.23, -1.52,  1.17, -0.25,  0.33,  0.02,\n        0.29,  0.74, -0.16, -0.06, -2.7 , -0.11,  1.05, -0.31, -0.95,\n       -0.9 ,  2.19,  0.09, -0.76, -0.57, -0.85,  2.14,  1.62,  0.05,\n       -0.4 ,  0.23,  2.3 ,  2.  ,  0.58, -0.37, -0.43,  0.01, -0.62,\n       -0.58, -0.52,  1.23,  0.57,  0.49, -0.02,  0.63, -0.1 ,  0.15,\n        0.96, -0.38,  0.73, -0.93,  0.1 ,  1.15,  0.39,  0.18, -3.55,\n       -0.53,  0.27,  0.05, -0.15, -1.86,  0.25,  0.08,  0.47,  1.4 ,\n       -0.54,  0.95]), 'grid': <function grid at 0x3198050>, 'trainOutput': array([[[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [ 0.97,  0.45,  0.16, ...,  1.37,  1.3 ,  0.29],\n        [ 1.69,  0.51,  0.  , ...,  1.62,  1.81,  0.48],\n        ..., \n        [ 2.79,  0.77,  0.08, ...,  3.17,  3.08,  1.61],\n        [ 2.74,  0.73,  0.12, ...,  3.25,  3.03,  1.59],\n        [ 2.78,  0.77,  0.1 , ...,  3.25,  3.05,  1.55]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-2.14,  0.  , -0.2 , ..., -0.5 ,  0.38,  0.43],\n        [-2.23, -0.07, -0.28, ..., -0.27, -0.02,  0.21],\n        ..., \n        [-4.72,  0.09, -0.2 , ...,  0.61, -0.54,  0.5 ],\n        [-4.51,  0.1 , -0.24, ...,  0.63, -0.52,  0.41],\n        [-4.62,  0.06, -0.22, ...,  0.52, -0.56,  0.33]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [ 0.52,  0.13,  0.12, ...,  0.43,  0.45,  0.16],\n        [ 0.48,  0.13,  0.1 , ...,  0.27,  0.58,  0.25],\n        ..., \n        [ 0.04,  0.12,  0.2 , ..., -0.4 ,  0.96,  1.03],\n        [ 0.1 ,  0.11,  0.2 , ..., -0.45,  0.93,  1.03],\n        [ 0.02,  0.13,  0.18, ..., -0.47,  0.91,  0.97]],\n\n       ..., \n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-0.28, -0.18,  0.08, ..., -0.98, -0.21,  0.07],\n        [-0.13, -0.23,  0.08, ..., -1.66, -0.54,  0.24],\n        ..., \n        [-0.66,  0.12,  0.12, ..., -2.06, -1.19,  0.3 ],\n        [-0.6 ,  0.21,  0.12, ..., -2.06, -1.16,  0.3 ],\n        [-0.33,  0.23,  0.12, ..., -1.81, -1.01,  0.26]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-1.07, -0.07,  0.  , ..., -0.7 , -0.2 , -0.2 ],\n        [-0.99, -0.01,  0.04, ..., -0.6 ,  0.25,  0.1 ],\n        ..., \n        [-0.99,  0.11,  0.  , ..., -0.08,  0.88,  1.29],\n        [-1.13,  0.07,  0.  , ..., -0.18,  0.9 ,  1.17],\n        [-1.13,  0.06,  0.  , ..., -0.23,  0.92,  1.17]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-6.56, -0.36,  0.04, ..., -1.78, -1.83, -1.03],\n        [-5.8 , -0.36,  0.04, ..., -1.23, -1.33, -0.73],\n        ..., \n        [-8.24, -0.79,  0.04, ..., -2.59, -2.34, -1.49],\n        [-8.3 , -0.78,  0.04, ..., -2.61, -2.36, -1.47],\n        [-7.99, -0.78,  0.01, ..., -2.57, -2.34, -1.41]]]), 'standard_normal': <built-in method standard_normal of mtrand.RandomState object at 0x7f399f841690>, 'RankWarning': <class 'numpy.lib.polynomial.RankWarning'>, 'ascontiguousarray': <function ascontiguousarray at 0x21c2668>, '_89': (200,), 'load': <function load at 0x23f9aa0>, '_i4': u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", 'hexbin': <function hexbin at 0x31971b8>, 'Arrow': <class 'matplotlib.patches.Arrow'>, 'less': <ufunc 'less'>, 'putmask': <built-in function putmask>, 'UFUNC_BUFSIZE_DEFAULT': 8192, 'get_state': <built-in method get_state of mtrand.RandomState object at 0x7f399f841690>, 'NAN': nan, 'test_transformed': array([[ -2.90000000e-01,   3.95000000e+01,   5.65000000e+01, ...,\n          8.48180000e-02,   1.46046000e-01,   2.20786000e-01],\n       [  3.80000000e-01,   2.80000000e+01,   3.50000000e+01, ...,\n          6.08164000e-01,   7.14327000e-01,   4.69965000e-01],\n       [  2.00000000e-02,   1.30250000e+02,   4.83750000e+01, ...,\n          9.14371000e-01,   8.75696000e-01,   1.20665000e-01],\n       ..., \n       [  2.70000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          1.78577000e-01,   7.33330000e-02,   8.55570000e-02],\n       [  0.00000000e+00,   4.14500000e+02,   2.80000000e+01, ...,\n          6.20088000e-01,   6.15484000e-01,   7.63330000e-02],\n       [  3.10000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          6.87380000e-02,  -4.30400000e-03,   4.11582000e-01]]), 'typeDict': {0: <type 'numpy.bool_'>, 1: <type 'numpy.int8'>, 2: <type 'numpy.uint8'>, 3: <type 'numpy.int16'>, 4: <type 'numpy.uint16'>, 5: <type 'numpy.int32'>, 6: <type 'numpy.uint32'>, 7: <type 'numpy.int64'>, 8: <type 'numpy.uint64'>, 9: <type 'numpy.int64'>, 10: <type 'numpy.uint64'>, 11: <type 'numpy.float32'>, 12: <type 'numpy.float64'>, 13: <type 'numpy.float128'>, 14: <type 'numpy.complex64'>, 15: <type 'numpy.complex128'>, 16: <type 'numpy.complex256'>, 17: <type 'numpy.object_'>, 18: <type 'numpy.string_'>, 19: <type 'numpy.unicode_'>, 20: <type 'numpy.void'>, 21: <type 'numpy.datetime64'>, 'unicode': <type 'numpy.unicode_'>, 23: <type 'numpy.float16'>, 'cfloat': <type 'numpy.complex128'>, 'longfloat': <type 'numpy.float128'>, 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, 'unicode_': <type 'numpy.unicode_'>, 'complex': <type 'numpy.complex128'>, 'timedelta64': <type 'numpy.timedelta64'>, 'uint16': <type 'numpy.uint16'>, 'c16': <type 'numpy.complex128'>, 'float32': <type 'numpy.float32'>, 'complex256': <type 'numpy.complex256'>, 'D': <type 'numpy.complex128'>, 'H': <type 'numpy.uint16'>, 'void': <type 'numpy.void'>, 'unicode0': <type 'numpy.unicode_'>, 'L': <type 'numpy.uint64'>, 'P': <type 'numpy.uint64'>, 'half': <type 'numpy.float16'>, 'void0': <type 'numpy.void'>, 'd': <type 'numpy.float64'>, 'h': <type 'numpy.int16'>, 'l': <type 'numpy.int64'>, 'p': <type 'numpy.int64'>, 'c32': <type 'numpy.complex256'>, 22: <type 'numpy.timedelta64'>, 'O8': <type 'numpy.object_'>, 'Timedelta64': <type 'numpy.timedelta64'>, 'object0': <type 'numpy.object_'>, 'b1': <type 'numpy.bool_'>, 'float128': <type 'numpy.float128'>, 'M8': <type 'numpy.datetime64'>, 'String0': <type 'numpy.string_'>, 'float16': <type 'numpy.float16'>, 'ulonglong': <type 'numpy.uint64'>, 'i1': <type 'numpy.int8'>, 'uint32': <type 'numpy.uint32'>, '?': <type 'numpy.bool_'>, 'Void0': <type 'numpy.void'>, 'complex64': <type 'numpy.complex64'>, 'G': <type 'numpy.complex256'>, 'O': <type 'numpy.object_'>, 'UInt8': <type 'numpy.uint8'>, 'S': <type 'numpy.string_'>, 'byte': <type 'numpy.int8'>, 'UInt64': <type 'numpy.uint64'>, 'g': <type 'numpy.float128'>, 'float64': <type 'numpy.float64'>, 'ushort': <type 'numpy.uint16'>, 'float_': <type 'numpy.float64'>, 'uint': <type 'numpy.uint64'>, 'object_': <type 'numpy.object_'>, 'Float16': <type 'numpy.float16'>, 'complex_': <type 'numpy.complex128'>, 'Unicode0': <type 'numpy.unicode_'>, 'uintp': <type 'numpy.uint64'>, 'intc': <type 'numpy.int32'>, 'csingle': <type 'numpy.complex64'>, 'datetime64': <type 'numpy.datetime64'>, 'float': <type 'numpy.float64'>, 'bool8': <type 'numpy.bool_'>, 'Bool': <type 'numpy.bool_'>, 'intp': <type 'numpy.int64'>, 'uintc': <type 'numpy.uint32'>, 'bytes_': <type 'numpy.string_'>, 'u8': <type 'numpy.uint64'>, 'u4': <type 'numpy.uint32'>, 'int_': <type 'numpy.int64'>, 'cdouble': <type 'numpy.complex128'>, 'u1': <type 'numpy.uint8'>, 'complex128': <type 'numpy.complex128'>, 'u2': <type 'numpy.uint16'>, 'f8': <type 'numpy.float64'>, 'Datetime64': <type 'numpy.datetime64'>, 'ubyte': <type 'numpy.uint8'>, 'm8': <type 'numpy.timedelta64'>, 'B': <type 'numpy.uint8'>, 'uint0': <type 'numpy.uint64'>, 'F': <type 'numpy.complex64'>, 'bool_': <type 'numpy.bool_'>, 'uint8': <type 'numpy.uint8'>, 'c8': <type 'numpy.complex64'>, 'Int64': <type 'numpy.int64'>, 'Int8': <type 'numpy.int8'>, 'Complex32': <type 'numpy.complex64'>, 'V': <type 'numpy.void'>, 'int8': <type 'numpy.int8'>, 'uint64': <type 'numpy.uint64'>, 'b': <type 'numpy.int8'>, 'f': <type 'numpy.float32'>, 'double': <type 'numpy.float64'>, 'UInt32': <type 'numpy.uint32'>, 'clongdouble': <type 'numpy.complex256'>, 'str': <type 'numpy.string_'>, 'f16': <type 'numpy.float128'>, 'f2': <type 'numpy.float16'>, 'f4': <type 'numpy.float32'>, 'int32': <type 'numpy.int32'>, 'int': <type 'numpy.int64'>, 'longdouble': <type 'numpy.float128'>, 'Complex128': <type 'numpy.complex256'>, 'single': <type 'numpy.float32'>, 'string': <type 'numpy.string_'>, 'q': <type 'numpy.int64'>, 'Int16': <type 'numpy.int16'>, 'Float64': <type 'numpy.float64'>, 'longcomplex': <type 'numpy.complex256'>, 'UInt16': <type 'numpy.uint16'>, 'bool': <type 'numpy.bool_'>, 'Float32': <type 'numpy.float32'>, 'string0': <type 'numpy.string_'>, 'longlong': <type 'numpy.int64'>, 'i8': <type 'numpy.int64'>, 'int16': <type 'numpy.int16'>, 'str_': <type 'numpy.string_'>, 'I': <type 'numpy.uint32'>, 'object': <type 'numpy.object_'>, 'M': <type 'numpy.datetime64'>, 'i4': <type 'numpy.int32'>, 'singlecomplex': <type 'numpy.complex64'>, 'Q': <type 'numpy.uint64'>, 'string_': <type 'numpy.string_'>, 'U': <type 'numpy.unicode_'>, 'a': <type 'numpy.string_'>, 'short': <type 'numpy.int16'>, 'e': <type 'numpy.float16'>, 'i': <type 'numpy.int32'>, 'clongfloat': <type 'numpy.complex256'>, 'm': <type 'numpy.timedelta64'>, 'Object0': <type 'numpy.object_'>, 'int64': <type 'numpy.int64'>, 'Float128': <type 'numpy.float128'>, 'i2': <type 'numpy.int16'>, 'int0': <type 'numpy.int64'>}, 'shape': <function shape at 0x21d1f50>, '_i98': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', 'setbufsize': <function setbufsize at 0x21dd1b8>, '_85': (201,), '_i93': u'test.shape', '_i92': u'train.shape', '_i91': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', '_i90': u'train.shape', '_i97': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'cfloat': <type 'numpy.complex128'>, '_i95': u'yoda.shape', 'RAISE': 2, 'detrend_mean': <function detrend_mean at 0x2c4f758>, '_87': (200,), 'isscalar': <function isscalar at 0x21dbb90>, 'SubplotTool': <class 'matplotlib.widgets.SubplotTool'>, 'get_current_fig_manager': <function get_current_fig_manager at 0x3194b18>, 'character': <type 'numpy.character'>, 'bench': <bound method NoseTester.test of <numpy.testing.nosetester.NoseTester object at 0x2383a90>>, 'fullInput': array([[[ 0.      ,  0.      ,  0.      , ...,  0.299584,  0.038816,\n          0.081309],\n        [ 0.97    ,  0.45    ,  0.16    , ...,  0.314446,  0.251952,\n          0.206263],\n        [ 1.69    ,  0.51    ,  0.      , ...,  0.357783,  0.510176,\n          0.429069],\n        ..., \n        [ 2.79    ,  0.77    ,  0.08    , ...,  0.269088,  0.126912,\n          0.103441],\n        [ 2.74    ,  0.73    ,  0.12    , ...,  0.262727,  0.133116,\n          0.111704],\n        [ 2.78    ,  0.77    ,  0.1     , ...,  0.259782,  0.121326,\n          0.124544]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.320344,  0.071274,\n          0.057831],\n        [-2.14    ,  0.      , -0.2     , ...,  0.410495,  0.634182,\n          0.521483],\n        [-2.23    , -0.07    , -0.28    , ...,  0.478352,  0.79485 ,\n          0.690853],\n        ..., \n        [-4.72    ,  0.09    , -0.2     , ...,  0.231589,  0.067725,\n          0.090799],\n        [-4.51    ,  0.1     , -0.24    , ...,  0.231602,  0.072388,\n          0.100995],\n        [-4.62    ,  0.06    , -0.22    , ...,  0.225328,  0.048442,\n          0.083666]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.19655 ,  0.150555,\n          0.12083 ],\n        [ 0.52    ,  0.13    ,  0.12    , ...,  0.194066,  0.153753,\n          0.128841],\n        [ 0.48    ,  0.13    ,  0.1     , ...,  0.187594,  0.153753,\n          0.132288],\n        ..., \n        [ 0.04    ,  0.12    ,  0.2     , ...,  0.183963,  0.073756,\n          0.08124 ],\n        [ 0.1     ,  0.11    ,  0.2     , ...,  0.177811,  0.060332,\n          0.066165],\n        [ 0.02    ,  0.13    ,  0.18    , ...,  0.174681,  0.06121 ,  0.06    ]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.150991,  0.073394,\n          0.067082],\n        [-0.28    , -0.18    ,  0.08    , ...,  0.150545,  0.066933,\n          0.067082],\n        [-0.13    , -0.23    ,  0.08    , ...,  0.15091 ,  0.068896,\n          0.069121],\n        ..., \n        [-0.66    ,  0.12    ,  0.12    , ...,  0.197203,  0.073121,\n          0.083666],\n        [-0.6     ,  0.21    ,  0.12    , ...,  0.198655,  0.074833,\n          0.069282],\n        [-0.33    ,  0.23    ,  0.12    , ...,  0.198691,  0.099599,  0.08    ]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.150959,  0.089443,\n          0.095102],\n        [-1.07    , -0.07    ,  0.      , ...,  0.191609,  0.267133,\n          0.241753],\n        [-0.99    , -0.01    ,  0.04    , ...,  0.223181,  0.315383,\n          0.298794],\n        ..., \n        [-0.99    ,  0.11    ,  0.      , ...,  0.188956,  0.062823,\n          0.055678],\n        [-1.13    ,  0.07    ,  0.      , ...,  0.191981,  0.066232,\n          0.058119],\n        [-1.13    ,  0.06    ,  0.      , ...,  0.191485,  0.062823,  0.06    ]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  1.10484 ,  0.054283,\n          0.094868],\n        [-6.56    , -0.36    ,  0.04    , ...,  1.356407,  1.782152,\n          1.461476],\n        [-5.8     , -0.36    ,  0.04    , ...,  1.523808,  2.131682,\n          1.812402],\n        ..., \n        [-8.24    , -0.79    ,  0.04    , ...,  0.575108,  0.300311,\n          0.310644],\n        [-8.3     , -0.78    ,  0.04    , ...,  0.569777,  0.276743,\n          0.284429],\n        [-7.99    , -0.78    ,  0.01    , ...,  0.557479,  0.214942,\n          0.323883]]]), 'source': <function source at 0x2369758>, 'add': <ufunc 'add'>, 'uint16': <type 'numpy.uint16'>, 'ndenumerate': <class 'numpy.lib.index_tricks.ndenumerate'>, 'hlines': <function hlines at 0x3197320>, 'ufunc': <type 'numpy.ufunc'>, 'save': <function save at 0x23fb140>, 'multinomial': <built-in method multinomial of mtrand.RandomState object at 0x7f399f841690>, 'ravel': <function ravel at 0x21d1e60>, 'float32': <type 'numpy.float32'>, 'real': <function real at 0x2301668>, 'int32': <type 'numpy.int32'>, 'path_length': <function path_length at 0x2c53c80>, 'tril_indices': <function tril_indices at 0x230daa0>, '_i117': u'## Fit Random Forest and generate predictions\\nnumStocks   = trainOutput.shape[2]\\nperformance = []\\npred        = np.zeros((310,numStocks))\\nfor stock in xrange(numStocks):\\n    \\n    # get stock-specific features\\n    X     = deriv[:,stock].reshape((deriv.shape[0],1))\\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n\\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n\\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'around': <function around at 0x21da938>, 'cbook': <module 'matplotlib.cbook' from '/usr/local/lib/python2.7/dist-packages/matplotlib/cbook.pyc'>, 'lexsort': <built-in function lexsort>, 'get_scale_names': <function get_scale_names at 0x2fc5050>, 'complex_': <type 'numpy.complex128'>, 'ComplexWarning': <class 'numpy.core.numeric.ComplexWarning'>, 'datestr2num': <function datestr2num at 0x307bd70>, 'np': <module 'numpy' from '/usr/local/lib/python2.7/dist-packages/numpy/__init__.pyc'>, 'unicode0': <type 'numpy.unicode_'>, 'ipmt': <function ipmt at 0x23fbcf8>, 'issubclass_': <function issubclass_ at 0x21b8ed8>, 'atleast_3d': <function atleast_3d at 0x22746e0>, 'nper': <function nper at 0x23fbc80>, 'integer': <type 'numpy.integer'>, 'unique': <function unique at 0x2369e60>, 'mod': <ufunc 'remainder'>, '_sh': <module 'IPython.core.shadowns' from '/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/core/shadowns.pyc'>, 'bitwise_not': <ufunc 'invert'>, 'plot_date': <function plot_date at 0x3197668>, '_i101': u'predicted_probs.shape', '_i131': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'laplace': <built-in method laplace of mtrand.RandomState object at 0x7f399f841690>, 'getbufsize': <function getbufsize at 0x21dd230>, 'isfortran': <function isfortran at 0x21c27d0>, '_i134': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'get_printoptions': <function get_printoptions at 0x21dacf8>, 'asarray_chkfinite': <function asarray_chkfinite at 0x236c398>, 'rcParams': RcParams({'agg.path.chunksize': 0,\n          'animation.avconv_args': '',\n          'animation.avconv_path': 'avconv',\n          'animation.bitrate': -1,\n          'animation.codec': 'mpeg4',\n          'animation.convert_args': '',\n          'animation.convert_path': 'convert',\n          'animation.ffmpeg_args': '',\n          'animation.ffmpeg_path': 'ffmpeg',\n          'animation.frame_format': 'png',\n          'animation.mencoder_args': '',\n          'animation.mencoder_path': 'mencoder',\n          'animation.writer': 'ffmpeg',\n          'axes.axisbelow': False,\n          'axes.color_cycle': ['#66c2a5',\n                               '#fc8d62',\n                               '#8da0cb',\n                               '#e78ac3',\n                               '#a6d854',\n                               '#ffd92f',\n                               '#e5c494'],\n          'axes.edgecolor': 'k',\n          'axes.facecolor': 'w',\n          'axes.formatter.limits': [-7, 7],\n          'axes.formatter.use_locale': False,\n          'axes.formatter.use_mathtext': False,\n          'axes.grid': False,\n          'axes.hold': True,\n          'axes.labelcolor': 'k',\n          'axes.labelsize': 'medium',\n          'axes.labelweight': 'normal',\n          'axes.linewidth': 1.0,\n          'axes.titlesize': 'large',\n          'axes.unicode_minus': True,\n          'axes.xmargin': 0,\n          'axes.ymargin': 0,\n          'axes3d.grid': True,\n          'backend': 'module://IPython.kernel.zmq.pylab.backend_inline',\n          'backend.qt4': 'PyQt4',\n          'backend_fallback': True,\n          'contour.negative_linestyle': 'dashed',\n          'datapath': '/usr/local/lib/python2.7/dist-packages/matplotlib/mpl-data',\n          'docstring.hardcopy': False,\n          'examples.directory': '',\n          'figure.autolayout': False,\n          'figure.dpi': 80,\n          'figure.edgecolor': 'white',\n          'figure.facecolor': 'white',\n          'figure.figsize': (6.0, 4.0),\n          'figure.frameon': True,\n          'figure.max_open_warning': 20,\n          'figure.subplot.bottom': 0.125,\n          'figure.subplot.hspace': 0.2,\n          'figure.subplot.left': 0.125,\n          'figure.subplot.right': 0.9,\n          'figure.subplot.top': 0.9,\n          'figure.subplot.wspace': 0.2,\n          'font.cursive': ['Apple Chancery',\n                           'Textile',\n                           'Zapf Chancery',\n                           'Sand',\n                           'cursive'],\n          'font.family': 'sans-serif',\n          'font.fantasy': ['Comic Sans MS',\n                           'Chicago',\n                           'Charcoal',\n                           'ImpactWestern',\n                           'fantasy'],\n          'font.monospace': ['Bitstream Vera Sans Mono',\n                             'DejaVu Sans Mono',\n                             'Andale Mono',\n                             'Nimbus Mono L',\n                             'Courier New',\n                             'Courier',\n                             'Fixed',\n                             'Terminal',\n                             'monospace'],\n          'font.sans-serif': ['Bitstream Vera Sans',\n                              'DejaVu Sans',\n                              'Lucida Grande',\n                              'Verdana',\n                              'Geneva',\n                              'Lucid',\n                              'Arial',\n                              'Helvetica',\n                              'Avant Garde',\n                              'sans-serif'],\n          'font.serif': ['Bitstream Vera Serif',\n                         'DejaVu Serif',\n                         'New Century Schoolbook',\n                         'Century Schoolbook L',\n                         'Utopia',\n                         'ITC Bookman',\n                         'Bookman',\n                         'Nimbus Roman No9 L',\n                         'Times New Roman',\n                         'Times',\n                         'Palatino',\n                         'Charter',\n                         'serif'],\n          'font.size': 10,\n          'font.stretch': 'normal',\n          'font.style': 'normal',\n          'font.variant': 'normal',\n          'font.weight': 'normal',\n          'grid.alpha': 1.0,\n          'grid.color': 'k',\n          'grid.linestyle': ':',\n          'grid.linewidth': 0.5,\n          'image.aspect': 'equal',\n          'image.cmap': 'jet',\n          'image.interpolation': 'bilinear',\n          'image.lut': 256,\n          'image.origin': 'upper',\n          'image.resample': False,\n          'interactive': True,\n          'keymap.all_axes': 'a',\n          'keymap.back': ['left', 'c', 'backspace'],\n          'keymap.forward': ['right', 'v'],\n          'keymap.fullscreen': ('f', 'ctrl+f'),\n          'keymap.grid': 'g',\n          'keymap.home': ['h', 'r', 'home'],\n          'keymap.pan': 'p',\n          'keymap.quit': ('ctrl+w', 'cmd+w'),\n          'keymap.save': ('s', 'ctrl+s'),\n          'keymap.xscale': ['k', 'L'],\n          'keymap.yscale': 'l',\n          'keymap.zoom': 'o',\n          'legend.borderaxespad': 0.5,\n          'legend.borderpad': 0.4,\n          'legend.columnspacing': 2.0,\n          'legend.fancybox': False,\n          'legend.fontsize': 'large',\n          'legend.frameon': True,\n          'legend.handleheight': 0.7,\n          'legend.handlelength': 2.0,\n          'legend.handletextpad': 0.8,\n          'legend.isaxes': True,\n          'legend.labelspacing': 0.5,\n          'legend.loc': 'upper right',\n          'legend.markerscale': 1.0,\n          'legend.numpoints': 2,\n          'legend.scatterpoints': 3,\n          'legend.shadow': False,\n          'lines.antialiased': True,\n          'lines.color': 'b',\n          'lines.dash_capstyle': 'butt',\n          'lines.dash_joinstyle': 'round',\n          'lines.linestyle': '-',\n          'lines.linewidth': 1.0,\n          'lines.marker': 'None',\n          'lines.markeredgewidth': 0.5,\n          'lines.markersize': 6,\n          'lines.solid_capstyle': 'projecting',\n          'lines.solid_joinstyle': 'round',\n          'mathtext.bf': 'serif:bold',\n          'mathtext.cal': 'cursive',\n          'mathtext.default': 'it',\n          'mathtext.fallback_to_cm': True,\n          'mathtext.fontset': 'cm',\n          'mathtext.it': 'serif:italic',\n          'mathtext.rm': 'serif',\n          'mathtext.sf': 'sans\\\\-serif',\n          'mathtext.tt': 'monospace',\n          'patch.antialiased': True,\n          'patch.edgecolor': 'k',\n          'patch.facecolor': 'b',\n          'patch.linewidth': 1.0,\n          'path.effects': [],\n          'path.simplify': True,\n          'path.simplify_threshold': 0.1111111111111111,\n          'path.sketch': None,\n          'path.snap': True,\n          'pdf.compression': 6,\n          'pdf.fonttype': 3,\n          'pdf.inheritcolor': False,\n          'pdf.use14corefonts': False,\n          'pgf.debug': False,\n          'pgf.preamble': [''],\n          'pgf.rcfonts': True,\n          'pgf.texsystem': 'xelatex',\n          'plugins.directory': '.matplotlib_plugins',\n          'polaraxes.grid': True,\n          'ps.distiller.res': 6000,\n          'ps.fonttype': 3,\n          'ps.papersize': 'letter',\n          'ps.useafm': False,\n          'ps.usedistiller': False,\n          'savefig.bbox': None,\n          'savefig.directory': '~',\n          'savefig.dpi': 72,\n          'savefig.edgecolor': 'w',\n          'savefig.extension': 'png',\n          'savefig.facecolor': 'w',\n          'savefig.format': 'png',\n          'savefig.frameon': True,\n          'savefig.jpeg_quality': 95,\n          'savefig.orientation': 'portrait',\n          'savefig.pad_inches': 0.1,\n          'svg.embed_char_paths': True,\n          'svg.fonttype': 'path',\n          'svg.image_inline': True,\n          'svg.image_noscale': False,\n          'text.antialiased': True,\n          'text.color': 'k',\n          'text.dvipnghack': None,\n          'text.hinting': True,\n          'text.hinting_factor': 8,\n          'text.latex.preamble': [''],\n          'text.latex.preview': False,\n          'text.latex.unicode': False,\n          'text.usetex': False,\n          'timezone': 'UTC',\n          'tk.pythoninspect': False,\n          'tk.window_focus': False,\n          'toolbar': 'toolbar2',\n          'verbose.fileo': 'sys.stdout',\n          'verbose.level': 'silent',\n          'webagg.open_in_browser': True,\n          'webagg.port': 8988,\n          'webagg.port_retries': 50,\n          'xtick.color': 'k',\n          'xtick.direction': 'in',\n          'xtick.labelsize': 'medium',\n          'xtick.major.pad': 4,\n          'xtick.major.size': 4,\n          'xtick.major.width': 0.5,\n          'xtick.minor.pad': 4,\n          'xtick.minor.size': 2,\n          'xtick.minor.width': 0.5,\n          'ytick.color': 'k',\n          'ytick.direction': 'in',\n          'ytick.labelsize': 'medium',\n          'ytick.major.pad': 4,\n          'ytick.major.size': 4,\n          'ytick.major.width': 0.5,\n          'ytick.minor.pad': 4,\n          'ytick.minor.size': 2,\n          'ytick.minor.width': 0.5}), 'pcolormesh': <function pcolormesh at 0x3197500>, 'string0': <type 'numpy.string_'>, 'barh': <function barh at 0x3196b18>, '_i130': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', '_i104': u'lastObserved[:,stock].shape', '_i133': u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', '_53': (array([  2.00000000e+00,   0.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         1.00000000e+00,   2.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         2.00000000e+00,   7.00000000e+00,   3.00000000e+00,\n         4.00000000e+00,   7.00000000e+00,   8.00000000e+00,\n         2.20000000e+01,   2.00000000e+01,   1.30000000e+01,\n         2.40000000e+01,   5.30000000e+01,   5.30000000e+01,\n         8.10000000e+01,   1.17000000e+02,   1.68000000e+02,\n         2.91000000e+02,   5.90000000e+02,   1.25600000e+03,\n         2.75800000e+03,   8.53900000e+03,   1.52450000e+04,\n         6.19300000e+03,   1.99500000e+03,   9.18000000e+02,\n         4.14000000e+02,   2.14000000e+02,   1.21000000e+02,\n         1.11000000e+02,   7.50000000e+01,   6.70000000e+01,\n         3.50000000e+01,   3.70000000e+01,   3.00000000e+01,\n         2.50000000e+01,   2.00000000e+01,   6.00000000e+00,\n         7.00000000e+00,   6.00000000e+00,   9.00000000e+00,\n         4.00000000e+00,   3.00000000e+00,   1.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n         3.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         3.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         1.00000000e+00]), array([-15.55  , -15.1994, -14.8488, -14.4982, -14.1476, -13.797 ,\n       -13.4464, -13.0958, -12.7452, -12.3946, -12.044 , -11.6934,\n       -11.3428, -10.9922, -10.6416, -10.291 ,  -9.9404,  -9.5898,\n        -9.2392,  -8.8886,  -8.538 ,  -8.1874,  -7.8368,  -7.4862,\n        -7.1356,  -6.785 ,  -6.4344,  -6.0838,  -5.7332,  -5.3826,\n        -5.032 ,  -4.6814,  -4.3308,  -3.9802,  -3.6296,  -3.279 ,\n        -2.9284,  -2.5778,  -2.2272,  -1.8766,  -1.526 ,  -1.1754,\n        -0.8248,  -0.4742,  -0.1236,   0.227 ,   0.5776,   0.9282,\n         1.2788,   1.6294,   1.98  ,   2.3306,   2.6812,   3.0318,\n         3.3824,   3.733 ,   4.0836,   4.4342,   4.7848,   5.1354,\n         5.486 ,   5.8366,   6.1872,   6.5378,   6.8884,   7.239 ,\n         7.5896,   7.9402,   8.2908,   8.6414,   8.992 ,   9.3426,\n         9.6932,  10.0438,  10.3944,  10.745 ,  11.0956,  11.4462,\n        11.7968,  12.1474,  12.498 ,  12.8486,  13.1992,  13.5498,\n        13.9004,  14.251 ,  14.6016,  14.9522,  15.3028,  15.6534,\n        16.004 ,  16.3546,  16.7052,  17.0558,  17.4064,  17.757 ,\n        18.1076,  18.4582,  18.8088,  19.1594,  19.51  ]), <a list of 100 Patch objects>), 'sign': <ufunc 'sign'>, '_dh': [u'/home/lane/iPython_notebooks', u'/home/lane/Kaggle/03 Predicting Stock Prices'], 'svd': <function svd at 0x238c9b0>, '_i106': u'pred = predicted_probs + lastObserved[200:,stock]', 'findobj': <function findobj at 0x31942a8>, 'spring': <function spring at 0x31989b0>, 'in1d': <function in1d at 0x236c050>, 'interp': <function interp at 0x236c668>, 'draw': <function draw at 0x3194d70>, 'ginput': <function ginput at 0x3194ed8>, 'rcdefaults': <function rcdefaults at 0x3194758>, 'rfft': <function rfft at 0x23feed8>, 'hypot': <ufunc 'hypot'>, 'logical_and': <ufunc 'logical_and'>, 'rrule': <class 'dateutil.rrule.rrule'>, 'table': <function table at 0x3198140>, 'diagflat': <function diagflat at 0x230d758>, 'float128': <type 'numpy.float128'>, 'matshow': <function matshow at 0x3196410>, 'isfinite': <ufunc 'isfinite'>, '_52': (array([  8.00000000e+00,   9.00000000e+00,   3.80000000e+01,\n         8.42000000e+02,   3.81220000e+04,   5.27000000e+02,\n         3.80000000e+01,   8.00000000e+00,   6.00000000e+00,\n         2.00000000e+00]), array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 10 Patch objects>), 'MINUTELY': 5, 'byte_bounds': <function byte_bounds at 0x2369488>, 'iinfo': <class 'numpy.core.getlimits.iinfo'>, 'kaiser': <function kaiser at 0x236d500>, 'ifftshift': <function ifftshift at 0x24096e0>, '_16': 0.32388299999999998, '_113': <type 'list'>, 'inside_poly': <function inside_poly at 0x2c53848>, 'warnings': <module 'warnings' from '/usr/lib/python2.7/warnings.pyc'>, '_116': -3.8199999999999998, 'cv': sklearn.cross_validation.KFold(n=200, n_folds=25), 'is_closed_polygon': <function is_closed_polygon at 0x2c539b0>, 'polysub': <function polysub at 0x238d0c8>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x2728f10>, 'ifftn': <function ifftn at 0x24092a8>, 'fromfile': <built-in function fromfile>, 'prod': <function prod at 0x21da6e0>, 'nanmax': <function nanmax at 0x236cc80>, 'LinearLocator': <class 'matplotlib.ticker.LinearLocator'>, 'tensorinv': <function tensorinv at 0x238c578>, 'plt': <module 'matplotlib.pyplot' from '/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc'>, 'seterrobj': <built-in function seterrobj>, 'power': <ufunc 'power'>, 'array_split': <function array_split at 0x2374d70>, 'zipf': <built-in method zipf of mtrand.RandomState object at 0x7f399f841690>, 'stem': <function stem at 0x3197aa0>, 'ioff': <function ioff at 0x3194488>, 'step': <function step at 0x3197b18>, 'percentile': <function percentile at 0x236d6e0>, 'hsv': <function hsv at 0x31987d0>, 'axhspan': <function axhspan at 0x3196938>, 'FPE_DIVIDEBYZERO': 1, '__name__': '__main__', 'subtract': <ufunc 'subtract'>, 'optimize': <module 'scipy.optimize' from '/usr/local/lib/python2.7/dist-packages/scipy/optimize/__init__.pyc'>, '_': -3.8199999999999998, 'mx2num': <function mx2num at 0x307fb18>, 'fft': <module 'numpy.fft' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/__init__.pyc'>, 'frombuffer': <built-in function frombuffer>, 'iscomplex': <function iscomplex at 0x2301758>, 'fill_betweenx': <function fill_betweenx at 0x3197140>, 'multivariate_normal': <built-in method multivariate_normal of mtrand.RandomState object at 0x7f399f841690>, 'add_docstring': <built-in function add_docstring>, 'argsort': <function argsort at 0x21d1aa0>, '_38': ([array([   0.,    0.,    0.,   11.,  179.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  189.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  189.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  194.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  188.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  191.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   12.,  181.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  193.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   23.,  158.,   11.,    2.,    0.,    2.,    0.]), array([   2.,    0.,    2.,   16.,  159.,   19.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  196.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  187.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  192.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  194.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  184.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  192.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    3.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   1.,    0.,    2.,   28.,  148.,   17.,    3.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  186.,    9.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  184.,    2.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  177.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,    7.,  186.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   20.,  168.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    2.,    0.,   15.,  167.,   16.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    0.,   14.,  167.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,   16.,  165.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   14.,  182.,    2.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    3.,   26.,  153.,   16.,    0.,    0.,    2.,    0.]), array([   3.,    1.,    7.,   46.,  102.,   26.,    8.,    3.,    2.,    2.]), array([   0.,    2.,    0.,   12.,  176.,   10.,    0.,    0.,    0.,    0.]), array([   2.,    0.,    1.,   20.,  155.,   18.,    4.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  181.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  184.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  189.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  182.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   11.,  182.,    6.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  184.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   22.,  166.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  195.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    3.,  193.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  190.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  196.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   29.,  140.,   21.,    4.,    2.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  190.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    3.,   31.,  144.,   17.,    3.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  193.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  188.,    4.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.])], array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 198 Lists of Patches objects>), '_19': 0.32388299999999998, 'fmin': <ufunc 'fmin'>, 'loadtxt': <function loadtxt at 0x23fb398>, '_31': (200, 198), '_30': (510, 198), '_33': (200, 198), '_18': 0.32388299999999998, '_35': [<matplotlib.lines.Line2D object at 0x3c0f110>], 'bytes_': <type 'numpy.string_'>, 'ones_like': <function ones_like at 0x21c2488>, '_36': [<matplotlib.lines.Line2D object at 0x3df1610>], 'ScalarFormatter': <class 'matplotlib.ticker.ScalarFormatter'>, 'is_busday': <built-in function is_busday>, 'arcsinh': <ufunc 'arcsinh'>, 'CLIP': 0, 'exp_safe': <function exp_safe at 0x2c51cf8>, '_i57': u\"fig = gcf()\\nfig.set_size_inches(16,4)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", '_i56': u\"yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", '_i55': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True)', '_i54': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100)', '_i53': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda,100)', '_i52': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda)', '__builtin__': <module '__builtin__' (built-in)>, 'dataset': array([[ 0.      ,  0.      ,  0.      , ...,  1.10484 ,  0.054283,\n         0.094868],\n       [-6.56    , -0.36    ,  0.04    , ...,  1.356407,  1.782152,\n         1.461476],\n       [-5.8     , -0.36    ,  0.04    , ...,  1.523808,  2.131682,\n         1.812402],\n       ..., \n       [-8.24    , -0.79    ,  0.04    , ...,  0.575108,  0.300311,\n         0.310644],\n       [-8.3     , -0.78    ,  0.04    , ...,  0.569777,  0.276743,\n         0.284429],\n       [-7.99    , -0.78    ,  0.01    , ...,  0.557479,  0.214942,\n         0.323883]]), 'annotate': <function annotate at 0x3198230>, '_i80': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201,:]\\ntest  = X[201:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'normalize': <function Normalize at 0x29e6b18>, 'intp': <type 'numpy.int64'>, 'standard_cauchy': <built-in method standard_cauchy of mtrand.RandomState object at 0x7f399f841690>, '_i82': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201]\\ntest  = X[201:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'unpackbits': <built-in function unpackbits>, 'HOURLY': 4, 'arrow': <function arrow at 0x3196848>, 'delete': <function delete at 0x236d938>, 'Infinity': inf, 'log': <ufunc 'log'>, 'numMetrics': 244, 'cdouble': <type 'numpy.complex128'>, 'complex128': <type 'numpy.complex128'>, 'tick_params': <function tick_params at 0x3198398>, 'switch_backend': <function switch_backend at 0x3194320>, 'round_': <function round_ at 0x21da9b0>, 'broadcast_arrays': <function broadcast_arrays at 0x2377410>, 'inner': <built-in function inner>, 'var': <function var at 0x21dab18>, 'c_': <numpy.lib.index_tricks.CClass object at 0x236f9d0>, 'slopes': <function slopes at 0x2c53758>, '_i87': u'train.shape', 'log10': <ufunc 'log10'>, 'thisMetric': array([[ 0.142166],\n       [ 0.272029],\n       [ 0.062272],\n       [ 0.229153],\n       [ 0.042557],\n       [ 0.33731 ],\n       [ 0.310483],\n       [ 0.133083],\n       [ 0.06245 ],\n       [ 0.110805],\n       [ 0.132204],\n       [ 0.169738],\n       [ 0.063246],\n       [ 0.260853],\n       [ 0.136382],\n       [ 0.095102],\n       [ 0.133041],\n       [ 0.175214],\n       [ 0.226495],\n       [ 0.153984],\n       [ 0.188709],\n       [ 0.045583],\n       [ 0.530984],\n       [ 0.060919],\n       [ 0.621289],\n       [ 0.048762],\n       [ 0.106771],\n       [ 0.088944],\n       [ 0.126271],\n       [ 0.07356 ],\n       [ 0.289156],\n       [ 0.109545],\n       [ 0.133791],\n       [ 0.127845],\n       [ 0.042164],\n       [ 0.206586],\n       [ 0.092436],\n       [ 0.125477],\n       [ 0.101871],\n       [ 0.1761  ],\n       [ 0.196723],\n       [ 0.097354],\n       [ 0.2     ],\n       [ 0.061192],\n       [ 0.096839],\n       [ 0.1     ],\n       [ 0.142867],\n       [ 0.21349 ],\n       [ 0.06    ],\n       [ 0.205047],\n       [ 0.251794],\n       [ 0.066332],\n       [ 0.078811],\n       [ 0.32426 ],\n       [ 0.034641],\n       [ 0.056372],\n       [ 0.314925],\n       [ 0.150481],\n       [ 0.109545],\n       [ 0.173429],\n       [ 0.467737],\n       [ 0.200942],\n       [ 0.135565],\n       [ 0.138363],\n       [ 0.166966],\n       [ 0.557494],\n       [ 0.292746],\n       [ 0.188267],\n       [ 0.129615],\n       [ 0.294524],\n       [ 0.057831],\n       [ 0.307571],\n       [ 0.476667],\n       [ 0.04    ],\n       [ 0.318974],\n       [ 0.061734],\n       [ 0.25307 ],\n       [ 0.34    ],\n       [ 0.239397],\n       [ 0.268701],\n       [ 0.291681],\n       [ 0.19    ],\n       [ 0.120324],\n       [ 0.146553],\n       [ 0.421189],\n       [ 0.25399 ],\n       [ 0.05831 ],\n       [ 0.119629],\n       [ 0.336452],\n       [ 0.073106],\n       [ 0.204885],\n       [ 0.11225 ],\n       [ 0.153768],\n       [ 0.181659],\n       [ 0.248149],\n       [ 0.371319],\n       [ 0.79813 ],\n       [ 0.303278],\n       [ 0.289271],\n       [ 0.513561],\n       [ 0.287653],\n       [ 0.106301],\n       [ 0.608997],\n       [ 0.136545],\n       [ 0.209152],\n       [ 0.304485],\n       [ 0.186934],\n       [ 0.319026],\n       [ 0.076449],\n       [ 0.109595],\n       [ 0.11949 ],\n       [ 0.15268 ],\n       [ 0.324157],\n       [ 0.679485],\n       [ 0.158254],\n       [ 0.179846],\n       [ 0.099722],\n       [ 0.034641],\n       [ 0.104297],\n       [ 0.075572],\n       [ 0.067905],\n       [ 0.564427],\n       [ 0.204559],\n       [ 0.153442],\n       [ 0.088192],\n       [ 0.068638],\n       [ 0.108525],\n       [ 0.14345 ],\n       [ 0.19105 ],\n       [ 0.164621],\n       [ 0.141067],\n       [ 0.104297],\n       [ 0.114066],\n       [ 0.172755],\n       [ 0.308887],\n       [ 0.067905],\n       [ 0.100222],\n       [ 0.200776],\n       [ 0.134164],\n       [ 0.122656],\n       [ 0.074833],\n       [ 0.249087],\n       [ 0.074012],\n       [ 0.119164],\n       [ 0.215587],\n       [ 0.424513],\n       [ 0.096437],\n       [ 0.103494],\n       [ 0.232809],\n       [ 0.052705],\n       [ 0.103441],\n       [ 0.189209],\n       [ 0.12    ],\n       [ 0.208113],\n       [ 1.304318],\n       [ 0.034641],\n       [ 0.340506],\n       [ 0.03    ],\n       [ 0.097011],\n       [ 0.216974],\n       [ 0.585928],\n       [ 0.231948],\n       [ 0.141578],\n       [ 0.089691],\n       [ 0.20445 ],\n       [ 0.125344],\n       [ 0.07746 ],\n       [ 0.083533],\n       [ 0.103655],\n       [ 0.052915],\n       [ 0.314713],\n       [ 0.405476],\n       [ 0.11879 ],\n       [ 0.283333],\n       [ 0.471181],\n       [ 0.228789],\n       [ 0.077746],\n       [ 0.074162],\n       [ 0.161245],\n       [ 0.212315],\n       [ 0.202731],\n       [ 0.131149],\n       [ 0.2319  ],\n       [ 0.244154],\n       [ 0.200693],\n       [ 0.453995],\n       [ 0.1206  ],\n       [ 0.220177],\n       [ 0.153623],\n       [ 0.270267],\n       [ 0.121655],\n       [ 0.074907],\n       [ 0.206263],\n       [ 0.157198],\n       [ 0.167929],\n       [ 0.111355],\n       [ 0.275035],\n       [ 0.126095],\n       [ 0.195192],\n       [ 0.113186],\n       [ 0.208753],\n       [ 0.536563],\n       [ 0.110905],\n       [ 0.083732],\n       [ 0.235891],\n       [ 0.131951],\n       [ 0.191949],\n       [ 0.129615],\n       [ 0.139443],\n       [ 0.261874],\n       [ 0.139084],\n       [ 0.321559],\n       [ 0.187113],\n       [ 0.090615],\n       [ 0.066165],\n       [ 0.067165],\n       [ 0.155385],\n       [ 0.119629],\n       [ 0.220454],\n       [ 0.17845 ],\n       [ 0.135195],\n       [ 0.30921 ],\n       [ 0.20955 ],\n       [ 0.086667],\n       [ 0.202731],\n       [ 0.072801],\n       [ 0.086859],\n       [ 0.183697],\n       [ 0.25738 ],\n       [ 0.202731],\n       [ 0.279106],\n       [ 0.114455],\n       [ 0.960422],\n       [ 0.151364],\n       [ 0.175531],\n       [ 0.122066],\n       [ 0.239049],\n       [ 0.150481],\n       [ 0.167332],\n       [ 0.36457 ],\n       [ 0.225389],\n       [ 0.279364],\n       [ 0.142867],\n       [ 0.020276],\n       [ 0.090615],\n       [ 0.426146],\n       [ 0.150591],\n       [ 0.296891],\n       [ 0.04    ],\n       [ 0.203415],\n       [ 0.25399 ],\n       [ 0.122384],\n       [ 0.112151],\n       [ 0.051424],\n       [ 0.08    ],\n       [ 0.380526],\n       [ 0.381838],\n       [ 0.133458],\n       [ 0.041231],\n       [ 0.338083],\n       [ 0.133583],\n       [ 0.215407],\n       [ 0.134454],\n       [ 0.109138],\n       [ 0.351568],\n       [ 0.263333],\n       [ 0.129529],\n       [ 0.098545],\n       [ 0.684471],\n       [ 0.348712],\n       [ 0.047958],\n       [ 0.298068],\n       [ 0.065405],\n       [ 0.364692],\n       [ 0.054263],\n       [ 0.301625],\n       [ 0.147309],\n       [ 0.605402],\n       [ 0.074162],\n       [ 0.129271],\n       [ 0.21    ],\n       [ 0.389102],\n       [ 0.304649],\n       [ 0.199109],\n       [ 0.08775 ],\n       [ 0.074012],\n       [ 0.25865 ],\n       [ 0.155885],\n       [ 0.156667],\n       [ 0.228206],\n       [ 0.099219],\n       [ 0.108679],\n       [ 0.08    ],\n       [ 0.124544],\n       [ 0.138724],\n       [ 0.104403],\n       [ 0.047958],\n       [ 0.264008],\n       [ 0.363517],\n       [ 0.558341],\n       [ 0.119629],\n       [ 0.106301],\n       [ 0.147121],\n       [ 0.124499],\n       [ 0.216795],\n       [ 0.145297],\n       [ 0.11348 ],\n       [ 0.311929],\n       [ 0.332265],\n       [ 0.244495],\n       [ 1.289358],\n       [ 0.079652],\n       [ 0.847526],\n       [ 0.108218],\n       [ 0.208992],\n       [ 0.393206],\n       [ 0.099051],\n       [ 0.050772],\n       [ 0.199444],\n       [ 0.093274],\n       [ 0.06    ],\n       [ 0.117898],\n       [ 0.380716],\n       [ 0.107703],\n       [ 0.080069],\n       [ 0.146287],\n       [ 0.218174],\n       [ 0.194165],\n       [ 0.166567],\n       [ 0.063596],\n       [ 0.184662],\n       [ 0.13784 ],\n       [ 0.618663],\n       [ 0.130384],\n       [ 0.164249],\n       [ 0.652687],\n       [ 0.693253],\n       [ 0.086667],\n       [ 0.317245],\n       [ 0.144837],\n       [ 0.016667],\n       [ 0.400222],\n       [ 0.079652],\n       [ 0.084327],\n       [ 0.156241],\n       [ 0.099051],\n       [ 0.193592],\n       [ 0.15748 ],\n       [ 0.152571],\n       [ 0.105251],\n       [ 0.220025],\n       [ 0.371349],\n       [ 0.053955],\n       [ 0.556996],\n       [ 0.149926],\n       [ 0.071414],\n       [ 0.932011],\n       [ 0.108372],\n       [ 0.36653 ],\n       [ 0.311359],\n       [ 0.199444],\n       [ 0.284917],\n       [ 0.066332],\n       [ 0.138924],\n       [ 0.091165],\n       [ 0.142127],\n       [ 0.219949],\n       [ 0.1294  ],\n       [ 0.30249 ],\n       [ 0.145258],\n       [ 0.06888 ],\n       [ 0.371139],\n       [ 0.251219],\n       [ 0.162207],\n       [ 0.124141],\n       [ 0.291738],\n       [ 0.35201 ],\n       [ 0.08124 ],\n       [ 0.174865],\n       [ 2.412726],\n       [ 0.063857],\n       [ 0.15592 ],\n       [ 0.261236],\n       [ 0.108628],\n       [ 0.138203],\n       [ 0.127671],\n       [ 0.345897],\n       [ 0.162788],\n       [ 0.271477],\n       [ 0.06888 ],\n       [ 0.148324],\n       [ 0.451934],\n       [ 0.036667],\n       [ 0.188532],\n       [ 0.093808],\n       [ 0.137113],\n       [ 0.509117],\n       [ 0.176068],\n       [ 0.319913],\n       [ 0.315718],\n       [ 0.244336],\n       [ 0.10198 ],\n       [ 0.182757],\n       [ 0.037417],\n       [ 0.07356 ],\n       [ 0.412432],\n       [ 0.064893],\n       [ 0.175784],\n       [ 0.194165],\n       [ 0.232904],\n       [ 0.044721],\n       [ 0.065574],\n       [ 0.146287],\n       [ 0.062004],\n       [ 0.176572],\n       [ 0.476527],\n       [ 0.238118],\n       [ 0.065574],\n       [ 0.11893 ],\n       [ 0.247745],\n       [ 0.172337],\n       [ 0.101379],\n       [ 0.059815],\n       [ 0.285326],\n       [ 0.091348],\n       [ 0.257833],\n       [ 0.546626],\n       [ 0.117379],\n       [ 0.26327 ],\n       [ 0.051099],\n       [ 0.102956],\n       [ 0.173141],\n       [ 0.117237],\n       [ 0.185472],\n       [ 0.171205],\n       [ 0.060828],\n       [ 0.094868],\n       [ 0.171205],\n       [ 0.27258 ],\n       [ 0.098995],\n       [ 0.854868],\n       [ 0.08    ],\n       [ 0.08705 ],\n       [ 0.12252 ],\n       [ 0.344384],\n       [ 0.353475],\n       [ 0.178263],\n       [ 0.10198 ],\n       [ 0.102198],\n       [ 0.174356],\n       [ 0.35819 ],\n       [ 0.136382],\n       [ 0.056075],\n       [ 0.127671],\n       [ 0.081854],\n       [ 0.109087],\n       [ 0.223557],\n       [ 0.325645],\n       [ 0.563777],\n       [ 0.140633],\n       [ 0.138564],\n       [ 0.954713],\n       [ 0.061644],\n       [ 0.095917],\n       [ 0.052915],\n       [ 0.495861],\n       [ 0.154416],\n       [ 0.095801],\n       [ 0.250422],\n       [ 0.031798],\n       [ 0.197737],\n       [ 0.317175],\n       [ 0.161898],\n       [ 0.038006],\n       [ 0.321472],\n       [ 0.072648],\n       [ 0.119907],\n       [ 0.118322],\n       [ 0.076012],\n       [ 0.236854],\n       [ 0.143798],\n       [ 0.164857],\n       [ 0.099387],\n       [ 0.021858],\n       [ 0.051424],\n       [ 0.291624],\n       [ 0.190029],\n       [ 0.133832],\n       [ 0.245515],\n       [ 0.273699],\n       [ 0.176289],\n       [ 0.200499],\n       [ 0.535859],\n       [ 0.159931],\n       [ 0.193075],\n       [ 0.285034],\n       [ 0.110454],\n       [ 0.194879],\n       [ 0.150997],\n       [ 0.043333],\n       [ 0.060645],\n       [ 0.150923],\n       [ 0.439634],\n       [ 0.230024],\n       [ 0.120046],\n       [ 0.103494],\n       [ 0.281267],\n       [ 0.083333],\n       [ 0.062539],\n       [ 0.452769]]), 'hypergeometric': <built-in method hypergeometric of mtrand.RandomState object at 0x7f399f841690>, 'uintp': <type 'numpy.uint64'>, 'unwrap': <function unwrap at 0x236c758>, 'NullLocator': <class 'matplotlib.ticker.NullLocator'>, '_i68': u'normTarget.shape', 'triangular': <built-in method triangular of mtrand.RandomState object at 0x7f399f841690>, 'noncentral_chisquare': <built-in method noncentral_chisquare of mtrand.RandomState object at 0x7f399f841690>, 'histogram': <function histogram at 0x236c230>, 'msg': 'To:lanemcintosh@gmail.com\\nFrom: mcintoshlane@gmail.com\\nSubject:Kaggle iPython Notebook \\n\\nYour Python Script has now Completed!', 'issubdtype': <function issubdtype at 0x21bf050>, 'maximum_sctype': <function maximum_sctype at 0x21b8cf8>, 'flexible': <type 'numpy.flexible'>, 'movavg': <function movavg at 0x2c51938>, 'squeeze': <function squeeze at 0x21d1cf8>, 'int8': <type 'numpy.int8'>, 'cholesky': <function cholesky at 0x238c668>, 'info': <function info at 0x23696e0>, 'seterr': <function seterr at 0x21dd0c8>, 'argmin': <function argmin at 0x21d1b90>, 'fignum_exists': <function has_fignum at 0x2cf9938>, 'genfromtxt': <function genfromtxt at 0x23fb500>, 'rec_append_fields': <function rec_append_fields at 0x2c52488>, 'j': 9, 'maximum': <ufunc 'maximum'>, '_23': (510, 55, 198), 'record': <class 'numpy.core.records.record'>, 'obj2sctype': <function obj2sctype at 0x21b8e60>, '_61': <matplotlib.text.Text object at 0x8c45410>, 'clongdouble': <type 'numpy.complex256'>, 'sum': <function sum at 0x21da140>, 'isrealobj': <function isrealobj at 0x23018c0>, 'log1p': <ufunc 'log1p'>, '_oh': {8: 510, 10: 200, 12: (510, 55, 244), 13: (510, 55, 198), 16: 0.32388299999999998, 18: 0.32388299999999998, 19: 0.32388299999999998, 21: (510, 55, 442), 23: (510, 55, 198), 24: 55, 25: (200, 198), 26: (200, 198), 27: (510, 55, 244), 30: (510, 198), 31: (200, 198), 33: (200, 198), 34: (200, 198), 35: [<matplotlib.lines.Line2D object at 0x3c0f110>], 36: [<matplotlib.lines.Line2D object at 0x3df1610>], 37: (array([   3.,   11.,   42.,  112.,   26.,    4.,    0.,    0.,    0.,    2.]), array([-2.12 , -1.478, -0.836, -0.194,  0.448,  1.09 ,  1.732,  2.374,\n        3.016,  3.658,  4.3  ]), <a list of 10 Patch objects>), 38: ([array([   0.,    0.,    0.,   11.,  179.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  189.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  189.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  194.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  188.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  191.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   12.,  181.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  193.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   23.,  158.,   11.,    2.,    0.,    2.,    0.]), array([   2.,    0.,    2.,   16.,  159.,   19.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  196.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  187.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  192.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  194.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  184.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  192.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    3.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   1.,    0.,    2.,   28.,  148.,   17.,    3.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  186.,    9.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  184.,    2.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  177.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,    7.,  186.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   20.,  168.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    2.,    0.,   15.,  167.,   16.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    0.,   14.,  167.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,   16.,  165.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   14.,  182.,    2.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    3.,   26.,  153.,   16.,    0.,    0.,    2.,    0.]), array([   3.,    1.,    7.,   46.,  102.,   26.,    8.,    3.,    2.,    2.]), array([   0.,    2.,    0.,   12.,  176.,   10.,    0.,    0.,    0.,    0.]), array([   2.,    0.,    1.,   20.,  155.,   18.,    4.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  181.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  184.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  189.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  182.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   11.,  182.,    6.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  184.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   22.,  166.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  195.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    3.,  193.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  190.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  196.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   29.,  140.,   21.,    4.,    2.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  190.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    3.,   31.,  144.,   17.,    3.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  193.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  188.,    4.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.])], array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 198 Lists of Patches objects>), 44: (200, 198), 52: (array([  8.00000000e+00,   9.00000000e+00,   3.80000000e+01,\n         8.42000000e+02,   3.81220000e+04,   5.27000000e+02,\n         3.80000000e+01,   8.00000000e+00,   6.00000000e+00,\n         2.00000000e+00]), array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 10 Patch objects>), 53: (array([  2.00000000e+00,   0.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         1.00000000e+00,   2.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         2.00000000e+00,   7.00000000e+00,   3.00000000e+00,\n         4.00000000e+00,   7.00000000e+00,   8.00000000e+00,\n         2.20000000e+01,   2.00000000e+01,   1.30000000e+01,\n         2.40000000e+01,   5.30000000e+01,   5.30000000e+01,\n         8.10000000e+01,   1.17000000e+02,   1.68000000e+02,\n         2.91000000e+02,   5.90000000e+02,   1.25600000e+03,\n         2.75800000e+03,   8.53900000e+03,   1.52450000e+04,\n         6.19300000e+03,   1.99500000e+03,   9.18000000e+02,\n         4.14000000e+02,   2.14000000e+02,   1.21000000e+02,\n         1.11000000e+02,   7.50000000e+01,   6.70000000e+01,\n         3.50000000e+01,   3.70000000e+01,   3.00000000e+01,\n         2.50000000e+01,   2.00000000e+01,   6.00000000e+00,\n         7.00000000e+00,   6.00000000e+00,   9.00000000e+00,\n         4.00000000e+00,   3.00000000e+00,   1.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n         3.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         3.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         1.00000000e+00]), array([-15.55  , -15.1994, -14.8488, -14.4982, -14.1476, -13.797 ,\n       -13.4464, -13.0958, -12.7452, -12.3946, -12.044 , -11.6934,\n       -11.3428, -10.9922, -10.6416, -10.291 ,  -9.9404,  -9.5898,\n        -9.2392,  -8.8886,  -8.538 ,  -8.1874,  -7.8368,  -7.4862,\n        -7.1356,  -6.785 ,  -6.4344,  -6.0838,  -5.7332,  -5.3826,\n        -5.032 ,  -4.6814,  -4.3308,  -3.9802,  -3.6296,  -3.279 ,\n        -2.9284,  -2.5778,  -2.2272,  -1.8766,  -1.526 ,  -1.1754,\n        -0.8248,  -0.4742,  -0.1236,   0.227 ,   0.5776,   0.9282,\n         1.2788,   1.6294,   1.98  ,   2.3306,   2.6812,   3.0318,\n         3.3824,   3.733 ,   4.0836,   4.4342,   4.7848,   5.1354,\n         5.486 ,   5.8366,   6.1872,   6.5378,   6.8884,   7.239 ,\n         7.5896,   7.9402,   8.2908,   8.6414,   8.992 ,   9.3426,\n         9.6932,  10.0438,  10.3944,  10.745 ,  11.0956,  11.4462,\n        11.7968,  12.1474,  12.498 ,  12.8486,  13.1992,  13.5498,\n        13.9004,  14.251 ,  14.6016,  14.9522,  15.3028,  15.6534,\n        16.004 ,  16.3546,  16.7052,  17.0558,  17.4064,  17.757 ,\n        18.1076,  18.4582,  18.8088,  19.1594,  19.51  ]), <a list of 100 Patch objects>), 61: <matplotlib.text.Text object at 0x8c45410>, 63: <matplotlib.text.Text object at 0x8d13e90>, 64: <matplotlib.text.Text object at 0x9b88ad0>, 65: <matplotlib.text.Text object at 0x92e02d0>, 66: (510, 55, 198), 67: (510, 198), 68: (200, 198), 70: 200, 71: sklearn.cross_validation.KFold(n=200, n_folds=63), 74: array([False, False, False, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), 75: (200,), 76: (200,), 77: array([[[ 0.      ,  0.      ,  0.      , ...,  0.160672,  0.054283,\n          0.060093],\n        [ 1.61    ,  0.12    ,  0.12    , ...,  0.246306,  0.448241,\n          0.377197],\n        [ 1.12    ,  0.31    ,  0.12    , ...,  0.281271,  0.484713,\n          0.431599],\n        ..., \n        [ 0.9     ,  0.19    ,  0.07    , ...,  0.119027,  0.084617,\n          0.074685],\n        [ 0.87    ,  0.22    ,  0.08    , ...,  0.122028,  0.058538,\n          0.080691],\n        [ 0.83    ,  0.25    ,  0.08    , ...,  0.125018,  0.043205,\n          0.088569]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.405808,  0.188892,\n          0.209284],\n        [ 0.95    , -0.18    ,  0.15    , ...,  0.42738 ,  0.348119,\n          0.34322 ],\n        [ 1.04    , -0.18    ,  0.15    , ...,  0.463135,  0.439758,\n          0.449271],\n        ..., \n        [ 0.87    , -0.01    ,  0.1     , ...,  0.447247,  0.132313,\n          0.208433],\n        [ 0.83    ,  0.      ,  0.05    , ...,  0.445714,  0.153232,\n          0.138243],\n        [ 0.97    , -0.05    ,  0.05    , ...,  0.445714,  0.155649,\n          0.138243]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.934708,  0.084538,\n          0.154596],\n        [ 2.75    ,  0.25    ,  0.      , ...,  0.859673,  0.675959,\n          0.553122],\n        [ 2.22    ,  0.24    ,  0.      , ...,  0.800801,  0.754047,\n          0.652951],\n        ..., \n        [ 6.09    , -0.13    ,  0.      , ...,  0.717239,  0.111535,\n          0.55109 ],\n        [ 6.22    , -0.13    ,  0.      , ...,  0.712795,  0.116218,\n          0.388987],\n        [ 5.75    , -0.17    ,  0.      , ...,  0.715292,  0.152665,\n          0.252609]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.199729,  0.051769,\n          0.117898],\n        [-3.29    ,  0.04    ,  0.24    , ...,  0.349317,  0.77501 ,\n          0.659621],\n        [-3.53    ,  0.06    ,  0.37    , ...,  0.460716,  1.013778,\n          0.894228],\n        ..., \n        [-2.21    ,  1.33    ,  0.5     , ...,  0.221407,  0.051251,\n          0.160312],\n        [-2.25    ,  1.27    ,  0.54    , ...,  0.203557,  0.054283,\n          0.14087 ],\n        [-2.42    ,  1.27    ,  0.53    , ...,  0.185629,  0.059889,\n          0.054874]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.52827 ,  0.128219,\n          0.104881],\n        [ 0.17    , -0.06    ,  0.      , ...,  0.520413,  0.180665,\n          0.150702],\n        [ 0.59    , -0.12    , -0.06    , ...,  0.520859,  0.288167,\n          0.243676],\n        ..., \n        [ 0.97    , -0.24    , -0.08    , ...,  0.296868,  0.023381,\n          0.264344],\n        [ 0.82    , -0.24    , -0.08    , ...,  0.297405,  0.037417,\n          0.211529],\n        [ 0.97    , -0.18    , -0.04    , ...,  0.298542,  0.037238,\n          0.132077]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.31634 ,  0.082624,\n          0.108628],\n        [-0.71    ,  0.26    ,  0.74    , ...,  0.307045,  0.20775 ,\n          0.205129],\n        [-1.06    ,  0.19    ,  0.74    , ...,  0.31471 ,  0.277897,\n          0.274672],\n        ..., \n        [-1.04    , -0.08    ,  0.12    , ...,  0.184709,  0.06532 ,  0.16    ],\n        [-0.95    , -0.19    ,  0.12    , ...,  0.178122,  0.028284,\n          0.152315],\n        [-0.84    , -0.18    ,  0.12    , ...,  0.173413,  0.054283,\n          0.123063]]]), 78: (510, 55, 442), 81: (510,), 83: (201,), 84: (309,), 85: (201,), 87: (200,), 88: (310,), 89: (200,), 90: (200,), 92: (200,), 93: (310,), 95: (510, 1), 102: 310, 104: (510,), 108: <matplotlib.text.Text object at 0x918f1d0>, 109: 198, 111: <matplotlib.text.Text object at 0x9894b90>, 113: <type 'list'>, 114: (310,), 116: -3.8199999999999998}, 'flatten': <function flatten at 0x2992b90>, 'gmail_pwd': 'hansolo8chewy', 'YEARLY': 0, 'digitize': <built-in function digitize>, 'clongfloat': <type 'numpy.complex256'>, 'ylim': <function ylim at 0x3195b90>, 'yscale': <function yscale at 0x3195c80>, 'inv': <function inv at 0x238c5f0>, 'ediff1d': <function ediff1d at 0x2369050>, 'pie': <function pie at 0x3197578>, '_i45': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,0))', 'char': <module 'numpy.core.defchararray' from '/usr/local/lib/python2.7/dist-packages/numpy/core/defchararray.pyc'>, 'single': <type 'numpy.float32'>, 'isposinf': <function isposinf at 0x2301500>, 'set_cmap': <function set_cmap at 0x3196398>, 'ScalarType': (<type 'int'>, <type 'float'>, <type 'complex'>, <type 'long'>, <type 'bool'>, <type 'str'>, <type 'unicode'>, <type 'buffer'>, <type 'numpy.float16'>, <type 'numpy.string_'>, <type 'numpy.float128'>, <type 'numpy.uint64'>, <type 'numpy.int16'>, <type 'numpy.timedelta64'>, <type 'numpy.object_'>, <type 'numpy.float64'>, <type 'numpy.int64'>, <type 'numpy.uint8'>, <type 'numpy.datetime64'>, <type 'numpy.complex256'>, <type 'numpy.float32'>, <type 'numpy.uint32'>, <type 'numpy.int8'>, <type 'numpy.void'>, <type 'numpy.complex128'>, <type 'numpy.uint64'>, <type 'numpy.int32'>, <type 'numpy.bool_'>, <type 'numpy.unicode_'>, <type 'numpy.complex64'>, <type 'numpy.int64'>, <type 'numpy.uint16'>), 'noncentral_f': <built-in method noncentral_f of mtrand.RandomState object at 0x7f399f841690>, 'triu': <function triu at 0x230d8c0>, 'inf': inf, 'fill': <function fill at 0x3197050>, 'expand_dims': <function expand_dims at 0x2374b90>, 'pareto': <built-in method pareto of mtrand.RandomState object at 0x7f399f841690>, 'logspace': <function logspace at 0x2270de8>, 'floor': <ufunc 'floor'>, 'polyadd': <function polyadd at 0x238d050>, 'TU': TU, 'nan': nan, 'modf': <ufunc 'modf'>, 'emath': <module 'numpy.lib.scimath' from '/usr/local/lib/python2.7/dist-packages/numpy/lib/scimath.pyc'>, 'arctan': <ufunc 'arctan'>, 'bmat': <function bmat at 0x2373cf8>, 'Slider': <class 'matplotlib.widgets.Slider'>, 'prism': <function prism at 0x3198938>, 'isclose': <function isclose at 0x21dbed8>, 'ERR_DEFAULT': 0, 'TH': TH, 'xscale': <function xscale at 0x3195c08>, '_i109': u'trainOutput.shape[2]', 'register_cmap': <function register_cmap at 0x2b80e60>, 'roll': <function roll at 0x21c2b90>, 'figsize': <function figsize at 0x1de18c0>, '_i70': u'len(target)', 'compare_chararrays': <built-in function compare_chararrays>, 'vsplit': <function vsplit at 0x2374ed8>, 'real_if_close': <function real_if_close at 0x2301a28>, 'repeat': <function repeat at 0x21d1848>, 'hamming': <function hamming at 0x236d2a8>, 'ALLOW_THREADS': 1, '_i66': u'trainOutput.shape', 'isInput': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True], '_12': (510, 55, 244), 'errorbar': <function errorbar at 0x3196ed8>, 'ravel_multi_index': <built-in function ravel_multi_index>, '_i67': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\nderiv.shape', 'string_': <type 'numpy.string_'>, 'isinf': <ufunc 'isinf'>, 'spacing': <ufunc 'spacing'>, 'Inf': inf, 'ndarray': <type 'numpy.ndarray'>, 'delaxes': <function delaxes at 0x3195398>, 'pcolor': <function pcolor at 0x3197488>, 'e': 2.718281828459045, 'ERR_CALL': 3, 'datetime_data': <built-in function datetime_data>, '_i79': u'X.shape', 'test': array([[ -2.90000000e-01,   2.85714000e-01,   7.00000000e+00, ...,\n          5.15190000e-01,   2.20786000e-01,   2.08753000e-01],\n       [  3.80000000e-01,   1.60000000e+00,   5.00000000e+00, ...,\n          8.83311000e-01,   4.69965000e-01,   5.36563000e-01],\n       [  2.00000000e-02,   1.11111000e-01,   9.00000000e+00, ...,\n          3.90504000e-01,   1.20665000e-01,   1.10905000e-01],\n       ..., \n       [  2.70000000e-01,   3.23529000e-01,   3.40000000e+01, ...,\n          1.79467000e-01,   8.55570000e-02,   8.33330000e-02],\n       [  0.00000000e+00,   2.94117000e-01,   1.70000000e+01, ...,\n          1.95387000e-01,   7.63330000e-02,   6.25390000e-02],\n       [  3.10000000e-01,   1.60000000e+00,   5.00000000e+00, ...,\n          1.05697000e+00,   4.11582000e-01,   4.52769000e-01]]), 'ERR_IGNORE': 0, 'flag': <function flag at 0x3198668>, 'hsplit': <function hsplit at 0x2374e60>, 'result_type': <built-in function result_type>, 'gradient': <function gradient at 0x236c578>, 'base_repr': <function base_repr at 0x21dbc80>, 'eigh': <function eigh at 0x238c938>, 'argwhere': <function argwhere at 0x21c2848>, 'set_string_function': <function set_string_function at 0x21dba28>, 'swapaxes': <function swapaxes at 0x21d1938>, 'FixedLocator': <class 'matplotlib.ticker.FixedLocator'>, '_111': <matplotlib.text.Text object at 0x9894b90>, 'tensorsolve': <function tensorsolve at 0x238c488>}\n        self.user_ns = {'disp': <function disp at 0x236cd70>, 'union1d': <function union1d at 0x236c0c8>, 'all': <function all at 0x21da398>, '_i132': u'sheet.shape', 'dist': <function dist at 0x2c51758>, 'issubsctype': <function issubsctype at 0x21b8f50>, 'sca': <function sca at 0x3195410>, 'savez': <function savez at 0x23fb1b8>, '_i58': u\"fig = gcf()\\nfig.set_size_inches(16,6)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", 'entropy': <function entropy at 0x2c4fe60>, 'atleast_2d': <function atleast_2d at 0x2274668>, 'restoredot': <built-in function restoredot>, '_95': (510, 1), 'streamplot': <function streamplot at 0x3197b90>, '_93': (310,), '_92': (200,), 'ptp': <function ptp at 0x21da500>, 'Subplot': <class 'matplotlib.axes.AxesSubplot'>, 'frange': <function frange at 0x2c52050>, 'PackageLoader': <class 'numpy._import_tools.PackageLoader'>, 'show': <function show at 0x3194398>, '_83': (201,), 'fft2': <function fft2 at 0x2409320>, '_63': <matplotlib.text.Text object at 0x8d13e90>, 'xkcd': <function xkcd at 0x3194848>, 'rec2csv': <function rec2csv at 0x2c535f0>, 'ix_': <function ix_ at 0x236db18>, 'resize': <function resize at 0x21d1c80>, '_64': <matplotlib.text.Text object at 0x9b88ad0>, 'blackman': <function blackman at 0x236d140>, '_68': (200, 198), 'norm': <function norm at 0x238ccf8>, 'FLOATING_POINT_SUPPORT': 1, '_i85': u'train.shape', 'MultipleLocator': <class 'matplotlib.ticker.MultipleLocator'>, 'mlab': <module 'matplotlib.mlab' from '/usr/local/lib/python2.7/dist-packages/matplotlib/mlab.pyc'>, 'busdaycalendar': <type 'numpy.busdaycalendar'>, 'pkgload': <function pkgload at 0x2107050>, 'mpl': <module 'matplotlib' from '/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc'>, 'rc': <function rc at 0x3194668>, 'thetagrids': <function thetagrids at 0x3195f50>, 'results': [0.40249999999999986, 0.3805, 1.05975, 0.6737500000000001, 0.6269999999999998, 0.41200000000000003, 0.9955, 0.38125000000000003, 0.6900000000000002, 0.8010000000000002, 0.6927500000000002, 0.9587500000000002, 1.095, 1.0350000000000001, 0.975, 0.6989999999999998, 0.7677500000000002, 0.48375, 0.6754999999999998, 1.056, 0.9384999999999999, 0.5549999999999999, 0.48974999999999996, 0.7722500000000001, 0.70925], '_104': (510,), '_i114': u'yoda = np.asarray(predicted_probs)\\nyoda.shape', 'ERR_RAISE': 2, '_i61': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('yoda')\", 'testcv': array([False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), 'cool': <function cool at 0x3198578>, 'tri': <function tri at 0x230d7d0>, 'lapack_lite': <module 'numpy.linalg.lapack_lite' from '/usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so'>, 'diag_indices': <function diag_indices at 0x23748c0>, 'window_hanning': <function window_hanning at 0x2c4f578>, 'array_equal': <function array_equal at 0x21dbf50>, 'FormatStrFormatter': <class 'matplotlib.ticker.FormatStrFormatter'>, '_i25': u'target.shape', '_i22': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(target[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'tanh': <ufunc 'tanh'>, 'longest_contiguous_ones': <function longest_contiguous_ones at 0x2c510c8>, 'get_plot_commands': <function get_plot_commands at 0x31960c8>, 'uint32': <type 'numpy.uint32'>, 'array_equiv': <function array_equiv at 0x21dd050>, '_i12': u'trainInput.shape', 'fftn': <function fftn at 0x2409230>, '_i10': u'len(target)', '_i17': u'trainInput[509,54,244]', '_i16': u'trainInput[509,54,243]', '_i15': u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:198] = trainOutput\\nfullInput[:,:,198:] = trainInput', '_i14': u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:197] = trainOutput\\nfullInput[:,:,198:] = trainInput', 'indices': <function indices at 0x21dbaa0>, 'fftpack': <module 'numpy.fft.fftpack' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack.pyc'>, 'loads': <built-in function loads>, '_i18': u'trainInput[509,54,243]', '_ii': u'sheet.shape', 'set_numeric_ops': <built-in function set_numeric_ops>, '_114': (310,), 'pmt': <function pmt at 0x23fbc08>, 'polar': <function polar at 0x3196578>, 'diag_indices_from': <function diag_indices_from at 0x2374938>, 'object0': <type 'numpy.object_'>, 'ishold': <function ishold at 0x3195230>, 'rate': <function rate at 0x23fbf50>, 'FPE_OVERFLOW': 2, 'Circle': <class 'matplotlib.patches.Circle'>, 'index_exp': <numpy.lib.index_tricks.IndexExpression object at 0x236fa50>, 'append': <function append at 0x236da28>, 'logseries': <built-in method logseries of mtrand.RandomState object at 0x7f399f841690>, '_i128': u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=500, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=25, indices=False)', '_i129': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', 'nanargmax': <function nanargmax at 0x236ccf8>, 'hstack': <function hstack at 0x22747d0>, 'typename': <function typename at 0x2301b18>, 'YearLocator': <class 'matplotlib.dates.YearLocator'>, 'diag': <function diag at 0x230d6e0>, 'pyplot': <module 'matplotlib.pyplot' from '/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc'>, 'axes': <function axes at 0x3195320>, 'ERR_WARN': 1, '_i127': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'unravel_index': <built-in function unravel_index>, 'uniform': <built-in method uniform of mtrand.RandomState object at 0x7f399f841690>, 'polyfit': <function polyfit at 0x238ced8>, 'nanmin': <function nanmin at 0x236cb90>, 'memmap': <class 'numpy.core.memmap.memmap'>, 'axvline': <function axvline at 0x31969b0>, '_90': (200,), 'irfftn': <function irfftn at 0x2409500>, 'nan_to_num': <function nan_to_num at 0x23019b0>, 'twinx': <function twinx at 0x3195668>, 'contourf': <function contourf at 0x3196de8>, 'complex64': <type 'numpy.complex64'>, 'deriv': array([[ 0.04,  0.04, -0.02, ...,  0.  ,  0.02, -0.04],\n       [-0.11, -0.04,  0.02, ..., -0.11, -0.04, -0.08],\n       [-0.08,  0.02, -0.02, ..., -0.02, -0.02, -0.06],\n       ..., \n       [ 0.27,  0.02,  0.  , ...,  0.25,  0.15, -0.04],\n       [ 0.  , -0.01,  0.  , ..., -0.05,  0.02,  0.  ],\n       [ 0.31,  0.  , -0.03, ...,  0.04,  0.02,  0.06]]), '_i34': u'target.shape', 'fmax': <ufunc 'fmax'>, 'copysign': <ufunc 'copysign'>, 'matplotlib': <module 'matplotlib' from '/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc'>, 'l2norm': <function l2norm at 0x2c51ed8>, 'FigureCanvasBase': <class 'matplotlib.backend_bases.FigureCanvasBase'>, 'sinh': <ufunc 'sinh'>, 'unicode_': <type 'numpy.unicode_'>, 'rgrids': <function rgrids at 0x3195ed8>, 'legend': <function legend at 0x31980c8>, 'trunc': <ufunc 'trunc'>, 'box': <function box at 0x31958c0>, 'vstack': <function vstack at 0x2274758>, 'finfo': <class 'numpy.core.getlimits.finfo'>, 'ERR_PRINT': 4, 'levypdf': <function levypdf at 0x2c4ff50>, 'IndexDateFormatter': <class 'matplotlib.dates.IndexDateFormatter'>, 'MO': MO, 'asscalar': <function asscalar at 0x2301aa0>, 'LogLocator': <class 'matplotlib.ticker.LogLocator'>, 'binomial': <built-in method binomial of mtrand.RandomState object at 0x7f399f841690>, 'broken_barh': <function broken_barh at 0x3196b90>, 'poisson': <built-in method poisson of mtrand.RandomState object at 0x7f399f841690>, 'HourLocator': <class 'matplotlib.dates.HourLocator'>, 'less_equal': <ufunc 'less_equal'>, 'l1norm': <function l1norm at 0x2c51e60>, 'BUFSIZE': 8192, 'sci': <function sci at 0x31947d0>, 'object_': <type 'numpy.object_'>, 'FR': FR, 'shuffle': <built-in method shuffle of mtrand.RandomState object at 0x7f399f841690>, 'divide': <ufunc 'divide'>, 'csingle': <type 'numpy.complex64'>, 'dtype': <type 'numpy.dtype'>, 'unsignedinteger': <type 'numpy.unsignedinteger'>, '_i110': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'fftshift': <function fftshift at 0x2409668>, 'fastCopyAndTranspose': <built-in function _fastCopyAndTranspose>, 'num2date': <function num2date at 0x307d0c8>, 'silent_list': <class 'matplotlib.cbook.silent_list'>, 'bitwise_and': <ufunc 'bitwise_and'>, 'uintc': <type 'numpy.uint32'>, '_i30': u'lastObserved = trainOutput[:,-1,:]\\nlastObserved.shape', 'byte': <type 'numpy.int8'>, 'select': <function select at 0x236c488>, 'ticklabel_format': <function ticklabel_format at 0x31982a8>, 'deg2rad': <ufunc 'deg2rad'>, 'plot': <function plot at 0x31975f0>, 'nditer': <type 'numpy.nditer'>, 'eye': <function eye at 0x230d668>, 'triu_indices': <function triu_indices at 0x230db90>, 'kron': <function kron at 0x2377140>, 'newbuffer': <built-in function newbuffer>, '_i86': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:200]\\ntest  = X[200:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'pred': array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       ..., \n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]]), 'negative': <ufunc 'negative'>, 'busday_offset': <built-in function busday_offset>, 'mintypecode': <function mintypecode at 0x2301410>, 'standard_gamma': <built-in method standard_gamma of mtrand.RandomState object at 0x7f399f841690>, 'lstsq': <function lstsq at 0x238cc80>, 'print_function': _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 65536), 'header': 'To:lanemcintosh@gmail.com\\nFrom: mcintoshlane@gmail.com\\nSubject:Kaggle iPython Notebook \\n', '_26': (200, 198), '_27': (510, 55, 244), '_24': 55, '_25': (200, 198), 'MAXDIMS': 32, 'clabel': <function clabel at 0x3196cf8>, 'setxor1d': <function setxor1d at 0x2369f50>, '_21': (510, 55, 442), 'rk4': <function rk4 at 0x2c51578>, 'fftfreq': <function fftfreq at 0x2409758>, 'ifft2': <function ifft2 at 0x2409398>, 'longdouble': <type 'numpy.float128'>, 'uint0': <type 'numpy.uint64'>, 'zeros_like': <function zeros_like at 0x21c2398>, '_i62': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',norm=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_i63': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',normed=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_i60': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nyaxis('yoda')\", 'ylabel': <function ylabel at 0x3195aa0>, 'int_asbuffer': <built-in function int_asbuffer>, 'uint8': <type 'numpy.uint8'>, '_i64': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_i65': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", 'chararray': <class 'numpy.core.defchararray.chararray'>, 'train': array([[  0.04    ,   1.5     ,   2.      , ...,   0.439681,   0.074476,\n          0.142166],\n       [ -0.11    ,   0.789473,  19.      , ...,   0.767666,   0.147196,\n          0.272029],\n       [ -0.08    ,   0.5     ,  12.      , ...,   0.216333,   0.062503,\n          0.062272],\n       ..., \n       [ -0.17    ,   0.222222,   9.      , ...,   0.405073,   0.133066,\n          0.126095],\n       [  0.15    ,  -0.2     ,  10.      , ...,   0.32209 ,   0.127541,\n          0.195192],\n       [  0.11    ,   0.      ,  10.      , ...,   0.232735,   0.130486,\n          0.113186]]), 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'linspace': <function linspace at 0x2270d70>, '_i32': u'normTarget   = target - lastObserved[:target.shape[0],:]', 'hold': <function hold at 0x31951b8>, 'mirr': <function mirr at 0x23fe140>, 'uint64': <type 'numpy.uint64'>, 'sample': <built-in method random_sample of mtrand.RandomState object at 0x7f399f841690>, 'ma': <module 'numpy.ma' from '/usr/local/lib/python2.7/dist-packages/numpy/ma/__init__.pyc'>, 'err': <module 'meanAbsoluteError' from 'meanAbsoluteError.pyc'>, 'f': <built-in method f of mtrand.RandomState object at 0x7f399f841690>, 'hist2d': <function hist2d at 0x31972a8>, 'Text': <class 'matplotlib.text.Text'>, 'isneginf': <function isneginf at 0x2301578>, 'true_divide': <ufunc 'true_divide'>, 'det': <function det at 0x238cc08>, 'SU': SU, 'DateLocator': <class 'matplotlib.dates.DateLocator'>, '_i122': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', '_i8': u'len(trainOutput)', 'thisColumn': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.07301677,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.07301677,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.07301677,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.07301677,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.07301677,  0.07301677,  0.        ,  0.        ]), 'SA': SA, 'rc_context': <function rc_context at 0x31946e0>, 'scatter': <function scatter at 0x3197848>, 'Out': {8: 510, 10: 200, 12: (510, 55, 244), 13: (510, 55, 198), 16: 0.32388299999999998, 18: 0.32388299999999998, 19: 0.32388299999999998, 21: (510, 55, 442), 23: (510, 55, 198), 24: 55, 25: (200, 198), 26: (200, 198), 27: (510, 55, 244), 30: (510, 198), 31: (200, 198), 33: (200, 198), 34: (200, 198), 35: [<matplotlib.lines.Line2D object at 0x3c0f110>], 36: [<matplotlib.lines.Line2D object at 0x3df1610>], 37: (array([   3.,   11.,   42.,  112.,   26.,    4.,    0.,    0.,    0.,    2.]), array([-2.12 , -1.478, -0.836, -0.194,  0.448,  1.09 ,  1.732,  2.374,\n        3.016,  3.658,  4.3  ]), <a list of 10 Patch objects>), 38: ([array([   0.,    0.,    0.,   11.,  179.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  189.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  189.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  194.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  188.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  191.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   12.,  181.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  193.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   23.,  158.,   11.,    2.,    0.,    2.,    0.]), array([   2.,    0.,    2.,   16.,  159.,   19.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  196.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  187.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  192.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  194.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  184.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  192.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    3.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   1.,    0.,    2.,   28.,  148.,   17.,    3.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  186.,    9.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  184.,    2.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  177.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,    7.,  186.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   20.,  168.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    2.,    0.,   15.,  167.,   16.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    0.,   14.,  167.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,   16.,  165.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   14.,  182.,    2.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    3.,   26.,  153.,   16.,    0.,    0.,    2.,    0.]), array([   3.,    1.,    7.,   46.,  102.,   26.,    8.,    3.,    2.,    2.]), array([   0.,    2.,    0.,   12.,  176.,   10.,    0.,    0.,    0.,    0.]), array([   2.,    0.,    1.,   20.,  155.,   18.,    4.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  181.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  184.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  189.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  182.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   11.,  182.,    6.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  184.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   22.,  166.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  195.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    3.,  193.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  190.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  196.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   29.,  140.,   21.,    4.,    2.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  190.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    3.,   31.,  144.,   17.,    3.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  193.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  188.,    4.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.])], array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 198 Lists of Patches objects>), 44: (200, 198), 52: (array([  8.00000000e+00,   9.00000000e+00,   3.80000000e+01,\n         8.42000000e+02,   3.81220000e+04,   5.27000000e+02,\n         3.80000000e+01,   8.00000000e+00,   6.00000000e+00,\n         2.00000000e+00]), array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 10 Patch objects>), 53: (array([  2.00000000e+00,   0.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         1.00000000e+00,   2.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         2.00000000e+00,   7.00000000e+00,   3.00000000e+00,\n         4.00000000e+00,   7.00000000e+00,   8.00000000e+00,\n         2.20000000e+01,   2.00000000e+01,   1.30000000e+01,\n         2.40000000e+01,   5.30000000e+01,   5.30000000e+01,\n         8.10000000e+01,   1.17000000e+02,   1.68000000e+02,\n         2.91000000e+02,   5.90000000e+02,   1.25600000e+03,\n         2.75800000e+03,   8.53900000e+03,   1.52450000e+04,\n         6.19300000e+03,   1.99500000e+03,   9.18000000e+02,\n         4.14000000e+02,   2.14000000e+02,   1.21000000e+02,\n         1.11000000e+02,   7.50000000e+01,   6.70000000e+01,\n         3.50000000e+01,   3.70000000e+01,   3.00000000e+01,\n         2.50000000e+01,   2.00000000e+01,   6.00000000e+00,\n         7.00000000e+00,   6.00000000e+00,   9.00000000e+00,\n         4.00000000e+00,   3.00000000e+00,   1.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n         3.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         3.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         1.00000000e+00]), array([-15.55  , -15.1994, -14.8488, -14.4982, -14.1476, -13.797 ,\n       -13.4464, -13.0958, -12.7452, -12.3946, -12.044 , -11.6934,\n       -11.3428, -10.9922, -10.6416, -10.291 ,  -9.9404,  -9.5898,\n        -9.2392,  -8.8886,  -8.538 ,  -8.1874,  -7.8368,  -7.4862,\n        -7.1356,  -6.785 ,  -6.4344,  -6.0838,  -5.7332,  -5.3826,\n        -5.032 ,  -4.6814,  -4.3308,  -3.9802,  -3.6296,  -3.279 ,\n        -2.9284,  -2.5778,  -2.2272,  -1.8766,  -1.526 ,  -1.1754,\n        -0.8248,  -0.4742,  -0.1236,   0.227 ,   0.5776,   0.9282,\n         1.2788,   1.6294,   1.98  ,   2.3306,   2.6812,   3.0318,\n         3.3824,   3.733 ,   4.0836,   4.4342,   4.7848,   5.1354,\n         5.486 ,   5.8366,   6.1872,   6.5378,   6.8884,   7.239 ,\n         7.5896,   7.9402,   8.2908,   8.6414,   8.992 ,   9.3426,\n         9.6932,  10.0438,  10.3944,  10.745 ,  11.0956,  11.4462,\n        11.7968,  12.1474,  12.498 ,  12.8486,  13.1992,  13.5498,\n        13.9004,  14.251 ,  14.6016,  14.9522,  15.3028,  15.6534,\n        16.004 ,  16.3546,  16.7052,  17.0558,  17.4064,  17.757 ,\n        18.1076,  18.4582,  18.8088,  19.1594,  19.51  ]), <a list of 100 Patch objects>), 61: <matplotlib.text.Text object at 0x8c45410>, 63: <matplotlib.text.Text object at 0x8d13e90>, 64: <matplotlib.text.Text object at 0x9b88ad0>, 65: <matplotlib.text.Text object at 0x92e02d0>, 66: (510, 55, 198), 67: (510, 198), 68: (200, 198), 70: 200, 71: sklearn.cross_validation.KFold(n=200, n_folds=63), 74: array([False, False, False, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), 75: (200,), 76: (200,), 77: array([[[ 0.      ,  0.      ,  0.      , ...,  0.160672,  0.054283,\n          0.060093],\n        [ 1.61    ,  0.12    ,  0.12    , ...,  0.246306,  0.448241,\n          0.377197],\n        [ 1.12    ,  0.31    ,  0.12    , ...,  0.281271,  0.484713,\n          0.431599],\n        ..., \n        [ 0.9     ,  0.19    ,  0.07    , ...,  0.119027,  0.084617,\n          0.074685],\n        [ 0.87    ,  0.22    ,  0.08    , ...,  0.122028,  0.058538,\n          0.080691],\n        [ 0.83    ,  0.25    ,  0.08    , ...,  0.125018,  0.043205,\n          0.088569]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.405808,  0.188892,\n          0.209284],\n        [ 0.95    , -0.18    ,  0.15    , ...,  0.42738 ,  0.348119,\n          0.34322 ],\n        [ 1.04    , -0.18    ,  0.15    , ...,  0.463135,  0.439758,\n          0.449271],\n        ..., \n        [ 0.87    , -0.01    ,  0.1     , ...,  0.447247,  0.132313,\n          0.208433],\n        [ 0.83    ,  0.      ,  0.05    , ...,  0.445714,  0.153232,\n          0.138243],\n        [ 0.97    , -0.05    ,  0.05    , ...,  0.445714,  0.155649,\n          0.138243]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.934708,  0.084538,\n          0.154596],\n        [ 2.75    ,  0.25    ,  0.      , ...,  0.859673,  0.675959,\n          0.553122],\n        [ 2.22    ,  0.24    ,  0.      , ...,  0.800801,  0.754047,\n          0.652951],\n        ..., \n        [ 6.09    , -0.13    ,  0.      , ...,  0.717239,  0.111535,\n          0.55109 ],\n        [ 6.22    , -0.13    ,  0.      , ...,  0.712795,  0.116218,\n          0.388987],\n        [ 5.75    , -0.17    ,  0.      , ...,  0.715292,  0.152665,\n          0.252609]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.199729,  0.051769,\n          0.117898],\n        [-3.29    ,  0.04    ,  0.24    , ...,  0.349317,  0.77501 ,\n          0.659621],\n        [-3.53    ,  0.06    ,  0.37    , ...,  0.460716,  1.013778,\n          0.894228],\n        ..., \n        [-2.21    ,  1.33    ,  0.5     , ...,  0.221407,  0.051251,\n          0.160312],\n        [-2.25    ,  1.27    ,  0.54    , ...,  0.203557,  0.054283,\n          0.14087 ],\n        [-2.42    ,  1.27    ,  0.53    , ...,  0.185629,  0.059889,\n          0.054874]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.52827 ,  0.128219,\n          0.104881],\n        [ 0.17    , -0.06    ,  0.      , ...,  0.520413,  0.180665,\n          0.150702],\n        [ 0.59    , -0.12    , -0.06    , ...,  0.520859,  0.288167,\n          0.243676],\n        ..., \n        [ 0.97    , -0.24    , -0.08    , ...,  0.296868,  0.023381,\n          0.264344],\n        [ 0.82    , -0.24    , -0.08    , ...,  0.297405,  0.037417,\n          0.211529],\n        [ 0.97    , -0.18    , -0.04    , ...,  0.298542,  0.037238,\n          0.132077]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.31634 ,  0.082624,\n          0.108628],\n        [-0.71    ,  0.26    ,  0.74    , ...,  0.307045,  0.20775 ,\n          0.205129],\n        [-1.06    ,  0.19    ,  0.74    , ...,  0.31471 ,  0.277897,\n          0.274672],\n        ..., \n        [-1.04    , -0.08    ,  0.12    , ...,  0.184709,  0.06532 ,  0.16    ],\n        [-0.95    , -0.19    ,  0.12    , ...,  0.178122,  0.028284,\n          0.152315],\n        [-0.84    , -0.18    ,  0.12    , ...,  0.173413,  0.054283,\n          0.123063]]]), 78: (510, 55, 442), 81: (510,), 83: (201,), 84: (309,), 85: (201,), 87: (200,), 88: (310,), 89: (200,), 90: (200,), 92: (200,), 93: (310,), 95: (510, 1), 102: 310, 104: (510,), 108: <matplotlib.text.Text object at 0x918f1d0>, 109: 198, 111: <matplotlib.text.Text object at 0x9894b90>, 113: <type 'list'>, 114: (310,), 116: -3.8199999999999998}, 'Normalize': <class 'matplotlib.colors.Normalize'>, 'spy': <function spy at 0x3196758>, 'train_transformed': array([[  4.00000000e-02,   2.05333333e+02,   3.26666670e+01, ...,\n          6.56650000e-01,   7.30560000e-01,   7.44760000e-02],\n       [ -1.10000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          3.24497000e-01,   2.54928000e-01,   1.47196000e-01],\n       [ -8.00000000e-02,   0.00000000e+00,   0.00000000e+00, ...,\n          9.13311000e-01,   9.19309000e-01,   6.25030000e-02],\n       ..., \n       [ -1.70000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          9.63428000e-01,   9.62613000e-01,   1.33066000e-01],\n       [  1.50000000e-01,   2.19333333e+02,   4.73333330e+01, ...,\n          9.05099000e-01,   6.36617000e-01,   1.27541000e-01],\n       [  1.10000000e-01,   6.95000000e+01,   7.55000000e+01, ...,\n          3.40341000e-01,   2.59492000e-01,   1.30486000e-01]]), 'MinuteLocator': <class 'matplotlib.dates.MinuteLocator'>, 'quiver': <function quiver at 0x3197758>, 'figure': <function figure at 0x3194938>, 'subplot2grid': <function subplot2grid at 0x31955f0>, 'get_sparse_matrix': <function get_sparse_matrix at 0x2c516e0>, 'add_newdoc': <function add_newdoc at 0x236d848>, 'seterrcall': <function seterrcall at 0x21dd2a8>, 'autumn': <function autumn at 0x31966e0>, 'logical_or': <ufunc 'logical_or'>, 'minimum': <ufunc 'minimum'>, 'WRAP': 1, 'tan': <ufunc 'tan'>, 'rms_flat': <function rms_flat at 0x2c51de8>, 'absolute': <ufunc 'absolute'>, 'gca': <function gca at 0x3195488>, 'winter': <function winter at 0x3198aa0>, 'gcf': <function gcf at 0x31949b0>, 'gci': <function gci at 0x31945f0>, 'csd': <function csd at 0x3196e60>, 'RRuleLocator': <class 'matplotlib.dates.RRuleLocator'>, 'get_array_wrap': <function get_array_wrap at 0x23770c8>, 'polymul': <function polymul at 0x238d140>, 'hot': <function hot at 0x3198758>, 'minorticks_off': <function minorticks_off at 0x3195e60>, '_81': (510,), 'get_ipython': <bound method ZMQInteractiveShell.get_ipython of <IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object at 0x2720f90>>, 'get_figlabels': <function get_figlabels at 0x3194aa0>, 'tile': <function tile at 0x23771b8>, 'array_str': <function array_str at 0x21db9b0>, 'eigvalsh': <function eigvalsh at 0x238c7d0>, 'pinv': <function pinv at 0x238cb18>, 'stock': 0, 'longlong': <type 'numpy.int64'>, 'pink': <function pink at 0x31988c0>, 'product': <function product at 0x21da1b8>, 'int16': <type 'numpy.int16'>, 's_': <numpy.lib.index_tricks.IndexExpression object at 0x236fad0>, 'mat': <function asmatrix at 0x236dc80>, 'fv': <function fv at 0x23fbb90>, 'summer': <function summer at 0x3198a28>, '_i123': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random\\nimport smtplib\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', 'yticks': <function yticks at 0x3195d70>, 'docstring': <module 'matplotlib.docstring' from '/usr/local/lib/python2.7/dist-packages/matplotlib/docstring.pyc'>, '_i36': u'plot(normTarget[:,197])', 'asanyarray': <function asanyarray at 0x21c25f0>, 'uint': <type 'numpy.uint64'>, 'negative_binomial': <built-in method negative_binomial of mtrand.RandomState object at 0x7f399f841690>, 'npv': <function npv at 0x23fe0c8>, 'logaddexp': <ufunc 'logaddexp'>, 'flatnonzero': <function flatnonzero at 0x21c28c0>, 'short': <type 'numpy.int16'>, 'correlate': <function correlate at 0x21c29b0>, 'getfigs': <function getfigs at 0x1de1848>, 'fromstring': <built-in function fromstring>, 'pylab_setup': <function pylab_setup at 0x3186cf8>, 'left_shift': <ufunc 'left_shift'>, 'tricontour': <function tricontour at 0x3197c08>, 'subplots': <function subplots at 0x3195578>, 'searchsorted': <function searchsorted at 0x21d1c08>, 'barbs': <function barbs at 0x3197ed8>, 'int64': <type 'numpy.int64'>, 'gamma': <built-in method gamma of mtrand.RandomState object at 0x7f399f841690>, 'may_share_memory': <function may_share_memory at 0x2369500>, '_76': (200,), '__': (310,), 'GridSpec': <class 'matplotlib.gridspec.GridSpec'>, 'help': Type help() for interactive help, or help(object) for help about object., 'xlim': <function xlim at 0x3195b18>, 'copper': <function copper at 0x31985f0>, 'MONTHLY': 1, 'dsplit': <function dsplit at 0x2374f50>, 'intersect1d': <function intersect1d at 0x2369ed8>, 'cosh': <ufunc 'cosh'>, 'window_none': <function window_none at 0x2c4f5f0>, 'can_cast': <built-in function can_cast>, 'performance': [0.73306000000000016], 'ppmt': <function ppmt at 0x23fbde8>, '__package__': None, 'cumsum': <function cumsum at 0x21da410>, 'roots': <function roots at 0x238cd70>, 'Widget': <class 'matplotlib.widgets.Widget'>, 'outer': <function outer at 0x21c2aa0>, 'intc': <type 'numpy.int32'>, 'fix': <function fix at 0x2301488>, 'stineman_interp': <function stineman_interp at 0x2c537d0>, 'busday_count': <built-in function busday_count>, 'cla': <function cla at 0x3197f50>, 'timedelta64': <type 'numpy.timedelta64'>, 'strpdate2num': <class matplotlib.dates.strpdate2num at 0x3025460>, 'Rectangle': <class 'matplotlib.patches.Rectangle'>, 'standard_exponential': <built-in method standard_exponential of mtrand.RandomState object at 0x7f399f841690>, 'subplot_tool': <function subplot_tool at 0x31957d0>, 'choose': <function choose at 0x21d17d0>, '_i': u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', '_i38': u'hist(normTarget)', 'FPE_INVALID': 8, 'recfromcsv': <function recfromcsv at 0x23fb6e0>, 'fill_diagonal': <function fill_diagonal at 0x23742a8>, 'void0': <type 'numpy.void'>, 'get_fignums': <function get_fignums at 0x3194a28>, 'exception_to_str': <function exception_to_str at 0x2994b18>, 'SECONDLY': 6, 'logaddexp2': <ufunc 'logaddexp2'>, 'greater': <ufunc 'greater'>, 'suptitle': <function suptitle at 0x31950c8>, '_109': 198, 'get_backend': <function get_backend at 0x2a00668>, '_i83': u'train.shape', 'matrix_power': <function matrix_power at 0x236dcf8>, 'histogram2d': <function histogram2d at 0x230d9b0>, 'LogFormatter': <class 'matplotlib.ticker.LogFormatter'>, 'polyint': <function polyint at 0x238cde8>, 'nonzero': <function nonzero at 0x21d1ed8>, '_88': (310,), 'rank': <function rank at 0x21da848>, 'quiverkey': <function quiverkey at 0x31977d0>, 'datetime64': <type 'numpy.datetime64'>, '_84': (309,), 'complexfloating': <type 'numpy.complexfloating'>, 'is_numlike': <function is_numlike at 0x29929b0>, '_i50': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],0))', 'ndindex': <class 'numpy.lib.index_tricks.ndindex'>, 'ctypeslib': <module 'numpy.ctypeslib' from '/usr/local/lib/python2.7/dist-packages/numpy/ctypeslib.pyc'>, 'waitforbuttonpress': <function waitforbuttonpress at 0x3194f50>, '_i120': u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'PZERO': 0.0, 'relativedelta': <class 'dateutil.relativedelta.relativedelta'>, 'MonthLocator': <class 'matplotlib.dates.MonthLocator'>, 'asfarray': <function asfarray at 0x23015f0>, 'gmail_user': 'mcintoshlane@gmail.com', 'radians': <ufunc 'radians'>, 'sin': <ufunc 'sin'>, 'fliplr': <function fliplr at 0x230d500>, 'alen': <function alen at 0x21da668>, '_13': (510, 55, 198), 'recarray': <class 'numpy.core.records.recarray'>, 'fmod': <ufunc 'fmod'>, '_10': 200, '_i73': u'for i,j in cv:\\n    print i,j', 'bone': <function bone at 0x3198500>, 'mean': <function mean at 0x21daa28>, 'griddata': <function griddata at 0x2c53668>, 'poly_below': <function poly_below at 0x2c538c0>, 'square': <ufunc 'square'>, 'isvector': <function isvector at 0x2c52320>, 'ogrid': <numpy.lib.index_tricks.nd_grid object at 0x236f950>, 'bytes': <type 'str'>, 'nanargmin': <function nanargmin at 0x236cc08>, 'r_': <numpy.lib.index_tricks.RClass object at 0x236f990>, 'hanning': <function hanning at 0x236d230>, 'trainInput': array([[[ -8.00000000e-01,   5.00000000e+00,   0.00000000e+00, ...,\n           2.99584000e-01,   3.88160000e-02,   8.13090000e-02],\n        [  1.33333300e+00,   3.00000000e+00,   0.00000000e+00, ...,\n           3.14446000e-01,   2.51952000e-01,   2.06263000e-01],\n        [  6.66666000e-01,   3.00000000e+00,   5.00000000e+00, ...,\n           3.57783000e-01,   5.10176000e-01,   4.29069000e-01],\n        ..., \n        [  6.66666000e-01,   3.00000000e+00,   0.00000000e+00, ...,\n           2.69088000e-01,   1.26912000e-01,   1.03441000e-01],\n        [  0.00000000e+00,   2.00000000e+00,   1.00000000e+00, ...,\n           2.62727000e-01,   1.33116000e-01,   1.11704000e-01],\n        [  1.50000000e+00,   2.00000000e+00,   5.00000000e+00, ...,\n           2.59782000e-01,   1.21326000e-01,   1.24544000e-01]],\n\n       [[  2.92682000e-01,   4.10000000e+01,   0.00000000e+00, ...,\n           3.20344000e-01,   7.12740000e-02,   5.78310000e-02],\n        [  3.33333000e-01,   3.00000000e+00,   0.00000000e+00, ...,\n           4.10495000e-01,   6.34182000e-01,   5.21483000e-01],\n        [  2.00000000e+00,   1.00000000e+00,   3.00000000e+00, ...,\n           4.78352000e-01,   7.94850000e-01,   6.90853000e-01],\n        ..., \n        [  0.00000000e+00,   1.10000000e+01,   0.00000000e+00, ...,\n           2.31589000e-01,   6.77250000e-02,   9.07990000e-02],\n        [  3.33333000e-01,   1.50000000e+01,   1.00000000e+00, ...,\n           2.31602000e-01,   7.23880000e-02,   1.00995000e-01],\n        [  7.89473000e-01,   1.90000000e+01,   0.00000000e+00, ...,\n           2.25328000e-01,   4.84420000e-02,   8.36660000e-02]],\n\n       [[  4.41860000e-01,   4.30000000e+01,   0.00000000e+00, ...,\n           1.96550000e-01,   1.50555000e-01,   1.20830000e-01],\n        [  6.66666000e-01,   3.00000000e+00,   5.00000000e+00, ...,\n           1.94066000e-01,   1.53753000e-01,   1.28841000e-01],\n        [  0.00000000e+00,   1.00000000e+00,   5.00000000e+00, ...,\n           1.87594000e-01,   1.53753000e-01,   1.32288000e-01],\n        ..., \n        [ -1.11111000e-01,   9.00000000e+00,   5.00000000e+00, ...,\n           1.83963000e-01,   7.37560000e-02,   8.12400000e-02],\n        [  0.00000000e+00,   6.00000000e+00,   5.00000000e+00, ...,\n           1.77811000e-01,   6.03320000e-02,   6.61650000e-02],\n        [  5.00000000e-01,   1.20000000e+01,   0.00000000e+00, ...,\n           1.74681000e-01,   6.12100000e-02,   6.00000000e-02]],\n\n       ..., \n       [[  4.87500000e-01,   8.00000000e+01,   0.00000000e+00, ...,\n           1.50991000e-01,   7.33940000e-02,   6.70820000e-02],\n        [ -5.00000000e-01,   6.00000000e+00,   0.00000000e+00, ...,\n           1.50545000e-01,   6.69330000e-02,   6.70820000e-02],\n        [  7.77777000e-01,   1.80000000e+01,   0.00000000e+00, ...,\n           1.50910000e-01,   6.88960000e-02,   6.91210000e-02],\n        ..., \n        [  7.30769000e-01,   2.60000000e+01,   0.00000000e+00, ...,\n           1.97203000e-01,   7.31210000e-02,   8.36660000e-02],\n        [  2.85714000e-01,   2.80000000e+01,   5.00000000e+00, ...,\n           1.98655000e-01,   7.48330000e-02,   6.92820000e-02],\n        [  3.23529000e-01,   3.40000000e+01,   0.00000000e+00, ...,\n           1.98691000e-01,   9.95990000e-02,   8.00000000e-02]],\n\n       [[  0.00000000e+00,   2.40000000e+01,   0.00000000e+00, ...,\n           1.50959000e-01,   8.94430000e-02,   9.51020000e-02],\n        [ -2.50000000e-01,   4.00000000e+00,   2.33333300e+00, ...,\n           1.91609000e-01,   2.67133000e-01,   2.41753000e-01],\n        [  0.00000000e+00,   2.00000000e+00,   0.00000000e+00, ...,\n           2.23181000e-01,   3.15383000e-01,   2.98794000e-01],\n        ..., \n        [  1.42857000e-01,   1.40000000e+01,   0.00000000e+00, ...,\n           1.88956000e-01,   6.28230000e-02,   5.56780000e-02],\n        [  6.00000000e-01,   1.00000000e+01,   1.00000000e+00, ...,\n           1.91981000e-01,   6.62320000e-02,   5.81190000e-02],\n        [  2.94117000e-01,   1.70000000e+01,   4.00000000e+00, ...,\n           1.91485000e-01,   6.28230000e-02,   6.00000000e-02]],\n\n       [[  6.00000000e-01,   1.50000000e+01,   0.00000000e+00, ...,\n           1.10484000e+00,   5.42830000e-02,   9.48680000e-02],\n        [  0.00000000e+00,   3.00000000e+00,   3.40000000e+00, ...,\n           1.35640700e+00,   1.78215200e+00,   1.46147600e+00],\n        [  0.00000000e+00,   1.00000000e+00,   3.00000000e+00, ...,\n           1.52380800e+00,   2.13168200e+00,   1.81240200e+00],\n        ..., \n        [ -3.33333000e-01,   3.00000000e+00,   3.40000000e+00, ...,\n           5.75108000e-01,   3.00311000e-01,   3.10644000e-01],\n        [ -7.14285000e-01,   7.00000000e+00,   1.00000000e+00, ...,\n           5.69777000e-01,   2.76743000e-01,   2.84429000e-01],\n        [  1.60000000e+00,   5.00000000e+00,   0.00000000e+00, ...,\n           5.57479000e-01,   2.14942000e-01,   3.23883000e-01]]]), 'connect': <function connect at 0x3194c08>, '_i72': u'for i in cv:\\n    print i', 'str_': <type 'numpy.string_'>, 'margins': <function margins at 0x3198410>, 'allclose': <function allclose at 0x21dbe60>, 'extract': <function extract at 0x236c9b0>, 'isOutput': [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'float16': <type 'numpy.float16'>, '_i13': u'trainOutput.shape', 'ulonglong': <type 'numpy.uint64'>, 'matrix': <class 'numpy.matrixlib.defmatrix.matrix'>, 'probas': array([[ 0.006,  0.002,  0.   , ...,  0.006,  0.   ,  0.   ],\n       [ 0.002,  0.   ,  0.   , ...,  0.008,  0.018,  0.   ],\n       [ 0.002,  0.004,  0.004, ...,  0.002,  0.002,  0.01 ],\n       ..., \n       [ 0.018,  0.   ,  0.006, ...,  0.006,  0.004,  0.006],\n       [ 0.   ,  0.   ,  0.   , ...,  0.002,  0.024,  0.   ],\n       [ 0.004,  0.02 ,  0.004, ...,  0.004,  0.   ,  0.006]]), 'asarray': <function asarray at 0x21c2578>, 'True_': True, 'IndexLocator': <class 'matplotlib.ticker.IndexLocator'>, 'poly1d': <class 'numpy.lib.polynomial.poly1d'>, 'rf': RandomForestClassifier(bootstrap=True, compute_importances=None,\n            criterion='gini', max_depth=None, max_features='auto',\n            min_density=None, min_samples_leaf=1, min_samples_split=2,\n            n_estimators=500, n_jobs=2, oob_score=False, random_state=None,\n            verbose=0), 'void': <type 'numpy.void'>, '_i28': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', 'promote_types': <built-in function promote_types>, '_i26': u'target.shape', 'rec': <module 'numpy.core.records' from '/usr/local/lib/python2.7/dist-packages/numpy/core/records.pyc'>, '_i24': u'len(trainOutput[0])', 'arange': <built-in function arange>, 'datetime_as_string': <built-in function datetime_as_string>, 'plotting': <function plotting at 0x3196050>, 'math': <module 'math' (built-in)>, '_i21': u'train.shape', 'get_cmap': <function get_cmap at 0x2b80ed8>, 'log2': <ufunc 'log2'>, 'specgram': <function specgram at 0x31979b0>, 'date2num': <function date2num at 0x307bed8>, '__builtins__': {'bytearray': <type 'bytearray'>, 'IndexError': <type 'exceptions.IndexError'>, 'all': <built-in function all>, 'help': Type help() for interactive help, or help(object) for help about object., 'vars': <built-in function vars>, 'SyntaxError': <type 'exceptions.SyntaxError'>, '__IPYTHON__active': 'Deprecated, check for __IPYTHON__', 'unicode': <type 'unicode'>, 'UnicodeDecodeError': <type 'exceptions.UnicodeDecodeError'>, 'memoryview': <type 'memoryview'>, 'isinstance': <built-in function isinstance>, 'copyright': Copyright (c) 2001-2012 Python Software Foundation.\nAll Rights Reserved.\n\nCopyright (c) 2000 BeOpen.com.\nAll Rights Reserved.\n\nCopyright (c) 1995-2001 Corporation for National Research Initiatives.\nAll Rights Reserved.\n\nCopyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\nAll Rights Reserved., 'NameError': <type 'exceptions.NameError'>, 'BytesWarning': <type 'exceptions.BytesWarning'>, 'dict': <type 'dict'>, 'input': <function <lambda> at 0x5cf2398>, 'oct': <built-in function oct>, 'bin': <built-in function bin>, 'SystemExit': <type 'exceptions.SystemExit'>, 'StandardError': <type 'exceptions.StandardError'>, 'format': <built-in function format>, 'repr': <built-in function repr>, 'sorted': <built-in function sorted>, 'False': False, 'RuntimeWarning': <type 'exceptions.RuntimeWarning'>, 'list': <type 'list'>, 'iter': <built-in function iter>, 'reload': <built-in function reload>, 'Warning': <type 'exceptions.Warning'>, '__package__': None, 'round': <built-in function round>, 'dir': <built-in function dir>, 'cmp': <built-in function cmp>, 'set': <type 'set'>, 'bytes': <type 'str'>, 'reduce': <built-in function reduce>, 'intern': <built-in function intern>, 'issubclass': <built-in function issubclass>, 'Ellipsis': Ellipsis, 'EOFError': <type 'exceptions.EOFError'>, 'locals': <built-in function locals>, 'BufferError': <type 'exceptions.BufferError'>, 'slice': <type 'slice'>, 'FloatingPointError': <type 'exceptions.FloatingPointError'>, 'sum': <built-in function sum>, 'getattr': <built-in function getattr>, 'abs': <built-in function abs>, 'print': <built-in function print>, 'True': True, 'FutureWarning': <type 'exceptions.FutureWarning'>, 'ImportWarning': <type 'exceptions.ImportWarning'>, 'None': None, 'hash': <built-in function hash>, 'ReferenceError': <type 'exceptions.ReferenceError'>, 'len': <built-in function len>, 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n    for supporting Python development.  See www.python.org for more information., 'frozenset': <type 'frozenset'>, '__name__': '__builtin__', 'ord': <built-in function ord>, 'super': <type 'super'>, 'TypeError': <type 'exceptions.TypeError'>, 'license': Type license() to see the full license text, 'KeyboardInterrupt': <type 'exceptions.KeyboardInterrupt'>, 'UserWarning': <type 'exceptions.UserWarning'>, 'filter': <built-in function filter>, 'range': <built-in function range>, 'staticmethod': <type 'staticmethod'>, 'SystemError': <type 'exceptions.SystemError'>, 'BaseException': <type 'exceptions.BaseException'>, 'pow': <built-in function pow>, 'RuntimeError': <type 'exceptions.RuntimeError'>, 'float': <type 'float'>, 'MemoryError': <type 'exceptions.MemoryError'>, 'StopIteration': <type 'exceptions.StopIteration'>, 'globals': <built-in function globals>, 'divmod': <built-in function divmod>, 'enumerate': <type 'enumerate'>, 'apply': <built-in function apply>, 'LookupError': <type 'exceptions.LookupError'>, 'open': <built-in function open>, 'basestring': <type 'basestring'>, 'UnicodeError': <type 'exceptions.UnicodeError'>, 'zip': <built-in function zip>, 'hex': <built-in function hex>, 'long': <type 'long'>, 'next': <built-in function next>, 'ImportError': <type 'exceptions.ImportError'>, 'chr': <built-in function chr>, 'xrange': <type 'xrange'>, 'type': <type 'type'>, '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\", 'Exception': <type 'exceptions.Exception'>, '__IPYTHON__': True, 'tuple': <type 'tuple'>, 'UnicodeTranslateError': <type 'exceptions.UnicodeTranslateError'>, 'reversed': <type 'reversed'>, 'UnicodeEncodeError': <type 'exceptions.UnicodeEncodeError'>, 'IOError': <type 'exceptions.IOError'>, 'hasattr': <built-in function hasattr>, 'delattr': <built-in function delattr>, 'setattr': <built-in function setattr>, 'raw_input': <function <lambda> at 0x7f39504c2578>, 'SyntaxWarning': <type 'exceptions.SyntaxWarning'>, 'compile': <built-in function compile>, 'ArithmeticError': <type 'exceptions.ArithmeticError'>, 'str': <type 'str'>, 'property': <type 'property'>, 'dreload': <function reload at 0x2725c08>, 'GeneratorExit': <type 'exceptions.GeneratorExit'>, 'int': <type 'int'>, '__import__': <built-in function __import__>, 'KeyError': <type 'exceptions.KeyError'>, 'coerce': <built-in function coerce>, 'PendingDeprecationWarning': <type 'exceptions.PendingDeprecationWarning'>, 'file': <type 'file'>, 'EnvironmentError': <type 'exceptions.EnvironmentError'>, 'unichr': <built-in function unichr>, 'id': <built-in function id>, 'OSError': <type 'exceptions.OSError'>, 'DeprecationWarning': <type 'exceptions.DeprecationWarning'>, 'min': <built-in function min>, 'UnicodeWarning': <type 'exceptions.UnicodeWarning'>, 'execfile': <built-in function execfile>, 'any': <built-in function any>, 'complex': <type 'complex'>, 'bool': <type 'bool'>, 'get_ipython': <bound method ZMQInteractiveShell.get_ipython of <IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object at 0x2720f90>>, 'ValueError': <type 'exceptions.ValueError'>, 'NotImplemented': NotImplemented, 'map': <built-in function map>, 'buffer': <type 'buffer'>, 'max': <built-in function max>, 'object': <type 'object'>, 'TabError': <type 'exceptions.TabError'>, 'callable': <built-in function callable>, 'ZeroDivisionError': <type 'exceptions.ZeroDivisionError'>, 'eval': <built-in function eval>, '__debug__': True, 'IndentationError': <type 'exceptions.IndentationError'>, 'AssertionError': <type 'exceptions.AssertionError'>, 'classmethod': <type 'classmethod'>, 'UnboundLocalError': <type 'exceptions.UnboundLocalError'>, 'NotImplementedError': <type 'exceptions.NotImplementedError'>, 'AttributeError': <type 'exceptions.AttributeError'>, 'OverflowError': <type 'exceptions.OverflowError'>}, 'rec_join': <function rec_join at 0x2c526e0>, 'acorr': <function acorr at 0x31967d0>, 'cumproduct': <function cumproduct at 0x21da488>, 'diagonal': <function diagonal at 0x21d1d70>, 'atleast_1d': <function atleast_1d at 0x22741b8>, '_i116': u'pred[0]', '_i115': u'yoda = np.asarray(predicted_probs)\\nluke = np.zeros((310,198))\\nluke[:,0] = yoda', 'meshgrid': <function meshgrid at 0x236d8c0>, 'eventplot': <function eventplot at 0x3196f50>, '_i112': u'numStocks', '_i111': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", 'column_stack': <function column_stack at 0x2374c08>, 'put': <function put at 0x21d18c0>, '___': <type 'list'>, 'smtpserver': <smtplib.SMTP instance at 0x7f393945a7a0>, 'remainder': <ufunc 'remainder'>, '_i19': u'fullInput[509,54,244+197]', 'get_scale_docs': <function get_scale_docs at 0x2fc7140>, '_i118': u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'row_stack': <function vstack at 0x2274758>, 'expm1': <ufunc 'expm1'>, 'ion': <function ion at 0x3194500>, 'insert': <function insert at 0x236d9b0>, 'semilogx': <function semilogx at 0x31978c0>, 'semilogy': <function semilogy at 0x3197938>, 'ndfromtxt': <function ndfromtxt at 0x23fb578>, 'sometrue': <function sometrue at 0x21da230>, 'place': <function place at 0x236ca28>, 'DataSource': <class 'numpy.lib._datasource.DataSource'>, 'newaxis': None, 'arccos': <ufunc 'arccos'>, 'epoch2num': <function epoch2num at 0x307fa28>, '_i59': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", 'signedinteger': <type 'numpy.signedinteger'>, '_i119': u'import smtplib', 'ndim': <function ndim at 0x21da7d0>, 'rand': <built-in method rand of mtrand.RandomState object at 0x7f399f841690>, 'irfft': <function irfft at 0x23fef50>, 'ranf': <built-in method random_sample of mtrand.RandomState object at 0x7f399f841690>, 'subplots_adjust': <function subplots_adjust at 0x3195758>, 'rint': <ufunc 'rint'>, 'fill_between': <function fill_between at 0x31970c8>, 'Axes': <class 'matplotlib.axes.Axes'>, 'MaxNLocator': <class 'matplotlib.ticker.MaxNLocator'>, 'arctan2': <ufunc 'arctan2'>, 'little_endian': True, 'ldexp': <ufunc 'ldexp'>, 'lognormal': <built-in method lognormal of mtrand.RandomState object at 0x7f399f841690>, 'lookfor': <function lookfor at 0x23697d0>, 'hfft': <function hfft at 0x2409050>, 'array': <built-in function array>, 'common_type': <function common_type at 0x2301b90>, 'size': <function size at 0x21da8c0>, 'logical_xor': <ufunc 'logical_xor'>, '_i51': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))', 'geterrcall': <function geterrcall at 0x21dd320>, 'sheet': [['fileId', 'O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8', 'O9', 'O10', 'O11', 'O12', 'O13', 'O14', 'O15', 'O16', 'O17', 'O18', 'O19', 'O20', 'O21', 'O22', 'O23', 'O24', 'O25', 'O26', 'O27', 'O28', 'O29', 'O30', 'O31', 'O32', 'O33', 'O34', 'O35', 'O36', 'O37', 'O38', 'O39', 'O40', 'O41', 'O42', 'O43', 'O44', 'O45', 'O46', 'O47', 'O48', 'O49', 'O50', 'O51', 'O52', 'O53', 'O54', 'O55', 'O56', 'O57', 'O58', 'O59', 'O60', 'O61', 'O62', 'O63', 'O64', 'O65', 'O66', 'O67', 'O68', 'O69', 'O70', 'O71', 'O72', 'O73', 'O74', 'O75', 'O76', 'O77', 'O78', 'O79', 'O80', 'O81', 'O82', 'O83', 'O84', 'O85', 'O86', 'O87', 'O88', 'O89', 'O90', 'O91', 'O92', 'O93', 'O94', 'O95', 'O96', 'O97', 'O98', 'O99', 'O100', 'O101', 'O102', 'O103', 'O104', 'O105', 'O106', 'O107', 'O108', 'O109', 'O110', 'O111', 'O112', 'O113', 'O114', 'O115', 'O116', 'O117', 'O118', 'O119', 'O120', 'O121', 'O122', 'O123', 'O124', 'O125', 'O126', 'O127', 'O128', 'O129', 'O130', 'O131', 'O132', 'O133', 'O134', 'O135', 'O136', 'O137', 'O138', 'O139', 'O140', 'O141', 'O142', 'O143', 'O144', 'O145', 'O146', 'O147', 'O148', 'O149', 'O150', 'O151', 'O152', 'O153', 'O154', 'O155', 'O156', 'O157', 'O158', 'O159', 'O160', 'O161', 'O162', 'O163', 'O164', 'O165', 'O166', 'O167', 'O168', 'O169', 'O170', 'O171', 'O172', 'O173', 'O174', 'O175', 'O176', 'O177', 'O178', 'O179', 'O180', 'O181', 'O182', 'O183', 'O184', 'O185', 'O186', 'O187', 'O188', 'O189', 'O190', 'O191', 'O192', 'O193', 'O194', 'O195', 'O196', 'O197', 'O198'], ['201', -3.82, -0.88, 0.54, 0.08, -1.65, -2.8, -1.74, -5.108279403464041, -4.58, -5.23, 1.78, -3.49, -1.71, -0.32, 0.35428571428571426, -5.32, -1.46, -3.82, -2.64, -4.65, -6.76, -2.19, -0.9256947683993239, -2.17, -4.67, -2.91, -6.9, -5.18, -3.43, -2.06, -1.41, -6.98, -3.19, -5.5, -4.35, -6.32, -8.4, -3.9, -2.75, -3.88, -4.834514634175348, -8.81, -1.81, 1.84, 3.29, 3.98, -1.89, 2.1, -0.34, 0.88, -1.2, -3.39, 1.35, 2.6471428571428572, 1.37, -3.15, -4.75, -4.42, -5.05, -3.59, 1.42, 2.1, -3.67, 0.25, -2.14, -0.95, -2.99, -5.14, -0.48, 0.71, -0.46, -5.02, -4.93, 0.67, -5.02, -1.15, -3.51, -2.33, -4.35, -6.47, -1.88, -0.7, -1.86, -6.76, -11.6, 11.63, -5.57, -5.65, -1.81, -4.15, -2.98, -4.98, -7.09, -2.53, -1.36, -2.51, -1.3273809523809526, 0.09, 4.07, 1.58, 2.83, 0.71, -1.4673734626473065, 3.31, 4.54, 3.33, -1.34, 0.0, -5.22, -3.09, -3.15, -3.04, -3.83, -2.39, -1.19, -3.23, -5.38, -0.73, 0.45, -0.72, -3.03, -1.47, 1.22, -0.86, -3.06, 1.69, 2.91, 1.71, -4.7, -4.57, -0.18, -3.76, -2.65, -1.5696768707482993, -1.01, 5.73, -5.73, -2.89, -2.1, -7.4, 1.2, 6.14, 3.12, -1.91, -2.13, -9.34, 9.31, 9.23, -3.1, 8.58, -6.09, -3.55, 1.78, -11.41, 25.62, 7.66, 11.19, -1.1, -2.67, -2.06, -4.23, 0.47, 1.67, 0.49, -9.21, -0.61, -2.21, 2.58, 3.81, 2.6, 1.64, 4.91, 6.16, 4.93, -4.6, -5.86, -3.12, 1.2, 0.02, -3.01, -3.17, -5.0, 12.86, -4.81, -12.61, -4.07, -3.55, -4.181362551799029, -1.16, -3.5, -2.83, -2.03, -1.53, -2.5, -3.14, -6.31, -4.71, -3.53], ['202', 7.014285714285714, -1.9, -0.6387782843795413, 0.5821428571428573, -0.08, -1.74, -0.8458847420401708, -1.17, -1.91, -0.5, 3.17, -0.07, 1.07, 1.35, 2.39, -2.31, 3.2, 0.84, 0.74, 1.0, -1.16, 3.18, 2.54, 1.5721746031746033, -2.59, -2.91, -3.55, -3.14, -2.03, -1.77, -0.75, -5.31, 0.03, -2.26, -2.36, -2.1, -4.2, 0.01, -0.61, -1.55, -2.3, -3.1750638007838266, -0.42, 1.15, 1.42, 2.47, -2.24, 3.27, 0.92, 0.81, 1.07, -1.09, 3.26, 2.62, 1.65, -0.82, -2.27, -0.17, -1.49, -1.55, 0.27, 1.3, -3.35, 2.1, -0.23, -0.33, -0.07, -2.21, 2.09, 1.46, 0.49, -1.68, -1.6042857142857143, 1.03, -3.61, 1.82, -0.5, -0.6, -0.35, -2.47, 1.81, 1.18, 0.22, -3.28, -9.13, 9.15, -2.82, -4.59, 0.79, -1.4957142857142858, -1.62, -1.36, -3.47, 0.77, 0.15, -0.8, -0.74, 1.86, 5.64, 3.23, 3.12, 3.39, 1.18, 5.62, 4.97, 3.97, -0.97, 1.77, -4.3342762881169605, -1.94, -2.32, -2.04, -3.58, -2.28, -2.39, -2.13, -4.22, -0.02, -0.63, -1.57, -3.54, -1.33, -0.11, 0.15, -1.98, 2.32, 1.69, 0.72, -3.13, -2.54, -0.28, -3.84, -1.37, -1.66, -0.96, 3.48, -3.41, -1.73, -3.69, -1.07, 2.85, 4.0, 1.93, 3.911438775510204, -1.52, -6.48, 6.48, 5.95, -1.98, 5.25, -3.93, -4.63, 2.01, -10.86, 10.55, 7.371428571428571, 11.015714285714285, -3.14, -1.22, 0.26, -1.88, 2.43, 1.79, 0.83, -6.0, -1.48, -2.14, 2.16, 1.53, 0.57, 0.67, 4.39, 3.9828571428571427, 2.76, -1.93, -2.26, -3.56, -0.62, -1.56, -1.92, -2.27, -1.18, 5.3, -4.25, -5.42, -1.7, -2.77, -2.96, -0.95, -2.09, -1.44, -0.67, -1.779047619047619, -2.33, -2.04, -5.38, -5.58, -2.6], ['203', 2.06, -0.11, 0.37, -0.13, 0.36, 0.82, 0.97, 1.61, 1.14, 2.93, 1.87, 2.06, 1.96, 1.85, 0.97, 2.26, 2.17, 2.29, 0.5, 0.92, 3.2, 2.66, 2.12, 2.55, 1.05, 1.03, 1.0726583949931126, 0.19, 0.09, -0.02, -0.88, 0.39, 0.3, 0.41, -1.34, -0.92, 1.31, 0.78, 0.25, 0.67, 1.63, 0.020062111801242236, 0.85, -0.1, -0.21, -1.07, 0.19, 0.11, 0.22, -1.53, -1.11, 1.12, 0.59, 0.06, 0.47, 1.0700628463056765, 1.55, 0.95, 1.7, 0.95, -0.11, -0.97, 0.29, 0.2, 0.32, -1.43, -1.02, 1.21, 0.69, 0.16, 0.57, 1.8, 1.06, -0.8592857142857143, 0.4, 0.32, 0.43, -1.32, -0.91, 1.33, 0.8, 0.27, 0.69, 0.74, 2.18, -2.2694285714285716, 1.94, 1.27, 1.18, 1.3, -0.47, -0.05, 2.21, 1.67, 1.14, 1.56, 1.95, 0.66, -0.09, 0.03, -1.72, -1.3, 0.92, 0.4, -0.13, 0.28, 0.58, 0.65, 0.03, 0.55, 0.63, 0.45, 0.74, 0.12, -1.63, -1.22, 1.01, 0.48, -0.05, 0.37, 0.26, 0.63, -1.74, -1.33, 0.89, 0.37, 0.0657142857142857, 0.25, 0.87, 0.68, -0.35, 0.4, 6.0, 0.27, 0.16, -1.08, 0.97, 0.52, 0.35, 1.67, -3.9, -1.17, -0.57, 1.04, 0.3, 1.58, -1.69, -1.74, 0.55, -1.66, 1.17, 1.08, -0.54, 2.23, 1.14, -1.55, -2.29, 3.89, 2.41, 0.42, 2.68, 2.15, 1.61, 2.03, 1.65, 1.99, 2.26, 1.72, 1.3340034013605442, 1.61, -0.26, -0.52, -1.05, -0.63, 1.13, 1.31, 0.26, -0.53, -0.12, 0.53, 0.58, 1.52, 0.6, 0.46, -0.88, 1.06, 0.69, 0.79, 0.42, 0.99, 0.47021978021978017, 0.29, -0.05, 0.5, 0.37, 0.88, 0.93, 0.67], ['204', -0.62, -0.06, 0.09122171562045875, 0.26, -0.37, 0.2984196236737595, 7.22, -0.29, 0.79, -1.71, -1.87, -5.55, -1.43, -1.81, -1.65, -1.51, -2.13, -1.83, -1.94, -0.14, -1.65, -2.61, -2.17, -2.08, -0.22, -0.2, 0.16, -3.76, 0.45, 0.05, 0.22, 0.36, -0.26, 0.04, -0.07, 1.76, 0.22, -0.76, -0.31, -0.22, -0.23, 0.7949361992161734, 4.07, 4.37, 3.96, 4.13, 4.28, 3.63, 3.95, 3.83, 5.73, 4.14, 3.11, 3.59, 3.68, 0.3, 0.04, -0.22, -0.17, -0.29, -0.39, -0.23, -0.08, -0.71, -0.41, -0.52, 1.3, -0.22, -1.21, -0.75, -0.66, -2.12, 0.11, 0.16, 0.31, -0.32, -0.01, -0.13, 1.7, 0.17, -0.82, -0.36, -0.27, 0.21, 1.33, -1.35, -0.06, 0.14, -0.48, -0.18, -0.29, 1.54, 0.01, -0.98, -0.52, -0.3759922724755494, 3.21, -0.2, -0.63, -0.32, -0.43, 1.39, -0.14, -1.12, -0.67, -0.58, 0.15, -0.17, 0.09, 0.21, 0.32, 0.13567351865003197, 0.43, 0.31, 0.19, 2.03, 0.49, -0.5, -0.04, 0.05, 0.89, 0.17307674813036728, -0.11, 1.72, 0.18, -0.8, -0.35, -0.26, 0.31, 0.46, 0.53, 0.33, 9.51, -0.07, 0.06, 0.19, -0.17, -0.02118982899237888, 0.36, 0.9, 3.11, -0.38, -0.26, -0.31, 0.58, 0.66, -0.71, -0.6, 0.21, 0.21, 0.42, -1.98, 0.98, 1.3, 1.71, -0.86, -1.2, -3.15, 0.24, 1.83, 0.3, -0.69, -0.23, -0.15, 0.61, -1.57, -1.51, -2.48, -2.03, -1.94, -0.06, -0.99, -0.53, -0.44, 0.75, -0.04154645354645334, 0.93, 0.46, 0.55, 0.21, 0.23, -0.19, 0.69, 0.16, -0.6, 0.71, -0.36, 0.47, 0.09, 0.26, -0.08, 0.45, 0.67, 0.22, 0.38, 0.96, -0.42, 1.06], ['205', -0.6857142857142857, -0.84, -0.38877828437954126, 0.44, -2.77, -1.44, -1.7058847420401708, -2.17, -3.19, -2.51, 1.03, -0.44, -1.05, -0.66, -0.29, -2.35, -0.95, -2.16, -2.09, 1.65, -4.09, -0.64, -0.29, -1.17, -2.81, -2.37, -3.51, -1.46, -2.07, -1.68, -1.31, -3.35, -1.96, -3.16, -3.09, 0.61, -5.07, -1.66, -1.31, -2.136158276802161, -1.89, -4.975063800783826, -2.08, -0.62, -0.23, 0.15, -1.92, -0.52, -1.73, -1.66, 2.1011904761904763, -3.67, -0.21, 0.15, -0.74, -0.88, -2.12, -2.17, -2.85, -1.47, 0.39, 0.77, -1.31, 0.1, -1.12, -1.05, 2.73, -3.07, 0.41, 0.77, -0.12, -2.29, -1.86, 0.38, -1.7, -0.29, -1.51, -1.43, 2.33, -3.45, 0.02, 0.38, -0.51, -4.18, -6.1, 6.13, -2.23, -2.07, -0.66, -1.87, -1.8, 1.94, -3.81, -0.35, 0.0, -0.89, -1.33, -0.16, 1.43, 0.2, 0.27, 4.1, -1.78, 1.75, 2.11, 1.21, -0.35, -0.13, -1.87, -1.73, -1.72, -1.57, -1.57, -1.22, -1.15, 2.62, -3.17, 0.31, 0.67, -0.23, -1.87, -0.36, 0.07, 3.89, -1.97, 1.55, 1.91, 1.01, -1.95, -1.46, 0.47, -1.49, -2.57, -0.26, -0.84, 3.32, -3.31, -1.7, -0.94, -2.48, 7.87, 3.45, 1.73, -0.06856122448979596, -1.67, -4.94, 5.08, 5.1, -1.7, 5.02, -3.43, -2.87, 1.48, -4.66, 14.77, 3.13, 4.68, -8.0, -0.43, 3.82, -2.04, 1.48, 1.84, 0.93, -5.15, -4.09, -5.64, -2.26, -1.8601904761904762, -2.78, 1.65, 3.59, 3.96, 3.04, -3.31, -3.7, -1.88, 0.36, -0.53, -1.69, -1.66, -1.99, 7.36, -1.88, -7.51, -2.23, -2.3589064979199876, -2.23, -0.89, -1.34, -1.77, -1.55, -1.1552380952380952, -1.28, -1.35, -2.4, -2.61, -1.3], ['206', -1.64, -0.62, -0.07984710169072946, 0.09, -1.39, -0.93, -0.89, -1.8, -2.11, -0.67, 2.95, 0.17, 1.61, 1.89, 1.82, -0.97, 1.46, -0.45, -1.4, 1.72, -1.68, 0.84, 1.46, 0.35, -1.09, -2.04, -3.51, -2.7, -1.29, -1.02, -1.09, -3.81, -1.45, -3.3, -4.22, -1.19, -4.49, -2.05, -1.44, -2.52, -1.13, -2.1, -0.84, 1.44, 1.72, 1.65, -1.14, 1.29, -0.29945408163265297, -1.56, 1.55, -1.85, 0.67, 1.29, 0.18, 0.1, -0.53, -1.4, -1.81, -2.25, 0.27, 0.21, -2.55, -0.15, -2.03, -2.96, 0.1, -3.24, -0.76, -0.15, -1.24, -1.96, -2.51, -0.07, -2.81, -0.43, -2.3, -3.23, -0.17, -3.51, -0.9485714285714286, -0.43, -1.51, -3.24, -5.68, 5.61, -2.45, -2.75, -0.36, -2.23, -3.16, -0.1, -3.44, -0.97, -0.36, -1.45, -2.6, 0.31, 2.45, 0.53, -0.43, 2.72, -0.71, 1.83, 2.46, 1.34, -0.22, 0.37, -2.44, -1.3984018193170984, -1.6, -1.37, -2.09, -1.88, -2.81, 0.26, -3.09, -0.61, 0.0, -1.09, -1.49, -0.22, -0.95, 2.18, -1.24, 1.29, 1.92, 0.8, -1.95, -1.86, 0.17, -1.85, -7.74, -0.12, -0.07, 3.7, -3.68, -1.84, -1.87, -2.75, 4.93, 2.88, 1.48, -0.88, -0.9, -4.43, 4.33, 4.33, -1.46, 5.55, -2.89, -1.51, 0.77, -6.35, 17.7, 4.12, 6.24, -4.85, 0.74, 3.16, -0.29, 2.27, 2.9, 1.77, -4.246832100439243, -2.2156457669314813, -3.34, -0.87, -0.25, -1.35, 1.03, 2.56, 3.19, 2.07, -2.1, -2.91, -1.49, 0.62, -0.48, -1.44, -1.56, -1.73, 11.01, -2.12, -10.56, -1.58, -2.34, -2.1, -1.09, -1.75, -1.7354471401614255, -0.72, -0.77, -0.52, -1.01, -3.55, -3.3, -1.69], ['207', -0.27, 0.42, 0.08, 0.02, -0.25, 0.44, 1.96, 0.46, 0.44, 0.2, 0.19, -0.88, -0.8, -0.12, -1.0, 0.35, -0.27, 0.11, 4.04, 0.56, -0.09266451791264106, -0.08, 0.43, -0.23, 0.57, 0.07, 0.01, -1.07, -0.99, -0.31, -1.19, 0.16, -0.46, -0.09, 3.84, 0.37, -0.32, -0.27, 0.24, -0.42, 1.32, 1.8549361992161735, 1.09, 0.07, 0.77, -0.13, 1.24, 0.61, 0.99, 4.96, 1.45, 0.75, 0.8, 1.32, 0.65, 0.73, 1.18, 1.19, 0.11, 1.02, 0.69, -0.2, 1.17, 0.54, 0.92, 4.88, 1.38, 0.68, 0.73, 1.2527347454133169, 0.58, 0.11, 0.32, -0.89, 0.47, -0.15, 0.22, 4.16, 0.68, -0.02, 0.04, 0.55, -0.05644035827487928, 0.08, 0.01, 0.06, 1.22, 1.37, 0.74, 1.12, 5.09, 1.58, 0.88, 0.93, 1.45, 0.78, -0.83, -0.15, -0.62, -0.25, 3.67, 0.21, -0.49, -0.43, 0.08, -0.58, 0.15, -0.12, 1.31, 0.3215981806829015, 0.2, 0.48567351865003194, 0.5418094764861292, 0.37, 4.32, 0.83, 0.13, 0.19, 0.7, 0.04, 0.35, 0.1, 3.93, 0.46, -0.24, -0.19, 0.33, -0.33, -0.41, -0.21, 0.04, 0.5, -2.57, 0.29, 0.18, -0.78, 0.77, 0.39, 0.14, -0.03, 0.72, -0.5, -0.27, -0.11, 0.18, 0.78, -0.76, -0.74, 0.25, -1.16, 0.49, -0.02, 0.02, 1.45, -0.52, -0.88, -1.47, -0.69, -3.69, -3.34, -4.01, -3.96, -3.46, -4.1, 0.69, -0.36, -0.69, -0.64, -0.13, -0.79, 0.34, 0.05, 0.57, -0.1, 0.46, 0.22, 0.28, 0.52, -0.15, 0.29, 0.32, 0.5825760496238783, 0.22, 1.4901996269574993, -0.21, 0.62, -0.41, -0.23, -0.66, 0.96, 0.22, 0.18, -0.35, 0.88, 0.515957527023814, 0.15, -1.11, 0.33], ['208', -2.38, 0.11, -0.028778284379541254, 0.06, -0.82, 0.54, -0.21, 0.23, 0.57, 0.0, -0.62, 0.16, -0.42, -0.19, 0.41, 1.5, -0.38, -0.15, 2.98, 1.14, 0.14, 0.3, -0.06, -0.81, 0.69, 0.06, 0.63, 0.79, 0.21, 0.43, 1.04, 2.14, 0.24, 0.48, 3.62, 1.78, 0.77, 0.93, 0.56, -0.18, 0.42, 0.68, -0.16, -0.58, -0.36, 0.25, 1.34, -0.54, -0.31, 2.81, 0.98, -0.03, 0.14, -0.23, -0.97, 0.7400628463056765, 1.07, 0.68, 0.57, 0.42, 0.23, 0.83, 1.93, 0.04, 0.27, 3.41, 1.57, 0.56, 0.72, 0.36, -0.39, 0.54, 0.19, 0.6, 1.7, -0.19, 0.05, 3.18, 1.34, 0.33, 0.49, 0.13, -0.61, 0.74, 0.14, -0.17, -0.41, 1.09, -0.79, -0.55, 2.56, 0.73, -0.27, -0.11, -0.47, -1.21, -0.4, -1.48, -1.86, -1.63, 1.45, -0.36, -1.35, -1.19, -1.54, -2.28, 0.11, -1.49, -0.39, 0.38, 0.37, 0.37, 0.38, 0.23, 3.3701587301587304, 1.53, 0.52, 0.68, 0.32, -0.42, -0.19, 0.15, 3.13, 1.29, 0.29, 0.45, 0.08, -0.66, -0.22, -0.33, 0.1, 0.37, -1.2, 0.12, -0.03, -1.02, 0.94, 0.48, 0.21, -0.47, 2.23, -0.74, -0.38, -1.18, 0.33, 1.18, -1.29, -1.28, 0.37, -1.53, 0.76, -0.45, 0.19, 1.11, -3.54, -0.81, -1.18, -2.18, -2.89, -1.78, -2.76, -2.6, -2.95, -3.67, 1.23, -1.13, -0.99, -0.83, -1.19, -1.93, -0.14, 0.16, -0.2, -0.94, 0.6, 0.73, -0.3, -0.36, -1.0277512446849837, 0.4, 0.36, 0.17, -1.09, -0.11980037304250064, 1.17, 0.01, 0.37, 0.06, -0.74, 0.6, 0.23, 0.76, 0.1, 0.43, 0.895957527023814, 0.24, 0.11, 1.17], ['209', -2.49, -0.54, -0.16877828437954126, 0.17, -1.32, -1.11, -1.2, -2.51, -2.01, -1.55, 1.25, -0.12, 0.47, 1.35, 1.77, -0.91, -0.16, -1.06, -1.55, -0.36, -2.22, -0.52, -0.2, -0.71, -2.68, -1.72, -2.77, -1.36, -0.77, 0.1, 0.51, -2.13, -1.39, -2.28, -2.77, -1.59, -3.43, -1.75, -1.43, -1.94, -1.38, -3.0550638007838264, -1.43, 0.59, 1.47, 1.89, -0.78, -0.04, -0.94, -1.43, -0.24, -2.1, -0.4, -0.08, -0.59, -1.57, -2.3142857142857145, -2.26, -1.6, -2.01, 0.88, 1.3, -1.37, -0.63, -1.52, -2.01, -0.82, -2.68, -0.98, -0.66, -1.18, -3.04, -2.86, 0.8402278911564625, -2.22, -1.49, -2.37, -2.86, -1.68, -3.52, -1.84, -1.52, -2.03, -2.66, -3.37, 3.416, -3.27, -2.63, -1.9, -2.78, -3.27, -2.09, -3.92, -2.25, -1.93, -2.44, -2.19, -0.65, 0.75, -0.15, -0.65, 0.55, -1.33, 0.39, 0.71, 0.19, -0.73, -0.71, -1.6, -1.02, -1.02, -0.95, -1.4, -0.9, -1.3998412698412697, -0.2, -2.07, -0.36, -0.04, -0.55, -0.93, -0.5, -0.5, 0.7, -1.18, 0.54, 1.0957142857142856, 0.35, -1.4, -1.63, 0.0, -1.15, -6.82, -0.30774866403437834, -0.22, 1.61, -1.7, -0.86, -0.15, -2.73, 2.39, 2.04, 1.04, -1.25, -0.73, -3.05, 3.0, 2.97, -1.0, 2.49, -2.02, -3.06, 1.55, -4.12, 14.86, 2.84, 4.16, -2.27, 0.0, 1.21, -0.68, 1.05, 1.38, 0.85, -3.03, -1.2, -1.87, -0.16, 0.16, -0.36, 0.68, 1.74, 2.07, 1.54, -1.99, -2.12, -1.04, 0.33, -0.19, -0.99, -1.07, -2.46, 7.4, -1.53, -7.58, -2.2, -1.44, -1.36, -0.52, -1.18, -0.86, -0.66, -0.43, -0.47, -0.85, -3.67, -0.88, -0.75], ['210', 2.72, -0.11, 0.08122171562045875, 0.19, 0.17, -0.31, -0.45, 0.5217205965359587, -0.77, 0.05, 1.62, 0.15, 0.843913265120849, 0.43, -0.76, -0.51, 0.47, 0.35, 1.49, -0.77, -0.32, 0.7, 0.47, -0.5, 0.43, -0.93, -1.54, -1.44, -0.4123253968253967, -1.17, -2.33, -2.09, -1.13, -1.24, -0.12, -2.34, -1.9, -0.9, -1.13, -2.09, 0.75, -1.74, -0.1, 0.62, 0.28, -0.91, -0.66, 0.31, 0.2, 1.34, -0.92, -0.47, 0.54, 0.32, -0.66, 0.34, -0.24, 0.78, -0.82, -0.72, -0.34, -1.52, -1.28, -0.31, -0.42, 0.71, -1.53, -1.09, -0.08, -0.3, -1.27, 0.78, -0.38, -1.18, -0.94, 0.04, -0.08, 1.06, -1.19, -0.75, 0.27, 0.04, -0.93, -1.52, -1.08, 1.03, 0.81, 0.3380874332127649, 1.23, 1.12, 2.26, -0.01, 0.6052352330209474, 1.46, 1.24, 0.25, -1.33, 0.57, 0.99, 0.87, 2.01, -0.26, 0.19, 1.22, 0.99, 0.01, -0.28, 0.56, -1.25, -0.21, -0.52, 0.08, -0.42, -0.11, 1.02, -1.23, -0.78, 0.23, 0.0, -0.97, -0.66, -0.3, 1.13, -1.12, -0.67, 0.34, 0.12, -0.86, -0.7610416300368755, -0.78, 0.19, -0.43, -4.41, 0.1, -0.1, -0.95, 0.91, 0.48, -0.46, -0.07, -1.5894817511227284, 0.41, 0.22, 1.42, -0.41, -0.64, 0.63, 0.65, -0.21, -1.29, -0.4, -1.29, 0.64, -1.21, 4.18, 0.89, 1.21, 1.69, -1.42, -2.22, -1.78, -0.78, -1.01, -1.97, -0.6, 0.82, 0.45, 1.47, 1.25, 0.26, 0.37, 1.02, 0.79, -0.19, -0.82, -1.21, -0.5527253150925656, -0.23, -1.19, -0.27, -0.17560369872470916, 0.4, 2.35, 0.1, -2.21, -0.55, -0.61, -0.42, -0.97, -0.43, 0.15, -0.41, -0.99, -0.16, 0.56, -0.95, -1.07, -0.15], ['211', 0.75, -1.4, 0.07122171562045874, 0.11, -1.33, -0.49, -1.84, -1.6, -1.79, -2.88, -0.78, -1.42, -1.73, -1.4429761904761904, -1.11, -3.65, -1.77, -2.83, -2.3, -0.82, -3.32, -2.05, -1.91, -1.93, -1.82, -0.76, -2.0873416050068876, -0.64, -0.96, -0.68, -0.34, -2.89, -1.0, -2.07, -1.53, -0.04, -2.56, -1.28, -1.14, -1.16, -1.6, -3.58, -1.49, -0.32, -0.03, 0.31, -2.26, -0.36, -1.44, -0.89, 0.6, -1.93, -0.64, -0.5, -0.52, -0.7, -0.97, -1.39, -1.11, -1.17, 0.29, 0.7348467679404526, -1.95, -0.04, -1.12, -0.57, 0.93, -1.62, -0.32, -0.18, -0.2, -0.63, -1.45, 0.35, -2.23, -0.32, -1.4, -0.86, 0.64, -1.9, -0.61, -0.47, -0.48, -2.48, -2.52, 2.45, -1.789129077338006, -2.481912566787235, -0.66, -1.74, -1.2, 0.29, -2.23, -0.95, -0.81, -0.83, 1.95, 0.8, 1.95, 0.85, 1.4005714285714286, 2.94, 0.34, 1.66, 1.8, 1.79, -0.08, 0.83, -0.78, -0.71, -0.78, -0.84, -1.14, -0.9534006093113236, -0.54, 0.96, -1.58, -0.29, -0.15, -0.16, -0.9, -0.05, 0.55, 2.07, -0.5, 0.81, 0.95, 0.93, -1.21, -1.05, 0.21, -1.06, 5.74, -0.14, 0.0, 2.39, -2.42, -1.19, -1.47, -1.32, 4.290518248877271, 1.4, 0.7, 0.33, -0.25, -2.3285238095238094, 2.08, 2.08, -0.7, 3.64, -1.42, -1.45, 0.71, -3.48, 9.03, 2.37, 3.4, -4.09, -0.6, 1.51, -1.05, 0.25, 0.39, 0.38, -2.1, -2.08, -2.52, -1.24, -1.1, -1.12, 0.45, 1.31, 1.46, 1.44, -1.73, -1.8, -0.85, 0.14, 0.12, -0.71, -0.84, -1.45, 4.6, -1.08, -4.80347619047619, -1.34, -1.09, -0.99, -0.02, -0.85, -0.9, 0.38, -0.32, -0.58, -0.97, -1.36, -0.89, -0.46], ['212', 8.94, -0.21, -0.8687782843795413, 0.35, 0.51, -0.83, -1.305884742040171, -1.16, -0.81, 0.42, 0.520608843537415, 1.46, 1.09, 1.95, 1.02, -2.39, 1.89, 2.07, -0.84, -1.7974455782312924, 0.41, 1.2, 2.08, 1.74, -1.72, -0.79, -0.09, 0.95, 0.58, 1.43, 0.5, -2.88, 1.37, 1.55, -1.34, -2.63, -0.09, 0.69, 1.56, 1.23, -0.87, -0.85, -1.03, -0.37, 0.48, -0.44, -3.8, 0.42, 0.59, -2.27, -3.54, -1.03, -0.26, 0.61, 0.28, -0.89, -0.58, -0.93, -0.36, -0.5907547529341225, 0.9531047225355607, -0.07, -3.44, 0.79, 0.96, -1.91, -3.19, -0.67, 0.11, 0.98, 0.64, -1.44, -1.5, -0.91, -4.25, -0.06, 0.12, -2.73, -4.0, -1.5, -0.73, 0.13, -0.2, -0.68, -4.34, 4.4, -0.6, -3.37, 0.86, 1.04, -1.84, -3.12, -0.6, 0.18, 1.05, 0.72, 2.71, 2.87, 4.38, 4.56, 1.59, 0.26, 2.87, 3.68, 4.721108978323264, 4.23, -1.2, 2.94, -2.03, -1.04, -1.06, -1.04, -1.44, 0.18, -2.6698412698412697, -3.95, -1.44, -0.67, 0.19, -0.14, -0.59, -1.62, -2.84, -4.11, -1.62, -0.85, 0.01, -0.32, -1.8410416300368755, -1.88, 0.43, -1.2, 5.57, -0.2696768707482993, 0.29, 2.53, -2.358279874187437, -1.23, 0.54, -2.17, -4.91, 2.06, 1.09, 4.5, -0.48, -3.13, 3.19, 3.09, -1.04, 3.64, -2.02, -3.26, 1.62, -4.34, 7.93, 2.93, 4.24, 4.9, 1.26, -1.31, 1.26, 2.06, 2.94, 2.765761712843646, -3.17, 2.6, 2.6, 3.41, 4.3, 3.96, 0.0, 0.78, 1.66, 1.32, -0.75, -0.65, -0.78, 0.87, 0.53, -1.11, -0.9456036987247092, -1.13, 4.02, -1.9698003730425007, -3.9, -1.03, -1.0688174603174603, -1.63, -0.33, -1.14, -1.04, -0.51, -0.62, -1.01, -1.3, -2.14, -2.66, -1.2669832262926028], ['213', -2.57, 0.12, -0.08, -0.3, 0.6929790809910596, 0.24, -1.095884742040171, -0.7, -0.24, -0.81, -1.04, 0.07, 0.37, -0.5, -0.42, 0.08, -1.58, -0.83, -1.3, -2.33, -0.58, -1.86, -0.79, -1.29, -0.18, -0.19, 0.23, 1.12, 1.43, 0.54, 0.62, 1.13, -0.54, 0.21, -0.27, -1.31, 0.46, -0.83, 0.25, -0.25, -0.42, -0.9250638007838266, -0.88, 0.3, -0.58, -0.49, 0.01, -1.65, -0.91, -1.38, -2.4, -0.66, -1.93, -0.86, -1.36, -0.15, -0.63, -0.59, 0.06, -1.18, -0.87, -0.79, -0.29, -1.94, -1.21, -1.67, -2.7, -0.95, -2.22, -1.16, -1.66, -2.52, -0.31, 0.08, 0.59, -1.08, -0.33, -0.8, -1.84, -0.08, -1.36, -0.29, -0.79, 0.07, 0.08, -0.08, -0.39, 0.5, -1.16, -0.42, -0.89, -1.92, -0.16, -1.44, -0.37, -0.87, -1.36, -0.89, -1.65, -0.91, -1.38, -2.41, -0.66, -1.93, -0.87, -1.37, -0.48, -0.7906317967746538, 0.18572371188304004, 0.27, 0.22, 0.38, 0.8518094764861293, 0.75, 0.28, -0.77, 1.01, -0.28, 0.8, 0.29, 0.91, 0.03, -0.47, -1.51, 0.25, -1.03, 0.05, -0.46, 0.1, 0.53, 0.05603717887804044, 0.7, -3.75, -1.14, -0.29, -1.12, 1.1, 0.56, 0.39, -0.44, -3.12, -0.63, -0.3, -1.29, 0.41, 0.92, -0.93, -0.85, 0.27, -1.74, 0.55, 0.26, -0.4, 2.38, -2.66, -1.66, -2.29, 3.07, 0.8203786848072563, -1.04, 0.73, -0.56, 0.52, 0.17576171284364575, 0.8, 1.56, 1.79, 0.49, 1.58, 1.07, -0.23, -1.28, -0.21, -0.71, -0.13, 0.0, 1.07, 1.09, 0.58, 0.26, 0.32, -0.54, -1.3, -0.09, 1.49, 0.41189489941485546, 0.4, -0.02, -0.51, 0.12, 0.55, 0.12, 0.73, 0.23, 0.48, -0.45, 1.08, 0.24], ['214', 0.94, 0.16, 0.21122171562045874, 0.19, 0.47, 0.46, 0.7141152579598291, 0.88, 0.86, 0.77, -0.25, -0.72, 0.36, -0.86, -0.32, 0.21, -0.34, 0.62, 1.09, 0.09, 0.94, 0.69, 0.23, 0.29, 0.26, 0.83, 1.0526583949931125, -0.48, 0.6, -0.62, -0.022180028704908802, 0.46, -0.09, 0.87, 1.34, 0.34, 1.19, 0.94, 0.47, 0.54, 0.85, 1.8549361992161735, 1.5, 1.08, -0.14, 0.4, 0.94, 0.39, 1.35, 1.82, 0.82, 1.67, 1.42, 0.95, 1.02, 0.2, -0.15, 0.28, 0.36, 0.41, -1.21, -0.67, -0.15, -0.69, 0.26, 0.73, -0.26, 0.58, 0.34, -0.13, -0.06, 1.01, 1.64, 0.55, 1.08, 0.53, 1.5, 1.97, 0.96, 1.82, 1.57, 1.1, 1.17, 1.54, 1.01, -1.07, 1.09, 0.53, -0.01, 0.94, 1.42, 0.41, 1.27, 1.02, 0.55, 0.62, 2.81, 0.56, -0.54, 0.41, 0.88, -0.12, 0.73, 0.48, 0.02, 0.08, 0.17, 0.53, 0.12017700342548367, 0.5315981806829014, 0.5551790696343399, 0.565673518650032, 1.11, 0.96, 1.43, 0.43, 1.28, 1.03, 0.56, 0.63, -0.15, 0.15, 0.47, -0.52, 0.32, 0.07, -0.39, -0.33, 0.48, 0.33, 0.19, 0.73, 8.71, 0.09, 0.14, -2.03, 2.07, 1.01, -1.42, 1.81, -1.49, -1.03, -0.48, 0.5, 0.07, 1.42, -1.54, -1.4, 0.47, -3.0, 0.9898783572413152, -1.13, 0.54, 3.33, -5.69, -2.27, -3.28, 1.48, -0.32, -0.99, -0.15, -0.4, -0.86, -0.79, 1.42, 0.68, 0.85, 0.6, 0.14, 0.2, -0.17, -0.25, -0.71, -0.64, 0.89, 0.86, 0.07, -0.46, -0.4, 0.5, 0.53, 0.88, -2.63, 0.52, 2.54, 1.3872638105244333, 0.5, 0.54, 0.07, 0.38, 1.0, 0.22, -0.2, 0.03, 0.47, 3.34, 1.61, 0.83], ['215', 0.8, 0.12, 0.05122171562045875, 0.13, 1.12, -0.34, -0.62, -0.27, -0.03, -0.76, -0.96, -0.59, -1.23, -0.48, -0.25, -1.04, -0.56, -0.67, 1.79, -1.54, -0.49, -0.99, -0.3556947683993239, -0.25, 0.18, 0.21937141458889198, 0.2, 0.37, -0.28, 0.48, 0.7678199712950912, -0.08, 0.41, 0.29, 2.77, -0.59, 0.47, -0.04, 0.51, 0.71, -0.42, -0.37506380078382656, -0.16, -0.64, 0.11, 0.34, -0.45, 0.04, -0.08, 2.39, -0.5203333333333333, 0.1, -0.4, 0.14, 0.34, 0.28, -0.16, -1.09, 0.13, 0.5592452470658775, 0.76, 1.0, 0.2, 0.69, 0.57, 3.06, -0.31, 0.75, 0.24, 0.79, 0.99, -0.38, -0.27, 0.23, -0.56, -0.07, -0.18, 2.28, -1.06, -0.01, -0.51, 0.03, 0.23, 0.04, -0.48, 0.45, -0.51, -0.79, -0.31, -0.42, 2.04, -1.29, -0.2261298384155527, -0.74, -0.2, 0.0, 0.04, 0.28, 0.49, 0.37, 2.885904761904762, -0.51, 0.55, 0.04, 0.59, 0.79, -0.19, 0.27, 0.0, -0.13, -0.18, -0.14, -0.1990429599640126, -0.11, 2.36, -0.99, 0.06, -0.44, 0.11, 0.31, 0.26, -0.09, 2.47, -0.88, 0.17, -0.33, 0.22, 0.42, -0.27, -0.25, 0.32, -0.38, 0.0, 0.28, 0.2, 0.18, -0.21, -0.11, 0.76, 0.46, -1.58, 0.26, 0.1, 0.42, -0.39, -0.44, 0.47, 0.46, -0.15, 0.06, -0.26, -1.83, 0.9647652642842468, -0.59, -5.25, 0.36, 0.61, 1.69, -2.5, -3.27, -2.24, -2.73, -2.2, -2.0, -0.45, 0.8, 1.06, 0.55, 1.1, 1.31, -0.26, -0.5, 0.04, 0.24, 0.03, 0.12, 0.24, 0.55, 0.75, -0.16, -0.16, -0.19, -1.71, -0.69, 1.75, -0.12273618947556672, 0.7310935020800124, -0.31, 0.2, -0.56, 0.04, -0.3047020479520478, -0.35, 0.08, -0.5, -0.94, 1.1730376647162362, -0.54], ['216', -5.56, 0.22, -0.36877828437954124, 0.07, -0.38, 0.26, 1.25, -0.32, 0.27, 1.76, 2.15, 1.0, 2.03, 1.88, 2.03, 3.81, 1.46, 1.84, 0.56, 1.85, 1.51, 1.22, 1.12, 1.3921746031746032, -1.1, -0.96, -0.38, -1.13, -0.12, -0.27, -0.12, 1.63, -0.68, -0.31, -1.56, -0.29, -0.63, -0.91, -1.01, -0.74, 0.49, 0.52, 0.75, 1.02, 0.86, 1.02, 2.78, 0.46, 0.83, -0.44, 0.84, 0.5, 0.22, 0.12, 0.39, -1.1, -0.61, -0.43, 0.21, -0.26, -0.15, 0.0, 1.75, -0.56, -0.19, -1.44, -0.17, -0.51, -0.79, -0.89, -0.63, -0.66, -0.11, 0.15, 1.9, -0.41, -0.04, -1.29, -0.02, -0.36, -0.64, -0.74, -0.47, 0.0, 1.7, -1.3344319727891159, -0.26, 1.75, -0.56, -0.19, -1.44, -0.17, -0.51, -0.79, -0.89, -0.63, -3.34, -1.97, -2.26, -1.9, -3.13, -1.89, -2.22, -2.5, -2.59, -2.33, 0.02, -1.99, 0.31, 0.28, 0.42, 0.22, 0.3, 0.37, -0.89, 0.3905357142857143, 0.04, -0.24, -0.34, -0.07, 0.39, -0.07, -1.25, 0.02, -0.32, -0.6, -0.7, -0.44, 0.57, 0.46, 0.27, 0.34, -10.1, -0.1, -0.68, 0.38, -0.3, -0.19, -0.4, -1.28, 0.1, -0.57, -0.28, -2.86, 0.4, 0.84, -0.87, -0.95, 0.28, 0.62, 0.57, -1.14, 0.59, 0.92, 1.7127091836734694, -0.67, -0.97, -0.14, 1.19, 1.29, 0.94, 0.66, 0.55, 0.83, 0.85, -0.09, -0.34, -0.62, -0.72, -0.45, 0.25, -0.27711507143650005, -0.38, -0.12, 0.19, 0.23, 0.53, -0.1, 0.17, 0.3, 0.3, -0.37, 1.16, 0.44, -1.22, 0.37, -0.49, 0.64, 0.34278685149693167, 0.23, -0.13, 0.77, 0.91, 0.53, 0.37, -1.12, -0.28, 0.75], ['217', 5.23, 0.0, 0.05122171562045875, 0.17, 1.0, 0.28, -0.08, 0.68, 0.51, 1.11, 0.07, 1.31, 0.84, 0.69, 1.16, -0.21, 0.86, 1.37, -0.01, -0.32, 1.61, 0.44, 0.37, 1.19, 1.27, 0.78, 1.04, 1.24, 0.78, 0.63, 1.1, -0.28, 0.79, 1.3, -0.08, -0.39, 1.55, 0.37, 0.3, 1.12, -0.3125315746467892, 0.22, -0.2, -0.46, -0.61, -0.15, -1.5, -0.45, 0.05, -1.31, -1.61, 0.3, -0.87, -0.93, -0.12, 0.91, 1.27, 0.987827972809784, 0.52, 0.33924524706587755, -0.15, 0.32, -1.04, 0.01, 0.52, -0.85, -1.15, 0.76, -0.4, -0.47, 0.34, 0.58, 0.41, 0.47, -0.9, 0.16, 0.67, -0.7, -1.01, 0.91, -0.26, -0.32, 0.49, 0.54, 1.83, -1.86, -0.05, -1.36, -0.3, 0.2, -1.16, -1.47, 0.44, -0.72, -0.79, 0.0740077275244506, 2.32, 1.32, 1.07, 1.58, 0.2, -0.11, 1.83, 0.65, 0.58, 1.4, -0.12, 1.37, -1.75, 0.24, -0.13, -0.2, 0.25, 0.5, -0.86, -1.17, 0.75, -0.42, -0.48, 0.33, 0.54, -0.25, -1.36, -1.66, 0.25, -0.92, -0.98, -0.17, -0.25, -0.46, 0.3, 0.32, 6.91, 0.18, 0.07, 0.39, -0.32, -0.18, 0.29, 1.51, -2.75, -0.49, -0.23, 2.55, 0.03, 0.75, -0.81, -0.64, 0.26, 0.54, 0.52, -1.88, 0.95, 1.64, -25.189348639455783, -1.12, -1.69, 2.72, 1.12, -0.31, 1.63, 0.45, 0.38, 1.2, 0.74, 1.43, 1.94, 0.76, 0.69, 1.51, -0.5, -1.1571150714365, -1.23, -0.42, 0.5, 0.72, 0.67, -0.07, 0.75, 0.3, 0.25, 0.66, -5.82, -1.29, 5.91, 0.89, 1.2, 0.74, 0.82, 0.13, -0.17, 0.12, 0.0, 0.16, -0.08, 1.83, 1.96, -0.25], ['218', -0.88, 0.11, -0.21, 0.25, 0.44, 0.24, 1.2441152579598291, 0.05, 0.36, 2.45, 2.6, 1.85, 1.49, 1.83, 2.73, 2.22, 1.63, 2.2, 4.2, 1.97, 1.99, 1.55, 0.25, 1.25, 1.61, -0.44, -0.15, -0.73, -1.09, -0.76, 0.13, -0.38, -0.95, -0.2727410958555916, 1.56, -0.61, -0.6, -1.02, -2.29, -1.32, -0.62, 0.71, 0.58, -0.36, -0.03, 0.86, 0.35, -0.22, 0.34, 2.3, 0.11, 0.13, -0.3, -1.58, -0.6, -0.22, -0.34, -0.94, 0.12, 0.95, 0.44310472253556066, 1.3348467679404525, 0.72, 0.14, 0.8026050661400617, 2.68, 0.48, 0.49, 0.38746485260770963, -1.22, -0.23, 0.05, 0.61, 0.89, 0.38, -0.19, 0.37, 2.33, 0.14, 0.16, -0.04285714285714287, -1.55, -0.57, 0.17, 5.63, -5.62, -0.27, -0.4119125667872351, -1.07, -0.52, 1.43, -0.74, -0.72, -1.15, -2.3890238095238097, -1.44, -2.62, 0.23, -0.57, -0.01, 1.94, -0.24, -0.22, -0.65, -1.93, -0.95, 0.781141873999017, 0.2, 0.77, 0.44, 0.75, 0.19, 0.81, 0.56, 2.53, 0.34, 0.35, -0.08, -1.36, -0.38, 1.0165360710717855, 0.24, 1.96, -0.22, -0.21, -0.64, -1.91, -0.93, 2.1789583699631248, 1.59, 0.62, 0.83, -8.17, 0.43, 0.29, -0.34, 0.36, 0.17, 0.78, -0.96, -0.93, -0.87, -0.44, -0.35, -0.44, 1.38, -1.61, -1.37, 0.42, -0.47, 0.88, -2.23, 1.12, 2.39, -3.4, -1.63, -2.41, 0.83, -1.3596213151927437, -2.14, -2.13, -2.54, -3.8, -2.83, 1.32, 0.47, 0.02, -0.41, -1.69, -0.71, 0.45, -0.43, -1.71, -0.72, 0.7601351386708531, 0.11, 0.89, -1.28, -0.3, 0.43, 0.47, 0.05, -1.62, 1.57, 1.88, -0.35, 0.4, 2.2, 1.0, 0.21, 0.32, -0.11, -0.8, -0.64, 1.19, 0.24, 1.24, 1.48], ['219', -5.8, -0.09, -0.07, 0.02, -1.32, -0.37, -0.5258847420401709, -1.6082794034640413, -1.17, -1.37, -0.03, -0.54, -1.096086734879151, 0.2, 0.58, -0.47, -0.5, -1.14, -1.08, 0.77, -1.55, -1.22, -1.99, -1.53, -2.02, -0.770628585411108, -1.3173416050068876, -0.51, -1.14, 0.23, 0.61, -0.44, -0.47, -1.11, -1.05, 0.8, -1.53, -1.19, -1.97, -1.5, -1.77, -1.36, -0.84, -0.63, 0.74, 1.13, 0.07, 0.04, -0.6, -0.54, 1.32, -0.9919345319135571, -0.68, -1.4257142857142857, -0.99, -1.24, -1.32, -1.62, -1.3, -0.21, 1.4831047225355605, 1.77, 0.7, 0.67, 0.02, 0.08, 1.96, -0.39, -0.06, -0.84, -0.37, -1.5063939988582844, -1.57, 0.39, -0.67, -0.7, -1.34, -1.276904761904762, 0.57, -1.75, -1.42, -2.19, -1.73, -1.05, 1.13, -1.1, -1.95, -1.05, -1.08, -1.72, -1.66, 0.19, -2.13, -1.79, -2.56, -2.1, 0.73, -0.91, -0.03, -0.68, -0.61, 1.25, -1.09, -0.75, -1.53, -1.07, -0.04, -0.97, -1.19, -0.32, -0.17, -0.44432648134996805, -0.88, -0.64, -0.58, 1.28, -1.06, -0.72, -1.5, -1.03, -0.26, -0.24, 0.06, 1.94, -0.42, -0.08, -0.86, -0.39, 0.04, -0.45, -0.28, -0.73, 1.83, -0.07, -0.02, 0.25, -0.19, -0.1, 0.14, -2.44, 4.25, 0.66, 0.3, -2.94, 0.13307978986877905, -1.04, 1.09, 0.89, -0.32, 0.36, -0.65, 0.14, -0.1, -2.64, 0.32, 1.74, 2.57, -4.29, -0.3, 1.87, -0.48, -0.14, -0.92, -0.45, -0.94, -2.13, -2.31, -1.98, -2.75, -2.28, 0.18, 0.34, -0.45, 0.02, -1.16, -1.14, -0.16, -0.78, -0.31, -0.28, -0.4, -1.54, -1.19, -0.93, 1.14, -0.62, -1.73, 0.63, 0.47, -1.13, -0.33, -0.03, 0.2, -0.35, 0.16, -1.85, -2.62, 0.64], ['220', -3.78, -0.47, 0.2, -0.1, -0.18, 0.21, 2.49, -0.54, 0.29, -1.87, -2.44, -2.88, -1.83, -1.27, -1.85, -0.82, -1.9, -1.87, 0.64, -2.1, -1.9, -1.79, -2.16, -2.38, -0.36, -0.27, 0.58, -0.44, 0.62, 1.21, 0.61, 1.67, 0.56, 0.58, 3.16, 0.35, 0.56, 0.67, 0.29, 0.10384172319783916, 0.74, -0.14, 1.03, 1.07, 1.66, 1.06, 2.12, 1.01, 1.03, 3.62, 0.8, 1.01, 1.12, 0.74, 0.51, -0.07, 0.37, -1.0, 0.0, -0.04, 0.58, -0.02, 1.04, -0.06, -0.04, 2.52, -0.27, -0.06, 0.05, -0.33, -0.56, -1.18, -0.62, -0.59, 0.45, -0.64, -0.62, 1.93, -0.85, -0.64, -0.53, -0.9, -1.13, 0.38, 0.66, -0.63, -0.02, 1.05, -0.05, -0.02, 2.54, -0.25, -0.05, 0.06, -0.31, -0.54, -2.75, -1.07, -1.09, -1.07, 1.47, -1.29, -1.09, -0.98, -1.35, -1.58, 0.07, -1.04, 0.13, -0.16, 0.27, -0.48, 0.02, 0.02, 2.59, -0.21, 0.0, 0.11, -0.27, -0.49, -0.03, 0.0, 2.56, -0.23, -0.02, 0.09, -0.29, -0.52, 0.12, -0.2, -0.01, 0.17, -8.24, -0.15, -0.13, 2.81, -2.93, -1.44, -0.47, 0.24616353211204947, -0.49, 0.31, 0.16, -1.89, 0.14, -0.48, 0.35, 0.49, -0.09670919513614704, 4.31, -0.27, 0.37, -0.19, 0.04, 9.6, -0.09, -0.11, 0.6, -2.5, -2.72, -2.52, -2.41, -2.78, -3.0, -0.44, 0.23, 0.21, 0.32, -0.06, -0.29, 0.02, 0.11, -0.27, -0.49, 0.35, 0.25, -0.09, -0.38, -0.6, -0.15, -0.09, -0.49, 5.3, 0.49, -5.46, 0.07, 0.13, 0.29, -0.15721314850306833, 0.35, -1.75, 0.11, 0.27, 0.49, 0.605957527023814, -2.17, -0.59, 0.69], ['221', -2.36, 0.45, 0.16, 0.02, -0.79, 0.2384196236737595, -1.19, -0.26, 0.34, 0.45, -0.13, 0.91, 0.43, 0.39, 1.81, 1.15, 0.31, 0.33, 1.82, -0.33, 0.8, 0.25, 0.5, 0.33, -0.3, 0.28, 0.58, 1.04, 0.56, 0.52, 1.94, 1.28, 0.44, 0.45, 1.95, -0.2, 0.9307606837606838, 0.38, 0.63, 0.46, 0.35, 0.6, -0.46, -0.48, -0.52, 0.89, 0.24, -0.6, -0.58, 0.9, -1.23, -0.11, -0.66, -0.41, -0.57, 0.47, 0.17, -0.22, 0.66, 0.01, -0.04, 1.37, 0.71, -0.12, -0.11, 1.38, -0.76, 0.37, -0.18, 0.07, -0.1, -0.54, 0.06, 1.41, 0.76, -0.08, -0.07, 1.42, -0.72, 0.41, -0.14, 0.11, -0.06, 0.77, 0.01, 0.0, -1.339129077338006, -0.65, -1.47, -1.46, 0.01, -2.1, -0.99, -1.53, -1.28, -1.45, -0.74, -0.7, -0.83, -0.82, 0.66, -1.47, -0.34, -0.89, -0.64, -0.81, 0.05, -0.64, -0.8398953488372093, 0.19, 0.22, 0.27, 0.14, 0.02, 1.51, -0.64, 0.49, -0.06, 0.19, 0.02, 0.21, 0.17307674813036728, 1.49, -0.65, 0.48956235827664396, -0.07, 0.18, 0.01, -0.32, -0.16, -0.11, 0.38, -2.29, 0.31, 0.2, -0.08, 0.1, 0.04, 0.24, 0.47, -1.67, -0.39, -0.2, -1.23, 0.48, 0.62, -0.64, -0.57, 0.2, -0.12, 0.4, 0.48, -0.24, 0.44, 0.57, -0.25, -0.43, 1.64, -1.35, -2.11, -1.0, -1.54, -1.29, -1.46, 0.64, 0.78, 1.14, 0.59, 0.84, 0.67, -0.35, -0.55, -0.3, -0.47, 0.5901351386708531, 0.86, 0.19, 0.25, 0.08, 0.22, 0.2, -0.23, 0.25, -0.5088836208193301, -0.3, 0.28, 0.29, -0.06, -0.17, 0.31, 0.07, 0.2, 0.69, 0.59, 0.11, -0.93, -0.02, 0.13], ['222', 2.92, 0.01, -0.07877828437954125, 0.07, -0.1170209190089404, 0.5, 0.36411525795982913, -0.82, -0.63, -0.84, -0.15939115646258506, -1.4, -0.68, 0.12, 0.97, -1.78, -1.34, -0.72, 1.72, -0.66, -1.39, -1.61, -0.29, -0.404883372579801, -0.58, -0.19, -0.67, -1.23, -0.51, 0.3, 1.14, -1.61, -1.17, -0.54, 1.89, -0.48, -1.22, -1.44, -0.12, -0.38, -0.8, -3.02, 0.769303232481804, 0.73, 1.54, 2.4, -0.38, 0.06, 0.69, 3.16, 0.76, 0.01, -0.21, 1.12, 0.86, -0.2, -0.87, -0.13, 0.14291666666666658, -0.16, 0.81, 1.66, -1.1, -0.67, -0.03, 2.41, 0.03, -0.72, -0.93, 0.39, 0.13, 0.53, -0.96, 0.85, -1.9, -1.46, -0.84, 1.59, -0.78, -1.52, -1.73, -0.41, -0.67, -1.24, -0.95, 0.9, -1.79, -2.72, -2.29, -1.67, 0.74, -1.416255228898086, -2.34, -2.55, -1.25, -1.51, 1.66, 0.96, 0.44, 1.08, 3.56, 1.14, 0.39, 0.18, 1.6511089783232642, 1.25, 0.05, 0.98, -0.23, 0.12, -0.16, 0.47, 0.51, 0.64, 3.1, 0.7, -0.05, -0.19969498055271245, 1.07, 0.81, 0.68, -0.12, 2.45, 0.06, -0.68, -0.9, 0.43, 0.17, -0.54, 0.47, 0.06, 0.69, 3.31, -0.13, -0.15, -0.6, 0.6, 0.32, 0.82, -0.82, 0.36, -0.25, -0.12, 1.53, 0.37, 0.58, -0.51, -0.4, 0.13, -1.07, 0.26, -0.84, 0.38, 1.49, 2.87, -1.02, -1.43, -0.37, -2.51, -2.33, -3.06, -3.27, -1.97, -2.23, 0.32, -0.045645766931481174, -0.74, -0.96, 0.37, 0.11, 0.56, -0.21, 1.12, 0.86, -0.55, -0.95, 0.78, 1.33, 1.07, 0.14, 0.17, -0.57, 1.33, -0.05, -0.7707193877551022, 0.48, -0.3688174603174603, -0.55, -0.26, 0.61, 0.38, 0.64, 0.09, 0.33, -0.29, -0.09, -0.46, 0.33], ['223', 4.64, -0.4, -0.18877828437954128, -0.12, -0.66, -0.97, -1.2558847420401709, -1.24, -1.68, -0.68, 1.24, 0.55, 0.2, 0.45, -0.22, -1.23, 0.74, -0.31, -0.6, 0.91, -1.09, 0.1, 0.95, 0.54, -1.13, -1.38, -1.9, -0.69, -1.03, -0.78, -1.44, -2.44, -0.49, -1.53, -1.82, -0.33, -2.235546329921431, -1.12, -0.29, -0.6461582768021608, -0.5, -3.18, -1.22, -0.35, -0.09, -0.76, -1.77, 0.2, -0.85, -1.14, 0.3607142857142857, -1.601934531913557, -0.44, 0.4, 0.0, -2.69, -1.17, -1.39, -1.37, -0.88, 0.26, -0.42, -1.43, 0.55, -0.5, -0.79, 0.71, -1.29, -0.09, 0.75, 0.34, -1.8863939988582845, -1.13, -0.67, -1.68, 0.29, -0.76, -1.05, 0.45, -1.54, -0.35, 0.49, 0.1435596417251207, -2.18, -4.47, 4.58, -0.46, -1.01, 0.97, -0.09, -0.38, 1.13, -0.88, 0.32, 1.17, 0.77, 1.48, 0.56, 2.0, 0.94, 0.64, 2.17, 0.14, 1.35, 2.21, 1.8, -0.35, 0.55, -1.6042762881169599, -1.04, -1.19, -0.96, -1.41, -1.04, -1.33, 0.16, -1.83, -0.64, 0.2, -0.2, -0.9, -0.37, -0.29, 1.22, -0.79, 0.41, 1.26, 0.85, -1.74, -1.32, -0.46, -1.29, 2.95, -0.53, -0.35, 1.76, -1.77, -0.9, -1.29, -2.04, 3.1, 2.03, 1.03, 2.41, -0.56, -3.2, 3.18, 3.02, -1.03, 2.63, -2.03, 1.86, -0.97, -4.21, 5.55, 2.88, 4.23, -3.06, -0.08, 1.51, -0.5, 0.7, 1.56, 1.15, -3.05, -1.57, -1.99, -0.8, 0.04, -0.36, 0.42, 1.21, 2.07, 1.66, -1.76, -2.25, -0.78, 0.85, 0.44, -1.0, -1.0456036987247093, -1.3, 2.94, -1.49, -2.98, -1.34, -0.44, -1.62, -0.4, -1.23, -0.69, -0.8, -0.93, -1.14, -1.22, 0.29, -0.76, -0.98], ['224', 2.98, 0.06, 0.011221715620458745, -0.29, 0.6, 1.0684196236737595, 0.97, 0.93, 0.93, 0.25, -1.36, 0.1, -1.17, -0.7, -0.94, -0.06, -0.9, 0.48, 1.15, 0.02, 0.43, -0.51, -1.31, -0.39, 1.0, 0.66, 1.63, 1.48, 0.2, 0.68, 0.4878199712950912, 1.32, 0.47, 1.87, 2.55, 1.4, 1.82, 0.87, 0.05, 0.99, 0.35, 0.7849361992161734, 0.34930323248180406, -1.26, -0.79, -1.03, -0.16, -1.0, 0.39, 1.06, -0.08, 0.34, -0.61, -1.41, -0.48, 0.21, 0.65, 0.67, 0.27, 1.43, 0.48, 0.23, 1.12, 0.27, 1.67, 2.35, 1.2, 1.62, 0.7296581632653062, 0.015338978481835797, 0.8141848072562359, 0.3736060011417156, 0.95, -0.24, 0.64, -0.21, 1.19, 1.86, 0.72, 1.14, 0.19, -0.62, 0.31, 1.7, 4.05, -3.99, 1.2, 0.89, 0.04, 1.43, 2.11, 0.97, 1.38, 0.43, -0.38, 0.56, 1.45, 0.31, -0.84, 0.54, 1.21, 0.08, 0.49, -0.45, -1.26, -0.33, -0.1, 0.31, 0.04, 1.05, 0.99, 1.09, 1.16, 1.4, 2.08, 0.93, 1.35, 0.4, -0.41, 0.52, 0.73, -0.23, 0.67, -0.36775528629437304, -0.05, -0.99, -1.79, -0.87, 1.33, 1.24, -0.25, 0.87, 4.38, -0.2, 0.07, -2.51, 2.51, 1.28, 0.37, 1.1, -0.45, -2.07, -1.05, 1.53, 0.72, 3.17, -3.12, -3.13, 1.03, -3.88, 2.07, 1.33, -0.91, 3.47, -9.74, -2.29, -3.5, 0.43, -0.5796213151927438, -1.12, -0.5127867132867132, -1.64, -2.44, -1.52, 3.15, 0.23, 0.41, -0.53, -1.33, -0.41, -0.19, -0.8511214088935782, -1.74, -0.82, 0.98, 1.3184535464535465, 0.76, -0.81, 0.12, 1.05, 1.04, 0.92, -6.14, 0.6603332627840632, 6.15, 1.2, 0.96, 1.58, 1.0127868514969316, 1.0, 1.36, 0.7, 0.33, 0.91, 0.64, 1.58, 1.13, 0.22], ['225', 5.29, 0.13, -0.05, -0.22, 1.34, 0.28, -3.59, 1.08, 0.3, 0.68, -0.09, 3.1, 2.07, 0.07, -0.49, -1.25, 0.84, 1.72, 0.77, -1.05, 1.62, 0.34, 1.52, 0.97, 2.17, 0.72, 0.77, 3.2001785714285718, 2.16, 0.16, -0.4, -1.16, 0.94, 1.81, 0.87, -0.96, 1.71, 0.43, 1.62, 1.06, 0.61, 1.45, -2.35, -1.0, -2.94, -3.4191849704247237, -4.22, -2.19, -1.34, -2.26, -4.03, -1.44, -2.68, -1.53, -2.07, 1.44, 1.4, 1.25, 0.93, -1.36, -1.96, -2.51, -3.25, -1.2, -0.34, -1.27, -3.0497619047619047, -0.44, -1.69, -0.53, -1.08, 1.77, 0.61, -0.56, -1.32, 0.77, 1.65, 0.7, -1.12, 1.55, 0.27, 1.45, 0.9, 0.86, -2.4, 2.36, 1.18, -0.76, 1.35, 2.23, 1.28, -0.56, 2.12, 0.84, 2.03, 1.47, 2.44, 1.96, 2.12, 3.01, 2.05, 0.21, 2.91, 1.61, 2.81, 2.25, -0.79, 2.04, -2.01, -0.06, -0.09, -0.18432648134996804, -0.16, 0.87, -0.07, -1.88, 0.77, -0.5, 0.67, 0.12, 0.06, -1.02, -0.6763144197072768, -2.72, -0.1, -1.36, -0.19, -0.74, -1.23, -0.79, -0.49, -0.86, 7.8, -1.34, -1.09, 1.09, -1.13, -0.56, -1.49, 1.7, -3.53, 0.07, 0.0, 2.67, 0.38307978986877905, -0.18, 0.19, 0.17, -0.05, 1.55, -0.15, -0.73, 0.13, -0.45, 5.91, 0.28, 0.41, 3.47, -0.09, -1.81, 0.84, -0.38270294784580494, 0.74, 0.19, -0.17, 1.75, 2.69, 1.4, 2.6, 2.04, -0.8555102040816327, -1.26, -0.09, -0.64, 0.43, 0.86, 0.34, 1.3732337781266353, 0.63, -0.05, -0.22, 0.92, 3.28, -1.94, -3.16, -0.27, 0.31, -0.83, -0.4772131485030684, -0.21, -0.13, 0.52, 0.75, 0.2, -0.29, 0.07, 0.22, -0.49], ['226', -0.34, 0.33, 0.25, 0.03, 0.47, 0.46, 0.73, 0.88, 1.04, 0.11, -1.37, 0.0019344980416409752, -1.11, -1.19, -1.0, 0.11, -0.7, -0.12, -0.8, -0.78, 0.7, -1.38, 0.47, -0.33, 0.68, 0.46, 1.5326583949931125, 1.19, 0.26, 0.18, 0.38, 1.51, 0.68, 1.27, 0.58, 0.6, 2.1, 0.0, 1.87, 1.06, 0.51, 1.7549361992161734, 0.31, -0.91, -0.99, -0.79, 0.32, -0.19134863945578234, 0.08, -0.6, -0.58, 0.9, -1.18, 0.7042857142857143, -0.13, 0.55, 0.62, -0.7, 0.87, 1.23, -0.08, 0.12, 1.24, 0.41, 1.0, 0.32, 0.33, 1.83, -0.27, 1.6, 0.79, -0.38, 1.32, 0.2, 1.32, 0.5, 1.08, 0.4, 0.41, 1.92, -0.19, 1.68, 0.87, 1.45, -0.35, 0.19, 1.11, 1.12, 0.29, 0.88, 0.2, 0.21, 1.71, -0.38, 1.48, 0.67, -0.56, -0.01, -0.81, -0.24, -0.9084761904761905, -0.9, 0.59, -1.49, 0.36, -0.44, 0.2, 0.0, 2.12, 0.37, 0.34, 0.38, 0.82, 0.58, -0.1, -0.08, 1.41, -0.68, 1.18, 0.38, 1.33, 0.23, -0.68, -0.66, 0.82, -1.25, 0.59, -0.21, 0.26, 1.06, 0.03, 0.58, -1.82, 0.2980695494981211, 0.05, -0.22, 0.23, 0.11, 0.37, 1.47, -1.83, -0.77, -0.36, -0.16, 0.86, 1.0, -1.04, -1.04, 0.38, -0.35, 0.72, 0.09, -0.08, 2.41, -4.61, -1.63, -2.41, 1.7, 0.91, 0.01, 1.51, -0.58, 1.28, 0.47, 1.2, 0.9, 1.5, -0.6, 1.26, 0.46, -0.59, -2.06, -0.23, -1.02, 0.98, 1.25, 1.5, 1.87, 1.06, 0.4, 0.42, 0.91, -2.89, 0.19, 3.04, 0.27, 0.07, -0.36, -0.7172131485030684, 0.96, 0.14, 0.99, 1.07, 0.59, 0.525957527023814, -0.93, -0.49, 0.2], ['227', -1.11, 0.46, 0.41, -0.14, 0.46, 0.98, 1.48, 1.4, 1.63, 1.19, -0.97, -0.15, 0.31, 0.61, -0.15, 1.21, -0.08, 0.5, 2.4, -0.59, 1.28, 0.06, -0.73, -0.43, 1.55, 1.29, 2.18, 0.8301785714285714, 1.29, 1.59, 0.83, 2.2, 0.9, 1.48, 3.41, 0.39, 2.28, 1.04, 0.24, 0.5838417231978392, 0.71, 2.96, 1.5493032324818041, 0.46, 0.76, 0.0, 1.37, 0.08, 0.65, 2.56, -0.44, 1.44, 0.21, -0.58, -0.28, 1.26, 0.8, 2.02, 1.96, 0.88, 0.3, -0.45, 0.9, -0.38, 0.19, 2.09, -0.89, 0.97, -0.25, -1.04, -0.74, 1.44, 0.58, -0.7353571428571428, 0.6, -0.68, -0.11, 1.78, -1.19, 0.67, -0.55, -1.33, -1.03, 1.94, 5.12, -5.07, 1.34, 1.36, 0.07, 0.65, 2.55, -0.44, 1.43, 0.2, -0.58, -0.29, -0.91, -0.02, -1.27, -0.71, 1.18, -1.78, 0.07, -1.14, -1.92, -1.62, 0.64, -0.05, 3.98572371188304, 1.08, 1.19, 1.065673518650032, 1.27, 0.57, 2.48, -0.51, 1.36, 0.13, -0.65, -0.36, 1.17, 0.69, 1.9, -1.08, 0.78, -0.44, -1.22, -0.92, 2.13, 1.89, -0.2, 1.23, -2.63, 0.29, 0.42, -1.43, 1.4224623233908948, 0.7688101710076211, 0.79, 2.12, -3.58, -2.08, -1.05, -0.54, 0.5, 3.3, -3.25, -3.19, 1.123290804863853, -2.27, 2.15, 1.82, -0.91, 3.69, -5.48, -2.58, -3.76, 3.62, -1.18, -2.92, -1.09, -2.29, -3.023374458874459, -2.77, 3.13, 1.79, 1.88, 0.65, -0.14, 0.16, -0.09, -1.21, -1.99, -1.7, 1.59, 2.05, 1.14, -0.79, -0.49, 1.08, 1.11, 1.4, -4.19, 3.1711163791806696, 4.37, 1.4618948994148555, 0.54, 1.94, 0.3, 1.54, 0.85, 0.48, 0.2, 0.6, 1.63, 1.56, -0.06, 1.68], ['228', 2.85, -1.09, -0.10877828437954125, 0.03, -0.23, 0.54, -0.46, 0.31, 0.62, 0.08, -1.36, 0.4, -0.18, -0.26, -0.46, -1.37, -0.6, -0.14, 3.72, -0.07, 0.84, 0.46, -1.33, -0.27, 0.64, 0.6, 1.4926583949931125, 1.78, 1.19, 1.11, 0.91, -0.02, 0.77, 1.24, 5.14, 1.31, 2.23, 1.84, 0.03, 1.1, -0.57, 1.4949361992161734, -0.31, -0.58, -0.66, -0.86, -1.76, -0.99, -0.53, 3.31, -0.46, 0.44, 0.06, -1.72, -0.66, 0.09, 0.29, -0.14, 0.84, 0.27, -0.08, -0.28, -1.19, -0.41, 0.05, 3.91, 0.12, 1.02, 0.64, -1.091735383663955, -0.08, 1.16, 0.34, -0.2, -1.12, -0.34, 0.12, 3.99, 0.19, 1.1, 0.72, -1.07, -0.01, 1.3, 3.62, -3.66, 0.55, -0.92, 0.2999013605442177, 0.33, 4.2, 0.4016746031746032, 1.31, 0.92, -0.8390238095238095, 0.19, 4.84, 1.48, 0.79, 1.25, 5.16, 1.32, 2.24, 1.86, 0.04, 1.12, 0.33, 1.44, 0.49, 0.69, 0.83517906963434, 0.61, 0.68, 0.46, 4.34, 0.53, 1.44, 1.1203050194472877, -0.74, 0.33, -0.37, 0.22, 3.86, 0.16224471370562701, 0.97, 0.59, -1.19, -0.13, 1.56, 1.19, 0.11, 0.76, 14.887738095238095, 0.25, 0.07, -1.86, 1.79, 0.91, 0.36, 0.72, -0.36, -1.35, -0.72, 1.41, 0.57, 2.06, -2.14, -2.03, 0.69, -2.69, 1.4198783572413154, 0.26, -0.14, 1.94, -0.75, -1.35, -1.97, 0.32, -3.5, -3.65, -2.78, -3.14, -4.86, -3.84, 1.99, 0.15, 0.91, 0.53, -1.26, -0.2, -0.75, -0.38, -2.15, -1.1, 0.66, 1.04, -0.37, -1.78, -0.72, 0.71, 0.71, 0.14, -0.49, 0.58, 0.52, 0.5172638105244333, -0.07, 1.43, 1.07, 0.85, 0.99, 0.02, 0.79, 0.81, 0.35, 1.23, -0.48, 0.43], ['229', 1.62, -1.01, -0.25, 0.37, -1.72, -1.0215803763262405, -1.81, -1.6, -1.99, -2.59, 0.3, -1.4792857142857143, -0.7, -0.07, -0.95, -3.43, -1.05, -2.13, -0.35, 0.55, -3.17, -0.72, -0.78, -1.29, -2.22, -1.62, -2.8473416050068874, -1.78, -0.99, -0.36, -1.25, -3.71, -1.34, -2.42, -0.65, 0.26, -3.46, -1.01, -1.07, -1.58, -1.42, -2.98, -1.12, 0.8, 1.44, 0.54, -1.948956349206349, 0.44, -0.66, 1.15, 2.07, -1.71, 0.78, 0.8071428571428572, 0.2, 0.14, -1.81, -2.28, -2.26, -1.91, 0.63, -0.15515323205954745, -2.75, -0.35, -1.45, 0.34, 1.2602380952380952, -2.49, -0.02, -0.08, -0.59, -1.3, -2.52, -0.88, -3.36, -0.98, -2.07, -0.29, 0.62, -3.11, -0.65, -0.71, -1.22, -2.78, -5.04, 5.07, -1.65, -2.5, -0.1, -1.19, 0.6, 1.52, -2.24, 0.24, 0.18, -0.34, 0.93, 0.87, 2.46, 1.34, 3.18, 4.12, 0.26, 2.8124285714285713, 2.74, 2.22, -0.57, 0.86, -3.8542762881169597, -1.19, -1.28, -1.19, -1.4881905235138708, -1.1, 0.7, 1.62, -2.15, 0.34, 0.27, -0.24, -1.85, -0.46, 1.82, 2.75, -1.06, 1.5757995496566926, 1.39, 0.87, -2.04, -1.77, 0.21, -1.68, 2.76, -0.42, -0.35, 1.31, -1.29, -0.62, -0.74, -2.37, 6.48, 2.42, 1.21, 0.89, -0.56, -3.88, 3.56, 3.49, -1.17, 1.91, -2.35, -4.57, 2.35, -4.66, 5.57, 3.1, 4.51, -6.3, -2.24, 0.91, -2.83, -0.36, -0.42, -0.93, -3.52, -3.13, -3.7, -1.26, -1.32, -1.83, 0.6, 2.54, 2.47, 1.95, -1.99, -2.44, -1.89, -0.06, -0.57, -1.21, -1.27, -1.66, 4.11, -3.07, -4.28, -1.1627361894755668, -2.75, -1.83, -0.43721314850306836, -1.41, -0.53, -0.62, -0.5, -0.55, -1.234042472976186, -2.74, -3.96, -1.75], ['230', 0.47, 0.94, -0.07877828437954125, -0.08, -0.47, 0.92, 0.09, 1.24, 0.85, 1.2770884353741496, 0.12, 0.52, -1.04, -0.52, -2.15, -0.14, -0.35, 0.68, 2.93, 2.44, 0.83, 0.13, -0.32, 1.62, 0.91, 1.43, 0.72, 0.4, -1.16, -0.64, -2.27, -0.25, -0.47, 0.56, 2.81, 2.32, 0.794453670078569, 0.01, -0.43, 1.5, 1.26, 0.6049361992161734, 0.5093032324818041, -1.55, -1.03, -2.66, -0.65, -0.87, 0.16, 2.4, 1.91, 0.31, -0.39, -0.83, 1.09, -0.1476426685347185, 0.25, 0.78, 1.21, 1.89, 0.52, -1.12, 0.91, 0.69, 1.74, 4.01, 3.51, 1.89, 1.1959625850340136, 0.7882646163360448, 2.68, -0.09, 1.36, -1.64, 0.39, 0.17, 1.21, 3.47, 2.97, 1.36, 0.66, 0.21, 2.15, 0.98, 3.22, -3.23, 3.05, 2.06, 1.84, 2.895714285714286, 5.2, 4.69, 3.05, 2.33, 1.9109761904761904, 3.85, 0.91, 0.97, -0.22, 0.833095238095238, 3.07, 2.58, 0.97, 0.27, -0.18, 1.75, 0.37, 1.08, 1.33, 0.58, 0.94, 0.26, 1.19, 1.03, 3.3, 2.8, 1.19, 0.49, 0.04, 1.98, 0.64, 0.15, 2.24, 1.75, 0.15956235827664397, -0.54, -0.99, 0.93, 1.41, 2.279561224489796, 0.0, 0.8, 1.51, 0.38, 0.24, 0.67, -0.64, -0.33, 0.62, 3.16, 2.84, -1.09, -0.57, 0.2, 0.4, 1.71, -1.82, -1.88, 0.59, 1.11, 1.19, 1.69, -0.83, 3.49, -2.54, -2.26, -3.63, -2.93, -2.04, -0.48, -2.04, -2.72, -3.16, -1.28, 1.73, -1.56, -1.56, -2.25, -2.69, -0.8, 0.0, -0.7, -1.14, 0.78, 0.85, 1.1, 0.7, -0.45, 1.48, 0.57, 0.59, 1.27, -1.28, 2.0, 0.96, 1.02, 1.34, 1.15, 1.94, 0.4, 0.12, 0.55, 0.61, 1.37, -0.77, 1.23, 2.321595238095238, -0.52], ['231', 0.5, -0.51, 0.08, 0.32, -0.19702091900894042, -0.91, -1.48, -1.49, -1.76, -4.04, -1.36, -2.97, -2.72, -2.92, -3.2, -5.088928571428571, -2.22, -3.596530612244898, -1.58, -2.62, -4.13, -3.28, -1.96, -3.44, -2.77, -1.36, -2.72, -1.6294545454545453, -1.38, -1.58, -1.87, -3.78, -0.87, -2.28, -0.23, -1.28, -2.81, -1.94, -0.61, -2.1, -1.16, -2.92, -1.11, 0.25, 0.05, -0.24, -2.18, 0.77, -0.339454081632653, 1.43, 0.36, -1.2, -0.32, 1.04, -0.48, -0.38, -2.35, -2.44, -1.09, -1.36, -0.2, -0.49, -2.43, 0.52, -0.91, 1.17, 0.11, -1.45, -0.5103418367346938, 0.78, -0.73, -0.31, -1.16, -0.29, -2.2285714285714286, 0.72, -0.71, 1.6274764481550195, 0.31, -1.25, -0.37, 0.99, -0.53, -2.51, -5.48, 5.42, -0.87, -1.95, 1.02, -0.42, 1.67, 0.6, -0.96, -0.08, 1.28, -0.24, -0.97, 1.1, 3.02, 1.56, 3.69, 2.6, 1.0, 1.91, 3.29, 1.74, -0.52, 1.04, 0.17, -1.16, -1.26, -1.19, -1.87, -1.42, 0.65, -0.41, -1.96, -1.08, 0.26, -1.25, -0.88, -0.39692325186963273, 2.1, 1.03, -0.54, 0.35, 1.71, 0.18, -2.25, -1.71, 0.46, -1.58, -1.76, -0.32, 0.0, 2.5, -2.37, -1.2, -0.64, -2.47, 2.67, 2.34, 1.11, 0.26, -0.51, -3.68, 3.61, 3.47, -1.17, 3.6, -2.35, -3.12, 1.58, -5.6, 5.75, 3.74, 5.61, -2.73, -2.5, -1.05, -2.59, -1.72, -0.38, -1.88, -3.47, -1.46, -1.55, -0.67, 0.68, -0.84, 0.1, 0.89, 2.27, 0.73, -1.84, -2.01, -0.79, 1.36, -0.16, -1.05, -1.23, -1.47, 3.08, -0.95, -3.07, -1.46, -2.01, -2.12, -1.51, -1.63, -1.3, 0.1, -0.43, -0.43, -0.63, -2.58, -3.76, -1.65], ['232', 0.18, 0.44, -0.09877828437954125, -0.01, 0.21, 0.92, 1.4, 0.83, 1.18, 1.24, -0.17, 0.37, 0.72, -0.39, 0.19, 1.4, -0.56, 0.82, -1.44, 1.19, 1.47, 0.13, -0.11, 0.81, 0.54, 1.21, 1.41, 0.55, 0.89, -0.22, 0.36, 1.57, -0.39, 0.99, -1.27, 1.36, 1.64, 0.3, 0.06, 0.98, 0.68, 1.06, 0.86, 0.34, -0.76, -0.18, 1.02, -0.93, 0.44, -1.81, 0.81, 1.09, -0.25, -0.48, 0.44, 0.33006284630567656, 0.24, -0.15, 1.33, 0.52, -1.1, -0.52, 0.67, -1.27, 0.1, -2.14, 0.47, 0.75, -0.59, -0.82, 0.09, 0.26, 1.63, 0.58, 1.79, -0.18, 1.21, -1.05, 1.58, 1.86, 0.52, 0.28, 1.2, 1.28, 3.44, -3.48, 1.05, 1.2, -0.75, 0.62, -1.63, 1.193744771101914, 1.28, -0.06, -0.3, 0.62, 2.48, -0.15, -1.93, -0.57, -2.8, -0.21, 0.07, -1.25, -1.48, -0.58, 0.32, -0.12, -0.56, 1.04, 1.11, 1.07, 1.81, 1.39, -0.88, 1.76, 2.04, 0.69, 0.46, 1.38, 0.96, 0.47307674813036726, -2.24, 0.37, 0.8286030199958774, -0.68, -0.92, 0.0, 2.06, 2.55, -0.14, 1.53, 7.728670068027211, 0.07, -0.07, -2.82, 2.79, 1.428810171007621, 0.59, 0.96, -0.19, -2.13, -1.02, 0.12, 0.67, 3.27, -3.24, -3.08, 1.03, -4.2, 2.05, 1.59, -0.78, 5.38, -5.440028911564625, -3.53, -5.3, 0.26, 2.72, 2.66, 2.95, 1.59, 1.35, 2.28, 3.18, 0.05, 0.28, -1.05, -1.28, -0.37, -0.23, -1.32, -1.55, -0.65, 1.13, 1.29, 1.11, -0.23, 0.68, 0.99, 1.13, 0.8, -2.64, 0.55, 2.41, 1.66, 1.19, 1.35, 0.92, 0.79, 1.41, 0.75, 1.27, 0.62, 0.505957527023814, 2.67, 1.86, 1.03], ['233', -0.8, 0.0, 0.011221715620458745, -0.24, -1.23, 0.04, 1.63, -0.23, 0.82, -0.42, -1.45, -1.4, -0.9, -0.42, 2.6, -0.06, -0.63, -0.78, 0.37, 2.55, -0.38, -0.6, -1.11, -0.49, -0.04, 0.04, 1.04, 0.05, 0.56, 1.04, 4.11, 1.41, 0.83, 0.68, 1.85, 4.06, 1.08, 0.86, 0.35, 0.97, 0.06, 2.39, 0.990204081632653, 0.5, 0.99, 4.05, 1.36, 0.78, 0.62, 1.8871355564861205, 4.0, 1.03, 0.81, 0.29, 0.92, -0.07, 0.29, 0.16, 0.84, 0.48, 0.48, 3.53, 0.85, 0.28, 0.12, 1.28, 3.48, 0.52, 0.3, -0.21, 0.41, -0.11, 0.0, 3.04, 0.37, -0.2, -0.36, 0.8, 2.99, 0.04, -0.18, -0.68, -0.07, 1.24, 1.85, -1.9, -2.95, -2.59, -3.15, -3.3, -2.17, -0.05, -2.91, -3.12, -3.61, -3.01, -0.21, -0.37, -0.57, -0.73, 0.43, 2.61, -0.32, -0.55, -1.05, -0.44, 0.31, -0.33, -0.26, 0.0, 0.06, -0.09, 0.2, -0.16, 1.0, 3.2, 0.25, 0.09030501944728757, -0.48, 0.14, 0.03, 0.36, 1.16, 3.36, 0.409562358276644, 0.18, -0.33, 0.29, 0.51, 0.3, -0.01, 0.13, -0.74, 0.23, 0.22, -0.52, 0.49, 0.26, -0.53, -1.72, 5.59, 0.0, 0.03, -0.4, -0.58, 0.09, 0.0, 0.04, -0.01, -0.82, -0.17, 0.63, -0.26, 0.56, -3.08, -0.35, -0.62, -5.57, -0.4696213151927438, 2.17, -0.75, -0.97, -1.47, -0.86, -0.04, -2.9, -2.86, -3.07, -3.57, -2.97, -0.04, -0.22, -0.73, -0.11, 0.87, 1.0, 0.18, -0.51, 0.11, -0.09, -0.03, -0.08, -1.9728571428571429, -0.43, 1.77, -0.11, -0.23, 0.69, 0.62, -0.23, 0.24, -0.67, -0.9, -0.21, 0.07, 1.02, -0.5, 0.39], ['234', -2.21, -1.53, -0.18877828437954128, 0.07, -0.42, -0.34, -0.62, -0.8482794034640413, -0.9, -1.31, -0.59, -1.16, 0.19, -0.8, 0.75, -1.01, -0.94, -1.1, 2.45, -0.34, -1.92, -1.14, -1.07, -0.93, -0.46, -0.53, -0.72, -0.57, 0.79, -0.2, 1.35, -0.42, -0.34, -0.51, 3.06, 0.25, -1.33, -0.54, -0.48, -0.34, -0.76, -2.56, -0.15, 1.37, 0.5378753944468231, 1.94, 0.15, 0.23, 0.06, 3.65, 0.83, -0.76, 0.03, 0.09, 0.23, 0.0, -0.69, -0.22, -0.71, -1.5, -0.99, 0.56, -1.2, -1.13, -1.29, 2.25, -0.53, -2.11, -1.33, -1.26, -1.13, -0.43, -0.52, 1.56, -0.22, -0.14, -0.31, 3.27, 0.46, -1.13, -0.34, -0.28, -0.14, -1.48, -0.98, 1.0, -2.05, -1.7494795918367347, -1.68, -1.84, 1.68, -1.09, -2.65, -1.87, -1.8014761904761905, -1.68, -0.12, -0.3, 0.07, -0.09, 3.49, 0.67, -0.92, -0.13, -0.06, 0.08, -0.27, -0.35, -0.83, -0.28, -0.32, -0.23, -0.38, -0.17, 3.42, 0.6, -0.99, -0.2, -0.13, 0.0, -0.24, -0.21, 3.59, 0.77, -0.82, -0.04, 0.03, 0.17, 0.12, 0.16, 0.17, -0.22, -0.46, 0.0, 0.02, 0.69, -0.67, -0.34, -1.33, -1.3, 2.01, 0.54, 0.22, -1.1, 0.0, -0.87, 0.93, 0.83, -0.28, 0.97, -0.56, -0.37160934502005916, 0.24, -1.14, 1.59, 0.78, 1.01, -2.04, -3.67, -2.72, -4.26, -3.5, -3.43, -3.3, -0.81, -0.97, -1.58, -0.8, -0.73, -0.6, 0.62, 0.8, 0.86, 1.0, -0.88, -1.19, -0.17, 0.07, 0.2, -0.3, -0.23560369872470915, -0.86, 1.17, -0.84, -1.2, -0.71, -0.10890649791998751, -0.24, 0.14, -0.24399479488765202, -0.42, 0.38, 0.25, -0.55, -0.38, -0.76, -0.4, -0.28], ['235', -1.17, -0.6, -0.14, 0.14, -0.78, -1.19, -1.33, -0.67, -1.45, -0.37, 1.61, 0.83, 0.93, 0.63, 0.34, -0.36, 1.04, -0.01, -2.8, -0.55, -0.85, 0.05, 0.45, 0.35, -1.05, -1.05, -1.95, -0.77, -0.67, -0.96, -1.25, -1.94, -0.56, -1.6, -4.34, -2.12, -2.42, -1.54, -1.14, -1.24, -0.55, -4.04, -1.19, 0.1811974674961171, -0.2, -0.49, -1.18, 0.2, -0.84, -3.6, -1.37, -1.67, -0.78, -0.38, -0.48, -0.49, 0.55, -1.07, -1.56, -1.29, -0.3, -0.5792006802721088, -1.28, 0.11, -0.94, -3.69, -1.4697619047619048, -1.76, -0.88, -0.48, -0.58, -0.25, -0.99, -0.29, -0.99, 0.4, -0.64, -3.41, -1.17, -1.47, -0.58, -0.18, -0.29, -2.37, -2.49, 2.46, -0.6733017616146798, -0.7, 0.69, -0.35, -3.13, -0.89, -1.19, -0.3, 0.11, 0.0, -0.1, 0.0, 1.41, 0.35, -2.44, -0.18, -0.49, 0.41, 0.82, 0.71, -0.118858126000983, -0.07, -1.98, -1.17, -1.33, -1.06, -1.39, -1.04, -3.8, -1.57, -1.87, -0.98, -0.58, -0.69, -0.45, -0.35, -2.78, -0.53, -0.84, 0.06, 0.46, 0.36, -0.28, -0.56, 0.2, -1.5, -0.25, -0.36, -0.07, 1.61, -1.69, -0.82, 0.13, -1.68, -0.31, 2.34, 1.15, -0.57, -1.0, -3.46, 3.48, 3.52, -1.17, 2.49, -2.35, -1.69, 0.83, -4.14, 7.46, 2.8, 4.35, 0.39, 2.5, 2.31, 2.0, 2.92, 3.34, 3.23, -3.5, 0.18, -0.3, 0.6, 1.0, 0.9, 0.49, 0.9, 1.31, 1.2, -1.49, -1.79, -0.41, 0.4, 0.3, -1.067919965685943, -1.22, -0.68, 4.84, -2.2, -5.06, -1.59, -2.27, -0.81, -0.1, -1.45, -1.16, -0.54, -0.85, -1.44, -0.71, -3.24, -2.71, -1.01], ['236', -3.53, 0.4, 0.17122171562045874, -0.24, -0.04, 0.13, 0.17411525795982916, 0.69, 0.78, 0.66, 0.66, 0.33, 0.47, 0.07, 0.05, 1.27, 1.37, 0.91, 3.48, -0.8690034013605442, 0.57, 0.6, 0.39, 0.875116627420199, 0.69, 0.19, 0.0, -0.33, -0.19, -0.59, -0.61, 0.6, 0.71, 0.25, 2.8, -1.54, -0.09, -0.06, -0.27, 0.07, 0.42, 0.95, 0.33, 0.14, -0.26, -0.28, 0.94, 1.04, 0.58, 3.14, -1.21, 0.25, 0.27, 0.06, 0.4, 0.26006284630567655, 0.76, 0.82, 1.19, 0.19, -0.4, -0.42, 0.8, 0.9, 0.44, 3.0, -1.35, 0.1, 0.13, -0.08, 0.26, 0.88, 0.59, -0.02, 1.3555085034013605, 1.3, 0.84, 3.41, -0.95, 0.5, 0.53, 0.32, 0.66, 0.74, 0.35, -0.35857142857142854, 0.61, 1.22, 1.3417857142857144, 0.86, 3.43, -0.93, 0.53, 0.55, 0.34, 0.68, -1.14, -0.5226334687834371, 0.1, -0.36, 2.18, -2.13, -0.69, -0.6575714285714286, -0.87, -0.53, -0.25, -0.64, -0.93, 0.14, 0.25, -0.09, -0.7, -0.46, 2.08, -2.0302873118944547, -0.79, -0.76, -0.97, -0.63, 0.09, -0.25, 2.55, -1.78, -0.33, -0.31, -0.52, -0.18, 0.28, 0.15, -0.35, -0.4, -3.64, -0.43, -0.14, 0.22, -0.22, -0.09, 0.27, 0.6, -3.09, -0.26, -0.14, -1.73, -0.14, 0.47, -0.5, -0.47, 0.14, 0.27, 0.29, 0.82, -0.65, -2.13, -1.12, 1.35, 2.14, 3.29, -2.72, -4.22, -2.81, -2.78, -2.99, -2.66, 0.43, 1.56, 1.47, 1.5, 1.28, 1.63, 0.09, 0.03, -0.18, 0.16, 0.73, 0.84, 0.06, -0.21, 0.13, 0.14, 0.01, 0.75, -1.47, -0.38, 1.5, 0.43, 0.76, 0.27, 0.34, -0.13, -0.07, -0.31, -0.24, 0.36, -0.07, 0.7, 0.47, -0.58], ['237', 2.1, -0.24, 0.06122171562045875, -0.08, 0.69, 0.5384196236737595, 1.7000361663652803, 1.61, 1.9, 1.55, -1.48, 0.281934498041641, 0.01, 0.65, -0.26, 0.72, 0.41, 0.88, 3.07, 1.18, 2.17, 2.2, 0.96, 0.64, 1.29, 1.63, 3.08, 1.59, 1.51, 2.17, 1.24, 2.24, 1.93, 2.4, 4.63, 2.700714285714286, 3.71, 3.74, 2.48, 2.16, 1.02, 2.42, 1.47, 0.01119746749611708, 0.57, -0.34, 0.64, 0.33, 0.8, 2.99, 1.09, 2.09, 2.12, 0.88, 0.56, 0.68, 2.33, 0.94, 1.17, 1.54, 0.7431047225355607, -0.27, 0.71, 0.41, 0.88, 3.07, 1.17, 2.16, 2.19, 0.96, 0.64, 2.12, 0.89, -0.91, 0.07, -0.24, 0.23, 2.41, 0.52, 1.51, 1.54, 0.31, -0.01, 2.78, 1.61, -1.62, 1.82, 0.98, 0.68, 1.15, 3.35, 1.44, 2.44, 2.47, 1.23, 0.91, 1.01, 0.82, -0.3, 0.16, 2.34, 0.45, 1.44, 1.47, 0.24, -0.08, 0.44, 0.79, 3.12, 0.8915981806829014, 0.75, 0.99, 1.13, 0.47, 2.65, 0.76, 1.75, 1.78, 0.55, 0.23, -0.3134639289282145, 0.66, 2.17, 0.29, 1.28, 1.31, 0.08, -0.24, 0.82, 0.8, 0.14, 1.09, 3.11, 0.54, 0.28, -2.04, 2.062462323390895, 1.04, -1.0, 2.13, -0.75, -1.65, -0.91, 1.14, 0.53, 2.63, -2.63, -2.52, 0.84, -3.06, 1.72, 1.48, -0.77, 3.45, -6.12, -2.33, -3.37, 0.84, -1.48, -1.84, -0.87, -0.85, -2.033374149659864, -2.36, 2.53, 0.37, 0.99, 1.01, -0.21, -0.53, -0.61, 0.03, -1.18, -1.5, 1.92, 2.24, -0.64, -1.21, -1.52, 0.85, 0.93, 1.78, -3.84, 2.310199626957499, 3.78, 1.33, 0.68, 0.58, -0.32, 1.29, 0.97, 0.6, 0.26, 1.2, 0.9, 0.96, 1.7, 0.88], ['238', -1.93, -0.36, -0.028778284379541254, 0.08, -0.46, -0.44, -0.16588474204017084, -1.01, -0.52, -0.76, -0.38, -0.6, 0.52, -0.15, -0.02, -0.15, -0.26, -0.73, 0.18, -0.33, -0.67, -0.53, -0.53, -0.57, -1.26, -0.77, -0.38, -0.22, 0.9108333333333334, 0.23, 0.36, 0.23, 0.12, -0.36, 0.56, 0.05, -0.3, -0.16, -0.15, -0.19, -0.19, -0.5350638007838266, -0.16, 1.12, 0.45, 0.58, 0.45, 0.34, -0.14, 0.79, 0.27, -0.041934531913557026, 0.07, 0.07, 0.03, -0.36, 0.11, -0.55, -0.41, -1.27, -0.5568952774644393, -0.53, -0.66, -0.77, -1.24, -0.33, -0.84, -1.18, -1.04, -1.04, -1.08, -1.1863939988582846, -0.61, 0.13, 0.0, -0.11, -0.59, 0.33, -0.18, -0.52, -0.39, -0.38, -0.42, -0.42, -0.51, 0.52, -0.7033017616146798, -0.13, -0.24, -0.71, 0.2, -0.31, -0.65, -0.51, -0.51, -0.55, -1.11, -0.61, -0.11, -0.59, 0.33, -0.18, -0.52, -0.38, -0.38, -0.42, -0.04, -0.63, -0.23, -0.3, -0.38482093036566006, -0.2, -0.5, -0.48, 0.44, -0.07, -0.41, -0.27, -0.27, -0.25141531611693435, -0.06, -0.03, 1.1736855802927233, 0.41, 0.06, 0.2, 0.21, 0.17, -0.32, -0.44, 0.01, -0.48, -3.09, -0.1, -0.07, 0.1, -0.14, -0.06, 0.67, -0.5238364678879506, 0.83, 0.49, 0.28, -0.95, -0.29, -0.9, 0.95, 0.9, -0.31, 0.17, -0.6, -0.92, 0.47, -1.48, -3.85, 1.04, 1.55, -0.76, -0.94, -0.51, -0.85, -0.71, -0.71, -0.75, -0.96, -0.43, -0.34, -0.2, -0.2, -0.24, -0.09, 0.14, 0.15, 0.1, -0.52, -0.47, -0.23, 0.01, -0.04, -0.29, -0.31, -0.94, -1.84, -0.16, 1.84, -0.97, -0.7, -0.15136255179902908, -0.04, -0.57, 0.17455285983857427, -0.22, -0.37, -0.52, -0.19, -2.59, -1.31, -0.5], ['239', -1.72, 0.49, 0.18, -0.09, -0.72, 0.17, 0.49411525795982914, -0.11, 0.2, -0.45, -0.85, 0.05, -1.03, -0.03, -0.38, 0.34, -1.09, -0.55, -3.41, -0.66, -0.59, -0.44, -1.14, -0.63, 0.2, 0.26, 0.4, 0.91, -0.18, 0.82, 0.47, 1.21, -0.24, 0.4172589041444084, -2.58, 0.19, 0.26, 0.42, -0.29, 0.23, 0.68, 0.9049361992161734, -0.51, -1.09, -0.09, -0.43, 0.29, -1.14, -0.6, -3.46, -0.71, -0.64, -0.49, -1.19, -0.68, 0.25, -0.22, -0.51, 0.5, 0.59, 1.01, 0.66, 1.39, -0.06, 0.49, -2.4, 0.38, 0.45, 0.6, -0.11, 0.41, -0.53, -0.42, -0.35, 0.38, -1.06, -0.52, -3.38, -0.62, -0.55, -0.4, -1.11, -0.59, 0.6, 2.08, -2.09, -0.03330176161467985, 0.73, -0.71, -0.17, -3.04, -0.28, -0.21, -0.06, -0.76, -0.1859922724755494, -1.06, -0.8, -1.43, -0.89, -3.74, -1.0, -0.93, -0.78, -1.48, -0.97, 0.06, -0.86, 0.88, 0.31, 0.55, 0.11, 0.65, 0.55, -2.35, 0.44, 0.51, 0.66, -0.05, 0.5285846838830657, 0.17, 0.1, -2.88, -0.11, -0.04, 0.11, -0.59, -0.07, 1.05, 0.96, -0.11, 0.57, -3.26, 0.2, 0.27, 0.54, -0.57, -0.3, 1.34, -0.1, -0.43, -0.67, -0.33, -0.65, 0.48307978986877903, 0.82, -0.93, -0.94, 0.29, 0.75, 0.59, 0.21, -0.07, 1.93, -3.81, -1.29, -1.92, 0.46, 3.06, 2.85, 2.92, 3.08, 2.35, 2.89, 0.91, 0.21, 0.07, 0.22, -0.49, 0.03, 0.14, 0.15, -0.56, -0.04, 0.16, 0.48, -0.02, -0.71, -0.19, 0.31, 0.43439630127529083, -0.11, -1.81, 0.69, 1.62, 0.81, 1.1410935020800126, 0.7, 0.52, 0.7100774025227806, -0.4, 0.25, 0.51, 0.39, 0.17, 0.48, 0.99, 0.66], ['240', 3.13, 0.12, 0.2912217156204588, 0.19, -0.29, -0.09, 0.18, 0.44, 0.32, 0.55, 0.06060884353741497, 0.14, -0.05, -0.08, -0.78, -0.13, -0.02, 0.55, -5.2, 2.03, 0.54, 0.59, -0.08, 0.71, 0.04, 0.11, 0.5, 0.09, -0.1, 0.013189937047079991, -0.83, -0.18, -0.07, 0.5, -5.24, 1.98, 0.49, 0.54, -0.13, 0.66, 0.08746842535321082, 0.0, 0.42, -0.19, -0.22, -0.92, -0.27, -0.15, 0.42, -5.32, 1.89, 0.409654729237061, 0.45, -0.21, 0.57, 0.97, 0.3, 0.73, 0.12, 0.61, -0.03, -0.73, -0.08, 0.04, 0.61, -5.14, 2.09, 0.59, 0.64, -0.02, 0.76, 0.55, 0.64, -0.7, -0.05, 0.07, 0.64, -5.11, 2.12, 0.62, 0.67, 0.01, 0.79, 0.56, 2.01, -2.03, 1.3766982383853201, 0.65, 0.77, 1.34, -4.45, 2.83, 1.33, 1.38, 0.71, 1.5, 1.38, 0.69, 0.12, 0.69, -5.07, 2.17, 0.68, 0.72, 0.06, 0.84, 0.08, 0.68, 0.3, 0.14, 0.12, 0.18567351865003195, 0.57, 0.57, -5.18, 2.05, 0.56, 0.6, -0.06, 0.72, 0.05, 0.0, -5.72, 1.47, -0.01, 0.15579954965669268, -0.63, 0.15, 0.56, 0.84, 0.24, 0.07, 4.26, 0.21, 0.18, -0.38, 0.38, 0.18, 0.51, -0.45, 3.03, -0.29, -0.15, 1.59, 0.0, 0.6305968614718616, -0.53, -0.39, 0.14, -0.67, 0.29, -0.08, 0.03, 1.65, -4.49, -1.19, -1.65, -3.0, 6.06, 7.62, 6.05, 6.1, 5.4, 6.22, 0.44, -1.45, -1.46, -1.42, -2.06, -1.3, 0.01, 0.05, -0.61, 0.17, 0.23, 0.22, -0.03, -0.66, 0.19224875531501634, 0.14, 0.18439630127529083, 0.56, -2.33, 1.13, 2.29, -0.002736189475566718, 0.48, 0.63, 0.78, 0.05, 0.29, 0.35, -0.06, -0.53, -0.15, 1.69, 0.29, 0.05], ['241', -3.36, 0.38, 0.18122171562045875, 0.08, 0.07, 0.02, -0.49588474204017086, -0.84, -0.36, -1.03, -0.59, -0.28, -0.59, -1.19, 1.2242857142857142, -0.7, -1.5071428571428571, -0.85, 0.77, -3.49, -0.9526645179126411, -1.17, -0.58, -0.65, -0.3, 0.98, -0.45, 0.31, 0.0, -0.61, 1.82, -0.11, -0.93, -0.26, 1.37, -2.92, -0.4, -0.59, 0.02, -0.06, -1.74, 0.23, -0.75, -0.31, -0.92, 1.5, -0.42, -1.23, -0.57, 1.05, -3.22, -0.681934531913557, -0.89, -0.29, -0.37, -0.15, -0.59, -1.4580521152823784, -0.36, -0.45, -0.61, 1.82, -0.11, -0.93, -0.26, 1.36, -2.92, -0.4, -0.59, 0.01, -0.07, -0.97, 0.16, 2.44, 0.5, -0.32, 0.35, 1.99, -2.33, 0.21, 0.02, 0.63, 0.55, -0.03, -1.13, 1.1305714285714286, -2.22, -1.9, -2.7, -2.04, -0.44, -4.66, -2.18, -2.36, -1.77, -1.85, -0.02, -0.33, -0.82, -0.15, 1.48, -2.81, -0.29, -0.23718300350443208, 0.13, 0.05, -0.28, -0.4, 2.51, -0.06, -0.05, 0.03, 0.48, 0.67, 2.31, -2.01, 0.53, 0.34, 0.95, 0.87, 0.23, -0.18, 1.63, -2.67, -0.14, -0.32, 0.28, 0.44217743764172346, 1.04, 1.46, -0.33, 0.37, 0.03, -0.07, -0.14, 0.42, -0.41, -0.22, 0.62, -0.03, -5.1, 0.1, 0.05, -1.74, 0.04, -0.06, 0.06, 0.21, -0.06, 0.54, -0.15, -0.07, 0.06, 1.43, 0.13, -0.92, -1.38, 5.14, -1.4696213151927437, -4.23, -1.5427867132867132, -1.93, -1.33, -1.41, -0.08, 2.55, 2.6, 2.41, 3.03, 2.94, -0.05, -0.10112140889357832, 0.42, 0.34, -0.24, -0.23, 0.14, 0.6, 0.52, -0.09, -0.03, -0.78, 0.09, 1.4, 0.0, -0.66, 0.73, -0.46, -0.08, 0.06, -0.04, 0.27, -0.11, -0.41, -0.38, -0.25, 1.79, -0.24], ['242', -3.4, 0.11, 0.09122171562045875, 0.07, -0.6570209190089404, -0.26, -0.82, -0.49, -0.26, 1.05, 1.07, 1.92, 0.52, 2.15, 2.57, 1.71, 1.86, 1.01, 5.22, 1.77, 0.78, 1.84, 1.57, 1.34, -0.8, -0.73, -0.02, 0.8401785714285714, -0.54, 1.07, 1.48, 0.64, 0.78, -0.06, 4.1, 0.7, -0.29, 0.76, 0.5, 0.27, -0.67, -0.66, -0.86, -1.37, 0.22, 0.63, -0.21, -0.06, -0.9, 3.23, -0.15, -1.0919345319135572, -0.08, -0.34, -0.57, -0.14, 0.56, -1.31, 0.06, 0.52, 1.62, 2.03, 1.19, 1.33, 0.48, 4.67, 1.25, 0.26, 1.32, 1.05, 0.82, -0.3, -1.08, 0.41, -0.43, -0.29, -1.12, 3.0, -0.37, -1.34, -0.3, -0.57, -0.79, -0.23, -1.61, 1.57, -1.48, -0.83, -0.69, -1.52, 2.59, -0.7683253968253968, -1.74, -0.7, -0.97, -1.19, -1.49, -0.66, 0.14, -0.69, 3.45, 0.06, -0.92, 0.13, -0.14, -0.36, -0.15, -0.65, -1.98, -0.46, -0.49, -0.44, -0.8, -0.84, 3.3, -0.08, -1.06, -0.01, -0.28, -0.51, -0.83, 0.04, 4.17, 0.76, -0.22, 0.83, 0.56, 0.33, -0.46, -0.44, 0.07, -0.69, -4.57, -0.08, -0.24, 1.14, -1.13, -0.56, -0.08, -0.22383646788795053, 1.29, 1.01, 0.44, -1.7, 0.13, -1.38, 1.34, 1.41, -0.47, 1.5, -0.93, -0.29, 0.14, -2.42, 0.2721071428571429, 1.57, 2.22, -1.18, -3.97, -3.27, -4.22, -3.21, -3.46, -3.68, -1.4, -0.72, -0.97, 0.07, -0.2, -0.42, 0.26, 1.05, 0.78, 0.56, -0.29, 0.07, -0.78, -0.27, -0.49, -0.47, -0.5, -0.37, 0.84, -1.45, -0.83, -1.0, -1.03, -0.52, -0.23, -0.94, -0.64, 0.26, 0.38, -0.38, -0.29, -1.97, -2.36, -0.05], ['243', 1.92, -0.07, 0.08015289830927054, 0.15, -0.53, -0.07, -0.44588474204017087, -0.74, 0.33, -1.34, -2.31, -1.02, -1.06, -0.5, -0.11, -1.48, -1.55, -1.44, 0.97, -0.7, -1.28, -1.57, -1.57, -1.39, -0.44, 0.14, 0.99, 1.32, 1.28, 1.86, 2.25, 0.85, 0.78, 0.89, 3.35, 1.65, 1.06, 0.76, 0.76, 0.95, -0.03253157464678917, 0.95, -0.32, -0.03, 0.53, 0.92, -0.46, -0.53, -0.42, 2.01, 0.32, -0.26, -0.56, -0.55, -0.37, -0.61, -0.76, -0.47, 0.53, -0.29, 0.56, 0.95, -0.43, -0.5, -0.39, 2.04, 0.36, -0.22, -0.52, -0.52, -0.33, -0.96, -0.85, 0.39, -0.99, -1.06, -0.95, 1.47, -0.2, -0.78, -1.08, -1.08, -0.89, 1.04, 0.72, -0.7, -1.23, -1.37, -1.44, -1.33, 1.08, -0.59, -1.17, -1.46, -1.46, -1.27, -0.42, 0.14, -0.07, 0.04, 2.48, 0.79, 0.21, -0.09, -0.09, 0.1, 0.06, 0.09, -0.97427628811696, 0.17, 0.17517906963433993, 0.2, 0.21, 0.11, 2.55, 0.86, 0.28, -0.02, -0.02, 0.2285846838830657, 0.2, 0.1, 2.44, 0.75, 0.17, -0.13, -0.13, 0.06, 0.83, 0.29, 0.29, 0.14, -1.11, 0.13, 0.2, -0.54, 0.56, 0.25, 0.34, -0.6638364678879505, 1.22, -0.37, -0.19, 0.94, 0.17, 0.57, -0.54, -0.49, 0.22329080486385297, -0.87, 0.33, -1.44, 0.69, 0.72, -1.59, -0.41, -0.65, -1.26, -2.29, -1.65, -2.22, -2.51, -2.51, -2.33, 0.5, -0.64, -0.4358074110763185, -0.88, -0.87, -0.69, -0.07, -0.3, -0.3, -0.11, 0.33, 0.8084535464535467, 0.23, 0.0, 0.26224875531501635, 0.17, 0.11, -0.76, -1.32, -0.38, 1.27, -0.39, 0.22, 0.23, 0.19, -0.08, 0.29, 0.29, 0.33, 0.18, 0.04, -1.31, 0.68, 0.07], ['244', -0.53, 0.15, 0.13122171562045873, 0.03, 0.0, 0.31, 0.51, -0.58, 0.1, -0.6, -0.71, -0.96, -0.58, 0.41, -0.16, -0.69, -0.52, -0.68, -0.7, -0.22, -0.42, -0.47, -1.3, -0.86, 0.36, 0.4, 0.12, -0.25, 0.14011904761904762, 1.14, 0.56, 0.02, 0.2, 0.04, 0.02, 0.5, 0.3, 0.24, -0.59, -0.15, 0.2, -0.24, 0.37, 0.38, 1.39, 0.8, 0.27, 0.45, 0.28, 0.27, 0.75, 0.54, 0.49, -0.34, 0.1, 0.03, -0.44, -0.07, 0.22, -0.01, 1.0, 0.42, -0.11, 0.07, -0.1, -0.11, 0.37, 0.16, 0.11, -0.72, -0.28, -0.5263939988582844, -1.01, -0.57, -1.1, -0.92, -1.09, -1.1, -0.63, -0.83, -0.88, -1.5769045181009465, -1.2164403582748793, 0.0, 1.73, -1.77, -0.43, -0.53, -0.35, -0.52, -0.53, -0.06, -0.26, -0.31, -1.14, -0.7, -0.4, 0.1, 0.18, 0.02, 0.0, 0.48, 0.28, 0.22, -0.61, -0.17, 0.02, 0.11, 0.04, 0.26, 0.41, 0.13567351865003197, -0.08, -0.16, -0.18, 0.3, 0.1, 0.04, -0.79, -0.35, 0.03, 0.08, -0.02, 0.46, 0.26, 0.21, -0.62, -0.18, 0.74, 0.63, 0.08, -0.04, -1.12, 0.01, -0.07, 0.0, 0.05, 0.0, 0.52, -0.85, 0.79, -0.45, -0.26, -0.3, 0.19, 0.76, -0.78, -0.74, 0.26, -0.09, 0.5, -0.27, 0.12, -0.21, -5.32, 0.2, 0.23, -0.73, 0.1, 0.48, 0.28, 0.22, -0.61, -0.17, 0.79, -0.38, -0.2, -0.26, -1.08, -0.64, -0.18, -0.05, -0.88, -0.44, 0.16, 0.11, -0.12, -0.83, -0.39, 0.26, 0.21, -0.45, -3.66, 0.52, 3.66, 0.3718948994148555, 0.08, 0.7104317111459968, 0.44, 0.29, -0.07, 0.16, 0.21, 0.38, 0.27, -0.29, 0.07, -0.03], ['245', -2.01, 0.34, -0.028778284379541254, -0.28, -0.1, 0.06, 0.044115257959829166, 0.09, 0.31, 0.28, -0.6, 0.23, 0.35, 0.02, 0.46, 0.6, 0.23, 0.28, -3.83, -0.6, 0.21, 0.31, -0.19, -0.4, -0.86, -0.28, 0.89, 0.84, 0.96, 0.63, 1.07, 1.21, 0.84, 0.89, -3.25, 0.0, 0.82, 0.92, 0.41, 0.21, 0.36, 0.75, 0.05, 0.20119746749611708, -0.21, 0.22, 0.37, 0.0, 0.05, -4.05, -0.83, -0.02, 0.08, -0.42, -0.63, 0.35, 0.54, -0.19, 0.34, -0.07, -0.33, 0.11, 0.25, -0.11, -0.07, -4.16, -0.95, -0.13, -0.03, -0.54, -0.74, 0.76, 0.26, 0.44, 0.58, 0.21, 0.26, -3.85, -0.62, 0.19, 0.29, -0.21, -0.35644035827487924, 0.89, 1.3, -1.39, -0.17, 0.14, -0.22, -0.17, -4.27, -1.06, -0.24, -0.14, -0.65, -0.85, -1.49, -0.2426334687834371, -0.36, -0.32, -4.4, -1.2, -0.38, -0.28, -0.79, -0.99, -0.02, -0.26, 0.23572371188304003, 0.18, 0.38, -0.024326481349968038, 0.12180947648612922, 0.05, -4.05, -0.84, -0.02, 0.08, -0.43, -0.5714153161169343, 0.08, 0.0, -4.1, -0.88, -0.07, 0.03, -0.47, -0.68, 0.54, 0.59, -0.26, 0.01, -4.48, 0.26, 0.21, 0.72, -0.71, -0.35, 0.65, -0.19, -1.76, -0.43, -0.18, -0.98, 0.3, 0.37, -0.4, -0.58, 0.18, 1.07, 0.39, 0.73, -0.39, 0.14, -2.67, -0.07, -0.07, 1.78, 4.28, 3.3548095238095237, 4.206609977324264, 4.31, 3.78, 3.57, 0.56, 0.89, 0.82, 0.92, 0.41, 0.21, 0.07, 0.1, -0.41, -0.61, 0.32, 0.26, -0.03, -0.51, -0.71, 0.18, 0.11, 0.13, -1.37, 0.73, 1.21, 0.047263810524433285, 0.37, 0.48, -0.2, 0.32, 0.0, -0.03, 0.0, -0.24, 0.68, -1.31, 0.58, 0.77], ['246', -8.0, -1.26, -0.28, -0.18, -0.51, -1.11, -0.5258847420401709, -2.018279403464041, -2.3, -2.19, 0.4, -1.92, 0.4, 1.59, -0.2, 0.61, -1.33, -1.68, -1.55, -2.94, -2.69, -0.88, -1.14, -1.55, -3.32, -2.36, -2.5473416050068876, -2.3, 0.0, 1.18, -0.59, 0.21, -1.72, -2.07, -1.9392857142857143, -3.32, -3.07, -1.27, -1.53, -1.8961582768021608, -1.8025315746467891, -4.55, -0.28, 2.36, 3.57, 1.75, 2.57, 0.6, 0.24, 0.38, -1.04, -0.79, 1.06, 0.79, 0.37, -1.3199371536943236, -2.44, -1.37, -1.94, -2.510754752934122, 1.18, -0.6, 0.2, -1.73, -2.07, -1.8313219954648525, -3.33, -3.08, -1.28, -1.54, -1.95, -1.99, -3.72, -1.76, -0.97, -2.87, -3.21, -3.08, -4.46, -4.21, -2.43, -2.69, -3.09, -3.64, -3.87, 3.21, -2.0, 0.8, -1.14, -1.48, -1.35, -2.75, -2.5, -0.68, -0.95, -1.36, -4.1, -2.78, -1.93, -2.27, -2.14, -3.52, -3.27, -1.48, -1.74, -2.15, -1.08, -2.81, -1.36427628811696, -1.06, -1.09, -1.09, -0.87, -0.35, -0.22, -1.63, -1.37, 0.46, 0.19, -0.23, -1.43, -0.53, 0.13, -1.29, -1.03, 0.81, 0.54, 0.12, -0.61, -0.5, -0.13, -1.31, -8.21, -2.0219304505018787, -1.86, 1.28, -1.24, -0.62, -0.47, -1.32, -1.33, 2.13, 1.05, -4.1, -0.98, -3.34, 3.37, 3.32, -1.06, 2.04, -2.19, -0.63, 0.26, -2.65, 11.22, 1.73, 2.69, 1.63, -0.66, -1.42, -1.16, 0.68, 0.41, -0.01, -3.14, 0.77, 0.26, 2.12, 1.85, 1.43, 0.51, 1.86, 1.59, 1.16, -2.46, -2.88, -1.33, -0.27, -0.68, -1.11, -1.0, -1.94, 5.58, -0.9098003730425006, -5.46, -2.05, -1.66, -1.06, -0.42, -1.743994794887652, -0.68, -1.03, -0.46, -1.03, -0.65, -2.84, -1.97, -0.44], ['247', -2.09, 0.12, 0.09122171562045875, 0.08, 0.15, -0.63, -1.0058847420401709, -0.77, -1.12, -1.73, 1.05, -1.42, -1.61, -1.77, -0.32273809523809527, -1.36, -1.012857142857143, -1.66, -1.39, -1.7233571428571428, -2.01, -0.62, -0.29, -1.33, -0.42, -1.2, -2.76, -2.44, -2.2123253968253964, -2.79, -1.37, -2.38, -2.08, -2.68, -2.42, -2.76, -3.02, -1.66, -1.33, -2.36, -1.79, -3.1750638007838266, -0.32, -0.19, -0.35, 1.1, 0.06, 0.38, -0.24, 0.03, -0.32, -0.6, 0.81, 1.14, 0.09, -1.02, -0.65, -0.08, -0.35, -0.13, -0.16, 1.3, 0.26, 0.57, -0.05, 0.22, -0.13, -0.4, 1.0, 1.34, 0.28, 1.25, 0.03, 1.46, 0.42, 0.73, 0.11, 0.38, 0.03, -0.24, 1.16, 1.5, 0.44, -2.62, -3.39, 3.63, -1.4, -1.02, -0.72, -1.33, -1.06, -1.41, -1.68, -0.27428571428571424, 0.04, -1.0, -0.7473809523809524, -0.38, 0.31, -0.31, -0.04, -0.38, -0.66, 0.74, 1.08, 0.03, -0.19, -0.41, -0.17989534883720928, -0.62, -0.7, -0.36, -0.69, -0.62, -0.35, -0.69, -0.97, 0.43, 0.76, -0.29, -1.02, -0.08, 0.27, -0.08, -0.35, 1.05, 1.39, 0.33, -1.11, -1.05, 0.13, 0.11, -1.59, 0.3580695494981211, 0.22, 0.46, -0.47, -0.26, -0.37, 0.36, -0.32, 1.25, 0.61, -0.98, -0.56, -1.6, 1.54, 1.93, -0.63, 0.69, -1.28, 0.3, -0.18, -2.12, 2.45, 1.43, 2.04, 0.19, -0.34, -0.34, -0.62, 0.78, 1.12, 0.06, -1.85, 0.0, -0.28, 1.13, 1.47, 0.41, 0.28, 1.4128849285635, 1.75, 0.69, -1.18, -1.54, -1.12, 0.33, -0.71, -0.69, -0.52, -0.78, 1.3, 0.0, -1.16, -0.03, -0.27, -1.45, -1.04, -0.77, -0.46, -0.42, -0.68, -0.64, -0.41, 1.13, 0.5, -0.64], ['248', -0.53, 0.12, -0.43877828437954125, 0.06, 0.07, -0.41, 1.5, 0.69, 0.45, 2.23, 2.33, 0.32, 2.17, 2.46, 0.9, 1.75, 2.68, 2.47, 6.64, 1.71, 2.05, 2.8010442176870747, 2.37, 2.19, 0.13, 0.28, -0.09, -1.96, -0.16, 0.13, -1.39, -0.57, 0.35, 0.14, 4.22, -0.6, -0.27, 0.43, 0.05, -0.13, 1.95, -0.15, 1.91, 1.84, 2.13, 0.58, 1.42, 2.35, 2.14, 6.3, 1.38, 1.72, 2.43, 2.05, 1.86, -0.28, 0.39, 1.28, 0.12, 0.07, 0.29, -1.24, -0.41, 0.51, 0.3, 4.38, -0.45, -0.11, 0.59, 0.2, 0.02, 1.1, -0.22, -1.52, -0.7, 0.22, 0.01, 4.08, -0.73, -0.4, 0.3, 0.05309548189905343, -0.27, -0.2, -0.24, 0.19, 1.32, 0.84, 1.77, 1.55, 5.69, 0.8, 1.14, 1.85, 1.46, 1.27, 0.36, 0.48, 0.92, 0.71, 4.8459047619047615, -0.04, 0.3, 1.0, 0.62, 0.43, 0.18114187399901702, 0.54, 0.56, -0.1, -0.06, -0.03, -0.44, -0.21, 3.86, -0.95, -0.4442217465074606, 0.08, -0.3, -0.48, -0.48, -0.23, 4.08, -0.74, -0.41, 0.29, -0.09, -0.27, 0.37, 0.45, 0.06, 0.05, 0.92, 0.18, -0.28, -0.17, 0.18, 0.11, 0.21406627346681525, 1.05, -0.9, 0.12, 0.1, -0.25, -0.39, -0.14, 0.14, 0.26, -0.08, -0.22, -0.2, -0.5, 0.25, -1.23, 8.05, 0.87, 1.21, 1.3056150793650794, -4.14, -4.63, -4.31, -3.64, -4.0, -4.18, -0.25, 0.6543542330685188, 0.33, 1.04, 0.65, 0.47, 0.18, 0.7, 0.32, 0.14, 0.41, 0.09, -0.52, -0.38, -0.56, -0.07, -0.09, 0.64, 4.812857142857143, -0.3, -4.13, 0.3, 0.05, -0.14, -0.18, -0.88, 0.18, 0.03, -0.29, -0.03, 0.04, -0.21, 1.5030376647162362, -0.43], ['249', -0.59, 0.63, 0.04, -0.06, 0.41, 0.27, 1.17, 0.65, 0.51, -0.62, -1.48, -1.17, -1.63, -0.09, -2.94, -0.25, -1.19, -0.79, -0.52, -1.2033571428571428, -0.35, -0.77, -1.16, -1.47, 0.45, 0.63, 0.9126583949931124, 0.32, -0.14535714285714285, 1.42, -1.4221800287049087, 1.26, 0.29, 0.8272589041444084, 0.97, 0.28, 1.15, 0.72, 0.33, 0.053841723197839156, 0.88, 1.64, 0.56, -0.46, 1.1, -1.79, 0.94, -0.02, 0.39, 0.7571355564861204, -0.04, 0.83, 0.41, 0.01, -0.3, 1.05, -0.44, 0.3, -0.11, 1.03, 1.56, -1.33, 1.4, 0.44, 0.85, 1.1371802721088435, 0.42, 1.3, 1.1974648526077096, 0.48273474541331685, 0.18418480725623584, 0.14, -0.53, -2.849285714285714, -0.16, -1.11, -0.7, -0.4269047619047619, -1.12, -0.26, -0.68, -1.07, -1.38, 1.05, 1.721742947528662, -1.58, 2.4266982383853204, 2.78, 1.8, 2.22, 2.49, 1.78, 2.67, 2.23, 1.83, 1.51, -0.13, -0.37, -0.95, -0.54, -0.28, -0.97, -0.11, -0.53, -0.92, -1.23, 0.25, -0.45, 2.3157237118830403, 0.49, 0.53, 0.585673518650032, 0.6618094764861292, 0.41, 0.68, -0.02, 0.85, 0.43, 0.04, -0.22141531611693435, 0.25, 0.17, 0.27, -0.43, 0.44, 0.02, -0.38, -0.69, 0.5, 0.43, -0.16, 0.55, -0.37, 0.1, 0.1, -0.9, 0.7, 0.45, -0.26, 0.95, -1.33, -0.98, -0.52, -0.21, 0.5, 1.46, -1.49, -1.47, 0.47, -1.4, 0.9, 1.36, -0.7, 1.74, -6.02, -1.1, -1.59, 1.22, -0.09, -0.69, 0.17, -0.25, -0.64, -0.95, 1.4708051948051948, 0.6, 0.87, 0.45, 0.05, -0.26, 0.176501700680272, -0.42, -0.81, -1.12, 0.55, 0.64, 0.16, -0.39, -0.7, 0.49, 0.53, 0.6, -4.07, 2.05, 4.14, 0.51, 0.37, 0.55, -0.32, -0.14, 0.36, 0.83, 0.57, 0.67, 0.87, 0.39, 0.4, 1.23], ['250', 2.04, -0.18, 0.12, 0.05, 0.18, -0.42, -2.1758847420401706, -0.99, -0.7, -0.15, 0.5, 1.35, 0.28, 0.89, 2.03, -1.09, 0.05, -0.12, 1.18, -0.09, -0.29, 0.19, 0.26, 0.19, -0.8, -0.17, -0.65, 0.85, -0.22, 0.38, 1.52, -1.58, -0.45, -0.5027410958555916, 0.68, -0.59, -0.705546329921431, -0.31, -0.24, -0.31, -0.56, 0.07, -1.48, -0.9788025325038829, -0.46, 0.67, -2.41, -1.28, -1.46, -0.17, -1.43, -1.62, -1.14, -1.08, -1.15, -0.68, -0.59, -1.28, -0.66, -0.43, 0.61, 1.74, -1.36, -0.23, -0.4, 0.9, -0.37, -0.57, -0.09, -0.02, -0.09, -0.75, -1.03, 1.13, -1.96, -0.83, -1.0, 0.29, -0.97, -1.16, -0.69, -0.62, -0.69, -0.36, -1.09, 1.11, -2.13, -3.05, -1.94, -2.11, -0.83, -2.08, -2.1047647669790526, -1.8, -1.73, -1.8, 0.18, 0.95, 1.15, 0.98, 2.29, 1.01, 0.81, 1.29, 1.36, 1.29, -0.07, 0.87, -0.11, -0.4, -0.41, -0.3, -0.2, -0.17, 1.13, -0.14, -0.34, 0.14, 0.21, 0.14, -0.12346392892821456, -0.03, 1.31, 0.03, -0.16, 0.32, 0.39, 0.31, -0.6, -0.51, 0.07, -0.3, 0.4, 0.07, 0.24, 0.53, -0.49, -0.29, 0.14, -0.98, 0.0, 0.8, 0.39, 1.04, -0.45, -1.15, 1.09, 1.17, -0.39, 0.82, -0.77, -0.95, 0.48, -0.57, -1.7, 0.42, 0.49, -0.07, -1.32, -1.26, -1.45, -0.98, -0.91, -0.98, -1.12, -0.06, -0.2, 0.29, 0.35, 0.28, 0.14, 0.48, 0.55, 0.48, -0.6772046485260771, -0.41, -0.34, 0.07, 0.0, -0.36, -0.36, -0.93, -0.87, -0.11, 0.85, 0.08, -0.59, -0.41, -0.07, -0.7999225974772194, -0.53, -0.2, -0.34, 0.07, -0.34, -1.41, 0.07, -0.28], ['251', -7.91, -0.4, -0.3487782843795412, 0.18, -2.26, -1.24, -0.32588474204017087, -1.05, -1.7, 0.8470884353741497, 2.84, 0.86, 1.59, 2.27, 0.97, 2.54, 0.71, 0.1, 3.72, 3.7, -0.57, 2.63, 2.04, 0.74, -2.16, -1.95, -2.37, -1.93, -1.22, -0.56, -1.82, -0.29, -2.07, -2.67, 0.85, 0.84, -3.319239316239316, -0.2, -0.78, -2.04, -0.28, -2.85, -0.250696767518196, 0.73, 1.4, 0.11, 1.67, -0.14, -0.75, 2.84, 2.82, -1.41, 1.76, 1.17, -0.11, -0.97, -0.75, -1.41, -1.62, -1.17, 0.66, -0.61, 0.94, -0.87, -1.47, 2.09, 2.08, -2.13, 1.02, 0.44, -0.84, -1.57, -1.82, -1.27, 0.27, -1.52, -2.12, 1.42, 1.4, -2.78, 0.36, -0.22, -1.49, -2.64, -4.67, 4.63, -0.56, 1.56, -0.25, -0.86, 2.72, 2.71, -1.53, 1.65, 1.06, -0.22, -3.37, -2.09, -1.79, -2.377880952380952, 1.14, 1.13, -3.04, 0.09, -0.49, -1.76, 0.13, -2.11, 0.73572371188304, -1.53, -1.32, -0.76, -0.31, -0.61, 2.98, 2.97, -1.28, 1.91, 1.32, 0.03, -1.99, 0.3, 3.61, 3.6, -0.67, 2.53, 1.94, 0.64, -1.59, -1.72, 0.19, -0.55, -6.78, -0.18, -0.01, 0.24, -0.23, -0.1, -3.25, -2.36, 6.18, 2.16, 1.1, -4.03, -1.4, -2.94, 3.07, 3.14, -1.07, 0.36, -2.14, -1.37, 0.68, -0.93, 6.33, 0.6, 0.9, -6.38, -3.19, -0.01, -4.13, -1.04, -1.62, -2.87, -3.31, -3.18, -4.1164625850340135, -1.03, -1.61, -2.85, 0.98, 3.22, 2.62, 1.32, -1.79, -2.03, -2.17, -0.58, -1.84, -1.03, -0.97, -1.28, 3.23, 0.5, -3.19, -1.4, -2.15, -1.6, -1.27, -1.03, -0.2, -1.51, -0.9897755102040815, -0.64, -0.34, -1.28, -1.68, 0.35], ['252', 5.65, 0.68, 0.26122171562045876, -0.15, 2.2929790809910595, 2.69, 1.7841152579598292, 2.9117205965359587, 2.09, 2.0, -2.82, 0.65, 0.04, -1.12, -1.77, 0.54, -1.52, 0.94, 2.6, -1.66, 2.947335482087359, -0.79, -1.45, -0.6, 0.23, 1.079371414588892, 4.96, 3.56, 2.94, 1.75, 1.08, 3.46, 1.33, 3.87, 5.57, 1.18, 5.89, 2.08, 1.41, 2.28, 1.96, 3.3549361992161733, 1.35, -0.6, -1.5921246055531768, -2.4, -0.1, -2.16, 0.29, 1.94, -2.3, 2.25, -1.43, -2.08, -1.24, -0.83, 0.46, -1.14, 1.47, 1.96, -1.16, -1.81, 0.5, -1.56, 0.9, 2.56, -1.7097619047619048, 2.87, -0.84, -1.49, -0.64, 4.3, 3.16, -0.65, 1.68, -0.41, 2.09, 3.76, -0.55, 4.08, 0.33, -0.33, 0.53, 3.26, 9.54, -9.47, 3.84, 2.35, 0.25, 2.76, 4.45, 0.1, 4.76, 0.99, 0.32, 1.19, 3.18, 1.527366531216563, -2.05, 0.4, 2.05, -2.2, 2.36, -1.33, -1.98, -1.13, 1.08, 1.48, 5.43, 2.76, 2.79, 2.78, 3.58, 2.5, 4.19, -0.15, 4.5, 0.74, 0.07, 0.94, 2.88, 1.05, 1.64, -2.58, 1.95, -1.5942004503433074, -2.37, -1.53, 3.6418280382942037, 3.59, 0.0, 3.26, 9.477952380952381, 0.32225133596562167, 0.09, -5.66, 5.67, 2.8688101710076213, 1.8, 4.3, -7.34, -5.59, -2.77, 2.88, 1.82, 8.460596861471862, -8.34, -8.28, 2.79, -8.56, 5.54, 5.0, -2.49, 10.64, -10.42, -7.14, -10.58, 7.36, -0.58, -4.16, 0.3, -3.31, -3.95, -3.12, 8.37, 3.73, 4.65, 0.89, 0.22, 1.09, -0.88, -3.6, -4.24, -3.41, 3.33, 3.55, 2.82, -0.66, 0.27224875531501636, 2.8, 2.874396301275291, 3.74, -5.39, 4.9, 5.41, 3.66, 3.85, 3.5, 0.86, 3.22, 2.82, 1.82, 1.91, 1.96, 2.61, 4.87, 4.73, 2.56], ['253', -0.16, 0.15, 0.05122171562045875, -0.24, 0.28, 0.91, 0.82, 1.65, 0.8, 2.54, 1.83, 1.92, 1.76, 1.08, -0.33, 2.92, 1.91, 2.78, 3.06, 1.33, 2.387335482087359, 2.0, 1.52, 1.59, -0.2, 0.6, 0.7, 0.09, -0.07, -0.74, -2.12, 1.07, 0.08, 0.93, 1.21, -0.49, 0.51, 0.17, -0.31, -0.23, 1.73, 1.68, 0.61, -0.15, -0.82, -2.21, 0.97, -0.01, 0.84, 1.12, -0.58, 0.448065468086443, 0.08, -0.4, -0.32, 1.4, -0.08, 1.43, 1.03, 0.76, -0.67, -2.06, 1.13, 0.15, 1.0, 1.28, -0.43, 0.58, 0.24, -0.24, -0.17, 0.8, 1.44, -1.4, 1.81, 0.83, 1.68, 1.96, 0.24, 1.26, 0.91, 0.43, 0.51, 0.94, 3.3, -3.29, 2.88, 3.26, 2.26, 3.13, 3.41, 1.67, 2.7, 2.35, 1.86, 1.93, -1.51, -0.2826334687834371, -0.97, -0.13, 0.14, -1.54, -0.55, -0.88, -1.36, -1.29, -0.13, -0.34, 2.46, 0.92, 0.82, 1.17, 0.61, 0.85, 1.13, -0.58, 0.43, 0.09, -0.39, -0.26141531611693436, 0.36, -0.24, 0.5236855802927234, -1.41, -0.42, -0.76, -1.23, -1.16, 0.97, 1.279561224489796, -0.41, 2.34, -4.36, -0.4, 0.07, -2.71, 2.63, 1.37, -0.2, 0.61, -2.2, -1.82, -0.89, -0.13, 0.07, 2.76, -2.77, -2.79, 0.93, -4.22, 1.82, 1.09, -0.8, 1.84, -8.55, -1.25, -1.9, 2.3, -0.51, -1.68, -0.69, -1.03, -1.5, -1.43, 2.76, 1.2, 1.01, 0.67, 0.19, 0.26, 0.18, -0.34, -0.82, -0.74, 0.78, 0.89, 0.52, -0.48, -0.4, 0.91, 1.0, 1.45, -5.81, 2.72, 5.46, 1.75, 0.29, 1.01, 0.07, 1.59, 1.56, 0.01, -0.79, 0.64, 0.93, 3.26, 0.28, 1.41], ['254', -1.08, 0.0, 0.13122171562045873, -0.11, -0.04, 0.9484196236737595, 2.82, 0.25, 0.8, -0.95, -1.66, -2.95, -0.9, -0.04, -1.01, 0.3, -2.31, -0.95, -0.5341378641200069, -1.37, -0.9, -2.01, -1.5, -1.97, -0.24, 0.54, 0.72, -1.31, 0.7714285714285715, 1.64, 0.66, 1.99, -0.66, 0.72, 0.96, 0.29, 0.77, -0.35, 0.16, -0.32, 0.81, 0.8649361992161734, 2.06, 2.11, 3.167875394446823, 2.0, 3.35, 0.66, 2.06, 2.31, 1.62, 2.11, 0.97, 1.5, 1.01, -0.19, 1.05, 0.15, 0.37, -0.05, 0.87, -0.1, 1.21, -1.42, -0.05, 0.3086780045351474, -0.48, 0.0, -1.11, -0.5972652545866831, -1.08, 0.64, -0.91, -0.96, 0.34, -2.27, -0.91, -0.67, -1.33, -0.86, -1.97, -1.46, -1.93, 0.79, 2.12, -2.18, 0.06, 1.31, -1.32, 0.06, 0.3, -0.37, 0.1, -1.01, -0.5, -0.97, -2.73, -1.24, -2.6, -1.24, -1.0, -1.67, -1.2, -2.3, -1.79, -2.26, 0.02, -1.25, 0.39, 0.8115981806829015, 0.74, 0.8656735186500321, 1.39, 1.39, 1.64, 0.96, 1.6157782534925393, 0.31, 0.83, 0.35, 0.97, 0.0, 0.24, -0.43, 0.05, -1.07, -0.55, -1.03, 0.98, 1.14, -0.12, 0.93, -8.11, 0.2, 0.03, -1.71, 1.74, 0.89, 1.25, 0.78, -0.77, -1.52, -0.76, -0.52, 0.51, 2.23, -2.42, -2.28, 0.77, -2.57, 1.56, -0.56, 0.26, 4.13, -0.68, -2.66, -4.09, 0.86, -0.24, -0.67, -0.2, -1.31, -0.79, -1.27, 2.3, 0.43, 0.48, -0.64, -0.12, -0.6, -0.05, -1.11, -0.6, -1.08, 0.77, 0.5, 1.08, 0.52, 0.04, 0.76, 0.81, 0.06257604962387836, -0.59, 0.7, 0.72, 0.42, 0.69, 0.56, -0.48, 1.18, 0.85, 0.34, 0.66, 0.66, 1.04, 0.42, 0.9, 0.73], ['255', -1.19, -0.12, 0.06, 0.26, 0.17, 0.63, -0.1, 1.07, 0.92, 0.61, 0.41, -1.07, -0.6160867348791511, -0.74, 0.08, 1.41, -0.4, 0.2, -0.29, 0.22, 0.88, -0.84, -0.09, -0.44, 2.45, 1.26, 0.19, -1.48, -1.09, -1.15, -0.33, 0.99, -0.81, -0.21, -0.7, -0.19, 0.46, -1.24, -0.5, -0.85, 1.17, 0.8749361992161734, 1.69, 0.3936589811608609, 0.49787539444682316, 1.16, 2.5, 0.67, 1.28, 0.79, 1.3, 1.97, 0.23, 0.99, 0.9508287981859411, 0.4, 1.46, -0.11, 0.75, 1.29, -0.06, 0.77, 2.1, 0.28, 0.89, 0.4, 0.91, 1.57, -0.16, 0.6, 0.25, -0.2, 1.35, 0.83, 2.16, 0.34, 0.95, 0.45, 0.97, 1.63, -0.1, 0.65, 0.3, 0.37, 2.35, -2.36, 0.52, 1.32, -0.49, 0.12, -0.37, 0.14, 0.8, -0.92, -0.17, -0.4659922724755494, -0.88, -0.79, -1.78, -1.19, -1.67, -1.17, -0.52, -2.21, -1.47, -1.82, 0.58, -0.81, 2.84, 0.73, 0.8, 0.7, 1.0109570400359875, 0.61, 0.12, 0.63, 1.29, -0.43, 0.32, 0.028584683883065676, 1.73, 0.4, -0.49, 0.02, 0.68, -1.04, -0.29, -0.64, 0.58, 0.71, 0.49, 1.19, -2.65, 0.88, 1.06, -1.27, 1.29, 0.64, 3.67, 1.3561635321120495, -0.7, -1.43, -0.74, -0.6, 0.81, 2.13, -2.2, -2.16, 0.72, -1.89, 1.43, -1.94, 1.0, 2.96, -4.49, -1.97, -2.98, 0.6738095238095239, 0.89, 0.51, 1.17, -0.55, 0.2, -0.15, 2.16, 0.38, 0.66, -1.06, -0.31, -0.66, -0.27, -1.6111214088935784, -0.96, -1.3, 0.87, 0.45, 1.45, 0.75, 0.4, 0.72, 0.79, 1.24, -2.97, 2.49111637918067, 2.9, 0.83, 0.71, 0.69, -0.27721314850306833, 0.84, 0.62, 0.59, 0.88, 0.77, 1.04, 0.73, 0.79, 1.06], ['256', -7.27, -1.02, -0.37, 0.21, -1.48, -1.52, -1.91, -3.6, -3.27, -4.18, 0.45, -3.2, -1.27, -0.59, -0.28, -2.25, -2.18, -3.35, -4.17, -2.46, -4.67, -3.09, -1.72, -2.63, -3.61, -2.76, -4.61, -3.63, -1.71, -1.04, -0.73, -2.69, -2.62, -3.78, -4.61, -2.9, -5.1, -3.53, -2.16, -3.07, -3.5, -4.755063800783826, -1.01, 1.99, 2.69, 3.01, 0.98, 1.05, -0.15, -1.01, 0.76, -1.491934531913557, 0.11, 1.53, 0.59, -2.03, -3.57, -2.68, -3.36, -2.95, 0.69, 1.0, -0.99, -0.92, -2.11, -2.95, -1.21, -3.45, -1.85, -0.46, -1.38, -3.32, -3.61, 0.31, -1.67, -1.6, -2.77, -3.61, -1.88, -4.11, -2.52, -1.14, -2.05, -4.56, -6.54, 6.47, -3.9, -1.97, -1.9, -3.07, -3.9, -1.996255228898086, -4.4, -2.82, -1.44, -2.35, -2.85, -1.97, 0.07, -1.0246649659863944, -1.97, -0.22, -2.48, -0.87, 0.54, -0.39, -1.11, -2.04, -2.78, -1.56, -1.72, -1.49, -2.04, -1.19, -2.04, -0.29, -2.55, -0.94, 0.47, -0.46, -1.2, -0.8069232518696328, -0.86, 0.92, -1.37, 0.26, 1.68, 0.74, -2.54, -2.5, -0.21, -1.88, -8.44, -0.98, -0.63, 2.16, -2.24, -1.12, -1.07, -5.74, 3.35, 3.03, 1.53, -3.64, -0.8, -4.78, 4.65, 4.67, -1.56, 3.32, -3.12, -2.53, 1.25, -6.04, 5.28, 4.1, 6.07, -3.2, 0.0, 1.79, -0.52, 1.13, 2.56, 1.61, -4.67, -1.76, -2.27, -0.65, 0.76, -0.17, 0.52, 1.65, 3.1, 2.14, -3.17, -3.81, -1.12, 1.42, 0.48, -1.4379199656859432, -1.62, -3.63, 6.82, -2.82, -6.95, -2.02, -1.92, -2.5, -0.93, -2.24, -0.9954471401614257, -0.78, -0.51, -1.42, -1.59, -2.66, -2.21, -1.32], ['257', -5.73, -0.83, -0.45, 0.1, -1.32, -1.69, -1.2458847420401709, -2.91, -2.54, -2.4, 0.27, -0.36, 0.55, 1.45, -0.22, -1.9, 0.33, -1.39, -3.76, -0.94, -3.5, -0.19, -0.09, -0.86, -3.15, -2.61, -2.66, -0.63, 0.28, 1.18, -0.48, -2.16, 0.07, -1.5327410958555914, -4.01, -1.2, -3.75, -0.46, -0.35, -1.12, -1.51, -3.8350638007838267, -2.05, 0.91, 1.82, 0.15, -1.54, 0.7, -1.03, -3.41, -0.57, -3.14, 0.17, 0.28, -0.5, -1.0, -2.7557142857142853, -3.76, -2.4, -2.93, 0.9, -0.76, -2.43, -0.21, -1.93, -3.990306689342404, -1.47, -4.02, -0.73, -0.63, -1.4, -3.9, -3.8, -1.65, -2.8633418367346937, -1.1, -2.8, -5.13, -2.35, -4.88, -1.62, -1.52, -2.28, -3.31, -6.68, 6.73, -2.19, -1.68, 0.55, -1.17, -3.55, -0.72, -3.28, 0.03, 0.13, -0.5859922724755494, -2.19, -0.51, 2.28, 0.52, -1.89, 0.98, -1.63, 1.74, 1.84, 1.06, -1.25, -0.53, -3.5198953488372093, -1.78, -1.83, -1.79, -2.73, -1.72, -4.08, -1.27, -3.82, -0.52, -0.42, -1.19, -2.13, -1.03, -2.4, 0.46, -2.14, 1.21, 1.32, 0.54, -2.89, -3.06, -0.54, -2.41, -4.28, -1.3, -1.1, 3.72, -3.59, -1.82, -1.84, -1.53, 2.93, 3.54, 1.8645476190476191, -2.89, -1.28, -5.52, 5.42, 5.34, -1.75, 5.49, -3.52, -1.78, 0.87, -8.16, 5.32, 5.52, 8.18, -3.0, 1.41, 2.93, 0.27, 3.7, 4.129638579674294, 3.01, -5.39, -1.48, -2.59, 0.75, 0.85, 0.08, 1.13, 3.42, 3.53, 2.8014285714285716, -2.57, -2.75, -2.21, 0.1, -0.67, -1.8, -1.94, -2.82, 2.69, -2.89, -2.68, -2.13, -2.56, -2.32, -0.77, -2.07, -2.02, -0.87, -1.39, -1.05, -1.56, -4.3, -3.9, -2.05], ['258', 1.72, 0.12, 0.73, 0.4, 0.21, 1.69, -0.18, 0.39, 1.69, -0.98, -3.69, -0.62, -1.3, -2.3, -1.0, 0.06856009070294794, -1.85, -0.92, -0.1, -2.12, -0.8426645179126411, -1.66, -1.05, -2.67, 0.84, 0.28, 2.8526583949931124, 3.18, 2.48, 1.44, 2.79, 3.5733503401360545, 1.91, 2.87, 3.72, 1.63, 2.9844536700785693, 2.11, 2.74, 1.06, 1.07, 3.2349361992161736, -0.35, -0.68, -1.68, -0.38, 0.46052947845804987, -1.23, -0.3, 0.52, -1.51, -0.23193453191355703, -1.04, -0.43, -2.06, 0.42, 1.66, -0.98, 2.4, 0.33, -1.01, 0.3, 1.27, -0.56, 0.38, 1.21, -0.83, 0.42, -0.36, 0.25, -1.39, -1.42, 1.35, 1.33, 2.1, 0.46, 1.41, 2.25, 0.18, 1.45, 0.66, 1.28, -0.38, 3.42, 0.21, -0.27, 0.03, 0.76, -0.85, 0.08, 0.91, -1.13, 0.12, -0.66, -0.05, -1.69, -1.04, -0.73, -1.6, -0.67, 0.15, -1.88, -0.63, -1.41, -0.8, -2.43, -0.21, -0.81, 0.95, 1.27, 0.93, 1.59, 0.89, 0.94, 1.8869325674325674, -0.28, 1.1557782534925394, 0.19, 0.81, -0.84, 0.53, -0.05, 0.83, -1.21, 0.04, -0.74, -0.13, -1.76, -0.78, -1.71, 0.77, 0.79, -2.44, 1.44, 0.73, -2.78, 2.67, 1.34, 0.51, 1.11, -2.3222410208838777, -2.61, -1.3, 0.82, 0.92, 3.67, -3.78, -3.77, 1.24, -4.32, 2.46, -3.33, 1.8, 2.46, -4.47, -1.82, -2.84, 2.45, -0.87, -2.0151904761904764, -0.78, -1.56, -0.95, -2.57, 3.7, 1.17, 1.27, 0.47, 1.09, -0.56, -0.09, -0.78, -0.17, -1.8, 1.85, 2.32, 0.69, 0.62, -1.03, 1.29, 1.2, 0.26, -2.25, 1.85, 2.27, 1.2, 1.49, 0.08, -1.5672131485030683, 2.27, 1.06, 1.48, 0.18, 1.444626243824729, 1.74, 1.48, 1.22, 0.7], ['259', -0.46, 0.26, 0.16, 0.06, 0.48, 0.61, 0.6941152579598292, 1.23, 0.29, 0.11, -0.13, -0.54, -1.35, -0.69, -1.08, 0.58, 0.09, 0.06, -1.97, -1.29, 0.15, -0.64, -0.38, -0.17, 0.11, 0.43, 0.27265839499311245, -0.41, -1.23, -0.56, -0.95, 0.72, 0.22, 0.30725890414440843, -1.84, -1.16, 0.28, -0.51, -0.25, -0.04, 1.47, -1.25, 0.66, -0.82, -0.15, -0.55, 1.13, 0.63, 0.61, -1.44, -0.75, 0.69, -0.1, 0.16, 0.37, 1.23, 1.06, 1.03, 0.17, 1.49, 0.68, 0.28, 1.96, 1.47, 1.44, -0.62, 0.07, 1.52, 0.72, 0.99, 1.2, 1.39, 0.8, -0.3853571428571429, 1.28, 0.78, 0.76, -1.29, -0.61, 0.84, 0.04, 0.31, 0.52, -0.14, 1.5, -1.5, 1.2466982383853202, 1.68, 1.19, 1.16, -0.89, -0.21, 1.24, 0.44, 0.71, 0.92, -1.22, -0.47, -0.49, -0.52, -2.54, -1.86, -0.43, -1.22, -0.96, -0.75, 0.12, -0.45, -0.33, 0.58, 0.58517906963434, 0.59, 0.02, -0.03, -2.06, -1.3794642857142856, 0.06, -0.74, -0.47, -0.20141531611693433, 0.69, 0.05, -2.03, -1.35, 0.08, -0.71, -0.45, -0.24, 0.3, 0.11, 0.02, 0.33, -3.64, 0.05, 0.04, -0.87, 0.9, 0.48, 0.72, -0.33, -2.8, -1.16, -0.61, -0.22, 0.68, 1.79, -1.85, -1.79, 0.58, -1.46, 1.16, -0.27, 0.14, 0.12, -3.6, -0.09, -0.1, 2.84, 2.12, 0.69, 2.166609977324263, 1.35, 1.62, 1.83, 1.913167899560757, 1.42, 1.45, 0.65, 0.92, 1.13, -0.04, -0.79, -0.53, -0.32, 0.29, 0.19, 0.76, 0.26, 0.48, 0.59, 0.57, 1.07, -1.98, 0.0, 2.15, 0.41, 0.8, 0.5, 0.21, 0.41, 0.58, 0.76, 0.68, 1.05, 0.29, -0.35, 0.85, -0.33], ['260', -3.6, -0.96, 0.04, 0.04, -1.18, -0.75, -0.63, -1.7382794034640414, -0.99, -2.15, -0.63, -2.0, -0.9860867348791511, -0.04, -0.4, -0.86, -1.06, -1.67, -2.43, -0.36, -2.21, -1.29, -1.87, -1.17, -0.56, -1.29, -1.4973416050068875, -1.38, -0.42, 0.6, 0.24, -0.22, -0.43, -1.04, -1.81, 0.27, -1.58, -0.66, -1.25, -0.54, -1.2525315746467893, -0.74, -0.15, 0.97, 2.0, 1.64, 1.17, 0.96, 0.34, -0.438347866419295, 1.67, -0.20034527076293904, 0.73, 0.14, 0.85, -1.08, -0.4, -0.36, -1.74, -1.11, 1.02, 0.66, 0.2, -0.01, -0.62, -1.39, 0.7, -1.17, -0.24, -0.83, -0.12, -1.14, -2.11, -0.36, -0.81, -1.02, -1.63, -2.39, -0.32, -2.17, -1.25, -1.83, -1.13, -1.4, -1.02, 1.03, -1.759129077338006, -0.46, -0.67, -1.27, -2.04, 0.03, -1.82, -0.9, -1.48, -0.77, -2.02, -1.31, -0.21, -0.82, -1.59, 0.5, -1.36, -0.44, -1.02, -0.31, -0.37, -1.4, 0.13, -0.82, -0.81, -0.9, -1.1, -0.61, -1.38, 0.9097126881055455, -0.9842217465074605, -0.23, -0.82, -0.051415316116934326, -0.85, -0.49, -0.78, 1.33, -0.55, 0.38, -0.21, 0.51, 0.4418280382942037, 0.35, -0.21, -1.04, -6.03, -0.01, -0.01, 1.54, -1.51, -0.74, -0.09, -3.42, 3.42, 1.73, 0.79, -1.77, -0.686920210131221, -2.57, 2.56, 2.38, -0.83, 2.39, -1.65, 0.15, -0.025234735715753215, -3.22, 16.43, 2.14, 3.26, -3.49, 0.29, 2.12, 0.23, 1.17, 0.58, 1.3, -2.51, -1.79, -1.85, -0.93, -1.51, -0.81, 0.06, 0.94, 0.34, 1.06, -0.98, -1.27, -0.87, -0.59, 0.12, -0.84, -0.8856036987247091, -1.71, 7.56, -0.51, -7.100719387755102, -1.82, -1.68, -0.28, 0.72, -1.54, -0.62, -0.35, -1.03, -0.56, -0.99, -2.3, -2.67, -1.41], ['261', -0.15, 0.18, 0.15122171562045875, -0.08, 0.06297908099105959, 0.47, -1.1458847420401708, 0.46, 0.58, 1.09, 0.2, 1.54, 1.1, 0.65, 0.6, 1.15, 0.59, 0.69, 2.03, 0.48, 1.497335482087359, 0.46, 0.24, 0.69, 0.25, 0.57, 0.88, 1.3305454545454547, 0.89, 0.45, 0.4578199712950912, 0.95, 0.38, 0.48, 1.82, 0.28, 1.25, 0.25, 0.03, 0.48, 0.25, 1.5, -0.44, -0.43, -0.87, -0.92, -0.38, -0.93, -0.83, 0.48, -1.04, -0.08, -1.06, -1.28, -0.84, 0.48, 0.43, 0.44, 0.93, -0.01, -0.44, -0.3751532320595474, 0.06, -0.5, -0.4, 0.92, -0.6, 0.36, -0.63, -0.85, -0.4, 0.24, 0.43, -0.05, 0.5, -0.07, 0.04, 1.36, -0.17, 0.8, -0.19, -0.42, 0.08355964172512072, 1.49, 2.18, -2.1, 0.48, 0.55, -0.02, 0.08, 1.41, -0.12, 0.85, -0.15, -0.37, 0.08, 0.55, -0.07, -0.56, -0.46, 0.86, -0.66, 0.3, -0.69, -0.91, -0.46, 0.25, -0.14, 4.1, 0.26, 0.56517906963434, 0.04567351865003196, 0.5, 0.1, 1.43, 0.09971268810554554, 0.86, -0.06969498055271243, -0.35, 0.1, 0.51, 0.39, 1.5836855802927234, -0.2, 0.76, -0.23, -0.45, 0.0, 0.74, 0.56, -0.18, 0.38, 1.56, 0.09, 0.06, 0.44, -0.47, -0.24, 0.53, 0.16, -1.19, -0.52, -0.27, -0.07, 0.19, 0.74, -0.72, -0.77, 0.30329080486385296, 0.7, 0.5, 0.62, -0.32, 1.44, -2.37, -1.02, -1.31, 1.16, -0.92, -1.51, -0.56, -1.54, -1.76, -1.31, 0.7508051948051948, 0.6, 0.97, -0.03, -0.25, 0.2, -0.36, -0.98, -1.2, -0.76, 0.61, 1.12, 0.62, -0.22, 0.23, 0.27, 0.26, 0.34, -0.91, 3.06, 0.88, 0.15, 0.36, 0.85, 0.45, 0.49, -0.07, -0.01, 0.34, 0.15462624382472906, 0.4, 0.7, -0.47, 0.0], ['262', -0.8, -0.03, -0.05, -0.01, -0.45, -0.42, -0.44, -0.1, 0.3, 0.0, -0.66, 0.5593248299319729, 0.29, 0.28, 0.28, 0.17, 0.13, 0.01, -1.24, 0.06, 0.17, -0.42, -0.13, 0.34, -0.46, -0.1, 0.66, 1.21, 0.9708333333333333, 0.94, 0.95, 0.84, 0.79, 0.67, -0.59, 0.72, 0.83, 0.24, 0.53, 1.01, -0.16, 1.04, -0.55, -0.2563410188391391, -0.27, -0.26, -0.37, -0.42, -0.53, -1.78, -0.49, -0.37, -0.96, -0.67, -0.20495238095238094, 0.54, -0.07, 0.04, 0.06, -0.29, -0.01, 0.0, -0.11, -0.16, -0.27, -1.52, -0.23, -0.11, -0.7, -0.41, 0.05, -0.67, -0.27, 0.01, -0.1, -0.14, -0.26, -1.51, -0.22, -0.1, -0.69, -0.4, 0.07, 0.82, 0.33174294752866196, -0.17, -0.28, -0.11, -0.15, -0.27, -1.52, -0.23, -0.11, -0.7, -0.41, 0.06, -0.98, -0.17, -0.04, -0.16, -1.41, -0.12, 0.06262653735269351, -0.59, -0.3, 0.17, 0.1, -0.17, 0.41, -0.14, 0.0, -0.21, -0.13, -0.12, -1.37, -0.07, 0.04, -0.55, -0.26, 0.26858468388306567, 0.5, -0.01, -1.25, 0.05, 0.16, -0.43, -0.14, 0.33, 0.13, 0.14, 0.02, 0.22, -2.79, 0.05, -0.01, 0.36, -0.4, -0.19, 0.66, 0.07, 0.17, 0.35, 0.2, -0.39, 0.02, -0.45, 0.53, 0.49, -0.15, 0.57, -0.39, 0.05, -0.02, -0.39, 1.3, 0.11, 0.34, -0.14, 1.25, 1.31, 1.43, 0.83, 1.12, 1.6, -0.56, -0.06, 0.11, -0.48, -0.19, 0.28, -0.17, -0.59, -0.3, 0.17, 0.18, 0.5, 0.42, 0.29, 0.76, -0.16, -0.14, -0.19, 0.68, 0.0, -0.77, -0.87, -0.2, 0.13, 0.47, -0.26, -0.26, -0.21, 0.17, 0.2, -0.34, -1.08, 0.14, -0.64], ['263', -0.06, 0.04, 0.00015289830927053559, -0.09, 0.0, 0.22, 0.57, -0.38, -0.1, -0.84, -0.79, -1.32, -0.4, 1.14, -0.54, -0.47, -1.49, -1.01, -2.51, 0.06, -1.02, -1.0, -1.2, -1.42, 0.02, -0.05, -0.017341605006887542, -0.53, 0.39, 2.09318993704708, 0.25, 0.32, -0.71, -0.22, -1.73, 0.85, -0.23, -0.21, -0.41, -0.63, 0.2, -0.09, 0.49, 0.93, 2.5, 0.79, 0.86, -0.17, 0.31, -1.2, 1.4, 0.31, 0.32, 0.12, -0.1, -0.27, 0.69, 0.16, -0.12, -0.43, 1.6531047225355606, -0.14, -0.07, -1.09, -0.61, -2.11, 0.46, -0.62, -0.6, -0.8, -1.02, 0.76, -1.96, -1.67, -1.6, -2.6, -2.13, -3.61, -1.07, -2.14, -2.12, -2.31, -2.53, -0.46, 1.02, -0.96, -0.3, 0.07, -0.96, -0.47, -1.98, 0.6, -0.48, -0.46, -0.66, -0.88, -0.55, -0.36, -1.02, -0.54, -2.04, 0.53, -0.55, -0.53, -0.73, -0.95, 0.11, -0.31, 0.84, 0.28, 0.3, 0.24, 0.66, 0.4913469387755102, -1.03, 1.57, 0.48, 0.5, 0.3, 0.07, 0.2, 0.18, -1.51, 1.08, -0.01, 0.01, -0.19, -0.41, 0.89, 0.97, -0.25, 0.23, -1.4, 0.19, 0.06, -0.5, 0.48, 0.26, 0.6, -0.94, 1.57, -0.5, -0.24, -0.05, 0.25, 0.7914761904761906, -0.86, -0.84, 0.29, -0.71, 0.56, 1.0, -0.49, 1.96, -2.68, -1.18, -2.0, -1.66, 1.71, 2.63, 1.53, 1.55, 1.35, 1.12, 0.84, -0.89, -1.08, -1.06, -1.25, -1.48, 0.18, 0.02, -0.18, -0.41, -0.07, -0.22, 0.16, -0.2, -0.42, 0.3620800343140569, 0.33, -0.32, -1.81, 0.86, 1.81, 0.51, -0.44, 0.36, -0.23, 0.22, 0.42, 0.06, 0.01, 0.65, 0.675957527023814, -0.46, -0.52, 0.62], ['264', -3.75, -0.57, -0.22877828437954126, -0.34, -0.34, -0.03, -2.21, -1.33, -1.58, -2.004642857142857, -0.939391156462585, -0.15, -2.23, 0.58, -0.40285714285714286, -0.64, -2.02, -1.53, -1.47, -1.47, -2.54, -1.5, -1.635694768399324, -2.2, -1.64, -0.93, -1.0973416050068874, 0.81, -1.29, 1.55, 0.54, 0.31, -1.08, -0.59, -0.53, -0.53, -1.61, -0.56, -0.79, -1.27, -0.6, -1.9, -1.92, -2.08, 0.73, -0.27, -0.49, -1.87, -1.38, -1.2228644435138796, -1.33, -2.39, -1.36, -1.58, -2.06, -0.74, -2.03, -0.29, -1.31, 0.16, 2.88, 1.85, 1.62, 0.21, 0.72, 0.770952380952381, 0.77, -0.32, 0.74, 0.51, 0.02, -0.58, -2.64, -0.99, -1.22, -2.59, -2.1, -2.04, -2.05, -3.1, -2.08, -2.3, -2.77, -1.71, -1.01, 0.98, -1.66, -0.23, -1.61, -1.12, -1.06, -1.06, -2.13, -1.09, -1.31, -1.8, -2.23, -1.43, -1.38, -0.89, -0.83, -0.84, -1.91, -0.87, -1.09, -1.57, -0.58, -1.38, -0.04, -0.16, -0.27, 0.055673518650031964, -0.05, 0.5, 0.56, 0.55, -0.53, 0.52, 0.3, -0.19, -0.5, -0.55, 0.06, 0.05, -1.03, 0.02, -0.2, -0.69, -0.38, -0.36, -0.6, 0.08, -6.66, -0.52, -0.47, -0.13, 0.16246232339089484, 0.11881017100762112, -1.5, -1.85, 1.16, 0.37, 0.19, -1.87, -0.036920210131220946, -0.48, 0.58, 0.52, -0.16, -0.19, -0.34, 2.13, -1.02, -0.14, 0.38, 0.11, 0.18, -1.19, -0.6, 0.0, -1.08, -0.03, -0.26, -0.74, -0.55, -0.6, -1.08, -0.03, -0.25, -0.74, 0.48, 1.06, 0.83, 0.34, -1.57, -1.55, -0.57, -0.22, -0.71, -0.18, -0.15, -1.2874239503761218, 0.27, 0.42, -0.26, -0.35, -0.4989064979199875, -0.35, -0.49, 0.3, 0.19, -0.83, 0.55, -0.445373756175271, 0.14, -1.09, -0.57, 0.69], ['265', 4.4, -1.33, -0.08, 0.23, 0.78, -1.25, -3.27, -1.87, -2.29, -0.86, 1.95, 0.47, -0.43, 1.74, 1.46, -1.64, 0.63, -0.66, -2.73, 0.51, -1.08, 0.6, 1.29, 0.58, -2.13, -1.38, -2.76, -1.45, -2.33, -0.2, -0.48, -3.52, -1.29, -2.56, -4.59, -1.41, -2.895546329921431, -1.33, -0.64, -1.34, -1.56, -4.855063800783826, -1.33, -0.9, 1.27, 0.99, -2.1, 0.16, -1.12, -3.19, 0.04071428571428572, -1.511934531913557, 0.12, 0.82, 0.11, -0.89, -1.69, -2.05, -1.69, -0.43, 2.18, 1.9, -1.21, 1.06, -0.23, -2.31, 0.94, -0.65, 1.03, 1.73, 1.01, -3.28, -2.56, -0.28, -3.32, -1.09, -1.9206972789115644, -4.4, -1.21, -2.78, -1.13, -0.44, -1.15, -3.33, -5.71, 5.69, -2.29, -3.05, -0.82, -2.09, -4.13, -0.94, -2.5, -0.85, -0.17, -0.87, 1.52, 0.79, 2.31, 1.0, -1.11, 2.18, 0.57, 2.27, 3.121108978323264, 2.25, -0.27, 0.78, -1.05, -1.6, -1.66, -1.55, -1.48, -1.28, -3.34, -0.12, -1.7, -0.03, 0.66, 0.008584683883065672, -0.66, -0.2, -2.09, 1.17, -0.42, 1.26, 1.96, 1.24, -2.36, -1.81, 0.2, -1.89, 4.69, 0.03, -0.14, 3.75, -3.71, -1.86, -0.37, -1.57, 2.96, 3.19, 1.61, 2.18, -0.74, -4.9, 4.99, 4.81, -1.6, 5.51, -3.2, -2.7, 1.32, -4.4, 7.27, 2.88, 4.38, -2.85, 1.92, 3.33, 1.7, 3.42, 4.14, 3.4, -4.78, -1.36, -1.58, 0.09, 0.78, 0.07, 0.22, 1.69, 2.4, 1.68, -2.21, -2.72, -1.45, 0.69, -0.02, -2.17, -2.12, -1.79, 7.19, -1.36, -6.3186904761904765, -1.26, -2.57, -2.13, -0.71, -1.73, -1.9, -0.63, -0.32, -1.16, -1.43, -2.44, -2.91, -1.61], ['266', 3.93, 0.24, 0.13122171562045873, 0.04, 0.36, 0.03, 0.76, 0.1, -0.09, 1.68, 1.4, 1.07, 1.61, 1.53, 1.01, 1.39, 1.8, 1.78, -0.45, 1.8, 1.807335482087359, 1.54, 2.2843052316006762, 1.54, -0.07, 0.07, 0.3126583949931125, -0.33, 0.21, 0.13, -0.3321800287049088, -0.01, 0.39, 0.4872589041444084, -1.82, 0.4, 0.37, 0.14, 0.78, 0.14, -0.2, -0.98, 0.61, 0.54, 0.46, -0.06, 0.32, 0.72, 0.7, -1.5, 0.73, 0.7280654680864429, 0.47, 1.11, 0.47, -0.33, -0.88, -0.51, -0.54, 0.07, -0.08, -0.6, -0.22, 0.18, 0.16, -2.03, 0.19, 0.16, -0.07, 0.57, -0.07, -0.27, 0.15, -0.52, -0.14, 0.26, 0.24, -1.95, 0.26, 0.24, 0.01, 0.65, 0.0, -0.18, -0.99, 1.14, 0.7066982383853202, 0.38, 0.78, 0.76, -1.44, 0.79, 0.76, 0.53, 1.17, 0.53, 0.48, 0.29, 0.4, 0.38, -1.81, 0.4, 0.38, 0.15, 0.79, 0.14, -0.11, 0.25, -0.68, -0.2184018193170985, -0.08, -0.36, -0.11, -0.02, -2.2, 0.0, -0.02, -0.25, 0.38, -0.26, 0.02, -0.09, -2.18, 0.11224471370562701, 0.0, -0.23, 0.41, -0.23, 0.04, 0.28, -0.06, -0.01, 1.67, -0.1, -0.07, 1.44, -1.47, -0.6911898289923789, -0.34, 0.74, 0.18, 0.53, 0.27, 1.92, 0.12, -0.84, 0.72, 0.82, -0.27, 2.18, -0.55, 0.12, -0.07, -0.31, -1.3, 0.24, 0.33, -0.2, 2.14, 2.26, 2.23, 2.0, 2.65, 1.99, -0.7168321004392431, -0.12, -0.03, -0.25, 0.38, -0.26, -0.09, -0.23, 0.41, -0.23, -0.06, -0.28, 0.13, 0.63, 0.06224875531501633, -0.25, -0.23, 0.19, -0.57, -0.36, 0.65, -0.03, -0.33, -0.5, -0.64, 0.09, -1.0, 0.33, -0.01, 0.22, 0.14, -0.6, -0.16, -0.05], ['267', -2.43, -0.79, 0.15, 0.26, -0.7, -1.27, -1.1758847420401708, -1.75, -1.94, -1.62, 1.62, -0.68, -1.3, 0.19, -0.16, -0.77, -0.77, -1.32, 5.65, 0.07, -1.92, -0.99, 0.03, -1.3178253968253968, -0.7214063389924734, -0.99, -3.18, -2.26, -2.87, -1.41, -1.75, -2.35, -2.35, -2.89, 3.97, -1.52, -3.48, -2.57, -1.57, -2.89, -0.8125315746467892, -5.31, -0.95, -0.63, 0.87, 0.52, -0.09, -0.09, -0.65, 6.37, 0.75, -1.25, -0.32, 0.71, -0.65, -0.8499371536943234, -0.99, -1.07, -1.49, -0.32, 1.51, 1.15, 0.54, 0.54, -0.02, 7.040952380952381, 1.39, -0.63, 0.31, 1.34, -0.02, -2.6, -1.8, -0.35, -0.95, -0.96, -1.51, 5.45, -0.12, -2.1, -1.18, -0.16, -1.51, -3.79, -4.41, 4.422833333333334, -1.46, -0.61, -0.61, -1.16, 5.83, 0.23, -1.76, -0.83, 0.19, -1.16, 0.54, -0.86, 0.0, -0.56, 6.47, 0.84, -1.16, -0.23, 0.8, -0.56, -0.53, -0.84, 1.19, -1.29, -1.53, -1.04, -0.85, -0.55, 6.47, 0.85, -1.16, -0.22, 0.8, -0.56, -0.64, -0.3, 7.07, 1.41, -0.61, 0.33, 1.36, 0.0, -1.9, -1.68, 0.13, -1.21, 2.12, -0.01, 0.0, 1.74, -1.75, -0.88, -0.61, -1.98, 3.2, 2.58, 1.34, -1.21, -1.18, -3.92, 3.9, 4.0, -1.28, 2.61, -2.61, -1.9, 0.94, -2.62, 5.18, 1.74, 2.6, -3.2, -6.88, -5.29, -7.17, -6.29, -5.33, -6.6, -3.98, -1.69, -1.99, -1.06, -0.04, -1.39, 0.756501700680272, 0.94, 1.98, 0.61, -1.83, -2.46, -0.63, 1.03, -0.33, -1.29, -1.23, -1.72, 2.55, -0.04, -2.45, -1.92, -2.39, -1.64, -1.2772131485030684, -1.26, -1.1297802197802196, -1.02, -1.23, -1.35, -0.3, -2.74, -4.03, -1.3], ['268', 0.39, -0.19, 0.04, 0.19, -0.19702091900894042, -0.27, -0.41, -0.17, -0.48, 0.12, 0.32, 0.71, -0.12, -0.4, 0.39, -0.37, -0.06, 0.11, 5.8, 0.83, -0.41, -0.34, -0.56, 0.06, 0.45, -0.51, -0.2, 0.39, -0.44, -0.72, 0.07, -0.68, -0.38, -0.21, 5.46, 0.51, -0.72, -0.66, -0.88, -0.26, -0.32, -0.05506380078382657, -0.59, -0.82, -1.1, -0.31, -1.07, -0.76, -0.6, 5.06, 0.13, -1.11, -1.04, -1.26, -0.65, -0.71, 0.0, -0.07, -1.25, 0.24, -0.28, 0.51, -0.25, 0.06, 0.23, 5.93, 0.96, -0.29, -0.22, -0.44, 0.18, -1.11, 0.52, 0.79, 0.03, 0.34, 0.51, 6.22, 1.24, -0.01, 0.06, -0.16, 0.46, -0.46, 1.59, -1.58, -0.27, -0.76, -0.45, -0.28, 5.39, 0.44, -0.8, -0.73, -0.95, -0.33, -0.43738095238095237, 0.49, 0.31, 0.48, 6.19, 1.21, -0.04, 0.03, -0.19, 0.43, -0.07, 0.44, 3.82, -0.11, 0.08, -0.2, 0.18, 0.17, 5.86, 0.89, -0.35, -0.28, -0.5, 0.12, 0.63, 0.01, 5.69, 0.73, -0.51, -0.45, -0.67, -0.05, 0.07, -0.29, 0.09, 0.06, -0.87, 0.08, -0.27, -0.14, 0.19, 0.07, 0.09, -0.14, 1.33, 0.22, 0.1, 0.15, -0.31, -0.26, 0.27, 0.33, -0.1, -0.17, -0.22, -2.43, 1.19, 0.51, 2.46, -0.31, -0.55, -1.28, -5.37, -4.69, -5.87, -5.8, -6.01, -5.43, -0.38, -0.71, -1.23, -1.16, -1.38, -0.77, 0.53, 0.07, -0.15, 0.47, -0.54, -0.7815464535464534, 0.46, -0.22, 0.4, -0.1, -0.03, -0.14, 1.24, 1.8, -1.33, 0.96, -1.49, 0.68, 0.6927868514969316, 0.12, 0.12, -0.61, -0.47, -0.05537375617527095, 0.06, 0.32, -1.73, -0.34], ['269', -13.632857142857144, -0.43, -0.41877828437954123, -0.1, -1.96, -0.76, 0.21, -2.13, -0.77, -2.3, -1.21, -3.03, 0.08, -0.2, 0.87, 0.26071428571428573, 0.17, -1.4294285714285713, -0.89, 0.08, -2.52, -1.18, -0.88, -1.47, -1.93, -2.3, -1.1, -1.84, 1.3, 1.02, 2.11, 1.48, 1.4014285714285712, -0.22, 0.33, 1.31, -1.33, 0.03, 0.33, -0.26, -4.05, -0.5, 0.76, 3.2, 2.92, 4.02, 3.39, 3.3, 1.65, 2.21, 3.21, 0.53, 1.9, 2.22, 1.61, -1.68, -3.1657142857142855, -1.62, -1.49, -2.37, -0.27, 0.79, 0.43142857142857144, 0.09, -1.5, -0.96, 0.01, -2.59, -1.26, -0.96, -1.54, -2.66, -2.1, 1.07, 0.45, 0.37, -1.23, -0.69, 0.28, -2.33, -0.99, -0.69, -1.27, -0.73, -4.21, 4.14, -3.14, -0.61, -0.69, -2.28, -1.74, -0.78, -3.36, -2.04, -1.74, -2.32, -3.29, -2.55, 0.5385714285714286, -1.68, -1.14, -0.17, -2.77, -1.44, -1.14, -1.72, -0.82, -2.54, -2.46, -1.19, -1.3, -1.34, -2.46, -1.6, -1.06, -0.09, -2.68, -1.35, -1.05, -1.64, -1.09, -0.88, 0.55, 1.53, -1.11, 0.25, 0.6328571428571429, -0.04, -1.64, -2.43, -0.24396282112195955, -2.45, -6.49, -0.33967687074829933, -0.22428571428571428, 1.49, -1.43, -0.74, -0.63, -3.76, 4.55, 2.49, 1.19, -6.488561224489796, -0.38, -3.95, 3.97, 3.58, -1.23, 2.18, -2.41, 0.29, -0.08, -7.29, 6.623125850340137, 4.87, 7.23, -4.75, -1.42, 0.98, -1.64, -0.3, 0.01, -0.59, -3.45, -2.38, -2.6, -1.27, -0.96, -1.55, 0.23, 1.37, 1.68, 1.08, -0.74, -1.04, -1.13, 0.31, -0.29, -1.19, -1.41, -2.04, 3.25, -2.56, -3.1, -3.84, -2.09, -1.43, -0.5172131485030683, -1.71, -0.69, -1.06, -0.27, -1.02, -0.84, -5.84, -3.81, -1.9], ['270', -8.31, 0.04, -0.08, 0.0, -1.74, -0.5, -0.22, -0.45, -0.7, 0.22, 1.0, 0.8293248299319728, -0.4, 0.81, 0.4, 2.38, 1.27, 0.14, 3.97, 2.39, -0.47, -0.89, 0.37, -0.38, -1.02, -0.56, -0.78, -0.18, -1.39, -0.19, -0.59, 1.3633503401360545, 0.27, -0.85, 2.94, 1.37, -1.45, -1.87, -0.62, -1.37, 0.0, -1.57, -0.6, -1.21, -0.01, -0.42, 1.7842665945165948, 0.45, -0.68, 3.12, 1.55, -1.28, -1.7, -0.4157142857142857, -1.19, -1.28, -0.75, -1.06, -0.73, 0.62, 1.22, 0.81, 2.79, 1.68, 0.54, 4.39, 2.8, -0.06, -0.49, 0.78, 0.02, 0.03, -0.59, -0.4, 1.56, 0.46, -0.67, 3.14, 1.56, -1.26, -1.68, -0.43, -1.18, -0.71, -0.28, 0.19, -0.19, 1.97, 1.2999013605442178, -0.26, 3.55, 1.98, -0.86, -1.28, -0.03, -0.78, -3.48, -2.11, -1.08, -2.19, 1.55, 0.01, -2.78, -3.19, -1.96, -2.7, 0.03, -2.11, -1.17, -0.36, -0.38482093036566006, -0.34, -1.04, -1.12, 2.66, 1.1, -1.72, -2.13, -0.89, -1.63, 0.9, 0.08, 3.83, 2.24, -0.6, -0.8942004503433073, 0.23, -0.52, -0.42, -0.74, -0.07, -0.99, -10.48, -0.05, 0.04, 0.67, -0.71, -0.33, -0.56, -0.64, 4.02, 0.76, 0.32, -4.15, -0.11, -1.08, 0.97, 1.1, -0.37, 1.08, -0.76, 0.44, -0.21, -3.12, -2.93, 1.98, 3.09, -4.02, -3.61, -1.52, -4.27, -4.67, -3.46, -4.19, -0.9268321004392431, -2.12, -2.79, -3.2, -1.97, -2.7, 0.7444897959183674, -0.42, 0.84, 0.08, -0.62, -0.67, 1.11, 1.27, 0.51, -0.34, -0.48, -0.44, -0.03, -0.85, 0.06, -1.44, -1.44, -0.16, -0.75, -0.4, -0.55, 0.0, -0.47, -0.05, 0.6, -3.1, -1.47, -0.5], ['271', 3.11, 0.05, -0.028778284379541254, 0.28, -0.41, -0.64, 1.0641152579598292, -0.86, -0.75, 0.0, 1.56, -0.46, -0.22, -0.63, 2.0, -1.62, 0.63, -0.01, -4.37, 0.75, 0.3473354820873589, -0.06, 0.87, 0.97, -1.72, -1.05, -1.54, -1.99, -1.75, -2.16, 0.43, -3.13, -0.91, -1.54, -5.84, -0.8, -1.23, -1.59, -0.68, -0.58, -2.92, 0.68, 0.46, 0.24, -0.18, 2.47, -1.148956349206349, 1.1, 0.45, -3.93, 1.6496666666666666, 0.77, 0.4, 1.33, 1.7508287981859412, 0.95, -0.52, -0.9, -0.74, 0.22, -0.42, 2.22, -1.4, 0.85, 0.21, -4.16, 0.97, 0.53, 0.16, 1.09, 1.19, -2.51, 0.64, 2.65, -0.9892857142857143, 1.28, 0.63, -3.75, 1.4, 0.95, 0.58, 1.51, 1.62, -1.06, -2.52, 2.51, -1.96, -3.55, -1.34, -1.97, -6.24, -1.22, -1.65, -2.01, -1.11, -1.0, -0.17, 1.64, 2.29, 1.64, -2.79, 2.41, 1.96, 1.59, 2.53, 2.63, -0.09, 1.68, -0.26, -0.82, -0.71, -0.9, -0.63, -0.64, -4.97, 0.12, -0.32, -0.69, 0.23, 0.34, -0.14, 0.01, -4.36, 0.76, 0.32, -0.05, 0.88, 0.98, -0.75, -0.46, 0.46, -0.59, -0.5090476190476191, 0.0, -0.07, 2.58, -2.57, -1.26, 0.11, -0.9138364678879505, 1.52, 1.66, 0.83, 1.58, -0.31692021013122096, -2.46, 2.41, 2.47, -0.82, 3.95, -1.64, -5.03, 2.5, -1.82, 4.687380952380952, 1.25, 1.8, -1.6161904761904764, 4.56, 5.35, 4.89, 4.51, 5.47, 5.58, -2.52, -0.75, -0.44, -0.8, 0.12, 0.22, -0.31, -0.37, 0.56, 0.66, -0.71, -0.89, 0.06, 0.93, 1.03, -0.8, -0.77, -0.77, 3.24, -0.49, -3.23, -0.73, -0.16, -0.86, 0.1, -0.71, -1.18, -0.78, 0.1, -0.77, -0.97, -0.23, 0.94, -0.7], ['272', -1.72, 0.53, 0.09122171562045875, -0.24, -0.94, 0.3, 0.7, -0.22, 0.17, -1.84, -2.08, -1.95, -1.75, -0.79, -1.54, -0.86, -1.64, -1.9597942176870748, -4.39, -0.63, -2.53, -2.1440578231292515, -3.1, -2.59, -0.28, -0.04, 0.27265839499311245, 0.13, 0.33, 1.32, 0.56, 1.25, 0.45, 0.09, -2.36, 1.49, -0.46, -0.18, -1.04, -0.52, -0.62, 1.2349361992161734, 0.11, 0.2, 1.19, 0.42, 1.12, 0.32, -0.04, -2.48, 1.35, -0.59, -0.32, -1.17, -0.66, 0.22, 0.55, 0.08, 0.19, -0.09, 0.99, 0.22, 0.92, 0.12, -0.24, -2.571321995464853, 1.15, -0.79, -0.52, -1.37, -0.85, 0.4736060011417156, -1.06, -0.76, -0.07, -0.86, -1.22, -3.63, 0.16, -1.76, -1.49, -2.33, -1.82, 0.25, 3.59, -3.59, -0.31, 0.6905204081632652, -0.1, -0.47, -2.9, 0.92, -1.01, -0.74, -1.58, -1.07, -0.16, -1.0, -0.79, -1.15, -3.56, 0.23, -1.69, -1.42, -2.1188910216767356, -1.75, 0.26, -1.03, 2.02, 0.42, 0.58, 0.31, -0.21, -0.36, -2.8, 1.03, -0.91, -0.64, -1.4040121365844473, -0.97, 0.46, 0.16, -2.44, 1.4, -0.55, -0.27, -1.12, -0.61, 1.6689583699631245, 0.87, -0.21, 0.43, -0.3, 1.06, 0.65, -0.4, 0.38, 0.18, 0.29, -0.91, 2.7405182488772715, -0.88, -0.45, -0.83, 0.57, 1.2, -1.37, -1.3, 0.44, -0.53, 0.88, 2.55, -1.29, -0.52, -2.93, 0.36, 0.52, -2.5161904761904763, 2.66, 3.93, 1.94, 2.22, 1.366625850340136, 1.88, 1.24, -1.22, -1.91, -1.65, -2.49, -1.98, 0.7, 0.27, -0.58, -0.07, 0.2, 0.02, 0.43, -0.85, -0.34, 0.42, 0.38, -0.21, -1.3, 1.79, 0.97, 0.0, -0.08, 1.29, 0.5927868514969317, 0.54, 0.07, 0.3, 0.73, 0.27, 0.855957527023814, -2.65, -1.0784047619047619, 0.58], ['273', -8.33, 0.98, 0.0, -0.27, 0.15, 1.03, 3.55, -0.65, 1.06, -1.41, -2.31, -5.0, -1.87, 0.05, -0.75, 0.67, -1.97, -1.47, -0.64, -2.75, -1.55, -0.58, -2.46, -2.6, -0.86, 0.07, 0.92, -2.75, 0.45, 2.42, 1.59, 3.365035714285714, 0.34, 0.86, 1.71, -0.45, 0.78, 1.77, -0.15, -0.3, -0.83, 0.46493619921617346, 3.77, 3.29, 5.32, 4.47, 5.97, 3.19, 3.72, 4.59, 2.37, 3.63, 4.65, 2.68, 2.52, 0.28, -0.15, 0.27, 0.7, 0.47, 1.96, 1.14, 2.5942857142857143, -0.1, 0.41, 1.25, -0.89, 0.33, 1.31, -0.6, -0.74, -1.91, -1.47, -0.8, 0.62, -2.02, -1.52, -0.69, -2.8, -1.6, -0.63, -2.51, -2.5964403582748794, 0.63, 2.56, -2.6, -0.67, 1.43, -1.23, -0.72, 0.11, -2.01, -0.8, 0.17, -1.72, -1.86, -4.03, -2.07, -2.63, -2.12, -1.31, -3.39, -2.21, -1.007183003504432, -3.11, -3.25, 0.21, -2.1, -0.05, 0.89, 0.77, 1.02, 0.57, 0.52, 1.36, -0.79, 0.43, 1.42, -0.49, -0.64, -0.82, 0.05, 0.84, -1.3, -0.08, 0.9, -1.01, -1.15, 0.9, 0.8, -0.38, 0.6, -11.69, 0.42, 0.39, -2.07, 2.13, 1.06, -1.6, -0.2, -2.77, -1.71, -0.92, -4.22, 0.45, 2.67, -2.71, -2.61, 0.88, -3.29, 1.75, 2.69, -1.36, 1.65, -6.99, -1.16, -1.65, 2.77, -0.78, -2.12, -0.91, 0.06, -1.83, -1.97, 2.72, 1.37, 1.23, 2.22, 0.3, 0.15, 0.14, 0.98, -0.92, -1.07, 0.93, 0.49, -0.84, -1.89, -2.03, 0.94, 0.87, -0.46, -3.61, 0.23, 3.64, 0.58, 0.85, 1.07, -0.15, 1.46, 0.64, 0.87, -0.05, 0.69, 1.22, -1.64, 1.34, 1.14], ['274', -5.39, 0.06, 0.17122171562045874, 0.0, 0.11, -0.1, 0.11, 0.06, 0.13, 1.24, 0.79, 1.57, 1.89, 1.89, 0.29, 2.08, 1.67, 0.97, 3.53, 0.09, 1.33, 0.99, 1.52, 1.47, 0.34, -0.16, 0.45, 0.78, 1.09, 1.09, -0.5, 1.28, 0.88, 0.19, 2.72, -0.69, 0.54, 0.2, 0.73, 0.7238417231978392, -0.26, 0.0, -0.33, 0.31, 0.47787539444682314, -1.27, 0.5, 0.09, -0.59, 1.92, -1.46, -0.24, -0.58, -0.05, -0.1, 0.0, 0.59, 0.74, 0.17, -0.64, 0.0, -1.57, 0.19, -0.21, -0.9, 1.61, -1.77, -0.55, -0.89, -0.36, -0.41, 0.05, -0.64, -1.57, 0.19, -0.21, -0.9, 1.61, -1.77, -0.55, -0.88, -0.36, -0.41, 0.25, -0.42, 0.5, 0.95, 1.79, 1.38, 0.69, 3.23, -0.2, 1.04, 0.7, 1.23, 1.18, -1.62, -0.83, -0.4, -1.08, 1.42, -1.95, -0.74, -1.07, -0.54, -0.6, 0.18, -0.89, -0.88, -0.13, -0.08, -0.05432648134996804, -0.4290429599640126, -0.69, 1.83, -1.56, -0.34, -0.67, -0.14, -0.13141531611693433, 0.33, 0.26, 2.53, -0.88, 0.35, 0.01, 0.55, 0.49, -0.3, -0.48, 0.12603717887804045, -0.18681321637643203, -4.73, 0.01, 0.1, 0.31, -0.3175376766091052, -0.15, 0.08, 1.09, -2.29, 0.25, 0.15, -2.64, 0.22, -0.42, 0.35, 0.33, -0.12, 0.45, -0.24, 0.4, -0.22, -1.26, 4.71, 0.92, 1.2, 2.3, -2.21, -3.32, -2.12, -2.45, -1.93, -1.98, -0.4, 1.15, 1.24, 0.9, 1.44, 1.39, -0.09, -0.34, 0.19, 0.14, 0.15, 0.09, 0.25, 0.53, 0.48, -0.09, -0.14, 0.06257604962387836, 1.96, -0.62, -2.13, 0.11, -0.14, -0.20136255179902912, 0.02278685149693166, -0.23, -0.24, 0.14, 0.29, 0.1, -0.144042472976186, 0.0, -0.58, -0.32], ['275', 2.73, 0.24, 0.17122171562045874, 0.14, 2.02, -0.34, -0.85, -0.46, -0.4, -0.58, -0.48, 0.11, -1.06, 0.36, 0.89, -1.06, -0.26, -0.71, -3.61, -2.68, -0.37, -0.51, -0.17, -0.08, -0.59, -0.44062858541110805, -0.1, 0.6, -0.58, 0.84, 1.38, -0.58, 0.23, -0.23, -3.14, -2.21, 0.11, -0.03, 0.31, 0.4, -0.78, 0.7749361992161734, -0.7, -1.17, 0.24, 0.78, -1.17, -0.37, -0.82, -3.71, -2.79, -0.48, -0.62, -0.28, -0.2, 0.71, -0.88, -0.08, -0.43, 0.48, 1.43, 1.97, 0.0, 0.81, 0.35, -2.5628197278911564, -1.64, 0.7, 0.55, 0.9, 0.98, -0.71, -0.94, 0.53, -1.41, -0.61, -1.07, -3.95, -3.03, -0.72, -0.86, -0.53, -0.44, -0.04, -1.45, 1.44, -1.4233017616146797, -1.93, -1.14, -1.59, -4.46, -3.54, -1.25, -1.39, -1.05, -0.97, -0.25, 0.48, 0.81, 0.35, -2.58, -1.64, 0.69, 0.55, 0.89, 0.98, -0.02, 0.52, -0.58, -0.23, -0.4, -0.11, -0.3290429599640126, -0.46, -3.36, -2.43, -0.11, -0.25, 0.09, 0.17, -0.03, 0.13, -2.91, -1.98, 0.35, 0.2, 0.55, 0.64, -1.23, -1.24, 0.11, -0.4, -0.76, -0.18, 0.27, 0.25, -0.26, -0.14, 0.21, -0.42, -4.25, 0.5, 0.19, 1.33, -0.22, -0.67, 0.66, 0.67, -0.22, 0.32, -0.43, -1.63, 0.83, -0.95, -4.09, 0.67, 0.97, 4.48, 3.13, 0.96, 3.36, 3.21, 3.56, 3.66, -0.68, 2.15015873015873, 2.37, 2.23, 2.58, 2.67, -0.22, -0.14, 0.2, 0.29, -0.48, -0.19, -0.08, 0.34, 0.43, -0.18, -0.27, -0.52, -1.68, -0.46, 2.129280612244898, -0.57, -0.36, -0.33136255179902907, 0.09, 0.010077402522780693, -0.21, -0.2, -0.32, 0.45, -0.5, -0.67, -0.16, -0.45], ['276', -7.06, -0.93, -0.58, 0.23, -1.54, -1.91, -1.14, -2.06, -2.52, -2.35, 2.6903184712113286, -1.51, 0.84, 0.6, -0.95, -2.11, 0.5071428571428571, -0.6, 0.95, -0.23, -3.12, -0.14, 1.25, -0.41, -3.12, -3.43, -4.72, -3.9, -1.5898809523809525, -1.84, -3.35, -4.48, -1.96, -3.0, -1.5, -2.65, -5.46, -2.55, -1.2, -2.82, 1.51, -6.38, -0.85, 2.39, 2.15, 0.6408150295752765, -0.61, 2.02, 0.93, 2.5, 1.3, -1.63, 1.4, 2.8, 1.12, -3.03, -3.6957142857142857, -1.16, -1.8, -3.17, -0.24, -1.78, -2.93, 0.3114285714285714, -1.42, 0.11, -1.06, -3.92, -0.9540374149659864, 0.4, -1.24, -1.54, -2.93, -1.54, -2.7, -0.13, -1.19, 0.34, -0.83, -3.69, -0.73, 0.64, -1.01, -4.65, -10.15, 10.23, -1.42, -1.17, 1.44, 0.36, 1.91, 0.73, -2.19, 0.82, 2.22, 0.54, -0.97, -0.25, 2.64, 1.55, 3.12, 1.92, -1.03, 2.02, 3.43, 1.74, -1.9, -0.24, -2.99, -2.21, -2.59, -2.04, -2.81, -1.06, 0.47, -0.7, -3.57, -0.61, 0.77, -0.88, -2.15, -1.77, 1.55, 0.37, -2.54, 0.46, 2.0485714285714285, 0.18, -3.69, -3.16, 0.03, -2.97, -1.94, -2.02, -1.07, 4.44, -4.37, -2.21, -1.79, -3.85, 4.17, 4.651428571428572, 2.264547619047619, -3.51, -1.72, -6.99, 7.607142857142857, 6.924285714285714, -2.2, 6.68, -4.39, -4.27, 1.78, -8.43, 28.87, 5.58, 8.48, -4.28, -3.27, -1.17, -4.02, -1.07, 0.3, -1.35, -6.7, -2.13, -2.89, 0.1, 1.48, -0.18, 0.79, 3.08, 4.5, 3.0285714285714285, -2.72, -3.33, -2.22, 1.39, -0.28, -2.25, -2.41, -2.1, 14.37, -3.9, -14.29, -2.12, -2.89, -3.56, -1.64, -2.42, -2.26, -1.34, -1.72, -1.3, -1.95, -3.22, -3.9, -0.7], ['277', -1.68, 0.22, -0.15, -0.01, -0.36, -0.39158037632624054, 0.0, 0.43, 0.25, 1.75, 1.99, 1.54, 2.43, 1.41, 1.32, 1.33, 1.88, 1.72, 8.06, 2.64, 1.52, 1.5, 1.35, 2.1, -0.2, -0.04, -0.23, -0.44, 0.43, -0.57, -0.66, -0.65, -0.11, -0.26, 5.95, 0.64, -0.46, -0.48, -0.63, 0.11, 0.12, 0.40493619921617346, 0.409303232481804, 0.88, -0.13, -0.22, -0.21, 0.34, 0.18, 6.43, 1.09, -0.02, -0.03, -0.18, 0.55, 0.5, 0.41, 1.32, 0.39, -0.67, -1.0, -1.09, -1.08, -0.54, -0.69, 5.5, 0.2, -0.89, -0.91, -1.06, -0.33, -0.04, 0.34, -0.09, -0.08, 0.46, 0.31, 6.56, 1.21, 0.11, 0.09, -0.06, 0.68, 0.24, 0.93, -0.89, 0.43, 0.01, 0.56, 0.4, 6.66, 1.31, 0.2, 0.18, 0.04, 0.77, -0.14, 0.42, 0.54, 0.39, 6.65, 1.3, 0.2526265373526935, 0.17, 0.02, 0.76, 0.17, 0.42, -2.14, -0.3, -0.26, -0.33, -0.13, -0.15, 6.07, 0.75, -0.35, -0.37, -0.52, 0.22, 0.15, 0.03, 6.23, 0.9, -0.2, -0.22, -0.37, 0.37, 0.0, 0.08, 0.28, -0.22, -0.84, 0.19, 0.2, 0.23, -0.24, -0.14, 0.67, 0.23, 1.8005182488772715, 0.59, 0.31, -0.95, -0.23, -0.9, 0.83, 0.87, -0.3, 0.45, -0.55, -1.92, 0.91, -0.33, 0.28, 0.21, 0.33, -1.75, -5.84, -5.02, -6.05, -6.07, -6.21, -5.52, -0.87, -0.87, -1.09, -1.11, -1.26, -0.53, 0.23, -0.02, -0.17, 0.57, 0.5701351386708531, 0.37, 0.3272746849074344, -0.15, 0.6622487553150163, -0.25, -0.18560369872470917, 0.5625760496238783, 0.19, -1.74, -0.23, -0.3, -0.73, 0.39, 0.74, -0.55, -0.11, -0.59, -0.1, -0.17, -0.25404247297618604, -1.22, -0.69, -1.42], ['278', -12.888571428571428, 0.021428571428571422, -0.26877828437954127, 0.01, -2.11, -1.44, 0.06, -1.98, -0.92, -2.51, -1.66, -2.51, -0.98, -0.79, -0.42, 0.06, -1.13, -1.86, -4.05, 0.51, -2.6, -0.76, -0.68, -0.88, -2.11, -2.46, -0.86, -0.86, 0.7208333333333333, 0.89, 1.26, 1.76, 0.54, -0.2, -2.43, 2.210714285714286, -0.95, 0.92, 1.0, 0.8438417231978392, -1.66, -0.96, 0.0, 1.57, 1.77, 2.14, 2.64, 1.42, 0.67, -1.58, 3.09, -0.09, 1.8, 1.88, 1.67, -1.49, -1.55, -1.75, -1.54, -1.55, 0.19, 0.5607993197278912, 1.05, -0.15, -0.89, -3.1, 1.5, -1.64, 0.22, 0.3, 0.1, -1.01, -1.5242857142857142, 0.37, 0.86, -0.35, -1.08, -3.29, 1.3, -1.83, 0.03, 0.11, -0.1, -1.0010901360544218, -4.99, 4.93, -2.1, 0.49, -0.2800986394557823, -1.41, -3.65, 0.93, -2.19, -0.34, -0.26, -0.46, -3.65, -2.57, -1.19, -1.92, -4.11, 0.44, -2.66, -0.82, -0.74, -0.94, -0.8, -2.62, -1.34, -1.77, -1.53, -1.93, -1.4, -0.74, -2.95, 1.65, -1.49, 0.38, 0.45, 0.25, -1.72, -0.66, -2.24, 2.41, -0.75, 1.12, 1.2, 0.99, -0.79, -0.3, -0.65, -1.68, -7.35, -0.33, -0.36, 4.87, -4.87, -2.43, -0.78, -2.68, 5.72, 3.57, 1.76, -6.314778911564626, -1.01, -5.25, 5.37, 5.38, -1.77, 7.16, -3.42, -2.15, 1.02, -4.16, 9.65, 2.797142857142857, 4.435714285714286, -5.99, 1.61, 4.75, 1.51, 3.43, 3.51, 3.3, -5.35, -3.0, -3.09, -1.26, -1.18, -1.38, 0.09, 1.89, 2.202857142857143, 1.76, -0.99, -1.12, -1.77, 0.08, -0.13, -1.66, -1.71, -1.83, 4.89, -1.47, -4.93, -2.58, -2.32, -1.84, -0.2, -1.91, -2.22, -0.64, -0.949047619047619, -1.59, -1.64, -3.01, -3.38, -1.05], ['279', -1.09, -0.23, 0.011221715620458745, 0.15, -1.61, 0.29, -0.12, -0.17, 0.42, -0.22, -0.7, -0.43, -0.31, 0.37, -1.5, -0.19, -0.12, -0.17, -0.06, 3.93, 0.01, 0.06, -0.38, -1.16, 0.7, -0.14, 0.49, 0.27, 0.4, 1.08, -0.81, 0.52, 0.59, 0.53, 0.65, 4.67, 0.72, 0.77, 0.33, -0.46, 0.43, 0.40493619921617346, 0.21, 0.12, 0.8, -1.08, 0.24, 0.32, 0.26, 0.37, 4.809666666666667, 0.44, 0.5, 0.06, -0.73, 0.48, 0.29, 0.3, 0.28, 0.09, 0.68, -1.2, 0.12, 0.2, 0.14, 0.25, 4.26, 0.32, 0.37, -0.06, -0.85, 0.23, -0.58, -1.86, -0.56, -0.48, -0.54, -0.18252355184498031, 3.55, -0.36, -0.3, -0.74, -1.52, 0.47, 0.42, -0.41, 1.3, 1.33, 1.41, 1.35, 1.46, 5.52, 1.54, 1.59, 1.15, 0.35, 0.61, -0.03, 0.08, 0.02, 0.13, 4.13, 0.2, 0.25, -0.18, -0.97, -0.06, 0.0, 2.55, 0.2, 0.22, 0.29, -0.1, -0.06, 0.05, 4.05, 0.13, 0.18, -0.26, -1.05, -0.28, -0.05, 0.11, 4.11, 0.18, 0.24, -0.2, -0.99, 0.31, 0.17, 0.2860371788780405, 0.24, 1.89, 0.07, 0.0, -0.49, 0.41, 0.23, 0.06, -1.92, 8.13, -0.44, -0.21, -0.56, 0.5, 0.49, -0.6, -0.6, 0.21, -0.78, 0.4, -0.8116093450200591, 0.47, -0.24, -1.35, 0.16, 0.36, -8.09, -0.16, 4.0, 0.07, 0.12, -0.31, -1.1, 0.57, -3.99, -3.77, -3.72, -4.14, -4.9, -0.23, 0.05, -0.39, -1.17, 0.34, 0.56, -0.28, -0.44, -1.22, 0.19, 0.2, -0.14, -0.79, 1.78, 0.91, 0.58, -0.85, 0.16, -0.79, 0.29, 0.16, 0.5, 0.21, 0.42, 0.95, -0.56, -0.99, 0.95], ['280', 4.518571428571429, -1.87, 0.27, 0.6521428571428572, 0.88, -0.16, 0.25, 0.44, -0.06, 0.47, 1.25, 0.15, -0.36, -0.56, -0.19, -1.48, 1.56, 1.09, 2.71, -0.19, 0.42, 0.87, 0.96, 0.62, 0.13, 0.46, -0.77, -1.09, -1.59, -1.78, -1.42, -2.7, 0.31, -0.15, 1.45, -1.42, -0.82, -0.37, -0.28, -0.62, 1.09, 1.23, 0.32, -0.51, -0.7, -0.34, -1.63, 1.7186513605442175, 0.94, 2.56, -0.34, 0.27, 0.72, 0.8442857142857143, 0.48, -0.15, -0.16, -0.38, -0.48, 0.83, -0.2, 0.17, -1.13, 1.92, 1.46, 3.08, 0.17, 0.78, 1.2314285714285713, 1.33, 0.99, -0.55, 1.6757142857142857, 0.37, -0.93, 2.13, 1.66, 3.29, 0.37, 0.99, 1.44, 1.53, 1.19, -0.24109013605442178, -1.07, 1.14, 0.66, -1.29, 1.75, 1.32, 2.91, 0.0, 0.62, 1.07, 1.16, 0.82, 2.76, 1.98, 3.08, 2.61, 4.26, 1.31, 1.93, 2.39, 2.48, 2.15, -0.45, 1.98, 0.74, -0.18, -0.13, -0.34, -1.07, -0.46, 1.14, -1.72, -1.12, -0.68, -0.59, -0.92, -0.41, -0.62, 1.6, -1.27, -0.66, -0.22, -0.13, -0.47, -0.05, -0.21, -0.2, -0.87, 5.531102040816326, -0.42, -0.62, 0.46, -0.44, -0.22, -0.39, 0.81, -1.43, 0.35, 0.22, 2.23, -0.04, -0.63, 0.73, 0.42, -0.17, 0.74, -0.35, -2.37, 1.18, -3.16, 1.52, 2.2342857142857144, 3.275714285714286, 1.45, -2.18, -2.82, -2.23, -1.79, -1.7, -2.03, -0.46, 0.66, 0.61, 1.06, 1.15, 0.81, 0.05, 0.45, 0.7728571428571429, 0.2, -0.08, -0.38, -0.4, 0.09, -0.25, -0.19, -0.34, 0.33, 0.9157142857142857, -0.31, -0.67, -0.09, -0.38, -0.49, -0.34, -0.64, -0.31, 0.06, 0.06095238095238095, 0.54, -0.15, -0.35, -0.77, -0.49], ['281', 0.68, -0.07, 0.17122171562045874, 0.15, 0.3, -0.08, -1.72, -1.64, -1.14, -1.8, -1.13, -0.37, -0.53, -0.92, 0.22, -1.27, -1.01, -1.48, -3.54, -1.53, -2.1, -2.2, -0.98, -1.51, -1.61, -1.09, -0.67, 0.77, 0.61, 0.22, 1.37, -0.14, 0.12, -0.35, -2.43, -0.4, -0.98, -1.08, 0.2588796134390452, -0.3461582768021609, -1.3525315746467892, -1.89, -1.43, -0.15, -0.55, 0.6, -0.9, -0.64, -1.11, -3.18, -1.16, -1.73, -1.83, -0.61, -1.15, -0.5099371536943235, -0.3957142857142858, -1.91, -1.22, -1.28, -0.39, 0.75, -0.75, -0.49, -0.95, -3.03, -1.0, -1.58, -1.68, -0.45, -0.99, -2.55, -0.89, 1.15, -0.36, 0.04948941254823622, -0.56, -2.65, -0.61, -1.19, -1.29, -0.06, -0.6, -1.1, -1.82, 1.8, -2.02, -1.49, -1.23, -1.69, -3.75, -1.74, -2.32, -2.42, -1.2, -1.6759922724755494, -1.84, -0.54, 0.26, -0.21, -2.3, -0.26, -0.84, -0.94, 0.3, -0.25, -0.23, -0.65, 1.7, -0.4, -0.42, -0.43, -0.8, -0.47, -2.55, -0.52, -1.1, -1.2, 0.03, -0.51, 0.45, -0.33, -2.1, -0.05, -0.63, -0.73, 0.51, 0.2021774376417234, -1.01, -0.74, 0.29, -0.46, -5.7, 0.05, 0.14, 1.91, -1.91, -0.95, 0.14, -0.4938364678879505, 0.4, 0.75, 0.46, 0.46, 0.11, -1.28, 1.45, 1.22, -0.42, 2.9, -0.87, -1.27, 0.67, -2.36, 0.76, 1.62, 2.39, -0.5661904761904761, 1.8, 2.09, 1.49, 1.39, 2.66, 2.1, -1.28, -0.2798412698412699, -0.58, -0.68, 0.9794625850340136, 0.01, 0.3, -0.1, 1.14, 0.6, -1.19, -1.07, 0.41, 1.25, 0.7, -0.42, -0.51, -1.63, 0.5, 1.19, -0.63, -0.82, -0.55, -0.83, -0.54, -0.23, -0.92, 0.06, 0.11, 0.27, -0.29, -1.65, -1.4, -1.25], ['282', -4.332857142857143, 0.31, 0.09015289830927053, -0.1, 0.05, 0.29, -0.47, -1.27, -0.5, -0.9229115646258504, -1.42, -0.49, -0.61, -0.59, 0.49, -0.94, -1.23, -1.17, -5.26, -0.92, -1.46, -0.64, -1.03, -1.6, -1.59, -0.58, 0.05, 0.94, 0.82, 0.85, 1.94, 0.49, 0.19, 0.25, -3.9, 0.5, -0.04, 0.79, 0.4, -0.18, -1.16, -0.34, -0.88, -0.12, -0.1, 0.99, -0.42895634920634923, -0.7371428571428571, -0.68, -4.79, -0.43, -0.941934531913557, -0.15, -0.5242857142857144, -1.11, -1.56, -1.55, -1.86, -0.36, -0.76, 0.03, 1.12, -0.32, -0.62, -0.56, -4.68, -0.31, -0.85, -0.03, -0.42, -0.99, -3.35, -0.79, 1.09, -0.35, -0.65, -0.59, -4.7, -0.34, -0.88, -0.05, -0.44, -1.02, -0.27, -0.83, 0.95, -1.86, -1.42, -1.72, -1.66, -5.73, -1.41, -1.95, -1.13, -1.52, -2.08, -0.18, -0.44, -0.3, -0.24, -4.37, 0.01, -0.53, 0.3, -0.09, -0.67, -0.27, -0.45, 0.18, 0.05, 0.09, -0.08, -0.14, 0.06, -4.08, 0.31, -0.23, 0.6, 0.21, -0.37, -0.67, -0.2, -4.14, 0.25, -0.29, 0.54, 0.14, -0.43, 0.07, 0.22, 0.04, -0.21, -1.4022619047619047, 0.16, -0.24, 1.03, -1.04, -0.53, 0.07, -0.66, 0.94, -0.12, -0.07, -2.0707142857142857, 0.41, 0.01, 0.0, -0.13, 0.04, 1.53, 0.08, 0.64, -0.32, -0.36, 5.63, 0.21, 0.44, -1.02, 4.1, 4.58, 4.01, 4.88, 4.47, 3.87, 0.1, -0.45, -0.54, 0.29, -0.11, -0.68, 0.09, 0.83, 0.44857142857142857, -0.14, -0.49, -0.1, -0.74, -0.39, -0.97, -0.02, -0.02, -1.34, 2.84, 0.28, -2.89, -0.56, 0.12, -0.35, -0.4972131485030683, 0.4, -0.42, 0.5, 0.25, 0.3, 0.23, -1.76, -0.41, -0.08], ['283', -9.94, -0.26, 0.13, 0.29, -0.96, -0.89, -0.8058847420401708, -1.3382794034640413, -1.46, -1.32, 1.09, -0.21, -0.45, 1.03, 0.39, 0.72, -0.24, 0.09, -0.62, 0.45, -2.202664517912641, -0.54, -0.41, -0.46, -2.53, -1.33, -2.38, -1.28, -1.52, -0.05, -0.69, -0.36, -1.31, -0.98, -1.69, -0.63, -3.29, -1.61, -1.48, -1.53, -0.4, -1.81, -1.11, -0.24, 1.25, 0.6708150295752765, 0.94, -0.03, 0.3, -0.41, 0.66, -2.011934531913557, -0.33, -0.2, -0.25, -0.08, -1.1, -1.86, -1.24, -0.88, 1.49, 0.84, 1.18, 0.21, 0.54, -0.17, 0.91, -1.8, -0.09, 0.04, -0.01, -0.94, -2.33, -0.64, -0.31, -1.26, -0.93, -1.64, -0.58, -3.24, -1.56, -1.43, -1.47, -1.87, -2.64, 2.69, -1.71, 0.33, -0.63, -0.3, -1.01, 0.061674603174603174, -2.62, -0.93, -0.8, -0.84, -3.18, -2.03, -0.96, -0.63, -1.33, -0.27, -2.94, -1.25, -1.13, -1.17, -0.23, -2.0, -1.19, -0.9, -0.94, -0.94, -1.0081905235138708, 0.33, -0.38, 0.7, -2.0, -0.3, -0.17, -0.22, -0.79, -1.41, -0.71, 0.36, -2.33, -0.63, -0.5, -0.55, -1.05, -1.05, 0.28, -1.09, -9.82, -0.09, -0.12, 1.62, -1.61, -0.82, -1.92, -1.82, 3.37, 1.78, 0.9, -5.06, -0.4069202101312209, -2.83, 2.82, 2.71, -0.93, 2.43, -1.89, -3.37, 1.64, -3.17, 5.88, 2.07, 3.01, -3.42, -0.71, 1.08, -1.63, 0.08, 0.21, 0.16, -2.59, -1.77, -2.68, -0.99, -0.86, -0.91, 0.94, 1.8288785911064216, 1.87, 1.83, -1.51, -1.36, -0.79, 0.13, 0.08, -0.92, -0.8856036987247091, -1.46, 3.05, -1.29, -2.8085714285714287, -1.98, -1.63, -0.92, -0.05, -1.12, -0.67, -0.34, -0.26, -0.95, -0.87, -3.12, -2.04, -0.62], ['284', -2.1, 0.13, -0.23877828437954127, -0.01, 0.96, 0.32, 0.26, -0.37, 0.31, -1.98, -2.55, -2.09, -3.56, -1.14, -1.05, -2.06, -1.35, -2.24, -3.64, -3.6, -1.76, -1.43, -1.45, -1.8648833725798009, 1.06, 0.93, 0.6126583949931124, 0.47, -1.04, 1.45, 1.54, 0.5, 1.23, 0.4272589041444084, -1.12, -1.08, 0.81, 1.15, 1.12, 0.56, -0.5145146341753485, -0.17, 0.11, -1.51, 0.97, 1.06, 0.03, 0.75, -0.16, -1.59, -1.55, 0.33965472923706097, 0.67, 0.65, 0.08, -0.6, 0.04, -0.42, 0.51, 1.64, 2.52, 2.61, 1.56, 2.3, 1.37, -0.08, -0.04, 1.87, 2.22, 2.19, 1.62, 2.25, -0.85, 0.09, -0.93, -0.21, -1.12, -2.53, -2.49, -0.63, -0.29, -0.32, -0.88, 0.22, -1.79, 1.88, -0.94, -1.02, -0.3, -1.2, -2.62, -2.58, -0.72, -0.38, -0.41, -0.97, 0.32, 0.08, 0.73, -0.18, -1.61, -1.57, 0.31, 0.65, 0.62, 0.06, 0.35, 0.07, 1.12, 0.21159818068290148, 0.22, 0.09567351865003196, -0.64, -0.9, -2.3198412698412696, -2.28, -0.41, -0.08, -0.1, -0.66, -0.59, 0.27, -1.43, -1.39, 0.49, 0.83, 0.81, 0.24, -0.75, -0.59, -0.07, -0.13, 0.75, -0.39, -0.43, 1.56, -1.59, -0.8, -0.24, 0.09, -3.16, -0.32, -0.14, -1.06, 0.58, 0.4514761904761905, -0.48, -0.55, 0.18, 2.4, 0.36, -0.11, 0.01, -1.83, -1.89, 1.31, 1.82, 3.32, 1.73, 0.04, 1.95, 2.3, 2.27, 1.7, 0.42, 1.68, 1.91, 2.26, 2.23, 1.66, -0.22, 0.34, 0.31, -0.25, 0.26, 0.31, -0.56, -0.02, -0.59, 0.18, 0.16, -0.36, -0.92, 0.58, 1.17, 0.12, 1.52, -0.46136255179902913, -0.56, 0.0, -0.68, 1.07, 0.89, 0.28, 0.03, -0.12, 1.07, -0.89], ['285', -9.07, 1.5, 0.29, 0.3, -0.43, 0.93, -0.59, 1.34, 0.33, -1.4558571428571427, -2.08, -1.09, -3.08, -3.11, -3.23, 2.2, -2.0, -1.81, -2.06, -1.22, -1.93, -2.75, -2.58, -2.55, 1.04, 0.49, 0.6726583949931124, 1.01, -1.02, -1.05, -1.17, 4.38, 0.09, 0.28, 0.03, 0.88, 0.15, -0.68, -0.5, -0.43615827680216085, 1.41, 0.5149361992161734, -0.37, -2.01, -2.04, -2.16, 3.33, -0.91, -0.72, -0.97, -0.13, -0.85, -1.68, -1.5, -1.48, 1.17, 0.27, 0.7878279728097839, 0.11, 1.68, -0.03, -0.15, 5.45, 1.12, 1.31, 1.06, 1.92, 1.18, 0.34, 0.52, 0.54, -0.29, 1.71, -0.12, 5.49, 1.15, 1.35, 1.09, 1.95, 1.22, 0.37, 0.56, 0.58, 0.94, 3.4, -3.47, 1.83, 5.61, 1.27, 1.47, 1.21, 2.07, 1.3638701615844473, 0.49, 0.6785238095238095, 0.7, -4.53, -3.58, -4.11, -3.92, -4.17, -3.35, -4.05, -4.85, -4.68, -4.65, 0.73, -3.55, 0.27, 0.42, 0.9151790696343399, 1.065673518650032, 0.6218094764861293, 0.2, -0.06, 0.79, 0.07, -0.77, -0.59, -0.5114153161169342, 0.37, 0.36, -0.25, 0.6, -0.13, -0.96, -0.78, -0.76, 0.81, 0.74, 0.88, 0.913186783623568, -13.35, 1.27, 1.07, -1.76, 1.7, 0.888810171007621, -2.68, 0.16, 0.35, -1.82, -0.94, -4.46, 1.12, 2.76, -2.67, -2.76, 0.973290804863853, -2.59, 1.76, -1.59, 0.75, 1.55, -4.18, -1.07, -1.62, -0.31, 0.61, 0.85, 0.13660997732426305, -0.71, -0.53, -0.51, 2.68, -0.24, -0.72, -1.55, -1.37, -1.35, 0.49, -0.83, -0.66, -0.63, 0.34, 0.57, 1.33, 0.18, 0.2, 0.94, 0.91, 1.67, -1.99, 0.73, 2.03, 0.36, 0.5, 1.15, 0.02, 0.99, 0.48, 1.02, 1.23, 1.46, 1.13, -1.95, 0.26, 0.54], ['286', -0.64, 0.55, 0.16, -0.04, -0.04, -0.54, -1.4499638336347196, -0.9182794034640412, -0.57, -1.07, -0.55, -0.21, -1.15, -0.06, -0.16, -0.45, -0.51, -1.1, -0.8, -1.13, -0.8, -1.19, -0.46, -0.46, -0.61, -0.42, -0.49734160500688757, 0.34, -0.6, 0.49, 0.39, 0.1, 0.04, -0.55, -0.26, -0.58, -0.25, -0.64, 0.09, 0.09, -0.05, -1.04, -0.86, -0.94, 0.15, 0.12081502957527657, -0.24, -0.3, -0.89, -0.59, -0.92, -0.59, -0.8861344435209981, -0.25, -0.25, -0.37, -0.94, -1.68, -0.33, 0.08, 1.1, 1.000799319727891, 0.71, 0.64, 0.05, 0.35, 0.02, 0.35, -0.04, 0.7, 0.7, -0.91, -1.01, -0.1, -0.39, -0.45, -1.04, -0.75, -1.07, -0.74, -1.13, -0.4, -0.4, -0.57, -1.44, 1.49, -0.91, -0.29, -0.35, -0.94, -0.64, -0.97, -0.64, -1.03, -0.3, -0.3, -1.32, -0.63, -0.06, -0.65, -0.36, -0.68, -0.35, -0.74, -0.01, -0.01, -0.05, -0.62, 0.01, -0.5184018193170985, -0.69, -0.33432648134996806, -0.56, -0.59, -0.29, -0.6194642857142857, -0.29, -0.68, 0.05, 0.05, 0.03, 0.03, 0.3, -0.03, 0.3, -0.09, 0.65, 0.65, -0.76, -0.92, 0.12, -0.43, -4.12, -0.15, 0.07, 0.6, -0.63, -0.2811898289923789, -0.33, -1.49, -0.28, 1.07, 0.54, -0.34, -0.66, -1.68, 1.61, 1.61, -0.4867091951361471, 0.98, -1.1, -0.36, 0.17, -1.67, 1.99, 1.15, 1.58, 0.23, -0.27, -0.33, 0.0, -0.39, 0.35, 0.35, -1.67, 0.06, 0.33353741496598643, -0.06, 0.68, 0.68, -0.27, -0.39, 0.34, 0.35, -0.52, -0.3415464535464533, 0.12, 0.74, 0.74, -0.54, -0.5, -0.99, 0.94, -1.09, -0.85, -0.4, -1.07, -0.62, 0.0, -0.59, -0.41, -0.86, -1.17, 0.12, -0.62, 0.04, -0.84, -1.27], ['287', -8.23, -0.97, -0.4998471016907295, 0.07, -1.54, -2.78, -1.89, -4.0, -2.98, -4.92, -1.64, -2.74, -1.14, -1.75, -1.1157142857142859, -1.85, -1.2885714285714285, -3.82, -6.35, -2.5574455782312926, -5.17, -1.87, -2.06, -2.63, -3.82, -2.97, -3.33, -1.1194545454545455, 0.5146428571428572, -0.12, 0.52, -0.22, -0.3, -2.22, -4.8, -1.27, -3.59, -0.24, -0.43, -1.01, -3.23, -3.79, -2.24, 1.64, 1.01, 1.66, 0.92, 0.83, -1.11, -3.72, -0.15, -2.5, 0.89, 0.7, 0.11, -2.93, -2.7457142857142856, -4.49, -3.44, -3.82, -0.62, 0.02, -0.72, -0.8, -2.71, -5.28, -1.77, -4.08, -0.74, -0.93, -1.5, -4.44, -3.22, 0.64, -0.1, -0.18, -2.1, -4.68, -1.15, -3.48, -0.12, -0.31, -0.89, -3.28, -8.36, 8.4, -3.84, -0.73, -0.82, -2.72, -5.29, -1.78, -4.09, -0.6742857142857143, -0.94, -1.52, -3.22, -3.13, -0.09, -2.007880952380952, -4.59, -1.06, -3.38, -0.02, -0.21, -0.79, -1.2, -3.16, -2.28, -2.52, -2.51, -2.45, -3.04, -1.92, -4.51, -0.97, -3.3, 0.06, -0.13, -0.71, -2.96, -1.14, -2.64, 0.97, -1.41, 2.02, 1.83, 1.24, -3.45, -3.75, -0.38, -2.78, -6.32, -1.1796768707482992, -0.7942857142857144, 5.09, -5.1, -2.56, -1.88, -6.04, 4.24, 5.06, 2.9582806122448977, -4.14, -1.62, -7.5, 7.44, 7.55, -2.5, 7.64, -5.05, -2.14, 1.1, -9.07, 8.073125850340135, 6.07, 9.16, -4.18, 1.54, 3.7048095238095238, 1.27, 4.79, 4.59, 3.98, -7.5, -2.09, -2.35, 1.05, 0.86, 0.27, 0.7165017006802721, 3.48, 3.28, 3.331428571428572, -2.95, -3.32, -3.1, -0.19, -0.77, -2.46, -2.51, -3.93, 3.99, -3.19, -4.06, -2.66, -3.05, -2.92, -0.58, -3.07, -2.42, -1.79, -1.7, -2.13, -2.35, -4.94, -4.24, -2.12], ['288', -2.41, -0.01, -0.01, -0.05, -0.65, -0.07, 1.26, -0.99, 0.2, -1.01, -1.64, -1.11, -0.77, 0.51, 0.42, -0.25, -0.7, -1.11, -4.77, -0.37, -0.62, -0.73, -0.37, -0.92, -0.98, -0.21, 0.64, 0.54, 0.89, 2.19, 2.09, 1.42, 0.95, 0.54, -3.18, 1.29, 1.04, 0.93, 1.29, 0.7738417231978392, -0.82, 0.6449361992161734, 0.1, 0.35, 1.64, 1.6108150295752766, 0.87, 0.41, 0.0, -3.71, 0.75, 0.49, 0.48386555647900187, 0.75, 0.19, -0.39, -0.72, -0.88, -0.05, -0.17075475293412243, 1.28, 1.19, 0.52, 0.06, -0.35, -4.04, 0.4, 0.15, 0.04, 0.4, -0.16, -0.82, -1.51, -0.09, -0.75, -1.2, -1.61, -5.01252355184498, -0.87, -1.12, -1.23, -0.7369045181009466, -1.3764403582748792, 0.77, -1.64, 1.68, -1.42, -0.66, -1.12, -1.52, -5.17, -0.78, -1.03, -1.14, -0.78, -1.34, -0.09, -0.77, -0.46, -0.87, -4.54, -0.12, -0.3173734626473065, -0.48, -0.13, -0.68, 0.09, -0.83, -0.29427628811696, -0.2, -0.3, -0.09, -0.31, -0.41, -4.1, 0.34, 0.08, -0.03, 0.33, -0.22, -0.23, 0.11, -3.7, 0.75, 0.5, 0.5157995496566927, 0.75, 0.19, -1.22, -1.33, 0.08, -0.29, -0.39, 0.14, 0.07, -0.04, 0.0, -0.01, 0.07, -0.83, 1.27, 0.41, 0.21, -1.16, -0.21, -0.66, 0.59, 0.64, -0.15670919513614703, 0.03, -0.44, -0.85, 0.45, -0.88, -0.17, 0.6, 0.92, -1.3, 3.95, 4.63, 4.36, 4.25, 4.62, 4.04, -0.6391948051948052, -0.64, -0.26, -0.36, 0.0, -0.56, -0.39, -0.11, 0.25, -0.3, 0.18, 0.35, -0.28, 0.36, -0.2, -0.22, -0.2, -0.9, 0.3, -0.25, -0.31, -0.3781051005851445, -0.16, -0.64, -0.56, -0.48, 0.05, 0.17, -0.19, -0.26, -0.09, -1.61, -0.2, -0.14698322629260274], ['289', 0.91, -0.53, -0.12, 0.08, -0.01, 0.57, -1.0299638336347197, -0.5482794034640412, -0.05062194561298938, -0.93, -1.03, -0.11, -1.05, -1.1, -0.41, -0.71, -0.84, -0.91, -0.43, 0.1, -0.95, -0.96, -0.93, -0.87, -0.04, -0.82, 0.1, 0.93, -0.02, -0.08, 0.6878199712950912, 0.33, 0.19, 0.12, 0.6, 1.14, 0.08, 0.07, 0.1, 0.16, -0.15, -1.11, -0.82, -0.94, -0.99, -0.29, -0.59, -0.73, -0.79, -0.32, 0.21, -0.84, -0.84, -0.82, -0.76, -0.2, 0.0, -0.52, 0.16, 0.12, -0.05, 0.65, 0.35, 0.21, 0.15, 0.63, 1.16, 0.1, 0.1, 0.12, 0.18, -1.33, 0.18, 0.71, 0.4, 0.27, 0.2, 0.68, 1.22, 0.15, 0.15, 0.18, 0.24, -0.41, -0.12, 0.08, -0.53, -0.2119125667872351, -0.43, -0.5, -0.03, 0.51, -0.3847647669790526, -0.55, -0.53, -0.47, -1.85, -0.23, -0.13, -0.2, 0.28, 0.81, -0.25, -0.25, -0.23, -0.17, -0.12, -0.24, 1.3, 0.13, -0.13, 0.40567351865003193, -0.09, -0.07, 0.41, 0.94, -0.12, -0.12, -0.01401213658444736, -0.03, 0.05, -0.02, 0.48, 1.01, -0.05, -0.05, -0.02, 0.04, -0.39, -0.64, 0.19603717887804045, 0.08, -5.17, -0.05, 0.0, -1.23, 1.25, 0.6588101710076211, -0.03, 0.29, 1.88, -0.27, -0.11, 0.48, -0.2, 0.5505968614718616, -0.47, -0.4, 0.14, -1.88, 0.3, 0.22, -0.12, -0.25, -5.18, 0.22, 0.35, -1.9428690476190476, -0.5, 0.53, -0.513390022675737, -0.53, -0.5, -0.44, 0.42, -1.03, -1.05, -1.05, -1.03, -0.97, 0.02, 0.0, 0.02, 0.08, -0.19, 0.04, 0.03, 0.03, 0.09, 0.15, 0.12, -0.71, -1.98, 0.67, 1.94, -0.33, -0.42, 0.0, 0.06, 0.11, 1.15, -0.07, -0.28, -0.12, -0.06, -0.68, -0.76, 0.02], ['290', 5.23, -1.59, -1.08, 0.09, -1.9570209190089405, -2.0315803763262403, -2.55, -2.23, -2.3, -1.2592857142857143, 2.04, 1.42, 0.17, 0.65, 0.77, -5.16, 1.57, 0.2, 1.58, 2.93, -1.11, 1.0, 2.35, 1.81, -1.73, -1.74, -3.23, -0.61, -1.83, -1.36, -1.24, -7.05, -0.46, -1.8, -0.45, 0.88, -3.09, -1.02, 0.31, -0.22, -1.6, -1.3650638007838265, -2.64, -1.23, -0.75, -0.64, -6.48, 0.15, -1.2, 0.16, 1.5, -2.49, -0.41, 0.92, 0.39, -1.66, -2.49, -3.81, -1.96, -1.43, 0.48, 0.6, -5.32, 1.39, 0.13260506614006173, 1.4271802721088434, 2.76, -1.28, 0.83, 2.18, 1.64, -2.09, -1.9, 0.12, -5.77, 0.91, -0.45, 0.92, 2.5891309523809523, -1.75, 0.34, 1.69, 1.15, -2.58, -9.65, 9.62, -1.9833017616146797, -5.88, 0.79, -0.57, 0.8, 2.15, -1.87, 0.23, 1.57, 1.03, 6.74, 4.11, 7.09, 5.65, 7.11, 8.53, 4.27, 6.49, 7.92, 7.35, -1.41, 4.13, -6.78, -2.27, -2.26, -2.46, -2.7790429599640123, -1.35, 0.01, 1.35, -2.64, -0.56, 0.77, 0.24, -2.21, -1.46, 1.38, 2.73, -1.31, 0.8, 2.15, 1.61, -4.571041630036876, -4.24, 0.12, -2.876813216376432, 20.08, -1.0, -0.56, 4.77, -4.81, -2.39, -1.17, -2.47, 8.14, 4.62, 2.31, 2.71, -1.39, -6.94, 6.89, 6.87, -2.27, 7.25, -4.54, -4.08, 1.83, -8.37, 13.81, 5.51, 8.28, -8.11, -2.8, 1.33, -2.65, -0.57, 0.76, 0.23, -6.88, -4.08, -3.93, -1.88, -0.56, -1.09, -0.15, 2.13, 3.5, 2.95, -2.2, -2.25, -2.24, 1.34, 0.8, -2.31, -2.39, -2.06, 7.3, -5.75, -7.19, -1.75, -2.03, -3.4513625517990287, -0.53, -2.54, -2.29, -1.81, -0.31, -1.65, -3.02, 0.66, -4.34, -3.48], ['291', -2.27, 0.11, 0.11122171562045875, 0.1, -1.48, -0.08, -0.17588474204017085, -0.27, -0.04, -1.27, -1.27, -1.05, -1.21, -0.88, -2.22, -0.51, -0.47, -1.44, 0.15, -0.22, -1.13, -1.04, 0.26, -1.19, -0.41, -0.63, 0.03265839499311246, 0.22, 0.07011904761904762, 0.39, -0.96, 0.76, 0.8, -0.18, 1.43, 1.06, 0.14, 0.23, 1.55, 0.08, -0.44, -0.22506380078382657, -0.22, -0.16, 0.16, -1.18, 0.54, 0.58, -0.4, 1.3071355564861205, 0.84, -0.08034527076293904, 0.01, 1.32, -0.15, -0.24, 0.15, -0.62, -0.17, -0.06, 0.33, -1.02, 0.7, 0.74, -0.24, 1.3871802721088435, 1.0, 0.08, 0.17, 1.49, 0.02, -0.85, -0.39, -1.34, 0.37, 0.41, -0.56, 1.04, 0.67, -0.25, -0.16, 1.16, -0.31, -0.03, -3.76, 3.82, 0.97, 1.74, 1.78, 0.79, 2.42, 2.04, 1.1338701615844473, 1.2, 2.54, 1.05, -1.58, -0.76, 0.04, -0.93, 0.66, 0.29, -0.62, -0.53, 0.78, -0.68, 0.22, -0.78, -1.1298229965745161, -0.35, -0.69, -0.05, -0.8, -0.97, 0.62, 0.26, -0.66, -0.57, 0.74, -0.72, -0.28, 0.23307674813036727, 1.61, 1.24, 0.31, 0.41, 1.73, 0.25, -2.76, -2.97, 0.22, -0.78, -4.588897959183674, -0.08, -0.07, -0.14, 0.14, 0.08, -1.11, -0.93, 2.07, 0.71, 0.32, -1.16, -0.25, -1.03, 1.08, 1.03, -0.35, -0.08, -0.71, -1.07, 0.53, -2.45, 0.11, 1.58, 2.37, -2.08, -1.41, -0.37, -1.28, -1.19, 0.12, -1.34, -1.01, -1.05, -0.91, -0.82, 0.49, -0.98, -0.14, 0.09, 1.41, -0.06, 0.12013513867085306, -0.11, -0.23, 1.32, -0.16, -0.35, -0.42, -0.26, 0.77, -1.12, -0.63, -0.57, -0.73, -1.53, -1.45, 0.07, -0.01, 0.11, -0.44, -0.11, -0.08, -2.37, -1.02, -0.61], ['292', 3.82, 0.58, 0.12, 0.3821428571428573, 0.76, 0.33, 1.6, 0.72, 1.28, 0.56, -0.98, -0.05806550195835902, -0.39, -0.15, -0.61, -0.68, 0.66, 0.41, -1.56, -0.47, 1.67, 0.74, -0.47, 0.31, 0.94, 0.84, 1.55, 0.72, 0.6, 0.83, 0.37, 0.3, 1.65, 1.4, -0.59, 0.51, 2.67, 1.73, 0.51, 1.3, 0.55, 2.75, 0.82, -0.13, 0.11, -0.35, -0.42, 0.92, 0.67, -1.3, -0.21, 1.93, 1.0938655564790019, 0.4214285714285715, 0.57, 0.59, 1.02, 1.78, 1.160952380952381, 0.95, 0.24, -0.22, -0.29, 1.05, 0.8, -1.17, -0.08, 2.06, 1.13, -0.08, 0.7, 1.12, 0.71, -0.46, -0.53, 0.81, 0.56, -1.41, -0.32, 1.82, 0.89, -0.32, 0.46, 1.77, 2.35, -2.29, 1.17, -0.0694795918367347, 1.27, 1.02, -0.96, 0.14, 2.29, 1.35, 0.14, 0.92, 2.23, 1.25, 1.35, 1.1, -0.88, 0.21, 2.36, 1.43, 0.21, 1.0, 0.12, 1.3, -0.81, 0.41, 0.59, 0.12, -0.1, -0.25, -2.2, -1.12, 1.0, 0.14030501944728757, -1.12, -0.35, -0.09, 0.15, -1.96, -0.88, 1.25, 0.33, -0.88, -0.1, 0.8689583699631245, 0.45, -0.02, -0.06, 6.59, 0.1, 0.11, -0.21, 0.24, 0.1, 0.28, 0.5, -2.04, -0.8, -0.42, 1.86, 0.35, 1.23, -1.28, -1.26, 0.4, -0.4, 0.81, 0.53, -0.3, -0.25, -2.04, 0.13, 0.25, 2.09, 2.15, 1.1, 3.27, 2.33, 1.1, 1.9, 1.22, 1.0301587301587303, 2.15, 1.21, 0.0, 0.78, -1.09, -0.91, -2.1, -1.33, 1.24, 1.51, -0.18, -1.2, -0.42, 0.42, 0.33, 0.65, -1.58, -0.43, 1.57, 0.15, 0.7810935020800125, 1.03, 0.78, 0.15, 0.03, 0.37, 0.14, 0.68, 0.335957527023814, -0.26, 1.3830376647162361, -0.29], ['293', 5.93, 0.75, 0.05, -0.18, 1.9, 0.59, 1.36, 0.96, 1.68, 0.34, -1.48, -1.12, -1.53, -0.34, 0.72, -0.32, 0.017142857142857144, -0.16, 1.35, -2.32, 0.9, -0.57, -1.24, -0.39, 1.71, 2.22, 1.85, 0.37, -0.05, 1.16, 2.23, 1.18, 1.4914285714285713, 1.34, 2.87, -0.85, 2.42, 0.93, 0.24, 1.11, 0.6374684253532109, 2.1449361992161733, 1.47, -0.42, 0.79, 1.86, 0.81, 1.11, 0.96, 2.5, -1.21, 2.068065468086443, 0.56, -0.13, 0.74, 0.13, 1.16, 1.12, 1.56, 1.9, 1.21, 2.28, 1.23, 1.54, 1.39, 2.93, -0.8, 2.6334211542425834, 0.98, 0.4553389784818358, 1.16, 1.07, 0.68, 1.06, 0.02, 0.32, 0.17, 1.69, -1.99, 1.25, -0.23, -0.91, -0.05, 1.98, 4.42, -4.46, -0.38, -1.02, -0.73, -0.88, 0.63, -3.01, 0.19, -1.27, -1.95, -1.1, 3.06, 0.66, 0.3, 0.15, 1.67, -2.01, 1.22, -0.25, -0.93, -0.07, 0.86, 0.68, -1.63, 0.79, 0.94, 0.7, 0.35, -0.15, 1.37, -2.3, 0.92, -0.55, -1.23, -0.37, 0.97, 0.5, 1.52, -2.15, 1.07, -0.4, -1.08, -0.22, 1.76, 0.48, -0.3, 0.943186783623568, 6.05, 0.18, -0.06, -0.84, 0.81, 0.43, 0.96, 0.71, -5.31, -1.53, -0.81, 2.94, 0.41, 2.43, -2.47, -2.37, 0.78, -1.23, 1.57, 0.88, -0.44, 1.07, -9.29, -0.75, -1.14, 5.293809523809524, -1.0, -3.62, -0.44, -1.89, -2.56, -1.72, 2.37, 2.7201587301587304, 3.3, 1.79, 1.1, 1.97, -0.56, -1.46, -2.13, -1.28, 1.74, 1.88, 0.91, -0.68, 0.18, 0.81, 0.76, 0.9225760496238784, -4.66, -0.61, 4.6, 1.75, 1.47, 1.6, 0.86, 0.58, 0.36, 0.54, 0.39, 0.06, 0.73, 2.46, 2.92, 0.3730167737073973], ['294', 3.64, 0.18, 0.4012217156204588, 0.05, 0.8129790809910595, 0.46, 1.2441152579598291, 0.93, 0.94, 3.73, 3.08, 2.558992063492063, 3.1, 2.4, 3.45, 3.21, 2.6599999999999997, 3.37, 7.7, 1.9966428571428572, 3.9, 3.33, 3.17, 3.36, 0.77, 0.64, 0.63, -0.52, 0.02, -0.66, 0.36, 0.13, -0.43, 0.28, 4.48, -1.06, 0.79, 0.24, 0.09, 0.27, 0.26, 2.08, 1.16, 0.54, -0.14, 0.88, 0.65, 0.09, 0.81, 5.03, -0.55, 1.32, 0.76, 0.61, 0.8, 0.14, 1.13, 1.43, 0.97, 0.61, -0.68, 0.34, 0.11, -0.45, 0.27, 4.46, -1.08, 0.77, 0.22, 0.2353389784818358, 0.25, 0.88, 1.3, 1.03, 0.79, 0.23, 0.95, 5.17, -0.4, 1.46, 0.9, 0.76, 0.94, 1.08, 1.55, -1.5, 0.27, -0.23, -0.79, -0.08, 4.11, -1.42, 0.43, -0.12, -0.27, -0.09, 0.19, 0.5, -0.56, 0.16, 4.35, -1.19, 0.67, 0.11, -0.04, 0.15, 0.43, 0.51, 0.15, 0.58, 0.49, 0.61, 1.07, 0.72, 4.94, -0.63, 1.23, 0.68, 0.53, 0.71, 0.39, 0.35, 4.18, -1.34, 0.51, -0.05, -0.18428571428571427, -0.01, 0.47, 0.55, 0.05, 0.59, 0.47, 0.1, 0.02, -1.44, 1.41, 0.72, 0.53, 0.5561635321120495, -3.3, -1.14, -0.6, 1.84, 0.4, 1.63, -1.74, -1.76, 0.57, -2.1, 1.14, -0.22, 0.12, 3.21, -3.08, -2.12, -3.24, 3.25, -3.68, -5.3, -3.53, -4.06, -4.2, -4.03, 1.71, 1.71, 1.87, 1.31, 1.16, 1.35, -0.16, -0.55, -0.7, -0.52, 0.98, 1.01, 0.39, -0.15, 0.03, 0.52, 0.61, 0.94, -1.26, -0.1, 1.24, 0.91, 0.31, 0.54, 0.18, 0.61, 0.65, 0.59, 0.58, 0.8, 0.36, 0.81, 0.81, -0.58], ['295', -0.38, -0.23, 0.011221715620458745, -0.12, -1.09, 0.29, 1.78, -0.02, -0.17, -0.77, -0.2, -1.45, -0.19, -0.58, 0.38, -0.34, -1.09, -0.64, 0.07, 1.01, -1.12, -0.87, -1.16, -1.2, 0.0, 0.18, -0.5373416050068875, -1.25, 0.01, -0.39, 0.58, -0.14, -0.9, -0.45, 0.27, 1.21, -0.92, -0.67, -0.96, -1.0, -0.29, -1.77, 0.7, 1.28, 0.88, 1.86, 1.13, 0.3992789115646258, 0.82, 1.54, 2.490714285714286, 0.34, 0.59, 0.39714285714285713, 0.26, 0.0, 0.07, 0.0, -0.61, -0.57, -0.39, 0.57, -0.14, -0.9, -0.45, 0.26, 1.2, -0.93, -0.68, -0.97, -1.01, 0.06, -0.18, 0.97, 0.25, -0.51, -0.06, 0.66, 1.6, -0.54, -0.28, -0.58, -0.62, -0.61, 1.01, -1.05, -1.14, -0.71, -1.47, -1.02, -0.31, 0.62, -1.49, -1.24, -1.53, -1.57, -0.62, -0.43, -0.76, -0.31, 0.41, 1.35, -0.79, -0.53, -0.83, -0.87, -0.28, -0.46, 0.62, 0.31, 0.25, 0.22, 0.33, 0.5865993906886765, 1.18, 2.12, -0.03, 0.23, -0.07, -0.051415316116934326, 0.0, -0.12, 0.72, 1.66, -0.48, -0.22, -0.52, -0.56, 0.04, 0.1, -0.013962821121959568, -0.45, -2.36, -0.22, -0.13, -0.65, 0.71, 0.34, -0.2859337265331848, -0.28, 3.32, -0.61, -0.28, -0.15, 0.26307978986877906, 0.63, -0.87, -0.94, 0.3, -1.1, 0.63, -1.01, 0.26, 0.92, 3.46, -0.51, -0.94, -3.28, -0.5096213151927438, 0.94, -1.19, -0.93, -1.23, -1.27, 0.91, -1.75, -2.1, -1.85, -2.14, -2.18, 0.36, 0.26, -0.04, -0.08, -0.18, -0.45, 0.1, -0.3, -0.34, 0.29, 0.23, 0.02, 1.63, 0.39, -1.84, 0.08, -0.34, 0.4, -0.04, -0.22, 0.19, 0.31, 0.05, 0.6, 0.44, -2.29, -0.36, 0.03], ['296', -1.04, -1.24, 0.03, -0.01, -0.26, 0.5, 0.21, 0.84, 0.2, 0.95, 0.18, 0.61, -0.16, -0.7, -0.31, 2.3, 0.41, 0.87, 3.32, 1.4, 1.04, 0.42, 0.19, 0.3, -1.08, 0.49937141458889195, 0.77, 0.43, -0.34, -0.87, -0.49, 2.12, 0.24, 0.69, 3.14, 1.22, 0.86, 0.24, 0.01, 0.17384172319783917, 0.92, 1.1549361992161733, 0.34, -0.76, -1.3, -0.91, 1.68, -0.19, 0.26, 2.7, 0.78, 0.458065468086443, -0.18, -0.42, -0.3, 0.96, 0.21, 0.32, 0.1, 1.11, -0.54, -0.15, 2.46, 0.58, 1.03, 3.49, 1.56, 1.2, 0.58, 0.35, 0.46, 0.46, 1.66, 0.39, 3.02, 1.1816609275411798, 1.58, 4.05, 2.11, 1.75, 1.13, 0.89, 1.01, 0.51, 2.3, -2.31, 1.3066982383853203, 2.62, 0.73, 1.18, 3.65, 1.71, 1.36, 0.74, 0.5, 0.62, -2.96, -1.31, -1.84, -1.4, 1.0, -0.88, -1.23, -1.83, -2.06, -1.95, -0.04, -1.1606317967746538, 0.0, 0.5315981806829014, 0.69517906963434, 0.39, 0.53, 0.45, 2.9, 0.98, 0.62, 0.01, -0.22, -0.11, 0.49, 0.08, 2.44, 0.53, 0.17, -0.44, -0.67, -0.56, 1.15, 1.17, -0.06, 0.69, -8.78, 0.19, 0.0, -0.13, 0.09246232339089482, 0.04, 0.49, 1.69, 0.76, -0.98, -0.47, -0.45, 0.68, 1.52, -1.55, -1.49, 0.48, -0.21, 0.99, 0.8, -0.32523473571575323, 1.63, -3.4, -1.11, -1.62, -0.89, -2.3, -1.87, -2.21, -2.81, -3.03, -2.92, 1.48, -0.44, -0.35, -0.96, -1.19, -1.08, -0.09, -0.61, -0.84, -0.73, 0.21, 0.5184535464535467, 0.53, -0.23, -0.047751244684983665, 0.51, 0.51, 0.98, -1.36, 0.05, 1.27, 0.83, 0.8, 0.7604317111459968, 0.11, 0.87, -0.03, 0.64, 0.79, 0.14, 0.65, -0.72, 1.23, 0.52], ['297', 0.29, 0.17, 0.04, 0.04, 0.97, -0.1, 1.0641152579598292, 0.59, 0.97, 0.49, -0.82, -0.51, 1.63, -0.38, -0.45, -0.4, 0.25, 0.32, 1.23, -1.63, 0.58, 0.25, -0.06, 0.52, 1.49, 1.19, 1.31, 0.3, 2.46, 0.44, 0.37, 0.4233503401360544, 1.07, 1.14, 2.07, -0.82, 1.4, 1.07, 0.8688796134390452, 1.35, 0.55, 0.27, 1.01, 2.1536589811608606, 0.13, 0.13081502957527658, 0.1264030612244898, 0.77, 0.83, 1.8571355564861205, -1.12, 1.128065468086443, 0.76, 0.46, 1.04, 0.39, 0.65, 0.37, 0.49, -1.12, -1.98, -2.04, -1.99, -1.36, -1.29, -0.39, -3.2, -1.03, -1.36, -1.65, -1.08, 0.76, 0.87, -0.07, -0.02, 0.63, 0.7, 1.62, -1.25, 0.96, 0.63, 0.33, 0.91, 1.09, 1.62, -1.66, 0.94, 0.05, 0.7, 0.77, 1.69, -1.18, 1.03, 0.7, 0.4, 0.98, 4.66, 0.89, 0.65, 0.72, 1.64, -1.23, 0.98, 0.65, 0.35, 0.93, 0.17, 0.95, 0.47, 0.1, 0.2751790696343399, -0.04, 0.24, 0.07, 1.0869325674325676, -1.87, 0.33, 0.0, -0.3, 0.28, 0.24, 0.17, 0.91, -1.94, 0.26, -0.07, -0.37, 0.21, 0.73, 0.39, 0.1, 0.23, 14.207619047619048, 0.01, 0.0, 0.0, -0.02, 0.0, 0.12, 2.7361635321120494, -4.22, -0.21, -0.13, 0.18, 0.09, 0.26, -0.42, -0.34, 0.1, 0.06, 0.19, -0.48, 0.3147652642842468, 0.78, -2.11, -0.59, -0.78, 4.23, -0.74, -2.83, -0.65, -0.98, -1.27, -0.7, 0.3, 2.15, 2.24, 1.9, 1.6, 2.19, -0.09, -0.33, -0.63, -0.05, 0.89, 0.86, 0.24, -0.3, 0.28, 0.11, 0.16, 0.63, -0.63, 0.54, 0.61, 1.27, 1.44, 0.54, 0.58, 0.98, 0.11455285983857427, -1.05, 0.63, -1.26, -0.04, 3.08, 2.4330376647162364, 0.25], ['298', 1.37, -0.28, 0.0, -0.17, -0.4, -0.41, -0.6658847420401709, 0.02, -0.38, 1.05, 0.81, 1.42, 1.34, 0.43, 1.5, 0.42, 1.59, 1.17, 1.6, 1.6, 1.21, 1.53, 1.61, 1.44, -1.04, 0.08, 0.23, 0.6, 0.53, -0.38, 0.68, -0.39, 0.77, 0.36, 0.78, 0.78, 0.39, 0.71, 0.79, 0.63, 0.22, -2.0150638007838264, -0.37, -0.08, -0.98, 0.08, -0.99, 0.17, -0.24, 0.18, 0.17, -0.21, 0.11, 0.19, 0.02, -0.07, -0.07, -0.52, -0.28, -0.29, -0.9, 0.16, -0.91, 0.24, -0.17, 0.25, 0.25, -0.14, 0.18, 0.26, 0.1, -0.73, 0.62, 1.07, -0.01, 1.16, 0.74, 1.17, 1.16, 0.78, 1.1, 1.18, 1.01, -0.55, -1.72, 1.69, -0.41330176161467985, -1.07, 0.09, -0.32, 0.1, 0.09, -0.29, 0.03, 0.11, -0.06, -0.74, 0.63, 1.17, 0.75, 1.18, 1.17, 0.78, 1.1124285714285715, 1.19, 1.02, -0.19, 0.63, -0.21427628811695995, -0.26, -0.39, -0.16, -0.54, -0.41, 0.01, 0.0, -0.38, -0.06, 0.02, -0.15, -0.64, -0.12, 0.42, 0.42, 0.03, 0.35, 0.43, 0.27, -0.32, -0.23, -0.2, -0.25, -1.34, -0.36, -0.35, -0.17, 0.2, 0.08, -1.29, 0.1, 1.0, 0.51, 0.27, 0.69, -0.24, -0.89, 0.87, 0.83, -0.26, -0.23, -0.53, 1.44, -0.71, -1.63, 4.72, 1.1, 1.65, -1.11, -0.54, 0.0, -0.39, -0.07, 0.01, -0.15, -0.8, -0.54, -0.38, -0.06, 0.02, -0.15, -0.16, 0.32, 0.4, 0.23, -0.42, -0.39, -0.47, 0.08, -0.09, -0.27, -0.28, 0.10257604962387837, 2.31, -0.47980037304250067, -2.36, -0.03, 0.14, -0.55, -0.17, 0.22, -0.07, -0.69, 0.55, -0.73, -0.39, -0.54, 0.32, -0.49], ['299', 2.98, 0.43, -0.32877828437954126, 0.38, 1.04, -0.011580376326240524, -0.44588474204017087, -0.1, -0.96, -0.25, 1.31, 0.06, 0.65, -1.2, 0.1, -2.46, 0.11, -0.12, -1.48, -1.52, -0.77, 0.43, 0.79, -0.17, -0.79, 0.68, -1.4973416050068875, -1.23, -0.64, -2.47, -1.1321800287049086, -3.71, -1.18, -1.4, -2.75, -2.79, -2.05, -0.87, -0.51, -1.4061582768021608, 0.12, -1.29, -0.31, 0.59, -1.0921246055531768, 0.03, -2.52, 0.05, -0.18, -1.538347866419295, -1.58, -0.83, 0.36, 0.72, -0.23, -0.5, -0.35, -0.22, -0.62, -0.89, -1.84, -0.55, -3.09, -0.54, -0.77, -2.12, -2.16, -1.41, -0.23, 0.13, -0.81, -0.6, 0.96, 1.31, -1.27, 1.33, 1.1, -0.28, -0.33, 0.44, 1.64, 2.01, 1.0935596417251208, -1.28, -2.54, 2.47, -0.30330176161467987, -2.55, 0.02, -0.21, -1.57, -1.62, -0.86, 0.33, 0.69, -0.26, 1.24, 2.27, 2.63, 2.4, 1.0, 0.96, 1.73, 2.95, 3.32, 2.35, 0.05, 2.29, 0.89, -0.2, -0.38, -0.02, -0.3590429599640126, -0.23, -1.59, -1.63, -0.88, 0.31, 0.67, -0.28, -0.64, -0.13, -1.36, -1.41, -0.65, 0.54, 0.9, -0.05, -1.16, -1.49, 0.6360371788780403, -0.19681321637643204, 2.43, 0.11, 0.4, -0.56, 0.621720125812563, 0.2788101710076211, -0.07, 0.52, -2.58, 0.44, 0.18, 1.52, 0.08, -0.56, 0.66, 0.62, -0.22, -0.77, -0.39, -3.21, 1.61, -1.19, 2.93, 0.66, 1.02, 2.62, 1.25, 0.2871787775716348, 0.72, 1.93, 2.3, 1.33, -0.65, 1.3, 0.77, 1.98, 2.34, 1.38, 0.53, 1.2, 1.57, 0.61, -0.92, -1.33, -0.67, 0.36, -0.59, -0.18, -0.19, -0.05, 1.45, 0.07, -1.36, 0.17, -0.52, -1.02, -0.94, 0.05, 0.08, 0.2, -0.06, -0.09, -0.08, 0.0, -0.43, -0.33], ['300', -6.47, 0.31, -0.13877828437954126, 0.43, -2.0070209190089403, -1.78, -1.6358847420401708, -3.58, -3.0406219456129895, -3.25, 1.3803184712113286, -1.42, -1.12, 0.16, 0.4642857142857143, -1.42, -1.1328571428571428, -3.02, -2.95, -0.09, -4.0, -1.4, -0.15, -2.18, -3.75, -2.34, -4.37, -2.56, -2.26, -1.0, -0.7, -2.56, -2.32, -4.14, -4.07, -1.24, -5.11, -2.54, -1.31, -3.32, -2.98, -4.065063800783826, -1.650696767518196, 0.31, 1.6, 1.91, 0.01, 0.25, -1.62, -1.54, 1.36, -2.61, 0.02, 1.29, -0.77, -4.09, -3.98, -3.68, -3.18, -2.15, 1.29, 1.6, -0.3, -0.05, -1.92, -1.85, 1.05, -2.91, -0.29, 0.98, -1.08, -4.45, -3.4, 0.3, -1.57, -1.33, -3.17, -3.1, -0.24, -4.15, -1.56, -0.31, -2.34, -4.12, -8.17, 8.28, -3.6533017616146797, -1.86, -1.62, -3.46, -3.39, -0.54, -4.406129838415552, -1.85, -0.61, -2.63, -0.84, -1.86, 0.24, -1.63, -1.55, 1.35, -2.62, 0.01, 1.4211089783232642, -0.78, -0.07885812600098302, -1.79, -1.52427628811696, -1.7, -2.05, -1.33, -2.1, -1.87, -1.79, 1.2997126881055456, -2.86, -0.23, 1.03, -1.02, -1.71, -0.24, 0.07, 3.02, -1.01, 1.7857995496566925, 2.96, 0.86, -3.23, -3.6, 0.66, -1.84, -1.66, -0.82, -0.43, 1.21, -1.2, -0.63, -0.73, -3.45, 6.35, 3.32, 1.72, -3.28, -1.22, -5.09, 5.04, 5.08, -1.69, 1.83, -3.38, -5.16, 2.51, -6.26, 11.05, 4.21, 6.28, -6.34, -0.31, 2.95, -1.08, 1.59, 2.88, 0.78, -5.07, -3.16, -3.91, -1.32, -0.06, -2.1, 0.78, 2.7, 4.01, 1.89, -3.09, -3.61, -1.87, 1.27, -0.79, -1.63, -1.72, -3.37, 5.54, -1.99, -5.66, -2.46, -2.27, -3.1, -2.04, -1.99, -0.88, -1.28, -0.82, -1.52, -1.09, -3.48, -2.76, -1.66], ['301', -3.58, 0.25, 0.011221715620458745, 0.02, 0.0, 0.38, 1.26, 0.09, 0.39, -3.2192857142857143, -3.61, -3.79, -4.1, -3.94, -4.840234693877551, -2.04, -3.8342857142857145, -3.15, -5.368518140589569, -2.7192857142857143, -3.62, -3.58, -3.63, -3.85, 0.67, -0.12, 0.4326583949931125, -0.18, -0.4891666666666667, -0.34, -1.44, 1.63, -0.25, 0.48, -1.84, 0.92, -0.01, 0.04, -0.02, -0.25, 0.9, 0.35, 0.59, -0.32, -0.15, -1.26, 1.82, -0.07, 0.66, -1.66, 1.1, 0.18, 0.22, 0.16, -0.06, 0.69, -0.15, 0.3, 0.53, 0.92, 0.17, -0.94, 2.15, 0.25, 0.99, -1.34, 1.43, 0.5, 0.8674648526077097, 0.49, 0.26943877551020406, -0.21, 0.75, -1.11, 1.98, 0.09, 0.82, -1.5, 1.26, 0.33, 0.37, 0.32, 0.1435596417251207, 0.42, 1.25, -1.27, 1.87, 3.12, 1.2, 1.95, -0.4, 2.583744771101914, 1.45, 1.5, 1.44, 1.21, -2.12, -1.1326334687834372, -1.86, -1.14, -3.41, -0.7, -1.62, -1.57, -1.63, -1.85, -0.07, -1.22, 0.0, 0.5815981806829015, 0.5351790696343399, 0.54, 0.66, 0.73, -1.59, 1.17, 0.24, 0.29, 0.23, 0.01, 0.41, -0.07, -2.3, 0.44, -0.3013969800041226, -0.44, -0.5, -0.72, 0.77, 0.73, -0.11, 0.48, -5.94, 0.09, -0.0642857142857143, -1.24, 1.27, 0.61, 0.53, -0.68, 1.03, -1.04, -0.52, -1.8, 0.46, 1.52, -1.59, -1.53, 0.573290804863853, -1.94, 1.04, 0.27, -0.14, 1.84, -1.28, -1.29, -2.02, -0.99, 2.28, 2.81, 1.86, 1.91, 1.85, 1.62, 1.57, -0.51, -0.9164625850340137, -0.87, -0.93, -1.15, 0.41, 0.04, -0.01, -0.24, 0.43, 0.32, 0.37, -0.06, -0.28, 0.52, 0.52, 0.11257604962387836, -0.91, 0.38, 1.01, 0.68, 0.7, 0.43, -0.22, 0.44, 0.47, 0.47, 0.63, 0.57, 0.65, -0.46, 1.23, 0.49301677370739727], ['302', 0.94, 0.48, 0.02, -0.18, 1.22, 0.5, 0.6141152579598291, 0.8017205965359587, 0.79, 2.72, 1.66, 2.62, 1.87, 3.06, 1.7, 2.18, 2.55, 2.72, 2.79, 2.0, 2.94, 1.66, 2.33, 2.05, 0.64, 0.16, 1.0726583949931126, 0.94, 0.2, 1.37, 0.04, 0.51, 0.87, 1.04, 1.11, 0.33, 1.25, 0.0, 0.66, 0.38, 0.26, 0.75, 0.1, -0.73, 0.42, -0.9, -0.43, -0.07, 0.1, 0.17, -0.61, 0.3, -0.94, -0.28, -0.56, 1.53, 0.7, 0.8078279728097839, 0.58, 0.9192452470658775, 1.17, -0.16, 0.3, 0.67, 0.84, 0.91, 0.13, 1.213421154242583, -0.2, 0.46, 0.18, 0.54, -0.32, -1.32, -0.85, -0.49, -0.32, -0.01252355184498033, -1.03, -0.12, -1.35, -0.7, -0.98, 1.15, 1.18, -1.16, 1.01, 0.47, 0.84, 1.01, 1.07, 0.29, 1.21, -0.04, 0.62, 0.34, 0.59, 0.53, 0.36, 0.53, 0.6015238095238095, -0.18, 0.74, -0.51, 0.15, -0.13, 0.03, 0.44, -1.08, 0.49, 0.52, 0.41, 0.17, 0.17, 0.24, -0.54, 0.37, -0.87, -0.21, -0.49, 1.0, 0.0, 0.07, -0.71, 0.21, -1.03, -0.38, -0.66, -0.19, -0.38, -0.1, 0.37, 1.82, 0.28, 0.2, -0.1, 0.07, 0.03, 0.22, 0.69, -1.3194817511227284, -1.0, -0.47, 0.54, 0.52, 1.43, -1.43, -1.54, 0.48, -0.09, 0.95, 1.81, -0.92, 0.46, -0.27, -0.36, -0.46, 1.4, -0.07, -0.7751904761904762, 0.14, -1.1, -0.45, -0.73, 1.45, 0.71, 0.92, -0.33, 0.33, 0.05, -0.21, -1.24, -0.58, -0.86, 0.68, 1.1684535464535466, 1.04, 0.66, 0.38, 0.47, 0.5443963012752908, 0.88, -3.24, -0.48, 3.7892806122448977, 0.49, 0.83, 0.38, -0.28, 0.59, 0.0, 0.7, 0.34, 0.83, 0.66, 0.0, 0.74, -0.21], ['303', -3.2, 0.32, 0.05122171562045875, 0.01, 0.26, 0.2, 0.45, 0.72, 0.63, 0.68, 0.47, -0.27, -1.02, 0.52, -0.54, 1.38, 0.95, 0.71, -1.66, 1.19, 0.77, 0.08, 0.04, -0.47, 1.3, 0.32937141458889196, 0.21, -0.73, -1.48, 0.05, -1.0, 0.9, 0.48, 0.24, -2.12, 0.72, 0.3, -0.39, -0.42, -0.94, 0.7, 0.0, 0.95, -0.76, 0.79, -0.27, 1.65, 1.22, 0.98, -1.4, 1.46, 1.04, 0.34, 0.31, -0.21, -0.04, 0.44, 0.51, 1.02, 1.72, 1.6631047225355606, 0.49, 2.42, 1.99, 1.75, -0.64, 2.23, 1.81, 1.11, 1.08, 0.56, 0.79, 0.16, -1.05, 0.85, 0.43, 0.19, -2.17, 0.67, 0.25, -0.44, -0.48, -0.99, 0.01, 1.69, -1.79, 1.23, 1.9205204081632652, 1.5017857142857143, 1.25, -1.13, 1.73, 1.31, 0.62, 0.58, 0.06, -1.99, -0.68, -0.42, -0.66, -3.0, -0.18, -0.6, -1.28, -1.32, -1.82, -0.06, -0.48063179677465384, 3.25, 0.46, 0.0, -0.02, -0.18819052351387078, -0.24, -2.58, 0.24, -0.17, -0.86, -0.9, -1.3514153161169342, 0.62, -0.02, -2.35, 0.48, 0.06, -0.5042004503433073, -0.66, -1.17, 0.76, 0.84, 0.16, 0.55, -5.57, 0.13, 0.14, -0.98, 1.1117201258125629, 0.5188101710076211, 0.0, 1.9661635321120494, 0.89, -0.95, -0.46, -1.65, 0.44, 1.42, -1.43, -1.32, 0.46, -1.29, 0.9498783572413152, 0.32, -0.16, 0.6607142857142857, -1.85, -0.45, -0.65, -0.9, 2.38, 2.9, 2.47, 1.8172970521541951, 1.73, 1.21, 1.37, -0.5, -0.41, -1.1, -1.13, -1.64, -0.09, -0.69, -0.72, -1.23, 0.57, 0.43, 0.61, -0.03, -0.55, 0.43, 0.45, 0.74, -1.95, 2.25, 2.01, 0.24, 0.9, 0.64, -0.51, 0.0, 0.1, 0.3, 0.42, 0.31, 1.16, -0.57, 0.94, 0.74], ['304', -2.26, 0.35, 0.11, 0.13, -0.39, -0.1, -1.0158847420401709, -0.14, -0.73, -1.34, 0.16, -0.54, -1.05, -0.83, -1.73, -0.87, -1.67, -1.51, 2.59, -1.51, -1.74, -0.96, -1.62, -1.48, 0.6, -0.38, -1.4673416050068875, -0.7, -1.21, -0.99, -1.8321800287049088, -1.03, -1.83, -1.67, 2.42, -1.67, -1.9, -1.12, -1.78, -1.64, -0.2, -1.94, -0.81, -0.52, -0.29, -1.2, -0.33, -1.14, -0.98, 3.14, -0.98, -1.21, -0.32613444352099813, -1.09, -0.94, -0.14, -0.07, 0.59, -0.73, -0.29, 0.22, -0.69, 0.19, -0.63, -0.46, 3.68, -0.46, -0.7, 0.1, -0.57, -0.43, 0.48, -0.51, -0.91, -0.04, -0.85, -0.69, 3.45, -0.68, -0.92, -0.13, -0.79, -0.65, -1.23, 0.66, -0.6, 0.4366982383853202, 0.88, 0.06, 0.23, 4.4, 0.23, -0.01, 0.79, 0.12, 0.26, 0.52, -0.48, -0.82, -0.65, 3.48, -0.65, -0.89, -0.09, -0.76, -0.62, -0.06, -0.56, -0.04, 0.07, 0.07517906963433994, 0.1, 0.34, 0.17, 4.33, 0.17, -0.07, 0.73, 0.06, 0.2, -0.37, 0.17, 4.16, 0.0, -0.24, 0.56, -0.11, 0.03, -0.04, -0.02, 0.29, 0.19, 1.57, -0.01, 0.0, 0.04, 0.0, -0.03, -0.34, -1.13, -0.25, -0.15, -0.07, -1.18, -0.21, 0.17, -0.29, -0.19, 0.05, 0.03, 0.1, -1.69, 0.89, 1.01, -2.18, -0.71, -0.96, 0.31, -3.83, -3.99, -4.22, -3.45, -4.1, -3.96, 0.17, 0.17, -0.24, 0.56, -0.11, 0.03, 0.41, 0.8, 0.13, 0.27, -0.77, -0.97, -0.39, -0.67, -0.53, 0.07, 0.09, -0.13, -1.16, -0.38, 1.16, -0.39, 0.8, 0.28, 0.14, 0.05, -0.27, 0.29, -0.93, 0.15, 0.14, 1.52, 0.29, 0.18], ['305', -1.99, -0.33, 0.05122171562045875, 0.0, -0.04, -0.11158037632624052, 0.44, -0.59, -0.31, -0.95, -0.91, -1.6, -0.29, -0.34, -1.01, -0.61, -0.52, -0.83, -3.2, -1.16, -1.23, -1.57, -1.11, -0.66, -0.28, -0.52, -0.00734160500688754, -0.69, 0.63, 0.58, -0.1, 0.3, 0.4, 0.08, -2.31, -0.25, -0.32, -0.66, -0.2, 0.25, -0.49, -1.0050638007838266, 0.65, 1.33, 1.28, 0.6, 1.0, 1.1, 0.78, -1.63, 0.45, 0.37, 0.03, 0.5, 0.95, -0.54, -0.59, -0.98, -0.54, -0.67, -0.05, -0.7192006802721088, -0.33, -0.23, -0.55, -2.92, -0.87, -0.94, -1.29, -0.82, -0.38, -0.1, -0.62, -0.67, -0.27, -0.18, -0.49, -2.87, -0.82, -0.89, -1.23, -0.77, -0.32, -0.38, 0.21, -0.25, 0.05, 0.4, 0.5, 0.18, -2.21, -0.15, -0.22, -0.57, -0.1, 0.35, -2.26, -0.26263346878343713, 0.1, -0.22, -2.6, -0.55, -0.62, -0.96, -0.49, -0.05, -0.08, -0.38, 0.61, -0.4, 0.08, -0.88, -0.44, -0.32, -2.7, -0.64, -0.72, -1.06, -0.59, -0.15, 0.66, -0.06692325186963273, -2.39, -0.33, -0.4, -0.74, -0.28, 0.17, 0.13, 0.0, -0.06, -0.26, -6.67, 0.1, 0.0, 2.9, -2.84, -1.44, 0.75, -0.17, -0.32, 0.8, 0.42, -1.0, -0.07, -1.21, 1.16, 1.19, -0.356709195136147, 4.22, -0.78, 0.49, -0.23, -1.25, 0.1527091836734694, 0.83, 1.37, 0.39, 2.32, 2.11, 2.04, 1.68, 2.16, 2.62, -1.24, 0.21, -0.07, -0.42, 0.05, 0.5, 0.28, -0.35, 0.12, 0.57, -0.29, -0.38, 0.63, 0.47, 0.92, -0.39, -0.39, -0.53, 0.27, 0.46, -0.33, -0.05, -0.2, 0.15, 0.5227868514969317, 0.2, -1.35, -0.62, 0.21, -0.13, -0.3, 0.62, -0.44, -0.24], ['306', 4.25, 0.14, 0.02, -0.07, 0.61, -0.05, 0.07, 0.07, 0.4, -0.10291156462585038, -0.81, -1.16, 1.05, -1.31, -1.4757142857142858, -2.6, -0.61, -0.56, -2.03, -0.9974455782312925, -0.03, -0.48, -0.75, -0.2, 1.0, 1.099371414588892, 0.3026583949931125, -0.35, 1.88, -0.5, -0.68, -1.8, 0.18, 0.25, -1.22, -0.52, 0.79, 0.33, 0.07, 0.62, 0.84, 0.7549361992161734, 0.62, 2.24, -0.15, -0.33, -1.46, 0.53, 0.61, -0.88, -0.17, 1.15, 0.68, 0.42, 0.97, 0.64, 0.42, -0.21, 0.39, -1.58, -2.34, -2.51, -3.61, -1.67, -1.59, -3.04, -2.35, -1.06, -1.52, -1.78, -1.24, 0.12, 0.77, -0.18, -1.31, 0.68, 0.76, -0.73, -0.02, 1.3, 0.84, 0.57, 1.12, 0.28, 0.43, -0.44, 0.95, -1.13, 0.86, 0.94, -0.55, 0.16, 1.48, 1.01, 0.75, 1.3, 4.59, 2.11, 2.01, 2.09, 0.6255850340136054, 1.31, 2.64, 2.17, 1.9, 2.46, 0.01, 2.11, -1.12, -0.04, 0.02, -0.14, 0.09, 0.08, -1.4, -0.69, 0.62, 0.16, -0.11, 0.44, -0.21, 0.01, -1.47, -0.77, 0.54, 0.20579954965669267, -0.19, 0.36, 0.49, 0.55, -0.07, -0.04, 13.52, 0.04, 0.05, 0.77, -0.75, -0.38, -1.19, 1.26, -1.58, 0.12, 0.03, 2.31, -0.3, -0.11, 0.0, 0.13, -0.02, 1.27, -0.07, -0.24, 0.1547652642842468, 0.26, 1.2006513605442177, -0.17, -0.29, 1.61, 1.51, 0.71, 2.04, 1.57, 1.31, 1.86, -0.08, 0.79, 1.32, 0.85, 0.59, 1.14, -0.52, -0.46, -0.72, -0.18, 0.44, 0.25, -0.06, -0.26, 0.28, 0.07208003431405688, -0.05, 0.14, 0.67, -0.89, -0.59, 0.07, 1.19, 0.2, 0.55, 0.34, -0.16, -0.86, -0.29, -0.57, -0.35, 3.1202406343656346, 1.93, 0.62], ['307', 5.131428571428571, -6.06, -2.47, 0.34, -2.15, -3.84, -4.15, -7.21, -5.86, -4.56, 4.350608843537414, -1.3, 2.46, 4.17, 1.3371428571428572, -7.799285714285714, 1.19, -0.37942857142857145, -4.49, -0.45, -4.69, 1.9, 3.57, 0.67, -6.37, -4.4, -8.52, -5.4, -1.8, -0.16, -2.89, -11.63, -3.02, -4.52, -8.46, -4.59, -8.65, -2.34, -0.73, -3.52, -4.22, -7.35, -3.3, 3.8, 5.54, 2.65, -6.568956349206349, 2.52, 0.93, -3.24, 0.8607142857142857, -3.44, 3.24, 4.93, 1.99, -5.57, -5.6499999999999995, -5.78, -5.81, -6.85, 1.67, -1.11, -9.799999999999999, -1.24, -2.77, -6.78, -2.84, -6.98, -0.4903418367346939, 1.09, -1.75, -8.72, -8.38, -2.73, -11.426705782312926, -2.86, -4.36, -8.32, -4.44, -8.51, -2.18, -0.57, -3.3064403582748794, -7.98, -22.21, 22.31, -5.8, -9.0, -0.13, -1.67, -5.74, -1.75, -5.93, 0.57, 2.22, -0.64, 2.51, 3.52, 10.378571428571428, 8.05, 3.59, 7.97, 3.37, 10.52, 12.33, 9.18, -4.35, 3.5, -7.25, -4.92, -5.58, -4.78, -5.68, -1.55, -5.62, -1.62, -5.81, 0.7, 2.36, -0.52, -6.05, -4.2, -4.13, -0.08, -4.33, 2.28, 4.042857142857143, 1.05, -8.66, -5.98, -0.75, -6.16, 5.1, -8.9796768707483, -7.28, 9.334285714285715, -8.66, -4.31, -5.08, -12.13, 8.36, 10.021428571428572, 4.954547619047619, 2.635221088435374, -3.6, -15.56, 16.117142857142856, 14.994285714285715, -4.92, 13.507142857142858, -9.85, -5.21, 2.63, -17.13, 28.92, 11.37, 17.15, -8.37, -0.07, 4.23, -0.21, 6.69, 8.45, 5.4, -14.83, -4.12, -4.26, 2.36, 4.040857142857143, 1.7685714285714287, 0.14, 6.91, 8.67, 5.8585714285714285, -6.05, -6.97, -6.33, 1.64, -1.21, -4.95, -5.32, -7.24, 14.53, -7.55, -14.36, -5.76, -6.64, -7.85, -2.81, -5.21, -4.11, -2.4, -3.82, -3.93, -5.19, -6.76, -9.7, -6.94], ['308', 1.31, 0.68, -0.038778284379541256, 0.08, 0.25, 1.05, 0.8741152579598291, 0.41, 1.15, 1.37, -0.28, 0.58, 2.37, 1.74, 0.8, -0.09, 0.91, 1.21, 2.21, 0.4, 1.497335482087359, 0.35, 0.41, 0.25, 1.0, 0.739371414588892, 1.65, 0.86, 2.65, 2.02, 1.08, 0.19, 1.19, 1.49, 2.5, 0.68, 1.74, 0.63, 0.69, 0.53, 0.3374684253532108, 1.0249361992161734, 0.78, 1.78, 1.15, 0.22, -0.67, 0.33, 0.62, 1.62, -0.1788095238095238, 0.87, -0.13613444352099813, -0.17, -0.33, -0.12, 0.92, 0.46, 1.66, -0.98, -0.62, -1.53, -2.4, -1.43, -1.13, -0.15, -1.92, -0.726578845757417, -1.97, -1.92, -2.07, 1.75, -0.37, -0.92, -1.8, -0.82, -0.52, 0.47, -1.31, -0.27, -1.36, -1.31, -1.46, 1.15, 3.06, -3.02, 0.56, -0.88, 0.11, 0.41, 1.4, -0.39, 0.66, -0.44, -0.39, -0.54, 4.41, 1.46, 1.0, 1.3, 2.31, 0.49, 1.55, 0.44, 0.5, 0.34, 0.29, 1.55, 1.52, 1.08, 1.03, 0.97, 0.46, 0.3, 1.29, -0.5, 0.55, -0.55, -0.42401213658444736, -0.5914153161169343, 0.94, 0.16, 0.99, -0.8, 0.25, -0.85, -0.79, -0.95, 0.94, 0.51, 0.11, 0.48, 8.924476190476192, -0.05, 0.14, -1.53, 1.54, 0.8, 0.16406627346681524, 0.96, -1.86, -2.06, -1.05, 0.7, 1.61, 2.95, -2.85, -3.16, 1.02, -2.23, 2.08, -0.27, 0.13, 1.4, -4.23, -0.93, -1.45, 1.81, -0.83, -1.77, -0.74, -1.82, -1.77, -1.92, 3.2, 0.96, 1.05, -0.05, 0.01, -0.15, -0.09, -1.09, -1.04, -1.19, 1.09, 1.43, 1.01, 0.06, -0.1, 1.05, 0.89, 0.64, -2.14, 0.9, 2.05, 0.26, 0.57, 0.96, -0.16, 0.41, 1.0, 1.11, 2.46, 1.8, 1.195957527023814, -1.35, 0.46, 0.26], ['309', -5.53, 1.06, -0.31877828437954125, -0.4078571428571427, 1.53, 3.39, 3.33, 4.95, 4.03, 3.810714285714286, -0.99, 0.7, -0.46, -0.3, -0.14, 7.0, -0.05, 2.95, 0.44, 1.05, 3.87, -0.6069251700680272, -1.14, -0.28, 4.75, 2.75, 4.882658394993112, 1.8284685082657772, 0.53, 0.69, 0.86, 8.07, 0.95, 3.98, 1.44, 2.06, 4.91, 0.46, -0.15, 0.71, 3.01, 5.28, 3.090204081632653, -1.15, -1.0, -0.83, 6.26, -0.75, 2.24, -0.26, 0.35, 3.15, -1.31, -1.8142857142857143, -0.6691712018140588, 3.26, 2.6, 4.81, 5.2, 4.29, 0.16, 0.33, 7.5, 0.42, 3.43, 0.91, 1.52, 4.35, -0.15, -0.68, 0.18, 6.37, 4.13, 0.17, 7.33, 0.26, 3.27, 0.75, 1.36, 4.19, -0.31, -0.84, 0.02, 4.5650595238095235, 12.41, -13.77, 3.95, 7.15, 0.09, 3.09, 0.58, 1.19, 4.01, -0.39428571428571424, -1.0, -0.15, -0.64, -2.98, -6.59, -3.777880952380952, -6.13, -5.56, -2.93, -7.12, -7.61, -6.158571428571428, 0.62, -2.96, 3.54, 3.91, 4.11, 3.69, 3.86, 3.0, 0.49, 1.1105357142857144, 3.92, -0.57, -0.4614285714285715, -0.23, 4.19, 0.83, -2.44, -1.84, 0.899562358276644, -3.46, -3.98, -3.14, 4.43, 3.12, -2.16, 4.05, -1.49, 2.12, 1.03, -8.34, 8.35, 4.17, 3.05, 4.38, -4.961283898641042, -7.75, -3.85, -2.7, 2.93, 11.89, -11.69, -11.55, 3.93, -12.34, 7.81, 1.92, -1.19, 11.31, 20.58, 1.91, 1.86, 5.47, 3.36, 0.61, 3.42, -1.05, -1.5687142857142857, -0.72, 11.36, 2.73, 2.79, -1.65, -2.17, -1.33, -0.06, -4.32, -4.587142857142857, -4.0, 4.06, 4.39, 4.45, -0.53, 0.33, 3.84, 3.81, 5.13, -3.24, 3.88, 3.5, 4.02, 4.42, 5.01, 0.87, 3.6, 3.82, 2.5, 3.2409523809523813, 3.7, 4.11, 3.75, 6.34, 4.26], ['310', 11.188571428571429, 0.19, 0.13122171562045873, 0.05, 1.67, 0.84, 1.8641152579598292, 2.28, 2.08, 1.7370884353741496, -1.34, -0.89, -0.33, -0.7, -0.73, 0.23, 0.13, 0.71, -0.73, -0.43, 2.42, 1.76, 0.38, 0.07, 2.53, 1.98, 2.66, 0.46, 1.03, 0.65, 0.62, 1.59, 1.49, 2.08, 0.6377619047619048, 0.92, 3.81, 3.15, 1.75, 1.43, 1.11, 3.34, 2.19, 0.5736589811608608, 0.19, 0.16, 1.13, 1.02, 1.61, 0.16, 0.46, 3.34, 2.68, 1.28, 0.97, 1.53, 1.47, 1.36, 1.85, 1.62, -0.38, -0.4, 0.55, 0.45, 1.04, -0.3990476190476191, -0.10976190476190477, 2.75, 2.1, 0.7127347454133168, 0.4, 2.45, 2.0, -0.03, 0.94, 0.83, 1.4232142857142855, -0.02, 0.27, 3.14, 2.5614285714285714, 1.09, 0.78, 2.37, 2.69, -2.72, 2.03, 0.96, 0.86, 1.44, 0.0, 0.3, 3.17, 2.51, 1.572517006802721, 0.81, 4.31, 1.06, -0.1, 0.48, -0.95, -0.66, 2.19, 1.5563946608946608, 0.15, -0.15, 0.7, 1.09, 0.8, 0.91, 0.86, 0.995673518650032, 1.16, 0.5813469387755101, -0.85, -0.56, 2.29, 1.63, 0.25, -0.05, -0.24, 0.58, -1.1663144197072766, -1.13, 1.709562358276644, 1.05, -0.32, -0.63, 1.16, 1.14, 0.31603717887804045, 0.91, 8.52, 0.4, 0.35, -1.88, 1.961720125812563, 0.94, 0.81, 1.7, -3.49, -1.84, -0.9, 5.59, 0.36, 2.73, -2.76, -2.69, 0.9, -2.83, 1.79, 0.25, -0.13, 3.5, -4.68, -2.35, -3.46, 3.46, 2.03, 0.3, 3.17, 2.51, 1.12, 0.8, 2.7631678995607567, 1.8643542330685188, 2.86, 2.21, 0.82, 0.51, -1.11, -0.64, -1.99, -2.29, 2.340135138670853, 2.09, -0.47, -1.36, -1.66, 1.03, 0.91, 2.18, -2.31, 0.87, 2.31, 1.52, 1.4211825396825397, 0.9, -0.31, 1.03, 0.81, 0.27, 0.22, 0.84, 1.21, 3.31, 2.37, 1.25], ['311', 8.06, 0.48, 0.19, 0.02, 0.38, 1.08, 1.02, 2.33, 1.3, 1.8, 0.74, 0.38, -0.15, -0.4, -0.69, -0.2792857142857143, 0.44, 1.5505714285714287, 3.76, 0.9, 2.31, 0.7230748299319728, 0.15, 0.81, 1.46, 1.58, 1.05, -0.24153149173422278, -0.89, -1.13, -1.42, -1.02, -0.3, 0.8, 3.0, 0.16, 1.56, -0.02, -0.59, 0.07, 1.53, 1.4749361992161734, 1.41, -0.53, -0.78, -1.06, -0.66, 0.06, 1.16, 3.37, 0.52, 1.92, 0.34, -0.23, 0.43, 1.8, 1.42, 1.44, 1.76, 1.95, -0.25, -0.53, -0.13, 0.6, 1.7, 3.92, 1.06, 2.47, 0.88, 0.3, 0.96, 2.36, 2.21, -0.27535714285714286, 0.12, 0.85, 1.95, 4.18, 1.31, 2.72, 1.13, 0.55, 1.21, 1.19, 4.56, -4.474, 2.5008709226619943, 0.41, 1.14, 2.25, 4.48, 1.6016746031746032, 3.02, 1.42, 0.84, 1.5, 4.2, 2.08, 0.73, 1.83, 4.06, 1.19, 2.6, 1.01, 0.43, 1.09, 0.4, 2.02, 1.81, 1.17, 1.21, 1.14, 1.35, 1.1, 3.31, 0.46, 1.86, 0.28, -0.29, 0.36, 1.08, 0.25, 2.18, -0.64, 0.75, -0.6842004503433073, -1.38, -0.73, 1.52, 1.1, 0.29, 0.88, 12.64, 0.13, 0.15, -2.44, 2.43, 1.22, 0.39, 2.35, -1.82, -2.41, -1.17, 4.1, 0.813079789868779, 3.57, -3.78, -3.6, 1.18, -3.78, 2.38, 1.98, -0.98, 4.09, -10.73, -2.76, -4.18, 1.8, -1.9, -2.76, -1.4, -2.93, -3.49, -2.85, 3.57, 0.89, 1.5441925889236814, -0.18, -0.75, -0.09, -0.5, -1.55, -2.11, -1.47, 1.29, 1.25, 1.07, -0.57, 0.08, 1.22, 1.16, 2.13, -5.02, 1.61, 5.13, 2.2, 1.24, 1.65, 0.66, 0.79, 1.21, 1.34, 0.76, 0.81, 0.98, 4.1, 1.78, 1.14], ['312', -3.94, -0.24, -0.08877828437954126, 0.16, -1.47, -1.59, -2.3, -1.91, -2.11, -1.28, 1.28, 0.78, -0.21, 1.17, 0.29, -0.15, -0.49, -0.97, -3.37, 2.03, -1.78, -0.34, 0.4, -0.53, -1.42, -1.58, -2.53, -0.49, -1.47, -0.11, -0.98, -1.41, -1.75, -2.22, -4.6, 0.74, -3.02, -1.6, -0.87, -1.79, -0.81, -2.935063800783827, -2.0497959183673466, -0.98, 0.39, -0.49, -0.92, -1.26, -1.73, -4.12, 1.24, -2.54, -1.11, -0.38, -1.31, -0.6, -0.89, -2.4, -1.95, -1.08, 1.38, 0.49, 0.06, -0.28, -0.76, -3.17, 2.24, -1.58, -0.13, 0.61, -0.33, -2.42, -2.43, -0.88, -1.31, -1.65, -2.12, -4.5, 0.85, -2.92, -1.49, -0.77, -1.69, -2.57, -4.44, 4.44, -1.57, -0.4294795918367347, -0.77, -1.25, -3.65, 1.74, -2.06, -0.62, 0.11, -0.82, -2.25, -1.062633468783437, -0.34, -0.82, -3.23, 2.18, -1.64, -0.19, 0.6911089783232642, -0.39, -0.33, -1.13, -1.01, -1.22, -1.48, -0.88, -0.8, -0.48, -2.9, 2.54, -1.3, 0.15, 0.89, -0.04, -0.94, -0.32, -2.43, 3.03, -0.82, 0.64, 1.38, 0.44, -1.47, -1.35, 0.08, -0.8, -6.76, -0.25, -0.34, 0.98, -0.96, -0.47, -0.69, -2.77, 6.59, 2.45, 1.23, -1.93, -0.82, -3.63, 3.7, 3.67, -1.22, 1.5, -2.44, -2.18, 1.1, -2.44, 11.59, 1.62, 2.43, -6.33, 2.16, 5.6, 1.8472132867132867, 3.14, 3.9, 3.1057617128436457, -3.65, -3.25, -3.5958074110763185, -2.32, -1.6, -2.52, 0.5, 1.47, 2.22, 1.27, -1.8998648613291471, -2.41, -0.95, 0.74, -0.2, -1.23, -1.14, -1.87, 6.4, -0.53, -6.63, -2.63, -2.38, -1.68, -0.93, -0.8599225974772193, -0.58, -1.2, -0.84, -1.14, -0.75, -2.85, -2.9, -0.5], ['313', 7.854285714285714, 0.59, 0.22122171562045873, 0.48, 0.78, 0.53, 0.5641152579598292, 1.04, 0.89, 1.69, 0.78, 0.46, 0.68, 0.26, 0.44, -0.38, 0.51, 0.94, -2.96, 0.87, 2.01, 0.49104421768707485, 1.26, 1.0, 2.37, 1.29, 0.9, -0.32, -0.1, -0.52, -0.34, -1.15, -0.27, 0.16, -3.7, 0.09, 1.22, -0.33, 0.48, 0.26384172319783916, 0.7674684253532109, 0.55, 1.22, 0.22, -0.2, -0.02, -0.83, 0.05, 0.48, -3.4, 0.41, 1.54, -0.01, 0.8971428571428572, 0.54, 0.86, 2.33, 0.88, 0.48, 1.0, -0.42, -0.24, -1.05, -0.17, 0.26, -3.61, 0.19, 1.32, -0.23, 0.57, 0.32, 0.64, 1.43, 0.18, -0.63, 0.25, 0.68, -3.2, 0.61, 1.75, 0.19, 1.0, 0.74, 0.88, 1.49, -1.46, 1.24, -0.81, 0.07, 0.5, -3.38, 0.43, 1.56, 0.01, 0.82, 0.56, 4.91, 2.07, 0.89, 1.32, -2.59, 1.25, 2.4, 0.83, 1.64, 1.39, 0.7, 2.09, 2.26, 0.75, 0.53, 1.2, 1.17, 0.43, -3.45, 0.35, 1.49, -0.06, 1.3685714285714285, 0.49, 1.21, 0.74, -3.86, -0.07, 1.06, -0.49, 0.32, 0.06, 0.88, 0.8, 0.71, 0.97, 14.397619047619049, 0.34, 0.14, -2.72, 2.72, 1.36, 0.86, 1.84, -1.62, -1.52, -0.78, 3.829285714285714, 0.69, 2.5, -2.4, -2.27, 0.76, -4.18, 1.52, -1.74, 0.79, 3.48, -6.48, -2.48, -3.45, 1.66, 4.78, 3.94, 5.11, 3.5, 4.34, 4.08, 2.3, 0.81, 1.13, -0.42, 0.39, 0.13, -0.31, -1.53, -0.73, -0.99, 1.010135138670853, 0.6, 1.24, 0.81, 0.55, 0.82, 0.83, 1.02, -3.31, 2.33, 3.4, 1.18, 0.7, 0.42, -0.25, 1.1, 0.97, 0.78, 0.930952380952381, 0.64, 0.68, 3.04, 2.171595238095238, 0.98], ['314', -0.31, -0.08, 0.0, 0.02, -1.44, 0.08, -0.16, -0.41, -0.3, 0.31, 0.41, 0.64, 0.42, 1.31, 0.19, 0.22, 0.41, 0.14, 4.89, 4.01, -0.01, -0.23, -0.55, -0.5, -0.46, -0.49, -0.1, 0.23, 0.01, 0.9, -0.22, -0.19, -0.01, -0.27, 4.46, 3.58, -0.42, -0.63, -0.95, -0.91, 0.52, 0.014936199216173434, -0.33, -0.22, 0.67, -0.44, -0.42, -0.23, -0.5, 4.22, 3.35, -0.65, -0.86, -1.18, -1.14, -0.27, -0.3, -0.22, -0.15, -0.11, 0.89, -0.22, -0.2, -0.01, -0.28, 4.46, 3.58, -0.256578845757417, -0.64, -0.96, -0.91, 0.2, -0.99, -1.1, -1.08, -0.9, -1.16, 3.533095238095238, 2.66, -1.31, -1.52, -1.83, -1.79, -0.29, 2.34, -2.29, 0.11, 0.02, 0.6399013605442176, -0.06, 4.69, 3.81, -0.2, -0.42, -0.74, -0.69, -1.4, 0.09, 0.19, -0.08, 4.66, 3.79, -0.23, -0.44, -0.76, -0.72, 0.27, 0.06, 3.96, 0.32, 0.26, 0.36, -0.1, -0.27, 4.47, 3.59, -0.41, -0.63, -0.95, -0.9, 0.49, 0.17, 4.75, 3.87, -0.15, -0.36, -0.68, -0.64, 1.31, 0.59, -0.07, 0.08, -4.04, 0.05, 0.0, -0.69, 0.69, 0.39, -0.32, -0.99, 6.95, -0.53, -0.29, -0.15, 0.49, 1.0, -0.95, -0.95, 0.32, -1.09, 0.62, 0.19, -0.1, -0.34, 0.68, 0.15, 0.33, -7.06, -4.37, -0.84, -4.67, -4.88, -5.18, -5.14, 0.94, -3.56, -3.87, -4.07, -4.38, -4.34, 0.32, -0.22, -0.54, -0.49, -0.39, -0.39, 0.54, -0.32, -0.28, 0.31, 0.27, -0.31, 0.01, 2.34, -0.06, -0.49, -1.29, 0.86, 0.05, 0.22, 0.34, 0.47, 0.48, 0.62, 0.895957527023814, -1.11, -2.21, 0.43], ['315', 0.43, -0.45, 0.17, -0.17, 0.25, 0.49, -1.325884742040171, 0.63, 0.92, -0.05, -1.52, 0.64, -1.2, -0.59, -1.39, 0.14, -0.6, -0.21, -0.34, -0.34633673469387755, 0.37, -0.33, -1.09, -0.28, 0.84, 0.32, 1.49, 2.2, 0.33, 0.94, 0.13, 1.69, 0.94, 1.34, 1.2, 1.17, 1.92, 1.21, 0.43, 1.26, 0.3874684253532108, 1.66, -0.4906967675181959, -1.83, -1.23, -2.02, -0.5, -1.23, -0.84, -0.98, -1.01, -0.27, -0.96, -1.73, -0.92, 1.1, 0.24, 0.69, 1.66, 1.16, 0.61, -0.2, 1.35, 0.61, 1.0, 0.86, 0.84, 1.58, 0.88, 0.1, 0.93, -0.35, 0.54, -0.81, 0.73, -0.01, 0.39, 0.25, 0.22, 0.96, 0.27, -0.51, 0.31, 1.7289098639455782, 3.03, -2.88, 1.36, 1.55, 0.81, 1.2, 1.06, 1.04, 1.78, 1.08, 0.3, 1.1840077275244505, 0.05, -0.19, -0.74, -0.3269047619047619, -0.48, -0.51, 0.23, -0.46, -1.23, -0.42, 0.19, -0.17, 2.56, 0.67, 0.71, 0.705673518650032, 0.55, 0.39134693877551024, 0.26, 0.23, 0.97, 0.27, -0.5, 0.32, 0.35, 0.16, -0.14, -0.17, 0.57, -0.12, -0.89, -0.07, 1.31, 1.14, -0.36, 0.38, 0.13, 0.04, 0.14, -1.7, 1.69, 0.84, 1.12, 1.38, -0.7, -1.31, -0.66, 0.23, 0.32, 2.12, -1.96, -2.08, 0.67, -2.47, 1.35, 0.95, -0.53, 1.63, -4.33, -1.04, -1.56, 0.74, 0.29, -0.03, 0.71, 0.02, -0.75, 0.06, 2.11, 0.32, 0.74, 0.05, -0.73, 0.09, -0.42, -0.69, -1.46, -0.64, 0.94, 1.51, 0.28, -0.77, 0.05, 0.78, 0.63, 0.64, -2.15, 1.48, 2.35, 0.54, 0.7, 1.06, 0.82, 0.53, 0.77, 0.67, 0.26, 0.62, 0.23, 0.23, 0.14, -0.08], ['316', 0.58, 1.27, -0.20877828437954127, 0.12, 0.99, 1.48, 1.2741152579598292, 1.58, 1.73, -0.51, -2.07, -2.68, -1.32, -1.97, -1.1, -2.041439909297052, -2.97, -1.49, -1.21, -0.93, 0.14733548208735894, -1.92, -1.9, -3.03, 2.75, 0.63, 1.6326583949931126, -0.62, 0.77, 0.11, 0.99, -0.29, -0.91, 0.59, 0.88, 1.17, 2.23, 0.16, 0.2688796134390452, -0.98, 0.77, 1.3349361992161735, 2.23, 1.4, 0.74, 1.62, 0.3464030612244898, -0.29, 1.22, 1.51, 1.8, 2.8980654680864433, 0.79, 0.8, -0.36, -0.14, 1.54, 1.7, 1.48, 0.82, -0.66, 0.22, -1.05, -1.67, -0.18, 0.11, 0.5239757335335068, 1.45, -0.61, -0.59, -1.73, 3.39, 1.49, 0.88, -0.4, -1.02, 0.48, 0.77, 1.06, 2.12, 0.05, 0.06, -1.09, 1.4, 4.66, -4.69, 0.6, -1.27, -1.88, -0.4, -0.11, 0.18, 1.22, -0.82, -0.81, -1.95, 1.02, 1.9, -0.62, 0.89, 1.18, 1.47, 2.53, 0.45, 0.47, -0.69, 0.87, 1.91, 3.13, 1.78, 1.52, 2.24, 2.53, 1.52, 1.81, 2.1, 3.17, 1.08, 1.09, -0.07, 1.6, 1.0, 0.29, 0.57, 1.63, -0.43, -0.42, -1.56, 1.7618280382942038, 2.13, 0.05, 2.82, 2.01, 0.75, 0.48, -5.45, 5.45, 2.7, 1.52, 2.63, -0.6, -3.56, -1.78, 0.35, 1.0330797898687791, 5.76, -5.71, -5.31, 1.75, -8.17, 3.51, -1.38, 0.7, 7.61, -4.46, -4.99, -7.56, 0.8738095238095238, 0.71, 0.6171787775716348, 1.34, -0.72, -0.7, -1.84, 5.36, 0.42, 1.05, -1.0, -0.98, -2.12, -0.62, -2.02, -2.01, -3.14, 1.7, 1.55, 1.44, 0.01, -1.13, 1.64, 2.0, 1.46, -2.2, 3.4101996269574992, 1.89, 2.2, 2.11, 1.42, -1.15, 2.28, 2.19, 1.07, 0.06, 1.46, 2.6, 3.25, 2.74, 3.41], ['317', -2.88, -0.85, 0.011221715620458745, 0.14, -0.55, 0.1, -1.73, -0.96, 0.0, -1.75, -2.06, -1.28, -0.3960867348791511, -0.23, -1.29, -1.4, -1.25, -1.75, -1.09, -1.75, -1.31, -1.52, -1.27, -1.28, -0.33, -0.29, 0.32, 0.8, 1.64, 1.87, 0.79, 0.68, 0.83, 0.32, 0.9907142857142857, 0.32, 0.77, 0.55, 0.81, 0.8, -0.25, 0.45, -0.48, 0.83, 1.06, -0.02, -0.12, 0.03, -0.48, 0.19, -0.48, -0.03, -0.25, 0.01, 0.0, 0.0, 0.42, -0.44, 0.52, -1.3, 0.23, -0.84, -0.95, -0.8, -1.3, -0.64, -1.3, -0.86, -1.07, -0.82, -0.82, -0.77, -1.52, -1.07, -1.17, -1.02, -1.52, -0.86, -1.52, -1.08, -1.3, -1.04, -1.05, 0.14, -1.12, 1.1, -0.46, -0.11, 0.04, -0.46, 0.21, -0.46, -0.02, -0.23, 0.02, 0.02, -3.04, -0.35, 0.15, -0.35, 0.31, -0.35, 0.09, -0.12, 0.13, 0.12, -0.02, -0.46, 1.24, -0.1384018193170985, -0.10482093036566006, -0.21, -0.5, -0.5, 0.16, -0.5, -0.06, -0.27, -0.02, -0.03, -0.33, 0.0, 0.67, 0.0, 0.45, 0.23, 0.49, 0.48, -0.79, -0.82, 0.3, -0.48, -9.03, 0.06, -0.06, 0.54, -0.56, -0.28, 0.08, -0.34, 0.08, 0.37, 0.13, -1.43, -0.06, -0.52, 0.43, 0.53, -0.14670919513614705, 0.86, -0.37, -1.72, 0.87, -1.46, 1.05, 0.95, 1.5, -0.14, -0.66, -0.66, -0.22, -0.43, -0.18, -0.19, -0.55, 0.0, 0.45, 0.23, 0.48, 0.48, -0.44, -0.22, 0.04, 0.03, 0.0, 0.28, -0.23, 0.25, 0.25, -0.18, -0.22, -0.88, 0.13, 0.0, -0.18, -1.042736189475567, -0.23, -0.48, 0.06278685149693167, -0.17, 0.03, 0.1, 0.19, -0.11, -0.48, -1.5, -1.07, -0.5], ['318', -3.31, 0.45, -0.02, -0.18, 0.65, 0.10841962367375949, 1.64, 0.1, 0.34, 0.03, -0.17, -1.21, 0.17, 0.25, -0.71, 1.64, -0.72, -0.05, -2.71, -1.17, -0.43266451791264104, -0.06, -0.83, -0.5, -0.41, 0.0, 0.2, -1.04, 0.34, 0.42, -0.54, 1.81, -0.55, 0.13, -2.55, -1.0, -0.3, 0.11, -0.66, -0.33, 0.4, 0.07, 1.26, 1.4, 1.48, 0.51, 2.89, 0.5, 1.18, -1.52, 0.04, 0.75, 1.16, 0.39, 0.73, -0.18, -0.21, 0.40782797280978395, 0.03, -0.14, 0.08, -0.88, 1.47, -0.89, -0.21, -2.88, -1.2160242664664933, -0.64, -0.23, -1.0, -0.66, -0.14, -0.22, -0.96, 1.39, -0.97, -0.29, -2.95, -1.41, -0.72, -0.31, -1.07, -0.74, 0.27, 2.55, -2.6, 0.7866982383853202, 2.37, -0.01, 0.67, -2.01, -0.46, 0.24, 0.65, -0.12, 0.27400772752445063, -2.69, -1.58, -2.32, -1.66, -4.28, -2.76, -2.08, -1.67, -2.43, -2.1, -0.06, -1.63, 1.15572371188304, 0.49, 0.54, 0.535673518650032, 0.76, 0.68, -2.0, -0.45, 0.25, 0.66, -0.11, 0.23, 0.12, 0.07, -2.67, -1.12, -0.43, -0.02, -0.78, -0.45, 0.97, 0.89, -0.38, 0.713186783623568, -7.99, 0.29, 0.07, -0.89, 0.971720125812563, 0.39, -0.08, 1.19, -2.48, -0.99, -0.52, -1.73, 0.15, 1.46, -1.46, -1.51, 0.5, -1.27, 0.99, 2.04, -1.03, 2.27, -4.02, -1.5, -2.23, 2.52, 2.82, 1.59, 2.3, 2.72, 1.94, 2.28, 1.48, 1.21, 0.7, 1.12, 0.34, 0.68, 0.5, 0.41, -0.36, -0.02, 0.36, 0.17, 0.09, -0.77, -0.43, 0.52, 0.56, 0.02, -2.07, 1.1, 2.1, 0.66, 1.26, 0.86, 0.34, 0.99, 0.47, -0.38, 0.23, 0.06, 0.615957527023814, 0.78, 1.84, 1.03], ['319', 0.1, 0.3, 0.13122171562045873, -0.14, 0.05, 0.23, 0.9241152579598292, 0.73, 1.12, 1.61, 0.63, 0.73, 0.53, 1.48, 0.74, 2.15, 1.09, 1.01, 8.25, 2.016979591836735, 2.02, 1.11, 0.67, 0.94, -0.28, 0.37, 0.97, 0.1, -0.1, 0.84, 0.1, 1.51, 0.45, 0.37, 7.57, 1.785112244897959, 1.38, 0.47, 0.03, 0.3, 2.4, 3.0049361992161736, 0.86, -0.2, 0.74, 0.0, 1.4, 0.35, 0.27, 7.46, 1.23, 1.308065468086443, 0.37, -0.07, 0.2, 0.07, 0.38, 1.54, 0.79, 1.07, 0.94, 0.21, 1.61, 0.55, 0.47, 7.68, 1.43, 1.48, 0.58, 0.13, 0.4, 1.52, 0.12, -0.73, 0.66, -0.39, -0.47, 6.67, 0.49, 0.53, -0.36, -0.8, -0.54, 1.73, 2.48, -2.4640000000000004, 0.86, 1.4, 0.34, 0.27, 7.45, 1.423744771101914, 1.27, 0.37, -0.07, 0.2, -2.217904761904762, -0.53, -1.04, -1.12, 5.97, -0.17, -0.13, -1.02, -1.45, -1.19, 0.36, -0.39063179677465387, -0.37, 0.46, 0.35, 0.68, 0.51, -0.08, 7.09, 0.88, 0.92, 0.03, -0.41, -0.15, 0.65, 0.59, 7.17, 0.96, 1.0, 0.1, -0.34, -0.07, -0.28, -0.53, -0.13, 0.9, -6.93, 0.65, 0.36, -1.29, 1.28, 0.63, 0.76, 0.14, 0.76, -0.96, -0.49, 0.07, -0.12, 1.57, -1.58, -1.4, 0.45, -2.04, 0.94, 2.97, -1.46, 1.56, -4.13, -1.1, -1.6, -0.8, -6.14, -5.8, -5.75, -6.59, -7.0, -6.76, 1.4, -0.36, 0.04, -0.85, -1.28, -1.02, -0.4, -0.89, -1.33, -1.06, 1.04, 1.22, 0.49, -0.44, -0.17, 0.5, 0.57, 0.85, -1.96, 0.13, 2.15, -0.03, 0.37, 0.93, 0.27, 0.95, 0.6, 0.32, -0.86, -0.03, 0.66, 0.6, -0.61, 1.05], ['320', 3.3242857142857143, 0.11, 0.08, 0.04, -0.2270209190089404, 0.75, 1.74, 0.44, 0.6, -0.29, -0.25, -1.65, 0.42, -0.66, -0.27, -1.67, -0.77, -0.59, -0.14, -0.43, -0.36, -0.7, -0.51, -0.9848833725798009, -0.11, 0.21, -0.04, -1.4, 0.67, -0.41, -0.01, -1.1049642857142856, -0.52, -0.33, 0.12, -0.18, -0.11, -0.45, -0.26, -0.88, -0.15, 0.58, 1.38, 2.11, 1.01, 1.41, -0.02, 0.9, 1.08, 1.54, 1.24, 1.31, 1.0538655564790018, 1.16, 0.53, 0.63, 0.29, 0.45, 0.51, -0.71, -1.08, -0.68, -2.08, -1.19, -1.0, -0.55, -0.85, -0.6165788457574171, -1.12, -0.93, -1.55, 1.17, 0.37, 0.4, -1.02, -0.11, 0.07, 0.7774764481550197, 0.23, 0.3, -0.04, 0.15, -0.48, 0.34, 0.78, -0.8, -0.03, -1.41, -0.5, -0.32, 0.3657885487528346, -0.16, -0.09, -0.44, -0.25, -0.87, 1.48, 1.4, 0.91, 1.1, 1.56, 1.26, 1.33, 0.98, 1.18, 0.54, 0.19, 1.42, 3.56, 0.49, 0.47, 0.47, 0.48, 0.19, 0.64, 0.34, 0.41, 0.07, 0.26, -0.37, 0.48, 0.29, 0.45, 0.16, 0.23, -0.12, 0.07, -0.55, 0.28, 0.37, -0.11, 0.39, 4.29, 0.12, 0.2, -0.6, 0.58, 0.3, 0.47, 0.69, -0.52, -0.98, -0.46, 1.3, 0.32, 1.36, -1.45, -1.44, 0.48, -0.98, 0.94, 0.51, -0.23, 1.37, -0.18, -0.85, -1.34, 0.14, -0.16, -0.29, -0.22, -0.57, -0.38, -1.0, 1.45, 0.14, 0.07, -0.27, -0.09, -0.71, 0.07, -0.34, -0.15, -0.78, 0.56, 0.58, 0.41, 0.19, -0.44, 0.45, 0.44, 0.52, 0.16, 2.92, -1.15, 0.94, 0.82, 0.22, -0.62, 0.6, 0.58, 0.09, 0.27, 0.11, 0.85, 0.49, 0.39, 0.17], ['321', 0.81, -0.23, -0.009847101690729465, 0.02, -0.45, 0.39, 1.74, 0.0, 0.87, 0.23, -0.45, -1.4, 0.27, 1.46, 0.5, -0.07, 0.08, 0.24, -0.93, 1.33, 0.61, -0.29, -0.07, -0.81, 0.83, -0.14, 0.68, -0.95, 0.73, 1.93, 0.96, 0.38, 0.54, 0.69, -0.48, 1.8, 1.07, 0.16, 0.38, -0.36, 0.04, 0.65, 1.65, 1.7, 2.91, 1.93, 1.35, 1.51, 1.66, 0.5771355564861204, 2.78, 2.04, 1.13, 1.35, 0.6, 0.5600628463056766, 0.14, 1.14, 0.54, -0.05, 1.19, 0.23, -0.34, -0.19, -0.04, -1.2, 1.06, 0.34, -0.56, -0.34, -1.08, -0.22, -1.22, -0.95, -1.52, -1.36, -1.21, -2.36, -0.13, -0.84, -1.73, -1.51, -2.24, 0.69, 1.06, -1.07, -0.27, -0.57, -0.42, -0.26, -1.43, 0.83, 0.11, -0.79, -0.57, -1.3, -0.92, 0.3, 0.15, 0.31, -0.86, 1.41, 0.68, -0.22, 0.0, -0.74, 0.04, 0.33, 0.22, 0.36, 0.43, 0.35, 0.14, 0.15, -1.01, 1.25, 0.53, -0.37, -0.15, -0.89, 0.45, -0.01, -0.9063144197072766, 1.1, 0.37, -0.4042004503433073, -0.31, -1.04, -0.22, -0.51, 0.12, 0.3, -3.27, 0.12, 0.03, 0.32, -0.21, -0.13, 0.0, -1.3, 2.16, -0.75, -0.36, 0.37, 0.38, 1.12, -1.02, -1.06, 0.35, 0.38, 0.73, -0.43, 0.23, 0.53, -1.72, -0.3, -0.49, -2.14, 1.17, 2.29, 1.55, 0.64, 0.87, 0.12, 1.12, -1.09, -0.72, -1.61, -1.39, -2.12, -0.38, -0.9, -0.68, -1.41, 0.82, 0.68, 0.52, 0.22, -0.52, 0.4720800343140569, 0.38, -0.05, -0.21, 0.4401996269574993, 0.12, 0.54, 0.33, 0.3, -0.74, 0.26, -0.46, 0.57, 0.12, 1.03, 1.04, -0.79, 0.05, 2.48], ['322', -0.37, -0.77, 0.0, 0.1, -1.75, -0.42158037632624057, -0.7158847420401708, -1.1382794034640413, -1.19, -0.8, 1.2, -0.21, 0.07, 0.31, 1.07, -0.3, 0.23, -0.78, 5.03, 2.15, -0.91, -0.26, 0.79, -0.13, -0.81, -1.24, -1.9373416050068875, -1.39, -1.11, -0.87, -0.12, -1.48, -0.95, -1.95, 3.79, 0.94, -2.08, -1.44, -0.4, -1.31, -3.05, -2.92, -0.59, 0.29, 0.52, 1.29, -0.09, 0.45, -0.57, 5.25, 2.36, -0.7, -0.05, 1.0, 0.08, -0.45, -1.32, -2.6, -0.76, -0.87, 0.3431047225355606, 1.0, -0.37, 0.16, -0.85, 4.95, 2.07, -0.99, -0.34, 0.71, -0.21, -1.15, -1.11, 0.76, -0.61, -0.08, -1.08, 4.7, 1.83, -1.22, -0.57, 0.47, -0.44, -1.93, -4.43, 4.38, -1.85, -1.36, -0.83, -1.83, 3.91, 1.07, -1.96, -1.32, -0.28, -1.1359922724755493, -1.08, -0.5, 0.54, -0.48, 5.34, 2.46, -0.61, 0.04, 1.09, 0.17, -0.2, -0.49, -2.38, -0.77, -0.84, -0.67, -1.03, -1.01, 4.78, 1.91, -1.14, -0.5, 0.55, -0.3114153161169343, -0.57, -0.03, 5.85, 2.95, -0.14, 0.52, 1.57, 0.65, -1.57, -1.51, 0.27603717887804047, -0.81, -3.11, -0.28, -0.28, 1.74, -1.74, -0.88, -0.32, -1.5, 5.77, 1.52, 0.78, -0.22, -0.23692021013122094, -2.21, 2.22, 2.28, -0.76, 2.8, -1.53, -1.34, 0.64, -3.07, 7.08, 1.98, 3.11, -5.69, -5.55, -2.74, -5.66, -5.04, -4.04, -4.91, -2.34, -2.89, -3.0, -2.36, -1.33, -2.23, 0.11, 0.66, 1.72, 0.79, -1.24, -1.31, -0.54, 1.05, 0.13, -0.78, -0.6956036987247092, -1.22, 3.58, -1.66, -3.61, -0.9, -1.01, -1.58, -0.91, -0.56, -0.77, -0.42, -0.01, -0.11, -0.67, -1.02, -2.05, -0.9], ['323', 7.08, 0.06, -0.23877828437954127, 0.05, 0.65, -0.17, 0.71, 0.4, -0.12, 0.77, 1.52, -0.17, -0.07, 1.39, 0.69, -0.3792857142857143, 1.06, 1.3205714285714287, 1.48, 0.27, 0.87, 0.8730748299319728, 1.15, 0.75, 0.23, 0.27, -0.73, -1.67, -1.57, -0.13, -0.82, -1.87, -0.44857142857142857, -0.2, -0.03, -1.23, -0.64, -0.64, -0.37, -0.76, 0.73, -0.74, 0.95, 0.1, 1.56, 0.86, -0.1889563492063492, 1.23, 1.49, 1.66, 0.44476190476190475, 1.04, 1.05, 1.32, 0.9250476190476191, 0.6700628463056766, 1.0842857142857143, 0.38, -0.32, 0.84, 1.46, 0.76, 0.3385714285714286, 1.13, 1.39, 1.56, 0.34, 0.94, 0.94, 1.22, 0.82, 1.31, -0.61, -0.69, -1.3133418367346938, -0.32, -0.07, 0.1, -1.1, -0.52, -0.51, -0.24, -0.63, -0.66, -0.85, 0.87, 0.09, -1.06, 0.37, 0.63, 0.79, -0.42, 0.18, 0.2757142857142857, 0.46, 0.06, 1.932095238095238, 1.16, 1.4528571428571428, 1.71, 1.88, 0.65, 1.25, 1.502816996495568, 1.54, 1.13, -0.66, 1.21, 0.65, -0.12, -0.37, 0.05, -0.28, 0.25, 0.42, -0.79, -0.19, -0.19, 0.08, -0.31, -0.02, -0.54, 0.17, -1.04, -0.45, -0.44, 0.41999999999999993, -0.56, -0.49, -0.13, -0.26, -0.29, 4.0, -0.1319304505018789, -0.47, -0.63, 0.55, 0.33, 0.0, 1.12, -1.1, 0.27, 0.14142857142857143, 3.51, -0.25, -0.38, 0.36, 0.38, -0.11, -0.8, -0.24, -0.7516093450200592, 0.48, -0.84, -2.95, 0.56, 0.97, 1.07, -0.7, -1.2, -0.61, -0.6, -0.33, -0.73, -0.31, 0.5, 0.6, 0.6, 0.9298095238095239, 0.48, -0.09, 0.01, 0.28, -0.12, -0.11, -0.51, -0.1, 0.27, -0.12, -0.11, -0.15, 0.52, -1.5, 0.38, 1.18, -0.31, -0.7, -0.37, -0.4, -0.53, 0.0, 0.43, -0.79, 0.43, 0.03, -0.38, -0.44, -0.57], ['324', -1.5, -0.19, 0.1, -0.06, -0.4, 0.19841962367375948, 1.17, -0.69, 0.05, -1.31, -1.08, -2.25, -0.39, -0.74, 0.3, -1.07, -1.82, -1.4, -2.68, -1.34, -1.66, -1.48, -1.61, -1.83, -0.54, -1.05, -0.24, -1.19, 0.7, 0.34, 1.39, 0.01, -0.75, -0.32, -1.62, -0.27, -0.5155463299214309, -0.41, -0.53, -0.76, -0.9, -0.9450638007838266, 0.96, 1.91, 1.55, 2.61, 1.21, 0.44, 0.87, -0.43, 0.93, 0.6, 0.79, 0.66, 0.44, -0.41, -0.29, 0.37, 0.55, -0.93, -0.35, 0.69, -0.69, -1.43, -1.01, -2.3, -0.96, -1.28, -1.1, -1.22, -1.44, -0.3, -0.58, 1.04, 0.09665816326530619, -1.09, -0.66, -1.95, -0.61, -0.93, -0.75, -0.87, -1.1, -0.18, 0.97, -1.03, -1.61, -1.37, -2.11, -1.69, -2.97, -1.64, -1.96, -1.78, -1.9, -2.12, -2.51, -0.24, -0.75, -0.33, -1.62, -0.27, -0.6, -0.42, -0.54, -0.76, 0.06, -0.25, 0.83, 0.24, 0.30517906963433994, 0.38567351865003197, 0.51, 0.43, -0.88, 0.48, 0.16, 0.34, 0.22, -0.01, 0.09, 0.09, -1.3, 0.06, -0.27, 0.035799549656692686, -0.21, -0.43, 0.48, 0.57, -0.07, 0.41, -7.41, 0.11, 0.13, -0.38, 0.39, 0.23881017100762114, 0.16, -0.8, -0.07, -0.45, -0.24, -0.74, 0.32, 0.69, -0.79, -0.67, 0.22, -0.59, 0.5298783572413152, 0.25, -0.15, 1.53, -1.25, -1.04, -1.56, 0.07380952380952381, 1.4, 1.37, 1.04, 1.23, 1.1, 0.87, 0.6808051948051949, 0.03, -0.32, -0.14, -0.27, -0.49, 0.36, 0.18, 0.06, -0.17, 0.05, -0.08, 0.17, -0.13, -0.35, 0.24, 0.28, -0.69, -0.86, 0.5, 0.98, 0.0, -0.11, 0.3, -0.22, 0.43, 0.25, 0.27, 0.37, 0.11, 0.52, -1.53, -0.12, 1.3130167737073972], ['325', -2.51, -0.06, 0.02, -0.24, 0.18, -0.05, -4.53, -0.97, -1.18, -0.36, 0.05, 3.4, 0.26, 0.26, 0.98, -0.6, 1.02, 0.02, -0.45, -0.07, -0.01, -0.18, -0.03, 0.19, -0.24, -0.33, -0.41, 3.35, 0.21, 0.22, 0.93, -0.65, 0.97, -0.03, -0.48223809523809524, -0.12, -0.06, -0.23, -0.08, 0.14, -1.0745146341753484, -0.8350638007838266, -3.64, -3.04, -3.03, -2.34, -3.87, -2.3, -3.27, -3.72, -3.36, -3.3, -3.46, -3.32, -3.11, -1.0, -0.8, -0.15, -0.49, -0.62, 0.11310472253556063, 0.72, -0.85, 0.76, -0.24, -0.709047619047619, -0.33, -0.27, -0.43, -0.29, -0.07, -0.78, -0.62, 0.71, -0.86, 0.75, -0.25, -0.71, -0.34, -0.27, -0.44, -0.3, -0.08, -0.61, -1.29, 1.25, -1.33, -1.5594795918367348, 0.04, -0.95, -1.42, -1.04, -0.98, -1.15, -1.0, -0.78, -1.27, 0.3173665312165629, 1.63, 0.62, 0.15, 0.53, 0.59, 0.42, 0.57, 0.79, -0.46, 0.24, -1.51, -0.31, -0.31, -0.53, -1.37, -0.99, -1.46, -1.08, -1.02, -1.19, -1.04, -0.7614153161169342, -0.2, -0.38, -0.47, -0.09, -0.03, -0.19, -0.05, 0.41217743764172343, -0.91, -1.29, -0.11, -0.98, -3.74, -0.4264527417027417, -0.04, 1.12, -1.06, -0.55, -0.64, -1.0, 0.46, 0.61, 0.34, -1.28, -0.26, -0.91, 0.81, 1.02, -0.31, 1.6, -0.74, -1.26, 0.4547652642842468, -4.03, 0.28, 2.69, 3.99, -0.47286904761904763, 0.09, 0.38, 0.44, 0.28, 0.42, 0.64, -1.03, -0.29, 0.06, -0.1, 0.04, 0.26, -0.35, -0.17, -0.02, 0.2, -1.23, -0.41, -0.18, 0.15, 0.37, -0.33, -0.49, -0.7274239503761217, 0.5, -1.45, -0.55, -0.88, -0.1, -0.33, 0.22, -1.08, -0.46, -0.1, -0.2, -0.07, -0.55, -2.01, -0.98, -0.88], ['326', 2.43, 0.7, -0.15877828437954128, -0.24, 0.4529790809910596, 1.01, 1.5541152579598292, 0.83, 1.01, 0.81, -0.66, -0.04, -0.56, 0.34, 0.86, 0.54, -0.11, 0.56, 4.47, 0.23071428571428573, 0.43, 1.7, -0.6, -0.13, 1.49, 0.88, 1.47, 0.62, 0.09, 1.0, 1.52, 1.2, 0.54, 1.22, 5.16, 0.8907142857142857, 1.09, 2.38, 0.05, 0.53, 0.93, 0.94, 0.85, -0.53, 0.38, 0.89, 0.58, -0.08, 0.6, 4.51, 0.27, 0.47, 1.74, -0.57, -0.09, 0.8500628463056766, 0.72, 0.94, 1.16, 1.4592452470658774, 1.0131047225355607, 1.43, 1.11, 0.45, 1.13, 5.06, 0.8, 1.0, 2.28, -0.04, 0.44, 0.5, 0.47, 0.51, 0.2, -0.46, 0.22, 4.11, -0.11, 0.09, 1.36, -0.94, -0.47, 1.35, 3.43, -3.2971666666666666, -0.05, -0.31, -0.96, -0.29, 3.58, -0.62, -0.42, 0.84, -0.9974829931972791, -0.9259922724755494, 1.89, 0.27, -0.65, 0.02, 3.91, -0.31, -0.11, 1.16, -1.14, -0.67, 0.16, 0.33, 1.07, 1.01, 1.06, 0.87, 0.93, 0.68, 4.59, 0.35, 0.55, 1.82, -0.49, -0.02, -0.79, 0.3030767481303673, 3.89, -0.33, -0.13, 1.14, -1.1542857142857141, -0.69, 1.65, 0.49, -0.37, 0.64, 3.71, -0.1, -0.02, -0.79, 0.8, 0.4, 0.34, 2.52, -1.17, -1.99, -1.0, 1.19, 0.66, 2.87, -2.89, -2.9, 1.0, -1.26, 2.05, 1.31, -0.68, 2.76, -6.94, -1.92, -2.77, 1.15, -3.5, -4.06, -3.87, -2.65, -4.86, -4.4, 3.03, 0.58, 0.2, 1.47, -0.83, -0.36, 0.38, 1.27, -1.03, -0.56, 1.05, 1.4184535464535466, -0.88, -2.27, -1.8, 1.07, 0.97, 0.73, -3.43, 1.45, 3.45, 1.89, 1.5, 1.42, 0.48, 0.92, 0.4845528598385743, 0.92, 0.14, 1.48, 0.94, 1.61, 1.77, 1.67], ['327', 0.17, 0.06, 0.22, -0.15, -0.09, 0.39, 0.03, 0.05172059653595872, -0.05, -0.84, -0.1, -1.1, -1.01, -0.72, -1.09, -1.11, -0.71, -0.81, 0.54, -0.52, -0.98, -1.17, -1.3, -1.04, 0.72, 0.21, -0.73, -1.0, -0.91, -0.62, -0.99, -1.01, -0.61, -0.71, 0.65, -0.42, -0.88, -1.06, -1.2, -0.94, 0.0, -1.49, 0.27, 0.09, 0.38, 0.01, -0.01, 0.39, 0.29, 1.66, 0.59, 0.12, -0.07, -0.2, 0.06, -0.54, 1.11, 0.0, -0.11, 0.18, 0.29, -0.09, -0.1, 0.3, 0.2, 1.57, 0.49, 0.03, -0.16, -0.3, -0.04, 0.35, -0.11, -0.37, -0.39, 0.01, -0.09, 1.28, 0.2, -0.26, -0.45, -0.58, -0.32, -0.62, 1.07, -1.07, 0.26, -0.02, 0.38, 0.29, 1.66, 0.58, 0.12, -0.07, 0.24251700680272095, 0.05, 0.68, 0.3573665312165629, 0.4, 0.3, 1.68, 0.6, 0.13, -0.05, -0.19, 0.07, 0.01, 0.27, 0.4, 0.11, 0.29, -0.11, -0.12, -0.1, 1.27, 0.19, -0.27, -0.45, -0.59, -0.27141531611693437, 0.37, -0.02, 1.37, 0.38224471370562696, -0.17, -0.36, -0.49, -0.24, 0.34, -0.15, -0.16, 0.03, 1.86, 0.05, -0.07, 1.63, -1.44, -0.7, 0.18, 0.37, 0.6, -0.23, -0.15, 0.07, 0.05, 0.2, -0.34, -0.36, 0.11, 2.15, 0.21, 1.71, -0.88, -0.01360430839002269, -2.67, 0.26, 0.45, -0.6, -1.37, -0.7328212224283652, -1.52, -1.7, -1.84, -1.58, 0.39, -0.32, -0.46, -0.65, -0.78, -0.53, 0.15, -0.19, -0.32, -0.07, -0.03, -0.44, 0.33, -0.14, 0.12, 0.09, 0.08, 0.02, -1.21, 0.21, 1.24, 0.7172638105244333, 0.3, 0.47, 0.26, 0.3, -0.69, 0.54, -0.21, 0.05, 0.295957527023814, 0.13, 0.58, -0.18], ['328', 6.37, 1.05, 0.92, -0.32, 2.17, 2.41, 2.1941152579598295, 4.28, 3.65, 3.38, -2.19, 1.09, -0.24, -0.84, -1.41, 1.07, -0.46, 1.123469387755102, 2.19, -0.02, 5.13, -0.45, -0.49, 0.21, 4.43, 3.88, 5.7, 3.35, 2.0, 1.38, 0.8, 3.33, 1.77, 3.38, 4.48, 2.22, 7.490760683760684, 1.78, 1.74, 2.45, 3.56, 6.48, 2.27, -1.31, -1.91, -2.47, -0.02, -1.42071768707483, 0.03, 1.09, -1.09, 4.0, -1.52, -1.56, -0.87, 2.36, 4.44, 3.53, 3.23, 3.63, -0.61, -1.17, 1.31, -0.22, 1.35, 2.43, 0.22, 5.38, -0.22, -0.25, 0.45, 4.6, 4.26, -0.57, 1.93, 0.39, 1.97, 3.06, 1.1491309523809523, 6.03, 0.39, 0.36, 1.06, 5.02, 10.76, -10.89, 4.86, 2.51, 0.97, 2.56, 3.65, 1.41, 6.64, 1.597142857142857, 0.93, 1.64, 3.02, 2.29, -1.51, 0.04, 1.1, -1.08, 4.02, -1.51, -1.54, -0.85, 1.96, 2.29, 3.17, 2.86, 2.91, 2.97, 3.85, 1.57, 2.65, 0.44, 5.61, 0.0, -0.03, 0.67, 3.69, 2.24, 1.06, -1.12, 3.98, -1.55, -1.58, -0.89, 3.96, 4.67, 0.13, 3.36, 6.17, 1.13, 0.88, -6.18, 6.17, 3.09, 2.48, 5.41, -6.64, -5.77, -2.89, 3.11, 2.06, 8.83, -8.7, -8.5, 2.84, -9.27, 5.76, 2.99, -1.51, 11.77, -10.43, -7.7, -11.45, 6.81, 1.17, -1.8328212224283653, 2.88, -2.58, -2.62, -1.94, 8.64, 3.4, 5.15, -0.43, -0.47, 0.23, -1.67, -5.31, -5.35, -4.69, 3.68, 4.34, 3.85, -0.03, 0.66, 2.95, 3.004396301275291, 4.31, -5.31, 4.19, 5.42, 3.67, 4.3210935020800125, 3.968637448200971, 0.7, 3.01, 2.68, 1.36, 1.89, 2.39, 3.17, 4.91, 7.18, 3.13], ['329', 0.62, 0.04, -0.49, 0.2, -0.2, 0.38, 0.64, 1.15, 1.15, 1.8, 0.07, 0.57, 0.7, 1.29, 0.04, 1.69, 0.97, 1.59, 3.55, 1.86, 2.15, 1.51, 1.3, 1.73, 1.08, 0.51, 1.73, 0.49, 0.63, 1.22, -0.03, 1.61, 0.9, 1.52, 3.47, 1.79, 2.08, 1.43, 1.23, 1.66, 1.05, 2.45, 1.23, 0.13, 0.72, -0.45918497042472345, 1.11, 0.4, 1.02, 2.961652133580705, 1.29, 1.58, 0.93, 0.8271428571428572, 1.16, 1.15, 1.69, 1.44, 0.87, 1.1792452470658776, 0.59, -0.66, 0.98, 0.27, 0.89, 2.83, 1.15, 1.44, 0.8, 0.6, 1.03, 0.14, 0.5, -1.2253571428571428, 0.39, -0.32, 0.29, 2.22, 0.56, 0.85, 0.21, 0.01, 0.43, 1.6, 2.12, -2.15, 1.76, 1.65, 0.93, 1.55, 3.51, 1.82, 2.12, 1.47, 1.26, 1.7440077275244505, -0.51, 0.11, -0.71, -0.09, 1.83, 0.17, 0.46, -0.18, -0.38, 0.04, 0.13, 0.13244557823129252, 0.88, 0.63, 0.56, 0.76, 0.83, 0.62, 2.55, 0.88, 1.17, 0.53, 0.33, 0.8185846838830657, 0.24, 0.21, 2.173685580292723, 0.26, 0.7286030199958774, -0.09, -0.28, 0.14, 0.2189583699631245, 0.34, 0.44, 0.53, -1.71, 0.01, -0.66, -1.62, 1.73, 0.61, 0.06, 2.85, -0.09, -1.22, -0.61, 0.25, 0.11, 1.85, -1.93, -1.81, 0.11, -2.53, 1.26, -1.14, 0.58, 2.5, -3.34, -1.68, -2.47, 0.04, -1.68, -1.63, -1.34, -1.97, -2.17, -1.75, 1.84, -0.06, 0.29, -0.35, -0.55, -0.13, -0.34, -0.64, -0.83, -0.41, 1.2, 1.22, 0.29, -0.2, 0.22, 0.6, 0.66, 1.12, -1.55, 0.4, 1.42, 0.5172638105244333, 0.46, 0.49, 0.42, 0.03, 0.5, -0.59, -0.5, -0.03, 0.07, 0.58, 1.46, 0.33], ['330', 0.41, 0.0, 0.24122171562045874, 0.19, -0.3, 0.14, -1.2158847420401708, -0.9482794034640413, -0.55, -3.51, -2.75, -2.98, -3.07, -2.81, -2.29, -3.53, -3.38, -3.44, -0.71, -2.53, -3.762664517912641, -3.46, -4.1, -3.82, 0.29, -0.21, -0.78, -0.23, -0.33, -0.06, 0.47, -0.79, -0.64, -0.7, 2.1, 0.23, -1.07, -0.72, -1.2811203865609546, -1.1, -0.38, -1.5950638007838267, -0.55, -0.09, 0.17, 0.71, -0.56, -0.41, -0.47, 2.34, 0.46, -0.811934531913557, -0.49, -1.15, -0.87, -0.14, -0.59, -0.9, -0.79, -0.45, 0.27, 0.8, -0.47, -0.32, -0.2773949338599383, 2.43, 0.55, -0.75, -0.4, -1.06, -0.78, -1.67, -0.72, 0.53, -0.74, -0.59, -0.65, 2.16, 0.28, -1.01, -0.67, -1.33, -0.9864403582748793, -0.85, 1.33, -1.4, -1.24, -1.26, -1.11, -1.17, 1.62, -0.24832539682539684, -1.54, -1.19, -1.85, -1.57, -0.44, 0.02, 0.15, 0.09, 2.92, 1.03, -0.28, 0.07, -0.59, -0.31, -0.06, -0.03, 1.34572371188304, 0.17, 0.26, 0.02, -0.13, -0.06, 2.76, 0.88, -0.43, -0.08, -0.74, -0.46, -0.07, -0.08, 2.82, 0.94, -0.37, -0.02, -0.68, -0.4, 1.04, 0.67, 0.3460371788780404, 0.02, -1.41, 0.13, -0.03, -0.15, 0.1, 0.06, 0.14, 0.39, 1.89, -0.39, -0.19, 0.2, 0.05, 0.48, -0.49, -0.45, 0.18, -0.31, 0.33, -2.021609345020059, 1.084765264284247, -0.45, 0.06, 0.24, 0.43, -1.98, -2.82, -1.84, -3.11, -2.7283894557823127, -3.403248299319728, -3.13, 0.48, -1.0, -1.29, -0.95, -1.6, -1.32, 0.3, 0.35, -0.31, -0.03, -0.58, -0.82, -0.05, -0.66, -0.38, 0.16, 0.11, -0.97, -0.48, 1.48, 0.57, 0.15726381052443328, -0.17, 0.61, 0.29, 0.3100774025227807, 0.1, 0.09, -0.2, 0.17462624382472908, 0.33, -1.57, 0.07, 0.46], ['331', 3.79, 2.18, 0.25122171562045875, -0.19, 0.52, 1.7, 2.63, 1.69, 1.12, 2.48, 1.82, 0.52, 0.79, 1.41, -0.95, 1.65, -0.21, 1.73, 6.53148185941043, 1.12, 2.36, 1.69, 0.31, 0.91, 0.83, 1.259371414588892, 0.65, -1.28, -1.01, -0.4, -2.72, -0.17, -1.99, -0.09, 4.61, -0.69, 0.53, -0.13, -1.48, -0.8561582768021608, 1.93, 0.79, 2.149303232481804, 0.27, 1.057875394446823, -1.46, 1.12, -0.73, 1.2, 5.97, 0.6, 1.83, 1.16, -0.21, 0.38, 0.4, 1.06, 1.18, 1.12, 1.67, 0.62, -1.73, 0.85, -0.99, 0.93, 5.68, 0.33, 1.56, 0.89, -0.48, 0.11, 2.13, 1.05, -2.33, 0.23, -1.6, 0.31, 5.03, -0.29, 0.94, 0.28, -1.09, -0.5, 0.33, 6.15, -6.06, 3.46, 2.62, 0.75, 2.7, 7.54, 2.09, 3.34, 2.66, 1.27, 1.9240077275244507, 1.49, 0.8973665312165628, -1.83, 0.08, 4.79, -0.52, 0.7, 0.04, -1.1788910216767359, -0.73, 0.85, 0.86, 1.99, 1.71, 1.65, 1.79, 2.69, 1.94, 6.74, 1.33, 2.58, 1.9603050194472875, 0.52, 1.12, 0.99, 0.74, 4.71, -0.6, 0.62, -0.04, -1.4, -0.81, 2.18, 2.72, 0.24603717887804044, 1.85, 4.83, 0.36, 0.21, -4.53, 4.57, 2.3, 2.53, 1.37, -2.72, -3.44, -1.74, 1.91, 1.34, 5.07, -5.1, -4.89, 1.72, -6.83, 3.42, 2.6, -1.31, 8.12, -15.54, -5.38, -8.02, 2.63, -3.79, -5.07, -3.9, -4.53, -5.83, -5.27, 5.17, 1.34, 1.23, 0.56, -0.8, -0.21, 0.11, -0.66, -2.01, -1.42, 1.192795351473923, 0.57, 0.78, -1.36, -0.77, 1.69, 1.79, 1.72, -8.15, 2.48, 8.28802380952381, 1.92, 0.99, 2.16, 0.6627868514969316, 1.85, 2.16, 1.81, 1.12, 1.2, 1.56, 2.19, 1.13, 0.37], ['332', 1.42, -0.11, 0.17122171562045874, 0.0, 0.97, 0.84, 1.11, 0.72, 0.43, 0.99, 0.47, 0.47899206349206347, -0.02, 0.41, 0.39, 0.37, -0.69, 0.57, 7.87, -1.49, 0.35, 0.01, 0.12, 0.05, 0.24, 0.54, 0.52, 0.0, -0.49, -0.06, -0.08, -0.09, -1.15, 0.21725890414440846, 7.36, -1.95, -0.04554632992143094, -0.46, -0.35, -0.42, -0.05, 0.40493619921617346, 0.52, -0.49, -0.06, -0.07, -0.09, -1.15, 0.11, 7.37, -1.95, -0.11, -0.46, -0.34, -0.42, -0.38, 1.54, 0.97, 0.52, 1.01, 0.5331047225355606, 0.42, 0.4, -0.67, 0.6, 7.89, -1.47, 0.38, 0.03, 0.14, 0.07, 0.38, 0.57, -0.02, -0.04, -1.1, 0.16, 7.43, -1.89, -0.06, -0.4, -0.29, -0.36, 0.61, 2.7, -2.76, 0.59, -0.02, -1.08, 0.18, 7.45, -1.6862552288980859, -0.04, -0.39, -0.27, -0.34, 0.37, 0.6873665312165629, -1.06, 0.2, 7.46, -1.86, -0.02, -0.37, -0.25, -0.33, 0.53, 0.63, 3.14, 0.96, 0.89, 1.1, 1.6909570400359875, 1.27, 8.62, -0.81, 1.05, 0.7, 0.8959878634155526, 0.74, 0.7, 0.41, 7.25, -2.05, -0.22, -0.56, -0.45, -0.52, 1.0, 1.25, 0.08603717887804044, 1.04, 1.15, 0.35, 0.25, -2.8, 2.81, 1.41, 0.45, 1.3761635321120496, -5.022241020883878, -1.92, -0.96, 0.79, 0.53, 2.970596861471862, -2.83, -2.84, 0.98, -4.24, 1.95, 0.5883906549799409, -0.23, 4.96, -4.7, -3.32, -5.03, 5.13, -6.38, -8.67, -6.97, -7.29, -7.18, -7.25, 2.89, 2.51, 1.87, 1.52, 1.64, 1.56, 0.63, -0.35, -0.23, -0.3, 0.47, 0.45, 0.98, 0.11, 0.04, 0.99, 1.1143963012752909, 0.82, -3.28, 2.28, 3.57, 0.87, 1.41, 0.86, -0.07, 1.22, 1.28, 0.44, -0.2566666666666667, 1.14, 1.025957527023814, 0.37, 1.71, 1.06], ['333', -16.58, -2.44, -0.77, 0.51, -3.42, -4.18, -2.705884742040171, -7.14, -4.23, -7.18, -2.04, -4.81, 0.05, -0.41, -0.8957142857142857, -4.311439909297052, -3.4771428571428573, -5.462517573696145, -6.28, -1.27, -8.22, -4.56, -3.32, -3.35, -6.12, -6.28, -5.25, -2.83, 2.13, 1.67, 1.16, -2.64, -1.47, -3.82, -4.33, 0.79, -6.31, -2.5, -1.31, -1.34, -4.82, -4.36, -2.49, 5.11, 4.63, 4.11, 0.21104365079365078, 1.4, -1.02, -1.54, 3.72, -3.58, 0.26, 1.57, 1.53, -4.69, -3.7799999999999994, -6.91, -4.88, -7.22, -0.45, -0.95, -4.47, -3.53, -5.83, -6.32, -1.32, -8.27, -4.61, -3.37, -3.4, -9.46, -6.8, -0.5, -4.176705782312926, -3.09, -5.4, -5.9, -0.87, -7.85, -4.18, -2.93, -2.96, -5.13, -13.79, 11.37, -6.34, -3.76, -2.6, -4.93, -5.43, -0.37, -7.39, -3.6842857142857146, -2.44, -2.47, -7.72, -2.67, 1.8285714285714285, -1.21, -1.73, 3.52, -3.76, 0.07, 1.37, 1.34, -1.44, -2.69, -5.48, -4.01, -3.87, -4.32, -3.83, -2.38, -2.9, 2.29, -4.91, -1.12, 0.17, 0.13, -2.71, -1.48, -0.53, 4.79, -2.59, 1.29, 2.6928571428571426, 2.58, -4.1, -2.4, 0.4, -4.34, -15.19, -2.0396768707482993, -1.24, 9.164285714285715, -8.57, -4.28, -0.92, -11.12, 11.68, 8.251428571428571, 4.064547619047619, -8.41, -2.84, -12.3, 12.967142857142857, 12.344285714285714, -4.03, 13.357142857142858, -8.03, -8.53, 4.15, -11.68, 22.44, 7.75, 11.54, -12.15, -0.96, 5.34, -2.07, 1.83, 3.15, 3.12, -12.14, -5.99, -7.04, -3.34, -2.08, -2.0185714285714282, 1.13, 3.98, 5.34, 5.538571428571428, -4.41, -4.74, -2.74, 1.3, 1.27, -3.96, -4.03, -7.3, 11.03, -5.29, -11.18, -6.05, -6.66, -3.99, -0.03, -4.34, -4.0, -2.81, -2.49, -3.08, -3.96, -7.61, -8.94, -3.38], ['334', 1.18, -0.12, -0.1, 0.25, 0.04, -0.24, -0.31, -0.07, -0.07, -0.8629115646258504, -1.87, -0.6406751700680272, 0.23, -0.64, -1.0, -1.73, -1.11, -1.38, -1.13, -1.37, -1.13, -1.45, -1.675694768399324, -1.21, 0.29, 0.78, 0.57, 1.24, 2.14, 1.25, 0.88, 0.14, 0.77, 0.5, 0.75, 0.51, 0.75, 0.43, 0.09, 0.67, -0.99, -0.24, -0.66, 0.89, 0.01, -0.35, -1.08, -0.46, -0.73, -0.48, -0.72, -0.48, -0.8, -1.13, -0.56, -0.2, -1.2, -0.4, -0.29, -1.53, -0.87, -1.23, -1.95, -1.34, -1.61, -1.35, -1.6, -1.35, -1.68, -2.0, -1.231743720565149, 0.6436060011417155, -0.67, -0.36, -1.09, -0.47, -0.74, -0.49, -0.73, -0.49, -0.81, -1.14, -0.57, 0.13, 0.75, -0.74, -0.30912907733800593, -0.74, -0.11, -0.39, -0.13, -0.37, -0.13, -0.45, -0.78, -0.21, 2.99, 0.5073665312165629, 0.63, 0.35, 0.61, 0.36, 0.61, 0.28, -0.05, 0.53, 0.09, 0.46, 1.24, -0.16, -0.01, -0.2, -0.12819052351387078, -0.27, -0.01, -0.26, -0.01, -0.34, -0.67, -0.1, 0.27, 0.07, 0.26, 0.01, 0.26, -0.07, -0.4, 0.17, -0.09, -0.47, 0.21, -0.05, 8.29, 0.25, 0.14, 1.56, -1.54, -0.81, 1.66, -0.64, -0.07, 0.35, 0.17, 0.61, 0.0, -0.61, 0.61, 0.57, -0.21, 2.43, -0.36, -1.25, 0.59, -0.54, 3.34, 0.35, 0.44, 0.06, -0.18, -0.25, 0.0, -0.28838945578231295, -0.66, -0.08, -0.55, 0.06, 0.25, -0.08, -0.41, 0.16, -0.18, -0.33, -0.65, -0.08, -0.12, 0.04, 0.14, -0.33, 0.31224875531501634, -0.19, -0.11, -0.12, 2.73, 1.64, -2.55, -0.36, -0.5088174603174603, 0.48, 0.57, 0.48, -0.41, 0.08, 0.59, -0.87, -0.1, -0.19, -0.93, 0.37], ['335', 4.68, -0.48, -0.04, 0.12, -0.49, -0.87, -0.38588474204017087, -1.06, -0.7, -1.1, -0.07, -0.99, 0.17, 0.72, -0.98, -2.04, -0.26, -0.92, 1.851481859410431, -0.02, -0.85, -0.74, -0.28, -0.41, -1.29, -0.88, -1.03, -0.92, 0.24, 0.79, -0.91, -1.97, -0.19, -0.85, 1.91, 0.05, -0.78, -0.67, -0.21, -0.2961582768021609, -0.06, -1.7650638007838266, -0.11, 1.18, 1.72, 0.01, -1.06, 0.74, 0.07, 2.861652133580705, 0.98, 0.168065468086443, 0.26, 0.72, 0.58, -0.42, -0.61, -0.98, -0.52, -1.27, 0.54, -1.15, -2.21, -0.43, -1.09, 1.66, -0.19, -1.03, -0.91, -0.45, -0.59, -0.7, -1.8, -1.68, -2.74, -0.97, -1.62, 1.12, -0.73, -1.56, -1.44, -0.99, -1.12, -1.23, -2.18, 2.13, -0.08330176161467984, -1.07, 0.73, 0.06, 2.85, 0.97, 0.13, 0.25, 0.71, 0.57, 0.4912233560090703, 1.047366531216563, 1.82, 1.15, 3.96, 2.07, 1.21, 1.33, 1.8, 1.66, -0.15, 0.93, -0.5, -0.8, -0.79, -0.73, -0.84, -0.66, 2.11015873015873, 0.24, -0.59, -0.48, -0.02, -0.15, -0.15346392892821453, -0.18, 2.78, 0.91, 0.07, 0.18, 0.65, 0.51, -1.11, -1.22, 0.20603717887804043, -0.7, 0.61, 0.03, 0.0, 1.49, -1.51, -0.75, 0.07406627346681526, -1.1938364678879505, 2.04, 1.62, 0.81, 2.35, -0.64, -2.43, 2.44, 2.35, -0.8, 2.3, -1.59, -1.1, 0.5747652642842468, -2.46, 5.36, 1.63, 2.46, -2.13, -2.88, -1.82, -2.64, -2.53, -2.08, -2.21, -2.42, -1.08, -0.83, -0.72, -0.26, -0.4, -0.25, 0.12, 0.58, 0.44, -0.65, -0.79, -0.36, 0.6532337781266354, 0.32, -0.79, -0.79, -1.01, 2.5, -0.5, -2.53, -1.56, -1.09, -0.82, -0.14, -0.81, -0.77, -0.75, -1.09, -0.28, -0.68, -1.8497593656343654, -2.01, -1.42], ['336', 4.03, -0.4, -0.36, 0.08, 0.62, -1.08, -0.71, -1.55, -2.05, -2.23, 0.68, -1.1392857142857142, -0.86, -1.62, -1.89, -2.06, -0.83, -1.75, -2.38, -2.08, -2.6, -1.0, -2.42, -1.1, -1.2, -0.35, -2.9, -1.81, -1.53, -2.29, -2.55, -2.73, -1.5, -2.42, -3.05, -2.728642857142857, -3.27, -1.67, -3.08, -1.78, -0.88, -1.7350638007838266, -1.1, 0.29, -0.49, -0.75, -0.93, 0.32285714285714284, -0.61, -1.26, -0.95, -1.48, 0.14, -1.2742857142857142, 0.04, -2.25, -1.04, -2.73, -2.86, -1.39, -0.77, -1.04, -1.21, 0.03, -0.9, -1.5228197278911566, -1.24, -1.76, -0.14, -1.57, -0.25, -1.67, 0.02571428571428569, -0.27, -0.44, 0.81, -0.13, -0.77, -0.47, -1.0, 0.6642857142857143, -0.81, 0.53, -2.51, -0.44, 0.53, -0.35, -0.18, 1.08, 0.17, -0.51, -0.2, -0.73, 0.91, -0.54, 0.8, 1.54, -0.18, 1.26, 0.32, -0.33, -0.03, -0.56, 1.08, -0.37, 0.97, -0.57, -0.16764311878597596, 0.86, -1.03, -0.96, -1.15, -1.42, -0.93, -1.57, -1.27, -1.79, -0.17, -1.6, -0.28, -1.4, -0.49, -0.3963144197072767, -0.34, -0.87, 0.76, -0.68, 0.65, 0.7, -0.85, 0.42, -1.47, 3.02, 1.17, 0.97, 2.33, -2.26, -1.12, -2.25, -1.91, 0.43, 2.06, 1.03, 2.21, -1.39, -3.14, 3.15, 3.01, -1.0, 3.47, -2.01, -1.5, 0.73, -4.27, 3.28, 3.0328571428571425, 4.1814285714285715, -0.28, 0.15, 0.3, -0.23, 1.461610544217687, -0.04, 1.31, -2.93, -0.15, -0.53, 1.11, -0.34, 1.0, 0.38, 1.65, 0.27, 1.54, -2.03, -2.55, -1.25, -1.43, -0.11, -0.99, -1.07, -1.58, 1.66, 0.29, -1.72, -0.42, -1.18, 0.19, 1.35, -1.3, -1.08, -1.09, -1.34, -1.48, -1.14, -0.4, -1.06, -1.2], ['337', 10.69, 2.9, -1.0587782843795412, 0.53, 0.68, -2.19, -2.39, -2.76, -3.83, -1.4529115646258504, 2.980608843537415, 1.08, 1.35, -0.8339200680272107, 2.07, -4.34, 0.46, -1.07, -1.61, -3.31, -2.62, -2.9769251700680273, 1.43, 0.26, -2.5214063389924735, -0.39, -4.697341605006888, -1.84, -1.5491666666666668, -3.99, -0.87, -7.1, -2.43, -3.92, -4.45, -6.1, -5.43, -5.7, -1.49, -2.63, -2.87, -6.33, -2.95, 0.27, -2.2, 0.99, -5.36, -0.30134863945578233, -2.12, -2.66, -4.34, -3.66, -4.01, 0.35, -0.81, -1.9, -3.7, -1.85, -3.69, -3.21, -2.46, 0.71, -5.62, -0.87, -2.38, -2.92, -4.6, -3.92, -4.27, 0.08, -1.08, -4.66, -0.7685714285714286, 3.25, -3.24, 1.6816609275411798, 0.08, -0.48, -2.19, -1.5, -1.86, 2.6, 1.42, -5.41, -8.31, 7.91, -3.9, -6.29, -1.58, -3.065714285714286, -3.61, -5.28, -4.6, -4.864285714285715, -0.63, -1.78, 3.88, 2.55, 5.03, 3.43, 2.8505714285714285, 1.7028571428571428, 1.8, 1.43, 6.04, 4.81, -1.04, 2.54, -5.36, -1.9, -1.88, -1.58, -2.36, -1.52, -2.07, -3.76, -3.07, -3.43, 0.96, -0.2, 0.81, -0.85, -0.55, -2.27, -1.57, -1.93, 2.52, 1.34, -4.32, -4.640438775510204, 0.61, -0.95, 7.72, -0.93, -0.8, 3.19, -3.19, -1.62, -1.55, -5.65, -2.98, 3.86, 1.92, 5.26, -1.16, -5.74, 5.87, 5.84, -1.92, 4.81, -3.78, 0.28, 0.02, -7.19, -4.93, -0.27, -0.06, 2.53, -0.3, -1.73, -1.02, -1.39, 3.09, 1.9, -5.69, 1.45, 0.71, 0.34, 4.900857142857143, 4.338571428571429, 0.74, -0.37, 4.16, 2.96, -3.73, -5.11, 1.11, 4.54, 3.34, -1.94, -1.89, -2.86, 6.04, -3.04, -7.28, -0.62, -1.07, -3.29, -1.15, -2.29, -1.46, -1.73, -0.03, -2.11, -2.16, -0.84, 0.48, -2.07], ['338', 3.83, -0.3, 0.12, -0.03, 0.45, 0.92, 0.6641152579598292, 1.25, 1.06, -1.02, -2.77, -1.47, -2.73, -2.38, -1.7, -2.35, -2.83, -1.47, 0.66, -1.04, -0.57, -0.8, -2.08, -2.18, 1.25, 1.45, 1.8, 1.34, 0.05, 0.4, 1.1, 0.44, -0.06, 1.34, 3.53, 1.78, 2.27, 2.03, 0.71, 0.61, 1.68, 1.8149361992161734, 0.46, -1.28, -0.93, -0.24, -0.89, -1.38, 0.0, 2.16, 0.43, 0.91, 0.7738655564790019, -0.62, -0.72, 0.83, 0.86, -0.74, 1.09, 1.76, 0.35, 1.05, 0.39, -0.1, 1.29, 3.507180272108844, 1.7302380952380951, 2.22, 1.98, 0.67, 0.56, 0.93, 1.4, 0.7, 0.04, -0.46, 0.94, 3.12, 1.37, 1.86, 1.62, 0.31, 0.21, 1.35, 3.351742947528662, -3.19, 0.7366982383853201, -0.66, -1.14, 0.24, 2.41, 0.67, 1.16, 0.92, -0.38, -0.49, 1.29, 1.36, -0.49, 0.9, 3.08, 1.34, 1.82, 1.59, 0.28, 0.17, 0.48, 1.35, -0.07, 0.5615981806829015, 0.98517906963434, 1.08, 1.86, 1.4, 3.59, 2.0397126881055456, 2.5057782534925392, 2.09, 0.77, 0.67, -0.24346392892821456, 0.46, 2.16, 0.43, 0.91, 0.68, -0.62, -0.72, 0.84, 1.09, 0.24, 1.2, 3.81, 0.12, -0.06, -2.53, 2.54, 1.3088101710076212, -2.44, 1.9961635321120494, -0.06, -1.96, -1.0, 1.92, 0.57, 2.91, -2.91, -2.91, 0.97, -3.87, 1.9698783572413152, 1.13, -0.56, 5.47, -10.92, -3.75, -5.55, 0.1, -1.67, -1.7, -1.22, -1.45, -2.72, -2.83, 2.88, 0.02, 0.48, 0.25, -1.04, -1.15, -0.45, -0.23, -1.52, -1.62, 1.1, 1.4, -0.22, -1.29, -1.39, 0.51, 0.61, 1.15, -6.42, 1.1, 6.27, 0.89, 0.29, 1.08, -0.11, 1.29, 1.04, 0.46, 0.26, 1.39, 1.19, 0.14, 0.2, 1.69], ['339', 3.3, 0.32, 0.47, -0.07, 0.5, 1.38, 1.91, 3.83, 2.21, 4.06, 0.52, 3.04, 1.01, 0.13, -0.56, 3.21, 2.26, 1.94, 7.21, 3.53, 4.88, 1.55, 0.93, 2.14, 3.0, 3.05, 3.5626583949931123, 2.51, 0.49, -0.23681006295292, -1.07, 2.68, 1.74, 1.42, 6.66, 3.0, 4.34, 1.03, 0.42, 1.62, 4.01, 2.76, 0.99, -1.97, -2.82, -3.49, 0.17, -0.75, -1.06, 4.05, 0.48, 1.79, -1.45, -2.04, -0.87, 2.53, 2.87, 1.5, 2.08, 3.02, -0.87, -1.55, 2.18, 1.24, 0.93, 6.15, 2.5, 3.83, 0.54, -0.07, 1.12, 3.99, 3.93, -0.68, 3.08, 2.13, 1.81, 7.08, 3.4, 4.74, 1.42, 0.8, 2.01, 3.88, 8.45, -8.35, 4.64, 3.79, 2.83, 2.51, 7.81, 4.11, 5.46, 2.12, 1.5, 2.71, 1.28, 0.83, -0.92, -1.23, 3.88, 0.31, 1.62, -1.61, -2.21, -1.04, 2.04, 0.81, 2.5257237118830402, 1.58, 1.73, 1.45, 1.76, -0.31, 4.84, 1.24, 2.56, -0.7, -1.3, -0.12, 2.25, 2.08, 5.17, 1.55, 2.88, -0.39, -0.99, 0.19, 3.89, 3.06, -0.1, 1.98, 2.5, 1.11, 0.73, -2.54, 2.5, 1.28, 0.4, 4.04, -0.99, -3.15, -1.59, 1.69, 0.66, 4.980596861471861, -4.84, -4.71, 1.59, -3.91, 3.17, 3.76, -1.88, 5.25, -14.99, -3.5, -5.19, 1.02, -2.94, -3.44, -2.18, -5.29, -5.86, -4.73, 4.82, 0.52, 1.3, -1.91, -2.51, -1.34, -0.78, -3.17, -3.76, -2.61, 2.41, 2.88, 2.48, -0.61, 0.58, 1.61, 1.65, 3.66, -7.49, 2.41, 7.41, 1.76, 1.54, 3.1, 1.19, 1.97, 1.29, 1.12, 0.14, 0.76, 1.88, 3.15, 2.9, 1.24], ['340', 1.88, -0.14, -0.03, 0.23, 0.06, 0.05, -1.23, 0.01, -0.32, 0.42, 0.5903184712113286, 1.49, 1.24, 0.11, 0.75, 0.82, 0.33, 0.25, 4.16, -0.41, 0.68, 0.69, 0.62, 1.16, -0.85, 0.5, 0.04, 1.1001785714285715, 1.2676746031746031, -0.27, 0.37, 0.44, -0.05, -0.13, 3.76, -0.79, 0.29, 0.31, 0.24, 0.77, -0.13, 0.15, -1.05, -0.25, -1.36, -0.72, -0.65, -1.14, -1.22, 2.63, -1.87, -0.8, -0.78, -0.85, -0.32, -0.78, -0.46, 0.61, 0.23, -0.7307547529341225, -1.11, -0.48, -0.41, -0.9, -0.97, 2.89, -1.62, -0.55, -0.54, -0.61, -0.08, 1.13, 0.31, 0.64, 0.72, 0.22, 0.5793027210884354, 4.05, -0.52, 0.57, 0.5814285714285714, 0.52, 1.05, -0.2, -0.52, 0.46, -0.32912907733800595, 0.07, -0.4082142857142857, -0.5, 3.38, -1.15, -0.07, -0.06, -0.13, 0.4, 0.992095238095238, -0.4, -0.49, -0.57, 3.31, -1.22, -0.15, -0.13, -0.2, 0.33, 0.36, -0.37, -1.74427628811696, -0.08, 0.02, -0.21, 0.09, -0.08, 3.82, -0.74, 0.35, 0.36, 0.29, 0.83, -0.19, 0.17, 3.9, -0.66, 0.42, 0.44, 0.37, 1.1421774376417235, 0.14, 0.14, 0.55, -0.09, 2.77, 0.2, 0.01, -0.53, 0.53, 0.26, 1.39, -1.55, -1.79, 0.21, 0.1, 1.03, -0.27, -0.28, 0.3, 0.26, -0.08, -0.79, -0.18, -2.52, 1.23, 0.2, -0.08, -0.17, -0.23, 1.74, -3.59, -4.39, -3.34, -3.33, -3.39, -2.88, -0.26, 0.83, 1.09, 1.11, 1.04, 1.57, -0.25, 0.022884928563499992, -0.05, 0.48, -0.36, -0.04, -0.27, -0.07, 0.46, 0.022080034314056876, -0.07, -0.07, -0.05, -1.42, 0.04, -0.16, -0.14, -0.2, 0.53, -0.11, 0.88, -0.33, -0.37, -0.61, -0.73, 0.63, -0.32, -0.64], ['341', 1.03, 0.12, 0.07122171562045874, 0.08, 0.07, -0.13, -1.18, -0.23, -0.12, -0.92, -1.31, 0.05, -0.95, -0.38, -0.9, -1.05, -1.27, -0.89, -0.28, -1.42, -0.45, -1.15, -0.98, -1.24, 0.42, 0.18, 0.4, 1.38, 0.37, 0.94, 0.41, 0.27, 0.04, 0.42, 1.05, -0.11, 0.8707606837606837, 0.17, 0.33, 0.07, -0.06, 0.95, -0.97, -1.0, -0.43, -0.95, -1.1, -1.32, -0.95, -0.33, -1.47, -0.5, -1.2, -1.04, -0.9891712018140588, -0.07, 0.08, -0.87, -0.09, 0.03, 0.57, 0.05, -0.1, -0.32, 0.06, 0.68, -0.47, 0.5, -0.2, -0.03, -0.3, 0.3, -0.54, -0.52, -0.67, -0.89, -0.51, 0.1, -1.04, -0.07, -0.77, -0.61, -0.87, 0.38, 0.23, -0.16, -0.02, -0.14, -0.37, 0.01, 0.63, -0.52, 0.46, -0.25, -0.08, -0.34, 0.11, 0.13, -0.23, 0.16, 0.77, -0.37, 0.6, -0.1, 0.06, -0.2, 0.161141873999017, 0.17, 0.11, -0.04, -0.01, 0.03, 0.36, 0.38, 1.0, -0.15, 0.83, 0.13, 0.29, 0.03, 0.19, -0.03, 0.62, -0.53, 0.44, -0.26, -0.09, -0.36, 0.31, 0.58, 0.18, 0.35, 0.4, -0.03, 0.07, 0.0, 0.07, 0.01, 0.34, -0.25, -0.92, 0.01, 0.03, 0.57, 0.07, -0.11, 0.05, 0.1, -0.05, -0.13, -0.09, -1.14, 0.59, 0.88, 1.55, -0.72, -0.97, 0.91, -0.64, -1.14, -0.17, -0.87, -0.71, -0.97, -0.13, 0.51, 0.98, 0.27, 0.44, 0.17, -0.47, -0.7, -0.53, -0.8, -0.15, 0.02, 0.23, 0.17, -0.1, -0.03, 0.06, -0.26, 1.03, 0.09, -0.99, -0.2627361894755667, -0.12, 0.07, -0.26, -0.22, -0.13, 0.22, -0.22, -0.06, 0.33, -0.17, 0.24, 0.53], ['342', -3.32, -2.45, -0.26, -0.61, 0.14, 1.14, 1.22, 0.16, 2.25, 0.74, -1.99, -0.57, -0.94, 0.11, 1.64, 0.61, 0.83, 0.51, 1.015862135879993, 0.26, 1.54, 1.44, 1.0, -0.2, 0.09, -0.66, 2.78, 1.45, 1.07, 2.14, 3.71, 2.65, 2.88, 2.55, 2.88, 2.29, 3.6, 3.5, 3.05, 1.83, -2.58, 6.59, 1.31, -0.37, 0.69, 2.23, 1.19, 1.41, 1.09, 1.42, 0.8984761904761904, 2.13, 2.02, 1.58, 0.38, -0.21, -0.28, -2.69, 1.68, 1.69, 1.06, 2.6, 1.56, 1.79, 1.46, 1.79, 1.21, 2.5, 2.4159625850340136, 2.115338978481836, 0.75, 0.09, 0.62, 1.53, 0.5, 0.72, 0.4, 0.73, 0.15, 1.43, 1.33, 0.89, -0.31, 4.27, -1.97, 0.91, -0.89, -1.02, -0.8, -1.11, -0.79, -1.36, -0.1, -0.2, -0.63, -1.81, 0.05, 0.12, 0.22, -0.1, 0.22, -0.35, 0.93, 0.82, 0.38, -0.8, 0.24, 0.12, -0.19, 0.92, 0.67, 0.81, -0.1, -0.32, 0.0, -0.57, 0.7, 0.6, 0.16, -1.02, -0.42, 0.22, 0.32, -0.25, 1.02, 0.92, 0.48, -0.71, -0.82, -0.43, -1.34, -0.38, 0.06, -1.38, -0.9, -0.88, 0.93, 0.46, 0.07, -0.25, -0.83, -1.2114285714285715, -0.865452380952381, -1.75, 1.39, 1.97, -2.2600000000000002, -2.1057142857142854, 0.94, -1.29, 1.86, 4.36, -2.17, -0.39, 3.39, 0.02, 0.06, 0.82, -0.1, -0.57, 0.7, 0.6, 0.16, -1.02, 2.78, 0.47, 1.28, 1.18, 0.7408571428571429, -0.46, -0.79, -0.1, -0.54, -1.71, 2.57, 3.37, -0.69, -0.43, -1.61, 0.93, 0.69, -0.03, 1.77, 0.74, -3.05, 1.34, 0.72, -0.26, -1.18, 1.18, 0.45, 2.0, 1.14, 1.87, 0.93, -0.94, -1.3, 1.11], ['343', 0.23, 0.4, 0.09122171562045875, -0.04, 0.18, 0.2784196236737595, 0.51, -0.31, -0.46, -0.91, -0.72, -0.53, -0.91, -1.02, -0.03, -0.66, -0.86, -0.84, -1.37, -0.62, -1.36, -0.64, -0.81, -1.47, -0.26, -0.17, -0.19, 0.19, -0.19, -0.3, 0.7, 0.06, -0.14, -0.12, -0.65, 0.1, -0.64, 0.09, -0.08, -0.75, -0.33, -1.3150638007838267, -0.38, -0.38, -0.49, 0.51, -0.13, -0.33, -0.31, -0.84, -0.09, -0.83, -0.11, -0.27, -0.94, -1.25, 0.27, -0.31, -0.2, 0.0, -0.11, 0.89, 0.25, 0.05, 0.07, -0.46, 0.29, -0.45, 0.28, 0.11, -0.57, 0.83, 0.11, 1.0, 0.36, 0.16, 0.18, -0.36, 0.4, -0.34, 0.38, 0.22, -0.46, -0.53, -0.36, 0.31, -0.88, -0.5419125667872351, -0.83, -0.81, -1.34, -0.59, -1.33, -0.61, -0.77, -1.44, 1.05, -0.25, -0.2, -0.18, -0.71, 0.04, -0.7, 0.02, -0.14, -0.82, -0.06, -0.35, 0.79, 0.18, 0.04, 0.28, -0.05, 0.02, -0.51, 0.24, -0.5, 0.22, 0.06, -0.62, -0.043463928928214546, -0.07, -0.53, 0.22, -0.52, 0.2, 0.04, -0.64, 0.04, -0.12, 0.11, 0.06, 3.03, 0.02, -0.13, -0.91, 0.94, 0.48, -0.28, 0.4061635321120495, 0.47, -0.37, -0.2, 0.04, -0.47, 0.63, -0.55, -0.5, 0.17, -1.44, 0.34, -1.07, 0.52, -0.09, 1.92, 0.05, 0.09, -0.5461904761904762, 0.47, 0.76, 0.02, 0.74, 0.57, -0.1, 0.51, -0.29, -0.74, -0.02, -0.18, -0.86, 0.45, 0.73, 0.56, -0.12, -0.44, -0.44, -0.28, -0.17, -0.84, 0.19, 0.13, -0.25, 0.94, 0.8, -0.93, 0.25, 0.3, -0.11, -0.67, 0.46, 0.35, -0.46, -1.15, 0.42, 0.57, 0.28, 0.38, 0.3], ['344', 3.92, 0.49, 0.17122171562045874, -0.09, 1.07, 0.66, 1.2541152579598291, 1.75, 1.4293780543870107, 1.89, 0.74, 0.53, 0.35, 1.45, -0.6, 0.44, 0.68, 1.28, -1.19, -0.23, 2.26, 0.92, 0.62, 0.57, 2.03, 1.48, 1.14, -0.21, -0.38857142857142857, 0.7, -1.33, -0.3, -0.06, 0.54, -1.91, -0.96, 1.52, 0.18, -0.11, -0.16, 2.1574684253532106, 1.67, 1.35, -0.18, 0.91, -1.13, -0.09, 0.15, 0.75, -1.71, -0.76, 1.72, 0.39, 0.09, 0.04, 1.6, 1.88, 1.4, 1.09, 1.54, 1.09, -0.95, 0.09, 0.33, 0.93, -1.53, -0.58, 1.91, 0.5859625850340136, 0.2727347454133169, 0.22, 2.36, 0.44, -2.02, -0.99, -0.75, -0.16, -2.6, -1.65, 0.81, -0.51, -0.81, -0.86, 1.28, 3.51, -3.5, 2.51, 1.05, 1.29, 1.9, -0.59, 0.37, 2.89, 1.54, 1.24, 1.18, 2.27, 1.44, 0.24, 0.84, -1.62, -0.67, 1.82, 0.48, 0.18, 0.13, 0.88, 1.46, 2.200104651162791, 1.01, 1.0, 1.1, 1.2, 0.6, -1.86, -0.91, 1.7457782534925395, 0.24, -0.06, -0.11, 0.84, 0.6, -2.44, -1.5, 0.97, -0.35, -0.65, -0.7, 1.33, 1.12, 0.01, 1.16, 6.71, 0.15, 0.17, -2.76, 2.68, 1.33, 0.11, 2.64, -4.06, -2.11, -1.0, 2.04, 0.28, 3.03, -3.04, -3.03, 1.0, -4.03, 2.0, 1.56, -0.82, 3.54, -13.39, -2.37, -3.57, 4.13, 3.12, 0.97, 3.5, 2.14, 1.84, 1.78, 2.99, 2.13, 2.5, 1.16, 0.86, 0.81, -0.37, -1.31, -1.6, -1.65, 1.39, 1.38, 0.96, -0.3, -0.35, 1.04, 1.1143963012752909, 1.77, -7.83, 2.100199626957499, 8.01, 1.197263810524433, 1.4611825396825397, 1.26, -0.05, 0.77, 1.27, 0.43, -0.11, 0.77, 1.31, 1.64, 2.38, 1.12], ['345', 2.54, -0.47, -0.05, 0.2, 0.26, -0.37, -0.8758847420401709, -0.94, -0.52, 0.49, 1.21, 0.8, 1.79, 2.08, 2.41, -0.15, 1.39, 0.42, 0.06, 0.11, 0.49, 1.06, 0.49, 1.32, 0.04, -0.5, -0.71, -0.4, 0.58, 0.86, 1.19, -1.34, 0.18, -0.78, -1.13, -1.09, -0.71, -0.15, -0.71, 0.11, -1.14, -1.72, -0.31, 0.98, 1.27, 1.6, -0.94, 0.58, -0.37, -0.73, -0.69, -0.31, 0.26, -0.31, 0.52, -0.03, -0.68, 0.08, -0.57, -1.28, 0.28, 0.61, -1.91, -0.4, -1.34, -1.7, -1.66, -1.28, -0.72, -1.28, -0.46, -0.98, -1.55, 0.33, -2.18, -0.68, -1.62, -1.97, -1.93, -1.55, -1.0, -1.55, -0.74, -0.73, -0.25, 0.22, -1.88, -2.5, -1.0, -1.94, -2.3, -2.25, -1.88, -1.32, -1.88, -1.07, 0.96, 0.64, 1.54, 0.58, 0.21, 0.26, 0.64, 1.21, 0.7811089783232642, 1.47, -0.04, 0.66, -1.05, -0.48, -0.37, -0.67, -0.88, -0.95, -1.31, -1.26, -0.88, -0.32, -0.88, -0.06, -0.2534639289282145, 0.07, -0.36, -0.32, 0.07, 0.63, 0.07, 0.89, -0.35, -0.62, -0.09, -0.84, 2.85, -0.07, -0.14, 1.44, -1.41, -0.71, 0.54, -0.98, -0.81, 0.94, 0.46, 1.3, -0.11, -1.4, 1.48, 1.44, -0.47, 2.11, -0.96, -2.11, 1.03, -2.62, -0.69, 1.78, 2.63, 0.7, 0.43, 0.04, 0.43, 1.0, 0.7496385796742939, 1.26, -1.46, 0.38, 0.38, 0.95, 0.38, 1.21, 0.0, 0.56, 0.0, 0.83, -0.61, -0.55, -0.56, -0.56, 0.26, -0.49, -0.57, -0.86, -0.62, -1.25, 0.32, -0.97, -0.93, 0.0, 0.83, -0.55, -0.52, -0.38, 1.1402244897959184, -0.76, -0.82, -1.3, -1.08, -1.5], ['346', 0.49, -0.69, 0.04, 0.06, -0.95, 0.94, -0.18588474204017086, -0.08, 1.04, 0.8321428571428571, -0.95, 0.27, 0.92, 1.0670238095238096, 1.49, 1.11, 0.15, 0.51, -0.53, 0.83, 1.25, -1.1, -0.48, 0.95, 0.82, 0.11, 1.8, 1.23, 1.89, 2.03, 2.46, 2.08, 1.12, 1.47, 0.43, 1.8, 2.22, -0.15, 0.48, 1.92, 0.26, 0.95, 0.57, 0.65, 0.79, 1.21, 0.84, -0.07072108843537415, 0.24, -0.79, 0.57, 0.98, -1.37, -0.75, 0.68, -0.07, 0.31, -0.08, 1.25, -0.08, 0.14, 0.56, 0.19, -0.76, -0.41, -1.44, -0.08, 0.32, -2.01, -1.39, 0.03, 0.2736060011417156, -0.22, 0.42, 0.05, -0.9, -0.38017346938775515, -1.57, -0.22, 0.18, -2.14, -1.53, -0.11, 1.45, 3.28, -3.3, -0.64, -0.37, -1.31, -0.9642857142857143, -1.99, -0.64, -0.24, -2.55, -1.94, -0.53, -1.56, -0.27, -0.95, -0.6, -1.62, -0.27, 0.13, -2.19, -1.4388910216767359, -0.16, 0.13, -0.26, 1.12, 0.33, 0.71, -0.08, 0.68, 0.35, -0.68, 0.68, 1.09, -1.26, -0.64, 0.79, 1.71, 0.3830767481303673, -1.03, 0.33, 0.74, -1.6, -0.98, 0.44, 1.5, 1.55, 0.09, 0.67, -4.63, 0.23, 0.07, 1.56, -1.57, -0.79, 0.44, -1.43, 0.06, -0.68, -0.36, 0.16, 0.62, 0.99, -0.89, -1.12, 0.32, 2.46, 0.61, -0.64, 0.32, 2.04, -3.28, -1.407142857142857, -2.08, 0.2656150793650793, 1.37, 1.37, 1.78, -0.58, 0.05, 1.48, 0.91, 0.0, 0.41, -1.92, -1.31, 0.11, -0.41, -2.32, -1.71, -0.29, 1.05, 1.25, 1.96, 0.63, 2.07, 0.26, 0.28, -0.07, -3.01, 0.92, 2.99, 0.8, 0.0, 1.32, 1.44, 0.81, -0.54, 0.7, 1.22, 0.26462624382472905, -0.11, 0.64, -0.96, 0.42], ['347', 1.71, 0.83, 0.02, -0.42, 1.38, 1.04, 2.6341152579598295, 1.14, 1.13, 0.18, -1.9, -1.44, -2.34, -0.54, -1.16, 0.33071428571428574, -1.64, 0.47748242630385496, 0.53, -1.69, 0.27, -0.23, -0.83, -1.1, 1.08, 0.76, 2.1626583949931124, 0.48, -0.45, 1.39, 0.8178199712950912, 2.28, 0.27, 2.11, 2.48, 0.22, 2.22, 1.71, 1.1, 0.82, 1.08, 0.9349361992161734, 1.65, -0.92, 0.91, 0.28, 1.8, -0.21, 1.62, 1.99, -0.26, 1.749654729237061, 1.23, 0.62, 0.34, -0.14, -0.62, 0.78, 1.18, 2.59, 1.84, 1.21, 2.74, 0.72, 2.56, 2.94, 0.66, 2.68, 2.17, 1.55, 1.27, 1.01, 0.73, -0.62, 0.8807142857142857, -1.1, 0.71, 1.08, -1.16, 0.82, 0.32, -0.28, -0.56, 1.6, 2.68, -2.7, 1.3966982383853201, 1.51, -0.48, 1.34, 1.71, -0.54, 1.45, 0.95, 0.34, 0.06, 0.06, -0.15, -1.97, -0.17, 0.19, -2.02, -0.06, -0.3171830035044322, -1.16, -1.43, 0.14, -0.07, 0.9, 1.1815981806829015, 1.03, 1.2456735186500318, 1.85, 1.83, 2.2, -0.05, 1.95, 1.44, 0.83, 0.54, 0.14, 0.02, 0.37, -1.85, 0.11, -0.39, -0.98, -1.26, 0.84, 1.17, -0.78, 1.42, 0.08, 0.12, 0.07, -2.49, 2.51, 1.3188101710076212, -2.37, 1.94, -4.1, -2.18, -1.16, 0.87, 0.53, 3.35, -3.25, -3.35, 1.1832908048638529, -3.77, 2.24, 4.57, -2.32, 5.56, -4.21, -3.69, -5.51, 4.09, -0.34, -2.21, -0.25, -0.75, -1.35, -1.62, 3.4131678995607566, 1.91, 2.0, 1.49, 0.88, 0.6, -0.09, -0.5, -1.1, -1.38, 1.15, 1.23, 0.41, -0.6, -0.8077512446849837, 1.182080034314057, 1.11, 1.05, -2.25, 1.28, 2.3, 1.89, 1.91, 1.02, -0.28, 1.94, 1.07, 0.58, 0.22, 0.58, 1.3, 2.83, 2.66, 1.65], ['348', 1.63, 0.49, 0.3412217156204588, -0.04, 0.61, 1.51, 1.34, 1.24, 1.76, 3.22, 0.74, 2.5819344980416408, 1.633913265120849, 2.66, 1.93, 3.31, 1.01, 2.62, 5.97, 1.92, 3.357335482087359, 2.06, 1.62, 2.01, 1.42, 2.33, 2.4926583949931125, 1.63, 0.82, 1.9, 1.18, 2.55, 0.27, 1.86, 5.635702380952381, 1.17, 2.56, 1.31, 0.87, 1.25, 1.01, 3.76, 0.82, -0.8, 0.27, -0.44, 0.9, -1.24071768707483, 0.23, 3.5971355564861205, -0.45, 0.91, -0.32, -0.10857142857142854, -0.37, 0.69, 1.33, 0.15, 2.04, 1.63, 1.08, 0.36, 1.71, -0.55, 1.04, 4.34, 0.35, 1.72, 0.49, 0.06, 0.43, 0.96, 0.55, -0.71, 0.63, -1.61, -0.04, 3.22, -0.72, 0.64, -0.59, -1.01, -0.64, 2.22, 4.62, -4.62, 1.27, 1.35, -0.9, 0.68, 3.96, -0.01, 1.36, 0.13, -0.3, 0.07, 1.74, -0.08, -2.22, -0.66, 2.58, -1.34, 0.01, -1.21, -1.63, -1.26, 0.65, -0.06, 1.81, 1.6, 1.39, 1.8, 2.19, 1.59, 4.91, 0.9, 2.28, 1.04, 0.61, 0.99, 1.13, 0.59, 3.26, -0.68, 0.68, -0.55, -0.97, -0.6, 2.31, 2.74, 0.07, 2.02, 5.47, 0.1, -0.07, -4.12, 4.122462323390895, 2.07, 0.66, 0.7, -2.43, -3.22, -1.64, 0.78, 0.88, 4.85, -4.67, -4.7, 1.643290804863853, -6.21, 3.22, 0.48, -0.24, 6.46, -7.74, -4.39, -6.51, 2.42, -2.59, -3.82, -2.5, -3.69, -4.1, -3.74, 4.83, 1.28, 1.37, 0.13, -0.29, 0.08, -0.09, -1.22, -1.64, -1.27, 1.81, 2.15, 1.14, -0.43, -0.05, 1.6, 1.68, 1.13, -5.79, 1.6711163791806698, 5.78, 1.85, 1.84, 1.57, 0.38, 1.7, 2.1, 1.15, 0.46, 1.2, 1.19, 3.1202406343656346, 2.25, 2.23], ['349', -0.03, -0.12, -0.3098471016907295, 0.07, 0.84, -0.08, -0.04588474204017083, -0.71, -0.24, -0.55, 0.0, -1.35, 0.013913265120848936, -0.71, 0.27, -0.98, -0.47, -0.48, -1.5, -2.23, -0.41, -1.32, -0.91, -0.63, -1.03, 0.55, -0.5173416050068875, -1.35, -0.05, -0.71, 0.27, -0.98, -0.47, -0.48, -1.4992857142857143, -2.23, -0.41, -1.32, -0.91, -0.5761582768021608, -0.44, 1.43, 0.81, 1.32, 0.66, 1.65, 0.38, 0.89, 0.89, -0.15, -0.89, 0.95, 0.03, 0.45, 0.74, -0.07, -0.58, -1.49, -0.72, -0.42075475293412246, -0.66, 0.33, -0.93, -0.42, -0.43, -1.3413219954648525, -2.18, -0.36, -1.27, -0.86, -0.57, -1.26, 0.16, 0.99, -0.28, 0.24, 0.23, -0.8, -1.53, 0.3, -0.62, -0.07690451810094656, 0.08, -0.45, 1.03, -1.06, -0.82, -1.25, -0.75, -0.75, -1.77, -2.306255228898086, -0.69, -1.59, -1.19, -0.8459922724755494, 2.19, 0.44, 0.51, 0.51, -0.52, -1.26, 0.57, -0.34, 0.07, 0.36, -0.03, 0.48, 0.42572371188304003, -0.04, 0.18517906963433994, -0.22432648134996808, -0.08, 0.0, -1.03, -1.76, 0.06, -0.85, -0.44, -0.15, 0.6, -0.08, -1.03, -1.76, 0.06, -0.85, -0.44, -0.15, 0.47, 1.43, 0.12, -0.15, 4.46, -0.2419304505018789, -0.42, 0.77, -0.76, -0.41, -0.32593372653318475, 0.08025974025974027, -3.53, 0.1, 0.05, 0.03, 0.28, -0.24, 0.23, 0.19, -0.05, 1.21, -0.13, -0.25, 0.09, -0.12, 1.2, 0.15, 0.09, 3.46, 0.96, -0.74, 1.1, 0.18, 0.59, 0.89, -0.22, 1.72, 1.86, 0.93, 1.35, 1.64, -0.14, -0.91, -0.5, -0.21, -0.19, -0.53, 0.78, 0.41, 0.7, -0.04, -0.07, -0.6074239503761216, 0.6, -0.2498003730425007, -0.75, -0.18, 0.01, 0.37, 0.29, -0.77, -0.44, 0.01, 0.57, 0.37, 0.07, 0.4, 0.6, 0.07], ['350', -1.99, -0.44, -0.17877828437954127, 0.17, -0.31, 0.19, -0.74, -0.95, -0.72, -0.83, -0.21, -0.38, -0.06, 0.48, -0.19, -0.67, -0.55, 0.13, 2.59, -0.19, -1.0, -0.19, -0.3956947683993239, -0.49, -1.26, -1.21, -0.62, -0.17, 0.15, 0.69, 0.02, -0.46, -0.34, 0.35, 2.81, 0.02, -0.79, 0.02, -0.28, -0.28, -0.76, -0.47, -0.45, 0.32, 0.86, 0.19, -0.29, -0.17, 0.52, 2.99, 0.19, -0.62, 0.19, -0.11, -0.11, -0.14993715369432348, -1.34, -1.5021720271902161, -1.2, -0.77, 0.54, -0.12920068027210885, -0.61, -0.49, 0.19, 2.65, -0.12976190476190477, -0.95, -0.14, -0.43, -0.43, -1.25, -1.3, -0.2497721088435375, -1.14, -1.02, -0.34, 2.11, -0.67, -1.47, -0.67, -0.97, -0.96, -0.48, -0.97, 1.0, -0.64, -0.48, -0.36, 0.33, 2.79, 0.0, -0.81, 0.0, -0.3, -0.3, -2.64, -0.16, 0.12, 0.81, 3.3159047619047617, 0.48, -0.34, 0.7228169964955679, 0.18, 0.18, -0.82, -0.14, 1.33, -0.13, -0.14, -0.24, -0.28, 0.69, 3.16, 0.36, -0.46, 0.36, 0.06, 0.06, -0.7, -0.96, 2.46, -0.32, -1.13, -0.33, -0.62, -0.62, -0.43, 0.33, -0.08, -0.38, -5.12, -0.4796768707482993, -0.3, 0.82, -0.88, -0.41, -0.2, -0.66, 1.38, 0.35, 0.14, -0.95, 0.37, -0.58, 0.56, 0.34, -0.13, 1.16, -0.27, -0.98, 0.45, -0.83, 9.49, 0.53, 0.81, -1.39, -3.34, -2.71, -3.51, -2.72, -3.01, -3.0, -0.36, -0.64, -0.81, 0.0, -0.3, -0.3, 0.18, 0.82, 0.52, 0.52, -0.66, -0.79, -0.64, -0.3, -0.29, 0.09208003431405688, -0.18, -1.02, 4.75, 0.17, -4.86, -1.3, -0.06, -0.34, 0.0, 0.06, -0.34, 0.61, 0.58, -0.17, -0.34, -2.2, -0.42, -0.14], ['351', 0.88, 0.0, 0.17122171562045874, -0.04, 0.18, 0.39, 0.9841152579598291, -0.1, 0.28, 0.23, -0.2, 0.17, -0.07, 1.5, -1.22, 0.15, -0.13, 0.23, -1.22, -0.02, 0.21733548208735892, 0.53, 0.29, -0.12, 0.04, 0.51, 0.42, 0.37, 0.13, 1.7, -0.9721800287049088, 0.35, 0.07, 0.42, -1.03, 0.17, 0.37, 0.72, 0.49, 0.08, 0.8, 0.6749361992161734, 0.05, -0.24, 1.32, -1.39, -0.02, -0.3, 0.05, -1.39, -0.2, 0.0, 0.35, 0.12, -0.29, -0.41, 0.19, -0.86, 0.26, 0.3, 1.57, -1.15, 0.22, -0.06, 0.3, -1.15, 0.05, 0.25, 0.6, 0.36, -0.05, -0.15, -1.25, -2.68, -1.33, -1.6, -1.25, -2.68, -1.5, -1.3, -0.96, -1.19, -1.59, 0.33, -0.06, 0.05, 1.460870922661994, 1.39, 1.11, 1.46, 0.23578854875283461, 1.21, 1.41, 1.77, 1.53, 1.12, 1.12, 0.08, -0.27, 0.08, -1.37, -0.17, 0.03, 0.38, 0.14, -0.27, 0.0, 0.05, -0.25, 0.2515981806829015, 0.18, 0.31, 0.35, 0.35, -1.1, 0.1, 0.3, 0.65, 0.42, 0.01, -0.25, 0.053076748130367266, -1.45, -0.25, -0.05, 0.3, 0.06, -0.34, -0.39, -0.48, 0.04, 0.29, 3.19, -0.03, 0.07, -0.51, 0.54, 0.25, 0.29, 1.04, -0.47, -0.4, -0.21, 0.44, -0.11, 0.54, -0.55, -0.58, 0.19, -0.76, 0.44, 0.31, -0.12, 1.05, -3.15, -0.72, -1.12, 0.52, 1.47, 1.21, 1.42, 1.77, 1.53, 1.12, 0.58, 0.25, 0.2, 0.55, 0.31, -0.09, 0.05, 0.35, 0.11, -0.29, 0.24, 0.37, -0.3, -0.23, -0.64, 0.22, 0.26, -0.07, 0.29, 0.06, -0.33, 0.15, 0.51, -0.06, -0.41, 0.35, 0.42, 0.14, -0.82, 0.06, 0.34, 0.84, 0.66, 0.7730167737073972], ['352', 11.16, 0.74, 0.8112217156204587, -0.45, 3.17, 2.9184196236737594, 3.05, 6.77, 5.59, 6.21, -1.89, 2.401934498041641, 0.94, -0.99, -0.49, 4.52, 0.57, 4.5, 5.19, 2.49, 8.27, 1.67, 0.23, 3.23, 7.5, 3.98, 8.26, 4.18, 2.88, 0.92, 1.43, 6.54, 2.51, 6.52, 7.230714285714286, 4.47, 10.36, 3.64, 2.17, 5.22, 4.53, 8.1, 3.92, -1.24, -3.12, -2.63, 2.27, -1.6, 2.25, 2.93, 0.7096666666666667, 5.93, -0.52, -1.93, 1.01, 5.21, 6.43, 4.94, 3.98, 5.22, -1.91, -1.41, 3.55, -0.37, 3.53, 4.22, 1.54, 7.26, 0.73, -0.7, 2.27, 6.79, 7.27, 0.51, 5.57, 1.57, 5.54, 6.25, 3.52, 9.35, 2.69, 1.23, 4.26, 8.048909863945578, 16.38, -16.33, 6.73, 5.03, 1.06, 5.01, 5.71, 3.0, 8.8, 2.17, 0.72, 3.74, 1.93, 1.61, -3.78, -0.02, 0.64, -1.94, 3.6426265373526934, -2.73, -4.1, -1.23, 1.5911418739990169, 1.66, 5.57, 3.44, 3.76, 3.31, 5.61, 3.91, 4.6, 1.92, 7.66, 1.1, -0.33, 2.65, 4.1, 1.64, 0.67, -1.92, 3.61, -2.7, -4.08, -1.21, 5.59, 5.78, 0.17, 4.75, 3.82, 1.97, 1.15, -6.1, 6.05, 3.04, 1.83, 7.19, -7.2, -6.85, -3.46, 5.57, 2.13, 10.55, -10.5, -10.32, 3.43, -9.09, 6.87, 6.64, -3.28, 16.77, -26.49, -11.15, -16.6, 7.02, 0.96, -2.57, 2.92, -3.35, -4.72, -1.87, 10.27, 3.62, 5.63, -0.8, -2.21, 0.72, -1.9, -6.09, -7.42, -4.65, 5.61, 6.11, 4.46, -1.42, 1.53, 3.4, 3.6, 6.78, -13.22, 4.91, 13.33, 5.44, 4.23, 5.96, 2.99, 4.780077402522781, 3.35, 0.87, 2.46, 1.98, 2.965957527023814, 9.05, 6.743037664716236, 4.46], ['353', -3.39, 1.04, -0.008778284379541255, 0.07, 0.06, 0.52, -0.5, 0.31, 0.72, 0.56, 0.09031847121132863, 0.42, -0.49, 0.71, 0.29, 1.06, 0.33, 0.49, 0.36, -0.25, 1.12, 1.04, 0.3543052316006761, -0.49, 1.33, 0.28, 0.68, 0.5401785714285715, -0.37, 0.83, 0.41, 1.19, 0.45, 0.61, 0.48, -0.13, 1.25, 1.16, 0.38, -0.37, 0.6174684253532109, 2.0, 0.14, -0.91, 0.29, -0.13, 0.64, -0.09, 0.07, -0.07, -0.67, 0.7, 0.62, -0.16, -0.91, 0.55, 0.45, 0.15, 0.75, 1.06, 1.21, 0.78, 1.56, 0.82, 0.98, 0.85, 0.24, 1.62, 1.54, 0.75, 0.0, 0.93, -0.15, -0.42, 0.35, -0.38, -0.22, -0.3469047619047619, -0.96, 0.41, 0.33, -0.45, -1.19, 1.05, 1.02, -1.02, 0.27, 0.77, 0.04, 0.2, 0.07, -0.54, 0.83, 0.75, -0.03, -0.78, -0.71, -0.5, -0.73, -0.57, -0.7, -1.3, 0.06, -0.02, -0.79, -1.54, -0.05, -0.49, -0.16, 0.61, 0.47, 0.7, 0.23, 0.16, 0.03, -0.58, 0.8, 0.71, -0.07, -0.7514153161169344, 0.39, 0.12307674813036727, -0.13, -0.74, 0.63, 0.55, -0.23, -0.97, 0.13, 0.32, 0.04, 0.25, -1.87, 0.07, 0.17, -1.76, 1.78, 0.91, 0.89, -0.5, -1.4494817511227285, -1.23, -0.64, -1.67, 0.49, 1.85, -1.79, -1.8, 0.62, -2.68, 1.24, -0.27, 0.13, 0.71, -1.7, -0.5, -0.74, 1.5738095238095238, 0.21, -0.61, 0.77, 0.68, -0.1, -0.84, 1.87, 0.82, 1.38, 1.3, 0.51, -0.24, -0.56, -0.08, -0.86, -1.6, 0.27, 0.36, -0.47, -0.77, -1.52, 0.17, 0.06, 0.12, -0.33, 0.43019962695749936, 0.39, -0.03, 0.64, 0.3, -0.75, 0.58, 0.63, 0.78, 0.08, 0.61, 1.06, -0.39, 0.35, 0.67], ['354', -7.13, -0.22, -0.19877828437954126, -0.17, -0.05, 1.22, -0.41, -0.6982794034640413, 0.32, -1.13, -2.29, -0.92, -1.76, -0.58, 0.59, 1.65, -0.57, -1.21, -3.38, -1.51, -1.402664517912641, -0.67, -2.47, -1.57, 0.6, -0.27, 1.18, 1.4, 0.54, 1.75, 2.94, 4.03, 1.76, 1.1, -1.12, 0.79, 0.87, 1.66, -0.18, 0.73, -1.8345146341753484, 1.33, -0.20979591836734693, -0.7588025325038829, 0.35, 1.52, 2.6, 0.36, -0.29, -2.478347866419295, -0.6, -0.53, 0.25, -1.56, -0.66, -2.0476426685347184, -1.76, -2.77, 0.48, 0.64, 1.2, 2.38, 3.47, 1.8814285714285712, 0.55, -1.65, 0.25, 0.32, 1.1114285714285714, -0.72, 0.19, -1.11, -0.56, 1.17, 2.24, 0.01, -0.4701734693877551, -2.82, -0.94, -0.87, -0.08857142857142856, -1.9, -1.0, 0.98, 2.82, -2.95, -1.71, 1.06, -1.15, -1.79, -3.94, -2.09, -2.02, -1.25, -3.04, -2.15, -0.94, -2.74, -2.18, -2.82, -4.95, -3.11, -3.04, -2.2775714285714286, -4.05, -3.17, -0.19, -2.78, -0.08427628811695997, 0.08, 0.73, 0.24567351865003195, -0.57, -0.65, -2.83, -0.95, -0.88, -0.1, -1.91, -1.01, -0.43, 0.08, -2.2, -0.3, -0.23, 0.55, -1.27, -0.37, 1.44, -0.26, -0.26, -0.18, -1.9, -0.5196768707482994, -0.75, 1.52, -1.57, -0.78, -3.31, -0.59, -0.66, -1.29, -0.67, -2.27, 1.02, 1.4905968614718617, -1.49, -1.9, 0.68, 2.49, 1.31, 2.98, -1.52, -1.64, -0.59, 1.25, 1.76, 0.64, 2.650378684807256, 1.93, 2.01, 2.81, 0.94, 1.87, 1.78, 0.39, 0.07, 0.86, -0.97, -0.06, 0.32, 0.78, -1.04, -0.13, 0.37, 0.9, -0.47, -1.81, -0.91, 0.62, 0.43, -1.03, -0.32, 0.37, 0.17, 0.79, 0.4411825396825397, 1.37, 0.92, 0.85, -0.47, 1.3952979520479523, 0.51, 0.82, 0.45, -0.69, -0.7184047619047619, 1.52], ['355', 0.88, 0.4, 0.16015289830927054, 0.11, 0.53, -0.1, 0.41, 0.02, -0.17, 1.14, 1.42, 0.93, 1.59, 1.48, 0.31, 1.16, 1.01, 1.06, -1.09, 0.85, 0.67, 1.2, 1.37, 1.3, -0.12, 0.03, -0.28, -0.48, 0.17, 0.06, -1.09, -0.26, -0.4, -0.35, -2.47, -0.56, -0.73, -0.21, -0.04, -0.12, 0.15, -0.28, 0.2, 0.65, 0.54, -0.61, 0.22, 0.08, 0.13, -2.0, -0.08, -0.26, 0.27, 0.44, 0.36, -0.65, -0.37, 0.26, -0.17, -0.45, -0.11, -1.26, -0.43, -0.57, -0.52, -2.531321995464853, -0.73, -0.9, -0.38, -0.21, -0.29, -0.73, -0.33, -1.15, -0.32, -0.46, -0.41, -2.53, -0.62, -0.79, -0.27, -0.1, -0.17, -0.2, -0.69, 0.69, 0.8566982383853201, 0.84, 0.7, 0.75, -1.39, 0.53, 0.36, 0.89, 1.06, 0.98, 0.18, 0.05736653121656289, -0.14, -0.09, -2.22, -0.31, -0.48, 0.05, 0.22, 0.14, 0.02, 0.0, 0.13, 0.0, 0.05, -0.06, 0.12, 0.05, -2.08, -0.16, -0.33, 0.19, 0.36, 0.29, -0.04, 0.07, -2.13, -0.22, -0.39, 0.14, 0.31, 0.23, -0.67, -0.71, 0.11, 0.08, 0.3, 0.1, 0.13, 0.76, -0.7475376766091052, -0.3511898289923789, 0.14, 0.93, -0.51, -0.02, 0.03, 0.45, 0.16, 0.0, -0.07, -0.06, 0.03, 1.15, 0.08, -1.31, 0.67, 0.33, -7.56, -0.21, -0.26, 0.6, 2.25, 1.95, 1.78, 2.32, 2.49, 2.41, 0.04, 0.29, -0.17, 0.36, 0.52, 0.45, 0.46, 0.53, 0.69, 0.62, -0.12, -0.08154645354645335, -0.07, 0.17, 0.09, 0.03, 0.03, 0.06257604962387836, -4.66, 0.0, 4.65, 0.23, 0.52, -0.23, -0.07, 0.54, -0.46, 0.03, 0.42, 0.09, -0.16, 0.35, -0.02, 0.26], ['356', 0.23, -0.37, -0.2, 0.05, -0.21, -0.42, -0.54, 0.14, -0.48, -0.22, 0.04, -0.28, 0.21, -0.17, 0.39, -0.02, -0.08, 0.25, 4.4, 0.43, -0.3426645179126411, -0.08, 0.47, 0.35, -0.57, -0.71, -0.22734160500688755, -0.31, 0.17, -0.2, 0.36, -0.05, -0.12, 0.21, 4.37, 0.39, -0.42, -0.12, 0.44, 0.32, -2.0, -0.6850638007838266, 0.05, 0.49, 0.11, 0.67, 0.26, 0.2, 0.53, 4.69, 0.71, -0.11, 0.2, 0.75, 0.63, -0.75, 0.31, 0.13, -0.63, -0.43, -0.38, 0.18, -0.23, -0.29, 0.04, 4.19, 0.22, -0.59, -0.29, 0.26, 0.14, -0.61, -0.06, 0.5607142857142857, 0.15, 0.09, 0.42, 4.58, 0.59, -0.22, 0.08, 0.64, 0.52, -0.45, -1.53, 1.75, -0.61, -0.41, -0.47, -0.14, 4.0, 0.04, -0.77, -0.47, 0.08, -0.04, -1.15, -0.21, -0.06, 0.27, 4.42, 0.45, -0.37, 0.1728169964955679, 0.49, 0.37, -0.22, 0.17, -0.82, -0.41, -0.42482093036566004, -0.34, -0.14, 0.33, 4.49, 0.51, -0.3, 0.0, 0.56, 0.43, -0.28, -0.47, 4.15, 0.18, -0.63, -0.33, 0.23, 0.1, -2.3, -0.93, 0.05, -0.13, -4.29, 0.03, -0.08, -0.36, 0.37, 0.23, -0.4, -0.75, -0.16, 0.61, 0.39, -0.11, -0.15, -1.0885238095238097, 0.89, 0.75, -0.35, -0.95, -0.84, -1.0, 0.47, -0.31, -6.17, 0.35, 0.0, -1.37, -4.43, -3.81, -4.59, -4.3, -3.76, -3.88, -0.92, -0.65, -0.81, -0.51, 0.05, -0.08, 0.16, 0.3, 0.86, 0.74, -0.49, -0.51, -0.14, 0.56, 0.44, -0.43, -0.43, -0.07742395037612165, -1.41, -0.84, 1.11, 0.11, -1.09, -0.69, -0.12, -0.27, 0.21, -0.9, 1.05, -0.67, -0.57, -1.06, -1.56, -1.61], ['357', -2.92, -0.52, 0.22122171562045873, 0.14, -1.51, -2.8, -1.8758847420401707, -3.3, -3.33, -3.84, 1.1, -1.76, -0.23, 0.12, -1.27, -3.49, -0.67, -3.29, -2.29, -1.53, -4.85, -0.78, -0.9256947683993239, -1.09, -3.26, -2.560628585411108, -4.89, -2.83, -1.32, -0.97, -2.35, -4.54, -1.76, -4.35, -3.35, -2.6, -5.89, -1.86, -2.1, -2.17, -2.602531574646789, -6.22, -1.920696767518196, 1.55, 1.91, 0.49, -1.76, 1.11, -1.56, -0.54, 0.24, -3.15, 1.0, 0.75, 0.68, -1.63, -3.38, -1.88, -2.46, -3.62, 0.35, -1.039200680272109, -3.27, -0.44, -3.06, -2.06, -1.3, -4.63, -0.55, -0.79, -0.86, -4.47, -3.96, -1.39, -3.61, -0.79, -3.41, -2.4, -1.64, -4.97, -0.9, -1.14, -1.21, -5.16, -8.09, 8.17, -2.6, -2.24, 0.61, -2.04, -0.7842114512471654, -0.25, -3.62, 0.5, 0.26, 0.18, -0.9, -0.36, 2.92, 0.21, 1.25, 2.04, -1.41, 2.81, 2.56, 2.48, -0.47, -0.38, -3.28427628811696, -2.68, -2.57, -2.6443264813499683, -3.19, -2.64, -1.63, -0.86, -4.21, -0.11, -0.35, -0.43, -2.76, -0.57, 1.04, 1.82, -1.61, 2.6, 2.35, 2.27, -2.8281719617057965, -3.05, 0.21, -2.81, -1.76, -0.5677486640343783, -0.61, 4.68, -4.72, -2.371189828992379, -0.19, -4.19, 4.56, 5.33, 2.66, -1.39, -2.5, -7.96, 7.96, 8.01, -2.63, 7.06, -5.25, -1.4, 0.73, -9.5, 17.62, 6.39, 9.49, -4.59, -1.59, 0.78, -2.62, 1.54, 1.3, 1.3857617128436457, -7.886832100439243, -2.35, -3.38, 0.76, 0.51, 0.44, 1.06, 4.28, 4.03, 3.95, -3.079864861329147, -3.88, -3.09, -0.24, -0.32, -2.71, -2.64, -3.48, 8.84, -3.22, -8.53, -2.95, -3.32, -2.771362551799029, -0.08, -2.5599225974772195, -2.17, -2.38, -2.43, -2.85, -2.78, -2.88, -3.54, -2.06], ['358', 3.93, -0.9, 0.13, -0.02, -0.52, 0.2, 0.8141152579598292, -0.05, -0.39, 0.3970884353741497, 0.36, -0.77, 0.28, -0.05, -0.28, -1.04, 0.53, 0.03, 1.66, 1.83, -0.44, 0.13, 0.89, -0.26, 0.49, -0.45, -0.41, -1.13, -0.08, -0.41, -0.64, -1.4, 0.17, -0.33, 1.3, 1.47, -0.8, -0.23, 0.53, -0.5761582768021608, -0.55, -1.98, 0.730204081632653, 1.06, 0.73, 0.49, -0.27, 1.31, 0.81, 2.45, 2.63, 0.33, 0.91, 1.67, 0.51, 0.04, 0.08, 1.07, -0.25, -0.33, -0.33, -0.56, -1.32, 0.25, -0.25, 1.38, 1.55, -0.72, -0.15, 0.61, -0.54, 1.37, 0.0, -0.23, -0.99, 0.58, 0.08, 1.71, 1.88, -0.39, 0.18, 0.94, -0.22, -1.0, -1.86, 1.77, 0.23, -0.6719125667872351, 0.81, 0.31, 1.95, 2.12, -0.16, 0.41, 1.17, 0.02, 1.66, 1.0773665312165628, 1.59, 1.08, 2.73, 2.91, 0.61, 1.18, 1.95, 0.79, -0.01, 1.02, -0.67, 0.2, 0.02, 0.16, -0.57, -0.5, 1.13, 1.3, -0.9593197278911564, -0.4, 0.36, -0.79, -0.18, -0.08, 1.63, 1.8, -0.47, 0.1, 0.86, -0.29, -1.86, -2.03, 0.17, -0.63, 3.28, -0.21, 0.07, -1.04, 1.05, 0.32, -0.51, -1.18, 3.62, -0.31, -0.16, 1.91, 0.65, 0.31, -0.29, -0.7, -0.32, -1.57, 0.39, -0.91, 0.48, -1.64, -2.93, 1.11, 1.58, -3.69, -1.68, 0.17, -2.07, -1.51, -0.76, -1.9, 0.53, -1.85, -2.23, -1.68, -0.93, -2.06, 0.39, 0.57, 1.33, 0.18, -0.43, -0.73, -0.18, 0.76, -0.39, 0.14, 0.04, 0.05, -1.44, -0.5898003730425007, 1.4165238095238095, -0.75, -1.11, -0.93, -1.14, -0.3, 0.1, -0.06, -0.06, -0.18, 0.22, -1.26, -1.3, -0.06], ['359', -0.46, 0.33, 0.13122171562045873, -0.3, 0.28, 0.85, -0.13588474204017084, 1.22, 0.65, 0.55, -0.61, 1.38, -0.96, -0.43, -0.89, 0.85, -0.76, 0.85, -2.02, -0.78, 0.43, -1.15, -1.19, -0.5, 0.59, 0.85, 1.16, 2.0, -0.36, 0.18, -0.29, 1.47, -0.15, 1.46, -1.42, -0.17, 1.04, -0.55, -0.59, 0.1, 1.17, 0.83, -0.6206967675181959, -2.31, -1.78, -2.24, -0.52, -2.11, -0.52, -3.35, -2.13, -0.94, -2.49, -2.53, -1.85, 0.35, 0.55, 0.86, 1.08, 1.52, 0.54, 0.07, 1.83, 0.21, 1.83, -1.07, 0.18, 1.4, -0.19, -0.23, 0.46, 1.2, 0.98, -0.46, 1.29, -0.33, 1.28, -1.6, -0.35, 0.86, -0.73, -0.76, -0.07, 1.17, 4.95, -4.91, 1.48669823838532, 1.76, 0.14, 1.76, -1.14, 0.11, 1.33, -0.26, -0.3, 0.39, 0.39, -0.3, -1.6, 0.0, -2.85, -1.62, -0.42, -1.99, -2.02, -1.34, -0.029020408163265305, -0.31, 2.4157237118830404, 1.08, 1.3, 0.79, 1.31, 1.62, -1.27, -0.02, 1.2, -0.4, -0.35401213658444736, 0.26, 1.42, -0.3, -2.85, -1.62, -0.42, -1.8542004503433074, -2.02, -1.34, 1.57, 1.39, -0.23, 1.18, 1.22, -0.26, 0.07, -1.34, 1.32, 0.67, 0.43, 0.77, -2.52, -2.11, -1.09, -0.2, 0.56, 3.320596861471862, -3.16, -3.26, 1.08, -1.92, 2.16, 1.45, -0.95, 3.9, -6.0, -2.65, -3.86, 2.57, 2.62, 1.27, 2.5, 0.89, 0.85, 1.55, 3.26, 1.34, 1.22, -0.37, -0.41, 0.28, 0.12, -1.5671150714365, -1.61, -0.93, 0.72, 1.01, 1.72, -0.04, 0.66, 1.09, 1.1, 1.27, -3.2, 2.2311163791806696, 3.26, 1.0572638105244332, 2.13, 1.76, 0.7, 0.68, 0.77, 0.5, 0.67, 0.53, 1.05, 1.71, 2.09, 0.83], ['360', -4.66, -0.29, 0.19122171562045873, 0.23, -1.18, -0.19, -0.45, -0.47, -1.09, -1.02, 0.38, -0.08, -0.87, -1.16, -0.63, -0.85, 0.37, -0.86, -1.92, 1.51, -1.73, -0.88, -0.76, -0.84, -0.88, -0.95, -1.4, -0.46, -1.25, -1.54, -1.01, -1.23, -0.01, -1.24, -2.3, 1.12, -2.1, -1.25, -1.13, -1.22, -0.6, -1.1450638007838265, -0.95, -0.7188025325038829, -1.09, -0.55, -0.77, 0.45, -0.79, -1.85, 1.59, -1.65, -0.7061344435209982, -0.68, -0.76, -0.08, -0.39, -1.23, -1.31, -0.15, -0.29, 0.25, 0.03, 1.26, 0.01, -1.06, 2.4, -0.86, 0.0, 0.12, 0.03, -0.2763939988582844, 0.14, 0.54, 0.32, 1.55, 0.3, -0.77, 2.7, -0.57, 0.29, 0.41, 0.33, -1.47, -1.04, 0.97, -0.4, -0.22, 1.0, -0.24, -1.31, 2.15, -1.11, -0.25, -0.13, -0.21, -2.03, -0.17, 1.23, -0.02, -1.08, 2.38, -0.88, -0.03, 0.09, 0.01, -0.26, -0.15, -1.3, -0.32, -0.39, -0.37, -1.3890429599640124, -1.23, -2.29, 1.13, -2.09, -1.24, -1.12, -1.21, 0.12653607107178547, -0.10692325186963274, -1.07, 2.482244713705627, -0.87, -0.01, 0.11, 0.03, -0.76, -1.12, 0.12, -0.75, -6.13, 0.13, 0.06, 0.21, -0.25, -0.12, 0.45, 0.3, 5.01, 0.63, 0.38, -2.38, -0.09, -1.12, 1.05, 1.01, -0.33, 0.49, -0.65, -1.79, 0.88, -4.13, -0.18, 2.76, 4.13, -4.87, 0.92, 3.5, 0.2, 1.07, 1.19, 1.11, -0.98, -2.49, -3.19, -2.35, -2.23, -2.31, 0.72, 0.87, 0.99, 0.9, -1.08, -1.24, -0.15, 0.12, 0.11224875531501632, -0.33, -0.45, -0.42, 0.47, -1.21, -0.66, -0.43, -1.32, -0.27, -0.08, -0.67, -0.08, 0.01, -0.03, -0.3, -0.18, -1.72, -1.81, -0.02], ['361', 4.91, 0.01, -0.12, 0.47, -0.23, -1.47, -0.6, -2.42, -2.12, -2.05, 1.65, -1.68, 0.42, 0.5170238095238096, -0.16, -3.559285714285714, 0.25, -1.1294285714285712, -0.83, -0.01, -2.28, 0.35, -0.15, 0.68, -2.85, -1.68, -3.65, -3.28, -1.22, -1.12, -1.78, -5.13, -1.38, -2.74, -2.45, -1.64, -3.87, -1.29, -1.78, -0.96, -1.11, -3.42, -0.38, 2.13, 2.23, 1.55, -1.91, 1.96, 0.56, 0.86, 1.7, -0.61, 2.06, 1.55, 2.4, -0.89, -1.41, -1.8980521152823784, -2.16, -2.46, 0.1, -0.57, -3.96, -0.17, -1.54, -1.24, -0.42, -2.69, -0.07, -0.57, 0.26, -2.64, -2.55, -0.67, -4.05, -0.11051058745176379, -1.63, -1.34, -0.52, -2.78, -0.17, -0.67, 0.17, -3.46, -5.95, 5.861428571428572, -1.9, -3.41, 0.41, -0.97, -0.68, 0.15, -2.13, 0.51, 0.0, 0.84, 2.75, 1.57, 3.95, 2.52, 2.83, 3.68, 1.33, 4.05, 3.53, 4.4, -1.07, 1.61, -2.83, -1.82, -1.96, -1.84, -2.29, -1.37, -1.08, -0.26, -2.53, 0.1, -0.4, 0.43, -2.2, -0.93, 0.3, 1.13, -1.17, 1.49, 0.99, 2.0721774376417237, -2.37, -1.17, 0.86, -2.27, 5.47, -0.13, 0.0, 3.88, -3.94, -1.94, -0.71, -2.75, 4.07, 3.72, 1.82, 2.38, -1.11, -5.66, 5.66, 5.57, -1.83, 5.83, -3.66, -5.46, 2.73, -6.88, 9.96, 4.59, 6.92, -3.9228690476190478, -1.23, 0.83, -1.46, 1.19, 0.69, 1.53, -5.5, -2.04, -2.27, 0.36, -0.15, 0.69, 0.24, 2.69, 2.18, 3.03, -2.18, -2.63, -2.39, -0.5, 0.33, -1.86, -1.91, -2.32, 4.82, -3.23, -4.58, -2.03, -1.99, -1.9, 0.84, -2.55, -1.55, -0.83, -1.02, -1.91, -2.71, -1.81, -2.68, -3.39], ['362', 0.92, 0.37, 0.26122171562045876, 0.36, -0.65, 0.02, -0.13588474204017084, -0.7, -0.99, 0.05, 1.6, 0.35, -1.11, -1.74, 1.05, -0.01, 0.32, 0.23, -3.45, 0.46, -0.04, 0.63, 0.44, 1.06, -1.15, 0.21, -1.53, -1.23, -2.67, -3.29, -0.54, -1.58, -1.26, -1.35, -4.97, -1.12, -1.61, -0.95, -1.14, -0.53, 0.54, -2.76, -0.3, -1.46, -2.08, 0.7, -0.3590816326530612, 0.009278911564625847, -0.12, -3.79, 0.11476190476190476, -0.39, 0.28, 0.7214285714285714, 0.71, -0.14, 0.47, -1.52, -1.199047619047619, 1.17, -0.64, 2.19, 1.12, 1.45, 1.36, -2.37, 1.59, 1.09, 1.76, 1.57, 2.2, -0.98, 1.82, 2.84, 1.76, 2.1, 2.01, -1.74, 2.25, 1.74, 2.41, 2.22, 2.85, -1.81, -1.22, 1.2, -0.99, -1.0494795918367348, -0.72, -0.81, -4.46, -0.58, -1.08, -0.42, -0.61, 0.01, 2.55, 0.06, 0.33, 0.24, -3.45, 0.47, -0.03, 0.64, 0.45, 1.07, -0.008858126000982985, 0.02, -1.68, -0.13, -0.18, 0.0, -0.27, 0.04659939068867647, -3.77, 0.14, -0.35931972789115646, 0.31, 0.12, 0.74, -0.31, -0.18, -3.68, 0.23, -0.27, 0.4, 0.21, 0.83, -0.73, -1.03, 0.51, -0.52, 5.08, 0.05, 0.29, 0.19, -0.25, -0.1, 0.38, -1.36, 0.78, 0.21, 0.07, 0.44, -0.39, -0.36, 0.3, 0.27, -0.11, 0.27, -0.18, -2.24, 1.164765264284247, -0.93, -1.01, 0.61, 0.82, -0.7, 3.950378684807256, 4.06, 3.54, 4.23, 4.04, 4.68, -0.32, -0.41, -0.5, 0.17, -0.02, 0.6, 0.09, 0.67, 0.48, 1.1, -1.02, -1.46, -0.58, -0.19, 0.43, -0.1, -0.09, -0.6, -0.41, -2.0, 0.27, 0.73, 0.5510935020800125, -0.39, 0.62, -0.15, 0.11, -0.33, -0.47523809523809524, 0.38, -1.0, 2.66, 0.013037664716236297, -2.24], ['363', -0.29, -0.21, -0.12984710169072947, 0.18, -0.3, -0.17, 0.69, -0.59, -0.51, -0.25, 1.47, -1.05, 0.27, 0.27, 0.57, -0.45, 0.04, 0.03, -0.95, -0.05, -0.57, -0.25, 0.07, -0.35, -0.44, 0.01, -1.7, -2.48, -1.18, -1.19, -0.89, -1.89, -1.41, -1.42, -2.38, -1.5, -2.01, -1.7, -1.38, -1.7461582768021608, -0.13, -1.14, 0.81, 1.34, 1.4978753944468233, 1.63, 0.61, 1.1, 1.09, 0.1, 1.01, 0.48, 0.81, 1.13, 0.71, -1.52, -0.29, 0.22, 0.0, -0.52, -0.01, 0.29, -0.72, -0.24, -0.24, -1.22, -0.32, -0.676578845757417, -0.52, -0.21, -0.62, -0.98, -0.52, 0.3, -0.71, -0.23, -0.23, -1.21, -0.32, -0.84, -0.52, -0.2, -0.62, -1.37, -0.48, 0.41, -0.81, -1.01, -0.53, -0.53, -1.51, -0.61, -1.13, -0.81, -0.5, -0.91, 0.35, 0.2, 0.49, 0.48, -0.5, 0.4, -0.12, 0.2, 0.52, 0.1, -0.17, 0.22, -0.56, -0.26, -0.17, -0.26, -0.29, -0.01, -0.99, -0.09, -0.61, -0.29, 0.03, -0.3314153161169343, -0.09, -0.28, -0.98, 0.012244713705627006, -0.6, -0.28, 0.04, -0.38, -0.12, -0.1, 0.27, 0.23318678362356798, 0.98, -0.02, 0.0, 0.99, -1.02, -0.49, 0.2, -0.8497402597402597, 0.3, 0.46, 0.27, -0.12, 0.003079789868779062, -0.77, 0.71, 0.79, -0.26, 1.42, -0.53, -1.24, 0.61, -0.88, 2.76, 0.5, 0.75, -0.3, 0.7, 0.91, 0.38, 0.7, 1.03, 0.6, -0.72, -0.2, -0.52, -0.2, 0.12, -0.3, 0.32, 0.32, 0.64, 0.22, -0.45, -0.83, 0.0, 0.32, -0.1, -0.26, -0.21, -0.65, 1.6, -0.59, -1.44, -0.23, -0.79, -0.32, -0.42, -0.25, -0.24, -0.05, -0.12, -0.23, 0.1, 1.64, -0.41, -0.18], ['364', -0.69, -0.32, 0.05122171562045875, 0.07, -0.1170209190089404, 0.85, 1.0041152579598291, 1.41, 0.48, 0.85, 0.47, 0.42, 0.46, -0.51, -2.7, 1.14, 0.87, 0.67, -3.77, 1.47, 0.71, 1.27, -0.42, 1.08, 0.48, 0.54, 0.38, -0.05, 0.0, -0.97, -3.15, 0.67, 0.4, 0.21, -4.22, 1.0, 0.24, 0.8, -0.89, 0.61, 2.01, -0.5250638007838266, 0.43, 0.05, -0.92, -3.1, 0.72, 0.46, 0.26, -4.17, 1.05, 0.29, 0.9438655564790018, -0.84, 0.67, 0.68, 0.74, 0.66, 0.73, 0.38, -0.96, -3.15, 0.67, 0.41, 0.21, -4.21, 1.01, 0.25, 0.81, -0.88, 0.62, 0.94, 1.36, -2.21, 1.65, 1.39, 1.19, -3.28, 1.99, 1.22, 1.79, 0.08, 1.6, 0.37, 2.9, -2.92, 3.65, 3.95, 3.67, 3.47, -1.1, 4.29, 3.51, 4.08, 2.34, 3.89, -2.4, -0.29, -0.26, -0.46, -4.85, 0.33, -0.42, 0.13, -1.54, -0.05, 0.03, -0.36, -2.09, 0.36, 0.78, -0.14, -0.02, -0.2, -4.6, 0.6, -0.16, 0.4, -1.29, 0.21, -0.41, 0.17, -4.41, 0.8, 0.04, 0.59, -1.09, 0.6521774376417234, 0.74, 0.45, 0.23, 0.32, -7.08, 0.0, -0.14, 1.55, -1.54, -0.76, -0.45, 2.18, 1.37, -0.73, -0.35, -0.31, 0.71, 1.02, -1.01, -1.11, 0.36, 2.3, 0.77, -0.33, 0.14, -0.12, -3.4, 0.0, 0.13, -1.27, 4.8, 5.45, 4.65, 5.24, 3.47, 5.04, 1.08, -0.62, -0.75, -0.2, -1.87, -0.38, 0.14, 0.56, -1.13, 0.37, 0.58, 0.53, -0.42, -1.67, -0.19, 0.36, 0.3, 1.44, -0.98, -1.86, 1.03, -1.0, 0.77, 1.28, 1.52, 1.2, -0.69, 0.32, 1.78, 0.55, -0.23, 0.46024063436563456, 2.9, -0.33], ['365', -5.08, 0.04, -0.028778284379541254, 0.09, -1.06, -0.11, 0.6700361663652803, -0.41, -0.2, -0.15, 0.28, -1.14, 0.66, 1.25, 0.46, 1.46, 0.45, -0.23, -0.56, 2.33, -0.55, -0.35, 0.41, 0.42, -1.14, -0.87, -0.43, -1.4098214285714286, 0.3846428571428572, 1.10318993704708, 0.18, 1.18, 0.17, -0.51, -0.84, 2.05, -0.83, -0.63, 0.13, 0.13, -0.42, -1.19, 1.189303232481804, 1.82, 2.41, 1.61, 2.63, 1.61, 0.92, 0.58, 3.51, 0.59, 0.79, 1.56, 1.57, -0.42, 0.04, 0.15, -0.6, -0.81, 0.58, -0.2, 0.8, -0.21, -0.88, -1.21, 1.66, -1.21, -1.01, -0.25, -0.21581519274376415, 1.45, -1.38, -0.78, 0.21, -0.78, -1.46, -1.79, 1.07, -1.78, -1.58, -0.83, -0.82, -0.64, -1.5, 1.49, -0.61, 1.0, 0.0, -0.68, -1.01, 1.87, -1.01, -0.81, -0.05, -0.04, -3.2679047619047616, -1.512633468783437, -0.99, -1.67, -1.99, 0.86, -1.99, -1.79, -1.04, -1.03, 0.07, -1.61, -3.589822996574516, -0.47, -0.52482093036566, -0.39, -0.5381905235138708, -0.68, -1.01, 1.87, -1.0, -0.8, -0.05, -0.04, -0.09, 0.07, -0.33, 2.57, -0.33, -0.13, 0.64, 0.64, -0.49, -0.04, 0.15603717887804044, -0.65, -9.63, -0.03, -0.09, 1.5, -1.52, -0.73, -0.43, -1.8297402597402599, 4.84, 0.94, 0.45, -2.51, 0.3, -1.47, 1.49, 1.36, -0.46, 2.22, -0.93, -0.42, 0.18, -1.84, 5.97, 1.29, 1.79, -4.88, 0.41, 2.91, 0.01, 0.21, 0.97, 0.98, -1.46, -2.43, -2.82, -2.63, -1.8712346938775508, -1.8785714285714286, 0.4, 0.2, 0.97, 0.97, -0.22, -0.42, 0.2, 0.76, 0.77, -0.47, -0.51, -0.38, 3.65, -2.45, -3.65, -1.84, -1.16, -0.56, 0.01, -0.48, -0.63, 0.24, 0.53, -0.15, -0.57, -3.48, -2.07, -0.61], ['366', -2.89, -0.35, 0.011221715620458745, 0.23, -1.19, -0.31158037632624047, -0.6858847420401708, -1.45, -1.16, -1.92, -0.36, -1.72, -1.35, -0.8, 0.91, -1.46, -1.31, -1.97, -0.89, -1.04, -2.37, -0.93, -0.6356947683993238, -1.73, -1.1, -0.540628585411108, -1.5373416050068875, -1.36, -0.99, -0.29681006295292, 1.3278199712950913, -1.11, -0.96, -1.62, -0.54, -0.68, -2.02, -0.57, -0.37, -1.38, -1.4, -1.41, -0.21, 0.38, 0.94, 2.67, 0.26, 0.41, -0.26, 0.84, 0.69, -0.67, 0.8938655564790019, 1.0, -0.02, -1.45, -1.13, -0.75, -1.25, -0.58, 0.56, 2.28, -0.12, 0.03, -0.63, 0.46, 0.31, -1.04, 0.42, 0.62, -0.39, -1.6763939988582846, -1.14, 1.72, -0.67, -0.3705105874517638, -1.19, 0.14747644815501967, -0.24, -1.59, -0.13, 0.06, -0.94, -1.71, -3.26, 3.22, -2.7633017616146796, -2.35, -2.2, -2.85, -1.78, -1.93, -3.25, -1.82, -1.62, -2.61, -0.77, -0.3926334687834371, 0.15, -0.52, 0.8866683673469387, 0.43, -0.93, 0.54, 0.74, -0.27, -0.12, -0.41, -1.69, -0.42, -0.62, -0.23, -0.61, -0.66, 0.43, 0.28, -1.07, 0.39, 0.59, -0.42, -0.8334639289282145, 0.05, 1.1, 0.95, -0.41, 1.06, 1.26, 0.24, -0.68, -0.54, 0.06, -0.37, -2.16, -0.24, -0.21, -0.26, 0.24, 0.13, -0.29, -1.43, 1.8, 0.8, 0.38, -1.4, -0.38692021013122097, -1.29, 1.27, 1.23, -0.44, -0.39, -0.86, -3.33, 1.68, -1.76, 4.31, 1.19, 1.77, -1.7, -1.04, -0.15, -1.49, -0.04, 0.16, -0.85, -1.25, -0.89, -1.35, 0.11, 0.31, -0.7, 0.46, 1.48, 1.68, 0.66, -1.14, -1.56, -1.0, 0.3932337781266354, -0.81, -0.42, -0.44, -1.41, 2.03, -1.35, -2.05, -0.11, -0.7989064979199876, -1.2, -1.01, -0.58, 0.3, -0.47, -0.56, -0.29, -0.19, -1.13, -1.15, -0.27], ['367', 5.21, 0.56, 0.07122171562045874, 0.03, 0.99, 1.25, 0.6, 2.16, 1.69, 2.39, 0.7303184712113286, 1.82, 1.26, 0.13, -0.9, 1.28, 0.86, 1.85, 2.46, 1.87, 3.04, 1.21, 0.95, 1.33, 2.49, 2.27, 1.87, 1.3, 0.74, -0.39, -1.4, 0.76, 0.34, 1.32, 1.94, 1.35, 2.51, 0.69, 0.44, 0.81, 2.21, 1.95, 0.56, -0.56, -1.66, -2.67, -0.54, -0.95, 0.02, 0.63, 0.05, 1.19, -0.6, -0.85, -0.49, 1.9800628463056764, 1.93, 1.16, 2.03, 1.12, -1.11, -2.12, 0.02, -0.39, 0.58, 1.19, 0.61, 1.76, 0.09295748299319728, -0.3, 0.07, 1.13, 2.26, -1.02, 1.15, 0.73, 1.71, 2.33, 1.74, 2.91, 1.08, 0.82, 1.2, 1.7, 4.0, -3.96, 3.32, 2.19, 1.77, 2.77, 3.39, 2.79, 3.97, 2.13, 1.87, 2.24, 3.57, 1.11, -0.41, 0.56, 1.17, 0.59, 1.74, -0.06, -0.32, 0.05, 0.6, 1.18, 2.48, 1.14, 1.22, 1.24, 1.52, 0.98, 1.59, 1.01, 2.16, 0.35, 0.09, 0.46, 1.17, 0.54, 0.61, 0.03, 1.17, -0.62, -0.88, -0.51, 1.35, 1.13, 0.23, 1.76, 10.77, 0.6, 0.9428571428571428, -1.79, 1.71, 0.87, 0.52, 1.41, -1.05, -2.33, -1.17, 2.58, 0.49, 3.69, -3.58, -3.37, 1.14, -2.66, 2.3, 0.25, -0.1, 4.48, -8.49, -3.0, -4.53, 0.97, -0.07, -0.58, 0.56, -1.22, -1.47, -1.11, 3.46, 0.51, 1.14, -0.65, -0.9, -0.54, -0.62, -1.77, -2.02, -1.66, 1.76, 1.88, 1.17, -0.26, 0.11, 1.12, 1.29, 2.04, -4.9, 2.44, 5.0, 2.73, 2.23, 1.43, 0.37, 1.97, 0.99, 0.26529795204795226, 0.29, 0.49, 1.05, 4.74, 3.3, 1.05], ['368', -0.08, 0.42, -0.07984710169072946, -0.01, -0.29, 0.08, 0.5, 0.71, 0.37, 0.43, 0.52, -0.06, 0.11, -0.03, -0.61, 0.87, 0.6, 0.31, 1.55, 1.55, 0.39, 0.36, 0.06, 0.41, 0.8, 0.23937141458889197, -0.09, -0.58, -0.42, -0.55, -1.0721800287049086, 0.34, 0.07, -0.21, 1.03, 1.02, -0.13, -0.17, -0.46, -0.11, 2.24, 0.4808975626058773, 0.5, 0.17, 0.03, -0.55, 0.93, 0.66, 0.37, 1.62, 1.61, 0.45, 0.42, 0.12, 0.47, 0.9900628463056765, 0.22, 0.87, 0.52, 0.33, -0.14, -0.72, 0.76, 0.49, 0.21, 1.4671802721088434, 1.44, 0.28, 0.25, -0.05, 0.31, 0.75, 0.47, -0.58, 0.9, 0.63, 0.34, 1.59, 1.58, 0.42, 0.39, 0.09, 0.45, -0.1, 1.0, -1.03, 1.05, 1.49, 1.22, 0.93, 2.18, 2.17, 1.01, 0.98, 0.67, 1.03, -0.81, -0.43, -0.27, -0.55, 0.68, 0.68, -0.47, -0.5, -0.8, -0.45, 0.19, -0.42, 1.31, 0.1, 0.19517906963433995, 0.10567351865003197, -0.16, -0.28, 0.95, 0.95, -0.21, -0.24, -0.54, -0.12141531611693432, 0.17, 0.17307674813036728, 1.24, 1.23, 0.08, 0.05, -0.25, 0.1, 0.51, 0.57, -0.1, 0.0, -2.58, -0.08, -0.14, 0.03, -0.04, 0.0, 0.98, -0.09383646788795053, 1.92, -0.18, -0.12, -0.07, -0.04, 0.28, -0.39, -0.25, 0.11, 0.02, 0.19, 1.06, -0.55, -0.56, 0.83, 0.36, 0.57, -1.94, -1.1, -0.01, -1.15, -1.18, -1.48, -1.12, 0.28, -1.09, -1.14, -1.17, -1.47, -1.12, 0.05, -0.03, -0.33, 0.02, 0.36, 0.22, 0.08, -0.3, 0.06, 0.11, 0.04, 0.77, -0.19, 0.5, -0.19, 0.6872638105244333, -0.13, 0.38, 0.36, -0.25, -0.21978021978021978, 0.16, -0.14, 0.694626243824729, 0.02, -0.6697593656343656, -0.51, -0.18], ['369', 2.85, 0.3, -0.29, 0.26, 0.35, -0.49, -0.35, 0.62, -0.62, -0.56, 0.46, 0.1, -0.34, -1.16, -1.75, -2.319285714285714, -1.17, -0.5594285714285715, -0.35, -0.4, -0.56, -1.3738418367346938, -0.17, -0.22, -0.18, 0.67, -1.02, -0.36, -0.79, -1.61, -2.19, -2.76, -1.62, -1.02, -0.8, -0.85, -1.02, -1.84, -0.62, -0.68, 1.06, -0.68, -0.66, -0.43, -1.26, -1.84, -2.3989563492063493, -1.27, -0.66, -0.44, -0.5, -0.66, -1.49, -0.26, -0.32, 0.68, 0.9157142857142857, 0.0, -0.94, -0.23, -0.82, -1.41, -1.9857142857142858, -0.84, -0.23, -0.01, -0.06, -0.23, -1.06, 0.17273474541331685, 0.11, 0.47, 0.6, -0.59, -1.18, -0.01, 0.6, 0.82, 0.77, 0.6, -0.24, 1.0, 0.95, -0.97, 1.01, -1.1, 1.2, -0.58, 0.59, 1.2, 1.42, 1.37, 1.2, 0.44571428571428573, 1.61, 1.55, 1.82, 1.8, 1.18, 1.8, 2.02, 1.97, 1.8, 0.95, 2.2, 2.15, -0.11, 1.83, 1.44, 0.12, 0.23, 0.21, 0.61, 0.61, 0.83, 0.78, 0.61, -0.23, 1.02, 0.96, 0.69, 0.0, 0.22, 0.17, 0.0, -0.83, 0.5985714285714285, 0.34, 0.11, 0.73, 0.5, 0.54, 5.34, -0.2496768707482993, -0.22, -1.18, 1.2, 0.28, 0.39, -0.56, 0.35, -0.28857142857142853, 0.3082806122448981, 1.48, -0.24, 0.56, -0.3771428571428571, -0.3042857142857143, -0.49, -1.69, 0.21, -2.56, 1.31, 1.81, -0.8172908163265306, -1.18, -1.84, -0.51, -0.22, -0.05, -0.22, -1.05, 0.18, 0.12, 0.46, -0.17, -0.17, -1.0, 0.23, 0.18, 0.0, -0.83, 0.4, 0.34142857142857147, -0.63, -0.96, 0.84, 1.24, 1.19, 0.07, 0.32, 0.62, -0.41, 0.97, 0.33, -0.22, 0.05, -0.4, -0.06, -0.38, -0.28, -1.07, -1.48, -0.71, -0.34, 1.11, 1.38, 0.23], ['370', -1.62, 1.26, 0.25, -0.18, 1.01, 1.12, 0.9641152579598291, 2.12, 2.23, 1.35, -1.74, 0.35, -1.3, -2.26, -0.21, 1.6711360544217686, -0.8, 0.47020578231292515, 6.41, 0.01, 2.39, 0.51, -0.67, 0.0, 2.12, 2.33, 3.14, 2.13, 0.45, -0.53, 1.56, 3.44, 0.96, 2.22, 8.29, 1.78, 4.2, 2.29, 1.09, 1.8138417231978392, 1.46, 4.274936199216174, 0.990204081632653, -1.65, -2.6, -0.56, 1.28, -1.14, 0.08, 6.03, -0.34, 2.03, 0.15, -1.02, -0.35, 1.6900628463056764, 1.94, 1.7, 2.51, 2.69, -0.97, 1.11, 2.97, 0.51, 1.76, 7.81, 1.33, 3.74, 1.83, 0.64, 1.32, 2.23, 3.6914285714285713, 2.1, 3.98, 1.5, 2.76, 8.87, 2.32, 4.76, 2.8314285714285714, 1.62, 2.31, 3.18, 5.47, -5.48, 1.56, 1.85, -0.59, 0.65, 6.63, 0.4137447711019141, 2.61, 0.72, -0.46, 0.21, -0.21, -0.28, -2.39, -1.18, 4.7, -1.6, 0.74, -1.11, -2.27, -1.61, 0.74, -0.28, 1.81, 0.79, 1.23, 1.31, 2.16, 1.24, 7.26, 0.81, 3.21, 1.31, 0.12, 0.8, 0.17653607107178546, 0.91, 5.94, -0.43, 1.94, 0.07, -1.1, -0.44, 2.18, 1.98, -0.08, 1.4, -0.44, 0.31, 0.21, -2.71, 2.75, 1.38, -2.37, 1.47, -2.68, -2.5, -1.27, -0.82, 0.58, 3.97, -3.9, -3.83, 1.26, -4.15, 2.57, 2.73, -1.38, 6.42, -3.73, -4.25, -6.46, 2.6171309523809523, -4.75, -6.01, -3.77, -5.55, -6.65, -6.02, 3.81, 1.34, 2.38, 0.5, -0.68, -0.01, -1.02, -1.84, -2.99, -2.34, 2.13, 2.84, 0.84, -1.17, -0.5, 1.31, 1.36, 2.03, -2.35, 1.89, 2.18, 2.16, 1.62, 2.03, 0.68, 1.74, 1.12, 0.12, 0.51, 1.15, 1.35, 3.4, 2.51, 1.62], ['371', -0.38, 0.0, 0.09122171562045875, 0.05, -0.89, -0.11, -0.4558847420401708, 0.07, -0.19, -0.23, -0.09939115646258503, -0.18, -0.52, -0.85, 0.28, -0.4, 0.13, -0.08, 4.49, 1.19, -0.09, -0.13, 0.14, 0.08, -0.47, -0.11, -0.12, -0.07, 0.007674603174603278, -0.73, 0.39, -0.2897142857142857, 0.24, 0.04, 4.61, 1.3, 0.03, -0.01, 0.25, 0.19, -1.04, -0.25506380078382657, -0.05, -0.25880253250388296, -0.67, 0.46, -0.22, 0.31, 0.1, 4.68, 1.37, 0.09, 0.05, 0.32, 0.26, -0.17, -0.38, 0.48, 0.29, 0.29, -0.33, 0.8, 0.11, 0.65, 0.44, 5.04, 1.8339757335335067, 0.44, 0.39, 0.66, 0.6, 0.55, 0.62, 1.13, 0.45, 0.98, 0.77, 5.39, 2.05, 0.77, 0.73, 0.99, 0.93, -0.18, -0.91, 0.95, -0.51, -0.68, -0.15, -0.35, 4.21, 0.9, -0.36, -0.4, -0.14, -0.2, 0.38, 0.17, 0.54, 0.33, 4.92, 1.6, 0.32, 0.28, 0.54, 0.49, -0.23, 0.12, -1.38, -0.07840181931709851, -0.14, -0.09, -0.36, -0.21, 4.36, 1.05, -0.21, -0.26, 0.01, -0.05, -0.08, -0.16, 4.58, 1.26, -0.01, -0.05, 0.21, 0.16, -0.45, -0.48, 0.27, -0.14, 1.27, -0.09, -0.15, 0.37, -0.23827987418743707, -0.18, 0.14, -0.68, 2.71, 0.27, 0.11, -0.2, 0.16307978986877908, -0.35, 0.37, 0.33, -0.07670919513614705, 0.49, -0.24, -1.14, 0.56, -1.07, -1.12, 0.71, 1.04, -2.344384920634921, -4.52, -3.17, -4.38, -4.42, -4.17, -4.22, -0.34, -1.4, -1.26, -1.3, -1.04, -1.09, -0.15, -0.04, 0.22, 0.17, -0.15, -0.02, -0.11, 0.26, 0.21, -0.11, -0.11, 0.14, -0.52, -1.16, 0.58, -0.17, -0.29, -0.37, -0.05, 0.14, -0.07, -0.2, 0.05, 0.25, -0.31, -0.38, -0.8584047619047619, -0.79], ['372', 9.71, 0.0, 0.04, -0.03, 1.29, 0.58, 0.75, 1.18, 0.87, 0.4453571428571429, -0.6, -0.5606751700680271, -1.19, -0.1, -1.64, -2.05, -0.75, 0.11, -0.5, -1.55, 0.64, 0.31, -0.83, -0.75, 0.95, 1.32, 0.98, 0.03, -0.6, 0.5, -1.05, -1.45, -0.15, 0.71, 0.1, -0.96, 1.25, 0.91, -0.23, -0.15, 1.5, 0.55, 0.96, -0.5388025325038829, 0.47, -1.08, -1.48, -0.17, 0.69, 0.08, -0.98, 1.22, 0.89, -0.26, -0.18, 0.77, 1.91, 0.88, 1.36, 1.59, 1.11, -0.45920068027210886, -0.86, 0.45, 1.32, 0.7, -0.23602426646649322, 1.86, 1.52, 0.37, 0.45, 1.69, 0.48, -1.54, -1.95, -0.65, 0.21, -0.4, -1.45, 0.75, 0.41, -0.73, -0.65, 0.59, 2.89, -2.93, 2.0966982383853203, -0.41, 0.91, 1.79, 1.17, 0.09, 2.33, 1.99, 0.83, 0.91, 3.24, 2.47, 1.33, 2.3053350340136056, 1.58, 0.5, 2.75, 2.4, 1.24, 1.32, 0.28, 2.44, 2.53, 0.82, 0.82, 0.87, 1.13, 0.86, 0.25, -0.81, 1.4, 1.06, -0.08, -0.01, 0.26, 0.27, -0.61, -1.66, 0.53, 0.2, -0.94, -0.86, 0.68, 0.68, 0.02, 0.99, 9.72, 0.05, -0.03, -1.51, 1.47, 0.72, 0.25406627346681526, 0.8, -3.8094817511227284, -1.65, -0.89, 4.77, 0.34, 2.45, -2.61, -2.51, 0.82, -2.25, 1.67, 0.97, -0.51, 3.42, -2.17, -2.33, -3.37, 4.04, 0.88, -1.06, 1.15, 0.81, -0.33, -0.26, 2.51, 1.9601587301587302, 2.23, 1.89, 0.74, 0.81, -0.27, -0.33, -1.46, -1.39, 0.89, 0.89, 0.07, -1.13, -0.9877512446849838, 0.84, 0.86, 1.13, -1.16, 1.72, 1.28, 1.78, 1.18, 1.21, 0.08, 0.95, 0.7, 0.42, 0.24, 0.68, 1.14, 2.55, 1.88, 2.1], ['373', 1.5, -0.25, -0.31877828437954125, -0.01, 0.83, 0.54, 0.07411525795982916, 0.72, 0.07, -1.34, -1.24, -1.5, -1.66, -2.46, -2.96, -1.28, -2.6, -1.06, 0.11, -3.08, -1.75, -2.69, -2.13, -1.73, 0.48, -0.36, -0.1, -0.26, -0.42, -1.23, -1.73, -0.04, -1.37, 0.19, 1.37, -1.86, -0.51, -1.47, -0.9, -0.49, 1.1574684253532108, 0.0, 0.16, -0.16, -0.97, -1.48, 0.22, -1.12, 0.45, 1.64, -1.6, -0.25, -1.21, -0.64, -0.23, 0.52, 0.25, 0.78, 0.73, 0.32, -0.82, -1.32, 0.38, -0.96, 0.7126050661400617, 1.8, -1.45, -0.09, -1.05, -0.48, -0.07, 0.33, 1.15, -0.51, 1.21, -0.15, 1.44, 2.64, -0.64, 0.73, -0.24, 0.34, 0.75, -0.48, 2.53, -2.6, 1.69669823838532, 1.72, 0.36, 1.96, 3.16, -0.13, 1.25, 0.27, 0.85, 1.27, 0.0, 0.017366531216562897, -1.33, 0.23, 1.41, -1.82, -0.47, -1.43, -0.86, -0.45, -0.39, -0.06, 0.72, 0.68, 0.6, 0.86, 1.29, 1.59, 2.79, -0.49, 0.88, -0.09, 0.48, 0.9, 1.3, -0.29, 1.18, -2.05, -0.7, -1.65, -1.09, -0.68, 0.89, 1.34, -0.13, 1.21, 0.03, 0.13225133596562166, -0.62, -2.19, 2.23, 1.1, 1.01, 0.69, -3.55, -1.35, -0.67, 0.72, 0.04, 2.04, -2.13, -1.93, 0.69, -3.25, 1.39, 0.45, -0.31, 3.88, -1.96, -2.51, -3.83, 3.55, -1.45, -3.19, -1.86, -2.8, -2.24, -1.84, 2.01, 1.8, 1.38, 0.4, 0.98, 1.4, 0.41, -0.96, -0.39, 0.02, 0.0927953514739229, 0.14, 1.39, 0.57, 0.99, 0.63, 0.69, 0.69, -0.96, 1.0101996269574993, 1.1, 0.31, 0.4611825396825397, 0.81, 0.42, 0.68, 1.23, 0.38, 0.01, 0.3846262438247291, 0.39, 1.37, 1.14, 0.56], ['374', 0.79, -0.99, 0.12, -0.11, -0.81, 0.33841962367375944, 1.39, 0.44, 0.1, 0.65, 0.01, -0.26, 0.29, -1.74, 0.06, 0.5, 0.52, 0.64, 2.135862135879993, 1.66, 0.23733548208735894, 0.98, -0.08, 0.62, 0.37, 0.14, 0.6726583949931124, -0.27, 0.28, -1.75, 0.05, 0.5, 0.51, 0.63, 1.96, 1.65, 0.19, 0.97, -0.08, 0.61, 0.3, -0.06506380078382656, 0.91, 0.55, -1.48, 0.32, 0.77, 0.78, 0.91, 2.23, 1.93, 0.46, 1.24, 0.19, 0.88, 0.07, 0.44, -0.07, -0.61, 0.43924524706587753, -2.02, -0.22, 0.22, 0.23, 0.36, 1.67, 1.37, -0.08, 0.69, -0.36, 0.33, -0.82, 2.43, 1.83, 2.29, 2.3, 2.43, 3.77, 3.46, 1.98, 2.77, 1.7, 2.4, 0.0, 1.6, -1.61, 0.59, 0.44, 0.46, 0.58, 1.9, 1.6, 0.14, 0.92, -0.14, 0.56, 2.84, 0.14, 0.01, 0.14, 1.45, 1.15, -0.3, 0.47, -0.58, 0.12, -0.02, 0.16, 0.38, 0.15, 0.33, -0.03, 0.13, 0.12, 1.44, 1.14, -0.32, 0.46, -0.59, 0.1, -0.45, 0.01, 1.31, 1.01, -0.44, 0.34, -0.71, -0.02, 0.34, 0.17, -0.26, 0.13, 8.22, 0.0, -0.07, 0.46, -0.4, -0.21, -0.66, 0.54, 1.92, -0.26, -0.13, 0.4, -0.32, 0.38, -0.39, -0.41, 0.13, 0.62, 0.29, 1.63, -0.81, 0.44, 0.93, -0.24, -0.4, -1.85, -1.29, -0.3, -1.73, -0.97, -2.0, -1.32, 0.35, -0.99, -1.43, -0.67, -1.71, -1.02, 0.45, 0.78, -0.28, 0.42, 0.11, -0.34, -0.33, -1.04, -0.36, 0.16, 0.22439630127529087, 0.5, 0.27, 0.24, -0.23, 0.88, -0.08, 0.72, 0.7, 0.12, -0.15, -0.17, -0.31, 0.25, 0.03, 2.9, 0.43, -0.35], ['375', -2.67, -0.06, 0.21, 0.15, 0.19, 0.51, 0.32, 1.23, 0.68, 1.51, 0.82, 1.21, 0.68, 0.33, 0.4742210884353741, 2.29, 1.1271428571428572, 1.43, 2.24, 0.87, 1.48, -0.08, -0.55, 1.3, 1.1685936610075265, 1.47, 0.68, 0.39, -0.14, -0.49, -0.78, 1.45, 0.26, 0.6, 1.41, 0.05, 0.65, -0.9, -1.36, 0.47, 0.92, 1.09, 0.29020408163265304, -0.53, -0.87, -1.16, 1.06, -0.13, 0.21, 1.02, -0.34, 0.26, -1.28, -1.75, 0.08, 1.6023573314652815, 0.82, 0.78, 0.88, 0.82, -0.35, -0.64, 1.6, 0.4, 0.74, 1.55, 0.19, 0.79, -0.76, -1.219795918367347, 0.61, 0.9, 1.17, -0.29, 1.95, 0.75, 1.1, 1.91, 0.54, 1.14, -0.41, -0.88, 0.97, 1.13, 5.05, -5.2, 1.47, 2.25, 1.04, 1.39, 2.2, 0.83, 1.44, -0.12, -0.59, 1.26, -1.06, -0.76, -1.18, -0.84, -0.05, -1.38, -0.79, -2.32, -2.78, -0.97, 0.36, -0.76, -0.08, 0.19, 0.4, 0.19, 0.42, 0.34, 1.14, -0.21, 0.39, -1.16, -1.62, 0.21, 0.46, 0.08, 0.8, -0.55, 0.05, -1.49, -1.917142857142857, -0.13, 3.04, 3.07, 0.39, 1.07, -3.29, 1.468069549498121, 0.9628571428571429, -1.49, 1.45, 0.73, -2.11, 0.0, -1.31, -1.67, -0.81, -1.33, 0.11, 2.61, -2.58, -2.49, 0.81, -2.19, 1.61, -0.74, 0.37, 2.77, -2.34, -1.79, -2.84, 1.2, -0.72, -1.34, -0.75, -2.27, -2.73, -0.92, 2.4, 0.63, 0.6, -0.95, -1.41, 0.42, 0.03, -1.54, -2.0, -0.18, 0.61, 0.89, 1.59, -0.47, 1.38, 0.75, 0.85, 0.97, -1.01, 0.65, 0.59, 0.95, 1.18, 2.07, 1.86, 0.96, 0.96, -0.34, 0.17, 0.47, 0.21, 2.2, 1.16, -0.23], ['376', 2.87, 0.0, -0.08, -0.03, 0.64, 0.53, 1.144115257959829, 1.34, 1.45, 1.62, -0.26, 0.36, 0.73, 0.75, 0.36, 1.69, 0.71, 1.31, 1.71, 2.02, 2.29, -0.1, 0.95, 0.63, 1.28, 0.76, 1.89, 0.63, 0.99, 1.02, 0.63, 1.96, 0.98, 1.58, 1.98, 2.29, 2.644453670078569, 0.17, 1.21, 0.9, 0.53, 2.0800621118012423, 1.25, 0.36, 0.39, -0.01, 1.32, 0.35, 0.94, 1.34, 1.64, 1.9480654680864429, -0.46, 0.58, 0.27, 0.8, 1.01, 1.4, 1.38, 0.89, 0.03, -0.25515323205954743, 0.96, -0.01, 0.58, 0.98, 1.28, 1.56, -0.82, 0.22, -0.09, 0.86, 0.86, -0.39, 0.93, -0.04, 0.55, 0.95, 1.25, 1.53, -0.85, 0.19, -0.12, 1.94, 2.1, -2.07, 1.26, 1.33, 0.35, 0.95, 1.35, 1.65, 1.93, -0.46, 0.58, 0.27, 0.15, -0.07, -0.96, -0.37, 0.02, 0.32, 0.59, -1.76, -0.73, -1.04, 0.12, -0.01, 0.16, 0.56, 0.62, 0.51, 0.91, 0.59, 1.0, 1.29, 1.57, -0.8, 0.23, -0.08, 1.82, 0.31, 0.4, 0.7, 0.97, -1.39, -0.36, -0.67, 0.77, 0.86, 0.15603717887804044, 0.88, 0.3, 0.03, 0.0, -0.64, 0.61, 0.3, 0.13, 3.1102597402597403, 0.72, -1.13, -0.57, 1.4, 0.53, 1.77, -1.73, -1.7, 0.55, -1.0, 1.07, 0.3, -0.14, 2.77, -5.3, -1.82, -2.79, -0.88, -0.09, 0.3, 0.57, -1.78, -0.76, -1.06, 1.69, -0.38, 0.27, -2.07, -1.05, -1.36, -0.66, -2.34, -1.32, -1.62, 1.37, 1.49, 1.72, 1.05, 0.73, 0.58, 0.63, 1.42, -2.56, 0.51, 2.58, 1.11, 0.9, 0.67, -0.31, 0.55, 0.22, 0.3, 0.67, 0.66, 0.98, 1.03, 0.96, 0.89], ['377', 2.53, 0.69, -0.08, -0.13, 1.95, 0.99, 0.024115257959829165, 1.62, 0.91, 1.46, 0.39, 1.94, -0.39, -0.28, 0.87, 0.55, 0.11, 1.22, -2.58, -1.56, 1.93, -0.42, 0.89, 0.41, 1.62, 2.04, 1.07, 1.54, -0.7598809523809524, -0.67, 0.48, 0.16, -0.27, 0.83, -2.96, -1.94, 1.53, -0.8, 0.5, 0.02, 1.01, 2.6849361992161733, -0.47, -2.28, -2.18, -1.05, -1.36, -1.79, -0.71, -4.428347866419295, -3.44, -0.01, -2.31, -1.03, -1.5, 1.13, 1.54, 0.63, 1.3, 1.86, 0.11, 1.27, 0.94, 0.5, 1.7126050661400618, -2.2, -1.18, 2.33, -0.03, 1.282734745413317, 0.8, 2.43, 1.75, 1.16, 0.83, 0.39, 1.5, -2.31, -1.29, 2.21, -0.14, 1.17, 0.69, 1.12, 1.83, -1.94, 0.58, -0.32, -0.75, 0.34, -3.42, -2.42, 1.2152352330209475, -1.28, 0.01, -0.46, 2.49, 0.91, -0.44, 0.67, -3.11, -2.1, 1.37, -0.96, 0.33, -0.14, 0.48, 0.92, 0.41, 1.22, 1.02, 1.44, 1.35, 1.11, -2.69, -1.67, 1.81, -0.53, 0.77, 0.29, 1.87, 0.24, -3.75, -2.75, 0.7, -1.62, -0.33, -0.8, 0.11, 0.28, -0.26, 1.43, 5.21, -0.03, -0.37, -2.68, 2.7, 1.37, 0.57, 3.79, -5.6794817511227285, -2.43, -1.27, 1.23, 0.41, 3.64, -3.68, -3.61, 1.2, -4.14, 2.4, 2.43, -1.19, 3.99, -8.62, -2.77, -3.97, 5.883809523809524, 4.15, 1.04, 4.63, 2.532096371882086, 3.56, 3.06, 3.57, 3.07, 3.55, 1.17, 2.49, 2.0, -0.46, -2.3, -1.02, -1.49, 0.89, 1.39, 1.88, 1.31, 0.82, 1.2, 1.28, 1.52, -4.24, 1.56, 4.35, 1.96, 2.95, 0.57, -0.48, 1.46, 1.53, 0.39, 0.83, 0.49, 1.05, 2.15, 4.5130376647162365, 1.06], ['378', 1.35, -0.12, 0.09122171562045875, -0.05, 0.1, 0.65, 0.19, 1.26, 1.27, 1.42, -0.81, 0.81, 0.63, 0.02, 0.26, 0.94, 1.01, 0.84, -4.22, 0.85, 2.16, 1.12, 0.64, 1.18, 1.66, 0.46, 2.2826583949931125, 1.63, 1.45, 0.84, 1.08, 1.77, 1.83, 1.66, -3.439285714285714, 1.68, 3.0644536700785694, 1.94, 1.46, 2.0, 0.95, 2.45, 0.61, -0.17, -0.78, -0.54, 0.14, 0.2, 0.03, -4.99, 0.05, 1.34, 0.31, -0.16, 0.37, 0.87, 1.21, 1.32, 0.75, 0.78, -0.61, -0.37, 0.31, 0.37, 0.21, -4.82, 0.22, 1.52, 0.48, 0.01, 0.54, 1.23, 1.4, 0.24, 0.92, 0.99, 0.82, -4.24, 0.83, 2.14, 1.09, 0.62, 1.16, 2.01, 2.12, -2.09, 1.15, 0.68, 0.74, 0.57, -4.47, 0.7837447711019141, 1.89, 0.85, 0.37, 0.91, 0.68, 0.47, 0.06, -0.1, -5.12, -0.09, 1.2, 0.17, -0.3, 0.23, 0.58, 0.48, 0.8, 0.44, 0.54, 0.33, 0.41, -0.17, -5.18, -0.15, 1.14, 0.11, -0.36, 0.17, 0.3, 0.57, -5.02, 0.01, 1.31, 0.27, -0.2, 0.5821774376417235, 0.51, 0.31, 0.08, 0.21, 1.91, 0.05, -0.2, -0.36, 0.3, 0.15, 0.39, 1.37, -1.1, -0.9, -0.48, 0.66, 0.09, 1.38, -1.41, -1.31, 0.44, -0.59, 0.9, 0.9183906549799409, -0.42, 1.16, -4.77, -0.84, -1.21, 1.19, 5.89, 5.3, 6.66, 5.57, 5.08, 5.64, 1.34, 0.56, 1.29, 0.26, -0.21, 0.32, -0.72, -1.02, -1.48, -0.96, 1.24, 1.53, 0.3, -0.47, 0.06, 0.47, 0.41, 1.18, -0.75, 0.66, 0.63, 0.52, 1.09, 0.848637448200971, 0.53, 0.72, 0.55, 0.0, -0.09, 0.2, 0.24, 1.34, 1.81, -0.02], ['379', 5.8, 0.52, 0.04015289830927054, -0.2, 1.86, 1.2, 0.5741152579598292, 1.0, 0.99, 0.73, -0.35, 0.51, 0.4, -0.6, 0.22, -1.11, -0.1, 0.6454705215419502, 0.21, -2.68, 0.93, 0.6370289115646258, -0.42, 0.13, 1.4, 0.71, 1.09, 0.87, 0.76, -0.25, 0.57, -0.76, 0.26, 0.89, 0.56, -2.34, 1.29, 0.7, -0.06, 0.49, 1.37, 1.7249361992161734, 0.22, -0.028802532503882913, -1.11, -0.29, -1.61, -0.61, 0.02, -0.3, -3.18, 0.41, -0.17, -0.93, -0.38, 0.07, 0.38, 1.25, 1.09, 0.33, -1.0, -0.18, -1.5, -0.49, 0.13, -0.19, -3.07, 0.683421154242583, -0.06, -0.82, -0.25056122448979595, 1.5, 1.34, 0.82, -0.51, 0.51, 1.14, 0.81, -2.1, 1.53, 0.94, 0.18, 0.74, 1.21, 3.09, -3.11, 0.52, -1.32, -0.31, 0.32, -0.01, -2.89, 0.71, 0.12, -0.64, -0.08, 1.82, 1.86, 1.02, 1.66, 1.3315238095238096, -1.59, 2.06, 1.46, 0.7, 1.26, 0.21, 1.83, 0.33, 0.95, 1.08, 0.77, 0.83, 0.63, 0.3, -2.59, 1.02, 0.43, -0.32, 0.23, 0.17, 0.2, -0.32, -3.2, 0.39, -0.2, -0.95, -0.4, 1.27, 1.54, -0.25, 1.01, 5.27, 0.1, 0.07, -0.93, 0.94, 0.47, -1.71, 1.17, -6.98, -1.91, -1.0, 2.91, 0.75, 2.84, -2.81, -2.84, 0.95, -1.49, 1.89, 0.89, -0.46, 2.5, -7.059348639455782, -1.73, -2.57, 6.9, 0.53, -2.88, 0.72, 0.13, -0.63, -0.07, 2.82, 3.51, 3.71, 3.3471428571428574, 2.33, 2.89, -0.19, -0.58, -1.33, -0.78, 0.96, 1.07, 0.4, -0.75, -0.2, 0.95, 0.92, 0.89, -4.08, 0.43, 3.86, 1.24, 1.82, 1.16, 0.56, 1.47, 0.8645528598385742, 0.74, 0.39, 0.47, 0.6, 1.78, 1.61, 1.36], ['380', -28.17857142857143, -0.37, 0.15122171562045875, -0.15, -1.35, 0.61, 0.6441152579598292, 2.23, 1.11, 1.81, 1.06, 1.05, -0.55, 0.02, -0.18, 7.230714285714286, 0.92, 1.52, 2.2, 1.45, 1.99, 2.1270289115646257, 0.45, -0.12, 1.45, -0.62, 0.74, -0.01, -1.5798809523809525, -1.03, -1.23, 6.1, -0.14, 0.45, 1.137761904761905, 0.39, 0.92, 0.76, -0.61, -1.17, 2.88, 1.44, 0.75, -1.5763410188391391, -1.02, -1.21, 6.354266594516595, 0.17865136054421765, 0.47, 1.13, 0.4, 0.93, 0.77, -0.59, -1.16, 0.99, 3.16, 2.29, 0.75, 2.37, 0.57, 0.37, 7.82, 1.48, 2.08, 2.76, 2.01, 2.56, 2.39, 1.0, 0.43, 1.97, 1.8, -0.19, 7.21, 0.91, 1.51, 2.18, 1.44, 1.98, 1.81, 0.43, -0.07644035827487929, 1.11, 3.61, -3.52, 1.99, 7.42, 1.1, 1.7, 2.38, 1.63, 2.17, 2.01, 0.6385238095238095, 0.06, -5.8, -5.05, -5.88, -5.32, -4.69, -5.39, -4.88, -4.797183003504432, -6.32, -6.85, 0.65, -5.07, 1.93572371188304, 0.93, 0.5, 0.47, 0.88, 0.59, 1.26, 0.53, 1.06, 0.9, -0.47, -1.03, -0.04, 0.29, 0.9136855802927233, -0.07, 0.47, 0.3, -1.06, -1.62, 1.64, 0.84, -0.36, 1.25, -11.682380952380951, 0.28, 0.15, -2.61, 2.64, 1.33, 0.23, 0.77, -0.38224102088387807, -1.75, -0.91, -14.094778911564626, 0.69, 2.87, -2.7, -2.64, 0.93, -3.95, 1.85, 2.77, -1.33, 3.69, 0.65, -2.3885714285714283, -3.7542857142857144, 0.66, -0.38, -0.73, -0.2, -0.3543095238095238, -1.71, -2.26, 2.61, 0.35, 0.53, 0.37, -0.99, -1.55, -0.18, -0.16, -1.51, -2.07, 1.19, 0.94, -0.02, -1.35, -1.91, 0.37, 0.43, 2.0, 0.2, 2.34, -0.32, 0.53, 0.08, 1.35, -0.57, 1.24, 1.18, 0.2, 1.25, 0.35, 1.93, 0.45, -0.46, 1.89], ['381', -1.09, -0.17, -0.3, -0.01, -0.29, -0.07, -3.4, -1.2, -1.06, -0.55, 0.21, 1.63, 0.99, 0.16, 1.38, -0.23, -0.43, -0.26, -0.038518140589569164, -0.28, -0.51, 0.03, -0.38, -0.11, -3.7, -0.36, -0.76, 1.42, 0.78, -0.05, 1.17, -0.44, -0.64, -0.47, -0.26, -0.49, -0.72, -0.18, -0.59, -0.32, -0.83, -0.9, -2.15, -0.63, -1.2821246055531768, -0.25, -1.83, -2.03, -1.86, -1.66, -1.89, -2.11, -1.58, -1.98, -1.72, -0.91, -0.99, -0.87, -0.52, -1.53, -0.82, 0.39, -1.2, -1.41, -1.24, -1.03, -1.26, -1.48, -0.95, -1.35, -1.09, -0.66, -0.71, 1.22, -0.39, -0.59, -0.42, -0.21, -0.45, -0.67, -0.13, -0.54, -0.2264403582748793, -0.59, -0.49, 0.45, -1.8733017616146799, -1.59, -1.79, -1.62, -1.41, -1.64, -1.87, -1.34, -1.73, -1.48, -1.19, -0.33, -0.2, -0.03, 0.18, -0.06, -0.28, 0.26, -0.15, 0.11, -0.18, -0.26, -0.6, -0.23, -0.26, -0.19, -0.12, 0.17, 0.38, 0.15, -0.08, 0.46, 0.05, 0.32, -0.66, -0.29, 0.21, -0.03, -0.25, 0.29, -0.12, 0.14, 0.09, 0.22276190476190477, 0.02, -0.49, -3.2922619047619044, 0.21, 0.27, 0.4, -0.43, -0.2, -0.97, -1.22, 0.58, 0.43, 0.21, -0.55, -0.34, -0.72, 0.78, 0.69, -0.22, 0.6, -0.49, -0.64, 0.34, -0.34, 0.3, 0.12, 0.28, -0.48, -0.5, -0.23, -0.46, 0.08, -0.32, -0.06, -0.69, -0.27, -0.22, 0.31, -0.09, 0.17, -0.04, 0.54, 0.13, 0.4, -0.99, -0.33, -0.58, -0.4, -0.14, -0.22, -0.25, -1.25, 0.37, -0.57, -0.44, -0.32, -0.66, -0.18, 0.26, -0.293994794887652, -0.28, 0.8, -1.13, -0.27, -0.44, -0.73, -0.91, -0.93], ['382', -3.52, -0.57, 0.04, 0.12, -1.01, -0.46, -1.1, -1.68, -1.26, -1.7, -0.15, -0.9, -0.09, 1.31, -0.46, -0.56, -1.08, -1.2, 1.28, -0.33, -2.07, -1.3, -0.49, -1.1, -0.26140633899247345, -1.2, -1.5273416050068875, -0.75, 0.06, 1.46, -0.32, -0.42, -0.93, -1.06, 1.875702380952381, -0.18, -1.93, -1.15, -0.35, -0.95, -1.55, -2.2, -0.81, 0.82, 2.23, 0.44, 0.34, -0.18, -0.31, 2.2, 0.58, -1.18, -0.4, 0.41, -0.2, -0.9, -1.48, -1.4, -1.07, -1.62, 1.4, -0.38, -0.48, -0.99, -1.12, 1.37, -0.24, -1.99, -1.21, -0.4072652545866831, -1.01, -1.01, -2.97, -1.75, -1.85, -2.35, -2.48, -0.03, -1.62, -3.34, -2.57, -1.78, -2.38, -1.87, -3.17, 3.23, -1.25, -0.1, -0.61, -0.74, 1.75, 0.13, -1.62, -0.84, -0.03, -0.64, -2.15, -1.15, -0.52, -0.64, 1.85, 0.24, -1.52, -0.74, 0.07, -0.54, -0.66, -1.127643118785976, -0.35, -0.49, -0.56, -0.47, -0.63, -0.13, 2.38, 0.75, -1.01, -0.22, 0.59, -0.02, -0.47, -0.51, 2.51, 0.88, -0.88, -0.09, 0.72, 0.1, -1.23, -0.9, 0.14, -0.58, -6.67, -0.63, -0.47, 0.48, -0.49, -0.29, -0.26, -2.5838364678879504, 2.79, 0.99, 0.51, -1.73, -0.15, -1.57, 1.49, 1.48, -0.49, 0.75, -1.02, -2.2, 1.09, -1.96, 6.0, 1.31, 2.01, -2.7, -2.94, -1.59, -3.31, -2.54, -1.75, -2.35, -1.41, -1.38, -1.75, -0.97, -0.16, -0.77, 0.38, 0.79, 1.61, 0.99, -1.2, -1.54, -0.41, 0.81, 0.2, -0.47, -0.56, -1.6174239503761216, 3.78, -0.79, -3.76, -0.63, -1.22, -1.22, -0.61, -0.48, -0.28, -0.07, 0.17, 0.0, -0.61, -0.64, -1.8, -0.35], ['383', 2.97, 0.5, -0.30877828437954125, -0.3, 2.11, 0.81, 0.9141152579598292, 1.4, 0.78, 3.04, 2.13, 2.56, 2.02, 2.69, 1.84, 2.87, 1.36, 2.71, 5.01, 1.28, 3.19, 1.71, 1.43, 1.53, 1.79, 1.1, 0.9, 0.42, -0.11, 0.55, -0.28, 0.73, -0.75, 0.57, 2.82, -0.83, 1.04, -0.4, -0.68, -0.58, 0.7, 0.77, 0.47, -0.53, 0.13, -0.7, 0.3, -1.17, 0.15, 2.39, -1.25, 0.61, -0.82, -1.1, -1.0, 0.91, 1.35, 0.72, 0.56, 1.0, 0.66, -0.17, 0.84, -0.64, 0.68, 2.94, -0.72, 1.15, -0.3, -0.58, -0.47, 1.66, 0.34, -0.83, 0.17, -1.3, 0.02, 2.26, -1.38, 0.48, -0.95, -1.23, -1.13, 0.89, 4.4, -4.38, 1.21669823838532, 1.01, -0.47, 0.85, 3.11, -0.55, 1.32, -0.12, -0.4, -0.3, 1.18, 0.17, -1.47, -0.16, 2.08, -1.55, 0.31, -1.12, -1.4, -1.3, 0.2, 0.2, 2.18, 1.04, 1.01, 1.11, 1.66, 1.33, 3.6, -0.08, 1.8, 0.35, 0.14598786341555264, 0.17, 1.26, 0.32, 2.24, -1.39, 0.46, -0.8442004503433073, -1.25, -0.8978225623582765, 1.75, 1.63, 0.0, 1.07, 2.23, 0.2, 0.14, -2.66, 2.66, 1.35, 0.6, 2.33, -3.399481751122728, -2.2, -1.09, 1.54, 0.39, 3.25, -3.22, -3.24, 1.06, -4.07, 2.09, 0.62, -0.31, 4.99, -6.6, -3.33, -4.95, 3.44, -1.88, -3.56, -1.74, -3.14, -3.41, -3.31, 3.19, 1.74, 2.0241925889236816, 0.43, 0.15, 0.25, -0.14, -1.3411214088935783, -1.7, -1.6, 0.82, 1.0084535464535467, 1.3, -0.28, -0.18, 1.192080034314057, 1.09, 1.27, -3.24, 1.11, 3.22, 1.63, 1.3, 1.59, 0.17278685149693168, 1.13, 1.2845528598385743, 0.7, 0.15, -0.06, 1.49, 2.15, 2.05, 2.82], ['384', 0.86, -0.19, -0.14877828437954127, 0.14, -0.8570209190089404, -0.24, -0.88, -0.49, -1.09, -0.05, 1.27, 0.92, 0.32, 0.63, 0.47, 0.65, 0.68, 0.27, -2.87, 1.63, -0.37, 0.01, 0.43, 0.48, -0.25, -0.52, -1.3, -0.34, -0.93, -0.63, -0.7221800287049088, -0.6, -0.58, -0.98, -4.08, 0.36, -1.62, -1.24, -0.7311203865609548, -0.77, -0.11, -2.3, -0.96, -0.59, -0.29, -0.44, -0.26, -0.24, -0.64, -3.75, 0.71, -1.28, -0.9, -0.49, -0.43, -0.29993715369432344, -0.11571428571428577, -0.45, -0.92, -0.37, 0.3, 0.15, 0.33, 0.36, -0.05, -3.18, 1.4339757335335068, -0.69, -0.31, 0.11, 0.16, -0.1, -0.68, -0.15, 0.03, 0.05, -0.35, -3.47, 1.0, -0.99, -0.61, -0.2, -0.14, -1.48, -1.43, 1.37, -0.53, 0.18, 0.2117857142857143, -0.2, -3.33, 1.15, -0.84, -0.47, -0.05, 0.01, -0.23, -0.7, 0.03, -0.38, -3.5, 0.97, -1.02, -0.64, -0.22, -0.17, -0.36, -0.58, -3.01, -0.5, -0.42, -0.5, -0.73, -0.41, -3.53, 0.95, -1.05, -0.67, -0.25, -0.2, -0.14, -0.32, -3.13, 1.36, -0.64, -0.26, 0.16, 0.21, -0.64, -0.66, 0.21, -0.7, -0.55, -0.13, -0.2, 1.67, -1.7, -0.84, -0.42, -1.2638364678879506, 3.26, 1.03, 0.49, 0.44, 0.03, -1.48, 1.4, 1.43, -0.49, 2.56, -0.98, -2.1, 1.03, -2.15, 5.05, 1.42, 2.24, -3.34, 2.9, 4.63, 2.57, 2.96, 3.4, 3.45, -1.51, -1.66, -1.97, -1.6, -1.18, -1.13, 0.38448979591836735, 0.38, 0.81, 0.86, -1.11, -1.25, -0.06, 0.42, 0.47, -0.48, -0.53, -0.52, 1.95, -2.07, -2.08, -0.46, -1.03, -0.48, 0.05, -0.3, -0.68, 0.2, 0.3, -0.35, -0.53, 0.79, -1.87, -0.36], ['385', -1.8, 0.18, 0.4112217156204588, -0.23, 0.67, -0.33, -1.7558847420401709, -0.42, -0.8, 0.13, 1.44, 1.02, 0.22, 0.88, 1.96, 0.19, 0.52, 0.15, -0.49, -1.35, 0.19, 0.4, 0.28, 0.15, -0.28, 0.43, -1.3, -0.41, -1.2, -0.55, 0.51, -1.23, -0.91, -1.27, -1.8992857142857142, -2.75, -1.23, -1.02, -1.14, -1.27, -1.05, -1.5650638007838267, -0.89, -0.79, -0.14, 0.93, -0.82, -0.5, -0.86, -1.49, -2.34, -0.82, -0.61, -0.73, -0.86, -0.5, 0.46, 3.03, -0.57, -0.09, 0.66, 1.74, -0.03, 0.3, -0.07, -0.7, -1.56, -0.03, 0.18, 0.06, -0.07, 0.48, -0.75, 1.07, -0.68, -0.36, -0.72, -1.35, -2.21, -0.2381462585034016, -0.47, -0.59, -0.72, -1.16, -0.57, 0.58, -1.8, -1.6519125667872352, -1.41, -1.77, -2.4, -3.24, -1.73, -1.53, -1.65, -1.77, -0.55, -0.06, 0.33, -0.04, -0.67, -1.53, 0.0, 0.21, 0.09, -0.04, 0.0, -0.06, 0.83, -0.28, 0.26, -0.81, -0.39, -0.37, -1.0, -1.86, -0.33, -0.12, -0.16401213658444735, -0.37, -0.05, -0.03, -0.64, -1.5, 0.04956235827664399, 0.25, 0.13, 0.0, 0.52, 0.72, -0.26396282112195957, -0.41, -1.27, 0.2480695494981211, 0.22, 4.17, -4.2, -2.11, 0.61, -1.28, -3.04, 0.55, 0.27, -0.83, 0.65, -0.86, 0.91, 0.8, -0.28, 6.2, -0.53, 2.29, -1.1, -1.22, -5.56, 0.72, 1.11, 2.94, 0.61, -0.86, 0.68, 0.89, 0.77, 0.64, -0.83, 1.49, 1.56, 1.77, 1.65, 1.52, -0.07, 0.21, 0.09, -0.04, -4.11, -5.19, -0.28, -0.12, -0.25, -0.25, -0.85, -2.56, -2.65, 0.54, 2.47, -0.27, 0.68, -0.08136255179902908, -0.13, -0.3599225974772193, -2.34, 0.93, 1.21, 0.38, -0.03, -0.72, 0.7030376647162363, -0.42], ['386', 2.39, -0.22, -0.30877828437954125, -0.07, 0.55, -0.45, 0.54, -0.63, -0.13, -0.17, -0.39, 0.29, 0.43, 0.57, -0.33, -0.42, 0.82, -0.22, -0.84, -1.48, -0.03, 0.9, 0.4, 0.31, -0.78, -1.08, 0.23, 0.68, 0.82, 0.96, 0.06, -0.02, 1.22, 0.18, -0.45, -1.1, 0.36, 1.29, 0.8, 0.7, 0.0, 0.67, -0.44979591836734695, 0.14, 0.28, -0.62, -0.7, 0.53, -0.5, -1.13, -1.76, -0.32, 0.61, 0.11, 0.02, -0.91, -0.77, -0.39, -0.35007142857142853, -0.59, 0.14, -0.76, -0.84, 0.39, -0.64, -1.26, -1.9, -0.46, 0.47, -0.03, -0.12, 0.05, -0.73, -0.9, -0.98, 0.25, -0.78, -1.4, -2.04, -0.4469183673469388, 0.33, -0.17, -0.20644035827487928, 0.47, -1.94, 1.89, 0.17, -0.08, 1.5899013605442176, 0.12, -0.51, -1.15, 0.3, 1.23, 0.74, 0.64, -2.8, 0.25, 1.24, 0.30533503401360546, -0.43, -1.07, 0.39, 1.32, 0.82, 0.73, -0.08, 0.3, -1.28, -0.37, -0.37, -0.47, -0.98, -1.03, -1.65, -2.28, -0.84, 0.08, -0.42, -0.51, -1.15, 0.05, -0.63, -1.27, 0.19, 1.12, 0.62, 0.52, -0.66, -0.49, 0.21603717887804044, -0.74, -8.4, -0.43, -0.47, 0.37, -0.41, -0.19, -2.62, -0.23, -2.62, 0.71, 0.39, 1.19, -0.37, -1.05, 1.15, 1.15, -0.38, 0.58, -0.63, 0.76, -0.4, -2.88, -3.76, 1.98, 2.94, 2.5771309523809522, 0.68, -0.65, 0.82, 1.75, 1.25, 1.16, -1.09, 1.34, 1.47, 2.42, 1.91, 1.82, -0.14, 0.93, 0.43, 0.34, -0.08, -0.04, -1.05, -0.49, -0.59, -0.35, -0.44, -0.56, -1.01, -1.07, 1.1314285714285712, -0.4327361894755667, -0.04, -0.56, -0.09, -0.97, 0.01, -0.23, -0.38, -0.61, -0.47, -1.1, 0.43, -0.17], ['387', -5.61, 0.62, -0.05877828437954126, -0.19, 0.49, 1.29, 1.0641152579598292, 0.8, 1.97, 1.2, -2.28, 0.2, -0.09, 0.47, 0.7, 3.42, 0.45, 1.18, 4.831481859410431, 0.3, 1.86, 0.13, -0.45, -0.2, 1.63, 1.52, 3.6026583949931124, 2.55, 2.25, 2.82, 3.05, 5.83, 2.8, 3.55, 7.27, 2.64, 4.24, 2.47, 1.87, 2.13, 1.03, 3.84, 1.0, -0.29, 0.27, 0.49, 3.21, 0.24, 0.97, 4.6, 0.09, 1.65, -0.08, -0.66, -0.41, -0.97, 0.99, 1.63, 1.66, 1.29, 0.56, 0.79, 3.51, 0.6185714285714285, 1.27, 4.91, 0.39, 1.95, 0.22, -0.37, -0.11, 0.9, 0.73, 0.23, 2.93, -0.02, 0.7, 4.32, -0.17, 1.8218537414965983, -0.34, -0.92, -0.67, 3.17, 4.35, -4.24, 0.5, 2.7, -0.25, 0.48, 4.09, -0.4, 1.15, -0.57, -1.1414761904761903, -0.9, -1.27, -2.14, -2.87, -2.16, 1.35, -3.01, -1.51, -3.18, -3.74, -3.5, 0.471141873999017, -2.14, 0.73, 1.31, 1.34, 1.18, 0.75, 0.73, 4.35, -0.15, 1.4, -0.32, -0.9, -0.65, 1.07, 0.07307674813036727, 3.59, -0.87, 0.67, -1.04, -1.62, -1.37, 1.19, 0.71, -0.27, 0.88, -2.63, 0.87, -0.11, -2.66, 2.63, 1.34, 0.37, 0.48, -1.59, -2.67, -1.31, -2.84, 0.71, 3.84, -3.87, -3.96, 1.31, -4.03, 2.62, 2.13, -1.06, 2.37, -6.39, -1.5, -2.23, 1.85, -3.44, -4.31, -2.82, -4.47, -5.03, -4.624238287156354, 3.99, 0.9, 1.56, -0.17, -0.75, -0.5, -0.64, -1.7, -2.27, -2.02, 1.94, 2.28, 1.08, -0.58, -0.33, 1.3, 1.27, 0.83, -3.27, 0.34, 3.2421428571428574, 1.15, 1.56, 1.67, 0.25, 1.6200774025227807, 1.36, 0.82, 1.49, 0.67, 1.41, 0.6502406343656345, 2.12, 0.83], ['388', -2.27, -0.98, -0.04, -0.23, -0.32, -0.86, -1.1658847420401708, -1.29, -1.96, -1.17, 1.37, 0.12, -1.41, 0.64, 0.05, -0.9, 1.07, -0.95, -0.63, 0.07, -1.932664517912641, 0.53, 0.25, -0.14, -0.69, -2.23, -2.4673416050068875, -1.2294545454545454, -2.74, -0.72, -1.242180028704909, -2.23, -0.29, -2.29, -1.97, -1.28, -3.29, -0.83, -1.1, -1.49, -0.43, -4.075063800783826, -1.29, -1.53, 0.52, -0.07, -1.02, 0.95, -1.07, -0.75, -0.05, -2.09, 0.41, 0.14, -0.26, -0.53, -0.07, -0.55, -1.82, 0.24, 2.08, 1.48, 0.52, 2.52, 0.47, 0.8, 1.5, -0.57, 1.97, 1.69, 1.29, -1.07, -1.8, -0.59, -1.53, 0.43, -1.58, -1.26, -0.57, -2.59, -0.11, -0.38, -0.78, -2.67, -4.46, 4.47, -1.18330176161468, -0.95, 1.02, -1.0, -0.68, 0.02, -2.02, 0.48, 0.21, -0.19, -2.62, -0.28, 1.99, -0.05, 0.27, 0.97, -1.08, 1.44, 1.16, 0.76, -0.42, -0.1506317967746538, -1.86427628811696, -1.35, -1.26, -1.53, -2.22, -1.9986530612244897, -1.68, -1.0, -3.01, -0.54, -0.81, -1.2, -1.75, -0.22, 0.33, 1.03, -1.03, 1.49, 1.22, 0.82, -1.48, -1.54, -0.39, -2.09, -5.09, -0.48, -0.39, 3.58, -3.59, -1.81, -1.48, -1.22, 2.45, 2.69, 1.37, -1.15, -0.56, -4.28, 4.24, 4.02, -1.34, 5.37, -2.69, 1.1183906549799407, -0.48, -6.64, 7.48, 4.43, 6.57, -2.44, -0.55, 0.7, -1.35, 1.16, 0.89, 0.49, -3.9891948051948054, -1.24, -2.04, 0.46, 0.19, -0.21, 0.82, 2.55, 2.27, 1.87, -1.97, -2.35, -1.69, -0.27, -0.67, -1.32, -1.46, -1.21, 3.91, -1.48, -3.8, -1.67, -1.26, -1.42, -0.4, -1.94, -1.79, -0.64, -0.22, -1.14, -1.03, -2.62, -1.94, -2.0569832262926027], ['389', 1.84, 0.44, 0.44, -0.14, 1.09, 1.52, 1.19, 1.0, 2.52, 1.21, -2.95, 0.24, -0.72, 0.88, -0.42, -0.32, -0.89, 0.45, 0.62, -0.77, 1.77, 0.02, -0.11, 0.27, 1.99, 2.28, 4.29, 3.408468508265777, 2.3, 3.95, 2.61, 2.7133503401360546, 2.12, 3.51, 3.69, 2.25, 4.86, 3.07, 2.92, 3.32, 0.12, 5.16, 0.97, -0.96, 0.64, -0.65, -0.56, -1.13, 0.21, 0.39, -1.0, 1.53, -0.21, -0.35, 0.03, 0.66, 0.74, -0.31, 2.24, 1.94, 1.61, 0.31, 0.4, -0.17, 1.18, 1.36, -0.05, 2.51, 0.75, 0.61, 1.0, 0.13, 0.32, -0.8697721088435375, -1.2, -1.76, -0.43, -0.25, -1.64, 0.88, -0.85, -0.99, -0.6, 4.6, 4.01, -4.2, 1.63, 0.09, -0.48, 0.87, 1.04, -0.36, 2.19, 0.44, 0.3, 0.69, 2.4, 1.54, -0.57, 0.78, 0.95, -0.44, 2.1, 0.35, 0.21, 0.6, 0.95, 1.53, 1.04, 1.52, 1.51, 1.61, 2.12, 1.35, 1.53, 0.12, 2.68, 0.92, 0.78, 1.17, 1.19, 0.75, 0.17, -1.21, 1.31, -0.43, -0.56, -0.18, 1.8, 2.11, -0.02, 2.17, 4.89, 0.3580695494981211, -0.14, -3.28, 3.19, 1.63, 1.09, 1.56, -3.71, -3.05, -1.5385714285714287, 0.93, 1.53, 4.61, -4.680000000000001, -4.65, 1.5, -4.78, 3.03, 2.99, -1.47, 6.22, -5.952619047619048, -4.19, -6.19, 3.59, 0.58, -1.39, 1.14, -0.6, -0.73, -0.35, 4.52, 1.99, 2.56, 0.8, 0.66, 1.05, -0.10349829931972804, -1.72, -1.85, -1.4685714285714286, 2.49, 2.96, 1.18, -0.14, 0.25, 1.5, 1.62, 1.18, -2.94, 1.57, 3.11, 1.81, 2.09, 1.32, 0.39, 2.26, 1.87, 1.07, 1.47, 1.03, 0.93, 2.53, 2.46, -0.23], ['390', 3.11, 0.53, 0.06, -0.28, 0.22, 1.0, 1.14, 2.33, 1.86, 3.54, 0.84, 2.68, 1.6, 0.84, 1.47, 3.42, 1.44, 3.48, 5.61, 4.17, 4.08, 2.72, 1.51, 3.06, 1.5485936610075264, 1.03, 2.67, 1.822860544217687, 0.75, 0.0, 0.62, 2.56, 0.6, 2.62, 4.73, 3.3, 3.21, 1.86, 0.66, 2.2, 1.3, 2.4849361992161736, 0.840204081632653, -1.05, -1.78, -1.17, 0.72, -1.2, 0.79, 2.86, 1.46, 1.37, 0.04, -1.13, 0.38, 1.35, 1.36, 1.88, 2.07, 1.91, -0.74, -0.12, 1.79, -0.15, 1.86, 3.95, 2.53, 2.44, 1.1, -0.08, 1.44, 1.88, 2.67, 0.62, 2.55, 0.59, 2.62, 4.72, 3.3, 3.2, 1.86, 0.66, 2.2535596417251207, 2.61, 5.49, -5.48, 2.04, 1.92, -0.03, 1.98, 4.08, 2.66, 2.57, 1.23, 0.04, 1.57, 0.76, 0.11, -1.91, 0.06, 2.12, 0.72, 0.64, -0.68, -1.84, -0.35, -0.1, 0.12235688121402405, 2.22, 1.21, 1.43, 1.13, 2.06, 2.01, 4.11, 2.69, 2.59, 1.26, 0.07, 1.59, 0.55, 0.10307674813036727, 2.05, 0.66, 0.57, -0.74, -1.9, -0.16782256235827656, 1.99, 2.13, -0.03, 1.87, 2.11, 0.08, 0.31, -2.04, 2.03, 1.01, 0.22, 3.2202597402597406, 1.24, -2.5, -1.22, 1.58, 0.85, 3.88, -3.81, -3.66, 1.22, -3.07, 2.45, 1.94, -1.25, 6.23, -6.44, -4.17, -6.13, -1.27, -1.96, -1.36, -1.45, -2.74, -3.88, -2.41, 3.61, -0.61, -0.09, -1.39, -2.55, -1.06, -0.52, -1.3, -2.46, -0.98, 1.86, 2.36, 0.79, -1.18, 0.40224875531501636, 1.25, 1.37, 2.5, -3.32, 3.05, 3.17, 1.53, 0.88, 1.99, 1.53, 1.49, 1.22, 1.2652979520479524, 0.5, 1.29, 0.46, 2.4, 0.31, 1.09], ['391', -1.84, 0.92, -0.028778284379541254, -0.06, -0.5, 0.13, -0.21, 0.04, -0.4, -0.15, 1.0503184712113285, 0.1, -0.88, -1.38, -0.42, 0.52, -0.63, -0.08, 0.85, -0.39, -0.61, -0.61, -0.3, -0.96, 0.21, -0.19, -0.98, -0.73, -1.7, -2.2, -1.25, -0.32, -1.45, -0.91, 0.01, -1.21, -1.43, -1.44, -1.12, -1.78, -0.81, -0.20506380078382658, -0.25, -0.98, -1.48, -0.44918497042472344, 0.41, -0.73, -0.18, 0.74, -0.49, -0.71, -0.71, -0.4, -1.06, 0.33, 0.14, -0.36, -0.55, 0.74, -0.5, 0.46, 1.41, 0.25, 0.81, 1.74, 0.5, 0.28, 0.27, 0.59, -0.08, -1.15, 1.25, 0.97, 1.92, 0.76, 1.32, 2.26, 1.01, 0.78, 0.78, 1.1, 0.43, -0.65, 0.65, -0.72, 0.27, 0.94, -0.21, 0.35, 1.28, 0.04, -0.18, -0.19, 0.13, -0.54, -1.53, -0.66, -1.14, -0.59, 0.33, -0.9, -1.12, -1.12, -0.81, -1.46, 0.02, -0.67, 1.13572371188304, 0.15, 0.26517906963433996, 0.26, 0.5518094764861292, 0.56, 1.49, 0.25, 0.03, 0.02, 0.34, -0.33, 0.35, -0.07, 0.92, -0.31, -0.53, -0.54, -0.22, -0.88, 0.08, -0.03, -0.29, 0.67, -4.6, 0.28, 0.17, -0.14, 0.08, 0.06, 1.06, 0.23, -0.51, -0.3, -0.21, -0.87, 0.31, 0.53, -0.51, -0.6, 0.14, -0.16, 0.52, 1.08, -0.54, 1.52, -3.48, -1.09, -1.38, 0.5, -0.99, -1.22, -1.44, -1.45, -1.13, -1.79, 0.52, 0.24, -0.22, -0.23, 0.09, -0.57, 0.906501700680272, -0.01, 0.31, -0.35, -0.45, -0.57, 0.47, 0.32, -0.35, 0.19, 0.26, 0.14, -1.18, 1.3301996269574994, 0.97, 0.0, 0.6, 0.15, -0.66, 0.72, 0.06, -0.17, 0.23, 0.05, 0.81, 0.93, 1.38, 1.62], ['392', 5.9, 0.48, -0.05, 0.0, 1.3129790809910595, 0.6, 1.67, 1.21, 1.39, 0.9253571428571429, -1.41, -0.55, -0.61, 0.75, -0.79, 0.23, 1.15, 0.91, 0.85, -1.66, 0.91, -0.13, -0.64, 2.76, -0.44, 0.35, 2.3, 0.87, 0.81, 2.19, 0.63, 1.66, 2.6, 2.36, 2.29, -0.25, 2.35, 1.3, 0.78, 4.273841723197839, 1.14, 3.1, 1.619303232481804, -0.06, 1.3, -0.24, 0.78, 1.71, 1.47, 1.4, -1.12, 1.47, 0.42, -0.1, 3.33, 0.98, 0.18, 0.91, 0.6, 1.5592452470658775, 1.37, -0.18, 0.85, 1.78, 1.53, 1.47, -1.05, 1.53, 0.48, -0.03, 3.39, 2.7, 0.11, -1.53, -0.51, 0.4, 0.17, 0.1, -2.39, 0.16, -0.87, -1.38, 2.0, 2.6189098639455786, 3.29, -3.37, 1.66, 1.03, 1.96, 1.72, 1.65, -0.87, 1.71, 0.67, 0.15, 3.58, 0.86, 0.63, 0.92, 0.68, 0.62, -1.88, 0.68, -0.36, -0.87, 2.52, -0.02, 0.64, 1.21, 0.03, 0.65, -0.69, -0.29, -0.24, -0.3, -2.78, -0.24, -1.27, -1.78, 1.59, 0.84, -0.05, -0.06, -2.55, 0.0, -1.04, -1.54, 1.83, 1.81, 2.35, 0.17, -0.38, 1.4, 0.56, 0.07, 3.24, -3.37, -1.65, 0.45, 3.6, -5.08, -0.12, -0.04, 2.88, 0.63, -0.16, 0.18, -0.2, 0.05, 4.96, 0.15, -2.041609345020059, 1.08, -0.95, 0.82, 0.49, 0.76, 5.11, 0.01, -2.49, 0.06, -0.97, -1.48, 1.9, 0.12, 2.56, 2.61, 1.55, 1.03, 4.49, -0.05, -1.03, -1.54, 1.83, 1.44, 2.08, 0.99, -0.51, 2.89, 0.0, -0.12, 1.12, 0.32, 0.0, -0.17, -0.36, 0.35, 1.51, 3.43, 0.54, -0.82, 0.34, 1.14, 0.28, -1.85, 0.17, -1.74, -2.2], ['393', 1.45, 0.34, 0.09122171562045875, -0.22, 0.0, -0.15, 0.45411525795982915, 0.67, 0.77, -0.05, -0.61, -0.7, -0.39, -0.47, -1.36, -0.21, -0.36, -0.2, -0.86, 0.06, 0.48733548208735894, 0.53, -0.85, -0.47, 1.51, 0.94, 0.56, -0.1, 0.22, 0.14, -0.7021800287049088, 0.4, 0.24, 0.41, -0.25, 0.67, 1.07, 1.14, -0.25, 0.18384172319783917, 0.27, 1.7949361992161734, 0.66, 0.32, 0.24, -0.66, 0.5, 0.34, 0.51, -0.15, 0.77, 1.17, 1.24, -0.15, 0.24, 0.8, 0.3, 0.15, 0.73, 0.34, -0.08, -0.98, 0.18, 0.02, 0.19, -0.47, 0.45, 0.85, 0.92, -0.47, -0.08, 0.5, 0.42, -0.9, 0.26, 0.11, 0.27, -0.39, 0.54, 0.93, 1.0, -0.39, 0.01, 0.98, 2.05, -2.04, 1.33, 1.17, 1.01, 1.18, 0.51, 1.45, 1.84, 1.92, 0.52, 0.91, 0.34, 0.16, -0.15, 0.01, -0.6484761904761905, 0.28, 0.67, 0.74, -0.64, -0.25, 0.23, 0.18, 2.45, 0.21, 0.61, -0.22, 0.31, 0.16, -0.49, 0.43, 0.82, 0.9, -0.49, -0.1, -0.29, 0.15, -0.66, 0.27, 0.66, 0.73, -0.65, -0.26, 1.01, 0.9, -0.04, 0.4, 0.97, 0.03, 0.0, 0.53, -0.5275376766091052, -0.26, 1.4240662734668152, 1.3561635321120495, 0.22, -0.45, -0.18, 0.78, 0.553079789868779, 0.7, -0.66, -0.63, 0.2, 0.78, 0.46, 1.79, -0.89, 0.92, 0.0, -0.67, -0.87, -0.26, 0.81, 0.93, 1.32, 1.4, 0.0, 0.4, 0.64, -0.12, 0.39, 0.46, -0.92, -0.53, -0.51, 0.07, -1.3, -0.92, 0.77, 0.76, -0.58, -1.37, -0.99, 0.23, 0.28439630127529086, 0.66, -0.66, 1.5, 0.77, 0.5272638105244333, 0.83, 0.81, 0.46278685149693166, 0.36, -0.75, 0.37, 1.35, -0.07, 0.49595752702381396, 1.12, 0.87, 0.0], ['394', -7.48, -0.71, -0.2787782843795412, 0.21, -1.78, -1.37, 0.07411525795982916, -3.92, -4.12, -1.09, 3.94, 0.71, 1.85, 3.53, 2.6342857142857143, 1.25, 1.13, -0.8, -2.76, 2.02, -1.92, 0.32, 0.5, 0.875116627420199, -4.96, -3.770628585411108, -4.84, -3.11, -2.01, -0.39, -1.26, -2.59, -2.7, -4.56, -6.45, -1.8286428571428572, -5.64, -3.48, -3.31, -3.09, -4.55, -3.89, -1.789795918367347, 1.13, 2.81, 1.9, 0.54, 0.42, -1.5, -3.45, 1.3, -2.62, -0.39, -0.21, 0.02, -2.46, -4.15, -2.54, -4.42, -2.89, 1.66, 0.77, -0.59, -0.7, -2.6, -4.53, 0.17, -3.7, -1.5, -1.33, -1.09, -2.3, -4.47, -0.88, -2.21, -2.32, -4.19, -6.08, -1.46, -5.27, -3.1, -2.94, -2.71, -4.71, -4.66, 4.67, -3.63, -1.34, -1.45, -3.34, -5.25, -0.59, -4.43, -2.25, -2.08, -1.85, -4.06, -2.32, -0.12, -2.03, -3.97, 0.76, -3.14, -0.92, -0.75, -0.51, -0.38, -2.35, -2.65, -1.5684018193170985, -1.51, -1.86, -2.2, -1.92, -3.85, 0.88, -3.02, -0.8, -0.63, -0.4, -1.41, -0.29, -1.98, 2.84, -1.13, 1.13, 1.31, 1.55, -1.63, -1.91, 0.35, -2.25, -11.87, -0.16, 0.06, 3.55, -3.6, -1.8, -0.44, -3.36, 6.23, 3.17, 1.62, -3.89, -0.67, -4.98, 5.03, 4.89, -1.64, 5.4, -3.29, -1.47, 0.68, -6.52, 4.45, 4.23, 6.41, -6.4, 1.72, 4.92, 0.86, 3.17, 3.35, 3.6, -4.91, -3.05, -3.87, -1.67, -1.49, -1.26, 0.85, 2.29, 2.47, 2.71, -1.91, -1.98, -1.41, 0.18, 0.41, -1.59, -1.65, -2.73, 6.5, -3.99, -7.12, -2.7, -3.3, -1.58, 0.24, -1.53, -1.63, -0.73, -0.55, -0.99, -1.81, -4.28, -4.46, -2.19], ['395', 0.18, -0.23, -0.10877828437954125, 0.17, -0.48, -0.31, 0.05, -1.23, -0.73, -3.26, -2.35, -3.58, -2.19, -2.58, -1.25, -3.68, -2.37, -3.17, -5.53, -1.98, -3.56, -2.3, -2.33, -2.14, -2.29, -0.5706285854111081, -0.93, -1.26, 0.16, -0.23, 1.13, -1.37, -0.02, -0.84, -3.25, 0.38, -1.24, 0.05, 0.02, 0.22, -0.44, -1.7891024373941227, 0.33, 1.44, 1.04, 2.42, -0.11, 1.26, 0.43, -2.02, 1.66, 0.02, 1.33, 1.3, 1.5, -0.14, -0.21, -1.06, 0.06, -1.09, -0.39, 0.97, -1.52, -0.18, -1.0, -3.41, 0.22, -1.4, -0.11, -0.14, 0.06, -0.96, -0.7, 1.36, -1.14, 0.21, -0.61, -3.03, 0.61, -1.01, 0.28, 0.26, 0.45, -0.9373265306122449, -2.6, 2.55, -2.04, -2.47, -1.13, -1.95, -4.33, -0.74, -2.34, -1.06, -1.09, -0.9, 0.27, 0.44, 1.36, 0.53, -1.91, 1.77, 0.13, 1.44, 1.41, 1.61, -0.16, 0.49, 0.13, -0.65, -0.68, -0.67, -0.91, -0.82, -3.23, 0.4, -1.22, 0.07, 0.04, 0.2985846838830657, -1.0, -0.1, -2.43, 1.23, -0.4, 0.9, 0.87, 1.07, -0.3, 0.0, 0.23, -0.7, 1.1, -0.03, 0.0, 1.59, -1.57, -0.78, -1.27, -1.79, 2.63, 1.3, 0.68, 0.07, -0.07, -1.86, 1.89, 1.93, -0.65, 2.32, -1.31, -2.04, 0.98, -2.68, 2.65, 1.71, 2.45, -2.56, 2.4, 3.75, 2.08, 3.42, 3.39, 3.59, -2.01, -1.31, -1.61, -0.33, -0.35, -0.16, 0.31, 1.31, 1.28, 1.48, -0.65, -0.76, -0.98, -0.03, 0.17, -0.65, -0.7, -1.26, 3.75, -0.45, -3.77, -1.01, -1.67, -0.96, 0.19, -0.58, -0.63, 0.44, -0.05, -0.27, -1.15, -2.24, -2.27, -1.46], ['396', 2.42, 0.18, 0.2, 0.13, -0.42, 0.55, 0.89, 1.6, 1.3, 0.59, -1.22, -0.23, -1.22, -1.29, -0.31, 0.23, -0.67, 0.28, 0.95, 1.01, 1.297335482087359, 0.01, -0.64, -0.59, 1.16, 0.869371414588892, 1.83, 1.01, 0.0, -0.07, 0.92, 1.47, 0.55, 1.51, 2.2, 2.25, 2.51, 1.25, 0.59, 0.64, 1.13, 1.4449361992161733, 0.82, -1.0, -1.06, -0.08, 0.46, -0.45, 0.5, 1.18, 1.24, 1.49, 0.24, -0.42, -0.36, 1.42, 1.33, 0.82, 1.17, 1.83, -0.07, 0.92, 1.47, 0.55, 1.6126050661400617, 2.4896933106575965, 2.25, 2.6734211542425825, 1.25, 0.58, 0.64, 1.07, 1.9, 0.99, 1.54, 0.62, 1.58, 2.27, 2.33, 2.58, 1.32, 0.66, 0.71, 1.76, 3.22, -3.22, 0.9, 0.54, -0.37, 0.59, 1.26, 1.32, 1.57, 0.32, -0.33, -0.28, 0.17, 0.36, -0.9, 0.04, 0.72, 0.77, 1.02, -0.22, -0.87, -0.82, 0.18, 0.31, 3.62, 0.72, 0.78, 0.82, 1.3418094764861292, 0.95, 1.64, 1.69, 1.95, 0.69, 0.03, 0.08, 0.55, 0.31, 0.68, 0.73, 0.98, -0.26, -0.91, -0.86, 0.66, 0.61, 0.0, 1.19, 0.56, 0.43, 0.21, -2.16, 2.17, 1.09, 0.31, 1.86, 0.81, -1.43, -0.73, 1.27, -0.01, 2.38, -2.27, -2.16, 0.73, -3.26, 1.47, 1.2583906549799408, -0.57, 3.79, -5.86, -2.51, -3.69, -0.83, -0.36, 0.05, 0.3, -0.93, -1.58, -1.53, 2.2108051948051948, -0.41, 0.3941925889236815, -0.98, -1.63, -1.58, -0.66, -1.23, -1.88, -1.83, 1.45, 1.43, 0.58, -0.65, -0.6, 0.71, 0.8, 1.61, -2.97, 2.98, 2.99, 0.61, 0.94, 1.24, 0.05, 0.56, 1.11, -0.06, -0.41, 0.14, 1.265957527023814, 1.43, 1.26, 1.58], ['397', 2.67, -0.12, 0.1, 0.21214285714285727, -0.72, -0.09, -0.25, -0.79, -0.34, -0.21, 0.06, 0.26, 0.22, 0.99, 0.51, -0.68, 0.88, -0.24, -0.36, 2.21, 0.07, 0.5130748299319728, -0.01, 0.16, -0.78, -0.5, -0.27, 0.2, 0.16, 0.93, 0.45, -0.74, 0.82, -0.3, -0.42, 2.15, 0.01, 0.45, -0.07, 0.1, -0.22, -0.57, -0.47, -0.03, 0.73, 0.26, -0.94, 0.63, -0.49, -0.61, 1.9507142857142856, -0.19, 0.25, -0.27, -0.1, 0.0, 0.06, -0.47, -0.23, -0.43, 0.76, 0.29, -0.9, 0.66, -0.46, -0.58, 1.98, -0.16, 0.29, -0.24, -0.07, -0.46, -1.1885714285714286, -0.47, -1.66, -0.1, -1.2067857142857144, -1.33, 1.21, -0.91, -0.47, -0.99, -0.82, -0.36, -0.87, 0.86, -0.72, -1.19, 0.37, -0.75, -0.87, 1.69, -0.44, 0.0, -0.52, -0.35, -0.54, 0.47, 1.58, 0.45, 0.33, 2.92, 0.76, 1.2, 0.68, 0.85, -0.09, 0.45, -0.64, -0.28, -0.28, -0.54, -1.09, -1.11, -1.23, 1.32, -0.81, -0.37, -0.89, -0.72, -0.82, 0.02, -0.12, 2.46, 0.31, 0.75, 0.23, 0.4, -0.68, -1.56, -0.45, -0.86, -1.18, -0.18, -0.19, 1.61, -1.65, -0.81, -1.28, -0.75, 4.6, 0.54, 0.39, 1.5, 0.16, -1.01, 1.05, 0.77, -0.27, 2.4, -0.55, 2.32, -1.13, -3.07, 6.27, 2.2142857142857144, 3.2314285714285713, -4.82, 0.15, 2.58, 0.43, 0.87, 0.35128571428571426, 0.52, -0.74, -2.37, -2.1, -1.67, -2.18, -2.01, -0.28, 0.44, 0.15285714285714286, 0.09, -0.35, -0.41, -0.72, -0.32676622187336457, -0.35, -0.47, -0.41, -0.75, 3.197142857142857, -0.56, -3.25, -0.73, 0.03, -0.2, 0.17, -0.79, -0.61, -0.16, 0.04, 0.12, -0.37, -2.03, -1.05, -1.02], ['398', 1.09, 0.19, 0.09122171562045875, -0.45, 1.59, 1.04, 1.03, 1.09, 0.87, 1.07, -0.17, 0.18, -0.36, -0.77, 0.69, 0.92, -0.22, 0.72, -0.49, -0.21, 1.42, 0.49, 0.74, -0.51, 1.59, 1.41, 1.2826583949931125, 0.35, -0.19, -0.6, 0.87, 1.1, -0.05, 0.89, -0.32, -0.04, 1.5907606837606838, 0.67, 0.91, -0.2961582768021609, 0.5, 1.21, 0.89, -0.54, -0.95, 0.51, 0.74, -0.4, 0.54, -0.67, -0.39, 1.24, 0.31, 0.56, -0.69, 1.28, 0.45, 0.14, 0.88, 1.44, -0.41, 1.06, 1.29, 0.14, 1.08, -0.14, 0.15, 1.78, 0.86, 1.1, -0.15, 0.6, 1.86, 1.48, 1.71, 0.56, 1.5, 0.28, 0.56, 2.21, 1.27, 1.52, 0.26, 1.23, 1.16, -1.16, 0.38, 0.23, -0.91, 0.02, -1.18, -0.9, 0.72, -0.2, 0.04, -1.19, 0.93, 0.15, -1.13, -0.2, -1.4, -1.13, 0.49, -0.42, -0.18, -1.42, 0.32, 0.21, 1.26, 1.08, 0.86517906963434, 1.5356735186500319, 1.3, 0.94, -0.28, 0.01, 1.64, 0.72, 0.96, -0.29, 0.61, 0.35, -1.2, -0.92, 0.8786030199958773, -0.22, 0.02, -1.22, 0.17, 0.42, -0.66, 1.45, 2.0, 0.54, 0.27, -2.58, 2.5324623233908947, 1.28, 0.13, 1.6902597402597401, -2.74, -2.16, -1.09, 0.49, 0.49, 3.41, -3.4, -3.28, 1.133290804863853, -3.91, 2.2398783572413152, 1.49, -0.74, 3.93, -6.22, -2.63, -3.89, 2.61, 1.58, 0.28480952380952385, 1.92, 0.99, 1.24, -0.01, 3.32, 1.29, 1.64, 0.71, 0.95, -0.3, -0.34, -0.91, -0.67, -1.9, 1.1101351386708531, 0.98, 0.58, 0.24, -1.0, 1.12, 1.18, 1.0825760496238783, -3.15, 1.04, 3.1, 1.32, 2.34, 0.34, -1.24, 1.31, 1.0, 0.1, 0.48, 1.49, 1.59, 2.13, 2.67, 1.51], ['399', -4.36, 1.46, 0.04, -0.16, 0.33, 0.82, 1.44, 0.02, -0.07, 0.5, -0.56, 0.23, -0.62, 0.16, 0.13, 2.28, -0.82, 0.43, -0.88, 0.06, 0.86, -0.1, -0.54, -0.65, -3.11, -1.0, 1.07, 0.8005454545454546, -0.05, 0.73, 0.7, 2.86, -0.25, 1.0, 0.12570238095238095, 0.63, 1.43, 0.46, 0.03, -0.08, -0.88, 0.69, 0.26, -0.85, -0.07, -0.1, 2.04, -1.05, 0.2, -1.11, -0.17, 0.62, -0.34, -0.77, -0.88, -0.03, -2.23, -2.04, -0.53, 1.12, 0.78, 0.75, 2.91, -0.2, 1.1526050661400618, -0.27, 0.68, 1.48, 0.51, 0.08, -0.03, -0.26, 0.33, -0.04, 2.11, -0.98, 0.27, -1.04, -0.1, 0.69, -0.27, -0.7, -0.81, 0.82, 2.82, -2.9, 0.37, 2.15, -0.94, 0.3, -1.01, -0.06832539682539683, 0.73, -0.23, -0.66, -0.78, -2.15, -1.74, -3.03, -1.8, -3.09, -2.17, -1.39, -2.33, -2.75, -2.86, 0.09, -1.76, 1.95, 0.96, 0.89, 1.08, 1.32, 1.26, -0.07, 0.88, 1.69, 0.72, 0.28, 0.17, 0.53, 0.06, -1.31, -0.37, 0.42, -0.54, -0.97, -1.08, 1.3, 1.14, -0.25, 1.27, -6.37, 0.11, 0.04, -2.76, 2.81, 1.428810171007621, 0.28, 1.29, -1.04, -1.93, -0.97, -2.21, 0.46, 2.75, -2.79, -2.89, 0.97, -4.26, 1.94, 2.37, -1.18, 3.96, -6.51, -2.62, -3.96, 1.0, 1.39, 0.95, 1.75, 0.78, 0.6696385796742939, 0.23, 2.89, 0.44, 0.8, -0.16, -0.6, -0.71, -0.36, -0.96, -1.38, -1.49, 1.032795351473923, 1.01, 0.6, -0.43, -0.54, 0.93, 1.02, 0.49, -3.11, 1.84, 3.11, 1.0, 1.56, 1.04, -0.11, 1.11, 1.2, 0.08, 0.7316666666666667, 0.8, 1.15, 1.38, 2.29, 1.24], ['400', -4.13, 1.15, 0.32122171562045876, -0.34, 0.3, 1.82, 1.414115257959829, 2.64, 1.88, 3.32, 0.89, 2.31, 1.67, 0.46, 0.85, 5.34, -0.42, 2.25, 5.46, 1.07, 3.28, 1.08, 0.11, 1.06, 2.34, 1.6993714145888918, 2.41, 1.41, 0.77, -0.43, -0.04, 4.41, -1.3, 1.34, 4.53, 0.18, 2.434453670078569, 0.19, -0.77, 0.16, 1.77, 2.1649361992161733, 0.99, -0.63, -1.81, -1.42, 2.96, -2.67, -0.06, 3.08, -1.21, 0.94, -1.2, -2.15, -1.23, 0.5, 1.6, 2.05, 2.16, 1.63, -1.19, -0.8, 3.62, -2.05, 0.57, 3.74, -0.59, 1.58, -0.57, -1.53, -0.6, 3.6, 2.85, 0.39, 4.86, -0.88, 1.78, 4.98, 0.61, 2.8, 0.62, -0.34, 0.6, 2.28, 9.31, -9.26, 2.4508709226619945, 4.45, -1.27, 1.38, 4.57, 0.21, 2.4, 0.23, -0.74, 0.2, -0.7, -1.92, -5.47, -2.94, 0.12, -4.06, -1.96, -4.04, -4.97, -4.07, 0.95, -1.93, 3.47, 2.3, 2.62, 2.255673518650032, 3.831809476486129, 2.68, 5.91, 1.5, 3.71, 1.51, 0.54, 1.49, 2.09, 1.06, 3.15, -1.15, 1.01, -1.14, -2.09, -1.16, 3.21, 3.67, 0.22, 3.15, -1.55, 1.18, 0.87, -4.63, 4.67, 2.37, 1.96, 3.13, -4.41, -4.61, -2.34, -2.15, 1.86, 7.12, -7.23, -6.76, 2.3, -7.0, 4.59, 2.74, -1.33, 11.35, -10.33, -7.49, -11.18, 4.46, -2.03, -4.17, -2.08, -4.16, -5.08, -4.18, 6.81, 2.23, 2.18, 0.01, -0.95, -0.01, 0.05, -2.12, -3.06, -2.15, 2.0601351386708533, 2.48, 2.22, -0.96, -0.03, 2.26, 2.47, 2.74, -5.19, 3.7, 5.19, 2.3, 2.08, 3.21, 0.94, 2.55, 2.14, 1.56, 1.72, 2.29, 2.325957527023814, 2.74, 3.47, 2.97], ['401', -1.88, 0.0, -0.07877828437954125, 0.12, -0.9, 0.19, 0.69, -0.06, 0.31, -0.17, 0.37, -1.02, 0.19, 0.27, -0.41, -0.85, 0.28, 0.19, 1.59, -0.07, -0.03, -0.81, -0.24, -0.31, 0.17, 0.16937141458889196, -0.54, -1.39, -0.18, -0.1, -0.78, -1.22, -0.1, -0.18, 1.21, -0.44, -0.4, -1.18, -0.61, -0.68, -0.13, -1.07, 0.860204081632653, 1.22, 1.31, 0.61, 0.17, 1.31, 1.23, 2.64, 0.96, 1.0, 0.22, 0.78, 0.72, -0.4376426685347185, -0.25, 0.08, 0.42, -0.36, 0.08, -0.6, -1.04, 0.09, 0.0, 1.4, -0.25, -0.22, -1.0, -0.43, -0.5, -0.41, -0.44, -0.68, -1.12, 0.0, -0.08, 1.32, -0.34, -0.3, -1.08, -0.52, -0.58, -0.3, 0.65, -0.65, 0.25, -0.44, 0.69, 0.61, 2.01, 0.35, 0.38, -0.4, 0.17, 0.11, -0.02, 0.69, 1.14, 1.05, 2.47, 0.79, 0.83, 0.04, 0.61, 0.55, -0.25, 0.71, 0.19572371188304005, -0.14, 0.0, -0.41, -0.44, -0.08, 1.31, -0.34, -0.31, -1.0196949805527125, -0.52, -0.58, 0.53, -0.36, 1.4, -0.26, -0.22, -1.0, -0.44, -0.5, -0.08, -0.13, 0.38, -0.57, 0.03, -0.19, -0.35, 0.52, -0.59, -0.2411898289923789, -0.08, 0.28, 0.4205182488772715, 0.31, 0.19, -0.94, -0.15, -0.6, 0.67, 0.49, -0.15, 0.94, -0.32, -0.2, 0.08, -1.37, 7.1, 0.9, 1.41, -0.35, -1.73, -1.63, -1.6, -2.36, -1.81, -1.87, -0.49, -0.1, 0.03, -0.74, -0.18, -0.24, -0.14, -0.78, -0.21, -0.28, 0.19, 0.07, 0.64, 0.57, 0.5, -0.21, -0.21, 0.12, 3.45, 0.09019962695749935, -3.36, -0.46, -1.1488174603174601, 0.08, -0.06, -0.68, -0.23, -0.09, -0.28, 0.27, 0.14, -1.15, -1.9884047619047618, 0.15], ['402', 2.15, 0.84, 0.69, -0.07, 0.87, 1.29, 0.76, 1.9917205965359586, 1.8893780543870107, 0.99, -0.94, 0.471934498041641, -0.6860867348791511, -2.04, -1.77, 0.08, -0.72, -0.36, 1.14, -1.27, 2.087335482087359, -1.96, -1.48, 0.24, 3.76, 1.89, 1.9826583949931125, 1.23, 0.19, -1.11, -0.7721800287049088, 1.03, 0.23, 0.59, 2.1, -0.33, 3.02, -1.03, -0.54, 1.2338417231978391, 1.42, 1.6, 0.71, -1.02, -2.31, -2.04, -0.2, -0.99, -0.63, 0.86, -1.54, 1.77, -2.23, -1.75, 0.2808287981859412, 1.31, 1.71, 1.46, 1.48, 1.75, -1.3, -1.03, 0.83, 0.03, 0.39, 1.9, -0.52, 2.82, -1.22, -0.73, 1.0, 1.85, 3.1, 0.28, 2.16, 1.35, 1.72, 3.25, 0.79, 4.18, 0.08, 0.58, 2.33, 2.33, 7.17, -7.08, 2.8466982383853203, 1.88, 1.07, 1.43, 2.96, 0.7037447711019141, 3.88, -0.2, 0.3, 2.04, 2.5, 0.91, -0.79, -0.44, 1.06, -1.34, 1.97, -2.04, -1.55, 0.16, 1.23, 0.94, 2.41, 1.55, 2.1, 1.08, 1.72, 0.36, 1.87, -0.3602873118944545, 2.79, -1.25, -0.6940121365844474, 0.96, 3.0265360710717855, 1.35, 1.5, -0.91, 2.598603019995877, -1.4842004503433075, -1.12, 0.6, 3.35, 2.54, -0.06, 1.75, 4.94, 1.4, 0.8, -1.45, 1.49, 0.71, 2.58, 3.2, -4.55, -3.1, -1.6, 1.05, 1.27, 4.83, -4.76, -4.67, 1.55, -2.38, 3.12, 1.74, -0.85, 5.18, -7.23, -3.51, -5.05, 4.47, -0.15, -2.38, 0.9, -3.07, -2.59, -0.89, 4.72, 2.29, 3.3635374149659865, -0.7, -0.21, 1.53, -1.04, -3.93, -3.45, -1.77, 1.79, 1.88, 3.01, 0.5, 2.3222487553150164, 1.57, 1.58, 2.01, -3.7, 2.03, 3.77, 0.9172638105244333, 3.03, 2.5, 1.74, 1.05, 1.2, 1.07, 2.93, 1.16, 0.75, 2.72, 3.75, 0.3], ['403', -4.38, 0.95, 0.04015289830927054, 0.1, -0.3, 0.44, 1.52, 0.02, 0.19, -1.29, -1.7, -1.77, -0.07, -2.02, -0.85, 0.29, -1.5, -1.5, -3.9, -0.71, -1.33, -1.94, -1.71, -1.94, -0.78, 0.64, 0.42, -0.07, 1.6808333333333332, -0.33, 0.86, 2.03, 0.2, 0.2, -2.24, 1.0, 0.37, -0.24, -0.01, -0.24, 0.05, -0.12993788819875776, 0.49, 1.811197467496117, -0.25, 1.0108150295752765, 2.1, 0.28, 0.27, -2.17, 1.08, 0.478065468086443, -0.17, 0.07, -0.17, 0.42, -0.55, 0.6, 0.15, -1.22, -1.95, -0.78, 0.36, -1.43, -1.43, -3.83, -0.64, -1.26, -1.87, -1.64, -1.87, 0.02, 0.75, 1.2, 2.36, 0.53, 0.53, -1.92, 1.34, 0.7, 0.08, 0.32, 0.08, 0.37, 0.95, -0.98, -0.44, 1.15, -0.65, -0.66, -3.08, 0.14, -0.49, -1.1, -0.86, -1.1, -1.92, -1.58, -1.78, -1.776904761904762, -4.17847619047619, -1.0, -1.62, -2.22, -1.99, -2.22, 0.08, -1.47, -0.54, 0.36, 0.37, 0.38567351865003197, 0.2109570400359874, 0.0, -2.4398412698412697, 0.8, 0.17, -0.45, -0.21, -0.45, 0.52, 0.22, -2.44, 0.8, 0.17, -0.44, -0.21, -0.44, -0.03, -0.05, 0.28, 0.35, -5.92, 0.06, 0.07, -0.72, 0.67, 0.34, -1.09, 1.40025974025974, 1.16, -0.7, -0.35, -2.34, 0.22, 1.09, -1.09, -1.07, 0.35, -1.11, 0.69, -1.17, 0.56, 0.6707142857142857, 0.0, -0.46, -0.74, -1.17, 2.72, 3.32, 2.67, 2.04, 2.28, 2.2057617128436457, 1.02, -0.5798412698412698, -0.62, -1.24, -1.0, -1.24, 0.04, -0.62, -0.38, -0.61, 0.23, 0.27, 0.66, 0.24, 0.0, 0.35, 0.34, 0.07, -0.1, 0.07, 0.08, 0.12, 0.5410935020800125, 0.43, -0.24, 0.41, -0.06, 0.12, 0.11, 0.88, 0.745957527023814, 1.6, 0.7030376647162363, 0.93], ['404', -0.16, 0.18, 0.18122171562045875, -0.02, 1.28, 0.04, 0.16, 0.67, 0.76, 0.24, -0.55, -0.41, 1.55, -0.94, -1.9, 0.17, 0.56, 0.19, -0.65, -2.45, 0.24, 1.7960714285714285, 1.2, -0.21, 1.39, 0.85, 0.8, 0.14, 2.11, -0.39, -1.35, 0.72, 1.11, 0.75, -0.09, -1.91, 0.8, 2.36, 1.77, 0.34, 0.66, -0.1, 0.66, 1.97, -0.53, -1.49, 0.58, 0.97, 0.61, -0.23, -2.04, 0.66, 2.21, 1.62, 0.2, 0.12006284630567655, 0.43, 1.01, 0.85, -1.28, -2.45, -3.39, -1.36, -0.97, -1.33, -2.16, -3.93, -1.116578845757417, 0.24, -0.34, -1.73, 1.19, 1.19, -0.97, 1.11, 1.51, 1.14, 0.3, -1.52, 1.19, 2.76, 2.16, 0.74, 0.63, -2.72, 2.69, 2.18, 2.1, 2.5, 2.13, 1.28, -0.56, 2.18, 3.76, 3.16, 1.72, 0.872095238095238, 0.08, 0.39, 0.03, -0.81, -2.61, 0.08, 1.62, 1.04, -0.37, 0.16, 0.04, -2.49, 0.06, -0.31, 0.45, -0.31, -0.36, -1.2, -2.99, -0.31, 1.23, 0.64, -0.76, -1.22, 0.05, -0.84, -2.64, 0.05, 1.59, 1.01, -0.4, -1.36, -1.41, 0.15, -0.08, 2.87, 0.1, 0.08, -1.81, 1.81, 0.9, -0.28, 1.23, -5.67, -0.19, -0.11, -0.11, -0.32, 0.22, -0.19, -0.28, 0.09, -2.71, 0.25987835724131525, 0.61, -0.3, -0.94, 1.28, 0.77, 0.91, 5.66, 0.9, -1.81, 0.9, 2.45, 2.179638579674294, 0.44, 0.26, 2.76, 2.76, 4.35, 3.74, 2.29, 0.0, 1.54, 0.96, -0.45, 0.7, 0.73, -1.52, -0.58, -1.97, 0.08, 0.03, 0.68, -0.14, 0.0, 0.14, 0.71, 0.12, -0.95, -1.4, 0.3, 0.78, -0.45, -0.06666666666666667, -0.21, 0.45, 0.34, 0.55, 0.34], ['405', 2.59, 0.66, 0.0, -0.28538095238095235, -0.1, 0.21, 0.4741152579598292, -0.09, 0.67, -0.93, -1.55, -1.17, -1.41, -1.4, 0.73, -1.18, -2.47, -1.2, -1.99, -1.41, -0.39, -2.02, -2.3, -1.49, 0.63, 0.52, 0.6626583949931124, 0.39, 0.14, 0.16, 2.32, 0.38, -0.93, 0.36, -0.44, 0.15, 1.18, -0.47, -0.76, 0.07, -0.38, 1.3949361992161733, 0.25, -0.24, -0.22, 1.93, -0.01, -1.31, -0.03, -0.82, -0.24, 0.7996547292370609, -0.85, -1.14, -0.31, 0.69, -0.31, -0.14805211528237844, 0.45, 0.49, 0.12310472253556064, 2.18, 0.24, -1.07, 0.22, -0.58, 0.0, 1.04, -0.61, -0.9, -0.07, 0.54, 0.47, 2.16, 0.22, -1.09, 0.2, -0.6, -0.01, 1.02, -0.63, -0.91, -0.09, 0.99, 3.58, -3.66, -1.65, -1.9, -3.18, -1.92, -2.7, -2.13, -1.12, -2.73, -3.01, -2.2, 0.5012233560090703, 0.25, -1.3, -0.02, -0.81, -0.23, 0.8, -0.84, -1.13, -0.31, 0.28, 0.26, -0.33, 0.65, 0.62, 0.67, 1.58, 1.3, 0.5, 1.09, 2.13, 0.47, 0.18, 1.0685846838830657, 0.88, 0.27, -0.79, -0.21, 0.82, -0.82, -1.11, -0.29, 1.36, 1.6, -0.31, 0.77, 0.71, 0.12, 0.28, -1.72, 1.78, 0.9, 0.55, -0.31, -0.93, -1.32, -0.66, 1.3, 0.19, 1.95, -1.95, -1.96, 0.64, -2.56, 1.28, 2.78, -1.37, 4.77, 0.34, -3.25, -4.7, 0.87, 1.08, 0.59, 1.63, -0.03, -0.32, 0.51, 1.97, 0.49, 1.03, -0.61, -0.9, -0.08, -0.54, -1.5411214088935783, -1.91, -1.1, 0.64, 0.72, 1.11, -0.29, 0.54, 0.65, 0.7, -0.22, -6.23, 0.65, 6.25, 0.97, 0.74, 1.4, 0.83, 0.34, 0.8002197802197802, 0.09, -0.12, 0.14, 0.56, 2.9, 1.53, 0.52], ['406', -11.77, 0.0, -0.08, -0.08, -0.74, -0.02, -0.67, 0.52, -0.65, 0.1, 1.03, 1.44, -0.34, 0.89, -0.3, 4.37, 0.5, 0.02, -2.24, 0.64, -0.5, 0.0, -0.17, -0.18, 0.4, -0.03, -0.93, 0.41, -1.35, -0.14, -1.32, 3.31, -0.53, -1.0, -3.229285714285714, -0.39, -1.51, -1.02, -1.19, -1.2, 0.33, -0.48, -1.33, -1.75, -0.55, -1.72, 2.89, -0.93, -1.4, -3.63, -0.79, -1.91, -1.42, -1.4928571428571429, -1.6, 1.24, 1.09, 1.71, -0.11, 0.44, 1.23, 0.04, 4.73, 0.84, 0.4626050661400617, -1.8013219954648525, 0.98, -0.16, 0.34, 0.16, 0.16, 2.02, -0.78, -1.18, 3.45, -0.39, -0.86, -3.1, -0.25, -1.2169183673469388, -0.88, -1.05, -1.0064403582748793, -0.72, 0.81, -0.83, 0.4, 4.69, 0.8, 0.32, -1.94, 0.94, -0.2, 0.3, 0.13, 0.12, -3.58, -4.1, -3.71, -4.17, -6.33, -3.58, -4.67, -4.19, -4.36, -4.36, 0.09, -4.17, 3.29, 0.0, 0.03, 0.0, -0.4, -0.48, -2.72, 0.14, -0.99, -0.5, -0.67, -0.68, 0.18, 0.07, -2.26, 0.62, -0.34139698000412266, -0.02, -0.19, -0.2, 0.58, 0.53, 0.03, 0.08, -10.58204761904762, 0.2, 0.17, -0.03, -0.01, 0.0, -0.3, -0.15, 1.06, 0.0, -0.02, -5.73, 0.27, 0.05, -0.05, -0.02, -0.01, 0.0, 0.02, 1.28, -0.65, -1.2, -2.0, 0.85, 1.22, -1.16, 2.39, 2.94, 1.78, 2.29, 2.4296385796742936, 2.1, 0.0, -0.54, -1.13, -0.64, -0.81, -0.81, 0.6, 0.5, 0.33, 0.32, -0.63, -0.47, 0.1, -0.17, -0.18, 0.0, -0.01, 0.51, -3.27, 2.01, 3.18, -1.57, -0.59, 0.27, -0.01, -0.08, 0.0, 0.56, 0.7702244897959184, -0.11, 0.28, -1.7, -1.26, -0.72], ['407', -2.11, -0.3, 0.08015289830927054, -0.12, -0.44, 0.81, 0.36, 0.56, 0.68, -0.57, -1.76, -0.52, -1.05, -1.24, -1.11, -0.36, -1.64, -0.85, 0.42, -0.16, -0.23, -0.79, -1.28, -0.91, 0.91, 0.63, 1.2, 1.26, 0.71, 0.53, 0.66, 1.42, 0.11, 0.92, 2.22, 1.63, 1.55, 0.99, 0.5788796134390451, 0.86, 0.8574684253532109, 1.7949361992161734, -0.05, -0.54, -0.72, -0.59, 0.16, -1.13, -0.33, 0.95, 0.36, 0.29, -0.27, -0.77, -0.39, 0.5900628463056766, 0.28, 0.29, 0.25, 0.49, -0.18, -0.05, 0.71, -0.6, 0.21, 1.49, 0.91, 0.83, 0.27, -0.23, 0.15, 0.98, 0.67, 0.13, 0.89, -0.41, 0.39, 1.68, 1.09, 1.02, 0.46, -0.05, 0.33, 1.33, 1.72, -1.75, 0.5766982383853202, 0.76, -0.54, 0.26, 1.55, 0.96, 0.88, 0.32, -0.18, 0.2, 0.02, -0.22, -1.29, -0.5, 0.78, 0.2, 0.12, -0.43, -0.93, -0.55, 0.28, -0.24, 0.68, 0.87, 0.65, 1.075673518650032, 1.09, 0.81, 2.1, 1.51, 1.44, 0.87, 0.44598786341555263, 0.8085846838830657, 0.2, 0.28, 1.28, 0.7, 0.62, 0.1957995496566927, -0.44, -0.06, 0.47, 0.69, -0.27, 0.55, 0.24, 0.1, 0.03, -3.28, 3.26, 1.64, -0.12, 0.52, 0.8277589791161221, -1.77, -0.87, -1.01, 0.42, 2.68, -2.71, -2.68, 0.87, -4.94, 1.76, 1.72, -0.86, 3.22, -5.13, -2.22, -3.16, -0.77, -0.99, -0.58, -0.4527867132867132, -1.2, -1.7, -1.33, 2.7, -0.41, -0.07, -0.63, -1.13, -0.75, -0.34, -0.56, -1.05, -0.68, 0.67, 0.8, 0.21, -0.5, -0.12, 0.89, 0.86, 0.57, -3.15, 0.02, 3.14, 0.94, 0.76, 0.72, 0.38, 0.58, 1.7, 0.39, 0.29, 1.16, 0.34, 1.75, 0.74, 0.53], ['408', 3.41, -0.08, -0.14877828437954127, 0.16, -1.45, -0.05, -0.49, -0.61, 0.0, -0.13, -0.33, 0.15, 0.93, 1.77, 1.0, -0.29, -0.33, 0.17, 1.27, 1.37, 0.48, 0.91, -0.13, -0.34, -1.55, -0.3, 0.19, 0.48, 1.26, 2.1, 1.33, 0.04, 0.0, 0.5, 1.6, 1.7, 0.81, 1.24, 0.19, -0.01, -0.75, 0.9749361992161734, -0.28, 0.77, 1.61, 0.84, -0.44, -0.48, 0.02, 1.11, 1.22, 0.33, 0.75, -0.28, -0.49, 0.25006284630567654, -0.71, -0.93, -0.01, -1.05, 0.83, 0.07, -1.2, -1.24, -0.75, 0.34, 0.44, -0.44, -0.02, -1.05, -1.25, -2.1, -1.87, -0.75, -2.02, -2.06, -1.57, -0.49, -0.39, -1.26, -0.84, -1.87, -2.07, 0.42, 0.67, -0.62, -1.12, -1.27, -1.31, -0.82, 0.5057885487528346, 0.37, -0.51, -0.09, -1.12, -1.32, 1.31, 0.2273665312165629, -0.04, 0.46, 1.56, 1.66, 0.77, 1.2, 0.15, -0.05, -0.22, 0.2, -0.09, 0.05, -0.16, 0.24, 0.2, 0.5, 1.6, 1.7, 0.81, 1.24, 0.2, -0.01, -0.9, -0.3, 1.1, 1.2, 0.31, 0.74, -0.3, -0.51, -0.09, 0.91, 0.09, -0.14, 2.64, -0.03, -0.02, -1.11, 1.08, 0.55, 0.86, -1.1797402597402598, 2.8787161013589584, -0.13, -0.05, 1.73, -0.16, 0.11, -0.08, -0.17, 0.1, -1.58, 0.1, -0.28, 0.13, 0.49, 0.8686904761904761, -0.46, -0.57, -2.85, -1.38, 0.1, -0.78, -0.36, -1.38, -1.58, 0.25, -1.48, -0.88, -0.46, -1.48, -1.68, -0.61, 0.43, -0.61, -0.81, 0.0, 0.21, -1.03, -1.03, -1.23, 0.02, 0.09, -0.79, 0.46, 0.16, -0.96, -0.27, -1.36, 0.0, -0.2, 0.3, 0.75, 0.23, -0.49, -0.23, 0.2, -0.78, -1.55, 1.0930167737073972], ['409', 5.44, 0.21, 0.29, -0.17, 1.32, 3.36, 2.4941152579598294, 5.13, 4.14, 3.63, -2.33, 1.0393248299319728, 0.34, -1.04, -1.56, 1.9, -0.8, 2.58, 4.85, 3.07, 4.52, 0.26, -0.81, 1.49, 5.29, 3.6, 6.132658394993112, 3.44, 2.73, 1.32, 0.8, 4.33, 1.56, 5.03, 7.35, 5.53, 7.02, 2.66, 1.55, 3.963841723197839, 3.39, 5.0, 2.57, -0.68, -2.05, -2.56, 0.86, -1.81, 1.54, 3.78, 2.02, 3.46, -0.76, -1.82, 0.46, 5.25, 4.55, 3.29, 3.89, 3.28, -1.37, -1.88, 1.56, -1.14, 2.24, 4.49, 2.72, 4.17, -0.07, -1.15, 1.15, 5.0, 4.72, -0.52, 2.97, 0.24, 3.66, 5.95, 4.15, 5.62, 1.32, 0.23, 2.6135596417251206, 5.36, 12.29, -12.37, 5.260870922661994, 3.51, 0.76, 4.2, 6.5, 4.69, 6.17, 1.85, 0.75, 3.1, 4.98122335600907, 1.7, -2.65, 0.67, 2.89, 1.14, 2.632626537352693, -1.61, -2.66, -0.4, 1.26, 1.9493682032253463, 4.6, 3.21, 3.38517906963434, 3.09, 4.47, 3.41, 5.7, 3.9, 5.37, 1.08, -0.01, 2.32, 3.3, 1.02, 2.21, 0.47, 1.89, -2.26, -3.31, -1.06, 4.33, 5.05, 0.37, 3.84, 9.37, 0.5803231292517006, 0.81, -5.78, 5.78, 2.91, 1.61, 5.15, -1.0094817511227283, -6.49, -3.21, 2.84, 2.0, 9.880596861471862, -9.66, -9.61, 3.19, -8.77, 6.37, 2.45, -1.19, 13.35, -14.71, -8.9, -13.33, 1.14, -1.16, -1.7, -0.31, -4.37, -5.4, -3.2, 9.6, 0.54, 1.41, -2.72, -3.76, -1.53, -0.85, -4.07, -5.1, -2.9, 4.32, 4.63, 3.35, -1.07, 1.23, 3.22, 3.29, 5.1, -7.43, 4.26, 7.65, 4.41, 4.27, 4.5586374482009715, 2.33, 4.3, 2.96, 1.93, 1.74, 2.54, 2.1, 7.83, 4.61, 2.12], ['410', 2.09, 0.62, 0.09122171562045875, -0.17, 0.28, 0.93, 0.22, 1.39, 1.3093780543870106, 2.22, 0.92, 2.16, 0.94, 0.8, 1.04, 1.86, 1.91, 2.52, -1.79, 1.74, 2.45, 3.7130748299319727, 1.41, 1.94, 1.39, 1.07, 1.28, 1.23, 0.02, -0.12, 0.11, 0.93, 0.98, 1.7072589041444086, -2.69, 0.81, 1.594453670078569, 2.76, 0.48, 1.0, 1.1, 2.41, 0.05, -1.2, -1.33, -1.1, -0.3, -0.24, 0.35, -3.87, -0.41, 0.28, 1.52, -0.74, -0.22, 1.65, 0.75, 1.12, 1.09, 1.27, -0.13, 0.1, 0.91, 0.97, 1.57, -2.7, 0.8, 1.5, 2.75, 0.46, 0.99, 1.56, 1.41, 0.6502278911564625, 1.05, 1.1, 1.71, -2.57, 0.93, 1.64, 2.89, 0.6, 1.12, 1.57, 1.71, -1.59, 1.17, 0.81, 0.87, 1.47, -2.8, 0.7, 1.4, 2.65, 0.37, 0.89, 0.71, 0.35, 0.05, 0.66, -3.58, -0.11, 0.58, 1.82, -0.44, 0.08, -0.39, 0.46, -0.34, 0.66, 0.58, 0.45, 0.3, 0.6, -3.63, -0.17, 0.53, 1.76, -0.5, 0.02, -1.2, -0.3, -4.21, -0.76, -0.07, 1.16, -1.09, -0.57, 0.11, -0.31, -0.17, -0.64, 2.04, -0.36, 0.23, -0.4, 0.41, 0.22, 0.13, 2.44, -0.96, -1.25, -0.64, 1.02, 0.3430797898687791, 1.9, -1.96, -1.95, 0.65, -0.63, 1.36, -0.07160934502005914, -0.16, 0.88, -3.37, -0.6, -0.94, 0.97, 4.08, 3.6, 4.32, 5.6, 3.25, 3.79, 2.0, 0.47, 0.7, 1.94, -0.33, 0.19, -0.23, 1.23, -1.02, -0.5, 1.19, 1.32, -1.44, -2.22, -1.71, 0.62, 0.5, 1.39, -1.76, -0.32, 1.7021428571428572, 0.82, 1.2010935020800126, 0.8, 0.52, 0.71, 0.28, 0.8, 0.1, 0.84, 0.28, 1.03, 1.31, -0.05], ['411', -1.3, -0.59, -0.10877828437954125, -0.03, -1.18, -0.71, -4.9, -1.97, -1.33, -2.82, -1.75, -0.77, -1.68, -0.29, -0.94, -2.111439909297052, -1.76, -2.19, -1.21, -1.55, -2.16, -1.57, -1.34, -1.92, -1.67, -0.87, -1.09, 0.99, 0.08, 1.49, 0.82, -0.69, 0.6328571428571429, -0.45, 0.55, 0.21, -0.41, 0.18, 0.42, -0.17, -1.68, -1.74, -2.06, -0.91, 0.49, -0.17, -1.67, -0.99, -1.43, -0.44, -0.78, -1.4, -0.8, -0.57, -1.16, -1.0, -0.76, -0.862172027190216, -1.01, -1.16, 1.41, 0.75, -0.76, -0.08, -0.52, 0.47, 0.13, -0.49, 0.11, 0.34, -0.25, -1.38, -2.54, -0.6592857142857144, -2.1485714285714286, -1.48, -1.91, -0.93, -1.26, -1.88, -1.29, -1.06, -1.64, -1.36, -4.07, 4.06, -1.9, -1.5, -0.82, -1.26, -0.27, -0.61, -1.23, -0.64, 0.05251700680272092, -0.99, -1.34, -0.4, 0.69, 0.24, 1.2415238095238095, 0.9, 0.28, 0.88, 1.11, 0.52, -0.61, -0.45, -2.01, -0.93, -1.03, -0.8, -1.08, -0.44, 0.55, 0.21, -0.41, 0.19, 0.42, -0.17, -1.28, -0.65, 1.0, 0.66, 0.03, 0.63, 0.87, 0.27, -1.09, -1.18, -0.22, -1.11, -3.8578571428571427, -0.96, -1.09, 1.59, -1.64, -0.85, -1.4, -2.49, 2.57, 1.83, 0.9745476190476191, -0.66, -0.67, -2.75, 2.8, 2.74, -0.92, 2.5, -1.83, -1.69, 0.83, -3.26, 10.0, 2.16, 3.25, -2.54, -1.63, -0.34, -0.96, -0.36, -0.13, -0.72, -2.74, -1.29, -0.62, -0.03, 0.21, -0.38, -0.68, 0.6, 0.84, 0.24, -1.34, -1.12, -1.27, 0.24, -0.35, -0.9, -0.96, -2.08, 5.86, -1.72, -5.67, -1.11, -1.53, -1.5, -0.59, -0.89, -0.79, -0.3, -0.47, -0.6, -0.92, -1.77, -2.05, -0.89], ['412', -1.51, 0.35, 0.08, -0.18, 0.48, 0.25, 0.21, 0.26, 0.33, 1.66, 0.58, 2.69, 1.96, -0.04, 1.5, 2.04, 1.4, 1.57, -1.17, 0.61, 2.21, 1.93, 1.16, 1.6, 0.37, 0.31937141458889196, 1.08, 2.1, 1.38, -0.61, 0.92, 1.46, 0.82, 0.98, -1.73, 0.04, 1.62, 1.35, 0.58, 1.02, 0.62, 1.12, -1.0, -0.71, -2.65, -1.15, -0.63, -1.25, -1.09, -3.75, -2.02, -0.47, -0.74, -1.49, -1.05, 0.39, 0.51, 0.14, 0.08, -0.29, -1.96, -0.45, 0.08, -0.55, -0.39, -3.052819727891156, -1.32, 0.24, -0.03, -0.79, -0.35, -0.75, 1.7, 1.5407142857142857, 2.08, 1.44, 1.6, -1.13, 0.65, 2.25, 1.97, 1.2, 1.64, 1.16, 1.05, -1.09, 0.16, 0.53, -0.1, 0.06, -2.63, -0.88, 0.69, 0.42, -0.34, 0.1540077275244506, -0.69, -0.37, -0.63, -0.47, -3.15, -1.4, 0.16, -0.11, -0.87, -0.43, 0.09, -0.44, 0.21, 0.17, 0.27, 0.09, 0.26, 0.16, -2.53, -0.78, 0.8, 0.52, -0.24, 0.2, -0.22, 0.15307674813036726, -2.69, -0.94, 0.8086030199958774, 0.36, -0.4, 0.04, 0.91, 0.78, -0.27, 0.22, -2.37, 0.05, -0.03, -0.26, 0.31, 0.15, 0.2, -0.11, -2.17, -0.37, -0.16, -0.75, -0.07, 0.48, -0.58, -0.51, 0.17, -0.44, 0.35, 1.61, -0.77, 0.75, -2.97, -0.48, -0.8, 2.09, 2.86, 1.8, 3.42, 3.14, 2.35, 2.81, 0.5, 1.04, 1.59, 1.31, 0.54, 0.99, -0.53, -0.27, -1.03, -0.59, 0.3, 0.84, -0.26, -0.76, -0.32, 0.16, 0.19, 0.31, -1.56, -0.23, 1.64, 0.5372638105244333, 0.6610935020800125, 0.5, 0.44, 0.1, 0.15, -0.08, -0.35, 0.04, 0.06, 0.86, 2.27, 0.42], ['413', 3.007142857142857, -0.58, 0.13122171562045873, 0.26, 0.88, -0.52, 0.28, 0.57, 0.7, -0.83, -1.72, -1.29, -0.9, -1.26, -1.96, -0.98, -0.33, -1.2, -0.46, -1.75, -0.02, -1.18, -0.84, -0.54, 1.09, -0.46, 0.9, 0.44, 0.83, 0.47, -0.24, 0.76, 1.41, 0.53, 1.28, -0.03, 1.73, 0.55, 0.9, 1.2, 0.38, 1.22, 0.4602040816326531, 0.39, 0.03, -0.68, 0.32, 0.97, 0.09, 0.9371355564861203, -0.47, 1.28, 0.11, 0.45, 0.76, 0.2, 0.91, 1.44, 1.0, 0.07, -0.36, -1.07, -0.08, 0.57, -0.3, 0.45, -0.85, 0.89, -0.28, 0.06, 0.36, 0.56, 0.43, -0.71, 0.29, 0.94, 0.06, 0.81, -0.49, 1.25, 0.08, 0.43, 0.73, 0.62, 0.52, -0.51, 1.15, 1.0, 1.66, 0.78, 1.53, 0.22, 1.98, 0.8, 1.14, 1.45, 0.35, 0.15, 0.65, -0.22, 0.52, -0.78, 0.96, -0.2, 0.14, 0.44, 0.26, 0.16, -1.54, -0.21, -0.16, -0.21432648134996807, -0.5, -0.87, -0.13, -1.42, 0.3106802721088435, -0.85, -0.51, -0.21, 0.1, 0.37, 0.75, -0.56, 1.19, 0.02, 0.36, 0.67, -0.21, -0.98, 0.5, -0.46, 0.61, 0.15, 0.42, -0.59, 0.63, 0.31, -0.1, 1.41, -1.83, 0.41, 0.22, 1.871438775510204, -0.28, -0.63, 0.64, 0.75, -0.22, -0.8, -0.44, -1.41, 0.74, -1.51, 3.5, 1.0, 1.43, 1.86, -0.3516360544217687, -1.29, 0.44, -0.72, -0.38, -0.08, -0.5468321004392431, 0.93, 1.76, 0.58, 1.3394625850340136, 1.23, -0.81, -1.16, -0.82, -0.52, 0.74, 0.86, 0.35, 0.35, 0.65, -0.23, -0.27, 0.61, 1.68, -1.31, -1.88, -0.73, 0.11, 0.01, 0.3, -1.77, 0.54, 0.015297952047952229, -0.27, -0.62, -0.29, -1.67, 0.31, 0.77], ['414', -1.9, -0.17, -0.04877828437954125, -0.14, -0.24, 0.55, 1.15, 0.51, 0.06, 0.94, 0.63, 0.3, 0.9, 1.02, 0.7, 1.33, 0.0, 1.04, -0.93, 1.27, 0.55, 0.65, -0.42, 0.06, -0.11, -0.18, 0.34265839499311246, -0.33, 0.26, 0.38, 0.07, 0.69, -0.63, 0.4, -1.55, 0.63, -0.09, 0.02, -1.05, -0.57, -0.15, 0.4249361992161734, 0.64, 0.6, 0.72, 0.4, 1.03, -0.3, 0.74, -1.22, 0.97, 0.25, 0.35, -0.72, -0.24, 0.24, 0.14, 0.43, 0.3, 0.04, 0.11, -0.2, 0.43, -0.89, 0.14, -1.81, 0.37, -0.35, -0.25, -1.31, -0.83, 1.57, -0.07, -0.31, 0.31, -1.0, 0.02, -1.92, 0.25, -0.46, -0.36, -1.43, -0.95, 0.03, 3.8, -3.83, 0.24, 0.62, -0.7, 0.34, -1.62, 0.56, -0.15, -0.05, -1.12, -0.64, -0.86, -0.38, -1.31, -0.29, -2.23, -0.06, -0.77, -0.67, -1.73, -1.25, 0.09, -0.26063179677465376, 1.4, 0.8715981806829014, 0.89, 0.825673518650032, 0.94, 1.04, -0.93, 1.27, 0.55, 0.65, -0.43, 0.06, 0.38, -0.1, -1.95, 0.23, -0.49, -0.38, -1.45, -0.97, 1.2, 0.91, -0.13, 0.93, -2.6, -0.26, -0.26, -0.7, 0.67, 0.37, -0.4, -0.07, 0.67, -1.6, -0.82, -0.88, 0.72, 2.38, -2.35, -2.38, 0.81, -1.02, 1.61, 1.04, -0.51, 2.82, -0.38, -1.83, -2.81, -0.61, 1.89, 2.22, 1.49, 1.59, 0.51, 1.0, 2.42, -0.32, -0.72, -0.61, -1.67, -1.19, 0.39, 0.11288492856349999, -0.97, -0.48, 0.19, 0.24845354645354667, 0.29, -1.07, -0.59, 0.8, 0.83, 0.44257604962387836, -0.19, 1.16, 0.13, 1.02, 0.98, 1.37, 0.49, 0.92, 0.3345528598385743, 0.9, 0.45, 0.82, 0.965957527023814, -0.49, 1.59, 1.08], ['415', -2.6, -0.29, 0.13122171562045873, -0.13, 0.78, 0.9, 0.49411525795982914, 0.26, 0.37, -0.61, -0.7993911564625851, -1.28, -1.22, -0.65, -0.84, -0.6, -1.5, -0.97, -11.0, -1.93, -0.43, -1.85, -1.44, -1.72, 0.09, 0.12, 0.21, -0.47, -0.41, 0.17, -0.03, 0.22, -0.69, -0.16, -10.27, -1.13, 0.38, -1.04, -0.64, -0.91, -0.05, 1.9608975626058773, 0.68, 0.06, 0.64, 0.44, 0.69, -0.22, 0.31, -9.85, -0.67, 0.85, -0.58, -0.07285714285714287, -0.45, -0.01993715369432346, 0.0, 0.26, 0.47, 0.62, 0.6831047225355606, 0.38, 0.63, -0.28, 0.25, -9.9, -0.72, 0.8, -0.64, -0.23, -0.5, 0.61, 0.04, -0.2, 0.05, -0.86, -0.33, -10.42, -1.29, 0.22, -1.21, -0.8, -1.08, 0.88, 2.57, -2.63, 0.24, 0.25, -0.66, -0.13, -10.25, -1.1, 0.41, -1.01, -0.6, -0.88, -0.38, -0.01, -0.91, -0.38, -10.47, -1.35, 0.16, -1.26, -0.85, -1.13, 0.62, 0.06, 2.79, 0.78, 0.93, 0.59, 0.9009570400359874, 0.53, -9.65, -0.44, 1.08, -0.36, 0.05, -0.22, 1.19, 0.36, -10.13, -0.97, 0.54, -0.89, -0.48, -0.75, 0.95, 0.85, -0.15, 0.72, -1.17, 0.14, 0.13, -0.74, 0.74, 0.4088101710076211, 0.63, 1.09, -2.6, -1.57, -0.81, -1.29, 0.78, 2.45, -2.3, -2.31, 0.833290804863853, -1.08, 1.57, 0.45, -0.26, 2.7, -2.59, -1.91, -2.64, 2.6, 11.68, 10.517178777571635, 11.88, 10.29, 10.74, 10.43, 2.4208051948051947, 1.35, 1.53, 0.09, 0.5, 0.22, -0.18, -1.42, -1.02, -1.29, 0.37, 0.56, 1.26, 0.41, 0.14, 0.84, 0.8, 0.29, -2.14, 1.84, 2.29, 0.35, 1.26, 0.85, -0.28, 0.55, 0.29, 1.1, 0.64, 1.15, 1.13, 0.44, 2.04, 1.49], ['416', 4.501428571428571, -0.63, -0.08, -0.13, 0.49, 0.48, 1.45, 0.75, 0.79, -0.05, -1.16, -0.74, -0.75, -0.48, -1.2, -0.33, -0.23, -0.35, 0.78, -1.15, 0.27, -0.02, -1.16, -0.74, 0.84, 0.969371414588892, 1.12, 0.42, 0.42, 0.69, -0.04, 0.84, 0.94, 0.83, 1.96, 0.01, 1.524453670078569, 1.15, 0.0, 0.42, 0.26, 1.99, 0.7, 0.0, 0.4378753944468231, -0.46, 0.42, 0.52, 0.4, 1.53, -0.41, 1.02, 0.73, -0.42, 0.0, 0.37, 0.76, 0.95, 0.78, 0.7, 0.27, -0.45, 0.42, 0.52, 0.4, 1.54, -0.41, 1.02, 0.73, -0.42, 0.0, 0.45, 0.43, -0.72, 0.15, 0.25, 0.13, 1.26, -0.68, 0.75, 0.46, -0.69, -0.21644035827487929, 1.24, 2.66, -2.7, 1.19669823838532, 0.88, 0.98, 0.86, 2.0, 0.05, 1.48, 1.19, 0.04, 0.46, 2.83, 0.28, 0.1, -0.02, 1.11, -0.82, 0.6, 0.5528169964955679, -0.83, -0.42, 0.43, 0.24, 3.05, 0.65, 0.82, 0.43567351865003195, 0.18, -0.11, 1.01, -0.92, 0.5, 0.21, -0.93, -0.51, 0.14, 0.29, 1.13, -0.81, 0.62, 0.33, -0.82, -0.4, 1.0189583699631244, 0.65, -0.08, 0.26, 8.541102040816327, 0.15, 0.02, -0.51, 0.52, 0.30881017100762115, -0.63, 1.96, -2.23, -1.25, -0.65, 2.6014387755102044, 0.25, 1.95, -1.88, -1.88, 0.63, -0.77, 1.27, 1.56, -0.76, 0.58, -3.25, -0.44, -0.62, 2.21, -0.82, -1.91, -0.5, -0.79, -1.92, -1.51, 1.9, 1.1101587301587303, 1.44, 1.14, -0.01, 0.41, -0.32, -0.29, -1.42, -1.01, 0.83, 0.92, -0.03, -1.14, -0.72, 0.64, 0.53, 0.76, -0.66, 2.08, 0.66, 0.52, 1.06, 1.12, 0.42, 0.82, 0.31, 0.11, 0.5, 0.37, 0.7, 1.2, 0.87, -0.05], ['417', -4.34, -1.12, -0.09, 0.08, -0.96, -1.03, -1.825884742040171, -2.03, -1.95, -3.62, -1.57, -2.28, -0.12, -1.65, -0.99, -1.56, -2.68, -3.3, -3.85, -2.41, -3.78, -3.18, -2.4, -1.98, -2.32, -2.61, -2.08, -0.72, 1.48, -0.08, 0.6, 0.02, -1.12, -1.76, -2.31, -0.85, -2.24, -1.63, -0.84, -0.42, -1.27, -2.59, -1.37, 2.21, 0.65, 1.32, 0.75, -0.4, -1.05, -1.61, -0.13, -1.53, -0.92, -0.12, 0.3, -0.41, -0.86, -1.86, -2.369047619047619, -3.51, -1.53, -0.87, -1.44, -2.56, -3.087394933859938, -3.74, -2.29, -3.66, -3.06, -2.28, -1.87, -1.65, -2.0, 0.67, 0.1, -1.04, -1.68, -2.24, -0.77, -2.006918367346939, -1.56, -0.76, -0.34, -1.96, -3.42, 3.39, -2.66, -0.57, -1.71, -2.34, -2.89, -1.44, -2.82, -2.21, -1.43, -1.01, -4.05, -2.1, -1.14, -1.78, -2.33, -0.87, -2.26, -1.65, -0.86, -0.44, -0.35, -2.12, -1.78, -1.09, -1.01, -1.23, -0.97, -0.64, -1.21, 0.27, -1.13, -0.52, 0.28, 0.7685846838830657, -0.48, -0.27692325186963274, -0.57, 0.92, -0.480437641723356, 0.13, 0.94, 1.36, -1.08, -0.5, 0.19, -1.09, -12.24, -0.08, -0.07, 2.2, -2.2, -1.08, 0.2, -1.17, 2.53, 2.09, 1.09, -2.19, -0.41, -3.29, 3.26, 3.21, -1.06, 3.27, -2.19, -1.38, 0.68, -2.9, 6.6, 2.08, 2.8, -2.55, 0.24, 1.5, 0.08, 0.7, 1.51, 1.94, -3.29, -1.24, -1.4, -0.79, 0.01, 0.44, 0.16, 0.62, 1.43, 1.86, -1.94, -2.09, -0.46, 0.8, 1.23, -1.12, -1.12, -1.88, 3.91, -1.82, -3.97, -1.65, -2.0, -1.25, 0.43, -1.01, -1.02, -0.32, -0.06, -0.54, -1.67, -2.87, -2.86, -1.18], ['418', -0.13, 0.07, -0.2, -0.11, -0.96, -0.3315803763262405, -0.51, -0.66, -0.24, -1.3029115646258504, -2.16, -1.11, -1.75, -1.62, -0.14, -1.34, -1.59, -1.75, -3.69, 0.84, -1.84, -1.84, -1.88, -1.98, -0.78, -0.29, 0.42, 1.08, 0.42, 0.55, 2.06, 0.84, 0.58, 0.42, -1.56, 3.07, 0.32, 0.33, 0.29, 0.19, -0.75, -0.8850638007838266, -0.65, -0.65, -0.52, 0.98, -0.23, -0.49, -0.65, -2.61, 1.97, -0.74, -0.73, -0.78, -0.88, -0.21, -0.54, -0.7, 0.06, 0.0, 0.13, 1.640799319727891, 0.42, 0.16, 0.0, -1.97, 2.64, -0.09, -0.08, -0.13, -0.23, -0.25, -0.13, 1.5, 0.29, 0.03, -0.13, -2.1, 2.5, -0.23, -0.22, -0.26, -0.36, 0.13, 0.18, -0.28, -1.61, -1.2, -1.45, -1.61, -3.55, 1.173744771101914, -1.7, -1.69, -1.74, -1.84, -1.29, -0.3426334687834371, -0.26, -0.42, -2.38, 2.2, -0.4473734626473065, -0.51, -0.55, -0.65, -0.11, -0.39, 2.39, -0.34, -0.28, -0.3, -0.16, -0.16, -2.13, 2.47, -0.0742217465074606, -0.25, -0.29, -0.39, 0.08, 0.053076748130367266, -1.97, 2.64, -0.09, -0.08, -0.13, -0.23, 0.61, 0.78, -0.11, 0.05, -4.02, 0.04, 0.16, 0.86, -0.84, -0.42, -0.79, -0.66, 5.07, 0.69, 0.4, -0.03, -0.31, -1.07, 1.12, 1.11, -0.35, 1.26, -0.7, 1.12, -0.56, -0.29, -0.94, 0.24, 0.46, -5.12, 2.0, 4.7, 1.91, 1.92, 1.87, 1.77, -0.95, -2.57, -2.66, -2.65, -2.7, -2.79, 0.09, 0.01, -0.04, -0.14, -0.33, 0.0, 0.08, -0.05, -0.14, -0.35, -0.32, -0.64, -0.28, 1.85, 0.22, -0.28, -0.91, 0.13, -0.1, -0.36, -0.91, -0.06, -0.6, 0.2, 0.23, -1.4, -0.81, -0.26], ['419', -1.77, -0.36, -0.2, 0.07, -1.96, -1.04, -1.61, -2.46, -2.12, -2.82, 0.51, -1.44, -1.5060867348791511, -0.16, -0.83, -2.33, -1.32, -2.53, -2.35, -0.25, -3.07, -1.96, -1.79, -1.44, -2.18, -1.5106285854111081, -3.31, -1.94, -2.07, -0.66, -1.33, -2.82, -1.82, -3.03, -2.85, -0.75, -3.56, -2.45, -2.29, -1.94, -1.86, -2.72, -1.4, -0.13, 1.3, 0.62, -0.9, 0.12, -1.11, -0.93, 1.21, -1.65, -0.52, -0.36, 0.0, -0.76, -1.36, -2.88, -2.32, -1.27, 1.44, 0.7507993197278912, -0.77, 0.26, -0.8773949338599383, -0.8, 1.4639757335335069, -1.52, -0.39, -0.23, 0.13, -2.83, -2.67, -0.68, -2.18, -1.16, -2.38, -2.2, -0.1, -2.92, -1.8, -1.64, -1.29, -2.75, -3.11, 3.07, -2.0, -1.51, -0.49, -1.71, -1.53, 0.59, -2.26, -1.13, -0.97, -0.61, -2.24, -0.4226334687834371, 1.03, -0.21, -0.03, 2.13, -0.76, 0.38, 0.55, 0.91, -0.33, -0.42, 0.89, -1.15, -1.15, -1.15, -1.52, -1.0934006093113235, -1.05, 1.08, -1.78, -0.65, -0.48, -0.13, -0.76, -0.29, 0.19, 2.34, -0.55, 0.59, 0.76, 1.12, -1.45, -1.44, -0.2839628211219596, -1.34, -6.58, -0.46, -0.65, 2.65, -2.72, -1.35, 0.27, -4.3, 5.08, 2.21, 1.13, -0.91, -1.01, -3.45, 3.39, 3.45, -1.13, 4.01, -2.28, -1.06, 0.47, -4.48, 13.09, 3.02, 4.42, -5.15, -0.47, 2.15, -0.73, 0.41, 0.58, 0.93, -3.42, -2.57, -2.83, -1.71, -1.55, -1.2, 0.26, 1.15, 1.32, 1.68, -2.19, -2.5, -0.88, 0.17, 0.52, -1.12, -1.17, -2.31, 6.74, 0.09, -6.72, -1.55, -1.48, -1.04, 0.36, -0.4, -1.04, -1.03, -0.82, -1.36, -1.39, -1.87, -2.99, -1.27], ['420', 2.73, 0.42, 0.26, 0.01, 0.3429790809910596, 0.58, 1.214115257959829, 0.95, 1.02, 0.94, -0.02, 0.13, 0.12, 0.67, 0.41, 0.4, 0.2, 0.66, 2.6, 0.09, 0.99, 0.81, -0.23, 0.1, 0.35, 0.14, 0.9926583949931125, 0.2684685082657772, 0.14, 0.69, 0.43, 0.42, 0.23, 0.68, 2.62, 0.12, 1.01, 0.83, -0.21, 0.16384172319783916, 0.92, 1.69, 0.820204081632653, -0.01, 0.54, 0.28, 0.27, 0.08, 0.53, 2.47, -0.03, 0.86, 0.68, -0.36, -0.02, 0.41, 0.49, 0.91, 1.01, 0.82, 0.55, 0.29, 0.28, 0.08, 0.54, 2.48, -0.03, 0.87, 0.69, -0.35, -0.02, 1.06, 0.27, -0.26, -0.27, -0.46, -0.01, 1.92, -0.57, 0.32, 0.14, -0.9, -0.57, 1.33, 3.13, -3.2, 0.53, -0.01, -0.21, 0.25, 2.18, -0.32, 0.57, 0.4, -0.64, -0.31, 0.21, 0.54, -0.19, 0.26, 2.19, -0.3, 0.59, 0.41, -0.63, -0.3, 0.25, 0.55, 3.01, 0.64, 0.73, 0.62, 0.8118094764861292, 0.45, 2.39, -0.11, 0.78, 0.6, -0.43, -0.04141531611693433, 0.13, 0.28, 1.93, -0.56, 0.33, 0.15, -0.89, -0.56, 1.81, 1.77, 0.03, 0.81, 0.3, 0.28, 0.34, -1.45, 1.43, 0.7888101710076211, 0.78, 2.11, -1.71, -1.35, -0.65, 1.31, 0.06, 2.02, -2.05, -2.09, 0.65, -2.36, 1.28, 0.59, -0.34, 2.15, -3.68, -1.53, -2.28, 1.7, -1.6016360544217687, -2.44, -1.3727867132867133, -1.75, -2.76, -2.44, 1.91, 0.85, 0.89, 0.72, -0.33, 0.01, -0.05, -0.18, -1.21, -0.88, 1.02, 1.18, 0.13, -1.03, -0.7, 0.63, 0.72, 1.01, -3.19, 2.25, 3.11, 0.19, 0.81, 1.2586374482009708, 0.33, 0.94, 0.73, -0.02, -0.23, 0.31, 0.84, 0.14, 1.75, 0.25], ['421', 0.48, 0.05, -0.06877828437954125, 0.2, -0.07, -1.09, -2.72, -1.58, -2.28, -1.52, 1.34, 0.85, -0.98, 0.31, 0.03, -1.67, -0.35, -1.12, -2.77, -0.47, -2.16, -0.87, -0.15, -0.48, -1.06, -0.890628585411108, -2.82, -0.48, -2.29, -1.01, -1.29, -2.97, -1.66, -2.42, -4.05, -1.78, -3.45, -2.18, -1.47, -1.8, -1.13, -5.315063800783826, -2.34, -1.81, -0.53, -0.81, -2.5, -1.18, -1.95, -3.59, -1.3, -2.98, -1.71, -0.99, -1.32, -1.2, -1.11, -0.83, -1.79, -0.54, 1.3, 1.02, -0.7, 0.64, -0.14, -1.81, 0.52, -1.19, 0.11, 0.84, 0.5, -1.4, -1.82, -0.28, -1.98, -0.65, -1.43, -3.07, -0.78, -2.46, -1.18, -0.32690451810094656, -0.79, -3.36, -3.46, 3.38, -1.54, -1.7, -0.37, -1.15, -2.8, -0.49, -2.19, -0.9, -0.18, -0.51, 0.41, 0.16, 1.35, 0.56, -1.12, 1.23, -0.49, 0.81, 1.55, 1.21, -0.41, 0.19, 1.51, -0.88, -0.74, -0.97, -1.18, -0.78, -2.43, -0.12, -1.82, -0.53, 0.2, -0.14, -0.46, -0.4, -1.67, 0.66, -1.05, 0.25, 0.98, 0.64, -1.78, -1.28, 0.17, -0.83, 1.13, -0.09, 0.27, 1.98, -1.97, -1.0, 0.55, -1.58, 2.1, 1.64, 0.89, 0.3, -0.63, -2.62, 2.65, 2.58, -0.84, 2.94, -1.7, -2.54, 1.24, -3.49, 9.12, 2.33, 3.49, -1.9828690476190476, 1.3083639455782314, 2.37, 0.8272132867132869, 1.95, 2.7, 2.35, -2.53, -1.05, -1.7, -0.41, 0.32, -0.02, 0.66, 1.31, 2.06, 1.71, -2.197204648526077, -2.48, -0.65, 0.73, 0.39, -0.83, -0.88, -1.53, 5.1, -0.12, -5.23, -0.62, -0.15, -1.37, -0.34, -0.96, -0.86, -0.69, 0.21, -1.37, -1.04, -1.1, -0.46, -1.3], ['422', -0.06, 0.0, -0.008778284379541255, -0.05, 0.01, -0.04, 0.014115257959829165, 0.0, -0.01, 0.05, -0.03, 0.05, 0.02, -0.07, 0.08, 0.05, -0.04, 0.03, 0.0, 0.05, 0.11733548208735894, 0.07, 0.24, 0.01, 0.16, -0.04, 0.12265839499311246, 0.09, 0.06, -0.04, 0.16781997129509119, 0.09, -0.01, 0.06, 0.03, 0.09, 0.11, 0.1, 0.28, 0.08384172319783915, 0.0, 0.014936199216173434, 0.0, -0.03, -0.13, 0.03, 0.0, -0.1, -0.02, -0.05, 0.0, 0.04806546808644298, 0.02, 0.19, -0.04, 0.03, 0.07, 0.08, 0.06, 0.03, -0.1, 0.06, 0.03, -0.07, 0.0, -0.02, 0.03, 0.05, 0.05, 0.22, -0.01, -0.03, 0.13, 0.16, 0.13, 0.03, 0.1, 0.07, 0.13, 0.15, 0.14, 0.32, 0.13355964172512072, 0.0, -0.42, 0.34, 0.00669823838532016, -0.03, -0.13, -0.05, -0.08, -0.03, 0.0, -0.01, 0.16, -0.07, -0.18, 0.0, -0.1, -0.03, -0.05, 0.0, 0.02, 0.02, 0.19, -0.04, 0.11, 0.0, 0.07572371188304003, 0.01, -0.06, 0.13567351865003197, 0.1718094764861292, 0.07, 0.14693256743256752, 0.1, 0.12, 0.11, 0.29, 0.10858468388306568, 0.06, 0.02, -0.03, 0.03, 0.05, 0.04, 0.22, -0.02, 0.0, 0.04, 0.07, 0.11, 0.0, 0.02, 0.0, -0.1, 0.15, 0.14881017100762112, 0.0, 0.0, 0.07, 0.0, 0.0, 0.0, 0.11, 0.12, -0.11, -0.04, 0.02, -0.26, -0.01, 0.16, -0.11, 0.23, 0.01, -0.15, -0.31, -0.04, 0.05, 0.06, 0.08, 0.07, 0.25, 0.01, 0.04, 0.0, 0.02, 0.02, 0.19, -0.04, -0.02, -0.01, 0.17, -0.07, 0.04, 0.02, -0.02, 0.17, -0.06, 0.02, -0.01, 0.0, -0.09, 0.15019962695749933, 0.06, 0.06, -0.14, -0.19, -0.23, -0.08, -0.03, 0.0, 0.0, 0.04, 0.04, 0.02, 0.06, 0.03], ['423', -1.52, 2.0214285714285714, 0.07, 0.01, 0.44, -0.01, 1.82, 0.07, -0.17, -0.95, -0.18, -2.6, -1.78, -0.37, -1.26, -1.01, -1.34, -1.13, -3.4, -2.53, -1.15, -1.57, -1.28, -1.54, -0.25, 0.48, -0.78, -2.43, -1.61, -0.19, -1.08, -0.84, -1.16, -0.95, -3.23, -2.36, -0.98, -1.4, -1.1, -1.37, 0.08, -1.42, 1.69, 0.84, 2.29, 1.38, 1.63, 1.29, 1.51, -0.8183478664192949, 0.07119047619047619, 1.48, 1.05, 1.35, 1.08, -0.14, -0.08, -0.47, -0.53, 0.84, 1.44, 0.53, 0.78, 0.45, 0.67, -1.65, -0.76, 0.64, 0.21, 0.51, 0.24, -0.25, -0.59, -0.8753571428571428, -0.65, -0.97, -0.76, -3.04, -2.17, -0.79, -1.21, -0.91, -1.18, -0.8395238095238095, 1.54, -1.55, 0.31, 0.25, -0.06821428571428571, 0.13, -2.17, -1.29, 0.11, -0.32, 0.010976190476190473, -0.29, 0.74, 0.06, -0.33, -0.12, -2.41, -1.53, -0.0773734626473065, -0.56, -0.27, -0.54, 0.2, -0.05, 2.85, 0.43, 0.35, 0.58, 0.39, 0.21, -2.09, -1.21, 0.19, -0.17969498055271244, 0.06, -0.21, 1.1, 0.18, -2.3, -1.42, -0.03, -0.45, -0.15, -0.42, 0.58, 0.61, 0.11, 0.52, 2.09, 0.82, 0.83, -0.99, 1.05, 0.5, 4.1, 0.87, -3.2, -0.84, -0.42, -0.73, 0.67, 1.27, -1.19, -1.21, 0.41, -1.5, 0.86, -0.12, 0.1447652642842468, 1.18, -5.07, -0.86, -1.18, 3.2, 2.53, 0.9, 2.33, 1.89, 2.2, 1.92, 1.24, 1.62, 1.41, 0.98, 1.290857142857143, 1.0114285714285713, 0.2, -0.42, -0.13, -0.4, 0.010135138670853056, -0.7, 0.63, 0.3, 0.03, 0.42, 0.48, 0.07, -3.14, 2.1, 3.32, 0.17, -0.06, 0.33, -0.27, 0.28, 0.25, 0.61, 0.77, 0.83, 0.6, 0.3, 0.12, 0.2], ['424', 6.1, 1.26, 0.16, -0.08, 0.94, 0.87, 1.894115257959829, 2.08, 1.28, 4.11, 2.230608843537415, 3.47, 2.39, 2.54, 2.35, 1.91, 2.71, 3.77, 4.39, 3.32, 5.0, 2.58, 2.83, 2.96, 2.47, 1.759371414588892, 1.85, 1.22, 0.16, 0.31, 0.13, -0.31, 0.48, 1.51, 2.12, 1.08, 2.72, 0.35, 0.6, 0.72, 0.78, 2.44, 0.62, -1.04, -0.9, -1.08, -1.51, -0.73, 0.29, 0.89, -0.14, 1.48, -0.86, -0.62, -0.48495238095238097, 1.44, 1.09, 2.02, 1.17, 1.68, 0.15, -0.03, -0.47, 0.31, 1.35, 1.96, 0.92, 2.55, 0.18, 0.43, 0.56, 2.84, 1.53, -0.18, -0.62, 0.16, 1.2, 1.8, 0.76, 2.4, 0.03, 0.28, 0.4, 1.68, 3.58, -3.6, 1.72, -0.44, 0.35, 1.38, 1.99, 0.95, 2.613870161584447, 0.22, 0.9225170068027209, 0.59, 0.86, 2.16, 0.79, 1.83, 2.44, 1.39, 3.04, 0.66, 0.91, 1.03, 0.41, 2.1923568812140237, 1.06572371188304, 1.23, 1.11, 1.36, 1.36, 1.03, 1.64, 0.6, 2.23, -0.13, 0.12, 0.24, 1.46, 0.33, 0.6, -0.43, 1.19, -1.0242004503433073, -0.9, -0.78, 0.93, 1.04, -0.14, 1.26, 2.12, 0.21, 0.17, -2.56, 2.51, 1.27, 1.78, 0.85, -1.38, -2.46, -1.23, 3.44, 1.22, 3.64, -3.74, -3.7, 1.24, -3.77, 2.47, 1.37, -0.6652347357157532, 3.86, -10.36, -2.75, -4.05, 1.39, -0.27, -1.02, 0.59, -1.74, -1.49, -1.37, 3.53, 0.76, 1.62, -0.72, -0.48, -0.36, -0.85, -2.31, -2.07, -1.95, 1.37, 1.49, 1.5, 0.25, 0.37, 1.24, 1.26, 2.06, -5.55, 1.2001996269574993, 2.54, 1.82, 1.1, 1.25, 0.12, 1.17, 1.12, 1.67, 1.01, 1.23, 1.12, 0.98, 1.68, 0.85], ['425', 2.41, 0.29, 0.08, 0.14, 0.59, -0.18, -0.6858847420401708, -0.44, -0.02, 0.9, 1.6, 1.5293248299319728, 1.26, 1.22, 1.02, 1.03, 1.53, 1.0, -4.42, 1.63, 0.77, 0.45, 1.32, 1.475116627420199, 0.13, 0.11, -0.6573416050068874, -0.08, -0.34, -0.37, -0.57, -0.57, -0.07, -0.47274109585559154, -5.93, 0.02, -0.82, -1.13, -0.28, -0.27, 0.51, 0.4808975626058773, -0.61, -0.26, -0.29, -0.49, -0.49, 0.01, -0.51, -5.85, 0.11, -0.74, -1.05, -0.2, -0.19, -0.35, 0.27, -0.74, 0.42, -0.35, -0.03, -0.23, -0.23, 0.27, -0.25, -5.6, 0.37, -0.48, -0.79, 0.06, 0.07, -0.55, -0.32, -0.2, -0.2, 0.3, -0.22, -5.5669047619047625, 0.7191309523809524, -0.45, -0.76, 0.09, 0.1, -0.44, -0.67, 0.65, -0.12, 0.0, 0.5, -0.02, -5.38, 0.7937447711019141, -0.25, -0.57, 0.29, 0.3, 1.09, -0.12, 0.5, -0.02, -5.39, 0.6, -0.25, -0.57, 0.29, 0.3, -0.23, 0.029368203225346196, -1.46427628811696, -0.11840181931709852, -0.16482093036566006, -0.16, -0.62, -0.52, -5.86, 0.1, -0.75, -1.06, -0.21, -0.2, 0.29, -0.1, -5.37, 0.62, -0.23, -0.55, 0.31, 0.32, -0.11, -0.55, 0.31603717887804045, -0.39, 3.45, 0.1, 0.26, 0.48, -0.46, -0.24, 0.02, -0.95, 1.36, 0.33, 0.15, 1.17, 0.07, -0.27940313852813836, 0.5, 0.5, -0.11670919513614705, 0.65, -0.35, -1.04, 0.49, -1.86, 2.4, 1.16, 1.77, -1.41, 5.57, 6.33, 5.43, 5.09, 6.0, 6.01, -0.46, -0.71, -0.84, -1.16, -0.31, -0.3, 0.13, -0.32, 0.54, 0.55, -0.06, 0.0, 0.45, 0.86, 0.87, -0.12, -0.2, -0.52, 2.22, -1.78, -2.14, -0.28, -0.07, -0.41, 0.01, -0.46, 0.0, 0.34, 0.32, -0.59, -0.42, 0.18, 0.23, -0.07], ['426', -52.74, 0.11, 0.04, 0.12, 0.18, -0.4, -0.5958847420401708, -1.2, -0.49, -1.9, -1.13, -1.9, -1.35, -0.57, -0.52, -1.16, -1.36, -1.21, -2.58, -1.57, -2.03, -0.6240578231292517, 0.67, -1.72, -0.08140633899247347, -1.58, -0.77, -0.77, -0.23, 0.57, 0.62, -0.03, -0.23, -0.08, -1.46, -0.44, -0.91, 0.4, 1.82, -0.59, -0.8525315746467891, -2.5950638007838265, 0.0, 0.55, 1.35, 1.4, 0.75, 0.55, 0.7, -0.7, 0.34, -0.14, 1.18, 2.6557142857142857, 0.18, -0.09993715369432345, -1.19, -1.18, -0.06, -0.55, 0.8, 0.85, 0.2, 0.0, 0.15, -1.24, -0.22, -0.69, 0.63, 2.05, -0.37, -1.1, -1.34, 0.05, -0.5885714285714285, -0.8, -0.65, -2.02, -1.01, -1.47, -0.17, 1.25, -1.16, -0.95, -6.34, 6.55, -1.38, -0.64, -0.8282142857142857, -0.69, -2.07, -1.05, -1.52, -0.22, 1.2, -1.2, -1.97, -0.6726334687834371, -0.2, -0.05, -1.44, -0.41, -0.88, 0.43, 1.85, -0.56, -0.66, -0.73, -1.39427628811696, -0.5, -0.85, -0.13, -0.54, 0.15, -1.24, -0.21, -0.68, 0.63, 2.6885714285714286, -0.36, -1.14, -0.69, -1.38, -0.36, -0.83, 0.48, 1.91, -0.51, -3.1, -2.52, 0.11, -0.28, -3.59, -0.61, -0.22, -0.8, 0.8, 0.41, -0.95, -0.9, 0.64, 0.95, 0.49, -2.74, -0.16, -1.45, 1.45, 1.5, -0.47, -1.06, -0.95, -2.39, 1.2, -1.69, 2.83, 1.06, 1.53, -0.77, 0.7, 1.04, 0.56, 1.89, 3.34, 0.89, -1.45, -0.33, -0.47, 0.84, 2.27, -0.15, 0.14, 1.32, 2.76, 0.32, -0.42, -0.76, -1.17, 1.42, -0.99, -0.56, -0.43, -1.25, 1.35, -0.95, -1.21, -1.08, -0.59, -2.55, -2.37, -1.22, 0.55, -0.13, -0.01, -0.09, -0.18, -1.04, -0.5, -0.93], ['427', 0.57, 0.0, 0.4712217156204588, 0.07, 0.19, -0.21158037632624052, 0.22411525795982914, 0.47, 0.47, -1.01, -1.73, -1.59, -1.23, -2.09, -1.21, -2.32, -1.34, -1.13, 0.52, -0.99, -0.67, -1.5, -0.84, -0.91, 0.33, 1.549371414588892, 0.73, 0.14, 0.51, -0.37, 0.53, -0.6, 0.39, 0.62, 2.29, 0.75, 1.08, 0.23, 0.9, 0.84, 0.45, -0.14506380078382658, 0.59, 0.36, -0.3421246055531769, 0.38, -0.74, 0.25, 0.47, 2.14, 0.6, 0.94, 0.09, 0.76, 0.69, 0.83, -0.73, -0.68, 0.27, 0.22, -0.7668952774644393, 0.02, -1.1, -0.11, 0.11, 1.77, 0.24, 0.57, -0.27, 0.39, 0.33, 0.29, 1.11, 0.9, -0.23, 0.77, 0.99, 2.67, 1.12, 1.46, 0.61, 1.28, 1.21, 0.5, -0.64, 0.55, 0.2, -1.12, -0.13, 0.09, 1.75, 0.22, 0.55, -0.29, 0.37, 0.3, 0.37, 1.34, 1.0, 1.22, 2.9, 1.35, 1.69, 0.84, 1.51, 1.44, 0.12, 1.28, -0.17, -0.09, -0.11, 0.07567351865003197, 0.34, 0.22, 1.88, 0.35, 0.68, -0.16, 0.51, 0.44, 0.37, 0.12, 1.66, 0.13, 0.46, -0.38, 0.29, 0.22, -0.33, -0.32, 0.38, 0.11, 1.31, 0.05354725829725827, 0.07, -0.16, 0.2, 0.09, -0.08, 1.3461635321120495, -0.01, 0.06, 0.08, 0.37, -0.27, -0.19, 0.21, 0.29, -0.1, -0.35, -0.2, -0.5, 0.26, 0.99, 1.94, -0.66, -1.07, -0.022869047619047622, -1.52, -1.5, -1.18, -2.01, -1.35, -1.42, -0.28, -0.02, 0.33, -0.51, 0.15, 0.09, -0.35, -0.84, -0.18, -0.24, 0.49, 0.36, 0.5872746849074344, 0.67, 0.6722487553150163, -0.05, -0.06, 0.37, 1.06, -0.35, -1.05, 0.26726381052443327, 0.36, -0.17, -0.07, -0.27, 0.04, -0.55, -0.4, 0.06, -0.1, 1.13, 0.6, -0.06], ['428', 3.12, 0.36, -0.04, -0.21, 0.64, 0.55, 1.6, 0.75, 1.24, 0.47, -0.96, -1.05, 0.1, -0.52, 1.14, -0.31, -0.41, 0.27, 0.68, -0.7763367346938775, 0.87, 0.13, -0.23, -0.34, 1.41, 1.36, 1.45, -0.08, 1.08, 0.45, 2.13, 0.66, 0.56, 1.24, 1.66, 0.17, 1.85, 1.1, 0.74, 0.63, -0.06, 2.58, 1.53, 1.16, 0.54, 2.21, 0.74, 0.64, 1.33, 1.75, 0.25, 1.968065468086443, 1.19, 0.82, 0.71, 0.27, 0.45, 0.71, 0.41, 0.37, -0.62, 1.04, -0.42, -0.51, 0.16, 0.58, -0.9, 0.76, 0.02, -0.33, -0.44, 0.94, 0.99, 1.67, 0.2, 0.1, 0.79, 1.2, -0.29, 1.39, 0.65, 0.29, 0.18, 2.05, 1.65, -1.63, -0.6233017616146799, -1.44, -1.54, -0.86, -0.45, -1.92, -0.27, -1.0, -1.36, -1.47, 3.15, 0.78, -0.1, 0.58, 1.0, -0.49, 1.18, 0.44, 0.08, -0.03, 0.21, 0.77, 2.890104651162791, 0.65, 0.70517906963434, 0.685673518650032, 0.88, 0.68, 1.1, -0.39, 1.29, 0.54, 0.18, 0.07, 0.29, 0.2, 0.41, -1.06, 0.6, -0.14, -0.5, -0.61, 0.58, 0.58, -0.4, 0.84, 9.54, 0.12, -0.09, -2.16, 2.18, 1.09, -0.52, 0.58, -2.54, -1.36, -0.66, 1.59, -0.04, 2.0905968614718615, -1.86, -1.97, 0.683290804863853, -3.21, 1.3, 2.02, -1.01, 2.62, -1.11, -1.79, -2.62, 2.54, -0.21, -1.47, 0.19, -0.55, -0.91, -1.02, 1.96, 1.28, 1.68, 0.93, 0.57, 0.46, -0.4, -0.74, -1.09, -1.2, 1.16, 1.16, 0.34, -0.36, -0.47, 0.62, 0.64, 0.8, -0.51, 2.82, 0.31, 1.447263810524433, 0.92, 0.7, -0.11, 0.9, 1.19, -0.03, -0.11, -0.3, 0.81, 2.29, 1.47, 0.6830167737073972], ['429', 1.04, 0.31, -0.48877828437954124, -0.1, 0.06, 0.64, 0.014115257959829165, 0.7, 0.64, 1.39, 0.58, 1.62, 0.99, 1.07, 1.9, 1.61, 0.32, 0.81, 1.61, 2.23, 1.53, -0.22, 0.75, 0.81, 0.27, -0.12, 0.81, 1.1484685082657773, 0.41, 0.49, 1.31, 1.02, -0.26, 0.22, 1.03, 1.64, 0.95, -0.8, 0.17, 0.23, -0.5025315746467891, 0.9649361992161734, -0.22, -0.62, -0.54, 0.28, -0.01, -1.28, -0.8, 0.0, 0.6, -0.08, -1.81, -0.85, -0.79, 1.3, 0.0, -0.68, 0.67, 0.4, 0.08, 0.9, 0.62, -0.66, -0.18, 0.62, 1.23, 0.54, -1.2, -0.24, -0.18, 0.37, 0.32, 0.82, 0.53, -0.74, -0.26, 0.54, 1.15, 0.46, -1.28, -0.32, -0.26, 0.97, 1.88, -1.88, -0.5, -0.28, -1.55, -1.07, -0.28, 0.33, -0.36, -2.08, -1.12, -1.07, -0.97, -0.21, -1.27, -0.79, 0.0, 0.61, -0.08, -1.8, -0.85, -0.79, 0.54, -0.19, 2.4957237118830404, 0.55, 0.67, 0.46, 1.07, 0.49, 1.29, 1.9, 1.21, -0.54, 0.43, 0.49, 1.49, 0.58, 0.8, 1.41, 0.72, -1.02, -0.05, 0.0, 1.23, 1.88, -0.04, 1.03, -3.26, 0.22, -0.8, 0.08, -0.1, -0.04, 0.62, 3.57, 1.54, -1.1, -0.57, 0.57, 0.6, 1.76, -1.67, -1.55, 0.54, 0.09, 1.09, 1.31, -0.73, 3.23, -7.53, -2.21, -3.24, -1.45, -0.22, 0.9371787775716347, -0.08, -1.8, -0.85, -0.79, 1.66, -0.82, -0.68, -2.4, -1.45, -1.39, -0.14, -1.7271150714365, -0.77, -0.71, 0.59, 0.87, 1.62, 0.97, 1.03, 0.57, 0.51, 0.74, -3.73, 2.02, 4.16, 0.65, -0.27, 0.64, 0.13278685149693165, 0.86, 0.0, 1.05, 1.23, 1.11, 0.58, -0.09, -0.35, 1.18], ['430', 1.24, -0.31, -0.1, -0.13, 0.62, 0.02, 0.45, 0.55, 0.0, -0.87, -0.2, -0.9, -0.75, -0.42, -1.01, -0.75, -1.27, -0.92, 2.02, -2.09, -1.05, -0.9, -1.35, -0.66, 0.57, 0.29, -0.67, -0.69, -0.55, -0.22, -0.81, -0.55, -1.07, -0.72, 2.22, -1.89, -0.85, -0.7, -1.15, -0.45, 0.16, 0.18493619921617344, 0.02, 0.15, 0.48, -0.11, 0.15, -0.38, -0.03, 2.94, -1.21, -0.16, -0.01, -0.46, 0.24, 0.2, 0.31, 1.77, -0.23, -0.12, 0.33, -0.26, 0.0, -0.53, -0.17, 2.79, -1.35, -0.3, -0.16, -0.61, 0.09, 0.49, -0.45, -0.16977210884353744, -0.33, -0.85, -0.5, 2.45, -1.68, -0.63, -0.48, -0.93, -0.23, -0.03, 1.19, -1.15, 0.14, 0.26, -0.27, 0.09, 3.06, -1.09, -0.04, 0.11, -0.35, 0.36, -0.91, -0.12, -0.53, -0.17, 2.79, -1.35, -0.24737346264730647, -0.16, -0.61, 0.09, -0.16, -0.06, -1.12, 0.38, 0.31, 0.44, 0.4, 0.35, 3.33, -0.83, 0.39577825349253937, 0.37, -0.004012136584447365, 0.62, 0.05, 0.05, 2.97, -1.18, -0.13, 0.02, -0.43, 0.27, 0.37, 0.48, -0.34, 0.4, -2.56, 0.21806954949812107, 0.0, -1.4, 1.46, 0.73, 0.31406627346681526, 0.89, -2.49, -0.78, -0.37, 0.62, 0.07, 1.1, -1.1, -1.11, 0.37, -2.23, 0.76, 0.68, -0.35, 1.14, -0.68, -0.77, -1.17, 2.34, -2.83, -3.7028212224283656, -3.01, -2.86, -3.3, -2.62, 1.1, 1.25, 1.06, 1.21, 0.76, 1.47, 0.18, 0.15, -0.3, 0.4, 0.09, 0.11, 0.03, -0.45, 0.25, 0.35, 0.41, 0.58, -0.22, -0.66, 0.36, 0.14, 0.46, 0.48, 0.7, 0.5, 0.74, 0.22, -0.33, 0.45, -0.22, 0.81, 0.83, -0.24], ['431', 0.09, 0.53, 0.13122171562045873, 0.0, 0.36, 0.34, 1.0841152579598292, 0.74, 0.7, 1.28, 0.52, 0.9, 1.03, 0.15, 1.36, 0.97, 0.82, 1.2377619047619046, 0.31, 0.51, 1.23, 0.97, 0.47, 0.6, 1.6, 0.64, 0.76, 0.38, 0.51, -0.36, 0.84, 0.45, 0.3, 0.68, -0.21, -0.01, 0.71, 0.45, -0.04, 0.08, -0.65, 1.56, 0.37, 0.12, -0.74, 0.46, 0.07, -0.08, 0.3, -0.59, -0.39, 0.33, 0.07, -0.43, -0.3, 0.83, 0.72, 0.63, 0.53, 0.25, -0.87, 0.34, -0.05, -0.2, 0.18, -0.71, -0.51, 0.21, -0.05, -0.55, -0.42, 0.19, 1.13, 1.2246428571428571, 0.82, 0.67, 1.05, 0.16, 0.36, 1.08, 0.82, 0.32, 0.45, 1.1, 2.33, -2.33, -0.08, -0.39, -0.54, -0.16, -1.04, -0.84, -0.13, -0.39, -0.88, -0.76, 0.4226190476190476, 0.3, -0.15, 0.23, -0.66, -0.46, 0.26, 0.0, -0.5, -0.37, -0.07, 0.3024455782312925, -0.73427628811696, 0.46, 0.7, 0.23, 0.46, 0.38, -0.5, -0.31, 0.41, 0.15, -0.34, -0.16141531611693433, 0.34, 0.08, -0.88, -0.69, 0.03, -0.23, -0.72, -0.6, 1.06, 1.2, -0.15, 0.33, 1.26, 0.2, 0.14, 0.39, -0.46, -0.2, 1.14, 2.36, -1.48, -0.93, -0.49, 0.05, 0.79, 1.38, -1.4, -1.41, 0.46, 0.48, 0.89, 0.62, -0.29, 1.4, -4.61, -0.9, -1.45, 1.57, 0.97, 0.2, 0.92, 0.66, 0.16, 0.29, 1.29, 0.77, 0.72, 0.46, -0.04, 0.12571428571428572, 0.05, -0.26, -0.75, -0.63, 0.66, 0.77, 0.31, -0.49, -0.37, 0.46, 0.47, 0.66, -3.21, -0.09, 3.35, 0.03, 1.05, 0.8, 0.12, 0.43, -0.54, 0.83, 1.2, 0.76, 0.68, 0.26, 0.57, 0.63], ['432', 2.96, -0.03, 0.05122171562045875, 0.19, -0.69, -0.08, -0.12588474204017086, -0.26, -0.55, -0.66, 0.41, -0.66, -0.18, -0.53, 0.04, -1.21, -0.09, -0.63, 0.4, 0.21, -0.86, 0.35, 0.02, -0.07, -0.45, -0.41, -1.0373416050068875, -1.07, -0.59, -0.94, -0.37, -1.61, -0.5, -1.04, -0.01, -0.2, -1.27, -0.06, -0.39, -0.48, 0.17548536582465155, -3.2, 0.0, 0.48, 0.12, 0.7, -0.55, 0.57, 0.02, 1.06, 0.87, -0.18193453191355702, 1.02, 0.69, 0.59, -0.27, 0.11, 0.07, -0.22, -0.47, -0.35, 0.23, -1.03, 0.1, -0.45, 0.59, 0.4, -0.5165788457574171, 0.54, 0.21, 0.12, -0.12, -0.12, 0.58, -0.68, 0.45, -0.1, 0.94, 0.75, -0.33, 0.89, 0.56, 0.47, -1.5, -1.75, 1.78, -0.7, -1.25, -0.13, -0.67, 0.36, 0.17, -0.9, 0.31, -0.02, -0.11, -0.15, 0.637366531216563, 1.13, 0.58, 1.63, 1.44, 0.4126265373526935, 1.58, 1.25, 1.15, 0.05, 0.58, -1.43427628811696, -0.3, -0.43, -0.2, -0.57, -0.55, 0.49, 0.3, -0.78, 0.44, 0.11, 0.02, -0.95, -0.02, 1.04, 0.85, -0.23, 0.99, 0.66, 0.57, -0.33, 0.2, 0.2, -0.706813216376432, -0.39, 0.08, 0.24, 0.19, -0.06827987418743707, -0.05118982899237888, -0.32, -0.46, 1.74, 0.53, 0.24, 1.49, 0.11, -0.68, 0.85, 0.81, -0.29, 0.23, -0.57, -0.8, 0.38, -1.8, -0.97, 1.16, 1.86, -1.66, -1.05, -0.19, -1.26, -0.05, -0.37, -0.47, -0.85, -0.7356457669314812, -1.07, 0.14, -0.19, -0.28, 0.21, 1.22, 0.9, 0.8, -0.55, -0.81, -1.0, -0.32, -0.42, -0.3, -0.34, -0.23742395037612163, -0.83, -1.54, 0.7, -0.87, -1.41, -0.68, -0.09, -0.29, -0.07, 0.54, -0.41, 0.43, -0.59, -1.65, -2.86, -1.2], ['433', -2.32, -1.34, 0.0, -0.24, 0.37, -0.44, 0.7141152579598291, 0.0, 0.28, 1.3470884353741497, 1.22, 0.691934498041641, 0.58, 0.66, 1.86, 1.43, 1.74, 0.74, -2.89, 0.26, 1.21, 1.95, 2.15, 1.24, 0.44, -1.17, -0.32, -0.72, -0.6091666666666666, -0.55, 0.63, 0.2, 0.51, -0.48, -4.06, -0.95, -0.01, 0.72, 0.92, 0.02, -0.64, 2.17, 0.4, 0.09, 0.17, 1.36, 0.93, 1.24, 0.24, -3.36, -0.22880952380952382, 0.71, 1.45, 1.65, 0.74, -0.44, 0.22, -1.16, -0.13, 0.32, 0.08, 1.3848467679404526, 0.84, 1.15, 0.16, -3.45, -0.32, 0.62, 1.36, 1.56, 0.65, -0.49, 0.24, 1.19, 0.76, 1.07, 0.08, -3.52, -0.4, 0.54, 1.28, 1.48, 0.57, 0.83, -3.23, 3.29, -0.95, -0.43, -0.12, -1.1, -4.66, -1.57, -0.64, 0.09, 0.28, -0.61, -0.47, -0.52, 0.31, -0.68, -4.25, -1.15, -0.22, 0.52, 0.8511089783232642, -0.19, 0.12097959183673469, -0.57, -4.09, -0.53, -0.69, -0.59, -0.83, -0.98, -4.55, -1.45, -0.52, 0.21, 0.47598786341555266, -0.49, -1.02, 0.16, -3.6, -0.47, 0.47, 1.21, 1.4, 0.5, -1.8610416300368755, -1.7, -0.71, -1.26, -1.58, -0.15, -0.07, 0.19, -0.23, -0.17, -0.58, 1.08, -1.21, 0.95, 0.54, -1.16, -0.11, -1.94, 1.96, 1.59, -0.52, 0.26, -1.03, 1.5, -0.84, -2.48, -0.19, 1.57, 2.56, 1.29, 3.9, 3.24, 4.22, 4.98, 5.18, 4.25, -1.6, 0.64, 0.94, 1.69, 2.2994625850340134, 0.9814285714285714, -0.3, 0.74, 0.93, 0.03, 0.26, 0.31, -1.03, 0.19, -0.6277512446849837, -0.61, -0.7, -0.09, -0.93, -2.92, 0.96, -0.85, -0.85, -1.22, -0.89, -1.48, -0.11, -0.12, 0.16, -0.11, -0.34, -1.64, -1.85, -0.88], ['434', -2.95, 0.59, 0.011221715620458745, 0.0, -0.61, 1.03, -0.07, 0.72, 0.77, 1.26, 0.27, 1.56, 0.55, 1.14, 0.26, 2.4, -0.03, 1.2, 0.99, 1.1, 1.44, 0.57, 0.04, -0.18, 0.68, 0.72, 0.99, 1.28, 0.29, 1.01318993704708, -0.01, 2.13, -0.3, 0.93, 0.72, 0.83, 1.17, 0.3, -0.22, -0.45, 1.94, 1.3, -0.3, -0.99, -0.4, -1.28, 0.83, -1.56, -0.35, -0.56, -0.44, -0.12, -0.97, -1.49, -1.71, 1.09, 1.1, 0.67, 1.03, 0.7, 0.59, -0.3, 1.84, -0.58, 0.64, 0.43, 0.55, 0.88, 0.01, -0.51, -0.73, 1.08, 0.11, -0.88, 1.24, -1.16, 0.05, -0.15, -0.032285714285714286, 0.29, -0.57, -1.09, -1.31, 1.4, 3.45, -3.25, 1.0366982383853203, 2.14, -0.29, 0.94, 0.73, 0.85, 1.18, 0.31, -0.21, -0.44, -1.93, -1.12, -2.38, -1.18, -1.38, -1.27, -0.94, -1.79, -2.3, -2.53, 0.24, -1.13, 1.85, 1.07, 1.15, 1.08, 1.29, 1.23, 1.02, 1.14, 1.47, 0.6, 0.08, -0.15, 0.78, 0.06, -0.21, -0.09, 0.24, -0.62, -1.14, -1.37, 1.02, 1.169561224489796, 0.07, 1.43, -5.57, 0.08, 0.02, -2.14, 2.14, 1.1088101710076212, 0.75, 0.18, -0.27, -2.12, -1.04, -1.48, 0.8, 3.19, -3.23, -3.19, 1.06, -3.24, 2.12, -0.21, 0.12, 3.71, -9.67, -2.43, -3.71, 0.31, 0.26, 0.11, 0.44, -0.42, -0.94, -1.16, 3.25, 0.15, 0.33, -0.53, -1.05, -1.27, -0.18, -0.86, -1.37, -1.6, 0.85, 1.05, 0.68, -0.52, -0.6777512446849837, 1.07, 1.1, 0.62, -5.17, 1.95, 5.25, 1.69, 1.31, 1.21, -0.23, 1.66, 0.71, 0.5, 0.87, 1.06, 1.44, 0.98, 1.97, 1.57], ['435', -1.93, -0.55, 0.25122171562045875, -0.04, -0.55, -0.16, -0.69, -0.91, -0.78, -1.34, -0.88, -0.92, -0.82, -0.41, -0.05, -0.19143990929705207, -1.23, -1.14, -2.46, -0.62, -1.67, -1.6, -0.72, -1.23, -0.31, -0.03, -0.47, -0.04, 0.06, 0.47, 0.83, 0.6850357142857143, -0.36, -0.27, -1.59, 0.26, -0.8, -0.73, 0.16, -0.35, -1.16, -2.11, -0.43, 0.1911974674961171, 0.6878753944468231, 0.88, 0.42, -0.31, -0.22, -1.55, 0.31, -0.76, -0.68, 0.21, -0.31, -0.28, -0.59, -0.47, -0.79, -0.53, 0.41, 0.77, 0.31, -0.42, -0.33, -1.66, 0.20023809523809524, -0.86, -0.79, 0.10273474541331684, -0.41, -0.83, -0.94, 0.36, -0.1, -0.82, -0.74, -2.06, -0.21, -1.27, -1.19, -0.31, -0.82, -1.43, -1.51, 1.4793333333333334, -1.29, -0.45, -1.18, -1.09, -2.41, -0.56, -1.62, -1.55, -0.66, -1.1159922724755493, 2.84, -0.84, -0.73, -0.64, -1.96, -0.11, -1.17, -1.1, -0.21, -0.72, -0.21, -0.96, 1.09, -0.15, -0.24, -0.04, -0.11, 0.09, -1.24, 0.62, -0.45, -0.37, 0.52, 0.01, 0.22, -0.2, -1.33, 0.53, -0.53, -0.33420045034330736, 0.43, -0.08, -0.96, -1.11, -0.23, -0.11, 8.07, -0.14, -0.21, 0.0, 0.01, -0.02, 0.43, -1.57, 1.53, 0.37, 0.6182806122448982, -0.89, 0.04, -0.49, 0.49, 0.51, -0.15, 0.0, -0.29, 0.17, -0.14, -0.43, 2.992107142857143, 0.28, 0.45, -1.44, 1.14, 1.89, 0.81, 0.88, 1.78, 1.26, -0.51, -0.73, -1.06, -0.99, -0.1, -0.61, 0.33, 0.07, 0.97, 0.45, -0.85, -1.04, 0.26, 0.89, 0.38, -0.13, -0.12, -1.02, 1.11, 0.61, -1.14, -0.04, -0.11, -0.63, -0.51, -0.4, 0.35, -0.06, 0.39, -0.46, -0.12, 1.41, 0.32, 0.65], ['436', -0.64, -0.29, 0.03, 0.03, 0.48, 0.35, 0.0, 0.4, 0.79, 1.49, 0.5, 1.25, 1.06, 2.17, 0.48, 1.2, 0.88, 1.43, -1.33, 0.98, 1.9, 0.87, 1.19, 1.44, -0.33, 0.85, 1.0226583949931125, 0.75, 0.56, 1.66, -0.01, 0.7, 0.38, 1.0472589041444085, -1.82, 0.48, 1.4, 0.37, 0.69, 0.9738417231978392, 0.05, 1.5549361992161734, 0.24, -0.19, 0.9, -0.76, 0.04052947845804987, -0.37, 0.18, -2.55, -0.27, 0.64, -0.37, -0.06, 0.18, -0.27, 0.37, -0.04, 1.88, 0.43, 1.09, -0.57, 0.14, -0.18, 0.37, -2.37, -0.08, 0.84, -0.18, 0.13, 0.37, -0.02, -0.66, -1.65, -0.94, -1.26, -0.72, -3.42, -1.16, -0.26, -1.27, -0.8169045181009466, -0.71, 1.09, 1.04, -1.13, 1.0, 0.72, 0.39, 0.94, -1.81, 0.49, 1.41, 0.39, 0.7, 0.95, 1.57, 0.29, -0.32, 0.23, -2.51, -0.23, 0.69, -0.3036053391053391, -0.01, 0.23, 0.06, 0.32, 1.4, 0.31, 0.37, 0.28, 0.61, 0.55, -2.19, 0.1, 1.02, 0.0, 0.31, 0.55, 0.56, 0.06, -2.476314419707277, -0.45, 0.46, -0.55, -0.24, 0.0, 0.19, 0.53, 0.08, 0.49, 4.59, 0.18, 0.2, -0.41, 0.4, 0.22, 0.45, 0.56, -1.12, -0.62, -0.29, -0.32, 0.17, 0.9, -0.99, -0.95, 0.32, -0.59, 0.63, -0.09, 0.06, 1.8, -0.75, -1.29, -1.89, 1.07, 2.86, 2.34, 3.28, 2.23, 2.56, 2.8, 0.93, 0.51, 0.92, -0.1, 0.21, 0.46, -0.4, -1.01, -0.7, -0.46, 0.93, 1.22, 0.62, 0.31, 0.56, 0.4220800343140569, 0.35, 0.44, -0.68, 0.88, 0.66, 0.43, 1.04, 0.3, 0.24, 0.21, 0.51, 0.21, 0.12, -0.16, 0.06, 0.27, 2.23, 0.55], ['437', 1.18, -0.18, 0.08, 0.12, -0.56, -0.17, -0.14, -0.9, -0.83, -1.03, 0.03, -0.84, -0.4, -0.17, 0.71, -1.88, -0.68, -0.96, -2.64, -1.09, -1.6, -0.52, -0.16, -0.39, -1.08, -0.63, -1.0273416050068875, -0.8694545454545455, -0.43, -0.2, 0.68, -1.9, -0.71, -0.98, -2.67, -1.12, -1.63, -0.55, -0.19, -0.41, -1.38, -1.45, -0.19, 0.44, 0.67, 1.56, -1.05, 0.16, -0.12, -1.82, -0.25, -0.77, 0.32, 0.68, 0.46, -0.56, -0.8, -0.97, -0.38, -0.63, 0.23, 1.12, -1.48, -0.28, -0.56, -2.25, -0.69, -1.21, -0.12, 0.24, 0.01, -0.54, -0.86, 0.88, -1.71, -0.51, -0.79, -2.47, -0.6008690476190477, -1.43, -0.35, 0.01, -0.22, -1.17, -2.2, 2.22, -1.73, -2.57, -1.39, -1.66, -3.33, -1.79, -2.3, -1.23, -0.87, -1.09, 0.34, 0.86, 1.22, 0.94, -0.78, 0.8, 0.28, 1.38, 1.8911089783232642, 1.52, -0.03, 0.84, 0.25, -0.41, -0.45, -0.31, -0.35, -0.28, -1.97, -0.41, -0.92, 0.16, 0.52, 0.3, -0.38, -0.07, -1.7, -0.13, -0.65, 0.44, 0.8, 0.58, -0.85, -0.88, 0.23, -0.18, 1.3, -0.02, 0.03, 0.27, -0.31, -0.16, 0.13, -2.6, -0.15, 0.83, 0.36, 0.58, -0.21692021013122098, -1.22, 1.12, 1.18, -0.42, 0.38, -0.81, -1.11, 0.54, -1.03, 5.06, 0.76, 1.08, 0.05, 1.65, 1.59, 1.07, 2.18, 2.546751700680272, 2.31, -1.24, 0.06, -0.52, 0.57, 0.94, 0.71, 0.58, 1.1, 1.46, 1.23, -0.78, -0.99, -0.4227253150925656, 0.36, 0.14, -0.4, -0.4, -0.8174239503761216, 2.83, 0.3403332627840632, -2.84, -0.72, -0.53, -0.791362551799029, -0.22, -0.34, 0.07, -0.23, -0.31, -0.4, -0.65, 0.02, 0.03, -0.32], ['438', -3.11, 1.0, -0.12, 0.24, 0.25, -0.06158037632624053, 1.87, 0.32, 0.53, 0.99, 0.79, 0.0, 1.33, -0.65, 0.92, 1.32, 1.35, 1.07, 2.97, -0.9, 1.06, 0.76, 1.05, 1.15, -0.04, 0.32, 0.2, -0.79, 0.54, -1.28681006295292, 0.13, 0.53, 0.56, 0.28, 2.16, -1.68, 0.27, -0.03, 0.26, 0.36, 0.0, 0.99, 1.0, 1.34, -0.65, 0.93, 1.33, 1.36, 1.07, 2.97, -0.9, 1.07, 0.77, 1.06, 1.15, 0.07, -0.22, -0.67, 0.33, -0.34, -1.96, -0.41, -0.01, 0.02, -0.26, 1.61, -2.21, -0.27, -0.56, -0.28, -0.18, 0.48, 1.66, 1.59, 1.99, 2.02, 1.73, 3.64, 0.0691309523809524, 1.73, 1.42, 1.72, 1.81, 0.68, -0.07, 0.0, 0.0708709226619941, 0.4, 0.43, 0.14, 2.02, -1.81, 0.14, -0.16, 0.13, 0.27400772752445063, -0.76, -0.33, 0.03, -0.25, 1.62, -2.2, -0.26, -0.55, -0.27, -0.17, 0.0, -0.34, -0.37, -0.89, -0.92, -0.82, -0.36, -0.28, 1.59, -2.23, -0.29, -0.58, -0.3, -0.2, -1.14, -0.01692325186963274, 1.88, -1.95, 0.0, -0.1742004503433073, -0.01, 0.08, 0.04, 0.42, 0.4060371788780404, 0.2, -2.32, 0.15, -0.14, 0.31, -0.39, -0.18, -2.08, -0.33, -3.65, 0.54, 0.25, -1.53, -0.28, -0.75, 0.74, 0.77, -0.24, 0.46, -0.48, -0.96, 0.48, 1.48, 5.66, -1.09, -1.46, 3.73, -1.92, -3.76, -1.85, -2.14, -1.853248299319728, -1.76, -0.74, 1.91, 1.98, 1.68, 1.97, 2.07, -0.07, -0.3, -0.01, 0.09, 0.58, 0.45845354645354663, 0.23, 0.29, 0.38, -0.28, -0.10560369872470916, 0.33, 3.39, 0.3, -3.4, -0.1027361894755667, -0.08, -0.06, 0.1, -0.06, -0.07, -0.67, -0.46, -0.63, -0.074042472976186, -0.4, -0.14, 0.36], ['439', 4.62, 0.13, 0.13, -0.2, 0.03, 0.43, 1.0841152579598292, -0.35, 1.05, -0.4, -1.5196815287886714, -2.03, -0.48, -0.37, -0.38, -1.78, -1.7028571428571428, -0.93, -2.54, -2.08, -0.01, -0.37, -1.16, -1.3378253968253968, 0.08, 0.96, 1.35, -0.31, 1.2714285714285714, 1.38, 1.38, -0.05, -0.01, 0.81, -0.82, -0.36, 1.75, 1.39, 0.58, 0.44384172319783916, 0.43, 2.03, 1.66, 1.59, 1.7, 1.69, 0.2764030612244898, 0.3, 1.13, -0.51, -0.05, 2.06, 1.7, 0.89, 0.71, -0.87, -0.49, -1.6, 0.19, 0.07, 0.11, 0.1, -1.31, -0.5985714285714286, -0.45, -1.7803066893424033, -1.61, 0.47, 0.1259625850340136, -0.69, -0.87, -0.15, -0.03, -0.009285714285714286, -0.9733418367346938, -1.37, -0.56, -2.1669047619047617, -1.72, 0.36, 0.0, -0.8, -0.97, 1.19, 1.85, -1.85, -0.03, -1.41, -1.37, -0.56, -2.17, -1.71, 0.36, 0.01, -0.79, -0.97, 1.1812233560090704, 1.4, 0.04, 0.86, -0.77, -0.31, 1.79, 1.44, 0.63, 0.45, 0.35, 1.3, 0.43, 0.88, 0.94, 1.05, 1.36, 0.82, -0.81, -0.35, 1.75, 1.39, 0.59, 0.41, -0.11, 0.53, -1.62, -1.16, 0.92, 0.57, -0.031428571428571445, -0.41, 1.47, 1.62, -0.29, 1.24, 2.02, 0.04, 0.15, -2.31, 2.33, 1.17, 0.53, -0.67, -3.35, -1.75, -0.89, 2.45, 0.43, 2.9, -2.74, -2.72, 0.88, -3.47, 1.79, 2.83, -1.38, 4.1, -0.16, -2.79, -4.08, 3.39, 2.19, 0.47, 2.59, 2.23, 1.41, 1.23, 2.61, 1.71, 2.11, 1.75, 0.94, 0.76, -0.36773809523809525, -0.35, -1.15, -0.6785714285714286, 1.07, 0.61, -0.04, -0.8, -0.98, 0.81, 0.97, -0.17, 0.0, 1.29, -0.15, 1.73, 0.57, 0.77, -0.18, 1.75, 1.17, 0.1, 0.18, 0.87, 0.95, 2.02, 0.93, 1.54], ['440', 2.49, -0.01, 0.05122171562045875, -0.21, 0.11, 0.04, 1.424115257959829, 1.05, 0.52, 0.92, 0.35, 0.241934498041641, 1.24, -0.44, 0.14, 0.25, 0.7, 0.72, 0.92, 0.67, 0.83, 1.66, 0.73, 0.97, 0.78, 0.84, 0.58, -0.3, 0.89, -0.79, -0.2, -0.09, 0.35, 0.38, 0.58, 0.32, 0.48076068376068376, 1.31, 0.39, 0.62, 0.8, -0.48, 0.88, 1.1936589811608609, -0.48, 0.1, 0.21, 0.66, 0.68, 0.88, 0.63, 0.79, 1.62, 0.69, 1.2308287981859412, 0.87, 0.75, 0.08, 0.86, -0.31, -1.66, -1.08, -0.97, -0.53, -0.51, -0.31, -0.56, -0.4, 0.42, -0.5, -0.27, 2.31, 1.37, 0.59, 0.7, 1.15, 1.17, 1.37, 1.12, 1.28, 2.11, 1.18, 1.42, 0.13, 0.25, -0.34, 0.78, 0.11, 0.56, 0.58, 0.78, 0.53, 0.69, 1.52, 0.59, 0.82, 2.68, 0.67, 0.44, 0.47, 0.67, 0.41, 0.58, 1.41, 0.48, 0.71, 0.22, 0.66, -1.73, 0.23, 0.34, 0.06, 0.22, 0.02, 0.22, -0.03, 0.13, 0.96, 0.03, 0.3285846838830657, -0.75, 0.2, 0.2, -0.05, 0.11, 0.93, 0.01, 0.24, 0.7, 0.48, -0.23, 0.02, 8.12, 0.02, -0.07, -0.46, 0.46, 0.23, -0.29, 0.11, -0.48, -0.48, -0.2, 1.24, 0.22, 0.69, -0.77, -0.74, 0.24, -0.66, 0.48, 1.33, -0.65, 0.62, -3.75, -0.35, -0.71, 0.45, 0.0, -0.25, -0.09, 0.73, -0.19, 0.04, 0.63, 0.25, 0.16, 0.99, 0.06, 0.3, 0.09, 0.83, -0.1, 0.13, 0.51, 0.39, -0.73, -0.92, -0.68, 0.14, 0.22, 0.99, -1.92, -0.73, 1.88, -0.29, 0.62, 0.19, 0.23, 0.26, -0.1, 0.6, 0.08, 0.79, -0.04, 0.63, 0.63, -0.06], ['441', -4.94, 0.19, 0.011221715620458745, -0.24, -0.10702091900894042, 1.31, 0.6941152579598292, 1.75, 2.14, 0.63, -1.54, -0.2, -0.48, -1.78, -0.05, 1.49, -0.31, 0.24, 2.92, -0.84, 1.59, -0.42, -1.79, -0.62, 2.0, 1.46, 2.21, 1.36, 1.07, -0.24, 1.52, 3.08, 1.25, 1.8, 4.547761904761905, 0.71, 3.17, 1.14, -0.25, 0.93, 1.26, 4.97, 0.84, -0.28, -1.58, 0.16, 1.7, -0.11, 0.44, 3.12, -0.64, 1.79, -0.22, -1.59, -0.42, 1.34, 1.87, 1.78, 2.2699285714285713, 1.12, -1.3, 0.44, 1.98, 0.17, 0.72, 3.41, -0.36, 2.08, 0.06, -1.31, -0.14, 0.82, 2.45, 1.76, 3.33, 1.49, 2.05, 4.78, 0.96, 3.42, 1.38, -0.01, 1.18, 3.3, 6.37, -6.3, 0.68, 1.54, -0.27, 0.28, 2.96, -0.79, 1.7952352330209473, -0.37, -1.74, -0.57, -0.48, -0.85, -1.78, -1.24, 1.4, -2.3, 0.09, -1.88, -3.23, -2.08, 0.49, -0.89, 0.42572371188304003, 1.46, 1.77, 1.05, 0.95, 0.55, 3.24, -0.53, 2.0857782534925393, -0.11, -1.48, -0.25141531611693435, 1.1265360710717855, 0.4, 2.67, -1.07, 1.35, -0.65, -2.02, -0.85, 2.23, 1.93, -0.29, 1.04, -0.92, 0.46, 0.35, -1.73, 1.74, 0.85, 0.05, 2.82, -2.87, -2.95, -1.45, -2.53, 1.24, 4.2, -4.18, -4.29, 1.47, -2.57, 2.92, 2.15, -1.05, 2.79, -9.91, -1.86, -2.76, 2.93, -2.22, -3.65, -1.29, -3.24, -4.57, -3.44, 4.41, 1.48, 2.44, 0.42, -0.96, 0.22, -0.94, -1.98, -3.32, -2.17, 2.17, 2.57, 1.1472746849074344, -1.37, -0.2, 1.38, 1.31, 1.58, -5.17, 0.45, 5.12, 1.13, 1.86, 2.47, 1.19, 1.58, 0.83, 0.95, 1.55, 1.88, 1.26, 0.84, 0.91, 0.86], ['442', 1.49, 0.32, -0.22877828437954126, 0.04, 1.09, 0.15, -0.8358847420401708, -1.05, -2.12, -1.06, 1.68, -0.67, -1.21, -0.62, -0.23, -1.39, -1.55, -0.86, 0.7114818594104309, -2.83, -1.11, -1.58, -1.39, -1.11, -1.44, 0.07, -2.7, -2.31, -2.84, -2.11681006295292, -1.88, -3.02, -3.18, -2.5, -0.97, -4.44, -2.74, -3.21, -3.02, -2.75, -1.1, -3.0450638007838267, -0.39, -0.54, 0.05, 0.45, -0.72, -0.88, -0.19, 1.38, -2.17, -0.44, -0.92, -0.72, -0.44, -0.82, -1.91, -0.6, -2.52, 0.15, 0.6, 0.99, -0.18, -0.34, 0.35, 1.93, -1.64, 0.1, -0.38, -0.18, 0.1, -0.36, -0.45, 0.39, -0.78, -0.94, -0.25, 1.32, -2.23, -0.49, -0.97, -0.77, -0.5, -2.49, 0.98, -1.03, -0.8033017616146798, -1.16, -1.32, -0.64, 0.92, -2.61, -0.88, -1.36, -1.16, -0.89, 2.36, 0.33, -0.16, 0.53, 2.11, -1.46, 0.28, -0.2, 0.0, 0.28, -0.13, 0.33, 1.41, 0.2, 0.33, 0.20567351865003197, 0.5, 0.7, 2.28015873015873, -1.3, 0.45, -0.03, 0.16, 0.44, 0.61, -0.2, 1.57, -1.99, -0.25, -0.6042004503433073, -0.53, -0.25, 0.08, 0.08, 0.08, 0.46, 4.75, 0.11, 0.21, -0.17, 0.16, 0.07, 0.94, -0.24, -3.83, -0.33, -0.17, 0.84, -0.04, 0.6514761904761905, -0.65, -0.49, 0.19, -0.23, 0.33, 0.09, 0.0, 1.45, -2.47, -1.02, -1.46, 3.86, -1.74, -3.5, -1.79, -2.26, -2.07, -1.79, 0.53, 1.82, 1.77, 1.29, 1.48, 1.77, 0.05, -0.48, -0.28, 0.0, -0.27, -0.59, 0.53, 0.2, 0.48, 0.17, 0.27, 0.02, -1.07, 0.61, 1.3, 0.5, 0.95, 0.33, 0.28, 0.33, 0.04, -0.29, -0.12, -0.03, 0.05, 1.7, 1.31, -0.11], ['443', -0.76, -0.56, 0.011221715620458745, 0.01, 0.11, 0.12, -0.59, 0.29, -0.08, -0.29, 0.19, 0.09, -0.02, -1.63, -0.61, -0.33, -0.26, -0.39, 1.36, -0.06, -0.42, 0.61, -0.26, 0.22, 0.68, -0.11, -0.48, -0.1, -0.21, -1.82, -0.8, -0.52, -0.45, -0.58, 1.17, -0.25, -0.61, 0.42, -0.44, 0.04, 0.17, -0.47, -0.38, -0.11, -1.72, -0.7, -0.42, -0.35, -0.48, 1.27, -0.15, -0.51, 0.51, -0.35, 0.13, 0.21, -0.34, 0.48, 0.71, -0.27, -1.61, -0.59, -0.31, -0.25, -0.37, 1.38, -0.04, -0.4, 0.63, -0.24, 0.24, 0.32, 1.36, 1.03, 1.32, 1.39, 1.26, 3.04, 1.6, 1.23, 2.27, 1.4, 1.89, -0.52, 0.01, 0.09, 0.3666982383853202, 0.28, 0.35, 0.23, 1.98, 0.56, 0.19, 1.23, 0.36, 0.84, 0.97, 0.04, 0.07, -0.06, 1.7, 0.27, -0.09, 0.94, 0.08, 0.56, 0.21, 0.03, 0.65, 0.08, 0.19, 0.07567351865003197, -0.03, -0.13, 1.63, 0.2, -0.16, 0.87, 0.01, 0.49, -0.79, 0.1, 1.75, 0.33, -0.03, 1.1257995496566926, 0.13, 0.62, 0.18, 0.11, -0.18, 0.09, 2.91, 0.01, 0.05, 0.0, -0.02, -0.02, -0.03, 0.32, 0.45, -0.15, -0.09, -0.38, 0.04, 0.22, -0.26, -0.21, 0.07, -0.08, 0.14, 0.59, -0.24, -0.07, -3.45, 0.03, 0.05, -0.37, -1.63, -1.4, -1.76, -0.74, -1.59, -1.12, 0.22, -0.23, -0.36, 0.7557142857142858, -0.2, 0.28, 0.13, 1.03, 0.17, 0.65, 0.02, 0.04, -0.89, -0.86, -0.38, 0.09, 0.07, 0.4525760496238784, -2.01, 0.3711163791806698, 2.03, 0.25, 0.17, -0.03, 0.48, -0.14, 0.15, 0.53, -0.24, 0.34, -0.51, 0.26, 0.26, 0.34], ['444', 1.57, -1.29, -0.06877828437954125, -0.05, -0.57, -0.53, -3.31, -1.13, -0.8506219456129893, -0.65, -0.05, 1.31, -0.45, 2.63, 0.89, -1.39, 0.12, -0.34, 0.87, 1.11, 0.0, 1.5, -0.98, 0.04, -0.35, 0.25, -0.61, 1.36, -0.4, 2.68, 0.94, -1.35, 0.17, -0.29, 0.92, 1.16, 0.05, 1.55, -0.94, 0.09, -1.85, 0.0, -1.94, -1.73, 1.31, -0.41, -2.67, -1.17, -1.63, -0.43, -0.2, -1.29, 0.19, -2.27, -1.25, -0.72, -1.36, -0.14, -0.91, -0.21, 3.1, 1.35, -0.95, 0.57, 0.11, 1.32, 1.57, 0.45, 1.96, -0.54, 0.49, 0.26, -3.2, -1.7, -3.92, -2.45, -2.9, -1.72, -1.48, -2.57, -1.11, -3.53, -2.52, -0.51, 0.15, -0.22, -1.53, -2.27, -0.76, -1.22, -0.02, 0.22, -0.88, 0.6, -1.86, -0.84, 2.75, 0.75, 1.54, 1.07, 2.3, 2.54, 1.41, 2.93, 0.41, 1.46, -0.42, 0.78, -2.36, -0.45, -0.3, -0.69, -0.78, -0.46, 0.75, 0.99, -0.12, 1.37, -1.11, -0.08, -1.94, -0.32, 1.21, 1.46, 0.34, 1.85, -0.65, 0.38, 0.18, 0.05956122448979598, -0.04, -0.57, 8.17, -0.35, -0.57, 0.63, -0.61, -0.31, -0.07, -1.38, 3.38, 0.88, 0.42, 0.78, -1.36, -1.32, 1.39, 1.37, -0.44, 0.91, -0.88, -1.22, 0.62, -2.29, 1.94, 1.48, 2.28, -3.44, -1.51, 0.24, -0.86, 0.62, -1.84, -0.82, -1.24, -1.75, -1.1, 0.38, -2.07, -1.06, -0.66, 1.5, -0.99, 0.04, -0.97, -0.69, -2.12, -2.45, -1.43, -0.42, -0.52, -1.19, 1.36, -1.85, -0.9107193877551023, -0.22, -0.1, 0.33, 1.04, -0.24, -0.08, -1.56, -1.33, -1.31, -0.7, -0.58, 0.15, -0.47], ['445', 2.74, -0.2, -0.17, 0.01, 0.18, -0.36, 0.4841152579598291, -1.08, -0.26, -0.25, 0.33, -0.5506751700680272, 0.76, 1.55, 1.68, -0.08, 0.24, -0.08, 0.91, -0.4, 0.16733548208735893, 1.88, 0.92, 0.39, -0.64, -0.96, -0.5473416050068876, -0.89, 0.43, 1.21, 1.35, -0.4, -0.09, -0.41, 0.58, -0.73, -0.19, 1.55, 0.58, 0.06, -1.12, 0.34493619921617347, 0.31, 1.33, 2.12, 2.26, 0.49, 0.81, 0.48, 1.49, 0.16, 0.7, 2.46, 1.5871428571428572, 0.96, -0.3876426685347185, -1.26, -0.78, -0.98, -1.0, 0.78, 0.92, -0.83, -0.51, -0.83, 0.15, -1.15, -0.62, 1.11, 0.16, -0.37, -0.83, -1.77, 0.14, -1.5367057823129253, -1.28, -1.6, -0.62, -1.92, -1.39, 0.33, -0.62, -1.14, 0.18, -3.53, 3.53, -1.9, -1.73, -1.42, -1.73, -0.76, -2.05, -1.52, 0.2, -0.75, -1.27, 1.04, -0.18, 0.32, -0.01, 0.99, -0.33, 0.21, 1.96, 1.1311089783232642, 0.47, -0.14, -0.23, 0.0, -0.6, -0.86, -0.42, -0.49, -0.32, 0.67, -0.64, -0.11, 1.64, 0.67, 0.15, -1.99, -0.17, 1.0, -0.32, 0.22, 1.96, 1.0, 0.47, -1.1781719617057962, -1.76, -0.13, -0.91, 1.92, -0.43, -0.29, -0.92, 0.9, 0.46, -0.74, -0.46, -0.5, 1.22, 0.62, 1.34, -0.58, -1.8, 1.91, 1.83, -0.61, -1.32, -1.44, 0.46, -0.2, -1.42, 3.62, 0.96, 1.36, 0.4, -1.1416360544217685, -1.3, -0.77, 0.96, 0.0, -0.52, -1.87, 0.15, 0.54, 2.5371428571428574, 1.32, 0.79, -0.39, 1.74, 0.78, 0.26, -0.19, -0.36, -2.09, -0.95, -1.46, -0.4779199656859431, -0.65, -1.05, 1.84, -0.28, -1.85, -1.96, -1.45, -1.16, -0.52, -1.56, 0.64, -0.29, -0.35, -0.92, -0.64, -2.03, -0.65, -0.71], ['446', -0.75, 0.51, 0.07015289830927054, -0.07, -0.25, -0.3, 1.61, 1.36, 0.56, 1.35, 1.27, 0.64, 0.84, 0.28, -1.88, 0.68, 0.48, 1.33, 2.08, 1.87, 1.22, 0.31, 0.15, 0.32, -0.04, 0.16, 0.11265839499311246, -0.63, -0.43, -0.97, -3.11, -0.58, -0.78, 0.06, 0.8, 0.59, -0.05, -0.95, -1.11, -0.93, 1.99, 1.6849361992161733, 0.71, 0.2, -0.35, -2.5, 0.04, -0.16, 0.69, 1.43, 1.23, 0.58, -0.33, -0.49, -0.31, 0.06, 0.5, 2.74, 0.41, 0.52, -0.55, -2.69, -0.15, -0.35, 0.49, 1.2471802721088434, 1.03, 0.38, -0.52, -0.68, -0.51, 0.82, 1.07, -2.16, 0.39, 0.2, 1.04, 1.79, 1.58, 0.93, 0.02, -0.14, 0.04, 0.78, 3.18, -3.27, 3.3, 2.61, 2.4, 3.27, 4.03, 3.82, 3.16, 2.23, 2.06, 2.25, -0.04, 0.67, -0.2, 0.65, 1.39, 1.18, 0.54, -0.37, -0.53, -0.35, 0.0, 0.63, 2.58, 0.61, 0.65, 0.72, 0.87, 0.85, 1.59, 1.38, 0.74, -0.17, -0.33, -0.15, 0.83, 0.02, 0.74, 0.53, -0.11, -1.01, -1.17, -0.99, 1.18, 1.2, 0.0, 1.343186783623568, -0.24, 0.04, 0.05, -2.39, 2.43, 1.24, -0.15, -0.19, 1.17, -1.24, -0.64, -0.29, 0.83, 1.82, -1.88, -1.92, 0.6, -3.7, 1.23, 0.4, -0.25, 2.6, -8.33, -1.85, -2.62, -1.07, -0.71, -0.2, -0.84, -1.73, -1.89, -1.72, 1.79, -0.5098412698412699, -0.64, -1.53, -1.69, -1.52, 0.13, -0.9, -1.06, -0.88, 0.56, 0.6, 1.05, -0.16, 0.09224875531501633, 0.61, 0.71, 1.35, -5.0, 2.28, 4.72, 0.86, -0.66, 1.21, 0.18, 0.39, 0.03, 1.31, 0.62, 1.07, 1.03, -0.74, -1.08, 1.06], ['447', -8.49, 0.36, 0.05122171562045875, 0.08, -0.29, 0.37, 0.6541152579598292, 0.57, 0.61, -0.1, -0.63, -1.08, -0.36, -0.56, -0.89, 1.32, -0.65, -0.28, -2.81, -0.62, -0.01, -1.24, -1.21, -0.23, 0.56, -0.11, 0.53, -0.45, 0.27, 0.07, -0.27, 1.96, -0.02, 0.35, -2.2, 0.01, 0.62, -0.61, -0.59, 0.4, 0.89, 1.2, 0.98, 0.73, 0.53, 0.18, 2.43, 0.43, 0.81, -1.76, 0.46, 1.08, -0.16, -0.14, 0.86, 0.89, 0.55, 0.0, 0.61, 0.32924524706587754, -0.2, -0.54, 1.68, -0.29, 0.08, -2.47, -0.26, 0.35, -0.88, -0.86, 0.13, -0.13, 0.45, -0.34, 1.89, -0.09, 0.28, -2.27, -0.07, 0.55, -0.69, -0.5269045181009466, 0.33, 0.69, 3.05, -2.96, 0.8008709226619941, 2.24, 0.25, 0.62, -1.94, 0.28, 0.89, -0.35, -0.32, 0.67, -1.72, -1.41, -1.94, -1.58, -4.08, -1.92, -1.32, -2.53, -2.5, -1.53, 0.19, -1.42, 0.1, 0.43, 0.56, 0.26, 0.55, 0.37, -2.18, 0.22971268810554554, 0.8157782534925394, -0.59, -0.4940121365844473, 0.42, 1.05, 0.17, -2.54, -0.34, 0.27, -0.96, -0.94, 0.05, 0.46, 0.24, 0.13, 0.51, -5.2, 0.0, 0.05, -0.14, 0.11, 0.07, 0.29, 1.1961635321120496, -0.97, -0.91, -0.44, -4.22, 0.42, 1.36, -1.31, -1.31, 0.44, -0.2, 0.85, 0.27, -0.14, 1.72, 0.85, -1.1, -1.61, 1.1, 2.79, 2.26, 2.88, 1.62, 1.65, 2.66, 1.35, 0.52, 0.61, -0.62, -0.6, 0.39, -0.09, -1.23, -1.2, -0.22, -0.4, -0.33, 1.2372746849074343, 0.02, 1.02, 0.44, -0.28, -0.2974239503761216, 0.5, -0.19, -0.58, 0.64, 0.58, 1.12, 1.0, 0.34, 0.2, 0.55, 0.28, 0.2, 0.13, -0.09, 0.51, -0.16], ['448', -1.22, -0.18, -0.06, 0.23, -0.2, -0.02, 1.25, -0.31, -0.36, 0.9370884353741497, 0.970608843537415, -0.41, 0.41, 0.6, 0.76, 0.91, 0.57, 0.36, 1.66, 0.37, 0.35, 0.03, 0.87, 0.2, -0.57, -0.48, -0.42734160500688756, -1.35, -0.54, -0.35, -0.1421800287049088, -0.05, -0.39, -0.47274109585559154, 0.7, -0.58, -0.6, -0.92, -0.09, -0.75, 0.28, -1.06, 0.9, 0.82, 1.02, 1.17, 1.32, 0.98, 0.78, 2.08, 0.78, 0.77, 0.44, 1.28, 0.62, -0.9, 0.54, -0.22, -0.74, 0.15924524706587756, 0.19, 0.35, 0.5, 0.16, -0.05, 1.25, -0.04, -0.06, -0.38, 0.46, -0.21, -0.35, -0.11, 0.16, 0.3, -0.04, -0.24, 1.05, -0.23, -0.25, -0.57, 0.26, -0.4, -0.92, -1.11, 1.15, -0.23330176161467986, 0.15, -0.19, -0.39, 0.9, -0.39, -0.4, -0.72, 0.11, -0.55, -0.87, -0.41, -0.34, -0.54, 0.75, -0.54, -0.4873734626473065, -0.87, -0.04, -0.7, 0.16, -0.45, 2.61, 0.03, -0.11, 0.16, -0.0790429599640126, -0.2, 1.09, -0.2, -0.21, -0.53, 0.3, -0.36, 0.4, 0.13, 1.29, 0.0, -0.01, -0.33, 0.5, -0.16, -0.67, -0.35, 0.62, -0.08, -2.34, 0.0, 0.07, -0.94, 0.96, 0.47, -0.44, -1.28, -0.24, -0.08, -0.03, -0.56, 0.3, -0.01, -0.09, -0.17, 0.03, -1.33, 0.04, -1.06, 0.51, -0.38, 16.84, 0.28, 0.36, 0.24, -1.15, -1.27, -1.29, -1.6, -0.78, -1.44, 0.09, 0.12, -0.01, -0.34, 0.5, -0.16, 0.14, -0.32, 0.51, -0.15, -0.32, -0.83, 0.46, 0.84, 0.17, 0.06, 0.11439630127529085, -0.24, 7.56, 1.490333262784063, -7.7, 0.37, -0.73, -0.38, -0.66, 0.01, 0.3, 0.15, 0.63, 0.32, 0.29, 0.12, -1.29, 0.11], ['449', 3.584285714285714, -0.03, 0.13122171562045873, 0.1, 1.42, 0.8, 0.5641152579598292, 1.35, 1.33, 1.5, -0.14, 0.93, 1.78, 0.27, -0.04, 0.49, 0.62, 1.29, -1.67, -0.16, 1.947335482087359, 0.83, 0.96, 0.9, 1.73, 1.39, 1.65, 1.08, 1.93, 0.41, 0.1, 0.63, 0.77, 1.43, -1.53, -0.01, 2.06, 0.97, 1.1, 1.04, 0.79, 3.03, 0.56, 0.84, -0.66, -0.97, -0.44, -0.31, 0.35, -2.58, -1.08, 0.9980654680864429, -0.11, 0.02, -0.04, 0.7, 1.62, 2.217827972809784, 0.99, -0.28, -1.49, -1.79, -1.27, -1.14, -0.49, -3.4, -1.91, 0.12, -0.94, -0.81, -0.8605612244897959, 1.2436060011417156, 1.23, -0.2953571428571429, 0.22, 0.35, 1.01, -1.94, -0.42, 1.64, 0.55, 0.69, 0.62, 2.04, 1.59, -1.58, 1.54, 0.53, 0.66, 1.33, -1.63, -0.12, 1.95, 0.87, 1.0, 0.94, 1.7, 1.01, 0.13, 0.79, -2.15, -0.64, 1.41, 0.33, 0.47, 0.4, 0.15, 0.99, 0.22572371188304005, 0.84, 0.77, 0.9, 0.9418094764861292, 0.66, -2.28, -0.77, 1.28, 0.2, 0.33, 0.27, 0.61, 0.21, -2.92, -1.43, 0.62, -0.46, -0.33, -0.39, 0.4618280382942037, 0.45, 0.04, 0.86, 5.04, 0.32, 0.4, -2.33, 2.38, 1.19, 1.23, 0.23, -3.26, -1.64, -0.87, 1.6, 0.69, 2.53, -2.55, -2.49, 0.84, -3.56, 1.66, 0.03, -0.02, 2.62, -2.77, -1.79, -2.59, 3.26, 3.23, 1.54, 3.64, 2.54, 2.68, 2.61, 2.52, 1.66, 2.07, 0.98, 1.12, 1.05, -0.4, -1.07, -0.94, -1.0, 1.27, 1.52, 0.67, 0.13, 0.07, 0.84, 0.8, 1.31, -1.71, 0.3, 1.86, 1.27, 1.34, 0.54, -0.06, 0.61, 1.5, 0.37, 0.95, 0.61, 0.6, 1.8, 1.93, 0.44], ['450', 1.66, 0.38, 0.12, -0.04, 0.18, 0.56, 1.0041152579598291, 1.51, 1.2, 1.64, 0.46, 0.691934498041641, 0.57, -0.26, 0.24, 1.39, 0.44, 1.41, 2.91, 0.16, 1.96, 0.53, 0.64, 0.87, 1.72, 0.57, 1.2026583949931124, 0.02, 0.11, -0.72, -0.22, 0.92, -0.03, 0.95, 2.43, -0.3, 1.49, 0.07, 0.18, 0.4, 0.73, 0.8449361992161734, 1.14, 0.08, -0.74, -0.25, 0.89, -0.05, 0.92, 2.41, -0.33, 1.46, 0.04, 0.15, 0.38, 0.49, 1.67, 0.99, 1.22, 1.1392452470658776, -0.82, -0.33, 0.81, -0.13, 0.84, 2.32, -0.41, 1.38, -0.04, 0.07, 0.3, 1.85, 1.9, 0.5, 1.65, 0.7, 1.68, 3.17, 0.42, 2.22, 0.79, 0.9, 1.13, 0.94, 2.7, -2.63, 1.42669823838532, 1.15, 0.2, 1.17, 2.66, -0.08, 1.72, 0.29, 0.4, 0.63, -0.44, 0.25, -0.94, 0.03, 1.5, -1.21, 0.56, -0.84, -0.73, -0.51, 0.4, 0.24, 1.9001046511627906, 0.73, 0.68, 0.73, 1.19, 0.97, 2.46, -0.28, 1.52, 0.1, 0.2, 0.43, 1.09, 0.27307674813036725, 1.47, -1.24, 0.54, -0.87, -0.76, -0.29782256235827664, 0.87, 1.33, 0.24, 0.91, -1.55, 0.44, 0.62, -1.65, 1.8017201258125628, 0.84, 1.25, 2.96, -2.75, -1.39, -0.72, 0.82, 0.31, 2.14, -2.12, -2.16, 0.71, -2.45, 1.4, 0.47, -0.23, 3.65, -12.89, -2.49, -3.65, 2.81, -1.23, -2.67, -0.92, -2.31, -2.2, -1.98, 2.14, 1.47, 1.8, 0.37, 0.48, 0.71, -0.32, -1.4, -1.29, -1.07, 1.24, 1.29, 1.1, 0.11, 0.34, 0.76, 0.74, 1.62, -6.51, 1.55, 6.68, 0.49, 0.71, 0.99, 0.23, 1.0, 0.57, 0.43, -0.14, 0.78, 0.76, 0.04, 1.2415952380952382, 0.65], ['451', -12.94, -0.19, -0.5, 0.15, -3.29, -0.89, -0.25, -0.83, -0.88, -1.86, -0.96, -1.43, -0.66, -1.0, -0.88, 1.41, -0.54, -1.7, 2.7, 3.14, -2.03, -2.46, -2.13, -0.85, -1.24, -1.96, -0.8773416050068876, -0.4671394557823129, 0.3, -0.04, 0.07, 2.39, 0.42, -0.75, 3.700714285714286, 4.14, -1.0055463299214311, -1.52, -1.18, 0.11, -0.65, -2.17, -0.24069676751819596, 0.77, 0.44, 0.55, 2.88, 0.9, -0.28, 4.19, 4.63, -0.61, -1.05, -0.71, 0.58, -0.72, -1.04, -0.15, -1.19, -1.2, -0.33, -0.22, 2.09, 0.12, -1.04, 3.39, 3.83, -1.37, -1.4825351473922903, -1.47, -0.19, -1.67, -0.87, 0.11, 2.43, 0.46, -0.71, 3.74, 4.18, -1.04, -1.48, -1.14, 0.15, -1.1, 0.34, -0.33, -0.98, 2.32, 0.35, -0.82, 3.62, 4.06, -1.15, -1.59, -1.25, 0.04, -2.52, -3.22, -1.93, -2.9646649659863944, 1.27, 1.71, -3.39, -3.793605339105339, -3.49, -2.23, -0.25, -3.33, -2.66, -0.82, -0.57, -1.21, -1.32, -1.16, 3.26, 3.7, -1.49, -1.93, -1.59, -0.31, 0.56, -0.10692325186963274, 4.48, 4.92, -0.1613969800041227, -0.77, -0.44, 0.86, 0.16, 0.0, 0.06, -1.29, -7.6, -0.47, -0.48, 2.9, -2.9, -1.4111898289923788, -0.11, 0.17, 9.38, 1.61, 0.87, -6.5, -0.37, -2.73, 2.72, 2.49, -0.82, 4.31, -1.65, -2.63, 1.3, -3.95, 1.2, 2.66, 3.87, -9.52, -4.44, 0.43, -4.61, -5.03, -4.7, -3.46, -2.47, -4.84, -5.01, -5.43, -5.11, -3.87, 0.18, -0.44, -0.1, 1.2, -0.94, -1.08, 0.62, 0.34, 1.65, -0.85, -0.92, -0.92, 0.66, -2.39, -0.72, -0.3227361894755667, -2.59, 0.28, 1.31, -0.91, -1.41, -0.17470204795204777, -0.63, 0.15, -1.01, -1.17, -3.95, -0.83], ['452', -0.12, -0.12, 0.011221715620458745, 0.0, 0.1329790809910596, -0.04, -0.81, -0.87, -0.95, -0.33, 0.540608843537415, 0.69, 0.76, -0.06, 1.43, -0.11, 0.17, -0.06, -0.23, -0.53, -0.95, 1.36, 0.39, 0.05, -1.07, -0.89, -0.86, 0.16054545454545455, 0.23, -0.59, 0.9, -0.64, -0.36, -0.59, -0.75, -1.06, -1.47, 0.82, -0.14, -0.43615827680216085, -1.09, -2.77, -1.01, 0.07, -0.5821246055531769, 0.74, -0.8, -0.52, -0.74, -0.91, -1.21, -1.610345270762939, 0.66, -0.29, -0.64, -1.42, -0.51, -0.28217202719021606, -0.95, -1.08, -0.82, 0.67, -0.87, -0.59, -0.82, -0.98, -1.29, -1.7, 0.59, -0.37, -0.71, -1.25, -0.27, 1.5, -0.05, 0.23, 0.0, -0.16, -0.47, -0.88, 1.42, 0.45, 0.11, -1.17, -2.028257052471338, 2.22, -1.70330176161468, -1.53, -1.25, -1.48, -1.64, -1.94, -2.35, -0.08, -1.03, -1.37, -1.44, -0.22, 0.28, 0.05, -0.11, -0.42, -0.83, 1.47, 0.51, 0.16, -0.3090204081632653, -0.23, 0.09572371188304005, -0.2, -0.19, -0.2843264813499681, -0.42819052351387077, -0.23, -0.39, -0.7, -1.11, 1.19, 0.22, -0.12, -1.38, -0.21692325186963274, -0.16, -0.47, -0.89, 1.42, 0.45, 0.11, -1.2, -0.95, 0.03, -0.76, -4.27, 0.0, -0.07, 0.5, -0.4082798741874371, -0.25, 0.45, -0.4, -0.2, 0.53, 0.22, -0.03, 0.49, -0.65, 0.67, 0.62, -0.2, 0.81, -0.43, -0.61, 0.27, -1.51, 2.38, 0.97, 1.5, 0.44, -0.1, -0.31, -0.72, 1.58, 0.62, 0.27, -0.63, 0.21, -0.42, 1.9, 0.93, 0.58, 0.62, 2.32, 1.35, 1.0, -0.98, -1.06, -1.66, -0.95, -1.29, -0.22, -0.35, -0.86, 0.79, -0.43, -0.9634761904761905, -0.53, 0.08, -0.72, -0.34, -1.15, -0.28, 0.47, 0.47, 0.3646262438247291, -0.38, -1.56, -0.11, -0.37], ['453', -4.54, -0.3, -0.38877828437954126, -0.12, -0.77, -0.18, 0.9, -0.1, -0.27, -0.52, 0.24, -0.52, -1.17, -0.69, -0.65, 1.3, -0.84, -0.44, 0.2, 1.44, -0.662664517912641, -0.49, -0.29, -1.04, 0.04, -0.88, -0.76, -0.76, -1.41, -0.94, -0.9, 1.05, -1.08, -0.69, -0.04, 1.19, -0.94, -0.73, -0.54, -1.28, 0.02, -0.83, 0.0, -0.6463410188391392, -0.18, -0.14, 1.83, -0.33, 0.07, 0.72, 1.97, -0.18, 0.03, 0.22, -0.524952380952381, -0.47, -0.43, 0.0, -0.05, 0.66, 0.48, 0.52, 2.5, 0.33, 0.73, 1.38, 2.64, 0.47, 0.69, 0.88, 0.13, 0.06, 0.18, 0.04, 2.01, -0.15, 0.25, 0.9, 2.15, 0.0, 0.21, 0.4, -0.35, -0.86, -0.25, 0.26, 0.14, 1.97, -0.19, 0.21, 0.86, 2.303744771101914, 0.11523523302094742, 0.17, 0.36852380952380953, -0.39, -3.31, -1.79, -2.11, -1.72, -1.09, 0.14, -1.97, -1.77, -1.57, -2.31, -0.01, -1.75, 0.64, 0.01, -0.13, 0.24567351865003195, 0.33, 0.4, 1.0501587301587303, 2.3, 0.14, 0.36, 0.55, -0.2, 0.07, -0.07, 0.65, 1.982244713705627, -0.26, -0.04, 0.15, -0.6, -0.15, 0.16, -0.15, 0.12, -10.09, 0.0, -0.48, 0.01, -0.03, -0.01, -0.02, -0.87, 3.81, 0.0, -0.03, -2.27, 0.1, 0.021476190476190475, 0.0, -0.03, 0.01, -0.03, 0.03, 1.228390654979941, -0.56, 0.93, -2.25, -0.65, -0.98, -3.77, -0.72, 1.24, -0.9, -0.69, -0.49, -1.24, 0.0, -1.93, -2.11, -1.9, -1.71, -2.45, 0.18, 0.21, 0.41, -0.35, -0.3, -0.32, -0.03, 0.2, -0.56, 0.02, 0.04, 0.0, -1.17, 0.45, 1.13, -0.08, -1.03, -0.22, -0.75, 0.17, 0.1, 0.27, 0.33, 0.2, 0.53, -1.16, -1.76, 1.19], ['454', -1.44, 0.03, 0.16, 0.06, -1.01, -0.63, 0.07411525795982916, -0.95, -0.72, -1.15, 0.03, -0.84, -0.69, -0.07, -0.91, -0.47, 0.02, -1.12, -1.8, 0.53, -1.21, -0.68, -0.34, -1.29, -0.3, -0.5, -1.18, -0.8771394557823129, -0.7253571428571428, -0.11, -0.94, -0.5, -0.02, -1.16, -1.84, 0.49, -1.25, -0.71, -0.38, -1.32, -0.05, -3.14, -0.31, 0.15, 0.78, -0.07, 0.38, 0.87, -0.28, -0.97, 1.38, -0.341934531913557, 0.17, 0.51, -0.45, -0.8399371536943234, -0.47, -1.5580521152823785, 0.29, -0.46, 0.62, -0.22, 0.22, 0.71, -0.43, -1.12, 1.23, -0.53, 0.01, 0.35, -0.6, -0.96, -1.08, -0.84, -0.4, 0.09, -1.05, -1.73, 0.6, -1.14, -0.61, -0.1369045181009466, -1.22, -1.89, -2.29, 2.2, -0.24, 0.44, 0.93, -0.21, -0.9, 1.45, -0.31, 0.23, 0.57, -0.3259922724755494, -1.46, -0.68, 0.49, -0.66, -1.34, 1.0, -0.75, -0.21, 0.13, -0.82, -0.09, -0.7, -1.65, -0.46, -0.58, -0.32, -1.16, -1.14, -1.82, 0.51, -1.23, -0.6396949805527123, -0.36, -1.31, -0.44, -0.03, -0.43631441970727664, 1.67, -0.09, 0.45, 0.79, -0.17, -1.32, -1.54, 0.01, -0.59, -4.2, -0.03, 0.09, 0.81, -0.82, -0.43, 0.07, -1.07, 3.18, 0.97, 0.47, -0.65, -0.3, -1.34, 1.4, 1.5, -0.47, 1.19, -0.93, -0.44, 0.24, -3.49, 1.0486904761904763, 2.3, 3.52, -3.28, 0.67, 2.37, 0.6, 1.14, 1.49, 0.52, -1.35, -1.67, -1.73, -1.2, -0.86, -1.81, 0.07, 0.54, 0.88, -0.08, -0.75, -1.07, -0.47, 0.34, -0.62, -0.48, -0.49, -0.85, 2.39, -1.04, -2.61, -0.44, -0.5, -0.81, -0.95, -0.38, -0.9397802197802197, -0.15, -0.11, -0.22, 0.14, -1.12, -1.76, -0.36], ['455', -0.49, 0.03, 0.12, -0.06, -0.09, 0.51, 0.7, 0.17, 0.74, -0.33, -0.67, -0.94, -0.1, -0.74, -0.7, -0.55, -0.73, -0.43, 1.66, -0.38, -0.05, -1.54, -1.31, 0.29, 0.65, 0.33, 0.35, -0.27, 0.57, -0.06, -0.03, 0.13, -0.06, 0.24, 2.34, 0.29, 0.62, -0.87, -0.64, 0.96, 0.3774684253532108, 2.03, 0.62, 0.85, 0.21, 0.24, 0.4, 0.22, 0.52, 2.63, 0.57, 0.9, -0.5061344435209981, -0.37, 1.24, -0.29993715369432344, 0.31, 0.67, 0.4, -0.22, -0.63, -0.6, -0.44, -0.63, -0.33, 1.76, -0.28, 0.05, -1.44, -1.21, 0.39, 0.18, 0.41, 0.03, 0.19, 0.01, 0.31, 2.6574764481550197, 0.36, 0.69, -0.81, -0.58, 1.03, 1.08, 2.38, -2.29, 0.38, 0.16, -0.03, 0.27, 2.38, 0.33, 0.65, -0.84, -0.61, 1.0, 0.04, 0.22, -0.18, 0.12, 2.22, 0.17, 0.49, -1.0, -0.77, 0.84, 0.0, 0.22, 2.57572371188304, 0.18, 0.56, -0.28, 0.4, 0.3, 2.4, 0.35, 0.68, -0.82, -0.59, 1.02, 1.09, 0.1, 2.1, 0.05, 0.38, -1.11, -0.88, 0.72, 0.92, 1.2, -0.18, 0.09, 0.08, 0.1, 0.04, 1.91, -1.91, -0.94, 0.44, -0.51, 0.0, -0.43, -0.19, -0.28, 0.41, 0.48, -0.41, -0.41, 0.18, 2.68, 0.38, 0.85, -0.46, 1.21, -0.76, -0.81, -1.2, -0.07, -1.95, -1.9951904761904762, -1.68, -3.15, -2.92, -1.35, 0.59, 0.05, 0.32, -1.17, -0.93, 0.67, -0.27, -1.49, -1.26, 0.34, 0.72, 0.73, 1.23, 0.23, 1.85, 0.22, 0.16, 0.19, -0.98, 1.0701996269574994, 1.2, -0.08, 0.7, 1.0, 1.62, 0.93, -0.52, 0.0, 0.75, 0.28, -0.61, 1.09, 0.95, -2.19], ['456', -1.67, -0.03, 0.12, 0.14, 0.18, -0.72, -1.4858847420401708, -1.12, -1.33, 0.12, 1.89, 1.61, 0.74, 0.97, 1.55, -0.02, 0.98, -0.03, -1.41, 0.72, -0.10266451791264107, 0.24, 0.59, 0.59, -1.7, -1.23, -1.74, -0.28, -1.12, -0.9, -0.34, -1.87, -0.9, -1.88, -3.23, -1.15, -1.915546329921431, -1.62, -1.28, -1.28, -1.52, -1.46, -1.46, -0.85, -0.62, -0.06, -1.6, -0.62, -1.61, -2.97, -0.88, -1.691934531913557, -1.35, -1.01, -1.0, -0.52, -1.37, -0.48, -0.76, -0.62, 0.23, 0.9048467679404526, -0.75, 0.23, -0.6673949338599383, -2.13, 0.10397573353350675, -0.88, -0.5, -0.16, -0.15, -1.73, -0.85, 0.57, -0.98, 0.0, -0.99, -2.36, -0.25, -1.1, -0.73, -0.38, -0.38, -1.55, -1.46, 1.43, -1.4, -1.54, -0.56, -1.55, -2.91, -0.81, -1.66, -1.29, -0.95, -0.94, -0.45, 0.14, 0.99, -0.01, -1.39, 0.73, -0.12, 0.26, 0.6, 0.6, 0.02, 0.13, -0.24, -0.68, -0.65, -0.704326481349968, -0.85, -0.99, -2.36, -0.25, -1.11, -0.73, -0.38, -0.3214153161169343, -0.08, 0.15, -1.38, 0.75, -0.11, 0.27, 0.62, 0.62, -0.62, -0.57, 0.13, -0.73, -1.28, -0.1, 0.0, 1.96, -1.96, -0.97, 0.0, -1.83, 1.17, 1.4, 0.72, -0.81, -0.36, -2.06, 2.27, 2.05, -0.69, 2.9, -1.36, -1.45, 0.74, -2.6, 3.57, 1.75, 2.57, -1.17, 1.55, 2.15, 1.28, 1.67, 2.02, 2.02, -2.04, -0.59, -0.85, -0.47, -0.13, -0.13, 0.26, 0.38, 0.73, 0.73, -1.25, -1.02, -0.12, 0.34, 0.35, -0.7, -0.69, -1.14, 1.54, -0.43980037304250064, -1.62, -0.99, -1.2, -0.46, 0.0, -0.84, -1.08, -0.31, -0.3, -0.31, -0.46, -1.89, -1.74, -0.16], ['457', 1.48, -0.72, 0.3412217156204588, 0.03, 0.0, 0.17, -0.015884742040170832, 0.84, 0.1, 0.86, 0.81, 0.75, 1.44, -0.38, -1.34, 1.29, 0.39, 0.6, 2.8, 1.74, 1.13, 1.21, 0.41, 0.86, -0.14, -0.22, 0.05, -0.06, 0.63, -1.18, -2.13, 0.47, -0.41, -0.21, 1.97, 0.93, 0.32, 0.4, -0.39, 0.05, 0.58, -1.0450638007838267, 0.11, 0.7711974674961171, -1.12, -2.08, 0.53, -0.36, -0.15, 2.03, 0.99, 0.38, 0.46, -0.2528571428571429, 0.11, 0.37, -0.94, 0.25, -0.12, -0.57, -1.8, -2.74, -0.15, -1.03, -0.83, 1.34, 0.3, -0.14657884575741703, -0.23, -1.01, -0.57, -0.15639399885828442, 1.25, -0.96, 1.67, 0.78, 0.98, 3.19, 2.13, 1.52, 1.6, 0.8, 1.25, 0.37, 1.24, -1.21, 2.23, 2.66, 1.76, 1.96, 4.19, 3.13, 2.5, 2.59, 1.78, 2.23, 0.27, -0.42, -0.88, -0.68, 1.49, 0.45, -0.16, -0.07, -0.86, -0.42, 0.25, -0.44, 0.7201770034254836, 0.16, 0.29, 0.08, 0.47, 0.2, 2.39, 1.35, 0.73, 0.82, 0.02, 0.47, -0.25, 0.26, 2.19, 1.14, 0.53, 0.61, -0.18, 0.26, 1.39, 1.57, 0.02, 0.52, 0.74, 0.5, 0.01, 0.31, -0.31, -0.16, 0.31, 1.11, 1.82, -0.33, -0.18, 0.84, 0.0, 0.5914761904761905, -0.48, -0.4, 0.16, 0.39, 0.31, -0.58, 0.24, 1.38, -3.43, -0.88, -1.34, -1.68, -1.88, -1.02, -1.62, -1.54, -2.32, -1.88, 0.46, -0.87, -0.6, -0.52, -1.31, -0.87, -0.26, 0.08, -0.71, -0.26, 0.1, 0.27, -0.35, -0.79, -0.35, 0.24, 0.27439630127529085, 0.78, -1.54, 0.75, 1.52, 0.32, 0.47, 0.5286374482009709, 0.5227868514969317, 0.7300774025227806, -0.12, 0.09, 0.06, 0.08462624382472905, 0.085957527023814, 0.27, -0.27, 0.88], ['458', -4.2, -0.56, -0.45, 0.18, -1.3, -0.99, -1.98, -2.05, -1.94, -2.4492857142857143, -0.69, -0.9, -0.44, -1.1, -0.25, -1.22, -1.67, -2.37, -3.42, -0.81, -2.92, -1.58, -1.29, -2.18, -2.22, -0.67, -1.77, -0.22, 0.25, -0.41, 0.44, -0.54, -0.99, -1.7, -2.75, -0.12, -2.25, -0.9, -0.6, -1.5, -1.86, -2.9850638007838266, -1.56, 0.47, -0.2, 0.65, -0.32, -0.78, -1.48, -2.54, 0.09, -2.04, -0.69, -0.3028571428571429, -0.9691712018140588, -1.6, -2.27, -2.5, -2.0, -2.02, -0.66, 0.18079931972789115, -0.79, -1.24, -1.95, -2.7103066893424037, -0.38, -2.5, -1.15, -0.85, -1.75, -2.05, -1.37, 0.85, -0.12, -0.58, -1.135765306122449, -2.35, 0.29, -1.84, 0.16000000000000003, -0.19, -1.09, -2.29, -3.31, 3.36, -2.2, -0.97, -1.42, -2.12, -3.17, -0.56, -2.67, -1.33, -1.04, -1.93, 1.98, -1.25, -0.46, -1.17, -2.23, 0.41, -1.72, -0.37, -0.07, -0.97, -0.04885812600098299, -1.24, 0.33, -0.85, -1.02, -0.66, -0.79, -0.71, -1.78, 0.88, -1.27, 0.15030501944728758, 0.39, -0.51, -0.74, -0.026923251869632736, -1.07, 1.6, -0.5504376417233561, 0.81, 1.11, 0.2, -1.0710416300368755, -1.2, 0.33603717887804047, -0.75, 5.617738095238095, -0.26, 0.07, 1.43, -1.41, -0.72, -0.36, -4.11, 3.13, 1.65, 0.87, -2.09, -0.68, -2.56, 2.55, 2.6, -0.85, 2.23, -1.72, -2.8, 1.39, -2.37, 4.97, 1.71, 2.31, -3.38, 1.0, 2.7, 0.52, 1.9, 2.21, 1.29, -2.53, -1.65, -2.13, -0.78, -0.48, -1.38, 0.49, 1.38, 1.68, 0.77, -1.95, -1.96, -0.88, 0.3, -0.6, -0.81, -0.86, -2.04, 2.72, -0.29, -2.55, -0.22, -1.0, -1.18, -0.9, -0.97, -0.83, -0.59, -0.67, -0.91, -0.28, 0.25, -1.15, -0.14], ['459', -1.87, -0.13, 0.21, -0.09, 0.43, 0.53, 0.30411525795982913, 0.62, 0.98, 0.33, -1.62, 0.07, -0.56, 1.56, -0.15, 0.24, -1.35, -0.2, -2.86, -0.52, 0.42, -0.49, -0.45, -1.06, 1.15, 1.13, 2.0126583949931125, 1.72, 1.08, 3.23, 1.49, 1.89, 0.27, 1.44, -1.25, 1.12, 2.08, 1.16, 1.19, 0.57, 0.5, 3.2249361992161734, 0.26, -0.63, 1.48, -0.23, 0.17, -1.42, -0.27, -2.93, -0.59, 0.35, -0.56, -0.53, -1.13, 0.21, 1.1, 1.42, 0.43, 0.89, 2.13, 0.41, 0.8, -0.8, 0.36, -2.31, 0.04, 0.98, 0.07, 0.1, -0.51, 0.78, -1.21, -1.68, -1.3, -2.87, -1.73, -4.35, -2.05, -1.12, -2.01, -1.98, -2.58, 2.18, 2.68, -2.66, 0.5166982383853201, 0.4, -1.2, -0.05, -2.71, -0.37, 0.58, -0.33, -0.3, -0.91, 1.88, 0.09, -1.59, -0.44, -3.09, -0.76, 0.18, -0.72, -0.69, -1.3, 0.5, 0.09, 1.86, 1.2315981806829015, 0.82517906963434, 1.68, 1.71, 1.17, -1.52, 0.84, 1.8, 0.88, 0.91, 0.29, 0.84, 0.5830767481303673, -2.66, -0.32, 0.63, -0.28, -0.25, -0.86, 1.21, 1.49, -0.04, 1.61, 5.53, 0.21, 0.19, -4.91, 4.86, 2.44, 0.28, 0.34, -1.6, -2.35, -1.18, -1.0, 0.56, 3.63, -3.68, -3.42, 1.2132908048638529, -7.19, 2.399878357241315, 1.67, -0.82, 5.140714285714285, -7.49, -3.47, -5.08, 1.65, 3.28, 2.4, 3.37, 2.44, 2.47, 1.84, 3.49, 0.86, 0.95, 0.04, 0.07, -0.55, -0.09, -0.9, -0.87, -1.48, 0.99, 1.2, 0.82, 0.03, -0.58, 1.15, 1.26, 0.66, -4.84, 1.66, 5.05, 1.86, 0.37, 0.79, -0.61, 0.22, 2.62, 0.62, 0.46, 0.97, 1.41, 1.78, 1.9215952380952381, 1.74], ['460', -4.19, -0.21571428571428575, -0.43877828437954125, -0.5, -0.42, -0.83, -3.57, -2.0, -1.64, -2.33, -1.06, 0.43, -0.29, -0.08, 0.02726190476190476, -1.42, -1.15, -1.62, -0.96, -3.6, -2.46, -1.2269251700680273, -0.65, -1.22, -0.62, -1.69, -1.28, 1.5, 0.78, 1.0, 1.1, -0.36, -0.09, -0.57, 0.11, -2.57, -1.41, -0.09000000000000001, 0.42, -0.16, -1.47, 0.08006211180124224, -2.74, -0.72, -0.5, -0.4, -1.84, -1.57, -2.04, -1.38, -4.01, -2.87, -1.65, -0.4385714285714286, -1.63, -1.7, -2.36, -1.56, -1.06, -2.04, 0.22, 0.32, -1.13, -0.86, -1.33, -0.66, -3.32, -2.17, -0.94, -0.36, -0.92, -2.36, -2.25, 0.5202278911564625, -1.35, -1.08, -1.55, -0.88, -3.53, -2.38, -1.16, -0.57, -1.14, -1.5949404761904762, -4.44, 4.48, -2.35, -1.44, -1.18, -1.65, -0.98, -3.426255228898086, -2.48, -1.1642857142857144, -0.67, -1.1859922724755494, -3.62, -0.92, 0.27, -0.20788095238095236, 0.47, -2.21, -1.05, 0.19, 0.78, 0.21, -1.04, -0.95, -1.81, -1.11, -1.24, -0.91, -1.19, -0.48, 0.2, -2.48, -1.32, -0.08, 0.51, -0.06, -0.11, -0.72, 0.68, -2.01, -0.85, 0.4, 0.99, 0.42, -1.18, -0.4, -0.66, -1.05, -10.622047619047619, -1.11, -1.13, 1.9, -1.94, -0.94, -2.01, -0.62, -2.34, 2.21, 1.14, -2.12, -0.34, -3.37, 3.58, 3.33, -1.06, 2.89, -2.21, -0.39, 0.16, -3.53, 8.56, 2.4742857142857146, 3.6514285714285712, 2.42, -1.38, -2.67, -1.52, -0.28, 0.326625850340136, -0.26, -3.15, 1.3201587301587303, 1.19, 2.7071428571428573, 3.07, 2.48, 0.13, 1.26, 1.892857142857143, 1.27, -3.18, -3.4, -1.11, 0.59, 0.02, -1.64, -1.65, -3.33, 4.37, -2.18, -4.36, -1.67, -1.13, -1.69, -0.57, -1.61, -1.18, -0.29, -0.039047619047619046, -0.48, -1.13, -4.27, -1.43, -1.13], ['461', -0.04, -0.92, -0.1, 0.05, 0.1029790809910596, -1.18, -3.8799638336347195, -1.45, -1.79, -0.79, 0.04, 2.37, 1.42, 0.74, 0.47, -0.94, 0.22, -0.05, -0.75, -1.3, -0.62, -0.25, 0.59, 0.53, -3.0, -1.26, -0.84, 2.32, 1.38, 0.7, 0.43, -0.99, 0.18, 0.017258904144408435, -0.79, -1.34, -0.66, -0.3, 0.6388796134390452, 0.49, -2.83, -0.3891024373941227, -3.09, -0.92, -1.59, -1.85, -3.23, -2.1, -2.36, -3.04, -3.58, -2.92, -2.56, -1.74, -1.79, -0.66, -1.97, -0.35217202719021606, -1.16, -2.19, -0.67, -0.94, -2.33, -1.19, -1.45, -2.14, -2.69, -2.01, -1.65, -0.83, -0.88, -1.5, -1.53, -0.27, -1.67, -0.52, -0.79, -1.48, -2.03, -1.35, -0.99, -0.16, -0.1564403582748793, -1.03, -3.84, 3.8, -1.26, -1.41, -0.25, -0.52, -1.22, -1.76, -1.09, -0.72, 0.11, 0.06, -0.24, 0.15, 1.17, 0.9, 0.19, -0.36, 0.33, 0.69, 1.54, 1.49, -0.8, 0.16, -1.79, -1.07, -1.05, -1.12, -1.01, -0.27, -0.97, -1.52, -0.84, -0.47, 0.36, 0.31, -0.62, -0.74, -0.7, -1.25, -0.57, -0.2, 0.64, 0.58, -1.07, -0.86, -0.1, -0.92, -0.76, -0.48, -0.48, 2.01, -2.04, -1.03, -0.65, -2.1738364678879503, -1.01, 2.15, 1.06, 0.0, -0.76, -3.18, 3.04, 3.19, -1.06, 3.11, -2.14, -1.56, 0.81, -2.97, 5.62, 2.06, 3.05, 0.98, -0.05, -0.56, 0.13, 0.5, 1.34, 1.29, -3.18, 0.51, 0.69, 1.06, 1.91, 1.85, -0.18, 0.37, 1.21, 1.16, -1.84, -1.06, -0.54, 0.84, 0.79, -1.08, -1.08, -1.56, 3.31, -1.03, -3.38, -1.66, -0.61, -1.37, -0.05, -1.41, -0.85, -0.94, -0.59, -1.08, -1.32, -1.56, -1.15, -0.67], ['462', -4.7785714285714285, -0.81, -0.23877828437954127, -0.08, -0.45, -0.2, -0.79, -1.14, -0.43, -0.7946428571428571, -0.13, -0.34, 1.27, 0.67, 0.19, 0.1, 1.17, -0.34, 2.14, -0.74, -0.95, 1.75, 2.3, -0.59, 0.47, -1.6, -0.73, -0.2, 1.4, 0.8, 0.32, 0.24, 1.3, -0.21, 2.28, -0.61, -0.82, 1.89, 2.44, -0.46, 0.61, 0.16089756260587734, -0.529795918367347, 1.61, 1.01, 0.52, 0.44, 1.512857142857143, -0.01, 2.49, -0.4088095238095238, -0.62, 2.1, 2.65, -0.26, 0.0, -0.81, -1.22, 0.32, -2.11, -0.59, -1.07, -1.15, -0.1, -1.59, 0.86, -1.98, -2.19, 0.48, 1.02, -1.84, -0.08, -0.8742857142857143, -0.48, -0.56, 0.5, -1.01, 1.46, -1.4, -1.61, 1.73, 1.62, -1.25, -0.8510901360544217, -8.25, 8.24, -1.05, -0.08947959183673469, 0.98, -0.53, 1.95, -0.93, -1.14, 1.56, 2.11, -0.78, -2.63, -0.97, 1.07, -0.45, 2.04, -0.84, -1.05, 1.65, 2.2, -0.69, -0.47, -0.87, -2.35, -0.74, -1.01, -0.55, -2.01, -1.5, 0.96, -1.89, -2.1, 0.58, 1.12, -1.74, -2.55, -0.52, 2.5, -0.4, -0.61, 2.1, 2.66, -0.25, -3.84, -3.63, 0.16, -1.27, -5.24, -0.01, 0.21428571428571427, 1.08, -1.12, -0.57, -2.41, -0.81, 0.31, 1.47, 0.78, -2.2947789115646255, -0.31, -2.54, 2.46, 2.1, -0.76, 1.78, -1.45, 0.71, -0.36, -6.12, 5.23, 4.104285714285715, 6.325714285714286, -0.33, -2.94, -2.82, -3.03, -0.38, 0.16, -2.68, -2.24, -0.13, -0.22, 2.51, 3.07, 0.15, 0.09, 2.73, 3.9157142857142855, 0.37, -0.48, -0.68, -2.57, 0.54, -2.3, -0.86, -0.86, -1.12, 2.65, -2.06, -2.58, -2.18, -1.65, -3.1, -2.83, -0.46, -0.29, 0.3, 0.18, 0.0, -0.27, -3.43, -2.63, -0.82], ['463', -3.03, -0.09, 0.011221715620458745, 0.19, -2.29, -0.24158037632624055, -0.31, -0.74, -0.49, 0.33, 0.48, 1.04, 1.22, 0.88, 1.4, 0.86, 1.05, 0.35, 2.8, 2.39, 0.22733548208735893, 0.55, 1.11, 0.77, -1.06, -0.51, -0.15, 0.55, 0.74, 0.4, 0.91, 0.38, 0.57, -0.12, 2.310714285714286, 1.9, -0.29, 0.07, 0.62, 0.29, -0.38, -0.43506380078382656, -0.7, 0.18, -0.16, 0.36, -0.18, 0.02, -0.67, 1.75, 1.34, -0.84, -0.48, 0.07, -0.26, -1.0, -0.61, 0.07, -0.06, -0.88, -0.34, 0.17, -0.36, -0.17, -0.7573949338599383, 1.56, 1.15, -1.02, -0.67, -0.12, -0.44, -1.05, -0.54, 0.51, -0.02, 0.18, -0.52, 1.91, 1.49, -0.68, -0.33, 0.23, -0.1, -0.44, -2.17, 2.13, -1.05, -0.53, -0.34, -1.03, 1.39, 0.98, -1.19, -0.83, -0.29, -0.61, -0.32, -0.52, 0.2, -0.5, 1.93, 2.132857142857143, -0.66, -0.31, 0.25, -0.08, -0.01, -0.59, -1.68, -0.29, -0.52482093036566, -0.09, -0.72, -0.6886530612244898, 1.73, 1.32, -0.86, -0.5, 0.05, -0.28, -0.15346392892821453, -0.02, 2.693685580292723, 2.02, -0.16, 0.19, 0.75, 0.42, -1.73, -1.7972380952380953, 0.41, -0.86, -0.722047619047619, -0.13, -0.07, 0.3, -0.32, -0.14, -0.26, -1.37, 4.14, 0.61, 0.3, -1.49, -0.11, -0.88, 0.92, 0.9, -0.28, 0.46, -0.63, -1.92, 0.99, -2.11, -0.81, 1.46, 2.12, -3.98, -2.4, -0.4, -2.54, -2.19, -1.65, -1.97, -0.9, -2.01, -2.14, -1.79, -1.249142857142857, -0.9314285714285715, 0.14, 0.36, 0.91, 0.58, -0.46, -0.32, -0.22, 0.55, 0.22, -0.31, -0.39, -0.5574239503761216, 0.22, -1.35, -0.6, -1.2, -0.59, -0.77, -0.25721314850306837, -0.2999225974772193, -0.07, 0.17, -0.55, 0.35, -0.354042472976186, -2.28, -0.89, -0.75], ['464', -1.13, 1.35, 0.42122171562045874, 0.09, 0.6629790809910596, 0.67, 1.5641152579598292, 0.7, 1.0593780543870106, 0.59, -0.24, -0.19, -1.28, 1.12, -0.74, 0.3, -0.59, 0.24, -1.27, -0.75, 0.28, 0.48, -0.44, 0.78, 1.24, 0.52, 0.83, 0.05, -1.05, 1.36, -0.4421800287049088, 0.54, -0.35, 0.48, -1.03, -0.51, 0.52, 0.72, -0.2, 1.02, 1.58, 1.9849361992161734, 0.78, -1.1, 1.31, -0.47918497042472347, 0.49, -0.4, 0.43, -1.08, -0.56, 0.498065468086443, 0.67, -0.25, 0.97, 0.94, 1.45, 1.02, 0.69, 1.89, 2.43, 0.55, 1.61, 0.7, 1.54, 0.02, 0.54, 1.58, 1.79, 0.85, 2.09, 0.55, -0.53, -1.84, -0.81, -1.69, -0.87, -2.36, -1.84, -0.83, -0.63, -1.54, -0.33, 1.17, 2.83, -2.89, 1.34, 1.05, 0.15, 0.99, -0.53, -0.01, 1.02, 1.23, 0.3, 1.5840077275244506, -0.34, 0.28, -0.89, -0.06, -1.57, -1.05, -0.03, 0.18, -0.74, 0.48, 0.43, 0.32, 1.74, 0.8, 1.06, 0.5, 1.18, 0.9665993906886764, -0.68, -0.16, 0.87, 1.08, 0.15, 1.38, 0.27, 0.35, -1.5, -0.98, 0.04, 0.24, -0.68, 0.54, 1.2089583699631243, 1.37, 0.27603717887804047, 0.6, -1.02, 0.23, 0.41, -1.0, 0.95, 0.5, 0.8240662734668153, 0.56, -2.72, -1.56, -0.82, -0.53, 0.41, 2.24, -2.33, -2.44, 0.8, -1.51, 1.56, -0.32, 0.19, 3.46, -1.89, -2.37, -3.48, 2.74, 1.88, 0.53, 1.56, 1.811610544217687, 0.84, 2.08, 2.37, 1.34, 1.03, 1.24, 0.31, 1.54, 0.31, 0.2, -0.71, 0.51, 0.98, 0.79, 0.1, -0.92, 0.3, 0.82, 0.76, 0.63, -0.39, 1.25, 0.42, 0.93, 1.77, 1.03, 1.23, 1.0600774025227806, 0.53, 0.67, 1.1, 1.29, -0.2, 2.13, 3.13, -0.82], ['465', 1.49, -1.57, 0.2912217156204588, -0.28, 0.97, 0.7384196236737595, 2.2141152579598296, 0.8, 1.29, 1.94, 0.78, 0.2393248299319728, 1.48, 1.59, 0.93, 2.01, 0.51, 1.83, -0.12, -0.32, 2.0, 2.81, 0.75, 0.67, 0.81, 1.62, 1.1826583949931124, -0.54, 0.7, 0.81, 0.15, 1.22, -0.26, 1.05, -0.89, -1.09, 1.22, 2.02, -0.03, -0.11, 1.29, 2.61, 1.7, 1.25, 1.36, 0.69, 1.77, 0.28, 1.6, -0.35, -0.55, 1.77, 2.57, 0.52, 0.44, 0.1, 0.15, 0.81, 0.8, 0.44, 0.1, -0.55, 0.52, -0.96, 0.34, -1.59, -1.7797619047619049, 0.51, 1.31, -0.72, -0.8, 0.9, 0.34, -0.65, 0.41, -1.06, 0.24, -1.69, -1.88, 0.41, 1.2, -0.83, -0.91, 1.84, 2.79, -2.72, 1.0, 1.07, -0.41, 0.9, -1.04, -1.24, 1.07, 1.87, -0.17, -0.26, 0.98, -0.07, -1.46, -0.17, -2.0544149659863944, -2.29, 0.0, 0.79, -1.23, -1.31, -0.02, -0.11, 1.57, 0.8715981806829014, 0.93, 0.8, 1.41, 1.31, -0.64, -0.83, 1.48, 2.28, 0.23, 0.15, -0.82, 0.15307674813036726, -1.92, -2.12, 0.17, 0.96, -1.06, -1.14, 1.82, 1.43, -0.59, 1.34, 3.09, 0.14, -0.1, -2.19, 2.15, 1.09, -0.69, 1.74, -4.44, -1.65, -0.85, 0.74, -0.08, 2.47, -2.46, -2.45, 0.863290804863853, -3.27, 1.6998783572413152, 2.46, -1.27, 4.26, -1.42, -2.9, -4.24, 4.62, 2.06, -0.2, 2.13, 2.94, 0.88, 0.79, 2.4608051948051948, 2.27, 2.33, 3.14, 1.08, 1.0, -0.07, 0.8788785911064217, -1.23, -1.31, 1.27, 1.21, -0.85, -2.0, -2.08, 0.78, 0.93, 0.72, 0.84, 1.95, -0.73, 1.3472638105244332, 1.78, 1.18, -0.08, 1.35, 0.87, -0.10470204795204777, -0.42, 0.09, 1.26, 2.12, 3.04, 1.66], ['466', 8.66, 0.95, 0.26122171562045876, -0.12, 3.89, 1.85, 2.3041152579598294, 3.68, 3.47, 5.28, -0.16, 3.53, 2.79, 0.41, 2.24, 2.38, 2.23, 4.62, 4.66, -1.35, 6.75, 3.06, 3.18, 3.59, 3.68, 2.83, 5.482658394993113, 3.7, 2.960119047619048, 0.57, 2.457819971295091, 2.55, 2.4, 4.79, 4.83, -1.19, 6.92, 3.23, 3.34, 3.75, 2.32, 7.524936199216174, 1.68, -0.72, -3.02, -1.25, -1.11, -1.26, 1.05, 1.09, -4.71, 3.11, -0.46, -0.34, 0.05, 2.37, 2.67, 3.3, 2.2, 2.42, -2.32, -0.54, -0.39, -0.54, 1.78, 1.82, -4.02, 3.86, 0.32965816326530617, 0.38, 0.78, 4.03, 4.85, 1.82, 1.97, 1.82, 4.2, 4.24, -1.75, 6.761853741496599, 2.8671428571428574, 2.76, 3.16, 5.92, 6.01, -5.82, 3.0066982383853205, 0.14052040816326533, -0.01, 2.33, 2.37, -3.5, 4.42, 0.81, 0.92, 1.3740077275244507, 3.09, 2.83, -0.15, 2.19, 2.23, -3.64, 4.27, 0.66, 0.78, 1.18, 0.73, 2.89, 3.94, 2.11, 2.0, 2.31, 2.98, 2.4765993906886763, 2.38, -3.5, 4.42, 0.81, 0.93, 1.32, 1.89, 0.63, 0.04, -5.7, 2.04, -1.49, -1.38, -0.99, 2.0, 2.11, 0.03, 2.76, 9.27, 0.1, 0.02, -5.32, 5.29, 2.65, 0.28, 4.43, -13.65, -4.17, -2.11, 4.17, 1.18, 6.19, -6.22, -6.34, 2.12, -7.91, 4.13, 3.08, -1.52, 8.85, -8.74, -5.9, -8.74, 12.95, 0.59, -5.74, 2.0, -1.53, -1.42, -1.03, 6.41, 6.71, 8.21, 4.47, 4.59, 5.0, -1.38, -3.46, -3.35, -2.97, 3.51, 4.13, 2.15, 0.11, 0.51, 1.98, 2.334396301275291, 3.64, -5.34, 3.8, 5.39, 2.5218948994148556, 2.33, 2.03, 0.39, 3.08, 2.54, 1.55, 0.35, 1.55, 1.7159575270238139, 3.71, 3.53, 3.59], ['467', -8.035714285714285, -0.34, 0.11015289830927054, 0.2, -1.12, -0.18, -1.13, -1.74, -0.36, -1.92, -1.09, -2.08, -0.32, -0.89, -0.99, 1.8810714285714285, -1.3, -1.85, -3.41, 0.39, -1.87, -1.81, -1.29, -2.13, -0.8, -1.55, -0.8073416050068876, -1.0, 0.78, 0.2, 0.1, 3.0, -0.21, -0.6527410958555916, -2.35, 1.5, -0.715546329921431, -0.73, -0.2, -1.06, -0.08, -0.48, 0.17, 1.8, 1.21, 1.12, 4.05, 0.8, 0.24, -1.36, 2.53, 0.21, 0.28, 0.81, -0.05, -1.68, -0.86, -1.36, 0.0, -1.6, -0.58, -0.67, 2.21, -0.98, -1.53, -3.1, 0.71, -1.56, -1.5, -0.97, -1.82, -3.2, -1.03, -0.1, 3.236658163265306, -0.41, -0.96, -2.54, 1.3, -0.99, -0.93, -0.4, -1.25, -0.56, -1.94, 1.92, -0.94, 2.9, -0.31, -0.87, -2.45, 1.4, -0.89, -0.83, -0.3, -1.16, -4.73, -3.73, -3.12, -3.66, -5.19, -1.46, -3.68, -3.593605339105339, -3.11, -3.94, -0.07, -3.81, 0.0, -0.43, -0.53, -0.33, -0.5581905235138708, -0.56, -2.14, 1.71, -0.58, -0.52, 0.01, -0.85, -0.11, -0.07, -1.59, 2.28, -0.03, 0.04, 0.57, -0.29, -1.54, -0.95, 0.44, -0.6, -14.15, 0.04, 0.11, 0.4, -0.4, -0.2, -0.29, -1.21, 4.56, 0.87, 0.46, -4.385357142857143, 0.03, -1.45, 1.46, 1.37, -0.41, 0.7, -0.89, -2.76, 1.36, -1.82, 0.0, 1.26, 1.83, -4.42, 1.55, 3.94, 1.59, 1.701610544217687, 2.2, 1.32, -1.3, -2.3, -2.26, -2.2, -1.67, -2.52, -0.04, 0.06, 0.6, -0.26, -0.34, -0.36, -0.022725315092565576, 0.53, -0.33, -0.41, -0.49, -1.43, -0.32, 0.04033326278406317, 0.28, -1.75, -1.64, -0.64, -0.86, -0.67, -0.56, 0.15, 0.25, 0.07, 0.305957527023814, -2.75, -2.18, -0.36], ['468', 1.49, 0.65, -0.4, 0.21, 0.2929790809910596, -0.22, -2.91, 0.17, -0.02, 0.86, 0.4, 1.34, 0.45, 1.12, 0.76, -0.08, 0.69, 0.73, 5.22, -0.52, 2.21, -0.02, 0.47, 0.68, 0.09, 0.33, 0.46, 0.94, 0.05, 0.72, 0.36, -0.47, 0.3, 0.34, 4.81, -0.91, 1.8, -0.41, 0.08, 0.28, -0.26, -1.3350638007838267, -0.47, -0.88, -0.21, -0.57, -1.4, -0.64, -0.6, 3.83, -1.83, 0.86, -1.34, -0.86, -0.65, 0.64, -0.74, 0.07, -0.3, 0.41, 0.67, 0.32, -0.52, 0.25, 0.29, 4.76, -0.9597619047619047, 1.75, -0.46, 0.03, 0.23, 0.02, -0.26, -0.36, -1.19, -0.42, -0.38, 4.307476448155019, -1.62, 1.07, -1.13, -0.64, -0.44, 0.15, 1.12, -1.02, 0.1, -0.83, -0.07, 0.5971428571428571, 4.43, -1.27, 1.43, -0.77, -0.29, -0.08, 1.5, 0.94, 0.77, 0.81, 5.3, -0.44, 2.28, 0.06, 0.55, 0.75, 0.22, 1.1, 1.73, 0.07, 0.14, 0.09567351865003196, 0.1709570400359874, 0.04, 4.5, -1.2, 1.5, -0.7, -0.22, -0.02, 1.01, 0.12, 4.46, -1.24, 1.46, -0.74, -0.26, -0.06, 0.14, 0.0, 0.58, 0.543186783623568, 4.677738095238095, 0.13, 0.07, 0.68, -0.71, -0.36, 0.88, 0.08, -2.62, -0.17, -0.07, 0.83, 0.29, -0.02, -0.18, -0.24, 0.09, 0.99, 0.07, -1.14, 0.51, 0.7963956916099773, 5.18, -0.38, -0.51, 2.72, -4.15, -5.45, -2.87, -4.98, -4.52, -4.32, 0.41316789956075695, 1.38, 2.73, 0.5, 0.99, 1.2, -1.32, -2.17, -1.7, -1.49, -0.03, 0.06, 0.88, 0.49, 0.7622487553150162, 0.07, 0.12, 0.18, 2.44, 1.37, -2.44, 0.23, -0.11, 0.39, 0.21, 0.12, -0.41, -0.4, 0.72, 0.74, 0.18, 0.08, -0.13, -0.05], ['469', -4.6, -0.68, 0.0, 0.14, -1.0, -0.53, -0.71, -1.57, -0.68, -3.41, -1.99, -3.8, -2.15, -1.53, -1.86, -2.97, -2.4, -3.57, -1.15, -1.67, -3.54, -2.13, -2.235694768399324, -3.09, -0.9414063389924735, -1.44, -1.45, -1.85, -0.17, 0.46, 0.12, -1.0066496598639456, -0.42, -1.62, 0.85, 0.32, -1.59, -0.15, -0.35, -1.12, -0.48253157464678914, -1.41, 0.4, 1.71, 2.35, 2.01, 0.86, 1.45, 0.24, 2.75, 2.21, 0.298065468086443, 1.73, 1.53, 0.74, -0.5, -0.65, -0.13217202719021603, -1.0, -1.29, 0.63, 0.29, -0.84, -0.26, -1.45, 1.02, 0.49, -1.42, 0.02, -0.18, -0.96, -1.26, -1.91, -0.34, -1.46, -0.88, -2.07, 0.38, -0.14, -2.04, -0.61, -0.81, -1.58, -1.32, -2.92, 2.99, -1.5433017616146798, -1.13, -0.55, -1.74, 0.72, 0.2, -1.71, -0.28, -0.48, -1.25, -1.73, -0.45, 0.59, -0.62, 1.87, 1.34, -0.59, 0.86, 0.66, -0.12, 0.22, -0.44, -1.79, -0.69, -0.87, -0.534326481349968, -1.0390429599640125, -1.2, 1.28, 0.7505357142857143, -1.17, 0.27, 0.07, -0.7, -1.24, 0.16, 2.51, 1.97, 0.03, 1.49, 1.29, 0.5, -1.49, -1.63, -0.16, -1.03, -5.23, -0.2196768707482993, -0.17, 0.26, -0.28, -0.13, -0.7, -2.38, 3.49, 1.39, 0.72, -2.33, -0.15, -2.2, 2.21, 2.29, -0.7, 0.63, -1.4, -0.48, 0.23, -3.129285714285714, -16.57, 2.05, 3.13, -3.64, -2.28, -0.52, -2.42, -0.99, -1.19, -1.96, -2.06, -1.77, -1.9, -0.47, -0.67, -1.44, 0.14, 1.46, 1.26, 0.47, -0.71, -1.12, -1.31, -0.2, -0.8977512446849837, -0.7, -0.78, -1.51, 3.27, -1.49, -3.37, -1.6981051005851444, -2.33, -1.11, -0.77, -1.28, -0.17, 0.09, -0.29, -0.12, -0.34, -3.17, -3.38, -0.63], ['470', -0.55, 1.15, 0.011221715620458745, -0.07, 0.15, 0.03, 1.62, -0.01, 0.22, 0.4, 0.23, -0.28, -0.36, 0.77, 0.37, 0.87, 0.08, 0.3, 1.8, 0.28, 0.16, -0.4, 0.18, -0.26, 0.53, -0.07, 0.16, -0.52, -0.59, 0.54, 0.14, 0.63, -0.15, 0.07, 1.57, 0.04, -0.07, -0.64, 0.03887961343904518, -0.5, -0.36, -0.34, 0.68, -0.07, 1.06, 0.66, 1.15, 0.37, 0.59, 2.09, 0.56, 0.45, -0.12, 0.46, 0.02, -0.26, -0.65, -2.41, -0.43, 0.76, 1.13, 0.73, 1.23, 0.44, 0.66, 2.17, 0.64, 0.52, -0.05, 0.54, 0.09, -0.48, -0.37, -0.4, 0.09, -0.69, -0.47, 1.02, -0.49, -0.61, -1.17, -0.59, -1.03, 0.15, 0.99, -0.98, 0.03, 0.5, -0.29, -0.07, 1.43, -0.09, -0.21, -0.77, -0.19, -0.63, -1.54, -0.46, -0.78, -0.56, 0.93, -0.58, -0.7, -1.26, -0.68, -1.12, 0.1, -0.41, 1.74, 0.28, 0.19, 0.4, 0.32, 0.22, 1.72, 0.2, 0.2557782534925394, -0.49, 0.09, -0.35, 0.9765360710717854, 0.1, 1.5, -0.02, 0.038603019995877313, -0.7, -0.12, -0.56, 0.38, 0.13, 0.04, 0.43, -4.45, -0.06, -0.11, -0.42, 0.42, 0.21, 0.12, 0.82, -0.21948175112272847, -0.54, -0.29, -0.3, 0.25, 0.81, -0.79, -0.86, 0.26, -0.59, 0.54, 0.78, -0.42, 0.95, -3.77, -0.68, -0.93, 0.28, -1.38, -1.5, -1.61, -2.17, -1.6, -2.03, 0.82, 0.12, -0.12, -0.68, -0.1, -0.54, 0.24, -0.57, 0.01, -0.43, 0.2227953514739229, 0.08, 0.8972746849074344, 0.58, 0.14, 0.27, 0.29, 0.04, -2.13, 1.54, 2.18, 0.13, 0.36, 0.22043171114599686, -0.36721314850306835, 0.27, 0.07, 0.83, 0.18, -0.22, 0.67, -0.13, 0.89, 0.48], ['471', -1.75, 0.02, 0.20015289830927055, -0.04, -1.0, 1.03, 0.9641152579598291, 0.9117205965359587, 1.6, 1.14, -0.59, 0.08, 0.69, 0.77, 0.08, 1.78, 0.18, 0.56, -0.24, 0.76, 1.697335482087359, 0.5, 0.74, 0.31, 2.18, 0.96, 1.74, 0.67, 1.28, 1.37, 0.67, 2.38, 0.77, 1.16, 0.36, 1.36, 2.27, 1.1, 1.34, 0.91, 1.31, 2.44, 1.06, 0.61, 0.69, 0.0, 1.7, 0.1, 0.48, -0.21286444351387962, 0.69, 1.59, 0.43, 0.67, 0.23, 0.99, 1.33, 1.0, 1.54, 0.45, 0.08, -0.6, 1.08, -0.51, -0.13, -0.92, 0.07, 0.97, -0.18, 0.06, -0.37, 0.99, 0.37, -0.68, 1.0, -0.59, -0.2, -1.0, -0.01, 0.89, -0.26, -0.02, -0.45, 2.02, 0.9, -0.91, 1.06, 1.7, 0.1, 0.48, -0.32, 0.68, 1.58, 0.42, 0.67, 0.23, 0.35, -0.63, -1.57, -1.19, -1.98, -1.0, -0.11, -1.25, -1.01, -1.44, 0.6, -0.73, 0.16, 0.85, 0.78, 0.95, 0.96, 0.38, -0.41, 0.58, 1.49, 0.33, 0.57, 0.13, 0.63, 0.58, -0.79, 0.2, 1.1, -0.06, 0.18, -0.25, 0.29, 0.87, 0.17, 0.89, 0.58, 0.33, 0.42, -2.36, 2.39, 1.19, 0.55, 0.31, -0.73, -1.66, -0.88, -0.85, 0.44, 2.61, -2.62, -2.56, 0.86, -3.49, 1.7, 0.11, 0.03476526428424678, 2.88, -8.55, -1.96, -2.86, 0.69, 1.38, 1.0, 1.91, 0.74, 0.98, 0.55, 2.66, 0.38, 0.9, -0.26, -0.02, -0.45, -0.52, -1.14, -0.9, -1.33, 1.682795351473923, 1.65, 0.63, 0.24, -0.19, 0.87, 0.89, 0.89, -4.25, 0.5, 4.33, 1.16, 1.04, 0.39, -0.43, 1.56, 1.18, 0.55, 0.15, 0.37, 0.83, 1.76, 0.84, 0.66], ['472', -6.98, 0.13, -0.25, 0.11, -1.04, -1.5, -1.29, -2.25, -2.48, -2.24, 0.66, -1.02, -0.35608673487915105, -0.41, 0.49, -1.3, -0.34, -1.48, -3.86, 0.49, -3.162664517912641, 0.39, -0.3, -0.5, -2.28, -2.45, -2.88, -1.66, -1.07, -1.06, -0.16, -1.94, -0.99, -2.12, -4.04429761904762, -0.17, -3.83, -0.27, -0.96, -1.15, -2.7, -3.3, -1.24, 0.6, 0.61, 1.52, -0.28, 0.68, -0.47, -2.87, 1.52, -2.21, 1.42, 0.72, 0.52, -0.8199371536943234, -2.44, -3.1, -3.01, -1.83, 0.01, 0.92, -0.88, 0.08, -1.06, -3.45, 0.92, -2.79, 0.81, 0.12, -0.08, -3.12, -1.84, 0.91, -0.89, 0.07, -1.07, -3.47, 0.9, -2.8, 0.8, 0.11, -0.03644035827487928, -3.33, -5.78, 5.83, -2.72, -1.78, -0.83, -1.96, -4.33, 0.0, -3.67, -0.1, -0.79, -0.99, -2.34, -0.8826334687834371, 0.97, -0.19, -2.6, 1.81, -1.93, 1.7, 1.0, 0.81, -0.67, -0.93, -2.61, -1.54, -1.56, -1.54, -1.8381905235138707, -1.14, -3.53, 0.83, -2.87, 0.73, 0.04, -0.16, -2.52, -0.77, -2.42, 2.0, -1.75, 1.89, 1.19, 0.99, -2.31, -2.26, -0.04, -1.596813216376432, -4.62, -0.22, -0.16, 2.76, -2.78, -1.4, -1.26, -1.88, 5.27, 3.07, 1.55, -3.54, -0.93, -4.56, 4.63, 4.56, -1.466709195136147, 4.25, -3.07, -1.57, 0.77, -5.72, 8.58, 3.85, 5.71, -5.292869047619047, 1.68, 4.52, 0.69, 4.42, 3.7, 3.5, -4.52, -2.72, -3.67, -0.1, -0.79, -0.98, 0.99, 3.798878591106422, 2.99, 2.79, -2.6, -3.05, -2.62, -0.69, -0.88, -1.53, -1.61, -2.2, 4.16, -2.53, -4.2, -1.42, -2.02, -1.94, -0.2, -1.68, -1.23, -0.99, -0.38, -1.75, -1.75, -1.29, -1.86, -1.85], ['473', 2.3, 0.25, 0.18122171562045875, -0.14, 0.3329790809910596, 0.3, 0.97, 0.37, -0.35, 2.89, 3.56, 2.48, 2.14, 3.39, 1.94, 2.29, 1.14, 2.66, 2.44, 2.41, 1.87, 2.18, 1.644305231600676, 2.15, 0.12, 0.49, -0.65, -1.04, -1.37, -0.17, -1.56, -1.23, -2.33, -0.87, -1.08, -1.11, -1.63, -1.33, -1.94, -1.36, 0.17, -2.5050638007838266, 0.4, -0.33, 1.057875394446823, -0.52, -0.19, -1.31, 0.18, -0.04, -0.07, -0.5803452707629391, -0.29, -0.91, -0.32, 0.0, -0.24, 0.13, -0.24, 0.73, 1.22, -0.2, 0.14, -0.98, 0.51, 0.29, 0.26, -0.26, 0.04, -0.58, 0.01, 0.23, -0.48, -1.4, -1.06, -2.17, -0.71, -0.92, -0.95, -1.47, -1.17, -1.78, -1.2, -1.08, 3.49, -3.53, 0.93, 0.34, -0.78, 0.7, 0.49, 0.46, -0.07, 0.24, -0.39, 0.21, -0.04, 0.59, -1.12, 0.36, 0.15, 0.12, -0.41, -0.1, -0.72, -0.13, 0.28, 0.63, 3.6, 0.61, 0.72, 0.56, 1.73, 1.5, 1.28, 1.25, 0.72, 1.03, 0.4, 1.0585846838830657, 0.9265360710717855, 0.27307674813036725, 0.04368558029272332, -0.24, -0.77, -0.46, -1.08, -0.49, 2.0189583699631246, 1.98, -0.19396282112195956, 1.17, -0.29, 0.26, 0.13, -1.05, 1.03, 0.5788101710076211, 0.43, 0.52, -0.88, -1.3, -0.6, 1.25, 0.39, 1.8914761904761903, -1.9, -1.8, 0.6, -1.55, 1.24, 0.92, -0.5, 5.09, -3.79, -3.43, -5.18, 0.9, 0.44, -0.03, -0.55, -0.25, -0.87, -0.28, 1.79, 0.47, -0.38580741107631855, -0.22, -0.84, -0.25, 1.0, 0.31, -0.32, 0.28, -0.36, -0.76, 0.69, -0.62, -0.03, 0.59, 0.71, 0.43, -3.95, 2.62, 3.85, 0.4918948994148555, 0.54, 1.32, 0.6, 0.7200774025227806, 0.52, 0.3, 0.43, 0.42, 0.72, 2.86, 1.38, 1.25], ['474', -0.72, 0.41, 0.12, -0.1, 0.11, 0.1484196236737595, 0.24411525795982916, 0.09, -0.16, -0.08, 0.19, 0.05, 0.61, 0.67, -0.56, -0.14, -0.72, -0.1, 1.35, -0.66, -0.28, -0.53, -1.22, -0.48, -0.91, 0.36, -0.27, -0.14, 0.41, 0.48, -0.75, -0.33, -0.91, -0.29, 1.16, -0.85, -0.47, -0.72, -1.41, -0.67, 0.39, -0.38, -0.13, 0.56, 0.63, -0.6, -0.18, -0.77, -0.15, 1.3, -0.71, -0.301934531913557, -0.58, -1.2357142857142858, -0.53, 6.07, 0.42, 0.017827972809783946, 0.05, -0.68, 0.07, -1.15, -0.74, -1.32, -0.7, 0.74, -1.26, -0.88, -1.13, -1.82, -1.08, -0.41, -0.75, -1.22, -0.8, -1.38, -0.77, 0.67, -1.33, -0.95, -1.19, -1.88, -1.15, -0.23, 2.8, -2.83, 0.48, 0.42, -0.16, 0.46, 1.92, -0.11, 0.28, 0.03, -0.67, 0.07, 0.0, 0.06, -0.58, 0.03, 1.49, -0.53, -0.15, -0.39, -1.09, -0.35, -0.04, 0.07, 0.76, 0.38, 0.46, 0.29567351865003194, 0.64, 0.62, 2.09, 0.06, 0.44, 0.19, -0.51, 0.24, 0.35, 0.07307674813036727, 1.46, -0.56, -0.17043764172335601, -0.42, -1.12, -0.38, 0.92, 1.16, -0.09, 0.53, 0.01, 0.05, 0.04, -1.06, 1.1417201258125629, 0.51, 0.16, -0.18, -1.18, -0.75, -0.36, -0.35, -0.57, 1.14, -1.16, -1.12, 0.37, -1.55, 0.76, 0.83, -0.41, 1.91, -4.38, -1.29, -1.98, 1.23, -1.41, -1.99, -1.61, -1.86, -2.54, -1.6442382871563543, 1.12, 0.59, 0.39, 0.14, -0.56, 0.18, 0.2, -0.25, -0.94, -0.2, -0.1, -0.06, 0.45, -0.7, 0.04, 0.37, 0.42, 0.20257604962387837, -2.05, 0.8, 2.12, 0.2, 0.83, 1.16, 0.75, 0.58, 0.59, -0.67, -1.04, -0.23, 0.41, 0.29, 0.85, 0.13], ['475', -4.772857142857143, -0.07, -0.04, 0.18, -1.52, -1.12, 0.5, -1.29, -0.63, -1.04, 0.61, -1.8, -0.58, 0.55, 0.39, 0.42, 0.29, -0.85, 2.45, 2.3, -1.32, -1.04, 0.4, 0.26, -1.83, -1.35, -1.64, -2.39, -1.18, -0.06, -0.22, -0.19, -0.31, -1.45, 1.83, 1.67, -1.92, -1.64, -0.21, -0.35, -1.06, -0.19, 0.7702040816326531, 1.24, 2.39, 2.23, 2.26, 2.13, 0.96, 4.33, 4.17, 0.48, 0.77, 2.24, 2.1, -0.57, -0.5, -0.84, -1.25, -0.46, 1.14, 0.98, 1.0, 0.88, -0.27, 3.05, 2.89, -0.75, -0.46, 0.99, 0.85, -1.31, -1.58, -0.16, -0.13, -0.25, -1.39, 1.89, 1.74, -1.86, -1.58, -0.15, -0.29, -1.04, -3.71, 3.73, -1.43, 0.03, -0.1, -1.24, 2.05, 1.9, -1.71, -1.43, 0.01, -0.13, -3.54, -1.45, -0.12, -1.26, 2.02, 1.87, -1.73, -1.45, -0.02, -0.16, 0.061141873999016993, -1.5, -0.31, -1.09, -0.93, -1.24, -1.33, -1.0034006093113235, 2.15, 1.99, -1.61, -1.33, 0.11, -0.03, -0.08, -0.19, 3.33, 3.17, -0.48, -0.19, 1.26, 1.12, -1.53, -1.16, 0.35, -0.99, -10.61, -0.03, 0.14, 3.65, -3.63, -1.83, -0.21, -2.27, 6.38, 2.19, 1.1, -2.3747789115646256, -0.55, -3.35, 3.21, 3.33, -1.1, 5.45, -2.18, -1.22, 0.58, -3.89, 2.26, 2.57, 3.83, -6.28, -3.41, -0.15, -3.68, -3.41, -2.0, -2.14, -3.26, -3.26, -3.54, -3.26, -1.85, -1.99, 0.29, 0.29, 1.75, 1.6, -0.61, -1.07, 0.0, 1.46, 1.32, -1.07, -1.09, -1.35, 0.95, -0.39, -1.17, -0.96, -0.56, -1.44, -0.14, -1.09, -1.56, -0.32, 0.12022448979591838, -1.03, -1.3, -0.66, -0.37, -1.36], ['476', 5.09, 0.8, 0.011221715620458745, -0.1, 0.64, 0.56, 0.0, 1.4, 0.54, -0.03, -0.36, 0.801934498041641, -1.35, -2.18, -1.97, -0.84, -0.22, -0.22, 1.57, -0.8, 0.48, -0.18, -0.6, 0.03, 2.0, 1.49, 0.33, 0.96, -1.0, -1.83, -1.62, -0.49, 0.13, 0.13, 1.93, -0.45, 0.84, 0.18, -0.25, 0.38, 0.52, 1.77, -0.62, -1.94, -2.76, -2.55, -1.43, -0.82, -0.82, 0.971652133580705, -1.39, -0.12, -0.78, -1.19, -0.57, 1.11, 1.01, 0.15, 0.83, 1.34, -0.84, -0.62, 0.52, 1.15, 1.14, 2.96, 0.56, 1.86, 1.19, 0.76, 1.4, 1.0, 2.2, 0.22, 1.37, 2.0, 2.0, 3.83, 1.41, 2.72, 2.04, 1.61, 2.26, 0.87, 1.26, -1.29, 1.98, 1.15, 1.78, 1.78, 3.61, 1.19, 2.5, 1.82, 1.39, 2.04, 3.92, 0.82, 0.63, 0.62, 2.43, 0.04, 1.33, 0.67, 0.24, 0.88, 0.26, 0.9593682032253462, -0.73, 0.53, 0.52, 0.51, 0.19, 0.0, 1.8, -0.58, 0.7, 0.04, -0.38, 0.25, 0.11, 0.2, 1.8, -0.58, 0.7, 0.04, -0.38, 0.25, 0.38, 0.0, 0.12, 0.22, 11.79, 0.02, -0.02, -1.62, 1.63, 0.82, -0.06, 1.3661635321120496, -1.45, -1.02, -0.55, 2.51, 0.2, 1.61, -1.62, -1.55, 0.54, -2.4, 1.06, 0.26, -0.055234735715753214, 0.64, -3.65, -0.44, -0.61, 1.47, -1.57, -2.33, -1.07, -1.72, -2.14, -1.52, 1.51, 0.78, 1.29, 0.62, 0.2, 0.83, -0.5, -0.66, -1.07, -0.45, 0.57, 0.72, 0.15, -0.42, 0.21, 0.55, 0.47, 1.4425760496238782, -1.69, -0.68, 1.67, 1.2, 1.05, 0.58, 0.63, 0.34, 0.81, 0.19, 0.08, 0.59, -0.06, 3.63, 1.42, -0.28], ['477', -1.49, 0.06, 0.05122171562045875, 0.05, -0.14, 0.82, 1.79, 0.29, 1.26, 1.2, 0.3, -0.18, 0.64, 0.47, 1.15, 1.41, 0.25, 1.23, 0.1, 1.17, 1.1, 0.31, 0.32, 0.76, 1.67, 0.14, 0.9, -0.48, 0.33, 0.17, 0.85, 1.1, -0.05, 0.92, -0.2, 0.87, 0.8, 0.01, 0.02, 0.45, -0.86, 1.9700621118012422, 1.38, 0.81, 0.65, 1.33, 1.59, 0.43, 1.4, 0.28, 1.35, 1.28, 0.49, 0.5, 0.94, 0.85, 0.51, 0.52, 0.78, 0.56, -0.17, 0.51, 0.77, -0.38, 0.59, -0.53, 0.6539757335335068, 0.46, -0.32, -0.32, 0.12, 0.76, 0.73, 0.68, 0.93, -0.22, 0.75, -0.37, 0.7, 0.63, -0.16, -0.15, 0.29, 1.61, 2.34, -2.24, 0.05, 0.3480874332127649, -0.89, 0.08, -1.04, 0.2137447711019141, -0.04, -0.83, -0.82, -0.39, -0.34, -0.2, -1.14, -0.18, -1.29, -0.23, -0.3, -1.08, -1.07, -0.64, 0.04, -0.17, 0.89, 0.73, 0.71, 0.76, 0.9509570400359874, 0.97, -0.14984126984126983, 0.91, 0.85, 0.06, 0.07, 0.5585846838830657, 0.78, -0.02, -1.11, -0.05, -0.12, -0.9, -0.9, -0.46, 0.86, 0.83, 0.04, 0.8, -0.84, 0.11, 0.0, -1.62, 1.63, 0.82, 0.54, 0.34, -0.01, -1.4, -0.69, -0.75, 0.75, 2.18, -2.12, -2.17, 0.74, -2.43, 1.46, -0.39, 0.19, 2.82, -4.59, -1.86, -2.77, 0.0, 1.1, 1.07, 1.0, 0.21, 0.22, 0.66, 2.16, 0.03, -0.07, -0.85, -0.84, -0.41, 0.1, -0.78, -0.78, -0.34, 1.26, 1.32, 0.89, 0.01, 0.44, 0.73, 0.75, 0.31, -2.73, 1.0501996269574994, 2.69, 1.19, 0.74, 0.88, 0.44, 0.67, 1.06, 0.41, 0.93, 0.39, 0.44, 0.0, 1.33, -0.01], ['478', 3.22, -0.08, -0.17877828437954127, 0.08, -0.33, -0.6115803763262405, -0.71, -1.88, -1.79, -1.61, 1.58, -0.41, -0.11, -0.08, 0.38, -3.39, -0.41, -1.89, -2.3, -1.47, -2.63, -1.14, 0.26, -0.75, -1.85, -0.61, -3.14, -1.96, -1.66, -1.63, -1.18, -4.89, -1.96, -3.42, -3.81, -3.0, -4.149239316239316, -2.68, -1.3, -2.246158276802161, -1.66, -2.3550638007838267, -1.2, 0.3, 0.34, 0.8, -2.99, 0.0, -1.169454081632653, -1.89, -1.06, -2.23, -0.73, 0.67, -0.34, -0.9299371536943234, -1.75, -1.5321720271902162, -1.0, -1.5, 0.04, 0.49, -3.28, -0.3, -1.6773949338599383, -2.19, -1.36, -2.52, -1.03, 0.37, -0.64, -2.44, -1.53, 0.46, -3.31, -0.34, -1.82, -2.22, -1.4, -2.56, -1.07, 0.33, -0.67, -2.14, -4.91, 4.68, -1.98, -3.75, -0.79, -2.26, -2.67, -1.85, -3.0, -1.52, -0.12, -1.12, 1.71, 1.84, 3.08, 1.55, 1.13, 1.98, 0.78, 2.32, 3.77, 2.73, 0.21, 1.87, -1.79427628811696, -0.6584018193170985, -0.85, -0.584326481349968, -1.2, -1.3434006093113235, -1.89, -1.06, -2.23, -0.73, 0.67, -0.33, -0.46, 0.29, -0.41, 0.43, -0.76, 0.8857995496566927, 2.19, 1.17, -2.5, -2.53, -0.33, -0.8, 3.48, -0.56, -0.36, 0.51, -0.48, -0.26, -0.47, -1.21, 0.45775897911612196, 1.42, 0.73, 1.68, -0.12, -2.21, 2.25, 2.12, -0.73, 0.78, -1.45, -0.92, 0.46, -3.79, 2.73, 2.45, 3.54, -0.2, 0.7, 0.84, -0.35, 1.18, 2.61, 1.59, -2.2, -0.14, -1.18, 0.33, 1.75, 0.74, 1.05, 1.53, 2.97, 1.94, -1.83, -1.95, -0.47, 1.41, 0.4, -0.73, -0.79, -1.82, 1.46, -2.05, -1.49, -0.98, -0.82, -1.86, -1.0, -1.46, -0.23, 0.39529795204795226, 0.18, -0.66, -0.87, -0.72, -0.88, -1.3769832262926027], ['479', 3.21, 1.04, -0.04, 0.05, -0.41, -0.6015803763262405, -1.11, -0.9, -0.77, -1.55, -0.28, -1.55, -1.21, -0.09, -0.38, -2.14, -0.69, -1.47, -1.29, -0.44, -1.44, -1.52, -0.73, -0.69, -0.5314063389924735, -0.35, -1.27, -1.27, -0.94, 0.19, -0.1, -1.86, -0.41, -1.2, -1.01, -0.17, -1.16, -1.24, -0.45, -0.42, -0.26, -0.77, 0.0, 0.34, 1.48, 1.18, -0.6, 0.87, 0.39054591836734703, 0.26, 1.12, 0.11, 0.03, 0.83, 0.87, -0.28, 0.3, -0.68, -0.55, -0.34, 1.14, 0.84, -0.94, 0.53, -0.27, -0.08, 0.78, -0.23, -0.31, 0.49, 0.52, -1.46, -1.46, -0.3, -2.05, -0.6, -1.39, -1.2, -0.36, -1.35, -1.43, -0.65, -0.61, -1.36, -2.0, 2.19, -1.17, -1.76, -0.3, -1.1, -0.91, -0.06, -1.06, -1.14, -0.35, -0.2559922724755494, 2.78, 0.6, 1.48, 0.68, 0.87, 1.73, 0.71, 0.64, 1.44, 1.48, -0.16, 0.61, -1.67427628811696, -0.71, -0.71, -0.74, -0.87, -0.79, -0.61, 0.24, -0.76, -0.83, -0.05, -0.01, -0.01, -0.01692325186963274, 0.19, 1.04, 0.04, -0.04, 0.75, 0.79, -0.85, -0.66, 0.05, -0.82, 8.17, 0.05, 0.1, 2.06, -2.04, -1.0, 0.42, 0.29, 2.22, 1.44, 0.75, 1.68, -0.46, -2.09, 2.15, 2.17, -0.71, 3.1, -1.41, -1.49, 0.74, -2.56, 4.750651360544218, 1.83, 2.71, -2.15, -0.26, 0.85, -0.15, -0.23, 0.5966255411255412, 0.6, -2.2, -1.1098412698412699, -1.0, -1.08, -0.29, -0.25, -0.11, -0.08, 0.72, 0.76, -0.79, -1.2, -0.03, 0.8, 0.83, -0.6379199656859431, -0.74, -0.89, 2.65, -1.9196667372159368, -2.64, -1.39, -0.31, -0.82, 0.04, -0.89, -1.06, -0.31, -0.34, -0.58, -0.86, 0.1, -1.05, -1.15], ['480', 1.65, 0.0, 0.3412217156204588, -0.06, 0.61, -0.29, 0.43, 0.55, 0.5793780543870106, 0.23, -0.67, 0.32, -0.27, 0.11, -0.44, -0.31, 0.68, -0.1, -2.42, -1.88, 0.32, 0.19, -0.8, 0.72, 1.04, 0.689371414588892, 0.91, 1.0, 0.4, 0.79, 0.23, 0.36, 1.36, 0.58, -1.76, -1.22, 1.0, 0.86, -0.13, 1.4, 1.22, 1.04, -0.08, -0.59, -0.2, -0.6891849704247235, -0.63, 0.36, -0.42, -2.72, -2.19, 0.0, -0.13, -1.12, 0.4, 0.6900628463056766, 1.85, 0.22, 0.68, 0.51, 0.39, -0.17, -0.04, 0.95, 0.17, -2.15, -1.4960242664664933, 0.59, 0.46, -0.53, 1.0, 0.4336060011417156, 0.12, -0.56, -0.42, 0.56, -0.21, -2.53, -2.0, 0.2, 0.07, -0.92, 0.61, 0.69, 1.98, -2.07, 0.7166982383853202, 0.13, 1.12, 0.34, -1.98, -1.45, 0.77, 0.63, -0.36, 1.2240077275244505, -1.75, 0.54, 0.99, 0.21, -2.11, -1.58, 0.63, 0.5, -0.5, 1.03, 0.38, 0.53, -1.31, 0.12, 0.42, -0.36432648134996803, -0.44, -0.77, -3.07, -2.54, -0.34931972789115645, -0.49, -1.47, 0.04, 0.11, 0.33, -2.32, -1.79, 0.42, 0.29, -0.71, 0.82, 0.97, 0.63, 0.38603717887804045, -0.34, -6.09, 0.18, -0.2, 1.21, -1.31, -0.63, -0.69, 0.7, -4.25, -0.14, -0.09, 0.84, 0.15, 0.3, -0.32, -0.32, 0.13, 1.95, 0.23, -0.53, 0.24, -1.32, -1.91, 0.94, 1.43, 4.15, 2.71, 0.54, 2.8, 2.67, 1.65, 3.21, 0.33, 2.16, 2.25, 2.11, 1.1, 2.65, -0.09, -0.13, -1.12, 0.4, 0.55, 0.55, 0.13727468490743444, -0.99, 0.53, 0.1, 0.06439630127529085, 0.49, -1.17, -0.99, 1.18, -0.15, 1.6, 1.05, 1.54, -0.43, -0.48, -0.03, 0.45, -0.08, -0.404042472976186, 0.13, 1.7930376647162363, -0.79], ['481', -6.64, -0.28, -0.27, 0.09, -1.31, -1.6815803763262405, -1.4458847420401708, -3.76, -3.1, -5.36, -0.37, -3.41, -2.23, -1.64, -1.56, -2.73, -3.26, -4.95, -3.12, -3.8130204081632653, -6.38, -3.21, -2.69, -4.48, -3.28, -2.73, -4.977341605006887, -3.05, -1.87, -1.27, -1.2, -2.37, -2.9, -4.59, -2.76, -3.5, -6.04, -2.85, -2.32, -4.13, -2.73, -5.68, -2.02, 1.301197467496117, 1.83, 1.9808150295752764, 0.7, 0.15, -1.279454081632653, 0.3, -0.47, -3.08, 0.2, 0.75, -1.12, -2.13, -2.34, -1.92, -2.67, -3.2, 0.61, 0.69, -0.51, -1.05, -2.78, -0.91, -1.66, -4.25, -1.0, -0.46, -2.3, -3.53, -3.78, 0.08, -1.11, -1.65, -3.36, -1.5, -2.26, -4.83, -1.6, -1.07, -2.89, -4.38, -7.35, 7.3, -3.86, -1.19, -1.72, -3.44, -1.58, -2.34, -4.9, -1.67, -1.14, -2.9159922724755494, -4.32, -2.7, -0.54, -2.28, -0.4, -1.16, -3.76, -0.49, 0.04, -1.8, -0.47, -2.65, -2.15427628811696, -1.92, -2.06, -1.7543264813499682, -2.17, -1.75, 0.14, -0.62, -3.23, 0.05, 0.59, -1.27, -2.1, -0.43, 1.92, 1.14, -1.51, 1.83, 2.38, 0.49, -1.93, -1.51, -0.1, -2.18, -12.62, -0.5, -0.36, 3.01, -3.017537676609105, -1.53, -0.55, -5.22, 3.1, 3.89, 1.92, -3.42, -1.19, -5.9085238095238095, 5.8, 5.81, -1.94, 4.55, -3.85, -1.97, 1.05, -6.45, 5.04, 4.32, 6.13, -3.07, -2.31, -0.77, -3.37, -0.1, 0.45, -1.41, -5.79, -1.56, -2.63, 0.68, 1.22, -0.65, 1.1, 3.39, 3.95, 2.03, -2.98, -3.71, -2.22, 0.54, -1.32, -1.96, -1.92, -3.63, 2.78, -2.0698003730425008, -2.93, -2.7127361894755664, -3.48, -2.75, -1.85, -2.1199225974772196, -1.58, -1.09, -1.33, -1.39, -0.92, -4.85, -4.77, -0.95], ['482', 1.07, 0.3, -0.20877828437954127, 0.1, -0.17, -0.3, -0.84, -0.16, -1.15, 0.49535714285714283, 1.73, 1.23, 0.51, 0.97, 0.37, 0.92, 0.6, 0.23, -0.85, 1.12, 0.43, 0.66, 1.17, 0.41217460317460314, -1.1, -0.9, -1.28, -0.49, -1.2, -0.74, -1.34, -0.8, -1.11, -1.48, -2.54, -0.6, -1.28, -1.05, -0.56, -1.3, -0.11, -2.3450638007838265, -0.79, -0.71, -0.25, -0.85, -0.31, -0.62, -0.99, -2.06, -0.11, -0.79, -0.56, -0.06, -0.81, -0.61, -0.48, -1.95, -1.19, -0.08, 0.46, -0.15, 0.4, 0.09, -0.28, -1.36, 0.6, -0.08, 0.15, 0.65, -0.1, 1.17, -0.54, -0.17977210884353745, -0.06, -0.37, -0.74, -1.81, 0.14, -0.54, -0.31, 0.19, -0.56, -1.92, -1.4, 1.44, 0.07, 0.55, 0.23, -0.14, -1.21, 0.75, 0.06, 0.29, 0.8, 0.05, -1.55, -0.48, -0.31, -0.68, -1.75, 0.2, -0.48, -0.25, 0.25, -0.5, 0.18, -0.4, -0.04427628811695997, -0.32, -0.5, -0.06, -0.17, -0.37, -1.44, 0.51, -0.17, 0.06, 0.56, -0.13141531611693433, -0.34, 0.2, -1.08, 0.88, 0.2, 0.43, 0.93, 0.18, -0.08, -0.09, -0.01, 0.13, -4.65, 0.09354725829725827, 0.0, -0.12, 0.08, 0.03, -0.01, 0.8, 1.3, 0.61, 0.28, 0.53, -0.24, -0.83, 0.86, 1.02, -0.3, -0.19, -0.61, -0.44, 0.19, -0.53, 1.69, 0.3, 0.53, -1.26, 1.3, 1.98, 1.29, 1.53, 2.03, 1.27, -0.92, -0.67, -0.68, -0.45, 0.05, -0.7, 0.0, 0.23, 0.73, -0.02, -1.067204648526077, -1.28, -0.23, 0.5, -0.25, -0.32, -0.25, -0.11, 1.07, 0.21, -1.06, -0.53, -0.94, -0.72, -0.6672131485030683, -0.48, 0.06, -0.41, -0.01, 0.0, 0.105957527023814, -1.44, -0.9, 0.53], ['483', 1.8842857142857141, -0.54, -0.04, 0.02, -0.89, 0.12, -0.21588474204017086, 0.13, 1.05, -0.31, -1.9, -0.7, -0.56, -0.33, -0.16, -0.87, -0.2, -1.5494285714285714, 1.79, 2.49, 0.29733548208735894, -1.1, -0.68, -0.67, 0.8, -0.1, 1.62, 1.22, 1.37, 1.6, 1.77, 1.05, 1.73, 0.36, 3.76, 4.47, 2.2, 0.82, 1.25, 1.25, -0.03, 2.34, 0.5993032324818041, 0.15, 0.37, 0.54, -0.17, 0.5, -0.85, 2.51, 3.22, 0.97, -0.4, 0.03, 0.03, 1.62, 0.15, 0.0, 0.81, 0.25, 0.22, 0.4, -0.32, 0.36, -1.0, 2.36, 3.06, 0.83, -0.54, -0.12, -0.12, -0.0063939988582844, 0.03, 0.17, -0.54, 0.13, -1.22, 2.13, 2.83, 0.6, -0.77, -0.34, -0.34, 2.21, 1.61, -1.61, -0.14, -0.71, -0.04, -1.39, 1.96, 2.66, 0.43, -0.94, -0.51, -0.51, 0.54, 0.57, 0.67, -0.6778809523809525, 2.69, 3.39, 1.14, -0.23, 0.2, 0.2, 0.96, 0.54, 0.74, 0.26, 0.43, 0.07, -0.1, -1.35, 2.0, 2.7, 0.47, -0.9, -0.47, -0.47, 0.68, 1.26, 3.6436855802927233, 4.1, 1.84, 0.46, 0.89, 0.89, 0.3, 0.93, 0.09, -0.06, 1.2277380952380952, 0.31, 0.21, 0.44, -0.52, -0.48, -0.14, -0.34, 5.45, -0.49, -0.26, 0.81, 0.47, 0.77, -0.74, -0.74, -0.26, 1.01, 0.47, 0.93, -0.54, -0.3, -1.05, 0.17, 0.24, -5.42, -2.06, 0.69, -1.5, -2.84, -2.42, -2.42, 0.78, -2.73, -2.17, -3.5, -3.09, -3.09, -0.57, -1.36, -0.94, -0.93, 1.0, 1.52, 0.8, 0.43, 0.43, 0.22, 0.24, 0.04, -0.23, 0.66, 0.39, -0.71, -0.8, 0.37, 0.07278685149693166, 0.03, -0.45, -0.06, -0.38, -0.34, 0.37, -0.49, -0.2, 1.02], ['484', 5.91, 1.35, 0.46, -0.06, 2.0929790809910593, 1.28, 1.67, 1.41, 1.96, 0.76, -1.55, -0.94, -0.2, -0.26, -1.29, -0.55, -0.84, 0.28, 2.0, -2.08, 1.23, -0.23, -0.67, -0.97, 1.37, 1.55, 2.3826583949931126, 0.63, 1.38, 1.31, 0.26, 1.03, 0.73, 1.87, 3.61, -0.53, 2.83, 1.35, 0.9, 0.6338417231978392, 1.36, 3.13, 1.71, 0.74, 0.68, -0.36, 0.39, 0.1, 1.23, 2.96, -1.15, 2.19, 0.72, 0.27, -0.04, 0.48, 0.9, 0.79, 1.67, 0.96, -0.06, -1.1, -0.35, -0.64, 0.49, 2.2, -1.88, 1.43, -0.03, -0.47, -0.77, 2.1, 1.03, -1.03, -0.28, -0.58, 0.55, 2.27, -1.82, 1.5, 0.04, -0.41, -0.71, 2.55, 4.0, -3.95, 2.08, 0.76, 0.4717857142857143, 1.6, 3.33, -0.79, 2.56, 1.08, 0.63, 0.33, 2.58, 1.3873665312165628, -0.29, 0.83, 2.56, -1.54, 1.79, 0.32, -0.12, -0.43, 1.06, 1.31, 1.43, 1.6115981806829016, 1.4451790696343398, 1.69, 1.6818094764861293, 1.13, 2.86, -1.25, 2.09, 0.62, 0.17, -0.07141531611693433, 0.79, 0.48, 1.71, -2.36, 0.94, -0.51, -0.95, -1.25, 1.33, 1.43, 0.08, 1.51, 7.46, 0.18, 0.34, -3.78, 3.79, 1.89, 0.56, 1.0861635321120495, -5.83, -3.1, -1.54, 2.98, 0.56, 4.61, -4.7, -4.68, 1.54, -5.68, 3.07, 1.01, -0.53, 4.86, -11.72, -3.25, -4.8, 5.75, -1.21, -3.99, -0.75, -2.18, -2.61, -2.91, 4.69, 2.9, 3.38, 1.89, 1.44, 1.13, -0.46, -1.3511214088935783, -1.88, -2.17, 1.94, 2.3, 0.99, -0.44, -0.75, 1.54, 1.53, 1.38, -6.89, 1.93, 6.92, 2.09, 1.84, 1.44, -0.3, 1.55, 2.2, 1.16, -0.01, 0.8746262438247291, 1.75, 2.25, 2.75, 1.96], ['485', 4.95, 0.18, -0.19, -0.17, 0.92, -0.05, 1.47, -0.25, 0.34, 0.35, 0.19, -1.21, 0.73, 1.39, 0.11, -0.64, 0.9, 1.06, -1.37, 0.12, 0.76, 0.97, 0.46, 0.25, 0.08, -0.1, 0.16, -1.4, 0.53, 1.2, -0.09, -0.83, 0.7, 0.86, -1.56, -0.07, 0.57, 0.78, 0.3688796134390452, 0.10384172319783916, 0.1, -1.0250638007838266, 1.58, 1.96, 2.797875394446823, 1.33, 0.58, 2.13, 2.29, -0.16, 1.35, 2.028065468086443, 2.21, 1.69, 1.47, -0.7699371536943234, 0.55, 0.19, 0.0, -0.38, 0.66, -0.61, -1.36, 0.17, 0.33, -2.08, -0.6, 0.04, 0.25, -0.26, -0.47, -0.1, -1.03, -1.27, -2.01, -0.49, -0.33, -2.73, -1.26, -0.62, -0.41, -0.92, -1.13, 0.0, -0.37, 0.32, 0.27669823838532015, -0.75, 0.79, 0.95, -1.48, 0.01, 0.66, 0.87, 0.36, 0.14, 0.47, 0.99, 1.55, 1.71, -0.74, 0.77, 1.41, 1.62, 1.11, 0.89, -0.44, 0.95, -0.73427628811696, -0.05, -0.08, -0.03, -0.54, 0.16, -2.25, -0.77, -0.13, 0.08, -0.43, -0.64, -0.59, -0.7, -2.4, -0.93, -0.29, -0.08, -0.59, -0.8, 0.59, 0.18, -0.34, -0.27, 1.48, -0.15, 0.07, -0.25, 0.21, 0.13, 0.17, -0.97, -0.42, 0.1, 0.06, 2.5, -0.01, -0.18, 0.28, 0.19, 0.003290804863852956, -0.31, -0.1, 1.18, -0.6, -1.62, 5.05, 1.04, 1.53, 0.7956150793650794, 1.74, 1.51, 2.17, 2.38, 1.86, 1.64, -0.15, 0.23, 0.64, 0.85, 0.34, 0.13, -0.41, 0.21, -0.3, -0.51, 0.31, 0.06, -0.62, -0.51, -0.72, -0.06, -0.1, -0.27, 2.76, -0.4, -2.8, -0.13, -0.17, -0.11, -0.21, -0.39, 0.08, 0.08, 0.12, -0.02, 0.1, -0.43, 0.55, -0.68], ['486', -2.65, 0.7614285714285715, 0.7412217156204587, -0.12, 1.04, 2.01, 1.0741152579598292, 2.29, 2.26, 2.18, -0.84, 0.58, 0.57, -0.23602380952380952, 0.8, 5.75, -1.06, 1.49, 0.66, -1.29, 2.71, -0.54, -1.8, 0.09, 3.31, 1.48, 3.05, 1.43, 1.42, 0.61, 1.65, 6.64, -0.23, 2.34, 1.51, -0.45, 3.57, 0.3, -0.97, 0.94, 1.34, 2.8949361992161733, 1.6, -0.01, -0.81, 0.22, 5.14, -1.63, 0.9, 0.08, -1.85, 2.12, -1.11, -2.36, -0.48, 0.92, 2.22, 1.89, 2.31, 1.6, -0.8, 0.23, 5.15, -1.62, 0.91, 0.09, -1.85, 2.13, -1.1, -2.35, -0.47, 3.3, 2.42, 1.04, 6.0, -0.6805105874517637, 1.7332142857142856, 0.9, -1.05, 2.95, -0.3, -1.57, 0.33, 2.5, 11.23, -11.32, 1.37, 4.91, -1.85, 0.68, -0.14, -2.07, 1.89, -1.33, -2.58, -0.6459922724755494, -0.67, -3.37, -6.44, -4.03, -4.82, -6.65, -2.88, -5.95, -7.14, -5.35, 0.81, -3.38, 3.62, 2.38, 2.75, 2.28, 3.28, 2.58, 1.74, -0.22, 3.81, 0.53, -0.74, 1.17, 2.63, 0.69, -0.82, -2.73, 1.2, -1.99, -3.24, -1.37, 5.23, 5.45, 0.28, 3.13, -1.25, 0.92, 0.64, -4.07, 4.05, 2.01, 1.35, 2.08, -7.04, -4.74, -2.44, -1.24, 1.74, 7.5, -7.5, -7.16, 2.36, -6.16, 4.76, 2.55, -1.26, 9.95, -6.62, -6.71, -9.92, 6.8, 1.52, -1.93, 2.04, -1.19, -2.44, -0.56, 7.12, 3.5201587301587303, 4.05, 0.76, -0.52, 1.4, -0.51, -3.16, -4.39, -2.54, 2.33, 2.42, 2.73, -1.27, 0.63, 2.42, 2.55, 2.23, -3.04, 3.32, 3.22, 2.31, 3.21, 4.06, 1.93, 2.6, 2.02, 1.55, 1.13, 2.09, 2.09, 3.89, 5.08, 3.38], ['487', -4.29, -0.06, -0.5687782843795413, 0.29, -1.48, -1.15, -1.36, -2.31, -3.69, -1.94, 2.59, 3.01, 0.37, -0.23, 1.13, -0.87, -1.03, -1.46, -1.62, -1.09, -3.28, -1.95, 0.034305231600676125, -1.52, -3.06, -1.0, -4.42, 0.41, -1.7423253968253969, -2.75, -1.42, -3.37, -3.54, -3.96, -4.1, -3.59, -5.73, -4.43, -2.58, -4.01, -2.7625315746467893, -5.245063800783826, -4.81, -2.478802532503883, -3.14, -1.82, -3.76, -3.93, -4.34, -4.49, -3.98, -6.11, -4.81, -2.98, -4.4, -0.28, -3.36, -1.62, -2.36, -2.31, -0.6, 0.7507993197278912, -1.24, -1.4, -1.83, -1.98, -1.46, -3.65, -2.3067380952380954, -0.43, -1.89, -2.3, -1.72, 1.3746428571428573, -0.64, -0.81, -1.24, -1.39, -0.87, -3.06, -1.72, 0.30309548189905344, -1.3, -4.39, -4.53, 4.52, -3.0033017616146798, -1.98, -2.14, -2.57, -2.72, -2.2, -4.37, -3.04, -1.18, -2.62, -2.32, -1.09, -0.17, -0.6, -0.76, -0.23, -2.44, -1.09, 0.81, -0.66, -0.63, -1.06, -1.71, -1.19, -1.31, -1.01, -0.92, -0.3034006093113235, -0.59, -0.06, -2.27, -0.92, 0.99, -0.49, -0.19, -0.4369232518696327, -0.15, 0.38, -1.85, -0.49, 1.43, -0.06, -0.98, -0.46, 0.06, -0.92, -4.5, -0.71, -0.5, 1.45, -1.41, -0.7, -0.52, -3.41, 1.87, 2.38, 1.17, -2.16, -0.34, -3.42, 3.47, 3.6, -1.17, 2.21, -2.36, -5.09, 2.55, -2.66, 8.93, 1.84, 2.72, -1.97, -0.33, 0.53, -1.7, -0.34, 1.58, 0.1, -3.56, -0.86, -2.21, -0.86, 1.05, -0.43, 1.39, 1.38, 3.34, 1.82, -3.6, -3.29, 0.0, 1.93, 0.43, -1.22, -1.15, -2.34, 4.39, -0.72, -4.56, -2.84, -2.9, -1.89, -1.46, -1.17, -0.87, -0.35, 0.17, -0.77, -0.43, -4.79, -3.76, -0.35], ['488', 1.12, -0.45, -0.038778284379541256, 0.16, 0.02, -0.94, -0.9, -0.63, -0.51, -1.74, -1.52, -0.74, -0.86, -0.86, -2.37, -1.64, -1.52, -1.61, -1.96, -1.45, -1.6, -1.92, -1.65, -1.25, 0.0, -0.91, -0.22, 0.79, 0.6908333333333334, 0.8131899370470801, -0.86, -0.12, 0.0, -0.09, -0.44, 0.07, -0.08, -0.41, -0.13, 0.27, -0.38, -0.41, -1.0, -0.03880253250388291, -0.12, -1.63, -0.9, -0.79, -0.87, -1.22, -0.71, -0.8603452707629391, -1.19, -0.91, -0.51, -0.34, -0.75, -0.91, -0.44, -0.88, 0.0, -1.52, -0.79, -0.67, -0.6573949338599383, -1.0013219954648527, -0.59, -0.75, -1.07, -0.79, -0.4, -1.86, -0.88, -1.52, -0.79, -0.67, -0.76, -1.11, -0.59, -0.75, -1.07, -0.79, -0.39, -0.43, -0.41, 0.41, 0.64, 0.74, 0.86, 0.77, 0.42, 0.94, 0.78, 0.46, 0.74, 1.14, 0.35, -0.02263346878343711, 0.12, 0.03, -0.32, 0.19, 0.04, -0.28, -0.01, 0.39, -0.15, -0.12, 0.53, -0.63, -0.77, -0.53, -0.22, -0.09, -0.44, 0.07, -0.08, -0.33969498055271247, -0.12, 0.27, -0.12, -0.13, -0.35, 0.16, 0.01, -0.31, -0.03, 0.36, 0.03, -0.07, 0.22, -0.48, 1.06, 0.13, 0.1, 1.06, -1.06, -0.53, -2.03, -0.9, 0.63, 1.29, 0.67, 0.58, -0.32, -2.0, 1.99, 1.94, -0.66, 1.65, -1.32, -1.54, 0.73, -0.64, -1.33, 0.44, 0.65, -0.58, 0.22, 0.52, 0.36, 0.04, 0.32, 0.72, -1.94, -0.29, -0.16, -0.48, -0.2, 0.2, -0.14, -0.32, -0.04, 0.36, -0.49, -0.29, 0.19, 0.28, 0.68, -0.71, -0.64, -0.57, -0.97, 0.03019962695749935, 0.94, -1.12, -1.86, -0.09, 0.4, -0.87, -0.48, -0.25, -0.3, -0.98, -0.49, -1.1, -1.5084047619047618, -0.37], ['489', -4.43, 0.34, 0.09122171562045875, 0.13, 1.02, 1.52, 1.0441152579598292, 1.3, 1.59, 2.05, 0.35, 0.77, 1.93, 0.48, 0.91, 3.26, 0.3, 1.75, 2.36, -0.39, 2.48, 1.0570289115646259, 1.15, 0.27, 2.47, 1.7093714145888919, 1.7, 0.42, 1.58, 0.14, 0.57, 2.91, -0.04, 1.4, 2.01, -0.73, 2.13, 0.41, 0.81, -0.08, 1.08, 2.500897562605877, 1.28, 1.16, -0.28, 0.15, 2.48, -0.46, 0.97, 1.59, -1.14, 1.7, -0.01, 0.38, -0.5, 0.4, 1.25, 1.36, 1.1, 0.11, -1.43, -1.0, 1.31, -1.6, -0.18, 0.42, -2.28, 0.54, -1.15, -0.77, -1.64, 1.36, 1.56, 0.43, 2.77, -0.18, 1.26, 1.87, -0.86, 2.143081632653061, 0.28, 0.67, -0.21, 1.64, 2.56, -2.59, 1.13, 2.33, -0.6, 0.83, 1.44, -1.29, 1.55, -0.13428571428571429, 0.24, -0.64, -1.58, -1.18, -2.87, -1.456904761904762, -0.87, -3.54, -0.76, -2.42, -2.04, -2.9, 0.3009795918367347, -1.08, 2.7457237118830404, 1.4, 1.01, 1.8, 1.74, 1.44, 2.05, -0.69, 2.345778253492539, 0.46, 0.85, -0.04, 1.27, 0.3, 0.61, -2.1, 0.729562358276644, -0.97, -0.58, -1.45, 0.62, 0.99, 0.41, 1.56, -3.24, -0.12, 0.05, -4.08, 4.042462323390895, 2.02, 0.71, 2.24, -4.96, -2.67, -1.43, -2.21, 0.89, 4.16, -4.23, -4.15, 1.4, -6.06, 2.73, -2.49, 1.25, 5.16, -7.24, -3.5, -5.2, 4.96, -0.31, -2.69, 0.11, -1.57, -1.18, -1.884238287156354, 4.1, 2.45, 2.88, 1.15, 1.55, 0.66, -0.42, -1.68, -1.29, -2.16, 1.63, 1.68, 1.28, 0.39, -0.49, 1.41, 1.42, 1.2925760496238783, -3.59, 2.19, 3.52, 1.2772638105244332, 1.7, 0.968637448200971, -0.88, 1.12, 2.13, 1.35, 0.57, 0.69, 1.78, 1.59, 2.883037664716236, 1.69], ['490', 7.2, 0.03, -0.02, 0.2, 0.91, 0.56, -0.5558847420401708, 0.87, 0.78, 0.18, -1.07, 0.18, -0.45, 0.03, -0.12, -1.69, -0.14, -0.06, -0.99, -1.6, 0.72, 0.17, -0.22, -0.15, 1.12, 1.29, 1.26, 1.3784685082657773, 0.62, 1.11, 0.96, -0.6266496598639456, 0.94, 1.02, 0.08, -0.54, 1.81, 1.25, 0.86, 0.93, 0.98, 2.9949361992161734, 0.0, -0.63, -0.15, -0.3, -1.87, -0.32, -0.24, -1.17, -1.78, 0.54, -0.02, -0.4, -0.33, 0.76, 1.41, 1.04, 0.24, 0.64, 0.48, 0.33, -1.25, 0.31, 0.4, -0.54, -1.16, 1.343421154242583, 0.62, 0.24, 0.3, 1.04, 0.15, -0.15, -1.72, -0.17, -0.09, -1.02, -1.63, 0.69, 0.14, -0.24, -0.18, 1.58, 0.99, -1.06, 0.33669823838532015, -1.57, -0.02, 0.06, -0.87, -1.48, 0.84, 0.29, -0.09, -0.03, 3.82, 1.91, 1.58, 1.66, 0.71, 0.09, 2.5126265373526935, 1.89, 1.5, 1.57, 0.25, 1.97, 1.51, 0.39, 0.34, 0.45, 0.32, 0.08, -0.85, -1.47, 0.86, 0.31, -0.08, -0.01, 0.03, 0.29307674813036727, -0.94, -1.55, 0.78, 0.22, -0.16, 0.15217743764172342, 0.14, 0.12, 0.36, 0.32, 11.41, 0.1, -0.17, -0.94, 0.92, 0.47, 0.27, 0.15616353211204947, -3.42, -0.76, -0.43, 3.53, 0.17, 1.3, -1.21, -1.17, 0.39, -1.41, 0.8, -1.14, 0.6047652642842468, 0.95, -4.36, -0.65, -0.95, 3.47, 1.5103786848072562, -0.62, 1.73, 1.17, 0.78, 0.85, 1.24, 1.8201587301587303, 2.36, 1.8, 1.41, 1.48, -0.53, -0.55, -0.93, -0.86, 0.8, 0.93, 0.10727468490743443, -0.38, -0.31, 0.42, 0.42, 0.83, -2.57, 1.07, 2.54, 0.85, 0.78, 0.4, 0.07, 0.44, 0.6445528598385742, 0.37, -0.19, 0.1, 0.33, 1.24, 0.73, 0.05], ['491', 4.05, 0.19, 0.44122171562045875, 0.05, 0.44, 1.21, 0.17411525795982916, 1.98, 1.59, 1.3470884353741497, -2.18, 0.11, -0.04, -0.78, -1.0457142857142858, -0.06, 0.8214285714285714, -0.05, 0.78, 0.09366326530612246, 1.47, -1.05, -0.12, -0.73, 1.11, 1.12, 3.15, 2.3405454545454543, 2.19, 1.43, 1.16, 2.1702857142857144, 2.41, 2.18, 3.03, 2.3, 3.73, 1.16, 2.11, 1.48, 2.187468425353211, 1.6649361992161733, 0.79, -0.14, -0.88, -1.15, -0.17, 0.07, -0.16, 0.67, -0.04, 1.36, -1.16, -0.22, -0.83, 0.45, 0.52, 1.13, 1.67, 0.93, -0.74, -1.01, -0.02, 0.21, -0.02, 0.82, 0.11, 1.5, -1.01, -0.08, -0.69, 1.86, 1.69, -0.27, 0.72, 0.96, 0.73, 1.57, 0.86, 2.26, -0.27, 0.67, 0.05, 2.5, 3.06, -3.02, 1.96, 1.0, 1.24, 1.0, 1.85, 1.13, 2.54, 0.0, 0.94, 0.32, 0.96, 0.96, 0.24, 0.01, 0.84, 0.13, 1.53, -0.99, -0.06, -0.67, 0.86, 0.93, 1.66, 0.95, 0.98, 1.01, 0.72, -0.23, 0.6, -0.11, 1.28, -1.1696949805527124, -0.29, -0.8514153161169343, 1.72, 0.95, 0.84, 0.12, 1.52, -1.0, -0.0642857142857143, -0.68, 0.21, 0.9, 0.36603717887804044, 1.1, 1.84, 0.66, 0.01, -0.98, 0.97, 0.48, -0.98, 3.09, -1.56, -2.02, -0.96, 2.02, 1.06, 2.83, -2.85, -2.93, 0.95, -1.35, 1.95, 0.61, -0.28, 2.14, -5.39, -1.4, -2.27, 1.66, 0.11, -0.71, 0.68, -1.82, -0.89, -1.5, 2.97, 0.82, 1.39, -1.12, -0.19, -0.8, -0.11349829931972805, -2.48, -1.56, -2.16, 1.65, 2.18, 1.97, 0.94, 0.32, 0.98, 1.0, 1.95, -2.83, 2.34, 2.68, 1.35, 0.83, 1.02, -0.61, 0.91, 0.5202197802197802, 1.14, 1.23, 1.23, 1.64, 1.03, 1.09, 1.04], ['492', -1.05, -0.66, -0.12, 0.21, -0.8, -0.1, 0.17411525795982916, 0.21172059653595873, 0.15, 0.06, 0.27, -0.67, 1.52, -0.13, -0.27, 0.25, 0.87, 0.68, -1.22, 1.14, 0.09, -0.08405782312925174, -0.22, 0.55, 0.29, -0.16, -0.21, -0.94, 1.25, -0.4, -0.53, -0.02, 0.6, 0.41, -1.49, 0.86, -0.18, -0.47, -0.49, 0.28, -0.25, 0.5149361992161734, 0.74, 2.21, 0.54, 0.4, 0.92, 1.55, 1.35, -0.56, 1.82, 0.76, 0.47, 0.45, 1.23, 0.0, -0.09, 0.42, 0.4, -1.44, -1.63, -1.76, -1.26, -0.64, -0.83, -2.7, -0.38, -1.42, -1.7, -1.72, -0.96, 0.7436060011417156, 0.19, -0.14, 0.38, 1.0616609275411797, 0.81, -1.09, 1.27, 0.22, -0.07, -0.09, 0.68, 0.0, 0.26, -0.36, 0.3308709226619941, 0.52, 1.14, 0.95, -0.96, 1.41, 0.35, 0.07, 0.04, 0.82, -2.06, -0.18, 0.62, 0.43, -1.46, 0.89, -0.16, -0.45, -0.47, 0.3, -0.64, -0.17, -0.99, -0.39, -0.18, -0.69, -0.8, -0.19, -2.07, 0.26, -0.78, -1.06, -1.08, -0.32, 0.18, -0.61, -1.88, 0.46, -0.59, -0.87, -0.9, -0.12, 0.07895836996312448, -0.2, 0.47, -0.81, -6.04, -0.08, 0.06, 1.4, -1.39, -0.67, -0.23, -1.65, 2.15, 0.7, 0.37, -0.48, 0.19, -1.36, 1.29, 1.05, -0.36, 2.0, -0.69, -2.52, 1.25, -2.34, 4.53, 1.6, 2.34, -2.2, 1.3, 2.39, 1.32, 1.03, 1.01, 1.79, -0.99, -1.06, -1.04, -1.32, -1.34, -0.58, -0.02, -0.29, -0.31, 0.47, 0.21, 0.03, 0.26, -0.02, 0.75, -0.33, -0.44, 0.16, 1.75, -1.52, -2.22, -1.0, -0.86, 0.29, 0.78, -0.66, -0.58, -0.09, 0.55, -0.39537375617527093, -0.49, -3.43, -1.18, -1.08], ['493', -3.89, -0.13, -0.15, 0.26, -2.03, -0.79, -1.0158847420401709, -3.09, -2.12, -2.62, 1.1, -0.68, 0.703913265120849, 0.27, 2.29, -2.73, -1.32, -1.7, -1.23, -0.19, -3.19, -1.41, -0.76, -1.11, -1.83, -0.93, -3.68, -1.76, -0.46, -0.6768100629529199, 1.17, -3.79, -2.39, -2.77, -2.31, -1.27, -4.24, -2.48, -1.84, -2.18, -3.4925315746467893, -1.8450638007838267, -1.95, 1.33, 0.96, 3.0608150295752767, -2.0389563492063494, -0.6007210884353742, -1.03, -0.56, 0.5, -2.52, -0.73, -0.08, -0.43, -1.45, -2.11, -2.21, -1.44, -3.1607547529341224, -0.36, 1.64, -3.35, -1.94, -2.33, -1.86, -0.82, -3.8, -2.04, -1.39, -1.74, -2.24, -2.89, 2.01, -2.99, -1.58, -1.97, -1.5, -0.46, -3.45, -1.68, -1.03, -1.38, -2.9, -5.04, 5.11, -4.8, -4.9, -3.52, -3.9, -3.44, -2.42, -5.35, -3.61, -2.98, -3.32, 1.15, 0.11, 1.45, 1.05, 1.5415238095238095, 2.61, -0.47, 1.35, 2.03, 1.67, -1.04, 0.13, -2.5798953488372094, -0.98, -0.98, -0.984326481349968, -1.32, -0.39, 0.08, 1.14, -1.89, -0.039694980552712436, 0.57, 0.21, -1.27, -0.93, 0.48, 1.54, -1.51, 0.3, 0.96, 0.61, -2.08, -1.55, 0.38, -1.27, 2.36, -0.3796768707482993, -0.04, 2.48, -2.51, -1.27, -0.95, -4.8, 4.84, 2.14, 1.08, -2.04, 0.13, -3.15, 3.19, 3.09, -1.05, 3.76, -2.0, -3.18, 1.64, -3.96, 8.22, 2.54, 3.87, -4.81, -1.41, 1.06, -1.98, -0.18, 0.48, 0.13, -3.1, -2.44, -2.9964625850340134, -1.23, -0.57, -0.92, 0.58, 1.83, 2.51, 2.15, -2.07, -2.2, -1.23, 0.66, 0.31, -0.7879199656859431, -1.06, -3.29, 4.09, -2.6, -4.24, -2.1, -1.29, -1.88, -0.35, -1.89, -1.2, 0.17, -0.06, 0.31, -1.53, -2.2297593656343655, -2.17, -1.6269832262926027], ['494', 0.1, 0.01, -0.08, 0.15, 0.1, -0.49, -1.22, -0.31, 0.33, -0.51, -1.8, 0.03, 0.0, -1.42, 1.27, -1.06, 0.54, -0.08942857142857143, 0.56, -0.01, 0.29, -1.16, -0.25, 0.38, -0.12, -0.13, 1.32, 1.87, 1.83, 0.39, 3.187819971295091, 0.75, 2.39, 1.74, 2.41, 1.83, 2.13, 0.65, 1.58, 2.23, -1.24, 1.25, -0.54, 0.041197467496117086, -1.46, 1.24, -1.1, 0.51, -0.13, 0.53, -0.04, 0.25, -1.2, -0.28, 0.355047619047619, 0.07, 0.07, 0.13194788471762156, 0.43, -0.51, -1.42, 1.28, -1.06, 0.55, -0.09, 0.5871802721088435, 0.0, 0.29, -1.16, -0.25, 0.38, -0.51, 0.93, 2.74, 0.36, 2.1494894125482364, 1.35, 2.02, 1.44, 1.74, 0.26, 1.19, 1.8835596417251208, 1.07, -0.86, 0.83, -1.76, -2.31, -0.72, -1.35, -0.7, -1.066255228898086, -0.97, -2.41, -1.5, -0.88, 0.28, 0.56, 1.63, 0.98, 1.65, 1.07, 1.4326265373526936, 0.1428169964955679, 0.82, 1.46, -0.25, 0.52, -0.69, -0.57, -0.5, -0.69, -1.05, -0.63, 0.02, -0.55, -0.26, -1.7, -0.79, -0.16, 0.63, -0.42, 0.66, 0.09, 0.38, -1.07, 0.0657142857142857, 0.47, -0.38, -0.88, 0.23, -0.76, 0.53, 0.04, 0.14, 1.83, -1.79, -0.87, 0.13, -1.14, 1.09, 1.18, 1.028280612244898, 0.25, -0.56, -1.77, 1.71, 1.84, -0.56, 2.62, -1.11, -0.84, 0.44, -3.01, -0.29, 2.1, 3.02, -0.97, -1.07, -0.57, -0.28, -1.72, -0.81, -0.18, -1.67, -0.5, 0.29, -1.16, -0.24, 0.39, -0.79, -1.45, -0.54, 0.09, 0.34, 0.62, 0.66, 0.92, 1.56, -0.4, -0.64, -0.35, -0.18, -1.06, 0.29, -0.83, 0.53, -0.26, 0.63, -0.97, -0.96, -0.87, -0.3, -0.55, -0.89, -1.04, 0.15, -0.79], ['495', -2.12, 0.0, 0.46, 0.06, -0.14, -0.38, 0.18, 0.09172059653595872, -0.56, 1.46, 1.89, 2.4293248299319727, 2.1, 1.44, 1.15, 2.25, 1.15, 1.47, 2.57, 2.53, 1.23, 1.07, 1.93, 1.605116627420199, -0.64, -1.24, -0.39734160500688753, 0.51, 0.2, -0.44, -0.73, 0.35, -0.73, -0.41, 0.66, 0.62, -0.65, -0.81, 0.03, -0.43, 0.24, 0.63, -0.94, -0.31, -0.95, -1.24, -0.16, -1.24, -0.92, 0.15, 0.11, -1.16, -1.31, -0.48, -0.94, -0.5, -0.21, -0.44, -0.33, -0.63, -0.65, -0.94, 0.15, -0.93, -0.62, 0.46, 0.42, -0.85, -1.01, -0.11173538366395512, -0.63, 0.01360600114171559, 0.02, -0.29, 0.8, -0.29, 0.03, 1.11, 1.07, -0.21, -0.37, 0.48, 0.02, -0.7, -0.89, 0.92, 0.31, 1.1780874332127649, 0.01, 0.32, 1.41, 1.37, 0.08, -0.07, 0.7785238095238095, 0.31, -1.7, -0.78, -1.08, -0.76, 0.31, 0.27, -1.0, -1.15, -0.32, -0.78, 0.03, -0.84, 1.67, -0.24, -0.36, 0.015673518650031963, 0.3009570400359874, 0.32, 1.4, 1.36, 0.08, -0.08, 0.76, 0.3, 0.22, -0.01, 1.08, 1.04, -0.24, -0.39, 0.45, -0.01, -1.01, -0.27, 0.28, 0.17, -5.08, 0.03, -0.06, 0.43, -0.45, -0.2, 0.0, -0.24, 2.1, 0.46, 0.23, -0.99, -0.5, -0.68, 0.62, 0.79, -0.25, 0.56, -0.49, 0.1, -0.06, 0.89, 2.22, -0.7, -0.95, -1.98, -1.08, -0.04, -1.3, -1.46, -0.63, -1.08, -0.74, -0.9056457669314812, -1.26, -1.42, -0.59, -1.04, 0.22, -0.16, 0.69, 0.22, -0.56, -0.41, 0.38, 0.84, 0.38, -0.25, -0.16, 0.0, 1.15, 1.34, -1.09, -0.33, -0.53, -0.46, -0.46, -0.14, -0.15, -0.46, -0.89, 0.03, 0.0, -1.23, -0.69, 0.25], ['496', -5.95, 0.0, -0.03984710169072946, 0.06, -0.5070209190089403, -1.07, -1.6158847420401707, -2.138279403464041, -2.03, -3.18, 0.04, -2.08, -1.2, -0.75, -0.19, -2.7, -1.47, -2.85, -5.89, -1.96, -3.432664517912641, -1.61, -2.04, -1.78, -1.69, -1.48, -3.22, -2.11, -1.2191666666666667, -0.79, -0.23, -2.74, -1.51, -2.89, -5.93, -2.0, -3.51, -1.65, -2.08, -1.82, -1.82, -3.84, -1.13, 0.9711974674961171, 1.35, 1.93, -0.64, 0.62, -0.79, -3.9, 0.12, -1.391934531913557, 0.47, 0.04, 0.3, -1.06, -1.59, -1.92, -1.35, -2.01, 0.45, 1.02, -1.52, -0.28, -1.67, -4.75, -0.77, -2.3, -0.42, -0.85, -0.59, -1.8, -2.45, 0.57, -1.97, -0.72, -2.12, -5.18, -1.22, -2.74, -0.87, -1.29, -1.04, -2.81, -3.59, 3.64, -3.0, -2.52, -1.29, -2.67, -5.72, -1.78, -3.29, -1.43, -1.85, -1.6, -2.88, -0.49, 1.27, -0.15, -3.28, 0.76, -0.78, 1.12, 0.69, 0.95, -0.42, -0.48, -2.57, -1.05, -1.04, -1.14, -1.73, -1.4, -4.49, -0.5, -2.03, -0.14, -0.57, -0.32, -1.53, -0.28692325186963274, -3.13, 0.92, -0.63, 1.28, 0.84, 1.1, -0.78, -1.3, 0.04, -1.48, -8.87, -0.03, 0.23, 1.95, -2.02, -0.98, -0.09, -2.67, 2.45, 2.05, 1.04, -2.99, -1.01, -3.2, 3.19, 3.17, -1.05, 2.93, -2.09, -1.51, 0.76, -5.33, 4.58, 3.47, 5.21, -2.28, 2.88, 4.18, 2.58, 4.55, 4.1, 4.535761712843646, -3.1, -1.24, -1.54, 0.35, -0.08, 0.18, 0.3, 1.92, 1.48, 1.74, -1.91, -2.26, -1.59, -0.43, -0.17, -1.03, -1.13, -2.13, 3.99, -1.76, -4.05197619047619, -1.84, -0.3, -1.17, 0.26, -1.31, -0.79, -1.6, -0.66, -0.94, -1.42, -2.58, -0.78, -1.58], ['497', 0.43, 0.0, -0.25877828437954126, 0.1, 0.23, -0.38, -0.49588474204017086, -1.31, -0.65, -0.9, -0.19, -0.59, -0.47, -0.22, 0.95, -0.65, -0.4, -0.73, -1.45, -0.18, -1.03, -0.36, -0.15, -0.83, -0.85, -0.7, -0.71, -0.3998214285714286, -0.28, -0.03, 1.14, -0.46, -0.21, -0.54, -1.27, 0.01, -0.84, -0.17, 0.04, -0.64, -0.99, -1.71, -0.31, 0.12, 0.37, 1.54, -0.06, 0.19, -0.14, -0.87, 0.41, -0.45, 0.23, 0.44, -0.24, -0.82, -0.86, -1.44, -0.56, -0.43, 0.26, 1.43, -0.17, 0.08, -0.26, -0.98, 0.29, -0.56, 0.11, 0.32, -0.36, -1.71, -0.68, 1.17, -0.43, -0.18, -0.51, -1.24, 0.04, -0.82, -0.14, 0.07, -0.61, -1.03, -1.96, 1.89, -1.83, -1.58, -1.33, -1.66, -2.38, -1.12, -1.96, -1.3, -1.09, -1.76, -0.52, -0.25, 0.25, -0.08, -0.81, 0.47, -0.39, 0.29, 0.5, -0.18, -0.05, -0.3, -1.66427628811696, -0.28, -0.37, -0.19, -0.5, -0.33, -1.06, 0.22, -0.64, 0.04, 0.32598786341555264, -0.43, -0.6, -0.17, -0.73, 0.55, -0.13139698000412267, 0.37, 0.58, -0.1, -0.68, -0.81, 0.34, -0.34, -1.36, 0.0, -0.1, 0.36, -0.3675376766091052, -0.15118982899237887, -0.28, -0.71, 1.33, 0.54, 0.26, 0.18, -0.36, -0.79, 0.77, 0.75, -0.21670919513614706, 0.56, -0.47012164275868484, -1.87, 0.93, -1.4, 0.43, 0.86, 1.53, -1.36, 0.56, 1.29, 0.43, 1.11, 1.32, 0.64, -0.6768321004392431, -0.72, -0.85, -0.18, 0.03, -0.65, 0.14, 0.68, 0.89, 0.21, -0.61, -0.75, -0.54, 0.21, -0.39775124468498363, -0.25, -0.23, -1.24, 0.29, -0.59, -0.33, -0.92, 0.41, -0.75, -0.68, -0.32, -0.14, -0.06, -0.47, -0.61, -0.07, -0.95, 0.97, 0.16], ['498', 0.83, -1.24, 0.05122171562045875, 0.3, -1.23, -1.42, -1.6358847420401708, -1.9, -1.82, -1.53, 0.02, -0.62, 1.13, 0.75, 0.29, -2.62, 0.74, -1.17, 2.19, -0.3, -1.59, 0.27, 0.34, 0.47, -1.05, -1.53, -1.55, -0.64, 1.1, 0.73, 0.27, -2.6366496598639455, 0.72, -1.2, 2.17, -0.33, -1.62, 0.25, 0.32, 0.45, -1.8125315746467892, -3.64, -0.92, 1.75, 1.38, 0.91, -2.02, 1.36, -0.56, 2.82, 0.31, -0.99, 0.89, 0.96, 1.1, -1.17, -0.4, -1.67, -2.25, -2.63, -0.37, -0.83, -3.7, -0.38, -2.28, 1.05, -1.41, -2.69, -0.84, -0.78, -0.64, -2.36, -2.27, -0.46, -3.35, -0.01, -1.91, 1.43, -1.05, -2.33, -0.48, -0.41, -0.28, -2.29, -5.37, 5.28, -1.82, -2.9, 0.45, -1.46, 1.9, -0.59, -1.88, -0.02, 0.05, 0.18, 1.18, 1.12, 3.45, 1.48, 4.94, 2.38, 1.05, 2.97, 3.04, 3.18, -0.48, 1.03, -3.44, -1.43, -1.51, -1.5, -2.25, -1.9, 1.44, -1.04, -2.32, -0.46, -0.3240121365844474, -0.26, -1.67, -0.36, 3.41, 0.88, -0.42, 1.47, 1.53, 1.67, -1.84, -1.85, 0.07, -1.98, 3.9, -0.52, -0.35, 2.71, -2.8, -1.38, -0.75, -2.14, 2.4, 2.88, 1.41, 0.36, -0.996920210131221, -4.52, 4.53, 4.28, -1.44, 4.21, -2.84, -2.25, 1.04, -6.74, 13.503125850340135, 4.52, 6.78, -2.37, -3.64, -2.44, -3.71, -1.88, -1.8087142857142857, -1.68, -4.31, -1.23, -1.3, 0.58, 0.64, 0.78, 0.06, 1.9, 1.96, 2.1, -1.75, -2.23, -1.8, 0.06, 0.2, -1.44, -1.6, -1.7674239503761218, 7.11, -3.2398003730425007, -7.02, -1.86, -1.61, -1.86, 0.14, -1.99, -1.2, -0.69, -1.18, -0.84, -2.0, -1.2, -2.45, -2.09], ['499', 9.254285714285714, -0.9, -0.04, 0.07, -0.2, 0.02, 1.174115257959829, 0.98, 0.58, 1.99, 1.24, 0.54, 1.51, 0.4, 0.8, 1.1610714285714285, 2.65, 1.72, 5.24, 3.04, 2.3, 2.9870289115646256, 1.96, 1.71, -0.38, 0.38, 0.7726583949931125, -0.7, 0.26, -0.83, -0.44, -0.08, 1.39, 0.5872589041444084, 3.95, 1.78, 1.04, 1.43, 0.7, 0.46, 1.31, 0.22, 1.45, 0.97, -0.14, 0.26, 0.62, 2.1, 1.18, 4.68, 2.49, 1.75, 2.14, 1.4442857142857142, 1.16, -0.55, 0.24, 1.21, 0.46, 0.47, -1.1, -0.7, -0.35, 1.12, 0.21, 3.67, 1.51, 0.77, 1.16, 0.44, 0.19, 0.62, 1.59, 0.4, 0.76, 2.24, 1.32, 4.82, 2.63, 1.89, 2.28, 1.55, 1.3, 0.47, -0.1, 0.11, 1.18, 0.36, 1.83, 0.92, 4.41, 2.23, 1.6552352330209474, 1.88, 1.15, 0.9, 1.05, 0.82, 1.47, 0.56, 4.04, 1.86, 1.12, 1.51, 0.79, 0.54, 0.22, 0.84, -1.16, 0.05, -0.06, 0.05, -0.64, -0.9, 2.53, 0.38, -0.34, 0.04, -0.67, -0.8614153161169343, -0.69, 0.26, 3.46, 1.3, 0.56, 0.95, 0.23, -0.02, 0.04, -0.3, 0.4660371788780404, -0.54, 3.25, 0.14, 0.35, -1.09, 1.1, 0.56, -0.02, -0.72, 1.94, -0.12, -0.03, 4.469285714285714, -0.05, 0.01, 0.06, -0.1, 0.10329080486385296, -1.79, 0.07, -0.43, 0.22, -1.94, 1.51, 1.22, 1.89, -2.04, -3.09, -2.09, -2.8, -2.42, -3.12, -3.36, 0.18, -1.02, -0.72, -0.34, -1.05, -1.29, -0.3, 0.38, -0.33, -0.58, 0.61, 0.46, -0.68, -0.72, -0.96, 0.05, -0.03, 0.93, 0.32, -0.3, -0.34, -0.03273618947556672, -0.74, 0.03, -0.24, -0.37, 0.42, 0.13, -0.6, 0.39, 0.28, -0.09, -1.83, 0.89], ['500', -0.74, -0.25, 0.13122171562045873, -0.7, -0.36, -0.55, -0.015884742040170832, -0.6, -0.23, -0.42, -0.14, 0.4, 0.08, -0.09, -0.22, -0.65, 0.2, -0.11, 2.73, -0.24, -0.43266451791264104, 0.61, -0.24, -0.59, -0.4, -0.21, -0.2573416050068875, 0.54, 0.22, 0.05, -0.022180028704908802, -0.51, 0.33, 0.03, 2.87, -0.1, -0.33, 0.75, -0.1, -0.4061582768021609, -0.1, -0.7350638007838266, -0.82, -0.32, -0.49, -0.62, -1.04, -0.2, -0.5, 2.32, -0.64, -0.841934531913557, 0.21, -0.64, -0.99, 0.47, 0.22, -0.08, 0.06, -0.5, -0.17, -0.3, -0.73, 0.12, -0.19, 2.64, -0.32, -0.55, 0.53, -0.32, -0.67, -0.18, -0.34, -0.13, -0.56, 0.28, -0.02, 2.82, -0.15, -0.38, 0.7, -0.15, -0.4564403582748793, -0.42, -0.6, 0.66, -0.16330176161467985, -0.43, 0.42, 0.11, 2.95, -0.02, -0.25, 0.83, -0.02, -0.37, -0.89, 0.22, 0.85, 0.54, 3.39, 0.41, 0.18, 1.26, 0.41, 0.06, -0.36, 0.19, -0.26427628811695997, -0.43, -0.19, -0.13432648134996805, -0.62, -0.3, 2.53, -0.43, -0.66, 0.41, -0.44, -0.79, 0.12, -0.32, 2.83, -0.13, -0.36, 0.71, -0.14, -0.49, -0.59, -0.53, -0.06, -0.3, 0.2, -0.1, 0.0, 0.44, -0.56, -0.23, -0.29, -2.71, 0.37, 0.83, 0.38, -0.21, -0.04, -1.29, 1.25, 1.11, -0.45, 0.76, -0.84, 0.27, -0.2, -1.66, -0.8, 0.82, 1.73, -0.29, -3.07, -2.89, -3.11, -2.06, -2.89, -3.23, -1.17, -0.19, -0.23, 0.85, 0.0, -0.35, 0.05, 1.08, 0.23, -0.12, -0.26, 0.19, -1.03, -0.84, -1.19, -1.05, -0.41, -0.35, 0.09, -0.5798003730425006, 0.17, 0.27, -0.93, -0.18, -0.35, -0.42, -0.31, -0.37, -0.31, -0.5, 0.17, -0.47, -1.24, -0.11], ['501', -1.71, -0.18, 0.25122171562045875, 0.04, -1.02, -0.3, 0.22, -0.15, -0.45, -0.48, -0.67, -0.64, 0.54, 1.4, -1.0, 0.08, 0.02, -0.65, 0.62, 1.5, -0.3, -0.27, -0.03, 0.55, 0.13, -0.6, 0.2, 0.14846850826577718, 1.22, 2.09, -0.33, 0.7633503401360544, 0.7, 0.02, 1.3, 2.18, 0.37, 0.41, 0.65, 1.23, 0.06, -0.89, 0.17, 1.19, 2.06, -0.36, 0.72, 0.66, -0.01, 1.27, 2.15, 0.368065468086443, 0.38, 0.62, 1.2, 0.21, 0.08, 0.91, -1.11, -1.01, 0.9531047225355607, -1.53, -0.46, -0.52, -1.19, 0.07, 0.95, -0.84, -0.81, -0.57, 0.01, 2.31, -1.85, -2.37, -1.31, -1.36, -2.02, -0.77, 0.09, -1.68, -1.64, -1.41, -0.84, -0.44, -1.61, 1.51, 0.53, 1.09, 1.03, 0.35, 1.63, 2.52, 0.71, 0.74, 0.98, 1.56, -1.21, -0.55, -0.06, -0.73, 0.54, 1.42, -0.38, -0.34, -0.11, 0.47, -0.14, -0.56, -2.41, -0.3, -0.35, -0.31, -0.49, -0.67, 0.6, 1.48, -0.32, -0.28, -0.05, 0.5885846838830657, -0.29, 0.18, 1.28, 2.16, 0.35, 0.39, 0.63, 1.21, -0.32, -0.11, 0.26, -0.52, -3.53, 0.03, 0.1, -0.32, 0.3, 0.14, -0.13, -1.52, 3.78, 0.64, 0.31, -0.86, -0.64, -0.87, 0.9, 0.93, -0.3, -0.46, -0.6, 0.8283906549799409, -0.37, -1.39, 4.627380952380952, 0.91, 1.42, -3.73, -1.09, 0.87, -0.91, -0.88, -0.64, -0.07, -0.9, -1.94, -1.77, -1.74, -1.5, -0.93, -0.18, 0.03, 0.27, 0.85, -0.46, -0.67, -0.21, 0.24, 0.82, -0.3, -0.33, -0.13, 2.49, -2.23, -2.59, -0.46, -1.01, -0.45, 0.58, -0.11, 0.5945528598385743, -0.32, -0.81, -0.31, -1.02, 0.63, -1.19, -0.4], ['502', -1.99, 0.15, -0.04, 0.07, 0.11, -0.28, -1.1458847420401708, -0.26, -0.8, 0.27, 0.99, 0.69, 0.37, 0.87, 0.43, 0.06107142857142857, 1.19, 0.17, -3.18, 0.38, 0.25, 0.98, 1.19, 0.82, -0.63, -0.6, -0.6773416050068874, -0.3, -0.61, -0.11, -0.55, -0.92, 0.2, -0.81, -4.12, -0.61, -0.73, 0.0, 0.2, -0.11615827680216084, 0.26, -1.5350638007838266, -0.41, -0.31, 0.18, -0.25, -0.63, 0.5, -0.51, -3.84, -0.31, -0.43, 0.29, 0.5, 0.14, -0.4, -0.99, -0.62, -0.94, -0.1, 0.5, 0.060799319727891155, -0.31, 0.81, -0.2, -3.54, 0.0, -0.12, 0.61, 0.81, 0.45, -0.14, -0.59, -0.44, -0.81, 0.32, -0.69, -4.01, -0.49, -0.4669183673469388, 0.11, 0.31, -0.05, -1.33, -2.39, 2.36, -0.16, -0.37, 0.76, -0.26, -3.59, -0.05, -0.18, 0.55, 0.75, 0.39, -1.13, 0.22, 1.13, 0.12, -3.23, 0.32, 0.19, 0.93, 1.13, 0.77, 0.121141873999017, 0.12, -1.65, -0.47, -0.55, -0.5, -0.9, -1.0, -4.32, -0.8, -0.93, -0.2, 0.0, -0.36, -0.67, 0.1, -3.34, 0.292244713705627, 0.08, 0.81, 1.01, 0.65, -1.55, -1.58, 0.08, -0.73, -3.93, 0.13, 0.14, 1.02, -1.01, -0.49, -0.07, 0.1, 0.23, 0.93, 0.5, -0.99, -0.04692021013122094, -1.51, 1.55, 1.55, -0.48, 1.67, -0.95, -0.6, 0.3147652642842468, -2.75, 0.76, 1.82, 2.67, -0.18, 3.56, 3.67, 3.54, 4.3, 4.51, 4.13, -1.38, -0.1, -0.12, 0.61, 0.81, 0.45, 0.02, 0.73, 0.93, 0.57, -0.75, -0.84, -0.7, 0.2, -0.16, -0.5, -0.5156036987247091, -0.26, 1.97, -1.67, -2.05, -0.7, 0.44, -0.9, -0.36, -1.1, -0.6, -0.44, -0.08, -0.21, -0.54, 0.23, 0.61, -0.8], ['503', -1.31, 0.0, -0.08, 0.19, -0.25, -0.32, 0.88, -1.03, -0.98, 0.05, 1.32, 0.36, 1.61, 1.62, 0.48, 0.46, 0.82, 0.0, -3.55, -0.04, -0.54, 1.36, 1.64, 0.38, -1.61, -0.82, -1.25, -0.95, 0.29, 0.29, -0.82, -0.84, -0.49, -1.3, -4.8, -1.34, -1.83, 0.04, 0.32, -0.93, 0.66, -1.1050638007838267, -0.31, 1.25, 1.25, 0.12, 0.11, 0.46, -0.36, -3.89, -0.4, -0.89, 1.0838655564790018, 1.27, 0.02, -1.1, -0.71, -0.73, -0.98, -1.54, 0.0, -1.11, -1.13, -0.78, -1.59, -5.08, -1.63, -2.12, -0.26, 0.02, -1.22, -1.14, -1.54, -1.12, -1.13, -0.78, -1.59, -5.08, -1.63, -2.12, -0.26, 0.02, -1.22, -1.42, -3.6, 3.58, -0.43, -0.02, 0.34, -0.48, -4.01, -0.52, -1.02, 0.87, 1.15, -0.0459922724755494, -1.71, -0.41, 0.35, -0.46, -3.9894285714285718, -0.5, -1.0, 0.89, 1.17, -0.09, 0.231141873999017, -0.36, -1.57, -0.45, -0.56, -0.28, -0.77, -0.82, -4.33, -0.8594642857142857, -1.35, 0.53, 0.81, -0.44, -1.16, 0.10307674813036727, -3.55, -0.04, -0.5304376417233561, 1.36, 1.64, 0.38, -1.18, -1.34, 0.17, -0.34, -5.47, -0.01, 0.07, 0.48, -0.43, -0.22, -0.44, -1.01, -0.19, 0.88, 0.4, -0.67, -0.08, -1.31, 1.21, 1.34, -0.43, 0.67, -0.86, -1.52, 0.75, -2.27, 15.02, 1.5, 2.21, 0.24, 3.73, 3.64, 3.12, 5.08, 5.38, 4.07, -1.33, 0.09, -0.5, 1.4, 1.68, 0.42, 0.59, 1.9, 2.19, 0.92, -0.96, -1.19, -1.29, 0.28, -0.96, -0.48, -0.42, -0.96, 7.65, -1.77, -7.81, -1.59, -0.05, -1.56, -1.24, -0.64, -0.32, 0.12, -0.06, 0.11, -0.33, -2.55, 0.57, 0.35], ['504', 3.65, -1.46, 0.23, -0.24, 0.14, 0.33, 1.2900361663652804, 0.18, 0.43, -1.32, -1.93, -2.23, -1.64, -2.18, -1.04, -2.91, -1.33, -1.55, 1.96, -2.57, -0.67, -1.24, -1.45, -1.85, 0.01, -0.28, 0.63, -0.3, 0.3, -0.25, 0.9, -1.0, 0.61, 0.5072589041444084, 3.96, -0.65, 1.28, 0.71, 0.49, 0.08, -0.12, 1.51, 0.93, 0.6, 0.05, 1.21, -0.7, 0.92, 0.69, 4.28, -0.35, 1.59, 1.01, 0.8, 0.39, 0.12006284630567655, 0.24, 0.57, 0.17, 0.33, -0.55, 0.61, -1.3, 0.32, 0.09, 3.66, -0.94, 0.98, 0.41, 0.19, -0.21, 0.6336060011417156, 0.88, 1.16, -0.75, 0.87, 0.64, 4.23, -0.4, 1.54, 0.96, 0.74, 0.34, 1.03, 0.611742947528662, -0.38, -0.28, -1.89, -0.29, -0.52, 3.03, -1.54, 0.38, -0.2, -0.41, -0.81, -0.027904761904761904, 1.65, 1.63, 1.4, 5.02, 0.36, 2.31, 1.73, 1.51, 1.1, 0.28, 1.6424455782312923, 0.5, 0.29, 0.28, 0.29567351865003194, 0.01, -0.23, 3.33, -1.26, 0.66, 0.09, -0.12, -0.53, -0.08, 0.24, 3.57, -1.03, 0.89, 0.32, 0.1, -0.3, 0.61, 0.45, -0.25, 0.37318678362356794, 0.0, 0.13, 0.05, -0.44, 0.46, 0.23, 0.36, 0.76, -2.62, -0.48, -0.27, 1.86, 0.35, 0.82, -0.72, -0.85, 0.27, -0.7, 0.53, 3.108390654979941, -1.52, 0.06, 0.72, -0.03, -0.05, 2.67, -3.21, -4.44, -2.58, -3.13, -3.34, -3.73, 0.8, 1.28, 1.95, 1.37, 1.15, 0.74, -0.65, -0.57, -0.78, -1.18, 0.63, 0.69, -0.08, -0.22, -0.62, 0.25, 0.24, 0.22257604962387836, 0.4, -0.1, -0.35, -0.03, 0.16, 0.21863744820097092, -0.4, 0.0, 0.32, 0.15, 0.87, 0.29, 0.54, -0.94, 0.58, 0.43], ['505', -3.94, 0.63, 0.041221715620458746, -0.07, -0.5, 0.92, 1.07, 0.5817205965359588, 1.25, 0.27, -1.31, -0.52, -0.25, -1.51, 0.86, 1.27, -0.95, -0.02, 0.27, 0.65, -0.11, -0.42, -1.44, -0.7, 1.56, 0.04, 1.6326583949931126, 0.8, 1.07, -0.2, 2.19, 2.61, 0.36, 1.31, 1.6, 1.98, 1.22, 0.9, -0.14, 0.62, -0.07, 2.1749361992161735, 0.79, 0.27, -1.0, 1.38, 1.8, -0.43, 0.5, 0.79, 1.18, 0.41, 0.1, -0.93, -0.18, 0.19, -0.5, 0.22, 1.51, 0.52, -1.26, 1.11, 1.52, -0.7, 0.23, 0.52, 0.9, 0.14, -0.17, -1.2, -0.45, 0.41, 1.81, 2.4, 2.82, 0.57, 1.51, 1.81, 2.19, 1.42, 1.11, 0.07, 0.82, 2.05, 4.48, -4.45, -0.58, 0.41, -1.79, -0.87, -0.58, -0.2, -0.95, -1.26, -2.28, -1.54, -2.17, -0.99, -2.19, -1.28, -0.99, -0.61, -1.36, -1.67, -2.68, -1.94, 0.36, -0.8406317967746538, 3.39, 0.97, 1.0, 0.89, 1.23, 0.94, 1.23, 1.62, 0.85, 0.54, -0.5, 0.25, 0.67, 0.29, 0.29, 0.67, -0.09, -0.4, -1.42, -0.68, 1.12, 1.4227619047619047, 0.14, 0.98, -6.35, 0.22, 0.2, -2.01, 2.01, 1.0, 0.72, -0.31, 0.67, -1.91, -0.97, -1.99, 0.5030797898687791, 2.98, -2.7, -2.87, 0.99, -3.01, 1.95, 0.4, -0.2, 3.58, -8.25, -2.47, -3.63, -0.67, 0.0, 0.38, -0.38, -0.6483894557823129, -1.71, -0.97, 2.9, -0.38, -0.75, -1.06, -2.08, -1.34, 0.38, -0.31, -1.34, -0.59, 1.28, 1.59, 0.7772746849074343, -1.03, -0.28, 0.95, 1.0643963012752908, 0.5, -4.2, 2.21, 4.27, 0.71, 0.76, 1.74, 0.76, 0.66, 1.12, 0.6, 0.06, 0.79, 0.98, -0.71, 0.58, 1.0], ['506', 1.61, 1.11, -0.17, -0.11, -0.24, 0.24, 1.1, -0.08, 0.29, 0.19, 0.72, -0.6592857142857144, 0.62, -0.53, 0.41, 0.38, -0.73, -0.23, -0.69, 0.38, -0.2, -1.91, -1.43, 0.04511662742019901, 0.72, 1.29, -0.53, -1.38, -0.11, -1.25, -0.32, -0.34, -1.44, -0.95, -1.41, -0.34, -0.92, -2.61, -2.14, -0.81, 0.74, -0.37506380078382656, 0.86, 1.29, 0.13, 1.07, 1.05, -0.06, 0.43, -0.03, 1.05, 0.46, -1.25, -0.78, 0.57, 0.13006284630567655, 0.53, 0.35, 0.33, -0.43, -1.14, -0.21, -0.24, -1.34, -0.85, -1.3, -0.24, -0.82, -2.51, -2.04, -0.71, 0.0, 0.72, 0.94, 0.92, -0.2, 0.3, -0.16, 0.92, 0.33, -1.38, -0.91, 0.44, -0.04, 4.38, -4.42, -0.21, -0.02, -1.13, -0.64, -1.09, -0.03, -0.61, -2.3, -1.83, -0.5, 0.29, -0.19, -1.1, -0.61, -1.07, 0.0, -0.5173734626473064, -2.28, -1.81, -0.48, 0.69, -0.19, 2.55, 0.51, 0.76, 0.37, 0.92, 0.5, 0.03, 1.11, 0.53, -1.19, -0.71, 0.63, 2.02, 0.42, -0.46, 0.61, 0.03, -1.68, -1.2, 0.14, 0.69, 0.44, -0.09, 1.07, 0.68, 0.48, 0.42, -0.44, 0.44, 0.21, 1.29, -0.55, 0.417758979116122, -0.96, -0.54, 0.8, 0.38, 1.81, -1.77, -1.56, 0.54, -0.64, 1.06, 1.87, -0.97, 2.68, -3.08, -1.86, -2.67, -0.4, 0.89, 1.08, 0.49, -1.22, -0.75, 0.6, 1.55, -0.19, -0.58, -2.28, -1.81, -0.47, 0.39, -1.71, -1.23, 0.11, 0.27, -0.08, 2.14, 0.48, 1.85, 0.49, 0.63, 0.0, -1.62, 1.78, 1.53, 0.68, 0.31, 1.65, 1.36, 0.12, 0.47, -0.06, 0.75, 0.34, 0.29, -0.1, 1.44, 0.63], ['507', 2.84, -0.72, -0.028778284379541254, -0.05, -1.06, -0.35, -0.9358847420401708, -1.06, -0.87, -0.09, 0.74, 0.63, 1.35, 1.58, 0.63, -0.32, 0.92, -0.06, -2.85, 1.58, -0.31, 0.74, 1.38, 0.38, -0.21, -1.44, -0.7873416050068875, -0.11, 0.61, 0.84, -0.11, -1.06, 0.18, -0.8, -3.57, 0.83, -1.04, 0.0, 0.63, -0.36, -0.47, -1.99, -0.71, 0.72, 1.1178753944468232, 0.0, -0.94, 0.3, -0.68, -3.46, 0.95, -0.93, 0.12, 0.75, -0.25, -0.37, -1.28, -0.23217202719021607, -0.73, -1.42, 0.23, -0.71, -1.65, -0.42, -1.39, -4.15, 0.23, -1.64, -0.6, 0.03, -0.96, -0.8, -1.64, -0.94, -1.88, -0.65, -1.62, -4.37, 0.0, -1.86, -0.83, -0.2, -1.19, -1.24, -3.78, 3.76, -0.71, -0.95, 0.29, -0.68, -3.46, 1.143744771101914, -0.93, 0.11, 0.75, -0.1959922724755494, -2.2673809523809525, 0.3173665312165629, 1.25, 0.26, -2.54, 1.91, 0.08262653735269351, 1.07, 1.71, 0.7, -0.02, 0.23, -1.45427628811696, -0.72, -0.91, -0.59, -1.0, -0.97, -3.74, 0.65, -1.22, -0.18, 0.45, -0.54, -0.81, -0.02, -2.8, 1.64, -0.25, 0.8, 1.44, 0.44, -1.35, -0.16, -0.22, -0.94, -4.51, -0.13, 0.0, 0.84, -0.85, -0.4, -0.25, -0.11, 3.37, 1.42, 0.67, 1.47, -0.28, -2.17, 2.21, 2.13, -0.7, 1.14, -1.4, 1.31, -0.66, -2.97, 0.29, 1.99, 2.94, -3.34, 2.85, 4.56, 2.62, 3.7, 4.36, 3.33, -2.05, -1.64, -1.86, -0.82, -0.2, -1.19, 0.22, 1.05, 1.69, 0.68, -0.92, -1.0, -0.82, 0.63, -0.36, -0.69, -0.76, -0.95, 0.09, -1.17, -0.19, -0.47, -1.57, -1.45, -0.99, -0.44, -0.43, -0.32, -0.3, -0.51, -0.46, -1.03, -2.41, -0.9269832262926028], ['508', -0.33, 0.23, 0.13122171562045873, -0.02, -0.61, -0.05, -0.46, -1.25, 0.14, -0.8278571428571428, -0.67, -1.1410079365079364, -0.36, 0.25, 1.43, -0.69, -0.75, -0.75, -2.47, 0.37, -0.79, -1.49, -1.17, -1.34, -0.76, -0.67, -0.12734160500688754, -0.48, 0.32, 0.93, 2.167819971295091, -0.02, -0.08, 0.03725890414440844, -1.81, 1.05, -0.12, -0.82, -0.5, -0.6261582768021609, -1.34, -0.7150638007838266, 0.32, 0.8, 1.43, 2.61, 0.47, 0.41, 0.41, -1.33, 1.54, 0.37, -0.34, -0.02, -0.19, -0.1, -1.5, -1.62, 0.11, -0.48, 0.62, 1.79, -0.33, -0.39, -0.4, -2.12, 0.73, -0.43, -1.13, -0.81, -0.98, -1.02, -1.09, 1.17, -0.94, -1.0, -1.01, -2.72, 0.11, -1.04, -1.74, -1.42, -1.5364403582748793, 0.06, 0.9, -1.02, -2.1933017616146797, -2.09, -2.14, -2.15, -3.84, -1.04, -2.19, -2.87, -2.56, -2.73, -2.68, -0.14, -0.06, -0.06, -1.79, 1.07, -0.1, -0.8, -0.48, -0.65, 0.03, -0.19, 1.4101046511627906, 0.07, 0.11, 0.05, -0.09, -0.01, -1.74, 1.12, -0.04, -0.74, -0.43, -0.59, 0.72, -0.08, -1.73, 1.13, -0.04, -0.6142004503433073, -0.42, -0.59, 0.46, 0.16, -0.06, 0.03318678362356798, -7.85, 0.02, 0.12, -0.15, 0.14, 0.07, 0.37, -1.49, 2.46, -0.13, -0.09, -0.12, 0.4, 0.17, -0.15, -0.16, 0.12329080486385297, -0.17, 0.12, 0.78, -0.4, -0.18, -3.95, 0.14, 0.1, -2.46, 1.68, 2.91, 1.72, 1.01, 1.33, 1.16, 0.2, -1.0656457669314812, -1.15, -1.85, -1.53, -1.7, -0.04, -0.7, -0.38, -0.55, 0.08, 0.04, 0.66, 0.32, 0.15, 0.09, 0.08, -1.19, -2.55, 0.40111637918066984, 2.43, -0.36, -0.66, 0.34, -0.17, -0.56, 0.0, 0.42, 0.8, 0.16, 0.51, -1.81, -1.01, 0.3330167737073973], ['509', -1.13, 0.06, 0.011221715620458745, 0.16, 0.78, 0.8284196236737595, -0.06, -0.39, 0.66, -0.18, -1.15, -0.72, 0.47, -0.45, 0.58, 0.46, -1.02, -0.43, -5.43, -0.95, -0.25, 0.6, 0.27, -0.74, 0.74, 0.27, 0.98, 0.43, 1.64, 0.71, 1.75, 1.63, 0.13, 0.73, -4.33, 0.2, 0.91, 1.77, 1.43, 0.41, -0.18, -0.21, 0.55, 1.2, 0.28, 1.31, 1.19, -0.3, 0.3, -4.74, -0.23, 0.47, 1.33, 1.0, -0.02, 0.76, 0.23, -0.8, 0.67, -0.64, -0.91, 0.11, -0.01, -1.48, -0.89, -5.88, -1.41, -0.72, 0.13, -0.2, -1.21, -0.94, 0.27, 1.03, 0.91, -0.58, 0.02, -5.01, -0.5, 0.19, 1.05, 0.71, -0.3, 0.77, -0.9382570524713382, 1.06, -0.75, -0.12, -1.59, -1.0, -5.98, -1.52, -0.83, 0.02, -0.31, -1.32, -1.0187766439909298, -0.5526334687834371, -1.47, -0.88, -5.86, -1.4, -0.71, 0.14, -0.19, -1.2, 0.23, -0.59, -0.82, 0.66, 0.38, 0.93, 0.85, 0.6, -4.46, 0.07, 0.77, 1.64, 1.3, 0.28, -0.8434639289282145, 0.25, -5.03, -0.52, 0.17, 1.03, 0.7, -0.32, -0.36, -0.14, 0.58, 0.77, -4.05, 0.23, 0.2, -2.62, 2.59, 1.31, -0.96, -0.63, -1.72, -1.3, -0.62, -0.53, 0.29, 2.05, -1.91, -2.03, 0.68, -3.95, 1.33, -0.6, 0.26, 2.52, 1.56, -1.72, -2.62, 1.5938095238095238, 5.56, 4.74, 5.48, 6.38, 6.03, 4.96, 2.0931678995607568, 0.78, 0.7, 1.56, 1.22, 0.21, 0.08, 0.86, 0.52, -0.49, 0.6, 0.59, -0.77, -0.33, -1.2577512446849837, 0.64, 0.67, -0.2874239503761216, 0.94, 0.51, -0.97, 0.39, 0.66, -0.44, -1.01, 1.68, 1.66, -0.08, 0.32, 0.19, 0.57, -0.23, 0.92, 1.17], ['510', -7.99, -0.78, 0.01, 0.2, -1.57, -1.0, -2.76, -1.99, -2.44, -1.74, 1.29, 1.1789920634920634, -0.26, -0.23, -0.1, -0.06, 0.21, -1.51, -1.74, 0.6, -2.21, -1.07, -0.23, -0.45, -1.16, -2.15, -2.99, -0.11, -1.53, -1.5, -1.37, -1.33, -1.06, -2.77, -2.99, -0.68, -3.45, -2.33, -1.5, -1.6761582768021608, -1.48, -2.98, -2.88, -1.42, -1.39, -1.26, -1.20359693877551, -0.9107210884353741, -2.66, -2.88, -0.57, -3.34, -2.22, -1.38, -1.61, -1.22, -1.63, -1.99, -2.35, -1.48, 0.03, 0.16, 0.21, 0.48, -1.25, -1.48, 0.86, -1.95, -0.81, 0.04, -0.19, -2.16, -1.51, 0.13, 0.17, 0.44, -1.29, -1.51, 0.83, -1.98, -0.84, 0.0, -0.23, -2.8, -3.94, 4.02, -1.64, 0.04, 0.32, -1.41, -1.64, 0.7, -2.11, -0.97, -0.13, -0.35, -4.9, -1.68, 0.27, -1.46, -1.68, 0.65, -2.15, -1.01, -0.17, -0.4, -0.41, -1.74, -1.31, -1.08, -0.98, -1.25, -1.95, -1.72, -1.95, 0.38, -2.42, -1.28, -0.44, -0.67, -0.64, -0.23, -0.23, 2.14, -0.7, 0.45, 1.31, 1.08, -1.16, -1.46, 0.31, -1.33, -14.62, -0.29, -0.14, 3.27, -3.31, -1.64, -0.27, -2.4, 4.66, 2.15, 1.07, -4.02, -0.26, -3.3, 3.32, 3.15, -1.08, 4.78, -2.16, -2.15, 1.11, -5.77, 9.04, 3.83, 5.7, -4.55, 0.0, 2.38, -0.47, 0.68, 1.54, 1.31, -3.25, -2.32, -2.78, -1.66, -0.82, -1.04, 0.48, 1.16, 2.02, 1.79, -2.37, -2.53, -0.68, 0.85, 0.62, -1.05, -1.2, -2.14, 5.57, -1.37, -5.64, -1.59, -1.43, -1.52, -0.23, -0.8, -1.46, -0.15, -0.01, -0.53, -1.29, -2.57, -2.34, -1.41]], 'figimage': <function figimage at 0x3195140>, 'jet': <function jet at 0x3198848>, 'figaspect': <function figaspect at 0x3183938>, 'Line2D': <class 'matplotlib.lines.Line2D'>, 'exp2': <ufunc 'exp2'>, 'imshow': <function imshow at 0x3197398>, 'axhline': <function axhline at 0x31968c0>, 'bool8': <type 'numpy.bool_'>, 'colormaps': <function colormaps at 0x31961b8>, 'msort': <function msort at 0x236d5f0>, 'alltrue': <function alltrue at 0x21da2a8>, 'zeros': <built-in function zeros>, 'identity': <function identity at 0x21dbde8>, 'False_': False, 'ispower2': <function ispower2 at 0x2c522a8>, 'LogFormatterExponent': <class 'matplotlib.ticker.LogFormatterExponent'>, 'ihfft': <function ihfft at 0x24090c8>, 'nansum': <function nansum at 0x236cb18>, 'bool_': <type 'numpy.bool_'>, '_i78': u'train.shape', '_44': (200, 198), 'inexact': <type 'numpy.inexact'>, 'distances_along_curve': <function distances_along_curve at 0x2c53c08>, 'broadcast': <type 'numpy.broadcast'>, 'copyto': <built-in function copyto>, 'amin': <function amin at 0x21da5f0>, 'arctanh': <ufunc 'arctanh'>, 'typecodes': {'All': '?bhilqpBHILQPefdgFDGSUVOMm', 'Complex': 'FDG', 'AllFloat': 'efdgFDG', 'Integer': 'bhilqp', 'UnsignedInteger': 'BHILQP', 'Float': 'efdg', 'Character': 'c', 'Datetime': 'Mm', 'AllInteger': 'bBhHiIlLqQpP'}, 'number': <type 'numpy.number'>, 'savetxt': <function savetxt at 0x23fb410>, 'copy': <function copy at 0x236c500>, 'int_': <type 'numpy.int64'>, '_i69': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'std': <function std at 0x21daaa0>, 'segments_intersect': <function segments_intersect at 0x2c51848>, 'not_equal': <ufunc 'not_equal'>, 'fromfunction': <function fromfunction at 0x21dbb18>, 'Figure': <class 'matplotlib.figure.Figure'>, 'tril_indices_from': <function tril_indices_from at 0x230db18>, 'double': <type 'numpy.float64'>, 'require': <function require at 0x21c2758>, 'predicted_probs': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.073016773707397273, 0.0, 0.0], 'triplot': <function triplot at 0x3197d70>, 'headers': array(['O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8', 'O9', 'O10', 'O11',\n       'O12', 'O13', 'O14', 'O15', 'O16', 'O17', 'O18', 'O19', 'O20',\n       'O21', 'O22', 'O23', 'O24', 'O25', 'O26', 'O27', 'O28', 'O29',\n       'O30', 'O31', 'O32', 'O33', 'O34', 'O35', 'O36', 'O37', 'O38',\n       'O39', 'O40', 'O41', 'O42', 'O43', 'O44', 'O45', 'O46', 'O47',\n       'O48', 'O49', 'O50', 'O51', 'O52', 'O53', 'O54', 'O55', 'O56',\n       'O57', 'O58', 'O59', 'O60', 'O61', 'O62', 'O63', 'O64', 'O65',\n       'O66', 'O67', 'O68', 'O69', 'O70', 'O71', 'O72', 'O73', 'O74',\n       'O75', 'O76', 'O77', 'O78', 'O79', 'O80', 'O81', 'O82', 'O83',\n       'O84', 'O85', 'O86', 'O87', 'O88', 'O89', 'O90', 'O91', 'O92',\n       'O93', 'O94', 'O95', 'O96', 'O97', 'O98', 'O99', 'O100', 'O101',\n       'O102', 'O103', 'O104', 'O105', 'O106', 'O107', 'O108', 'O109',\n       'O110', 'O111', 'O112', 'O113', 'O114', 'O115', 'O116', 'O117',\n       'O118', 'O119', 'O120', 'O121', 'O122', 'O123', 'O124', 'O125',\n       'O126', 'O127', 'O128', 'O129', 'O130', 'O131', 'O132', 'O133',\n       'O134', 'O135', 'O136', 'O137', 'O138', 'O139', 'O140', 'O141',\n       'O142', 'O143', 'O144', 'O145', 'O146', 'O147', 'O148', 'O149',\n       'O150', 'O151', 'O152', 'O153', 'O154', 'O155', 'O156', 'O157',\n       'O158', 'O159', 'O160', 'O161', 'O162', 'O163', 'O164', 'O165',\n       'O166', 'O167', 'O168', 'O169', 'O170', 'O171', 'O172', 'O173',\n       'O174', 'O175', 'O176', 'O177', 'O178', 'O179', 'O180', 'O181',\n       'O182', 'O183', 'O184', 'O185', 'O186', 'O187', 'O188', 'O189',\n       'O190', 'O191', 'O192', 'O193', 'O194', 'O195', 'O196', 'O197',\n       'O198', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10',\n       'I11', 'I12', 'I13', 'I14', 'I15', 'I16', 'I17', 'I18', 'I19',\n       'I20', 'I21', 'I22', 'I23', 'I24', 'I25', 'I26', 'I27', 'I28',\n       'I29', 'I30', 'I31', 'I32', 'I33', 'I34', 'I35', 'I36', 'I37',\n       'I38', 'I39', 'I40', 'I41', 'I42', 'I43', 'I44', 'I45', 'I46',\n       'I47', 'I48', 'I49', 'I50', 'I51', 'I52', 'I53', 'I54', 'I55',\n       'I56', 'I57', 'I58', 'I59', 'I60', 'I61', 'I62', 'I63', 'I64',\n       'I65', 'I66', 'I67', 'I68', 'I69', 'I70', 'I71', 'I72', 'I73',\n       'I74', 'I75', 'I76', 'I77', 'I78', 'I79', 'I80', 'I81', 'I82',\n       'I83', 'I84', 'I85', 'I86', 'I87', 'I88', 'I89', 'I90', 'I91',\n       'I92', 'I93', 'I94', 'I95', 'I96', 'I97', 'I98', 'I99', 'I100',\n       'I101', 'I102', 'I103', 'I104', 'I105', 'I106', 'I107', 'I108',\n       'I109', 'I110', 'I111', 'I112', 'I113', 'I114', 'I115', 'I116',\n       'I117', 'I118', 'I119', 'I120', 'I121', 'I122', 'I123', 'I124',\n       'I125', 'I126', 'I127', 'I128', 'I129', 'I130', 'I131', 'I132',\n       'I133', 'I134', 'I135', 'I136', 'I137', 'I138', 'I139', 'I140',\n       'I141', 'I142', 'I143', 'I144', 'I145', 'I146', 'I147', 'I148',\n       'I149', 'I150', 'I151', 'I152', 'I153', 'I154', 'I155', 'I156',\n       'I157', 'I158', 'I159', 'I160', 'I161', 'I162', 'I163', 'I164',\n       'I165', 'I166', 'I167', 'I168', 'I169', 'I170', 'I171', 'I172',\n       'I173', 'I174', 'I175', 'I176', 'I177', 'I178', 'I179', 'I180',\n       'I181', 'I182', 'I183', 'I184', 'I185', 'I186', 'I187', 'I188',\n       'I189', 'I190', 'I191', 'I192', 'I193', 'I194', 'I195', 'I196',\n       'I197', 'I198', 'I199', 'I200', 'I201', 'I202', 'I203', 'I204',\n       'I205', 'I206', 'I207', 'I208', 'I209', 'I210', 'I211', 'I212',\n       'I213', 'I214', 'I215', 'I216', 'I217', 'I218', 'I219', 'I220',\n       'I221', 'I222', 'I223', 'I224', 'I225', 'I226', 'I227', 'I228',\n       'I229', 'I230', 'I231', 'I232', 'I233', 'I234', 'I235', 'I236',\n       'I237', 'I238', 'I239', 'I240', 'I241', 'I242', 'I243', 'I244'], \n      dtype='|S10'), '_iii': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'xlabel': <function xlabel at 0x3195a28>, 'typeNA': {<type 'numpy.float16'>: 'Float16', <type 'numpy.int16'>: 'Int16', 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, <type 'numpy.timedelta64'>: 'Timedelta64', <type 'numpy.uint8'>: 'UInt8', 'c16': 'Complex64', <type 'numpy.datetime64'>: 'Datetime64', 'D': 'Complex64', <type 'numpy.int8'>: 'Int8', 'H': 'UInt16', 'L': 'UInt64', <type 'numpy.void'>: 'Void0', <type 'numpy.bool_'>: 'Bool', 'd': 'Float64', 'h': 'Int16', 'l': 'Int64', <type 'numpy.unicode_'>: 'Unicode0', 'c32': 'Complex128', <type 'numpy.string_'>: 'String0', 'Timedelta64': <type 'numpy.timedelta64'>, 'b1': 'Bool', 'M8': 'Datetime64', 'String0': <type 'numpy.string_'>, <type 'numpy.object_'>: 'Object0', 'I': 'UInt32', '?': 'Bool', 'Void0': <type 'numpy.void'>, <type 'numpy.complex256'>: 'Complex128', 'G': 'Complex128', 'O': 'Object0', 'UInt8': <type 'numpy.uint8'>, 'S': 'String0', <type 'numpy.complex128'>: 'Complex64', 'UInt64': <type 'numpy.uint64'>, 'g': 'Float128', <type 'numpy.complex64'>: 'Complex32', 'Float16': <type 'numpy.float16'>, <type 'numpy.float128'>: 'Float128', 'Bool': <type 'numpy.bool_'>, 'u8': <type 'numpy.uint64'>, <type 'numpy.float64'>: 'Float64', 'u4': <type 'numpy.uint32'>, 'Unicode0': <type 'numpy.unicode_'>, 'u1': <type 'numpy.uint8'>, 'u2': <type 'numpy.uint16'>, 'Datetime64': <type 'numpy.datetime64'>, 'Int8': <type 'numpy.int8'>, <type 'numpy.float32'>: 'Float32', 'B': 'UInt8', 'F': 'Complex32', 'c8': 'Complex32', 'Int64': <type 'numpy.int64'>, 'Complex32': <type 'numpy.complex64'>, 'V': 'Void0', <type 'numpy.uint64'>: 'UInt64', 'b': 'Int8', 'f': 'Float32', 'm8': 'Timedelta64', <type 'numpy.int64'>: 'Int64', 'f16': 'Float128', 'UInt32': <type 'numpy.uint32'>, 'f2': 'Float16', 'f4': 'Float32', 'f8': 'Float64', 'Complex128': <type 'numpy.complex256'>, <type 'numpy.uint64'>: 'UInt64', 'Object0': <type 'numpy.object_'>, 'Int16': <type 'numpy.int16'>, <type 'numpy.int64'>: 'Int64', 'Float64': <type 'numpy.float64'>, 'UInt16': <type 'numpy.uint16'>, 'Float32': <type 'numpy.float32'>, 'i8': <type 'numpy.int64'>, <type 'numpy.uint32'>: 'UInt32', 'i1': <type 'numpy.int8'>, 'i2': <type 'numpy.int16'>, 'M': 'Datetime64', 'i4': <type 'numpy.int32'>, 'Q': 'UInt64', 'U': 'Unicode0', <type 'numpy.int32'>: 'Int32', 'e': 'Float16', 'i': 'Int32', 'm': 'Timedelta64', 'q': 'Int64', <type 'numpy.uint16'>: 'UInt16', 'Float128': <type 'numpy.float128'>}, '_i11': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', 'lastObserved': array([[ 2.78,  0.77,  0.1 , ...,  3.25,  3.05,  1.55],\n       [-4.62,  0.06, -0.22, ...,  0.52, -0.56,  0.33],\n       [ 0.02,  0.13,  0.18, ..., -0.47,  0.91,  0.97],\n       ..., \n       [-0.33,  0.23,  0.12, ..., -1.81, -1.01,  0.26],\n       [-1.13,  0.06,  0.  , ..., -0.23,  0.92,  1.17],\n       [-7.99, -0.78,  0.01, ..., -2.57, -2.34, -1.41]]), 'getbuffer': <built-in function getbuffer>, 'xcorr': <function xcorr at 0x3197e60>, 'slogdet': <function slogdet at 0x238cb90>, 'clip': <function clip at 0x21da0c8>, 'tripcolor': <function tripcolor at 0x3197cf8>, '_i27': u'trainInput.shape', 'half': <type 'numpy.float16'>, 'normal': <built-in method normal of mtrand.RandomState object at 0x7f399f841690>, '_i126': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', 'savez_compressed': <function savez_compressed at 0x23fb230>, 'TickHelper': <class 'matplotlib.ticker.TickHelper'>, 'isinteractive': <function isinteractive at 0x3194410>, 'eigvals': <function eigvals at 0x238c758>, 'seed': <built-in method seed of mtrand.RandomState object at 0x7f399f841690>, 'triu_indices_from': <function triu_indices_from at 0x230dc08>, 'conjugate': <ufunc 'conjugate'>, 'clim': <function clim at 0x3196320>, 'array2string': <function array2string at 0x21db050>, 'alterdot': <built-in function alterdot>, 'cross_validation': <module 'sklearn.cross_validation' from '/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc'>, 'asfortranarray': <function asfortranarray at 0x21c26e0>, 'binary_repr': <function binary_repr at 0x21dbc08>, 'angle': <function angle at 0x236c6e0>, '_78': (510, 55, 442), '_i9': u'len(targets)', 'randint': <built-in method randint of mtrand.RandomState object at 0x7f399f841690>, '_i7': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(trainOutput), n_folds=63, indices=False)', '_i6': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(train), n_folds=63, indices=False)', '_i5': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', 'linalg': <module 'numpy.linalg' from '/usr/local/lib/python2.7/dist-packages/numpy/linalg/__init__.pyc'>, 'apply_over_axes': <function apply_over_axes at 0x2374b18>, '_i2': u'ls', '_i1': u'cd /home/lane/Kaggle/03\\\\ Predicting\\\\ Stock\\\\ Prices/', 'yoda': array([ 0.        ,  0.22      ,  0.        ,  0.        ,  0.22      ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.1       ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.02714286,  0.        ,  0.01714286,\n        0.        ,  0.1       ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.02714286,  0.        ,  0.        ,  0.01714286,\n        0.        ,  0.        ,  0.61571429,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.61571429,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.02714286,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.1       ,  0.        ,  0.        ,\n        0.02714286,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.22      ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.02714286,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.61571429,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.1       ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.22      ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.61571429,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'figlegend': <function figlegend at 0x3194de8>, 'ERR_LOG': 5, 'right_shift': <ufunc 'right_shift'>, 'take': <function take at 0x21d16e0>, 'rollaxis': <function rollaxis at 0x21c2c08>, 'set_state': <built-in method set_state of mtrand.RandomState object at 0x7f399f841690>, 'solve': <function solve at 0x238c500>, 'FixedFormatter': <class 'matplotlib.ticker.FixedFormatter'>, 'boxplot': <function boxplot at 0x3196c08>, 'SecondLocator': <class 'matplotlib.dates.SecondLocator'>, 'spectral': <function spectral at 0x3198b18>, 'get_numarray_include': <function get_numarray_include at 0x23691b8>, 'trace': <function trace at 0x21d1de8>, 'Artist': <class 'matplotlib.artist.Artist'>, 'any': <function any at 0x21da320>, 'Button': <class 'matplotlib.widgets.Button'>, 'who': <function who at 0x2369578>, 'compress': <function compress at 0x21da050>, 'NullFormatter': <class 'matplotlib.ticker.NullFormatter'>, 'histogramdd': <function histogramdd at 0x236c2a8>, '_i88': u'test.shape', '_i89': u'y.shape', 'beta': <built-in method beta of mtrand.RandomState object at 0x7f399f841690>, 'amap': <function amap at 0x2c51d70>, 'multiply': <ufunc 'multiply'>, '_i81': u'X.shape', 'mask_indices': <function mask_indices at 0x230da28>, 'detrend_none': <function detrend_none at 0x2c4f7d0>, '_i84': u'test.shape', 'amax': <function amax at 0x21da578>, 'numCols': 442, '_66': (510, 55, 198), 'subplot': <function subplot at 0x3195500>, 'logical_not': <ufunc 'logical_not'>, 'dist_point_to_segment': <function dist_point_to_segment at 0x2c517d0>, 'trainingDays': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510], '_i75': u'traincv.shape', '_i74': u'traincv', '_i77': u'train[traincv]', '_i76': u'testcv.shape', '_i71': u'cv', 'nbytes': {<type 'numpy.float16'>: 2, <type 'numpy.string_'>: 0, <type 'numpy.float128'>: 16, <type 'numpy.uint64'>: 8, <type 'numpy.int16'>: 2, <type 'numpy.timedelta64'>: 8, <type 'numpy.object_'>: 8, <type 'numpy.float64'>: 8, <type 'numpy.int64'>: 8, <type 'numpy.uint8'>: 1, <type 'numpy.datetime64'>: 8, <type 'numpy.complex256'>: 32, <type 'numpy.float32'>: 4, <type 'numpy.uint32'>: 4, <type 'numpy.int8'>: 1, <type 'numpy.void'>: 0, <type 'numpy.complex128'>: 16, <type 'numpy.uint64'>: 8, <type 'numpy.int32'>: 4, <type 'numpy.bool_'>: 1, <type 'numpy.unicode_'>: 0, <type 'numpy.complex64'>: 8, <type 'numpy.int64'>: 8, <type 'numpy.uint16'>: 2}, 'exp': <ufunc 'exp'>, '_ih': ['', u\"get_ipython().magic(u'cd /home/lane/Kaggle/03\\\\\\\\ Predicting\\\\\\\\ Stock\\\\\\\\ Prices/')\", u\"get_ipython().system(u'ls -F --color ')\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(train), n_folds=63, indices=False)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(trainOutput), n_folds=63, indices=False)', u'len(trainOutput)', u'len(targets)', u'len(target)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'trainInput.shape', u'trainOutput.shape', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:197] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:198] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'trainInput[509,54,243]', u'trainInput[509,54,244]', u'trainInput[509,54,243]', u'fullInput[509,54,244+197]', u'train            = np.zeros((510,55,244+198))\\ntrain[:,:,0:198] = trainOutput\\ntrain[:,:,198:]  = trainInput', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(target[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'trainOutput.shape', u'len(trainOutput[0])', u'target.shape', u'target.shape', u'trainInput.shape', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput(:,-1,:)', u'lastObserved = trainOutput[:,-1,:]\\nlastObserved.shape', u'target.shape', u'normTarget   = target - lastObserved[:target.shape[0],:]', u'normTarget.shape', u'target.shape', u'plot(normTarget[:,0])', u'plot(normTarget[:,197])', u'hist(normTarget[:,197])', u'hist(normTarget)', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1)))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1)))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1))', u'yoda.shape', u'normTarget.shape', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-2,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((200*198,1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True)', u\"yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,4)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,6)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nyaxis('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',norm=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',normed=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\nderiv.shape', u'normTarget.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'len(target)', u'cv', u'for i in cv:\\n    print i', u'for i,j in cv:\\n    print i,j', u'traincv', u'traincv.shape', u'testcv.shape', u'train[traincv]', u'train.shape', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201,:]\\ntest  = X[201:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201]\\ntest  = X[201:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'train.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:200]\\ntest  = X[200:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'y.shape', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'train.shape', u'test.shape', u'yoda = X.reshape((X.shape[0],1))', u'yoda.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock].reshape((deriv.shape[0],1))\\ny     = normTarget[:,stock]\\ntrain = X[:200,:]\\ntest  = X[200:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'predicted_probs.shape', u'len(predicted_probs)', u'len(predicted_probs[0])', u'lastObserved[:,stock].shape', u'pred = predicted_probs + lastObserved[200:,stock]', u'pred = predicted_probs + lastObserved[200:,stock]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape[2]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'numStocks', u'type(predicted_probs)', u'yoda = np.asarray(predicted_probs)\\nyoda.shape', u'yoda = np.asarray(predicted_probs)\\nluke = np.zeros((310,198))\\nluke[:,0] = yoda', u'pred[0]', u'## Fit Random Forest and generate predictions\\nnumStocks   = trainOutput.shape[2]\\nperformance = []\\npred        = np.zeros((310,numStocks))\\nfor stock in xrange(numStocks):\\n    \\n    # get stock-specific features\\n    X     = deriv[:,stock].reshape((deriv.shape[0],1))\\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n\\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n\\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import smtplib', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import pybrain', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random\\nimport smtplib\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=500, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=25, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'sheet.shape', u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection'], 'axvspan': <function axvspan at 0x3196a28>, 'FuncFormatter': <class 'matplotlib.ticker.FuncFormatter'>, 'dot': <built-in function dot>, 'int0': <type 'numpy.int64'>, 'pylab': <module 'matplotlib.pylab' from '/usr/local/lib/python2.7/dist-packages/matplotlib/pylab.pyc'>, '_i23': u'trainOutput.shape', 'WE': WE, '_i121': u'import pybrain', 'longfloat': <type 'numpy.float128'>, 'draw_if_interactive': <function wrapper at 0x325c410>, 'rayleigh': <built-in method rayleigh of mtrand.RandomState object at 0x7f399f841690>, 'text': <function text at 0x31981b8>, 'random': <module 'random' from '/usr/lib/python2.7/random.pyc'>, 'demean': <function demean at 0x2c4f6e0>, 'random_integers': <built-in method random_integers of mtrand.RandomState object at 0x7f399f841690>, 'datetime': <module 'datetime' from '/usr/lib/python2.7/lib-dynload/datetime.so'>, 'colors': <function colors at 0x3196140>, 'stackplot': <function stackplot at 0x3197a28>, '_i124': u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", 'locator_params': <function locator_params at 0x3198320>, '_67': (510, 198), '_i125': u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', 'find': <function find at 0x2c51050>, '_i20': u'train            = np.zeros((510,55,244+198))\\ntrain[:,:,0:198] = trainOutput\\ntrain[:,:,198:]  = trainInput', 'pause': <function pause at 0x3194578>, 'randn': <built-in method randn of mtrand.RandomState object at 0x7f399f841690>, 'errstate': <class 'numpy.core.numeric.errstate'>, 'title': <function title at 0x3195938>, 'FPE_UNDERFLOW': 4, '_i108': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_8': 510, '_i113': u'type(predicted_probs)', 'frexp': <ufunc 'frexp'>, 'savefig': <function savefig at 0x3194e60>, 'PolarAxes': <class 'matplotlib.projections.polar.PolarAxes'>, 'DAILY': 3, 'center_matrix': <function center_matrix at 0x2c51500>, '_65': <matplotlib.text.Text object at 0x92e02d0>, 'smtplib': <module 'smtplib' from '/usr/lib/python2.7/smtplib.pyc'>, 'SHIFT_OVERFLOW': 3, 'over': <function over at 0x31952a8>, 'complex256': <type 'numpy.complex256'>, 'plotfile': <function plotfile at 0x31965f0>, '_i96': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock].reshape((deriv.shape[0],1))\\ny     = normTarget[:,stock]\\ntrain = X[:200,:]\\ntest  = X[200:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'get': <function getp at 0x2a9d1b8>, 'luke': array([[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.22,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       ..., \n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ]]), 'NZERO': -0.0, 'ceil': <ufunc 'ceil'>, 'ones': <function ones at 0x21c2410>, 'add_newdoc_ufunc': <built-in function add_newdoc_ufunc>, 'X': array([[  0.04    ,   1.5     ,   2.      , ...,   0.439681,   0.074476,\n          0.142166],\n       [ -0.11    ,   0.789473,  19.      , ...,   0.767666,   0.147196,\n          0.272029],\n       [ -0.08    ,   0.5     ,  12.      , ...,   0.216333,   0.062503,\n          0.062272],\n       ..., \n       [  0.27    ,   0.323529,  34.      , ...,   0.179467,   0.085557,\n          0.083333],\n       [  0.      ,   0.294117,  17.      , ...,   0.195387,   0.076333,\n          0.062539],\n       [  0.31    ,   1.6     ,   5.      , ...,   1.05697 ,   0.411582,\n          0.452769]]), 'count_nonzero': <built-in function count_nonzero>, 'target': array([[ 2.53,  1.03,  0.12, ...,  3.69,  3.56,  2.03],\n       [-4.95,  0.18, -0.24, ...,  1.22, -0.04,  0.38],\n       [ 0.16,  0.  ,  0.2 , ..., -0.04,  1.3 ,  1.61],\n       ..., \n       [-1.02,  1.53,  0.62, ...,  3.85,  4.87,  2.06],\n       [ 0.43,  0.12, -0.08, ..., -0.59, -0.67,  0.2 ],\n       [ 0.11,  0.  ,  0.29, ...,  0.48,  2.58,  0.47]]), '_108': <matplotlib.text.Text object at 0x918f1d0>, 'gray': <function gray at 0x31986e0>, 'qr': <function qr at 0x238c6e0>, 'bar': <function bar at 0x3196aa0>, '_102': 310, 'median': <function median at 0x236d668>, '_i99': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'geterr': <function geterr at 0x21dd140>, 'convolve': <function convolve at 0x21c2a28>, 'twiny': <function twiny at 0x31956e0>, 'logistic': <built-in method logistic of mtrand.RandomState object at 0x7f399f841690>, 'weibull': <built-in method weibull of mtrand.RandomState object at 0x7f399f841690>, 'x': array([ 0.004,  0.02 ,  0.004,  0.002,  0.002,  0.006,  0.002,  0.002,\n        0.008,  0.   ,  0.002,  0.   ,  0.   ,  0.   ,  0.002,  0.004,\n        0.   ,  0.006,  0.002,  0.012,  0.018,  0.006,  0.004,  0.002,\n        0.012,  0.026,  0.006,  0.02 ,  0.012,  0.   ,  0.002,  0.002,\n        0.   ,  0.004,  0.008,  0.002,  0.006,  0.   ,  0.   ,  0.012,\n        0.006,  0.01 ,  0.012,  0.004,  0.006,  0.012,  0.012,  0.   ,\n        0.01 ,  0.002,  0.006,  0.008,  0.014,  0.   ,  0.   ,  0.006,\n        0.008,  0.004,  0.018,  0.008,  0.01 ,  0.002,  0.   ,  0.006,\n        0.   ,  0.016,  0.018,  0.   ,  0.004,  0.004,  0.004,  0.008,\n        0.01 ,  0.012,  0.004,  0.002,  0.004,  0.01 ,  0.002,  0.006,\n        0.006,  0.004,  0.004,  0.004,  0.03 ,  0.008,  0.   ,  0.006,\n        0.004,  0.008,  0.   ,  0.014,  0.03 ,  0.01 ,  0.004,  0.004,\n        0.016,  0.004,  0.002,  0.004,  0.   ,  0.002,  0.004,  0.008,\n        0.002,  0.004,  0.   ,  0.006,  0.004,  0.004,  0.006,  0.002,\n        0.016,  0.004,  0.032,  0.012,  0.   ,  0.01 ,  0.   ,  0.002,\n        0.   ,  0.   ,  0.016,  0.002,  0.004,  0.008,  0.008,  0.   ,\n        0.002,  0.004,  0.01 ,  0.006,  0.002,  0.002,  0.006,  0.002,\n        0.006,  0.004,  0.008,  0.   ,  0.006,  0.002,  0.004,  0.   ,\n        0.002,  0.006,  0.006,  0.   ,  0.   ,  0.   ,  0.002,  0.016,\n        0.004,  0.028,  0.002,  0.004,  0.002,  0.   ,  0.002,  0.01 ,\n        0.002,  0.   ,  0.002,  0.002,  0.   ,  0.012,  0.002,  0.   ,\n        0.016,  0.004,  0.   ,  0.006]), 'isreal': <function isreal at 0x23017d0>, 'where': <built-in function where>, 'rcParamsDefault': RcParams({'agg.path.chunksize': 0,\n          'animation.avconv_args': '',\n          'animation.avconv_path': 'avconv',\n          'animation.bitrate': -1,\n          'animation.codec': 'mpeg4',\n          'animation.convert_args': '',\n          'animation.convert_path': 'convert',\n          'animation.ffmpeg_args': '',\n          'animation.ffmpeg_path': 'ffmpeg',\n          'animation.frame_format': 'png',\n          'animation.mencoder_args': '',\n          'animation.mencoder_path': 'mencoder',\n          'animation.writer': 'ffmpeg',\n          'axes.axisbelow': False,\n          'axes.color_cycle': ['b', 'g', 'r', 'c', 'm', 'y', 'k'],\n          'axes.edgecolor': 'k',\n          'axes.facecolor': 'w',\n          'axes.formatter.limits': [-7, 7],\n          'axes.formatter.use_locale': False,\n          'axes.formatter.use_mathtext': False,\n          'axes.grid': False,\n          'axes.hold': True,\n          'axes.labelcolor': 'k',\n          'axes.labelsize': 'medium',\n          'axes.labelweight': 'normal',\n          'axes.linewidth': 1.0,\n          'axes.titlesize': 'large',\n          'axes.unicode_minus': True,\n          'axes.xmargin': 0,\n          'axes.ymargin': 0,\n          'axes3d.grid': True,\n          'backend': 'Agg',\n          'backend.qt4': 'PyQt4',\n          'backend_fallback': True,\n          'contour.negative_linestyle': 'dashed',\n          'datapath': '/usr/local/lib/python2.7/dist-packages/matplotlib/mpl-data',\n          'docstring.hardcopy': False,\n          'examples.directory': '',\n          'figure.autolayout': False,\n          'figure.dpi': 80,\n          'figure.edgecolor': 'w',\n          'figure.facecolor': '0.75',\n          'figure.figsize': [8.0, 6.0],\n          'figure.frameon': True,\n          'figure.max_open_warning': 20,\n          'figure.subplot.bottom': 0.1,\n          'figure.subplot.hspace': 0.2,\n          'figure.subplot.left': 0.125,\n          'figure.subplot.right': 0.9,\n          'figure.subplot.top': 0.9,\n          'figure.subplot.wspace': 0.2,\n          'font.cursive': ['Apple Chancery',\n                           'Textile',\n                           'Zapf Chancery',\n                           'Sand',\n                           'cursive'],\n          'font.family': 'sans-serif',\n          'font.fantasy': ['Comic Sans MS',\n                           'Chicago',\n                           'Charcoal',\n                           'ImpactWestern',\n                           'fantasy'],\n          'font.monospace': ['Bitstream Vera Sans Mono',\n                             'DejaVu Sans Mono',\n                             'Andale Mono',\n                             'Nimbus Mono L',\n                             'Courier New',\n                             'Courier',\n                             'Fixed',\n                             'Terminal',\n                             'monospace'],\n          'font.sans-serif': ['Bitstream Vera Sans',\n                              'DejaVu Sans',\n                              'Lucida Grande',\n                              'Verdana',\n                              'Geneva',\n                              'Lucid',\n                              'Arial',\n                              'Helvetica',\n                              'Avant Garde',\n                              'sans-serif'],\n          'font.serif': ['Bitstream Vera Serif',\n                         'DejaVu Serif',\n                         'New Century Schoolbook',\n                         'Century Schoolbook L',\n                         'Utopia',\n                         'ITC Bookman',\n                         'Bookman',\n                         'Nimbus Roman No9 L',\n                         'Times New Roman',\n                         'Times',\n                         'Palatino',\n                         'Charter',\n                         'serif'],\n          'font.size': 12,\n          'font.stretch': 'normal',\n          'font.style': 'normal',\n          'font.variant': 'normal',\n          'font.weight': 'normal',\n          'grid.alpha': 1.0,\n          'grid.color': 'k',\n          'grid.linestyle': ':',\n          'grid.linewidth': 0.5,\n          'image.aspect': 'equal',\n          'image.cmap': 'jet',\n          'image.interpolation': 'bilinear',\n          'image.lut': 256,\n          'image.origin': 'upper',\n          'image.resample': False,\n          'interactive': False,\n          'keymap.all_axes': 'a',\n          'keymap.back': ['left', 'c', 'backspace'],\n          'keymap.forward': ['right', 'v'],\n          'keymap.fullscreen': ('f', 'ctrl+f'),\n          'keymap.grid': 'g',\n          'keymap.home': ['h', 'r', 'home'],\n          'keymap.pan': 'p',\n          'keymap.quit': ('ctrl+w', 'cmd+w'),\n          'keymap.save': ('s', 'ctrl+s'),\n          'keymap.xscale': ['k', 'L'],\n          'keymap.yscale': 'l',\n          'keymap.zoom': 'o',\n          'legend.borderaxespad': 0.5,\n          'legend.borderpad': 0.4,\n          'legend.columnspacing': 2.0,\n          'legend.fancybox': False,\n          'legend.fontsize': 'large',\n          'legend.frameon': True,\n          'legend.handleheight': 0.7,\n          'legend.handlelength': 2.0,\n          'legend.handletextpad': 0.8,\n          'legend.isaxes': True,\n          'legend.labelspacing': 0.5,\n          'legend.loc': 'upper right',\n          'legend.markerscale': 1.0,\n          'legend.numpoints': 2,\n          'legend.scatterpoints': 3,\n          'legend.shadow': False,\n          'lines.antialiased': True,\n          'lines.color': 'b',\n          'lines.dash_capstyle': 'butt',\n          'lines.dash_joinstyle': 'round',\n          'lines.linestyle': '-',\n          'lines.linewidth': 1.0,\n          'lines.marker': 'None',\n          'lines.markeredgewidth': 0.5,\n          'lines.markersize': 6,\n          'lines.solid_capstyle': 'projecting',\n          'lines.solid_joinstyle': 'round',\n          'mathtext.bf': 'serif:bold',\n          'mathtext.cal': 'cursive',\n          'mathtext.default': 'it',\n          'mathtext.fallback_to_cm': True,\n          'mathtext.fontset': 'cm',\n          'mathtext.it': 'serif:italic',\n          'mathtext.rm': 'serif',\n          'mathtext.sf': 'sans\\\\-serif',\n          'mathtext.tt': 'monospace',\n          'patch.antialiased': True,\n          'patch.edgecolor': 'k',\n          'patch.facecolor': 'b',\n          'patch.linewidth': 1.0,\n          'path.effects': [],\n          'path.simplify': True,\n          'path.simplify_threshold': 0.1111111111111111,\n          'path.sketch': None,\n          'path.snap': True,\n          'pdf.compression': 6,\n          'pdf.fonttype': 3,\n          'pdf.inheritcolor': False,\n          'pdf.use14corefonts': False,\n          'pgf.debug': False,\n          'pgf.preamble': [''],\n          'pgf.rcfonts': True,\n          'pgf.texsystem': 'xelatex',\n          'plugins.directory': '.matplotlib_plugins',\n          'polaraxes.grid': True,\n          'ps.distiller.res': 6000,\n          'ps.fonttype': 3,\n          'ps.papersize': 'letter',\n          'ps.useafm': False,\n          'ps.usedistiller': False,\n          'savefig.bbox': None,\n          'savefig.directory': '~',\n          'savefig.dpi': 100,\n          'savefig.edgecolor': 'w',\n          'savefig.extension': 'png',\n          'savefig.facecolor': 'w',\n          'savefig.format': 'png',\n          'savefig.frameon': True,\n          'savefig.jpeg_quality': 95,\n          'savefig.orientation': 'portrait',\n          'savefig.pad_inches': 0.1,\n          'svg.embed_char_paths': True,\n          'svg.fonttype': 'path',\n          'svg.image_inline': True,\n          'svg.image_noscale': False,\n          'text.antialiased': True,\n          'text.color': 'k',\n          'text.dvipnghack': None,\n          'text.hinting': True,\n          'text.hinting_factor': 8,\n          'text.latex.preamble': [''],\n          'text.latex.preview': False,\n          'text.latex.unicode': False,\n          'text.usetex': False,\n          'timezone': 'UTC',\n          'tk.pythoninspect': False,\n          'tk.window_focus': False,\n          'toolbar': 'toolbar2',\n          'verbose.fileo': 'sys.stdout',\n          'verbose.level': 'silent',\n          'webagg.open_in_browser': True,\n          'webagg.port': 8988,\n          'webagg.port_retries': 50,\n          'xtick.color': 'k',\n          'xtick.direction': 'in',\n          'xtick.labelsize': 'medium',\n          'xtick.major.pad': 4,\n          'xtick.major.size': 4,\n          'xtick.major.width': 0.5,\n          'xtick.minor.pad': 4,\n          'xtick.minor.size': 2,\n          'xtick.minor.width': 0.5,\n          'ytick.color': 'k',\n          'ytick.direction': 'in',\n          'ytick.labelsize': 'medium',\n          'ytick.major.pad': 4,\n          'ytick.major.size': 4,\n          'ytick.major.width': 0.5,\n          'ytick.minor.pad': 4,\n          'ytick.minor.size': 2,\n          'ytick.minor.width': 0.5}), 'fftsurr': <function fftsurr at 0x2c518c0>, 'SHIFT_UNDERFLOW': 6, 'argmax': <function argmax at 0x21d1b18>, 'minorticks_on': <function minorticks_on at 0x3195de8>, 'prctile': <function prctile at 0x2c51230>, 'deprecate_with_doc': <function <lambda> at 0x2369410>, 'imsave': <function imsave at 0x3196500>, 'polyder': <function polyder at 0x238ce60>, 'LogFormatterMathtext': <class 'matplotlib.ticker.LogFormatterMathtext'>, 'imread': <function imread at 0x3196488>, 'close': <function close at 0x3194b90>, 'DayLocator': <class 'matplotlib.dates.DayLocator'>, 'Formatter': <class 'matplotlib.ticker.Formatter'>, 'is_string_like': <function is_string_like at 0x29927d0>, 'contour': <function contour at 0x3196d70>, 'rad2deg': <ufunc 'rad2deg'>, 'isnan': <ufunc 'isnan'>, 'autoscale': <function autoscale at 0x3198488>, 'firstLine': ['fileId', 'O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8', 'O9', 'O10', 'O11', 'O12', 'O13', 'O14', 'O15', 'O16', 'O17', 'O18', 'O19', 'O20', 'O21', 'O22', 'O23', 'O24', 'O25', 'O26', 'O27', 'O28', 'O29', 'O30', 'O31', 'O32', 'O33', 'O34', 'O35', 'O36', 'O37', 'O38', 'O39', 'O40', 'O41', 'O42', 'O43', 'O44', 'O45', 'O46', 'O47', 'O48', 'O49', 'O50', 'O51', 'O52', 'O53', 'O54', 'O55', 'O56', 'O57', 'O58', 'O59', 'O60', 'O61', 'O62', 'O63', 'O64', 'O65', 'O66', 'O67', 'O68', 'O69', 'O70', 'O71', 'O72', 'O73', 'O74', 'O75', 'O76', 'O77', 'O78', 'O79', 'O80', 'O81', 'O82', 'O83', 'O84', 'O85', 'O86', 'O87', 'O88', 'O89', 'O90', 'O91', 'O92', 'O93', 'O94', 'O95', 'O96', 'O97', 'O98', 'O99', 'O100', 'O101', 'O102', 'O103', 'O104', 'O105', 'O106', 'O107', 'O108', 'O109', 'O110', 'O111', 'O112', 'O113', 'O114', 'O115', 'O116', 'O117', 'O118', 'O119', 'O120', 'O121', 'O122', 'O123', 'O124', 'O125', 'O126', 'O127', 'O128', 'O129', 'O130', 'O131', 'O132', 'O133', 'O134', 'O135', 'O136', 'O137', 'O138', 'O139', 'O140', 'O141', 'O142', 'O143', 'O144', 'O145', 'O146', 'O147', 'O148', 'O149', 'O150', 'O151', 'O152', 'O153', 'O154', 'O155', 'O156', 'O157', 'O158', 'O159', 'O160', 'O161', 'O162', 'O163', 'O164', 'O165', 'O166', 'O167', 'O168', 'O169', 'O170', 'O171', 'O172', 'O173', 'O174', 'O175', 'O176', 'O177', 'O178', 'O179', 'O180', 'O181', 'O182', 'O183', 'O184', 'O185', 'O186', 'O187', 'O188', 'O189', 'O190', 'O191', 'O192', 'O193', 'O194', 'O195', 'O196', 'O197', 'O198'], 'get_xyz_where': <function get_xyz_where at 0x2c51668>, 'irr': <function irr at 0x23fe050>, 'sctypeDict': {0: <type 'numpy.bool_'>, 1: <type 'numpy.int8'>, 2: <type 'numpy.uint8'>, 3: <type 'numpy.int16'>, 4: <type 'numpy.uint16'>, 5: <type 'numpy.int32'>, 6: <type 'numpy.uint32'>, 7: <type 'numpy.int64'>, 8: <type 'numpy.uint64'>, 9: <type 'numpy.int64'>, 10: <type 'numpy.uint64'>, 11: <type 'numpy.float32'>, 12: <type 'numpy.float64'>, 13: <type 'numpy.float128'>, 14: <type 'numpy.complex64'>, 15: <type 'numpy.complex128'>, 16: <type 'numpy.complex256'>, 17: <type 'numpy.object_'>, 18: <type 'numpy.string_'>, 19: <type 'numpy.unicode_'>, 20: <type 'numpy.void'>, 21: <type 'numpy.datetime64'>, 'unicode': <type 'numpy.unicode_'>, 23: <type 'numpy.float16'>, 'cfloat': <type 'numpy.complex128'>, 'longfloat': <type 'numpy.float128'>, 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, 'unicode_': <type 'numpy.unicode_'>, 'complex': <type 'numpy.complex128'>, 'timedelta64': <type 'numpy.timedelta64'>, 'uint16': <type 'numpy.uint16'>, 'c16': <type 'numpy.complex128'>, 'float32': <type 'numpy.float32'>, 'complex256': <type 'numpy.complex256'>, 'D': <type 'numpy.complex128'>, 'H': <type 'numpy.uint16'>, 'void': <type 'numpy.void'>, 'unicode0': <type 'numpy.unicode_'>, 'L': <type 'numpy.uint64'>, 'P': <type 'numpy.uint64'>, 'half': <type 'numpy.float16'>, 'void0': <type 'numpy.void'>, 'd': <type 'numpy.float64'>, 'h': <type 'numpy.int16'>, 'l': <type 'numpy.int64'>, 'p': <type 'numpy.int64'>, 'c32': <type 'numpy.complex256'>, 22: <type 'numpy.timedelta64'>, 'O8': <type 'numpy.object_'>, 'Timedelta64': <type 'numpy.timedelta64'>, 'object0': <type 'numpy.object_'>, 'b1': <type 'numpy.bool_'>, 'float128': <type 'numpy.float128'>, 'M8': <type 'numpy.datetime64'>, 'String0': <type 'numpy.string_'>, 'float16': <type 'numpy.float16'>, 'ulonglong': <type 'numpy.uint64'>, 'i1': <type 'numpy.int8'>, 'uint32': <type 'numpy.uint32'>, '?': <type 'numpy.bool_'>, 'Void0': <type 'numpy.void'>, 'complex64': <type 'numpy.complex64'>, 'G': <type 'numpy.complex256'>, 'O': <type 'numpy.object_'>, 'UInt8': <type 'numpy.uint8'>, 'S': <type 'numpy.string_'>, 'byte': <type 'numpy.int8'>, 'UInt64': <type 'numpy.uint64'>, 'g': <type 'numpy.float128'>, 'float64': <type 'numpy.float64'>, 'ushort': <type 'numpy.uint16'>, 'float_': <type 'numpy.float64'>, 'uint': <type 'numpy.uint64'>, 'object_': <type 'numpy.object_'>, 'Float16': <type 'numpy.float16'>, 'complex_': <type 'numpy.complex128'>, 'Unicode0': <type 'numpy.unicode_'>, 'uintp': <type 'numpy.uint64'>, 'intc': <type 'numpy.int32'>, 'csingle': <type 'numpy.complex64'>, 'datetime64': <type 'numpy.datetime64'>, 'float': <type 'numpy.float64'>, 'bool8': <type 'numpy.bool_'>, 'Bool': <type 'numpy.bool_'>, 'intp': <type 'numpy.int64'>, 'uintc': <type 'numpy.uint32'>, 'bytes_': <type 'numpy.string_'>, 'u8': <type 'numpy.uint64'>, 'u4': <type 'numpy.uint32'>, 'int_': <type 'numpy.int64'>, 'cdouble': <type 'numpy.complex128'>, 'u1': <type 'numpy.uint8'>, 'complex128': <type 'numpy.complex128'>, 'u2': <type 'numpy.uint16'>, 'f8': <type 'numpy.float64'>, 'Datetime64': <type 'numpy.datetime64'>, 'ubyte': <type 'numpy.uint8'>, 'm8': <type 'numpy.timedelta64'>, 'B': <type 'numpy.uint8'>, 'uint0': <type 'numpy.uint64'>, 'F': <type 'numpy.complex64'>, 'bool_': <type 'numpy.bool_'>, 'uint8': <type 'numpy.uint8'>, 'c8': <type 'numpy.complex64'>, 'Int64': <type 'numpy.int64'>, 'Int8': <type 'numpy.int8'>, 'Complex32': <type 'numpy.complex64'>, 'V': <type 'numpy.void'>, 'int8': <type 'numpy.int8'>, 'uint64': <type 'numpy.uint64'>, 'b': <type 'numpy.int8'>, 'f': <type 'numpy.float32'>, 'double': <type 'numpy.float64'>, 'UInt32': <type 'numpy.uint32'>, 'clongdouble': <type 'numpy.complex256'>, 'str': <type 'numpy.string_'>, 'f16': <type 'numpy.float128'>, 'f2': <type 'numpy.float16'>, 'f4': <type 'numpy.float32'>, 'int32': <type 'numpy.int32'>, 'int': <type 'numpy.int64'>, 'longdouble': <type 'numpy.float128'>, 'Complex128': <type 'numpy.complex256'>, 'single': <type 'numpy.float32'>, 'string': <type 'numpy.string_'>, 'q': <type 'numpy.int64'>, 'Int16': <type 'numpy.int16'>, 'Float64': <type 'numpy.float64'>, 'longcomplex': <type 'numpy.complex256'>, 'UInt16': <type 'numpy.uint16'>, 'bool': <type 'numpy.bool_'>, 'Float32': <type 'numpy.float32'>, 'string0': <type 'numpy.string_'>, 'longlong': <type 'numpy.int64'>, 'i8': <type 'numpy.int64'>, 'int16': <type 'numpy.int16'>, 'str_': <type 'numpy.string_'>, 'I': <type 'numpy.uint32'>, 'object': <type 'numpy.object_'>, 'M': <type 'numpy.datetime64'>, 'i4': <type 'numpy.int32'>, 'singlecomplex': <type 'numpy.complex64'>, 'Q': <type 'numpy.uint64'>, 'string_': <type 'numpy.string_'>, 'U': <type 'numpy.unicode_'>, 'a': <type 'numpy.string_'>, 'short': <type 'numpy.int16'>, 'e': <type 'numpy.float16'>, 'i': <type 'numpy.int32'>, 'clongfloat': <type 'numpy.complex256'>, 'm': <type 'numpy.timedelta64'>, 'Object0': <type 'numpy.object_'>, 'int64': <type 'numpy.int64'>, 'Float128': <type 'numpy.float128'>, 'i2': <type 'numpy.int16'>, 'int0': <type 'numpy.int64'>}, 'xticks': <function xticks at 0x3195cf8>, 'hist': <function hist at 0x3197230>, 'bivariate_normal': <function bivariate_normal at 0x2c515f0>, 'NINF': -inf, 'min_scalar_type': <built-in function min_scalar_type>, 'geometric': <built-in method geometric of mtrand.RandomState object at 0x7f399f841690>, 'normTarget': array([[-0.25,  0.26,  0.02, ...,  0.44,  0.51,  0.48],\n       [-0.33,  0.12, -0.02, ...,  0.7 ,  0.52,  0.05],\n       [ 0.14, -0.13,  0.02, ...,  0.43,  0.39,  0.64],\n       ..., \n       [ 1.4 ,  0.26,  0.09, ...,  1.32,  0.72,  0.22],\n       [-0.54,  0.3 , -0.04, ..., -0.37, -0.02, -0.14],\n       [ 0.95,  0.18,  0.17, ...,  0.12,  0.37,  0.05]]), 'sort_complex': <function sort_complex at 0x236c7d0>, 'nested_iters': <built-in function nested_iters>, 'concatenate': <built-in function concatenate>, 'ERR_DEFAULT2': 521, '_i48': u'yoda = normTarget.reshape((200*198,1))', '_i49': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1]+1,0))', 'vdot': <built-in function vdot>, 'bincount': <built-in function bincount>, 'num2epoch': <function num2epoch at 0x307faa0>, '_i46': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-2,0))', 'sctypes': {'int': [<type 'numpy.int8'>, <type 'numpy.int16'>, <type 'numpy.int32'>, <type 'numpy.int64'>], 'float': [<type 'numpy.float16'>, <type 'numpy.float32'>, <type 'numpy.float64'>, <type 'numpy.float128'>], 'uint': [<type 'numpy.uint8'>, <type 'numpy.uint16'>, <type 'numpy.uint32'>, <type 'numpy.uint64'>], 'complex': [<type 'numpy.complex64'>, <type 'numpy.complex128'>, <type 'numpy.complex256'>], 'others': [<type 'bool'>, <type 'object'>, <type 'str'>, <type 'unicode'>, <type 'numpy.void'>]}, 'transpose': <function transpose at 0x21d19b0>, 'add_newdocs': <module 'numpy.add_newdocs' from '/usr/local/lib/python2.7/dist-packages/numpy/add_newdocs.pyc'>, '_i42': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1))', '_i41': u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1)))', 'detrend_linear': <function detrend_linear at 0x2c4f848>, 'corrcoef': <function corrcoef at 0x236d0c8>, 'fromregex': <function fromregex at 0x23fb488>, 'vector_lengths': <function vector_lengths at 0x2c53b90>, 'vectorize': <class 'numpy.lib.function_base.vectorize'>, 'set_printoptions': <function set_printoptions at 0x21dac08>, '_i43': u'yoda.shape', '_i44': u'normTarget.shape', 'trim_zeros': <function trim_zeros at 0x236c848>, 'WEEKLY': 2, 'cos': <ufunc 'cos'>, '_37': (array([   3.,   11.,   42.,  112.,   26.,    4.,    0.,    0.,    0.,    2.]), array([-2.12 , -1.478, -0.836, -0.194,  0.448,  1.09 ,  1.732,  2.374,\n        3.016,  3.658,  4.3  ]), <a list of 10 Patch objects>), 'vlines': <function vlines at 0x3197de8>, 'detrend': <function detrend at 0x2c4f668>, 'arccosh': <ufunc 'arccosh'>, 'DateFormatter': <class 'matplotlib.dates.DateFormatter'>, 'equal': <ufunc 'equal'>, 'display': <function display at 0x1d4c848>, '_i39': u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1))', 'cumprod': <function cumprod at 0x21da758>, 'LinAlgError': <class 'numpy.linalg.linalg.LinAlgError'>, 'float_': <type 'numpy.float64'>, 'deprecate': <function deprecate at 0x23692a8>, 'vander': <function vander at 0x230d938>, '_i31': u'target.shape', 'geterrobj': <built-in function geterrobj>, '_i33': u'normTarget.shape', 'interactive': <function interactive at 0x2a006e0>, '_i35': u'plot(normTarget[:,0])', 'clf': <function clf at 0x3194cf8>, '_i37': u'hist(normTarget[:,197])', 'prepca': <function prepca at 0x2c511b8>, 'wald': <built-in method wald of mtrand.RandomState object at 0x7f399f841690>, 'fromiter': <built-in function fromiter>, 'prctile_rank': <function prctile_rank at 0x2c51488>, '_i29': u'lastObserved = trainOutput(:,-1,:)', 'cm': <module 'matplotlib.cm' from '/usr/local/lib/python2.7/dist-packages/matplotlib/cm.pyc'>, 'tril': <function tril at 0x230d848>, 'poly': <function poly at 0x2377b90>, 'loglog': <function loglog at 0x3197410>, '_i100': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'bitwise_or': <ufunc 'bitwise_or'>, '_i102': u'len(predicted_probs)', '_i103': u'len(predicted_probs[0])', 'figtext': <function figtext at 0x3195050>, 'norm_flat': <function norm_flat at 0x2c51f50>, '_i3': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', '_i107': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', 'tricontourf': <function tricontourf at 0x3197c80>, 'diff': <function diff at 0x236c5f0>, 'cohere': <function cohere at 0x3196c80>, 'normpdf': <function normpdf at 0x2c4fed8>, 'AutoLocator': <class 'matplotlib.ticker.AutoLocator'>, 'iterable': <function iterable at 0x236c1b8>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x2728f10>, 'get_include': <function get_include at 0x2369140>, 'pv': <function pv at 0x23fbe60>, 'tensordot': <function tensordot at 0x21c2b18>, 'piecewise': <function piecewise at 0x236c410>, 'rfftn': <function rfftn at 0x2409410>, 'invert': <ufunc 'invert'>, 'UFUNC_PYVALS_NAME': 'UFUNC_PYVALS', 'fftpack_lite': <module 'numpy.fft.fftpack_lite' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.so'>, 'sinc': <function sinc at 0x236d578>, 'numRows': 55, 'SHIFT_INVALID': 9, 'ubyte': <type 'numpy.uint8'>, 'axis': <function axis at 0x31959b0>, '_i47': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]+1,0))', 'matrix_rank': <function matrix_rank at 0x238caa0>, 'degrees': <ufunc 'degrees'>, 'pi': 3.141592653589793, 'numpy': <module 'numpy' from '/usr/local/lib/python2.7/dist-packages/numpy/__init__.pyc'>, '__doc__': 'Automatically created module for IPython interactive environment', 'empty': <built-in function empty>, 'fig': <matplotlib.figure.Figure object at 0xaa97ad0>, 'find_common_type': <function find_common_type at 0x21bfe60>, 'random_sample': <built-in method random_sample of mtrand.RandomState object at 0x7f399f841690>, 'longest_ones': <function longest_ones at 0x2c51140>, 'irfft2': <function irfft2 at 0x2409578>, 'arcsin': <ufunc 'arcsin'>, 'sctypeNA': {<type 'numpy.float16'>: 'Float16', <type 'numpy.int16'>: 'Int16', 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, <type 'numpy.timedelta64'>: 'Timedelta64', <type 'numpy.uint8'>: 'UInt8', 'c16': 'Complex64', <type 'numpy.datetime64'>: 'Datetime64', 'D': 'Complex64', <type 'numpy.int8'>: 'Int8', 'H': 'UInt16', 'L': 'UInt64', <type 'numpy.void'>: 'Void0', <type 'numpy.bool_'>: 'Bool', 'd': 'Float64', 'h': 'Int16', 'l': 'Int64', <type 'numpy.unicode_'>: 'Unicode0', 'c32': 'Complex128', <type 'numpy.string_'>: 'String0', 'Timedelta64': <type 'numpy.timedelta64'>, 'b1': 'Bool', 'M8': 'Datetime64', 'String0': <type 'numpy.string_'>, <type 'numpy.object_'>: 'Object0', 'I': 'UInt32', '?': 'Bool', 'Void0': <type 'numpy.void'>, <type 'numpy.complex256'>: 'Complex128', 'G': 'Complex128', 'O': 'Object0', 'UInt8': <type 'numpy.uint8'>, 'S': 'String0', <type 'numpy.complex128'>: 'Complex64', 'UInt64': <type 'numpy.uint64'>, 'g': 'Float128', <type 'numpy.complex64'>: 'Complex32', 'Float16': <type 'numpy.float16'>, <type 'numpy.float128'>: 'Float128', 'Bool': <type 'numpy.bool_'>, 'u8': <type 'numpy.uint64'>, <type 'numpy.float64'>: 'Float64', 'u4': <type 'numpy.uint32'>, 'Unicode0': <type 'numpy.unicode_'>, 'u1': <type 'numpy.uint8'>, 'u2': <type 'numpy.uint16'>, 'Datetime64': <type 'numpy.datetime64'>, 'Int8': <type 'numpy.int8'>, <type 'numpy.float32'>: 'Float32', 'B': 'UInt8', 'F': 'Complex32', 'c8': 'Complex32', 'Int64': <type 'numpy.int64'>, 'Complex32': <type 'numpy.complex64'>, 'V': 'Void0', <type 'numpy.uint64'>: 'UInt64', 'b': 'Int8', 'f': 'Float32', 'm8': 'Timedelta64', <type 'numpy.int64'>: 'Int64', 'f16': 'Float128', 'UInt32': <type 'numpy.uint32'>, 'f2': 'Float16', 'f4': 'Float32', 'f8': 'Float64', 'Complex128': <type 'numpy.complex256'>, <type 'numpy.uint64'>: 'UInt64', 'Object0': <type 'numpy.object_'>, 'Int16': <type 'numpy.int16'>, <type 'numpy.int64'>: 'Int64', 'Float64': <type 'numpy.float64'>, 'UInt16': <type 'numpy.uint16'>, 'Float32': <type 'numpy.float32'>, 'i8': <type 'numpy.int64'>, <type 'numpy.uint32'>: 'UInt32', 'i1': <type 'numpy.int8'>, 'i2': <type 'numpy.int16'>, 'M': 'Datetime64', 'i4': <type 'numpy.int32'>, 'Q': 'UInt64', 'U': 'Unicode0', <type 'numpy.int32'>: 'Int32', 'e': 'Float16', 'i': 'Int32', 'm': 'Timedelta64', 'q': 'Int64', <type 'numpy.uint16'>: 'UInt16', 'Float128': <type 'numpy.float128'>}, 'imag': <function imag at 0x23016e0>, 'sctype2char': <function sctype2char at 0x21bf1b8>, 'singlecomplex': <type 'numpy.complex64'>, 'SHIFT_DIVIDEBYZERO': 0, 'sort': <function sort at 0x21d1a28>, 'standard_t': <built-in method standard_t of mtrand.RandomState object at 0x7f399f841690>, '_i40': u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1)))', 'csv2rec': <function csv2rec at 0x2c527d0>, 'MachAr': <class 'numpy.core.machar.MachAr'>, 'apply_along_axis': <function apply_along_axis at 0x2374aa0>, 'new_figure_manager': <function new_figure_manager at 0x3186f50>, 'tight_layout': <function tight_layout at 0x3195848>, 'array_repr': <function array_repr at 0x21db398>, '_i105': u'pred = predicted_probs + lastObserved[200:,stock]', 'reciprocal': <ufunc 'reciprocal'>, 'frompyfunc': <built-in function frompyfunc>, 'rot90': <function rot90 at 0x230d5f0>, 'dstack': <function dstack at 0x2374c80>, 'float64': <type 'numpy.float64'>, 'traincv': array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True, False, False, False, False, False, False,\n       False, False], dtype=bool), 'Annotation': <class 'matplotlib.text.Annotation'>, 'colorbar': <function colorbar at 0x31962a8>, 'cast': {<type 'numpy.float16'>: <function <lambda> at 0x21bf230>, <type 'numpy.string_'>: <function <lambda> at 0x21bf2a8>, <type 'numpy.float128'>: <function <lambda> at 0x21bf320>, <type 'numpy.uint64'>: <function <lambda> at 0x21bf398>, <type 'numpy.int16'>: <function <lambda> at 0x21bf410>, <type 'numpy.timedelta64'>: <function <lambda> at 0x21bf488>, <type 'numpy.object_'>: <function <lambda> at 0x21bf500>, <type 'numpy.float64'>: <function <lambda> at 0x21bf578>, <type 'numpy.int64'>: <function <lambda> at 0x21bf5f0>, <type 'numpy.uint8'>: <function <lambda> at 0x21bf668>, <type 'numpy.datetime64'>: <function <lambda> at 0x21bf6e0>, <type 'numpy.complex256'>: <function <lambda> at 0x21bf758>, <type 'numpy.float32'>: <function <lambda> at 0x21bf7d0>, <type 'numpy.uint32'>: <function <lambda> at 0x21bf848>, <type 'numpy.int8'>: <function <lambda> at 0x21bf8c0>, <type 'numpy.void'>: <function <lambda> at 0x21bf938>, <type 'numpy.complex128'>: <function <lambda> at 0x21bf9b0>, <type 'numpy.uint64'>: <function <lambda> at 0x21bfa28>, <type 'numpy.int32'>: <function <lambda> at 0x21bfaa0>, <type 'numpy.bool_'>: <function <lambda> at 0x21bfb18>, <type 'numpy.unicode_'>: <function <lambda> at 0x21bfb90>, <type 'numpy.complex64'>: <function <lambda> at 0x21bfc08>, <type 'numpy.int64'>: <function <lambda> at 0x21bfc80>, <type 'numpy.uint16'>: <function <lambda> at 0x21bfcf8>}, '_i94': u'yoda = X.reshape((X.shape[0],1))', 'gumbel': <built-in method gumbel of mtrand.RandomState object at 0x7f399f841690>, 'rfft2': <function rfft2 at 0x2409488>, 'eig': <function eig at 0x238c8c0>, 'packbits': <built-in function packbits>, 'issctype': <function issctype at 0x21b8de8>, 'mgrid': <numpy.lib.index_tricks.nd_grid object at 0x236f910>, 'vonmises': <built-in method vonmises of mtrand.RandomState object at 0x7f399f841690>, 'ushort': <type 'numpy.uint16'>, 'normTarget_vector': array([[-0.25],\n       [ 0.26],\n       [ 0.02],\n       ..., \n       [ 0.12],\n       [ 0.37],\n       [ 0.05]]), 'Polygon': <class 'matplotlib.patches.Polygon'>, 'helper': <module 'numpy.fft.helper' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/helper.pyc'>, 'empty_like': <built-in function empty_like>, '_75': (200,), '_74': array([False, False, False, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), '_77': array([[[ 0.      ,  0.      ,  0.      , ...,  0.160672,  0.054283,\n          0.060093],\n        [ 1.61    ,  0.12    ,  0.12    , ...,  0.246306,  0.448241,\n          0.377197],\n        [ 1.12    ,  0.31    ,  0.12    , ...,  0.281271,  0.484713,\n          0.431599],\n        ..., \n        [ 0.9     ,  0.19    ,  0.07    , ...,  0.119027,  0.084617,\n          0.074685],\n        [ 0.87    ,  0.22    ,  0.08    , ...,  0.122028,  0.058538,\n          0.080691],\n        [ 0.83    ,  0.25    ,  0.08    , ...,  0.125018,  0.043205,\n          0.088569]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.405808,  0.188892,\n          0.209284],\n        [ 0.95    , -0.18    ,  0.15    , ...,  0.42738 ,  0.348119,\n          0.34322 ],\n        [ 1.04    , -0.18    ,  0.15    , ...,  0.463135,  0.439758,\n          0.449271],\n        ..., \n        [ 0.87    , -0.01    ,  0.1     , ...,  0.447247,  0.132313,\n          0.208433],\n        [ 0.83    ,  0.      ,  0.05    , ...,  0.445714,  0.153232,\n          0.138243],\n        [ 0.97    , -0.05    ,  0.05    , ...,  0.445714,  0.155649,\n          0.138243]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.934708,  0.084538,\n          0.154596],\n        [ 2.75    ,  0.25    ,  0.      , ...,  0.859673,  0.675959,\n          0.553122],\n        [ 2.22    ,  0.24    ,  0.      , ...,  0.800801,  0.754047,\n          0.652951],\n        ..., \n        [ 6.09    , -0.13    ,  0.      , ...,  0.717239,  0.111535,\n          0.55109 ],\n        [ 6.22    , -0.13    ,  0.      , ...,  0.712795,  0.116218,\n          0.388987],\n        [ 5.75    , -0.17    ,  0.      , ...,  0.715292,  0.152665,\n          0.252609]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.199729,  0.051769,\n          0.117898],\n        [-3.29    ,  0.04    ,  0.24    , ...,  0.349317,  0.77501 ,\n          0.659621],\n        [-3.53    ,  0.06    ,  0.37    , ...,  0.460716,  1.013778,\n          0.894228],\n        ..., \n        [-2.21    ,  1.33    ,  0.5     , ...,  0.221407,  0.051251,\n          0.160312],\n        [-2.25    ,  1.27    ,  0.54    , ...,  0.203557,  0.054283,\n          0.14087 ],\n        [-2.42    ,  1.27    ,  0.53    , ...,  0.185629,  0.059889,\n          0.054874]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.52827 ,  0.128219,\n          0.104881],\n        [ 0.17    , -0.06    ,  0.      , ...,  0.520413,  0.180665,\n          0.150702],\n        [ 0.59    , -0.12    , -0.06    , ...,  0.520859,  0.288167,\n          0.243676],\n        ..., \n        [ 0.97    , -0.24    , -0.08    , ...,  0.296868,  0.023381,\n          0.264344],\n        [ 0.82    , -0.24    , -0.08    , ...,  0.297405,  0.037417,\n          0.211529],\n        [ 0.97    , -0.18    , -0.04    , ...,  0.298542,  0.037238,\n          0.132077]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.31634 ,  0.082624,\n          0.108628],\n        [-0.71    ,  0.26    ,  0.74    , ...,  0.307045,  0.20775 ,\n          0.205129],\n        [-1.06    ,  0.19    ,  0.74    , ...,  0.31471 ,  0.277897,\n          0.274672],\n        ..., \n        [-1.04    , -0.08    ,  0.12    , ...,  0.184709,  0.06532 ,  0.16    ],\n        [-0.95    , -0.19    ,  0.12    , ...,  0.178122,  0.028284,\n          0.152315],\n        [-0.84    , -0.18    ,  0.12    , ...,  0.173413,  0.054283,\n          0.123063]]]), 'einsum': <built-in function einsum>, '_71': sklearn.cross_validation.KFold(n=200, n_folds=63), '_70': 200, 'signbit': <ufunc 'signbit'>, 'cond': <function cond at 0x238ca28>, 'chisquare': <built-in method chisquare of mtrand.RandomState object at 0x7f399f841690>, 'conj': <ufunc 'conjugate'>, 'asmatrix': <function asmatrix at 0x236dc80>, 'floating': <type 'numpy.floating'>, 'flatiter': <type 'numpy.flatiter'>, 'bitwise_xor': <ufunc 'bitwise_xor'>, 'WeekdayLocator': <class 'matplotlib.dates.WeekdayLocator'>, '_34': (200, 198), 'fabs': <ufunc 'fabs'>, 'Locator': <class 'matplotlib.ticker.Locator'>, 'generic': <type 'numpy.generic'>, 'reshape': <function reshape at 0x21d1758>, 'to': 'lanemcintosh@gmail.com', 'NaN': nan, 'cross': <function cross at 0x21c2cf8>, 'sqrt': <ufunc 'sqrt'>, 'show_config': <function show at 0x20f9b18>, 'longcomplex': <type 'numpy.complex256'>, 'poly_between': <function poly_between at 0x2c53938>, 'pad': <function pad at 0x23fec08>, 'split': <function split at 0x2374de8>, 'getp': <function getp at 0x2a9d1b8>, 'floor_divide': <ufunc 'floor_divide'>, '__version__': '1.7.1', 'format_parser': <class numpy.core.records.format_parser at 0x226ebb0>, 'nextafter': <ufunc 'nextafter'>, 'exponential': <built-in method exponential of mtrand.RandomState object at 0x7f399f841690>, 'dedent': <function dedent at 0x2994938>, 'polyval': <function polyval at 0x238cf50>, 'infty': inf, 'flipud': <function flipud at 0x230d578>, 'i0': <function i0 at 0x236d488>, 'permutation': <built-in method permutation of mtrand.RandomState object at 0x7f399f841690>, 'disconnect': <function disconnect at 0x3194c80>, 'iscomplexobj': <function iscomplexobj at 0x2301848>, 'sys': <module 'sys' (built-in)>, 'average': <function average at 0x236c320>, '_exit_code': 0, 'setdiff1d': <function setdiff1d at 0x236c140>, 'psd': <function psd at 0x31976e0>, 'mafromtxt': <function mafromtxt at 0x23fb5f0>, 'bartlett': <function bartlett at 0x236d1b8>, 'polydiv': <function polydiv at 0x238d1b8>, 'numStocks': 198, 'drange': <function drange at 0x307d140>, 'safe_eval': <function safe_eval at 0x2369938>, 'ifft': <function ifft at 0x23fee60>, 'cov': <function cov at 0x236cde8>, 'greater_equal': <ufunc 'greater_equal'>, 'i': 243, 'Tester': <class 'numpy.testing.nosetester.NoseTester'>, 'trapz': <function trapz at 0x236d7d0>, 'PINF': inf, 'rec_drop_fields': <function rec_drop_fields at 0x2c52500>, 'recfromtxt': <function recfromtxt at 0x23fb668>, 'setp': <function setp at 0x31948c0>, 'In': ['', u\"get_ipython().magic(u'cd /home/lane/Kaggle/03\\\\\\\\ Predicting\\\\\\\\ Stock\\\\\\\\ Prices/')\", u\"get_ipython().system(u'ls -F --color ')\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(train), n_folds=63, indices=False)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(trainOutput), n_folds=63, indices=False)', u'len(trainOutput)', u'len(targets)', u'len(target)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'trainInput.shape', u'trainOutput.shape', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:197] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:198] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'trainInput[509,54,243]', u'trainInput[509,54,244]', u'trainInput[509,54,243]', u'fullInput[509,54,244+197]', u'train            = np.zeros((510,55,244+198))\\ntrain[:,:,0:198] = trainOutput\\ntrain[:,:,198:]  = trainInput', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(target[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'trainOutput.shape', u'len(trainOutput[0])', u'target.shape', u'target.shape', u'trainInput.shape', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput(:,-1,:)', u'lastObserved = trainOutput[:,-1,:]\\nlastObserved.shape', u'target.shape', u'normTarget   = target - lastObserved[:target.shape[0],:]', u'normTarget.shape', u'target.shape', u'plot(normTarget[:,0])', u'plot(normTarget[:,197])', u'hist(normTarget[:,197])', u'hist(normTarget)', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1)))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1)))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1))', u'yoda.shape', u'normTarget.shape', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-2,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((200*198,1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True)', u\"yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,4)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,6)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nyaxis('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',norm=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',normed=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\nderiv.shape', u'normTarget.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'len(target)', u'cv', u'for i in cv:\\n    print i', u'for i,j in cv:\\n    print i,j', u'traincv', u'traincv.shape', u'testcv.shape', u'train[traincv]', u'train.shape', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201,:]\\ntest  = X[201:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201]\\ntest  = X[201:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'train.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:200]\\ntest  = X[200:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'y.shape', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'train.shape', u'test.shape', u'yoda = X.reshape((X.shape[0],1))', u'yoda.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock].reshape((deriv.shape[0],1))\\ny     = normTarget[:,stock]\\ntrain = X[:200,:]\\ntest  = X[200:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'predicted_probs.shape', u'len(predicted_probs)', u'len(predicted_probs[0])', u'lastObserved[:,stock].shape', u'pred = predicted_probs + lastObserved[200:,stock]', u'pred = predicted_probs + lastObserved[200:,stock]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape[2]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'numStocks', u'type(predicted_probs)', u'yoda = np.asarray(predicted_probs)\\nyoda.shape', u'yoda = np.asarray(predicted_probs)\\nluke = np.zeros((310,198))\\nluke[:,0] = yoda', u'pred[0]', u'## Fit Random Forest and generate predictions\\nnumStocks   = trainOutput.shape[2]\\nperformance = []\\npred        = np.zeros((310,numStocks))\\nfor stock in xrange(numStocks):\\n    \\n    # get stock-specific features\\n    X     = deriv[:,stock].reshape((deriv.shape[0],1))\\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n\\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n\\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import smtplib', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import pybrain', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random\\nimport smtplib\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=500, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=25, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'sheet.shape', u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection'], 'y': array([-0.25, -0.33,  0.14,  0.64, -0.07, -0.22, -0.67, -0.86,  0.3 ,\n        0.29,  0.04,  0.97,  0.36,  0.51, -0.49, -0.09,  0.53, -1.21,\n        2.27,  2.77, -0.52,  0.  ,  0.88,  0.29,  0.46,  0.9 ,  0.05,\n        0.33, -2.03,  0.43,  0.68,  0.56, -0.69, -1.95,  0.05, -0.7 ,\n       -0.47, -0.29,  0.68,  0.19,  0.87, -0.02,  0.38,  0.21, -0.36,\n        0.  , -0.55,  0.89, -0.14, -0.24, -2.89, -0.2 , -1.47, -1.58,\n       -0.86, -0.56, -0.13, -0.27, -0.07,  0.16, -1.16, -0.25,  0.65,\n        0.34,  0.34,  3.43,  0.41,  0.05,  0.1 ,  0.48,  0.1 , -0.63,\n       -2.05,  0.85,  0.57,  0.23,  0.2 ,  0.13,  0.88, -1.5 , -0.65,\n        0.09,  0.95, -0.72, -2.65, -0.09,  0.04,  0.36,  2.23, -0.33,\n       -0.02, -0.05,  1.37,  0.86,  0.04,  2.78, -0.76, -4.44, -0.15,\n        0.28, -0.99,  0.66,  0.19, -1.3 , -1.45, -0.52, -0.95,  0.27,\n       -3.92,  0.46, -0.5 , -0.17,  1.65,  3.24,  1.18,  0.55,  0.23,\n       -0.03, -0.43, -0.51,  0.08,  0.04, -1.49,  1.15, -0.77,  0.  ,\n       -0.26,  1.78,  0.99, -0.95, -0.76, -0.41, -0.14,  1.34,  0.15,\n       -1.35, -0.18, -0.21,  0.23, -1.52,  1.17, -0.25,  0.33,  0.02,\n        0.29,  0.74, -0.16, -0.06, -2.7 , -0.11,  1.05, -0.31, -0.95,\n       -0.9 ,  2.19,  0.09, -0.76, -0.57, -0.85,  2.14,  1.62,  0.05,\n       -0.4 ,  0.23,  2.3 ,  2.  ,  0.58, -0.37, -0.43,  0.01, -0.62,\n       -0.58, -0.52,  1.23,  0.57,  0.49, -0.02,  0.63, -0.1 ,  0.15,\n        0.96, -0.38,  0.73, -0.93,  0.1 ,  1.15,  0.39,  0.18, -3.55,\n       -0.53,  0.27,  0.05, -0.15, -1.86,  0.25,  0.08,  0.47,  1.4 ,\n       -0.54,  0.95]), 'grid': <function grid at 0x3198050>, 'trainOutput': array([[[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [ 0.97,  0.45,  0.16, ...,  1.37,  1.3 ,  0.29],\n        [ 1.69,  0.51,  0.  , ...,  1.62,  1.81,  0.48],\n        ..., \n        [ 2.79,  0.77,  0.08, ...,  3.17,  3.08,  1.61],\n        [ 2.74,  0.73,  0.12, ...,  3.25,  3.03,  1.59],\n        [ 2.78,  0.77,  0.1 , ...,  3.25,  3.05,  1.55]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-2.14,  0.  , -0.2 , ..., -0.5 ,  0.38,  0.43],\n        [-2.23, -0.07, -0.28, ..., -0.27, -0.02,  0.21],\n        ..., \n        [-4.72,  0.09, -0.2 , ...,  0.61, -0.54,  0.5 ],\n        [-4.51,  0.1 , -0.24, ...,  0.63, -0.52,  0.41],\n        [-4.62,  0.06, -0.22, ...,  0.52, -0.56,  0.33]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [ 0.52,  0.13,  0.12, ...,  0.43,  0.45,  0.16],\n        [ 0.48,  0.13,  0.1 , ...,  0.27,  0.58,  0.25],\n        ..., \n        [ 0.04,  0.12,  0.2 , ..., -0.4 ,  0.96,  1.03],\n        [ 0.1 ,  0.11,  0.2 , ..., -0.45,  0.93,  1.03],\n        [ 0.02,  0.13,  0.18, ..., -0.47,  0.91,  0.97]],\n\n       ..., \n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-0.28, -0.18,  0.08, ..., -0.98, -0.21,  0.07],\n        [-0.13, -0.23,  0.08, ..., -1.66, -0.54,  0.24],\n        ..., \n        [-0.66,  0.12,  0.12, ..., -2.06, -1.19,  0.3 ],\n        [-0.6 ,  0.21,  0.12, ..., -2.06, -1.16,  0.3 ],\n        [-0.33,  0.23,  0.12, ..., -1.81, -1.01,  0.26]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-1.07, -0.07,  0.  , ..., -0.7 , -0.2 , -0.2 ],\n        [-0.99, -0.01,  0.04, ..., -0.6 ,  0.25,  0.1 ],\n        ..., \n        [-0.99,  0.11,  0.  , ..., -0.08,  0.88,  1.29],\n        [-1.13,  0.07,  0.  , ..., -0.18,  0.9 ,  1.17],\n        [-1.13,  0.06,  0.  , ..., -0.23,  0.92,  1.17]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-6.56, -0.36,  0.04, ..., -1.78, -1.83, -1.03],\n        [-5.8 , -0.36,  0.04, ..., -1.23, -1.33, -0.73],\n        ..., \n        [-8.24, -0.79,  0.04, ..., -2.59, -2.34, -1.49],\n        [-8.3 , -0.78,  0.04, ..., -2.61, -2.36, -1.47],\n        [-7.99, -0.78,  0.01, ..., -2.57, -2.34, -1.41]]]), 'standard_normal': <built-in method standard_normal of mtrand.RandomState object at 0x7f399f841690>, 'RankWarning': <class 'numpy.lib.polynomial.RankWarning'>, 'ascontiguousarray': <function ascontiguousarray at 0x21c2668>, '_89': (200,), 'load': <function load at 0x23f9aa0>, '_i4': u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", 'hexbin': <function hexbin at 0x31971b8>, 'Arrow': <class 'matplotlib.patches.Arrow'>, 'less': <ufunc 'less'>, 'putmask': <built-in function putmask>, 'UFUNC_BUFSIZE_DEFAULT': 8192, 'get_state': <built-in method get_state of mtrand.RandomState object at 0x7f399f841690>, 'NAN': nan, 'test_transformed': array([[ -2.90000000e-01,   3.95000000e+01,   5.65000000e+01, ...,\n          8.48180000e-02,   1.46046000e-01,   2.20786000e-01],\n       [  3.80000000e-01,   2.80000000e+01,   3.50000000e+01, ...,\n          6.08164000e-01,   7.14327000e-01,   4.69965000e-01],\n       [  2.00000000e-02,   1.30250000e+02,   4.83750000e+01, ...,\n          9.14371000e-01,   8.75696000e-01,   1.20665000e-01],\n       ..., \n       [  2.70000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          1.78577000e-01,   7.33330000e-02,   8.55570000e-02],\n       [  0.00000000e+00,   4.14500000e+02,   2.80000000e+01, ...,\n          6.20088000e-01,   6.15484000e-01,   7.63330000e-02],\n       [  3.10000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          6.87380000e-02,  -4.30400000e-03,   4.11582000e-01]]), 'typeDict': {0: <type 'numpy.bool_'>, 1: <type 'numpy.int8'>, 2: <type 'numpy.uint8'>, 3: <type 'numpy.int16'>, 4: <type 'numpy.uint16'>, 5: <type 'numpy.int32'>, 6: <type 'numpy.uint32'>, 7: <type 'numpy.int64'>, 8: <type 'numpy.uint64'>, 9: <type 'numpy.int64'>, 10: <type 'numpy.uint64'>, 11: <type 'numpy.float32'>, 12: <type 'numpy.float64'>, 13: <type 'numpy.float128'>, 14: <type 'numpy.complex64'>, 15: <type 'numpy.complex128'>, 16: <type 'numpy.complex256'>, 17: <type 'numpy.object_'>, 18: <type 'numpy.string_'>, 19: <type 'numpy.unicode_'>, 20: <type 'numpy.void'>, 21: <type 'numpy.datetime64'>, 'unicode': <type 'numpy.unicode_'>, 23: <type 'numpy.float16'>, 'cfloat': <type 'numpy.complex128'>, 'longfloat': <type 'numpy.float128'>, 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, 'unicode_': <type 'numpy.unicode_'>, 'complex': <type 'numpy.complex128'>, 'timedelta64': <type 'numpy.timedelta64'>, 'uint16': <type 'numpy.uint16'>, 'c16': <type 'numpy.complex128'>, 'float32': <type 'numpy.float32'>, 'complex256': <type 'numpy.complex256'>, 'D': <type 'numpy.complex128'>, 'H': <type 'numpy.uint16'>, 'void': <type 'numpy.void'>, 'unicode0': <type 'numpy.unicode_'>, 'L': <type 'numpy.uint64'>, 'P': <type 'numpy.uint64'>, 'half': <type 'numpy.float16'>, 'void0': <type 'numpy.void'>, 'd': <type 'numpy.float64'>, 'h': <type 'numpy.int16'>, 'l': <type 'numpy.int64'>, 'p': <type 'numpy.int64'>, 'c32': <type 'numpy.complex256'>, 22: <type 'numpy.timedelta64'>, 'O8': <type 'numpy.object_'>, 'Timedelta64': <type 'numpy.timedelta64'>, 'object0': <type 'numpy.object_'>, 'b1': <type 'numpy.bool_'>, 'float128': <type 'numpy.float128'>, 'M8': <type 'numpy.datetime64'>, 'String0': <type 'numpy.string_'>, 'float16': <type 'numpy.float16'>, 'ulonglong': <type 'numpy.uint64'>, 'i1': <type 'numpy.int8'>, 'uint32': <type 'numpy.uint32'>, '?': <type 'numpy.bool_'>, 'Void0': <type 'numpy.void'>, 'complex64': <type 'numpy.complex64'>, 'G': <type 'numpy.complex256'>, 'O': <type 'numpy.object_'>, 'UInt8': <type 'numpy.uint8'>, 'S': <type 'numpy.string_'>, 'byte': <type 'numpy.int8'>, 'UInt64': <type 'numpy.uint64'>, 'g': <type 'numpy.float128'>, 'float64': <type 'numpy.float64'>, 'ushort': <type 'numpy.uint16'>, 'float_': <type 'numpy.float64'>, 'uint': <type 'numpy.uint64'>, 'object_': <type 'numpy.object_'>, 'Float16': <type 'numpy.float16'>, 'complex_': <type 'numpy.complex128'>, 'Unicode0': <type 'numpy.unicode_'>, 'uintp': <type 'numpy.uint64'>, 'intc': <type 'numpy.int32'>, 'csingle': <type 'numpy.complex64'>, 'datetime64': <type 'numpy.datetime64'>, 'float': <type 'numpy.float64'>, 'bool8': <type 'numpy.bool_'>, 'Bool': <type 'numpy.bool_'>, 'intp': <type 'numpy.int64'>, 'uintc': <type 'numpy.uint32'>, 'bytes_': <type 'numpy.string_'>, 'u8': <type 'numpy.uint64'>, 'u4': <type 'numpy.uint32'>, 'int_': <type 'numpy.int64'>, 'cdouble': <type 'numpy.complex128'>, 'u1': <type 'numpy.uint8'>, 'complex128': <type 'numpy.complex128'>, 'u2': <type 'numpy.uint16'>, 'f8': <type 'numpy.float64'>, 'Datetime64': <type 'numpy.datetime64'>, 'ubyte': <type 'numpy.uint8'>, 'm8': <type 'numpy.timedelta64'>, 'B': <type 'numpy.uint8'>, 'uint0': <type 'numpy.uint64'>, 'F': <type 'numpy.complex64'>, 'bool_': <type 'numpy.bool_'>, 'uint8': <type 'numpy.uint8'>, 'c8': <type 'numpy.complex64'>, 'Int64': <type 'numpy.int64'>, 'Int8': <type 'numpy.int8'>, 'Complex32': <type 'numpy.complex64'>, 'V': <type 'numpy.void'>, 'int8': <type 'numpy.int8'>, 'uint64': <type 'numpy.uint64'>, 'b': <type 'numpy.int8'>, 'f': <type 'numpy.float32'>, 'double': <type 'numpy.float64'>, 'UInt32': <type 'numpy.uint32'>, 'clongdouble': <type 'numpy.complex256'>, 'str': <type 'numpy.string_'>, 'f16': <type 'numpy.float128'>, 'f2': <type 'numpy.float16'>, 'f4': <type 'numpy.float32'>, 'int32': <type 'numpy.int32'>, 'int': <type 'numpy.int64'>, 'longdouble': <type 'numpy.float128'>, 'Complex128': <type 'numpy.complex256'>, 'single': <type 'numpy.float32'>, 'string': <type 'numpy.string_'>, 'q': <type 'numpy.int64'>, 'Int16': <type 'numpy.int16'>, 'Float64': <type 'numpy.float64'>, 'longcomplex': <type 'numpy.complex256'>, 'UInt16': <type 'numpy.uint16'>, 'bool': <type 'numpy.bool_'>, 'Float32': <type 'numpy.float32'>, 'string0': <type 'numpy.string_'>, 'longlong': <type 'numpy.int64'>, 'i8': <type 'numpy.int64'>, 'int16': <type 'numpy.int16'>, 'str_': <type 'numpy.string_'>, 'I': <type 'numpy.uint32'>, 'object': <type 'numpy.object_'>, 'M': <type 'numpy.datetime64'>, 'i4': <type 'numpy.int32'>, 'singlecomplex': <type 'numpy.complex64'>, 'Q': <type 'numpy.uint64'>, 'string_': <type 'numpy.string_'>, 'U': <type 'numpy.unicode_'>, 'a': <type 'numpy.string_'>, 'short': <type 'numpy.int16'>, 'e': <type 'numpy.float16'>, 'i': <type 'numpy.int32'>, 'clongfloat': <type 'numpy.complex256'>, 'm': <type 'numpy.timedelta64'>, 'Object0': <type 'numpy.object_'>, 'int64': <type 'numpy.int64'>, 'Float128': <type 'numpy.float128'>, 'i2': <type 'numpy.int16'>, 'int0': <type 'numpy.int64'>}, 'shape': <function shape at 0x21d1f50>, '_i98': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', 'setbufsize': <function setbufsize at 0x21dd1b8>, '_85': (201,), '_i93': u'test.shape', '_i92': u'train.shape', '_i91': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', '_i90': u'train.shape', '_i97': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'cfloat': <type 'numpy.complex128'>, '_i95': u'yoda.shape', 'RAISE': 2, 'detrend_mean': <function detrend_mean at 0x2c4f758>, '_87': (200,), 'isscalar': <function isscalar at 0x21dbb90>, 'SubplotTool': <class 'matplotlib.widgets.SubplotTool'>, 'get_current_fig_manager': <function get_current_fig_manager at 0x3194b18>, 'character': <type 'numpy.character'>, 'bench': <bound method NoseTester.test of <numpy.testing.nosetester.NoseTester object at 0x2383a90>>, 'fullInput': array([[[ 0.      ,  0.      ,  0.      , ...,  0.299584,  0.038816,\n          0.081309],\n        [ 0.97    ,  0.45    ,  0.16    , ...,  0.314446,  0.251952,\n          0.206263],\n        [ 1.69    ,  0.51    ,  0.      , ...,  0.357783,  0.510176,\n          0.429069],\n        ..., \n        [ 2.79    ,  0.77    ,  0.08    , ...,  0.269088,  0.126912,\n          0.103441],\n        [ 2.74    ,  0.73    ,  0.12    , ...,  0.262727,  0.133116,\n          0.111704],\n        [ 2.78    ,  0.77    ,  0.1     , ...,  0.259782,  0.121326,\n          0.124544]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.320344,  0.071274,\n          0.057831],\n        [-2.14    ,  0.      , -0.2     , ...,  0.410495,  0.634182,\n          0.521483],\n        [-2.23    , -0.07    , -0.28    , ...,  0.478352,  0.79485 ,\n          0.690853],\n        ..., \n        [-4.72    ,  0.09    , -0.2     , ...,  0.231589,  0.067725,\n          0.090799],\n        [-4.51    ,  0.1     , -0.24    , ...,  0.231602,  0.072388,\n          0.100995],\n        [-4.62    ,  0.06    , -0.22    , ...,  0.225328,  0.048442,\n          0.083666]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.19655 ,  0.150555,\n          0.12083 ],\n        [ 0.52    ,  0.13    ,  0.12    , ...,  0.194066,  0.153753,\n          0.128841],\n        [ 0.48    ,  0.13    ,  0.1     , ...,  0.187594,  0.153753,\n          0.132288],\n        ..., \n        [ 0.04    ,  0.12    ,  0.2     , ...,  0.183963,  0.073756,\n          0.08124 ],\n        [ 0.1     ,  0.11    ,  0.2     , ...,  0.177811,  0.060332,\n          0.066165],\n        [ 0.02    ,  0.13    ,  0.18    , ...,  0.174681,  0.06121 ,  0.06    ]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.150991,  0.073394,\n          0.067082],\n        [-0.28    , -0.18    ,  0.08    , ...,  0.150545,  0.066933,\n          0.067082],\n        [-0.13    , -0.23    ,  0.08    , ...,  0.15091 ,  0.068896,\n          0.069121],\n        ..., \n        [-0.66    ,  0.12    ,  0.12    , ...,  0.197203,  0.073121,\n          0.083666],\n        [-0.6     ,  0.21    ,  0.12    , ...,  0.198655,  0.074833,\n          0.069282],\n        [-0.33    ,  0.23    ,  0.12    , ...,  0.198691,  0.099599,  0.08    ]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.150959,  0.089443,\n          0.095102],\n        [-1.07    , -0.07    ,  0.      , ...,  0.191609,  0.267133,\n          0.241753],\n        [-0.99    , -0.01    ,  0.04    , ...,  0.223181,  0.315383,\n          0.298794],\n        ..., \n        [-0.99    ,  0.11    ,  0.      , ...,  0.188956,  0.062823,\n          0.055678],\n        [-1.13    ,  0.07    ,  0.      , ...,  0.191981,  0.066232,\n          0.058119],\n        [-1.13    ,  0.06    ,  0.      , ...,  0.191485,  0.062823,  0.06    ]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  1.10484 ,  0.054283,\n          0.094868],\n        [-6.56    , -0.36    ,  0.04    , ...,  1.356407,  1.782152,\n          1.461476],\n        [-5.8     , -0.36    ,  0.04    , ...,  1.523808,  2.131682,\n          1.812402],\n        ..., \n        [-8.24    , -0.79    ,  0.04    , ...,  0.575108,  0.300311,\n          0.310644],\n        [-8.3     , -0.78    ,  0.04    , ...,  0.569777,  0.276743,\n          0.284429],\n        [-7.99    , -0.78    ,  0.01    , ...,  0.557479,  0.214942,\n          0.323883]]]), 'source': <function source at 0x2369758>, 'add': <ufunc 'add'>, 'uint16': <type 'numpy.uint16'>, 'ndenumerate': <class 'numpy.lib.index_tricks.ndenumerate'>, 'hlines': <function hlines at 0x3197320>, 'ufunc': <type 'numpy.ufunc'>, 'save': <function save at 0x23fb140>, 'multinomial': <built-in method multinomial of mtrand.RandomState object at 0x7f399f841690>, 'ravel': <function ravel at 0x21d1e60>, 'float32': <type 'numpy.float32'>, 'real': <function real at 0x2301668>, 'int32': <type 'numpy.int32'>, 'path_length': <function path_length at 0x2c53c80>, 'tril_indices': <function tril_indices at 0x230daa0>, '_i117': u'## Fit Random Forest and generate predictions\\nnumStocks   = trainOutput.shape[2]\\nperformance = []\\npred        = np.zeros((310,numStocks))\\nfor stock in xrange(numStocks):\\n    \\n    # get stock-specific features\\n    X     = deriv[:,stock].reshape((deriv.shape[0],1))\\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n\\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n\\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'around': <function around at 0x21da938>, 'cbook': <module 'matplotlib.cbook' from '/usr/local/lib/python2.7/dist-packages/matplotlib/cbook.pyc'>, 'lexsort': <built-in function lexsort>, 'get_scale_names': <function get_scale_names at 0x2fc5050>, 'complex_': <type 'numpy.complex128'>, 'ComplexWarning': <class 'numpy.core.numeric.ComplexWarning'>, 'datestr2num': <function datestr2num at 0x307bd70>, 'np': <module 'numpy' from '/usr/local/lib/python2.7/dist-packages/numpy/__init__.pyc'>, 'unicode0': <type 'numpy.unicode_'>, 'ipmt': <function ipmt at 0x23fbcf8>, 'issubclass_': <function issubclass_ at 0x21b8ed8>, 'atleast_3d': <function atleast_3d at 0x22746e0>, 'nper': <function nper at 0x23fbc80>, 'integer': <type 'numpy.integer'>, 'unique': <function unique at 0x2369e60>, 'mod': <ufunc 'remainder'>, '_sh': <module 'IPython.core.shadowns' from '/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/core/shadowns.pyc'>, 'bitwise_not': <ufunc 'invert'>, 'plot_date': <function plot_date at 0x3197668>, '_i101': u'predicted_probs.shape', '_i131': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'laplace': <built-in method laplace of mtrand.RandomState object at 0x7f399f841690>, 'getbufsize': <function getbufsize at 0x21dd230>, 'isfortran': <function isfortran at 0x21c27d0>, '_i134': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'get_printoptions': <function get_printoptions at 0x21dacf8>, 'asarray_chkfinite': <function asarray_chkfinite at 0x236c398>, 'rcParams': RcParams({'agg.path.chunksize': 0,\n          'animation.avconv_args': '',\n          'animation.avconv_path': 'avconv',\n          'animation.bitrate': -1,\n          'animation.codec': 'mpeg4',\n          'animation.convert_args': '',\n          'animation.convert_path': 'convert',\n          'animation.ffmpeg_args': '',\n          'animation.ffmpeg_path': 'ffmpeg',\n          'animation.frame_format': 'png',\n          'animation.mencoder_args': '',\n          'animation.mencoder_path': 'mencoder',\n          'animation.writer': 'ffmpeg',\n          'axes.axisbelow': False,\n          'axes.color_cycle': ['#66c2a5',\n                               '#fc8d62',\n                               '#8da0cb',\n                               '#e78ac3',\n                               '#a6d854',\n                               '#ffd92f',\n                               '#e5c494'],\n          'axes.edgecolor': 'k',\n          'axes.facecolor': 'w',\n          'axes.formatter.limits': [-7, 7],\n          'axes.formatter.use_locale': False,\n          'axes.formatter.use_mathtext': False,\n          'axes.grid': False,\n          'axes.hold': True,\n          'axes.labelcolor': 'k',\n          'axes.labelsize': 'medium',\n          'axes.labelweight': 'normal',\n          'axes.linewidth': 1.0,\n          'axes.titlesize': 'large',\n          'axes.unicode_minus': True,\n          'axes.xmargin': 0,\n          'axes.ymargin': 0,\n          'axes3d.grid': True,\n          'backend': 'module://IPython.kernel.zmq.pylab.backend_inline',\n          'backend.qt4': 'PyQt4',\n          'backend_fallback': True,\n          'contour.negative_linestyle': 'dashed',\n          'datapath': '/usr/local/lib/python2.7/dist-packages/matplotlib/mpl-data',\n          'docstring.hardcopy': False,\n          'examples.directory': '',\n          'figure.autolayout': False,\n          'figure.dpi': 80,\n          'figure.edgecolor': 'white',\n          'figure.facecolor': 'white',\n          'figure.figsize': (6.0, 4.0),\n          'figure.frameon': True,\n          'figure.max_open_warning': 20,\n          'figure.subplot.bottom': 0.125,\n          'figure.subplot.hspace': 0.2,\n          'figure.subplot.left': 0.125,\n          'figure.subplot.right': 0.9,\n          'figure.subplot.top': 0.9,\n          'figure.subplot.wspace': 0.2,\n          'font.cursive': ['Apple Chancery',\n                           'Textile',\n                           'Zapf Chancery',\n                           'Sand',\n                           'cursive'],\n          'font.family': 'sans-serif',\n          'font.fantasy': ['Comic Sans MS',\n                           'Chicago',\n                           'Charcoal',\n                           'ImpactWestern',\n                           'fantasy'],\n          'font.monospace': ['Bitstream Vera Sans Mono',\n                             'DejaVu Sans Mono',\n                             'Andale Mono',\n                             'Nimbus Mono L',\n                             'Courier New',\n                             'Courier',\n                             'Fixed',\n                             'Terminal',\n                             'monospace'],\n          'font.sans-serif': ['Bitstream Vera Sans',\n                              'DejaVu Sans',\n                              'Lucida Grande',\n                              'Verdana',\n                              'Geneva',\n                              'Lucid',\n                              'Arial',\n                              'Helvetica',\n                              'Avant Garde',\n                              'sans-serif'],\n          'font.serif': ['Bitstream Vera Serif',\n                         'DejaVu Serif',\n                         'New Century Schoolbook',\n                         'Century Schoolbook L',\n                         'Utopia',\n                         'ITC Bookman',\n                         'Bookman',\n                         'Nimbus Roman No9 L',\n                         'Times New Roman',\n                         'Times',\n                         'Palatino',\n                         'Charter',\n                         'serif'],\n          'font.size': 10,\n          'font.stretch': 'normal',\n          'font.style': 'normal',\n          'font.variant': 'normal',\n          'font.weight': 'normal',\n          'grid.alpha': 1.0,\n          'grid.color': 'k',\n          'grid.linestyle': ':',\n          'grid.linewidth': 0.5,\n          'image.aspect': 'equal',\n          'image.cmap': 'jet',\n          'image.interpolation': 'bilinear',\n          'image.lut': 256,\n          'image.origin': 'upper',\n          'image.resample': False,\n          'interactive': True,\n          'keymap.all_axes': 'a',\n          'keymap.back': ['left', 'c', 'backspace'],\n          'keymap.forward': ['right', 'v'],\n          'keymap.fullscreen': ('f', 'ctrl+f'),\n          'keymap.grid': 'g',\n          'keymap.home': ['h', 'r', 'home'],\n          'keymap.pan': 'p',\n          'keymap.quit': ('ctrl+w', 'cmd+w'),\n          'keymap.save': ('s', 'ctrl+s'),\n          'keymap.xscale': ['k', 'L'],\n          'keymap.yscale': 'l',\n          'keymap.zoom': 'o',\n          'legend.borderaxespad': 0.5,\n          'legend.borderpad': 0.4,\n          'legend.columnspacing': 2.0,\n          'legend.fancybox': False,\n          'legend.fontsize': 'large',\n          'legend.frameon': True,\n          'legend.handleheight': 0.7,\n          'legend.handlelength': 2.0,\n          'legend.handletextpad': 0.8,\n          'legend.isaxes': True,\n          'legend.labelspacing': 0.5,\n          'legend.loc': 'upper right',\n          'legend.markerscale': 1.0,\n          'legend.numpoints': 2,\n          'legend.scatterpoints': 3,\n          'legend.shadow': False,\n          'lines.antialiased': True,\n          'lines.color': 'b',\n          'lines.dash_capstyle': 'butt',\n          'lines.dash_joinstyle': 'round',\n          'lines.linestyle': '-',\n          'lines.linewidth': 1.0,\n          'lines.marker': 'None',\n          'lines.markeredgewidth': 0.5,\n          'lines.markersize': 6,\n          'lines.solid_capstyle': 'projecting',\n          'lines.solid_joinstyle': 'round',\n          'mathtext.bf': 'serif:bold',\n          'mathtext.cal': 'cursive',\n          'mathtext.default': 'it',\n          'mathtext.fallback_to_cm': True,\n          'mathtext.fontset': 'cm',\n          'mathtext.it': 'serif:italic',\n          'mathtext.rm': 'serif',\n          'mathtext.sf': 'sans\\\\-serif',\n          'mathtext.tt': 'monospace',\n          'patch.antialiased': True,\n          'patch.edgecolor': 'k',\n          'patch.facecolor': 'b',\n          'patch.linewidth': 1.0,\n          'path.effects': [],\n          'path.simplify': True,\n          'path.simplify_threshold': 0.1111111111111111,\n          'path.sketch': None,\n          'path.snap': True,\n          'pdf.compression': 6,\n          'pdf.fonttype': 3,\n          'pdf.inheritcolor': False,\n          'pdf.use14corefonts': False,\n          'pgf.debug': False,\n          'pgf.preamble': [''],\n          'pgf.rcfonts': True,\n          'pgf.texsystem': 'xelatex',\n          'plugins.directory': '.matplotlib_plugins',\n          'polaraxes.grid': True,\n          'ps.distiller.res': 6000,\n          'ps.fonttype': 3,\n          'ps.papersize': 'letter',\n          'ps.useafm': False,\n          'ps.usedistiller': False,\n          'savefig.bbox': None,\n          'savefig.directory': '~',\n          'savefig.dpi': 72,\n          'savefig.edgecolor': 'w',\n          'savefig.extension': 'png',\n          'savefig.facecolor': 'w',\n          'savefig.format': 'png',\n          'savefig.frameon': True,\n          'savefig.jpeg_quality': 95,\n          'savefig.orientation': 'portrait',\n          'savefig.pad_inches': 0.1,\n          'svg.embed_char_paths': True,\n          'svg.fonttype': 'path',\n          'svg.image_inline': True,\n          'svg.image_noscale': False,\n          'text.antialiased': True,\n          'text.color': 'k',\n          'text.dvipnghack': None,\n          'text.hinting': True,\n          'text.hinting_factor': 8,\n          'text.latex.preamble': [''],\n          'text.latex.preview': False,\n          'text.latex.unicode': False,\n          'text.usetex': False,\n          'timezone': 'UTC',\n          'tk.pythoninspect': False,\n          'tk.window_focus': False,\n          'toolbar': 'toolbar2',\n          'verbose.fileo': 'sys.stdout',\n          'verbose.level': 'silent',\n          'webagg.open_in_browser': True,\n          'webagg.port': 8988,\n          'webagg.port_retries': 50,\n          'xtick.color': 'k',\n          'xtick.direction': 'in',\n          'xtick.labelsize': 'medium',\n          'xtick.major.pad': 4,\n          'xtick.major.size': 4,\n          'xtick.major.width': 0.5,\n          'xtick.minor.pad': 4,\n          'xtick.minor.size': 2,\n          'xtick.minor.width': 0.5,\n          'ytick.color': 'k',\n          'ytick.direction': 'in',\n          'ytick.labelsize': 'medium',\n          'ytick.major.pad': 4,\n          'ytick.major.size': 4,\n          'ytick.major.width': 0.5,\n          'ytick.minor.pad': 4,\n          'ytick.minor.size': 2,\n          'ytick.minor.width': 0.5}), 'pcolormesh': <function pcolormesh at 0x3197500>, 'string0': <type 'numpy.string_'>, 'barh': <function barh at 0x3196b18>, '_i130': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', '_i104': u'lastObserved[:,stock].shape', '_i133': u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', '_53': (array([  2.00000000e+00,   0.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         1.00000000e+00,   2.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         2.00000000e+00,   7.00000000e+00,   3.00000000e+00,\n         4.00000000e+00,   7.00000000e+00,   8.00000000e+00,\n         2.20000000e+01,   2.00000000e+01,   1.30000000e+01,\n         2.40000000e+01,   5.30000000e+01,   5.30000000e+01,\n         8.10000000e+01,   1.17000000e+02,   1.68000000e+02,\n         2.91000000e+02,   5.90000000e+02,   1.25600000e+03,\n         2.75800000e+03,   8.53900000e+03,   1.52450000e+04,\n         6.19300000e+03,   1.99500000e+03,   9.18000000e+02,\n         4.14000000e+02,   2.14000000e+02,   1.21000000e+02,\n         1.11000000e+02,   7.50000000e+01,   6.70000000e+01,\n         3.50000000e+01,   3.70000000e+01,   3.00000000e+01,\n         2.50000000e+01,   2.00000000e+01,   6.00000000e+00,\n         7.00000000e+00,   6.00000000e+00,   9.00000000e+00,\n         4.00000000e+00,   3.00000000e+00,   1.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n         3.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         3.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         1.00000000e+00]), array([-15.55  , -15.1994, -14.8488, -14.4982, -14.1476, -13.797 ,\n       -13.4464, -13.0958, -12.7452, -12.3946, -12.044 , -11.6934,\n       -11.3428, -10.9922, -10.6416, -10.291 ,  -9.9404,  -9.5898,\n        -9.2392,  -8.8886,  -8.538 ,  -8.1874,  -7.8368,  -7.4862,\n        -7.1356,  -6.785 ,  -6.4344,  -6.0838,  -5.7332,  -5.3826,\n        -5.032 ,  -4.6814,  -4.3308,  -3.9802,  -3.6296,  -3.279 ,\n        -2.9284,  -2.5778,  -2.2272,  -1.8766,  -1.526 ,  -1.1754,\n        -0.8248,  -0.4742,  -0.1236,   0.227 ,   0.5776,   0.9282,\n         1.2788,   1.6294,   1.98  ,   2.3306,   2.6812,   3.0318,\n         3.3824,   3.733 ,   4.0836,   4.4342,   4.7848,   5.1354,\n         5.486 ,   5.8366,   6.1872,   6.5378,   6.8884,   7.239 ,\n         7.5896,   7.9402,   8.2908,   8.6414,   8.992 ,   9.3426,\n         9.6932,  10.0438,  10.3944,  10.745 ,  11.0956,  11.4462,\n        11.7968,  12.1474,  12.498 ,  12.8486,  13.1992,  13.5498,\n        13.9004,  14.251 ,  14.6016,  14.9522,  15.3028,  15.6534,\n        16.004 ,  16.3546,  16.7052,  17.0558,  17.4064,  17.757 ,\n        18.1076,  18.4582,  18.8088,  19.1594,  19.51  ]), <a list of 100 Patch objects>), 'sign': <ufunc 'sign'>, '_dh': [u'/home/lane/iPython_notebooks', u'/home/lane/Kaggle/03 Predicting Stock Prices'], 'svd': <function svd at 0x238c9b0>, '_i106': u'pred = predicted_probs + lastObserved[200:,stock]', 'findobj': <function findobj at 0x31942a8>, 'spring': <function spring at 0x31989b0>, 'in1d': <function in1d at 0x236c050>, 'interp': <function interp at 0x236c668>, 'draw': <function draw at 0x3194d70>, 'ginput': <function ginput at 0x3194ed8>, 'rcdefaults': <function rcdefaults at 0x3194758>, 'rfft': <function rfft at 0x23feed8>, 'hypot': <ufunc 'hypot'>, 'logical_and': <ufunc 'logical_and'>, 'rrule': <class 'dateutil.rrule.rrule'>, 'table': <function table at 0x3198140>, 'diagflat': <function diagflat at 0x230d758>, 'float128': <type 'numpy.float128'>, 'matshow': <function matshow at 0x3196410>, 'isfinite': <ufunc 'isfinite'>, '_52': (array([  8.00000000e+00,   9.00000000e+00,   3.80000000e+01,\n         8.42000000e+02,   3.81220000e+04,   5.27000000e+02,\n         3.80000000e+01,   8.00000000e+00,   6.00000000e+00,\n         2.00000000e+00]), array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 10 Patch objects>), 'MINUTELY': 5, 'byte_bounds': <function byte_bounds at 0x2369488>, 'iinfo': <class 'numpy.core.getlimits.iinfo'>, 'kaiser': <function kaiser at 0x236d500>, 'ifftshift': <function ifftshift at 0x24096e0>, '_16': 0.32388299999999998, '_113': <type 'list'>, 'inside_poly': <function inside_poly at 0x2c53848>, 'warnings': <module 'warnings' from '/usr/lib/python2.7/warnings.pyc'>, '_116': -3.8199999999999998, 'cv': sklearn.cross_validation.KFold(n=200, n_folds=25), 'is_closed_polygon': <function is_closed_polygon at 0x2c539b0>, 'polysub': <function polysub at 0x238d0c8>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x2728f10>, 'ifftn': <function ifftn at 0x24092a8>, 'fromfile': <built-in function fromfile>, 'prod': <function prod at 0x21da6e0>, 'nanmax': <function nanmax at 0x236cc80>, 'LinearLocator': <class 'matplotlib.ticker.LinearLocator'>, 'tensorinv': <function tensorinv at 0x238c578>, 'plt': <module 'matplotlib.pyplot' from '/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc'>, 'seterrobj': <built-in function seterrobj>, 'power': <ufunc 'power'>, 'array_split': <function array_split at 0x2374d70>, 'zipf': <built-in method zipf of mtrand.RandomState object at 0x7f399f841690>, 'stem': <function stem at 0x3197aa0>, 'ioff': <function ioff at 0x3194488>, 'step': <function step at 0x3197b18>, 'percentile': <function percentile at 0x236d6e0>, 'hsv': <function hsv at 0x31987d0>, 'axhspan': <function axhspan at 0x3196938>, 'FPE_DIVIDEBYZERO': 1, '__name__': '__main__', 'subtract': <ufunc 'subtract'>, 'optimize': <module 'scipy.optimize' from '/usr/local/lib/python2.7/dist-packages/scipy/optimize/__init__.pyc'>, '_': -3.8199999999999998, 'mx2num': <function mx2num at 0x307fb18>, 'fft': <module 'numpy.fft' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/__init__.pyc'>, 'frombuffer': <built-in function frombuffer>, 'iscomplex': <function iscomplex at 0x2301758>, 'fill_betweenx': <function fill_betweenx at 0x3197140>, 'multivariate_normal': <built-in method multivariate_normal of mtrand.RandomState object at 0x7f399f841690>, 'add_docstring': <built-in function add_docstring>, 'argsort': <function argsort at 0x21d1aa0>, '_38': ([array([   0.,    0.,    0.,   11.,  179.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  189.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  189.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  194.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  188.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  191.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   12.,  181.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  193.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   23.,  158.,   11.,    2.,    0.,    2.,    0.]), array([   2.,    0.,    2.,   16.,  159.,   19.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  196.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  187.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  192.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  194.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  184.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  192.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    3.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   1.,    0.,    2.,   28.,  148.,   17.,    3.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  186.,    9.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  184.,    2.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  177.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,    7.,  186.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   20.,  168.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    2.,    0.,   15.,  167.,   16.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    0.,   14.,  167.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,   16.,  165.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   14.,  182.,    2.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    3.,   26.,  153.,   16.,    0.,    0.,    2.,    0.]), array([   3.,    1.,    7.,   46.,  102.,   26.,    8.,    3.,    2.,    2.]), array([   0.,    2.,    0.,   12.,  176.,   10.,    0.,    0.,    0.,    0.]), array([   2.,    0.,    1.,   20.,  155.,   18.,    4.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  181.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  184.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  189.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  182.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   11.,  182.,    6.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  184.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   22.,  166.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  195.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    3.,  193.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  190.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  196.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   29.,  140.,   21.,    4.,    2.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  190.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    3.,   31.,  144.,   17.,    3.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  193.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  188.,    4.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.])], array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 198 Lists of Patches objects>), '_19': 0.32388299999999998, 'fmin': <ufunc 'fmin'>, 'loadtxt': <function loadtxt at 0x23fb398>, '_31': (200, 198), '_30': (510, 198), '_33': (200, 198), '_18': 0.32388299999999998, '_35': [<matplotlib.lines.Line2D object at 0x3c0f110>], 'bytes_': <type 'numpy.string_'>, 'ones_like': <function ones_like at 0x21c2488>, '_36': [<matplotlib.lines.Line2D object at 0x3df1610>], 'ScalarFormatter': <class 'matplotlib.ticker.ScalarFormatter'>, 'is_busday': <built-in function is_busday>, 'arcsinh': <ufunc 'arcsinh'>, 'CLIP': 0, 'exp_safe': <function exp_safe at 0x2c51cf8>, '_i57': u\"fig = gcf()\\nfig.set_size_inches(16,4)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", '_i56': u\"yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", '_i55': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True)', '_i54': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100)', '_i53': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda,100)', '_i52': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda)', '__builtin__': <module '__builtin__' (built-in)>, 'dataset': array([[ 0.      ,  0.      ,  0.      , ...,  1.10484 ,  0.054283,\n         0.094868],\n       [-6.56    , -0.36    ,  0.04    , ...,  1.356407,  1.782152,\n         1.461476],\n       [-5.8     , -0.36    ,  0.04    , ...,  1.523808,  2.131682,\n         1.812402],\n       ..., \n       [-8.24    , -0.79    ,  0.04    , ...,  0.575108,  0.300311,\n         0.310644],\n       [-8.3     , -0.78    ,  0.04    , ...,  0.569777,  0.276743,\n         0.284429],\n       [-7.99    , -0.78    ,  0.01    , ...,  0.557479,  0.214942,\n         0.323883]]), 'annotate': <function annotate at 0x3198230>, '_i80': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201,:]\\ntest  = X[201:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'normalize': <function Normalize at 0x29e6b18>, 'intp': <type 'numpy.int64'>, 'standard_cauchy': <built-in method standard_cauchy of mtrand.RandomState object at 0x7f399f841690>, '_i82': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201]\\ntest  = X[201:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'unpackbits': <built-in function unpackbits>, 'HOURLY': 4, 'arrow': <function arrow at 0x3196848>, 'delete': <function delete at 0x236d938>, 'Infinity': inf, 'log': <ufunc 'log'>, 'numMetrics': 244, 'cdouble': <type 'numpy.complex128'>, 'complex128': <type 'numpy.complex128'>, 'tick_params': <function tick_params at 0x3198398>, 'switch_backend': <function switch_backend at 0x3194320>, 'round_': <function round_ at 0x21da9b0>, 'broadcast_arrays': <function broadcast_arrays at 0x2377410>, 'inner': <built-in function inner>, 'var': <function var at 0x21dab18>, 'c_': <numpy.lib.index_tricks.CClass object at 0x236f9d0>, 'slopes': <function slopes at 0x2c53758>, '_i87': u'train.shape', 'log10': <ufunc 'log10'>, 'thisMetric': array([[ 0.142166],\n       [ 0.272029],\n       [ 0.062272],\n       [ 0.229153],\n       [ 0.042557],\n       [ 0.33731 ],\n       [ 0.310483],\n       [ 0.133083],\n       [ 0.06245 ],\n       [ 0.110805],\n       [ 0.132204],\n       [ 0.169738],\n       [ 0.063246],\n       [ 0.260853],\n       [ 0.136382],\n       [ 0.095102],\n       [ 0.133041],\n       [ 0.175214],\n       [ 0.226495],\n       [ 0.153984],\n       [ 0.188709],\n       [ 0.045583],\n       [ 0.530984],\n       [ 0.060919],\n       [ 0.621289],\n       [ 0.048762],\n       [ 0.106771],\n       [ 0.088944],\n       [ 0.126271],\n       [ 0.07356 ],\n       [ 0.289156],\n       [ 0.109545],\n       [ 0.133791],\n       [ 0.127845],\n       [ 0.042164],\n       [ 0.206586],\n       [ 0.092436],\n       [ 0.125477],\n       [ 0.101871],\n       [ 0.1761  ],\n       [ 0.196723],\n       [ 0.097354],\n       [ 0.2     ],\n       [ 0.061192],\n       [ 0.096839],\n       [ 0.1     ],\n       [ 0.142867],\n       [ 0.21349 ],\n       [ 0.06    ],\n       [ 0.205047],\n       [ 0.251794],\n       [ 0.066332],\n       [ 0.078811],\n       [ 0.32426 ],\n       [ 0.034641],\n       [ 0.056372],\n       [ 0.314925],\n       [ 0.150481],\n       [ 0.109545],\n       [ 0.173429],\n       [ 0.467737],\n       [ 0.200942],\n       [ 0.135565],\n       [ 0.138363],\n       [ 0.166966],\n       [ 0.557494],\n       [ 0.292746],\n       [ 0.188267],\n       [ 0.129615],\n       [ 0.294524],\n       [ 0.057831],\n       [ 0.307571],\n       [ 0.476667],\n       [ 0.04    ],\n       [ 0.318974],\n       [ 0.061734],\n       [ 0.25307 ],\n       [ 0.34    ],\n       [ 0.239397],\n       [ 0.268701],\n       [ 0.291681],\n       [ 0.19    ],\n       [ 0.120324],\n       [ 0.146553],\n       [ 0.421189],\n       [ 0.25399 ],\n       [ 0.05831 ],\n       [ 0.119629],\n       [ 0.336452],\n       [ 0.073106],\n       [ 0.204885],\n       [ 0.11225 ],\n       [ 0.153768],\n       [ 0.181659],\n       [ 0.248149],\n       [ 0.371319],\n       [ 0.79813 ],\n       [ 0.303278],\n       [ 0.289271],\n       [ 0.513561],\n       [ 0.287653],\n       [ 0.106301],\n       [ 0.608997],\n       [ 0.136545],\n       [ 0.209152],\n       [ 0.304485],\n       [ 0.186934],\n       [ 0.319026],\n       [ 0.076449],\n       [ 0.109595],\n       [ 0.11949 ],\n       [ 0.15268 ],\n       [ 0.324157],\n       [ 0.679485],\n       [ 0.158254],\n       [ 0.179846],\n       [ 0.099722],\n       [ 0.034641],\n       [ 0.104297],\n       [ 0.075572],\n       [ 0.067905],\n       [ 0.564427],\n       [ 0.204559],\n       [ 0.153442],\n       [ 0.088192],\n       [ 0.068638],\n       [ 0.108525],\n       [ 0.14345 ],\n       [ 0.19105 ],\n       [ 0.164621],\n       [ 0.141067],\n       [ 0.104297],\n       [ 0.114066],\n       [ 0.172755],\n       [ 0.308887],\n       [ 0.067905],\n       [ 0.100222],\n       [ 0.200776],\n       [ 0.134164],\n       [ 0.122656],\n       [ 0.074833],\n       [ 0.249087],\n       [ 0.074012],\n       [ 0.119164],\n       [ 0.215587],\n       [ 0.424513],\n       [ 0.096437],\n       [ 0.103494],\n       [ 0.232809],\n       [ 0.052705],\n       [ 0.103441],\n       [ 0.189209],\n       [ 0.12    ],\n       [ 0.208113],\n       [ 1.304318],\n       [ 0.034641],\n       [ 0.340506],\n       [ 0.03    ],\n       [ 0.097011],\n       [ 0.216974],\n       [ 0.585928],\n       [ 0.231948],\n       [ 0.141578],\n       [ 0.089691],\n       [ 0.20445 ],\n       [ 0.125344],\n       [ 0.07746 ],\n       [ 0.083533],\n       [ 0.103655],\n       [ 0.052915],\n       [ 0.314713],\n       [ 0.405476],\n       [ 0.11879 ],\n       [ 0.283333],\n       [ 0.471181],\n       [ 0.228789],\n       [ 0.077746],\n       [ 0.074162],\n       [ 0.161245],\n       [ 0.212315],\n       [ 0.202731],\n       [ 0.131149],\n       [ 0.2319  ],\n       [ 0.244154],\n       [ 0.200693],\n       [ 0.453995],\n       [ 0.1206  ],\n       [ 0.220177],\n       [ 0.153623],\n       [ 0.270267],\n       [ 0.121655],\n       [ 0.074907],\n       [ 0.206263],\n       [ 0.157198],\n       [ 0.167929],\n       [ 0.111355],\n       [ 0.275035],\n       [ 0.126095],\n       [ 0.195192],\n       [ 0.113186],\n       [ 0.208753],\n       [ 0.536563],\n       [ 0.110905],\n       [ 0.083732],\n       [ 0.235891],\n       [ 0.131951],\n       [ 0.191949],\n       [ 0.129615],\n       [ 0.139443],\n       [ 0.261874],\n       [ 0.139084],\n       [ 0.321559],\n       [ 0.187113],\n       [ 0.090615],\n       [ 0.066165],\n       [ 0.067165],\n       [ 0.155385],\n       [ 0.119629],\n       [ 0.220454],\n       [ 0.17845 ],\n       [ 0.135195],\n       [ 0.30921 ],\n       [ 0.20955 ],\n       [ 0.086667],\n       [ 0.202731],\n       [ 0.072801],\n       [ 0.086859],\n       [ 0.183697],\n       [ 0.25738 ],\n       [ 0.202731],\n       [ 0.279106],\n       [ 0.114455],\n       [ 0.960422],\n       [ 0.151364],\n       [ 0.175531],\n       [ 0.122066],\n       [ 0.239049],\n       [ 0.150481],\n       [ 0.167332],\n       [ 0.36457 ],\n       [ 0.225389],\n       [ 0.279364],\n       [ 0.142867],\n       [ 0.020276],\n       [ 0.090615],\n       [ 0.426146],\n       [ 0.150591],\n       [ 0.296891],\n       [ 0.04    ],\n       [ 0.203415],\n       [ 0.25399 ],\n       [ 0.122384],\n       [ 0.112151],\n       [ 0.051424],\n       [ 0.08    ],\n       [ 0.380526],\n       [ 0.381838],\n       [ 0.133458],\n       [ 0.041231],\n       [ 0.338083],\n       [ 0.133583],\n       [ 0.215407],\n       [ 0.134454],\n       [ 0.109138],\n       [ 0.351568],\n       [ 0.263333],\n       [ 0.129529],\n       [ 0.098545],\n       [ 0.684471],\n       [ 0.348712],\n       [ 0.047958],\n       [ 0.298068],\n       [ 0.065405],\n       [ 0.364692],\n       [ 0.054263],\n       [ 0.301625],\n       [ 0.147309],\n       [ 0.605402],\n       [ 0.074162],\n       [ 0.129271],\n       [ 0.21    ],\n       [ 0.389102],\n       [ 0.304649],\n       [ 0.199109],\n       [ 0.08775 ],\n       [ 0.074012],\n       [ 0.25865 ],\n       [ 0.155885],\n       [ 0.156667],\n       [ 0.228206],\n       [ 0.099219],\n       [ 0.108679],\n       [ 0.08    ],\n       [ 0.124544],\n       [ 0.138724],\n       [ 0.104403],\n       [ 0.047958],\n       [ 0.264008],\n       [ 0.363517],\n       [ 0.558341],\n       [ 0.119629],\n       [ 0.106301],\n       [ 0.147121],\n       [ 0.124499],\n       [ 0.216795],\n       [ 0.145297],\n       [ 0.11348 ],\n       [ 0.311929],\n       [ 0.332265],\n       [ 0.244495],\n       [ 1.289358],\n       [ 0.079652],\n       [ 0.847526],\n       [ 0.108218],\n       [ 0.208992],\n       [ 0.393206],\n       [ 0.099051],\n       [ 0.050772],\n       [ 0.199444],\n       [ 0.093274],\n       [ 0.06    ],\n       [ 0.117898],\n       [ 0.380716],\n       [ 0.107703],\n       [ 0.080069],\n       [ 0.146287],\n       [ 0.218174],\n       [ 0.194165],\n       [ 0.166567],\n       [ 0.063596],\n       [ 0.184662],\n       [ 0.13784 ],\n       [ 0.618663],\n       [ 0.130384],\n       [ 0.164249],\n       [ 0.652687],\n       [ 0.693253],\n       [ 0.086667],\n       [ 0.317245],\n       [ 0.144837],\n       [ 0.016667],\n       [ 0.400222],\n       [ 0.079652],\n       [ 0.084327],\n       [ 0.156241],\n       [ 0.099051],\n       [ 0.193592],\n       [ 0.15748 ],\n       [ 0.152571],\n       [ 0.105251],\n       [ 0.220025],\n       [ 0.371349],\n       [ 0.053955],\n       [ 0.556996],\n       [ 0.149926],\n       [ 0.071414],\n       [ 0.932011],\n       [ 0.108372],\n       [ 0.36653 ],\n       [ 0.311359],\n       [ 0.199444],\n       [ 0.284917],\n       [ 0.066332],\n       [ 0.138924],\n       [ 0.091165],\n       [ 0.142127],\n       [ 0.219949],\n       [ 0.1294  ],\n       [ 0.30249 ],\n       [ 0.145258],\n       [ 0.06888 ],\n       [ 0.371139],\n       [ 0.251219],\n       [ 0.162207],\n       [ 0.124141],\n       [ 0.291738],\n       [ 0.35201 ],\n       [ 0.08124 ],\n       [ 0.174865],\n       [ 2.412726],\n       [ 0.063857],\n       [ 0.15592 ],\n       [ 0.261236],\n       [ 0.108628],\n       [ 0.138203],\n       [ 0.127671],\n       [ 0.345897],\n       [ 0.162788],\n       [ 0.271477],\n       [ 0.06888 ],\n       [ 0.148324],\n       [ 0.451934],\n       [ 0.036667],\n       [ 0.188532],\n       [ 0.093808],\n       [ 0.137113],\n       [ 0.509117],\n       [ 0.176068],\n       [ 0.319913],\n       [ 0.315718],\n       [ 0.244336],\n       [ 0.10198 ],\n       [ 0.182757],\n       [ 0.037417],\n       [ 0.07356 ],\n       [ 0.412432],\n       [ 0.064893],\n       [ 0.175784],\n       [ 0.194165],\n       [ 0.232904],\n       [ 0.044721],\n       [ 0.065574],\n       [ 0.146287],\n       [ 0.062004],\n       [ 0.176572],\n       [ 0.476527],\n       [ 0.238118],\n       [ 0.065574],\n       [ 0.11893 ],\n       [ 0.247745],\n       [ 0.172337],\n       [ 0.101379],\n       [ 0.059815],\n       [ 0.285326],\n       [ 0.091348],\n       [ 0.257833],\n       [ 0.546626],\n       [ 0.117379],\n       [ 0.26327 ],\n       [ 0.051099],\n       [ 0.102956],\n       [ 0.173141],\n       [ 0.117237],\n       [ 0.185472],\n       [ 0.171205],\n       [ 0.060828],\n       [ 0.094868],\n       [ 0.171205],\n       [ 0.27258 ],\n       [ 0.098995],\n       [ 0.854868],\n       [ 0.08    ],\n       [ 0.08705 ],\n       [ 0.12252 ],\n       [ 0.344384],\n       [ 0.353475],\n       [ 0.178263],\n       [ 0.10198 ],\n       [ 0.102198],\n       [ 0.174356],\n       [ 0.35819 ],\n       [ 0.136382],\n       [ 0.056075],\n       [ 0.127671],\n       [ 0.081854],\n       [ 0.109087],\n       [ 0.223557],\n       [ 0.325645],\n       [ 0.563777],\n       [ 0.140633],\n       [ 0.138564],\n       [ 0.954713],\n       [ 0.061644],\n       [ 0.095917],\n       [ 0.052915],\n       [ 0.495861],\n       [ 0.154416],\n       [ 0.095801],\n       [ 0.250422],\n       [ 0.031798],\n       [ 0.197737],\n       [ 0.317175],\n       [ 0.161898],\n       [ 0.038006],\n       [ 0.321472],\n       [ 0.072648],\n       [ 0.119907],\n       [ 0.118322],\n       [ 0.076012],\n       [ 0.236854],\n       [ 0.143798],\n       [ 0.164857],\n       [ 0.099387],\n       [ 0.021858],\n       [ 0.051424],\n       [ 0.291624],\n       [ 0.190029],\n       [ 0.133832],\n       [ 0.245515],\n       [ 0.273699],\n       [ 0.176289],\n       [ 0.200499],\n       [ 0.535859],\n       [ 0.159931],\n       [ 0.193075],\n       [ 0.285034],\n       [ 0.110454],\n       [ 0.194879],\n       [ 0.150997],\n       [ 0.043333],\n       [ 0.060645],\n       [ 0.150923],\n       [ 0.439634],\n       [ 0.230024],\n       [ 0.120046],\n       [ 0.103494],\n       [ 0.281267],\n       [ 0.083333],\n       [ 0.062539],\n       [ 0.452769]]), 'hypergeometric': <built-in method hypergeometric of mtrand.RandomState object at 0x7f399f841690>, 'uintp': <type 'numpy.uint64'>, 'unwrap': <function unwrap at 0x236c758>, 'NullLocator': <class 'matplotlib.ticker.NullLocator'>, '_i68': u'normTarget.shape', 'triangular': <built-in method triangular of mtrand.RandomState object at 0x7f399f841690>, 'noncentral_chisquare': <built-in method noncentral_chisquare of mtrand.RandomState object at 0x7f399f841690>, 'histogram': <function histogram at 0x236c230>, 'msg': 'To:lanemcintosh@gmail.com\\nFrom: mcintoshlane@gmail.com\\nSubject:Kaggle iPython Notebook \\n\\nYour Python Script has now Completed!', 'issubdtype': <function issubdtype at 0x21bf050>, 'maximum_sctype': <function maximum_sctype at 0x21b8cf8>, 'flexible': <type 'numpy.flexible'>, 'movavg': <function movavg at 0x2c51938>, 'squeeze': <function squeeze at 0x21d1cf8>, 'int8': <type 'numpy.int8'>, 'cholesky': <function cholesky at 0x238c668>, 'info': <function info at 0x23696e0>, 'seterr': <function seterr at 0x21dd0c8>, 'argmin': <function argmin at 0x21d1b90>, 'fignum_exists': <function has_fignum at 0x2cf9938>, 'genfromtxt': <function genfromtxt at 0x23fb500>, 'rec_append_fields': <function rec_append_fields at 0x2c52488>, 'j': 9, 'maximum': <ufunc 'maximum'>, '_23': (510, 55, 198), 'record': <class 'numpy.core.records.record'>, 'obj2sctype': <function obj2sctype at 0x21b8e60>, '_61': <matplotlib.text.Text object at 0x8c45410>, 'clongdouble': <type 'numpy.complex256'>, 'sum': <function sum at 0x21da140>, 'isrealobj': <function isrealobj at 0x23018c0>, 'log1p': <ufunc 'log1p'>, '_oh': {8: 510, 10: 200, 12: (510, 55, 244), 13: (510, 55, 198), 16: 0.32388299999999998, 18: 0.32388299999999998, 19: 0.32388299999999998, 21: (510, 55, 442), 23: (510, 55, 198), 24: 55, 25: (200, 198), 26: (200, 198), 27: (510, 55, 244), 30: (510, 198), 31: (200, 198), 33: (200, 198), 34: (200, 198), 35: [<matplotlib.lines.Line2D object at 0x3c0f110>], 36: [<matplotlib.lines.Line2D object at 0x3df1610>], 37: (array([   3.,   11.,   42.,  112.,   26.,    4.,    0.,    0.,    0.,    2.]), array([-2.12 , -1.478, -0.836, -0.194,  0.448,  1.09 ,  1.732,  2.374,\n        3.016,  3.658,  4.3  ]), <a list of 10 Patch objects>), 38: ([array([   0.,    0.,    0.,   11.,  179.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  189.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  189.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  194.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  188.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  191.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   12.,  181.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  193.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   23.,  158.,   11.,    2.,    0.,    2.,    0.]), array([   2.,    0.,    2.,   16.,  159.,   19.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  196.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  187.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  192.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  194.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  184.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  192.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    3.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   1.,    0.,    2.,   28.,  148.,   17.,    3.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  186.,    9.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  184.,    2.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  177.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,    7.,  186.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   20.,  168.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    2.,    0.,   15.,  167.,   16.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    0.,   14.,  167.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,   16.,  165.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   14.,  182.,    2.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    3.,   26.,  153.,   16.,    0.,    0.,    2.,    0.]), array([   3.,    1.,    7.,   46.,  102.,   26.,    8.,    3.,    2.,    2.]), array([   0.,    2.,    0.,   12.,  176.,   10.,    0.,    0.,    0.,    0.]), array([   2.,    0.,    1.,   20.,  155.,   18.,    4.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  181.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  184.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  189.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  182.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   11.,  182.,    6.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  184.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   22.,  166.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  195.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    3.,  193.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  190.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  196.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   29.,  140.,   21.,    4.,    2.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  190.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    3.,   31.,  144.,   17.,    3.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  193.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  188.,    4.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.])], array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 198 Lists of Patches objects>), 44: (200, 198), 52: (array([  8.00000000e+00,   9.00000000e+00,   3.80000000e+01,\n         8.42000000e+02,   3.81220000e+04,   5.27000000e+02,\n         3.80000000e+01,   8.00000000e+00,   6.00000000e+00,\n         2.00000000e+00]), array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 10 Patch objects>), 53: (array([  2.00000000e+00,   0.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         1.00000000e+00,   2.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         2.00000000e+00,   7.00000000e+00,   3.00000000e+00,\n         4.00000000e+00,   7.00000000e+00,   8.00000000e+00,\n         2.20000000e+01,   2.00000000e+01,   1.30000000e+01,\n         2.40000000e+01,   5.30000000e+01,   5.30000000e+01,\n         8.10000000e+01,   1.17000000e+02,   1.68000000e+02,\n         2.91000000e+02,   5.90000000e+02,   1.25600000e+03,\n         2.75800000e+03,   8.53900000e+03,   1.52450000e+04,\n         6.19300000e+03,   1.99500000e+03,   9.18000000e+02,\n         4.14000000e+02,   2.14000000e+02,   1.21000000e+02,\n         1.11000000e+02,   7.50000000e+01,   6.70000000e+01,\n         3.50000000e+01,   3.70000000e+01,   3.00000000e+01,\n         2.50000000e+01,   2.00000000e+01,   6.00000000e+00,\n         7.00000000e+00,   6.00000000e+00,   9.00000000e+00,\n         4.00000000e+00,   3.00000000e+00,   1.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n         3.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         3.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         1.00000000e+00]), array([-15.55  , -15.1994, -14.8488, -14.4982, -14.1476, -13.797 ,\n       -13.4464, -13.0958, -12.7452, -12.3946, -12.044 , -11.6934,\n       -11.3428, -10.9922, -10.6416, -10.291 ,  -9.9404,  -9.5898,\n        -9.2392,  -8.8886,  -8.538 ,  -8.1874,  -7.8368,  -7.4862,\n        -7.1356,  -6.785 ,  -6.4344,  -6.0838,  -5.7332,  -5.3826,\n        -5.032 ,  -4.6814,  -4.3308,  -3.9802,  -3.6296,  -3.279 ,\n        -2.9284,  -2.5778,  -2.2272,  -1.8766,  -1.526 ,  -1.1754,\n        -0.8248,  -0.4742,  -0.1236,   0.227 ,   0.5776,   0.9282,\n         1.2788,   1.6294,   1.98  ,   2.3306,   2.6812,   3.0318,\n         3.3824,   3.733 ,   4.0836,   4.4342,   4.7848,   5.1354,\n         5.486 ,   5.8366,   6.1872,   6.5378,   6.8884,   7.239 ,\n         7.5896,   7.9402,   8.2908,   8.6414,   8.992 ,   9.3426,\n         9.6932,  10.0438,  10.3944,  10.745 ,  11.0956,  11.4462,\n        11.7968,  12.1474,  12.498 ,  12.8486,  13.1992,  13.5498,\n        13.9004,  14.251 ,  14.6016,  14.9522,  15.3028,  15.6534,\n        16.004 ,  16.3546,  16.7052,  17.0558,  17.4064,  17.757 ,\n        18.1076,  18.4582,  18.8088,  19.1594,  19.51  ]), <a list of 100 Patch objects>), 61: <matplotlib.text.Text object at 0x8c45410>, 63: <matplotlib.text.Text object at 0x8d13e90>, 64: <matplotlib.text.Text object at 0x9b88ad0>, 65: <matplotlib.text.Text object at 0x92e02d0>, 66: (510, 55, 198), 67: (510, 198), 68: (200, 198), 70: 200, 71: sklearn.cross_validation.KFold(n=200, n_folds=63), 74: array([False, False, False, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), 75: (200,), 76: (200,), 77: array([[[ 0.      ,  0.      ,  0.      , ...,  0.160672,  0.054283,\n          0.060093],\n        [ 1.61    ,  0.12    ,  0.12    , ...,  0.246306,  0.448241,\n          0.377197],\n        [ 1.12    ,  0.31    ,  0.12    , ...,  0.281271,  0.484713,\n          0.431599],\n        ..., \n        [ 0.9     ,  0.19    ,  0.07    , ...,  0.119027,  0.084617,\n          0.074685],\n        [ 0.87    ,  0.22    ,  0.08    , ...,  0.122028,  0.058538,\n          0.080691],\n        [ 0.83    ,  0.25    ,  0.08    , ...,  0.125018,  0.043205,\n          0.088569]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.405808,  0.188892,\n          0.209284],\n        [ 0.95    , -0.18    ,  0.15    , ...,  0.42738 ,  0.348119,\n          0.34322 ],\n        [ 1.04    , -0.18    ,  0.15    , ...,  0.463135,  0.439758,\n          0.449271],\n        ..., \n        [ 0.87    , -0.01    ,  0.1     , ...,  0.447247,  0.132313,\n          0.208433],\n        [ 0.83    ,  0.      ,  0.05    , ...,  0.445714,  0.153232,\n          0.138243],\n        [ 0.97    , -0.05    ,  0.05    , ...,  0.445714,  0.155649,\n          0.138243]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.934708,  0.084538,\n          0.154596],\n        [ 2.75    ,  0.25    ,  0.      , ...,  0.859673,  0.675959,\n          0.553122],\n        [ 2.22    ,  0.24    ,  0.      , ...,  0.800801,  0.754047,\n          0.652951],\n        ..., \n        [ 6.09    , -0.13    ,  0.      , ...,  0.717239,  0.111535,\n          0.55109 ],\n        [ 6.22    , -0.13    ,  0.      , ...,  0.712795,  0.116218,\n          0.388987],\n        [ 5.75    , -0.17    ,  0.      , ...,  0.715292,  0.152665,\n          0.252609]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.199729,  0.051769,\n          0.117898],\n        [-3.29    ,  0.04    ,  0.24    , ...,  0.349317,  0.77501 ,\n          0.659621],\n        [-3.53    ,  0.06    ,  0.37    , ...,  0.460716,  1.013778,\n          0.894228],\n        ..., \n        [-2.21    ,  1.33    ,  0.5     , ...,  0.221407,  0.051251,\n          0.160312],\n        [-2.25    ,  1.27    ,  0.54    , ...,  0.203557,  0.054283,\n          0.14087 ],\n        [-2.42    ,  1.27    ,  0.53    , ...,  0.185629,  0.059889,\n          0.054874]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.52827 ,  0.128219,\n          0.104881],\n        [ 0.17    , -0.06    ,  0.      , ...,  0.520413,  0.180665,\n          0.150702],\n        [ 0.59    , -0.12    , -0.06    , ...,  0.520859,  0.288167,\n          0.243676],\n        ..., \n        [ 0.97    , -0.24    , -0.08    , ...,  0.296868,  0.023381,\n          0.264344],\n        [ 0.82    , -0.24    , -0.08    , ...,  0.297405,  0.037417,\n          0.211529],\n        [ 0.97    , -0.18    , -0.04    , ...,  0.298542,  0.037238,\n          0.132077]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.31634 ,  0.082624,\n          0.108628],\n        [-0.71    ,  0.26    ,  0.74    , ...,  0.307045,  0.20775 ,\n          0.205129],\n        [-1.06    ,  0.19    ,  0.74    , ...,  0.31471 ,  0.277897,\n          0.274672],\n        ..., \n        [-1.04    , -0.08    ,  0.12    , ...,  0.184709,  0.06532 ,  0.16    ],\n        [-0.95    , -0.19    ,  0.12    , ...,  0.178122,  0.028284,\n          0.152315],\n        [-0.84    , -0.18    ,  0.12    , ...,  0.173413,  0.054283,\n          0.123063]]]), 78: (510, 55, 442), 81: (510,), 83: (201,), 84: (309,), 85: (201,), 87: (200,), 88: (310,), 89: (200,), 90: (200,), 92: (200,), 93: (310,), 95: (510, 1), 102: 310, 104: (510,), 108: <matplotlib.text.Text object at 0x918f1d0>, 109: 198, 111: <matplotlib.text.Text object at 0x9894b90>, 113: <type 'list'>, 114: (310,), 116: -3.8199999999999998}, 'flatten': <function flatten at 0x2992b90>, 'gmail_pwd': 'hansolo8chewy', 'YEARLY': 0, 'digitize': <built-in function digitize>, 'clongfloat': <type 'numpy.complex256'>, 'ylim': <function ylim at 0x3195b90>, 'yscale': <function yscale at 0x3195c80>, 'inv': <function inv at 0x238c5f0>, 'ediff1d': <function ediff1d at 0x2369050>, 'pie': <function pie at 0x3197578>, '_i45': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,0))', 'char': <module 'numpy.core.defchararray' from '/usr/local/lib/python2.7/dist-packages/numpy/core/defchararray.pyc'>, 'single': <type 'numpy.float32'>, 'isposinf': <function isposinf at 0x2301500>, 'set_cmap': <function set_cmap at 0x3196398>, 'ScalarType': (<type 'int'>, <type 'float'>, <type 'complex'>, <type 'long'>, <type 'bool'>, <type 'str'>, <type 'unicode'>, <type 'buffer'>, <type 'numpy.float16'>, <type 'numpy.string_'>, <type 'numpy.float128'>, <type 'numpy.uint64'>, <type 'numpy.int16'>, <type 'numpy.timedelta64'>, <type 'numpy.object_'>, <type 'numpy.float64'>, <type 'numpy.int64'>, <type 'numpy.uint8'>, <type 'numpy.datetime64'>, <type 'numpy.complex256'>, <type 'numpy.float32'>, <type 'numpy.uint32'>, <type 'numpy.int8'>, <type 'numpy.void'>, <type 'numpy.complex128'>, <type 'numpy.uint64'>, <type 'numpy.int32'>, <type 'numpy.bool_'>, <type 'numpy.unicode_'>, <type 'numpy.complex64'>, <type 'numpy.int64'>, <type 'numpy.uint16'>), 'noncentral_f': <built-in method noncentral_f of mtrand.RandomState object at 0x7f399f841690>, 'triu': <function triu at 0x230d8c0>, 'inf': inf, 'fill': <function fill at 0x3197050>, 'expand_dims': <function expand_dims at 0x2374b90>, 'pareto': <built-in method pareto of mtrand.RandomState object at 0x7f399f841690>, 'logspace': <function logspace at 0x2270de8>, 'floor': <ufunc 'floor'>, 'polyadd': <function polyadd at 0x238d050>, 'TU': TU, 'nan': nan, 'modf': <ufunc 'modf'>, 'emath': <module 'numpy.lib.scimath' from '/usr/local/lib/python2.7/dist-packages/numpy/lib/scimath.pyc'>, 'arctan': <ufunc 'arctan'>, 'bmat': <function bmat at 0x2373cf8>, 'Slider': <class 'matplotlib.widgets.Slider'>, 'prism': <function prism at 0x3198938>, 'isclose': <function isclose at 0x21dbed8>, 'ERR_DEFAULT': 0, 'TH': TH, 'xscale': <function xscale at 0x3195c08>, '_i109': u'trainOutput.shape[2]', 'register_cmap': <function register_cmap at 0x2b80e60>, 'roll': <function roll at 0x21c2b90>, 'figsize': <function figsize at 0x1de18c0>, '_i70': u'len(target)', 'compare_chararrays': <built-in function compare_chararrays>, 'vsplit': <function vsplit at 0x2374ed8>, 'real_if_close': <function real_if_close at 0x2301a28>, 'repeat': <function repeat at 0x21d1848>, 'hamming': <function hamming at 0x236d2a8>, 'ALLOW_THREADS': 1, '_i66': u'trainOutput.shape', 'isInput': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True], '_12': (510, 55, 244), 'errorbar': <function errorbar at 0x3196ed8>, 'ravel_multi_index': <built-in function ravel_multi_index>, '_i67': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\nderiv.shape', 'string_': <type 'numpy.string_'>, 'isinf': <ufunc 'isinf'>, 'spacing': <ufunc 'spacing'>, 'Inf': inf, 'ndarray': <type 'numpy.ndarray'>, 'delaxes': <function delaxes at 0x3195398>, 'pcolor': <function pcolor at 0x3197488>, 'e': 2.718281828459045, 'ERR_CALL': 3, 'datetime_data': <built-in function datetime_data>, '_i79': u'X.shape', 'test': array([[ -2.90000000e-01,   2.85714000e-01,   7.00000000e+00, ...,\n          5.15190000e-01,   2.20786000e-01,   2.08753000e-01],\n       [  3.80000000e-01,   1.60000000e+00,   5.00000000e+00, ...,\n          8.83311000e-01,   4.69965000e-01,   5.36563000e-01],\n       [  2.00000000e-02,   1.11111000e-01,   9.00000000e+00, ...,\n          3.90504000e-01,   1.20665000e-01,   1.10905000e-01],\n       ..., \n       [  2.70000000e-01,   3.23529000e-01,   3.40000000e+01, ...,\n          1.79467000e-01,   8.55570000e-02,   8.33330000e-02],\n       [  0.00000000e+00,   2.94117000e-01,   1.70000000e+01, ...,\n          1.95387000e-01,   7.63330000e-02,   6.25390000e-02],\n       [  3.10000000e-01,   1.60000000e+00,   5.00000000e+00, ...,\n          1.05697000e+00,   4.11582000e-01,   4.52769000e-01]]), 'ERR_IGNORE': 0, 'flag': <function flag at 0x3198668>, 'hsplit': <function hsplit at 0x2374e60>, 'result_type': <built-in function result_type>, 'gradient': <function gradient at 0x236c578>, 'base_repr': <function base_repr at 0x21dbc80>, 'eigh': <function eigh at 0x238c938>, 'argwhere': <function argwhere at 0x21c2848>, 'set_string_function': <function set_string_function at 0x21dba28>, 'swapaxes': <function swapaxes at 0x21d1938>, 'FixedLocator': <class 'matplotlib.ticker.FixedLocator'>, '_111': <matplotlib.text.Text object at 0x9894b90>, 'tensorsolve': <function tensorsolve at 0x238c488>}\n   2828             finally:\n   2829                 # Reset our crash handler in place\n   2830                 sys.excepthook = old_excepthook\n   2831         except SystemExit:\n\n...........................................................................\n/home/lane/Kaggle/03 Predicting Stock Prices/<ipython-input-134-831b400e8055> in <module>()\n     27         results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\n     28 \n     29     performance.append(np.array(results).mean())\n     30 \n     31     # generate predictions (making sure to add last observed value back in)\n---> 32     predicted_probs = [x[1] for x in rf.predict_proba(test)]\n     33     thisColumn      = np.asarray(predicted_probs)\n     34     pred[:,stock]   = thisColumn + lastObserved[200:,stock]\n     35 \n     36     \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, compute_i...=False, random_state=None,\n            verbose=0), X=array([[ -2.89999992e-01,   2.85714000e-01,   7.....11581993e-01,   4.52769011e-01]], dtype=float32))\n    486             delayed(_parallel_predict_proba)(\n    487                 self.estimators_[starts[i]:starts[i + 1]],\n    488                 X,\n    489                 self.n_classes_,\n    490                 self.n_outputs_)\n--> 491             for i in range(n_jobs))\n        n_jobs = 2\n    492 \n    493         # Reduce\n    494         proba = all_proba[0]\n    495 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object <genexpr>>)\n    514         self.n_dispatched = 0\n    515         try:\n    516             for function, args, kwargs in iterable:\n    517                 self.dispatch(function, args, kwargs)\n    518 \n--> 519             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    520             # Make sure that we get a last message telling us we are done\n    521             elapsed_time = time.time() - self._start_time\n    522             self._print('Done %3i out of %3i | elapsed: %s finished',\n    523                         (len(self._output),\n\n    ---------------------------------------------------------------------------\n    Sub-process traceback:\n    ---------------------------------------------------------------------------\n    ValueError                                         Wed Oct  2 10:04:55 2013\nPID: 21086                                    Python 2.7.3: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.pyc in _parallel_predict_proba(trees=[DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f0d8>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f0c0>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f138>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f180>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f150>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f210>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f078>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f0a8>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f090>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f030>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f048>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f108>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f0f0>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f168>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f120>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f228>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f240>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f258>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f270>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f288>,\n            splitter='best'), ...], X=array([[ -2.89999992e-01,   2.85714000e-01,   7.....11581993e-01,   4.52769011e-01]], dtype=float32), n_classes=172, n_outputs=1)\n    115 \n    116     if n_outputs == 1:\n    117         proba = np.zeros((n_samples, n_classes))\n    118 \n    119         for tree in trees:\n--> 120             proba_tree = tree.predict_proba(X)\n    121 \n    122             if n_classes == tree.n_classes_:\n    123                 proba += proba_tree\n    124 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.pyc in predict_proba(self=DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f0d8>,\n            splitter='best'), X=array([[ -2.89999992e-01,   2.85714000e-01,   7.....11581993e-01,   4.52769011e-01]], dtype=float32))\n    470 \n    471         if self.n_features_ != n_features:\n    472             raise ValueError(\"Number of features of the model must \"\n    473                              \" match the input. Model n_features is %s and \"\n    474                              \" input n_features is %s \"\n--> 475                              % (self.n_features_, n_features))\n    476 \n    477         proba = self.tree_.predict(X)\n    478 \n    479         if self.n_outputs_ == 1:\n\nValueError: Number of features of the model must  match the input. Model n_features is 1003 and  input n_features is 2197 \n___________________________________________________________________________",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-134-831b400e8055>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# generate predictions (making sure to add last observed value back in)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mpredicted_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mthisColumn\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_probs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstock\u001b[0m\u001b[1;33m]\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mthisColumn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlastObserved\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstock\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    489\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m                 self.n_outputs_)\n\u001b[1;32m--> 491\u001b[1;33m             for i in range(n_jobs))\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[1;31m# Reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    517\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    448\u001b[0m                         \u001b[1;31m# Convert this to a JoblibException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m                         \u001b[0mexception_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mk_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n    ...........................................................................\n/home/lane/Kaggle/03 Predicting Stock Prices/<string> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/kernel/zmq/kernelapp.py in main()\n    463 \n    464 def main():\n    465     \"\"\"Run an IPKernel as an application\"\"\"\n    466     app = IPKernelApp.instance()\n    467     app.initialize()\n--> 468     app.start()\n        app.start = <bound method IPKernelApp.start of <IPython.kernel.zmq.kernelapp.IPKernelApp object at 0x269ac90>>\n    469 \n    470 \n    471 if __name__ == '__main__':\n    472     main()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/kernel/zmq/kernelapp.py in start(self=<IPython.kernel.zmq.kernelapp.IPKernelApp object>)\n    453     def start(self):\n    454         if self.poller is not None:\n    455             self.poller.start()\n    456         self.kernel.start()\n    457         try:\n--> 458             ioloop.IOLoop.instance().start()\n    459         except KeyboardInterrupt:\n    460             pass\n    461 \n    462 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    177         self._waker.close()\n    178         self._impl.close()\n    179     \n    180     def start(self):\n    181         try:\n--> 182             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object at 0x2720a50>>\n    183         except ZMQError as e:\n    184             if e.errno == ETERM:\n    185                 # quietly return on ETERM\n    186                 pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    667             # this IOLoop that update self._events\n    668             self._events.update(event_pairs)\n    669             while self._events:\n    670                 fd, events = self._events.popitem()\n    671                 try:\n--> 672                     self._handlers[fd](fd, events)\n        self._handlers = {<zmq.sugar.socket.Socket object at 0x2714e88>: <function wrapped at 0x2725758>, 65: <function wrapped at 0x27256e0>, <zmq.sugar.socket.Socket object at 0x271f050>: <function wrapped at 0x27257d0>}\n        fd = <zmq.sugar.socket.Socket object at 0x2714e88>\n        events = 1\n    673                 except (OSError, IOError) as e:\n    674                     if e.args[0] == errno.EPIPE:\n    675                         # Happens when the client closes the connection\n    676                         pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in wrapped(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    297                     top = n.old_contexts[1]\n    298 \n    299             # Execute callback if no exception happened while restoring state\n    300             if top is None:\n    301                 try:\n--> 302                     ret = fn(*args, **kwargs)\n        ret = None\n        args = (<zmq.sugar.socket.Socket object at 0x2714e88>, 1)\n        kwargs = {}\n    303                 except:\n    304                     exc = sys.exc_info()\n    305                     top = contexts[1]\n    306 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    422             # dispatch events:\n    423             if events & IOLoop.ERROR:\n    424                 logging.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    425                 return\n    426             if events & IOLoop.READ:\n--> 427                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object at 0x2720a10>>\n    428                 if not self.socket:\n    429                     return\n    430             if events & IOLoop.WRITE:\n    431                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    454                 logging.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    455         else:\n    456             if self._recv_callback:\n    457                 callback = self._recv_callback\n    458                 # self._recv_callback = None\n--> 459                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object at 0x2720a10>>\n        callback = <zmq.eventloop.minitornado.stack_context._StackContextWrapper object at 0x3250aa0>\n        msg = [<zmq.core.message.Frame object at 0x3b9c218>, <zmq.core.message.Frame object at 0x3b77cc8>, <zmq.core.message.Frame object at 0x3b773e0>, <zmq.core.message.Frame object at 0x3b77f28>, <zmq.core.message.Frame object at 0x32358a0>, <zmq.core.message.Frame object at 0x3235808>, <zmq.core.message.Frame object at 0x3235218>]\n    460                 \n    461         # self.update_state()\n    462         \n    463 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<zmq.eventloop.minitornado.stack_context._StackContextWrapper object>, *args=([<zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>],), **kwargs={})\n    396         close our socket.\"\"\"\n    397         try:\n    398             # Use a NullContext to ensure that all StackContexts are run\n    399             # inside our blanket exception handler rather than outside.\n    400             with stack_context.NullContext():\n--> 401                 callback(*args, **kwargs)\n        callback = <zmq.eventloop.minitornado.stack_context._StackContextWrapper object at 0x3250aa0>\n        args = ([<zmq.core.message.Frame object at 0x3b9c218>, <zmq.core.message.Frame object at 0x3b77cc8>, <zmq.core.message.Frame object at 0x3b773e0>, <zmq.core.message.Frame object at 0x3b77f28>, <zmq.core.message.Frame object at 0x32358a0>, <zmq.core.message.Frame object at 0x3235808>, <zmq.core.message.Frame object at 0x3235218>],)\n        kwargs = {}\n    402         except:\n    403             logging.error(\"Uncaught exception, closing connection.\",\n    404                           exc_info=True)\n    405             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/minitornado/stack_context.py in wrapped(*args=([<zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>],), **kwargs={})\n    236                 callback(*args, **kwargs)\n    237         elif new_contexts:\n    238             with new_contexts[0]:\n    239                 callback(*args, **kwargs)\n    240         else:\n--> 241             callback(*args, **kwargs)\n        callback = <function dispatcher at 0x325cc80>\n        args = ([<zmq.core.message.Frame object at 0x3b9c218>, <zmq.core.message.Frame object at 0x3b77cc8>, <zmq.core.message.Frame object at 0x3b773e0>, <zmq.core.message.Frame object at 0x3b77f28>, <zmq.core.message.Frame object at 0x32358a0>, <zmq.core.message.Frame object at 0x3235808>, <zmq.core.message.Frame object at 0x3235218>],)\n        kwargs = {}\n    242     return _StackContextWrapper(wrapped, fn, _state.contexts)\n    243 \n    244 \n    245 @contextlib.contextmanager\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/kernel/zmq/ipkernel.py in dispatcher(msg=[<zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>, <zmq.core.message.Frame object>])\n    268         if self.control_stream:\n    269             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    270 \n    271         def make_dispatcher(stream):\n    272             def dispatcher(msg):\n--> 273                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.core.message.Frame object at 0x3b9c218>, <zmq.core.message.Frame object at 0x3b77cc8>, <zmq.core.message.Frame object at 0x3b773e0>, <zmq.core.message.Frame object at 0x3b77f28>, <zmq.core.message.Frame object at 0x32358a0>, <zmq.core.message.Frame object at 0x3235808>, <zmq.core.message.Frame object at 0x3235218>]\n    274             return dispatcher\n    275 \n    276         for s in self.shell_streams:\n    277             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/kernel/zmq/ipkernel.py in dispatch_shell(self=<IPython.kernel.zmq.ipkernel.Kernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'numStocks   = trainOutput.shape[2]\\npred        =...server.close() #closing the mailserver connection', 'silent': False, 'store_history': True, 'user_expressions': {}, 'user_variables': []}, 'header': {'msg_id': 'C0539C4A707F42009C5F3E5BBA21EFF8', 'msg_type': 'execute_request', 'session': 'FB28E85968364D02A146C50943F5C28E', 'username': 'username'}, 'metadata': {}, 'msg_id': 'C0539C4A707F42009C5F3E5BBA21EFF8', 'msg_type': 'execute_request', 'parent_header': {}})\n    236             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    237         else:\n    238             # ensure default_int_handler during handler call\n    239             sig = signal(SIGINT, default_int_handler)\n    240             try:\n--> 241                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <IPython.kernel.zmq.ipkernel.Kernel object at 0x2720e90>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object at 0x2720a10>\n        idents = ['FB28E85968364D02A146C50943F5C28E']\n        msg = {'parent_header': {}, 'msg_type': 'execute_request', 'msg_id': 'C0539C4A707F42009C5F3E5BBA21EFF8', 'content': {'user_variables': [], 'code': 'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'silent': False, 'allow_stdin': True, 'store_history': True, 'user_expressions': {}}, 'header': {'username': 'username', 'msg_id': 'C0539C4A707F42009C5F3E5BBA21EFF8', 'msg_type': 'execute_request', 'session': 'FB28E85968364D02A146C50943F5C28E'}, 'buffers': [], 'metadata': {}}\n    242             except Exception:\n    243                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    244             finally:\n    245                 signal(SIGINT, sig)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/kernel/zmq/ipkernel.py in execute_request(self=<IPython.kernel.zmq.ipkernel.Kernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['FB28E85968364D02A146C50943F5C28E'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'numStocks   = trainOutput.shape[2]\\npred        =...server.close() #closing the mailserver connection', 'silent': False, 'store_history': True, 'user_expressions': {}, 'user_variables': []}, 'header': {'msg_id': 'C0539C4A707F42009C5F3E5BBA21EFF8', 'msg_type': 'execute_request', 'session': 'FB28E85968364D02A146C50943F5C28E', 'username': 'username'}, 'metadata': {}, 'msg_id': 'C0539C4A707F42009C5F3E5BBA21EFF8', 'msg_type': 'execute_request', 'parent_header': {}})\n    385             self._publish_pyin(code, parent, shell.execution_count)\n    386 \n    387         reply_content = {}\n    388         try:\n    389             # FIXME: the shell calls the exception handler itself.\n--> 390             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object at 0x2720f90>>\n        code = 'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection'\n        store_history = True\n        silent = False\n    391         except:\n    392             status = u'error'\n    393             # FIXME: this code right now isn't being used yet by default,\n    394             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/core/interactiveshell.py in run_cell(self=<IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object>, raw_cell='numStocks   = trainOutput.shape[2]\\npred        =...server.close() #closing the mailserver connection', store_history=True, silent=False, shell_futures=True)\n   2662                     \n   2663                     code_ast = self.transform_ast(code_ast)\n   2664                     \n   2665                     interactivity = \"none\" if silent else self.ast_node_interactivity\n   2666                     self.run_ast_nodes(code_ast.body, cell_name,\n-> 2667                                        interactivity=interactivity, compiler=compiler)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance at 0x272bcb0>\n   2668                     \n   2669                     # Execute any registered post-execution functions.\n   2670                     # unless we are silent\n   2671                     post_exec = [] if silent else self._post_execute.iteritems()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/core/interactiveshell.py in run_ast_nodes(self=<IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.For object>, <_ast.Print object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.For object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, ...], cell_name='<ipython-input-134-831b400e8055>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>)\n   2766 \n   2767         try:\n   2768             for i, node in enumerate(to_run_exec):\n   2769                 mod = ast.Module([node])\n   2770                 code = compiler(mod, cell_name, \"exec\")\n-> 2771                 if self.run_code(code):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object at 0x2720f90>>\n        code = <code object <module> at 0x7f394b7ac730, file \"<ipython-input-134-831b400e8055>\", line 4>\n   2772                     return True\n   2773 \n   2774             for i, node in enumerate(to_run_interactive):\n   2775                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/core/interactiveshell.py in run_code(self=<IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f394b7ac730, file \"<ipython-input-134-831b400e8055>\", line 4>)\n   2822         outflag = 1  # happens in more places, so it's easier as default\n   2823         try:\n   2824             try:\n   2825                 self.hooks.pre_run_code_hook()\n   2826                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2827                 exec code_obj in self.user_global_ns, self.user_ns\n        code_obj = <code object <module> at 0x7f394b7ac730, file \"<ipython-input-134-831b400e8055>\", line 4>\n        self.user_global_ns = {'disp': <function disp at 0x236cd70>, 'union1d': <function union1d at 0x236c0c8>, 'all': <function all at 0x21da398>, '_i132': u'sheet.shape', 'dist': <function dist at 0x2c51758>, 'issubsctype': <function issubsctype at 0x21b8f50>, 'sca': <function sca at 0x3195410>, 'savez': <function savez at 0x23fb1b8>, '_i58': u\"fig = gcf()\\nfig.set_size_inches(16,6)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", 'entropy': <function entropy at 0x2c4fe60>, 'atleast_2d': <function atleast_2d at 0x2274668>, 'restoredot': <built-in function restoredot>, '_95': (510, 1), 'streamplot': <function streamplot at 0x3197b90>, '_93': (310,), '_92': (200,), 'ptp': <function ptp at 0x21da500>, 'Subplot': <class 'matplotlib.axes.AxesSubplot'>, 'frange': <function frange at 0x2c52050>, 'PackageLoader': <class 'numpy._import_tools.PackageLoader'>, 'show': <function show at 0x3194398>, '_83': (201,), 'fft2': <function fft2 at 0x2409320>, '_63': <matplotlib.text.Text object at 0x8d13e90>, 'xkcd': <function xkcd at 0x3194848>, 'rec2csv': <function rec2csv at 0x2c535f0>, 'ix_': <function ix_ at 0x236db18>, 'resize': <function resize at 0x21d1c80>, '_64': <matplotlib.text.Text object at 0x9b88ad0>, 'blackman': <function blackman at 0x236d140>, '_68': (200, 198), 'norm': <function norm at 0x238ccf8>, 'FLOATING_POINT_SUPPORT': 1, '_i85': u'train.shape', 'MultipleLocator': <class 'matplotlib.ticker.MultipleLocator'>, 'mlab': <module 'matplotlib.mlab' from '/usr/local/lib/python2.7/dist-packages/matplotlib/mlab.pyc'>, 'busdaycalendar': <type 'numpy.busdaycalendar'>, 'pkgload': <function pkgload at 0x2107050>, 'mpl': <module 'matplotlib' from '/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc'>, 'rc': <function rc at 0x3194668>, 'thetagrids': <function thetagrids at 0x3195f50>, 'results': [0.40249999999999986, 0.3805, 1.05975, 0.6737500000000001, 0.6269999999999998, 0.41200000000000003, 0.9955, 0.38125000000000003, 0.6900000000000002, 0.8010000000000002, 0.6927500000000002, 0.9587500000000002, 1.095, 1.0350000000000001, 0.975, 0.6989999999999998, 0.7677500000000002, 0.48375, 0.6754999999999998, 1.056, 0.9384999999999999, 0.5549999999999999, 0.48974999999999996, 0.7722500000000001, 0.70925], '_104': (510,), '_i114': u'yoda = np.asarray(predicted_probs)\\nyoda.shape', 'ERR_RAISE': 2, '_i61': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('yoda')\", 'testcv': array([False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), 'cool': <function cool at 0x3198578>, 'tri': <function tri at 0x230d7d0>, 'lapack_lite': <module 'numpy.linalg.lapack_lite' from '/usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so'>, 'diag_indices': <function diag_indices at 0x23748c0>, 'window_hanning': <function window_hanning at 0x2c4f578>, 'array_equal': <function array_equal at 0x21dbf50>, 'FormatStrFormatter': <class 'matplotlib.ticker.FormatStrFormatter'>, '_i25': u'target.shape', '_i22': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(target[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'tanh': <ufunc 'tanh'>, 'longest_contiguous_ones': <function longest_contiguous_ones at 0x2c510c8>, 'get_plot_commands': <function get_plot_commands at 0x31960c8>, 'uint32': <type 'numpy.uint32'>, 'array_equiv': <function array_equiv at 0x21dd050>, '_i12': u'trainInput.shape', 'fftn': <function fftn at 0x2409230>, '_i10': u'len(target)', '_i17': u'trainInput[509,54,244]', '_i16': u'trainInput[509,54,243]', '_i15': u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:198] = trainOutput\\nfullInput[:,:,198:] = trainInput', '_i14': u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:197] = trainOutput\\nfullInput[:,:,198:] = trainInput', 'indices': <function indices at 0x21dbaa0>, 'fftpack': <module 'numpy.fft.fftpack' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack.pyc'>, 'loads': <built-in function loads>, '_i18': u'trainInput[509,54,243]', '_ii': u'sheet.shape', 'set_numeric_ops': <built-in function set_numeric_ops>, '_114': (310,), 'pmt': <function pmt at 0x23fbc08>, 'polar': <function polar at 0x3196578>, 'diag_indices_from': <function diag_indices_from at 0x2374938>, 'object0': <type 'numpy.object_'>, 'ishold': <function ishold at 0x3195230>, 'rate': <function rate at 0x23fbf50>, 'FPE_OVERFLOW': 2, 'Circle': <class 'matplotlib.patches.Circle'>, 'index_exp': <numpy.lib.index_tricks.IndexExpression object at 0x236fa50>, 'append': <function append at 0x236da28>, 'logseries': <built-in method logseries of mtrand.RandomState object at 0x7f399f841690>, '_i128': u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=500, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=25, indices=False)', '_i129': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', 'nanargmax': <function nanargmax at 0x236ccf8>, 'hstack': <function hstack at 0x22747d0>, 'typename': <function typename at 0x2301b18>, 'YearLocator': <class 'matplotlib.dates.YearLocator'>, 'diag': <function diag at 0x230d6e0>, 'pyplot': <module 'matplotlib.pyplot' from '/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc'>, 'axes': <function axes at 0x3195320>, 'ERR_WARN': 1, '_i127': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'unravel_index': <built-in function unravel_index>, 'uniform': <built-in method uniform of mtrand.RandomState object at 0x7f399f841690>, 'polyfit': <function polyfit at 0x238ced8>, 'nanmin': <function nanmin at 0x236cb90>, 'memmap': <class 'numpy.core.memmap.memmap'>, 'axvline': <function axvline at 0x31969b0>, '_90': (200,), 'irfftn': <function irfftn at 0x2409500>, 'nan_to_num': <function nan_to_num at 0x23019b0>, 'twinx': <function twinx at 0x3195668>, 'contourf': <function contourf at 0x3196de8>, 'complex64': <type 'numpy.complex64'>, 'deriv': array([[ 0.04,  0.04, -0.02, ...,  0.  ,  0.02, -0.04],\n       [-0.11, -0.04,  0.02, ..., -0.11, -0.04, -0.08],\n       [-0.08,  0.02, -0.02, ..., -0.02, -0.02, -0.06],\n       ..., \n       [ 0.27,  0.02,  0.  , ...,  0.25,  0.15, -0.04],\n       [ 0.  , -0.01,  0.  , ..., -0.05,  0.02,  0.  ],\n       [ 0.31,  0.  , -0.03, ...,  0.04,  0.02,  0.06]]), '_i34': u'target.shape', 'fmax': <ufunc 'fmax'>, 'copysign': <ufunc 'copysign'>, 'matplotlib': <module 'matplotlib' from '/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc'>, 'l2norm': <function l2norm at 0x2c51ed8>, 'FigureCanvasBase': <class 'matplotlib.backend_bases.FigureCanvasBase'>, 'sinh': <ufunc 'sinh'>, 'unicode_': <type 'numpy.unicode_'>, 'rgrids': <function rgrids at 0x3195ed8>, 'legend': <function legend at 0x31980c8>, 'trunc': <ufunc 'trunc'>, 'box': <function box at 0x31958c0>, 'vstack': <function vstack at 0x2274758>, 'finfo': <class 'numpy.core.getlimits.finfo'>, 'ERR_PRINT': 4, 'levypdf': <function levypdf at 0x2c4ff50>, 'IndexDateFormatter': <class 'matplotlib.dates.IndexDateFormatter'>, 'MO': MO, 'asscalar': <function asscalar at 0x2301aa0>, 'LogLocator': <class 'matplotlib.ticker.LogLocator'>, 'binomial': <built-in method binomial of mtrand.RandomState object at 0x7f399f841690>, 'broken_barh': <function broken_barh at 0x3196b90>, 'poisson': <built-in method poisson of mtrand.RandomState object at 0x7f399f841690>, 'HourLocator': <class 'matplotlib.dates.HourLocator'>, 'less_equal': <ufunc 'less_equal'>, 'l1norm': <function l1norm at 0x2c51e60>, 'BUFSIZE': 8192, 'sci': <function sci at 0x31947d0>, 'object_': <type 'numpy.object_'>, 'FR': FR, 'shuffle': <built-in method shuffle of mtrand.RandomState object at 0x7f399f841690>, 'divide': <ufunc 'divide'>, 'csingle': <type 'numpy.complex64'>, 'dtype': <type 'numpy.dtype'>, 'unsignedinteger': <type 'numpy.unsignedinteger'>, '_i110': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'fftshift': <function fftshift at 0x2409668>, 'fastCopyAndTranspose': <built-in function _fastCopyAndTranspose>, 'num2date': <function num2date at 0x307d0c8>, 'silent_list': <class 'matplotlib.cbook.silent_list'>, 'bitwise_and': <ufunc 'bitwise_and'>, 'uintc': <type 'numpy.uint32'>, '_i30': u'lastObserved = trainOutput[:,-1,:]\\nlastObserved.shape', 'byte': <type 'numpy.int8'>, 'select': <function select at 0x236c488>, 'ticklabel_format': <function ticklabel_format at 0x31982a8>, 'deg2rad': <ufunc 'deg2rad'>, 'plot': <function plot at 0x31975f0>, 'nditer': <type 'numpy.nditer'>, 'eye': <function eye at 0x230d668>, 'triu_indices': <function triu_indices at 0x230db90>, 'kron': <function kron at 0x2377140>, 'newbuffer': <built-in function newbuffer>, '_i86': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:200]\\ntest  = X[200:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'pred': array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       ..., \n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]]), 'negative': <ufunc 'negative'>, 'busday_offset': <built-in function busday_offset>, 'mintypecode': <function mintypecode at 0x2301410>, 'standard_gamma': <built-in method standard_gamma of mtrand.RandomState object at 0x7f399f841690>, 'lstsq': <function lstsq at 0x238cc80>, 'print_function': _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 65536), 'header': 'To:lanemcintosh@gmail.com\\nFrom: mcintoshlane@gmail.com\\nSubject:Kaggle iPython Notebook \\n', '_26': (200, 198), '_27': (510, 55, 244), '_24': 55, '_25': (200, 198), 'MAXDIMS': 32, 'clabel': <function clabel at 0x3196cf8>, 'setxor1d': <function setxor1d at 0x2369f50>, '_21': (510, 55, 442), 'rk4': <function rk4 at 0x2c51578>, 'fftfreq': <function fftfreq at 0x2409758>, 'ifft2': <function ifft2 at 0x2409398>, 'longdouble': <type 'numpy.float128'>, 'uint0': <type 'numpy.uint64'>, 'zeros_like': <function zeros_like at 0x21c2398>, '_i62': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',norm=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_i63': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',normed=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_i60': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nyaxis('yoda')\", 'ylabel': <function ylabel at 0x3195aa0>, 'int_asbuffer': <built-in function int_asbuffer>, 'uint8': <type 'numpy.uint8'>, '_i64': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_i65': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", 'chararray': <class 'numpy.core.defchararray.chararray'>, 'train': array([[  0.04    ,   1.5     ,   2.      , ...,   0.439681,   0.074476,\n          0.142166],\n       [ -0.11    ,   0.789473,  19.      , ...,   0.767666,   0.147196,\n          0.272029],\n       [ -0.08    ,   0.5     ,  12.      , ...,   0.216333,   0.062503,\n          0.062272],\n       ..., \n       [ -0.17    ,   0.222222,   9.      , ...,   0.405073,   0.133066,\n          0.126095],\n       [  0.15    ,  -0.2     ,  10.      , ...,   0.32209 ,   0.127541,\n          0.195192],\n       [  0.11    ,   0.      ,  10.      , ...,   0.232735,   0.130486,\n          0.113186]]), 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'linspace': <function linspace at 0x2270d70>, '_i32': u'normTarget   = target - lastObserved[:target.shape[0],:]', 'hold': <function hold at 0x31951b8>, 'mirr': <function mirr at 0x23fe140>, 'uint64': <type 'numpy.uint64'>, 'sample': <built-in method random_sample of mtrand.RandomState object at 0x7f399f841690>, 'ma': <module 'numpy.ma' from '/usr/local/lib/python2.7/dist-packages/numpy/ma/__init__.pyc'>, 'err': <module 'meanAbsoluteError' from 'meanAbsoluteError.pyc'>, 'f': <built-in method f of mtrand.RandomState object at 0x7f399f841690>, 'hist2d': <function hist2d at 0x31972a8>, 'Text': <class 'matplotlib.text.Text'>, 'isneginf': <function isneginf at 0x2301578>, 'true_divide': <ufunc 'true_divide'>, 'det': <function det at 0x238cc08>, 'SU': SU, 'DateLocator': <class 'matplotlib.dates.DateLocator'>, '_i122': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', '_i8': u'len(trainOutput)', 'thisColumn': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.07301677,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.07301677,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.07301677,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.07301677,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.07301677,  0.07301677,  0.        ,  0.        ]), 'SA': SA, 'rc_context': <function rc_context at 0x31946e0>, 'scatter': <function scatter at 0x3197848>, 'Out': {8: 510, 10: 200, 12: (510, 55, 244), 13: (510, 55, 198), 16: 0.32388299999999998, 18: 0.32388299999999998, 19: 0.32388299999999998, 21: (510, 55, 442), 23: (510, 55, 198), 24: 55, 25: (200, 198), 26: (200, 198), 27: (510, 55, 244), 30: (510, 198), 31: (200, 198), 33: (200, 198), 34: (200, 198), 35: [<matplotlib.lines.Line2D object at 0x3c0f110>], 36: [<matplotlib.lines.Line2D object at 0x3df1610>], 37: (array([   3.,   11.,   42.,  112.,   26.,    4.,    0.,    0.,    0.,    2.]), array([-2.12 , -1.478, -0.836, -0.194,  0.448,  1.09 ,  1.732,  2.374,\n        3.016,  3.658,  4.3  ]), <a list of 10 Patch objects>), 38: ([array([   0.,    0.,    0.,   11.,  179.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  189.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  189.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  194.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  188.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  191.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   12.,  181.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  193.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   23.,  158.,   11.,    2.,    0.,    2.,    0.]), array([   2.,    0.,    2.,   16.,  159.,   19.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  196.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  187.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  192.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  194.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  184.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  192.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    3.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   1.,    0.,    2.,   28.,  148.,   17.,    3.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  186.,    9.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  184.,    2.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  177.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,    7.,  186.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   20.,  168.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    2.,    0.,   15.,  167.,   16.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    0.,   14.,  167.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,   16.,  165.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   14.,  182.,    2.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    3.,   26.,  153.,   16.,    0.,    0.,    2.,    0.]), array([   3.,    1.,    7.,   46.,  102.,   26.,    8.,    3.,    2.,    2.]), array([   0.,    2.,    0.,   12.,  176.,   10.,    0.,    0.,    0.,    0.]), array([   2.,    0.,    1.,   20.,  155.,   18.,    4.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  181.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  184.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  189.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  182.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   11.,  182.,    6.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  184.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   22.,  166.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  195.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    3.,  193.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  190.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  196.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   29.,  140.,   21.,    4.,    2.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  190.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    3.,   31.,  144.,   17.,    3.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  193.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  188.,    4.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.])], array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 198 Lists of Patches objects>), 44: (200, 198), 52: (array([  8.00000000e+00,   9.00000000e+00,   3.80000000e+01,\n         8.42000000e+02,   3.81220000e+04,   5.27000000e+02,\n         3.80000000e+01,   8.00000000e+00,   6.00000000e+00,\n         2.00000000e+00]), array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 10 Patch objects>), 53: (array([  2.00000000e+00,   0.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         1.00000000e+00,   2.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         2.00000000e+00,   7.00000000e+00,   3.00000000e+00,\n         4.00000000e+00,   7.00000000e+00,   8.00000000e+00,\n         2.20000000e+01,   2.00000000e+01,   1.30000000e+01,\n         2.40000000e+01,   5.30000000e+01,   5.30000000e+01,\n         8.10000000e+01,   1.17000000e+02,   1.68000000e+02,\n         2.91000000e+02,   5.90000000e+02,   1.25600000e+03,\n         2.75800000e+03,   8.53900000e+03,   1.52450000e+04,\n         6.19300000e+03,   1.99500000e+03,   9.18000000e+02,\n         4.14000000e+02,   2.14000000e+02,   1.21000000e+02,\n         1.11000000e+02,   7.50000000e+01,   6.70000000e+01,\n         3.50000000e+01,   3.70000000e+01,   3.00000000e+01,\n         2.50000000e+01,   2.00000000e+01,   6.00000000e+00,\n         7.00000000e+00,   6.00000000e+00,   9.00000000e+00,\n         4.00000000e+00,   3.00000000e+00,   1.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n         3.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         3.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         1.00000000e+00]), array([-15.55  , -15.1994, -14.8488, -14.4982, -14.1476, -13.797 ,\n       -13.4464, -13.0958, -12.7452, -12.3946, -12.044 , -11.6934,\n       -11.3428, -10.9922, -10.6416, -10.291 ,  -9.9404,  -9.5898,\n        -9.2392,  -8.8886,  -8.538 ,  -8.1874,  -7.8368,  -7.4862,\n        -7.1356,  -6.785 ,  -6.4344,  -6.0838,  -5.7332,  -5.3826,\n        -5.032 ,  -4.6814,  -4.3308,  -3.9802,  -3.6296,  -3.279 ,\n        -2.9284,  -2.5778,  -2.2272,  -1.8766,  -1.526 ,  -1.1754,\n        -0.8248,  -0.4742,  -0.1236,   0.227 ,   0.5776,   0.9282,\n         1.2788,   1.6294,   1.98  ,   2.3306,   2.6812,   3.0318,\n         3.3824,   3.733 ,   4.0836,   4.4342,   4.7848,   5.1354,\n         5.486 ,   5.8366,   6.1872,   6.5378,   6.8884,   7.239 ,\n         7.5896,   7.9402,   8.2908,   8.6414,   8.992 ,   9.3426,\n         9.6932,  10.0438,  10.3944,  10.745 ,  11.0956,  11.4462,\n        11.7968,  12.1474,  12.498 ,  12.8486,  13.1992,  13.5498,\n        13.9004,  14.251 ,  14.6016,  14.9522,  15.3028,  15.6534,\n        16.004 ,  16.3546,  16.7052,  17.0558,  17.4064,  17.757 ,\n        18.1076,  18.4582,  18.8088,  19.1594,  19.51  ]), <a list of 100 Patch objects>), 61: <matplotlib.text.Text object at 0x8c45410>, 63: <matplotlib.text.Text object at 0x8d13e90>, 64: <matplotlib.text.Text object at 0x9b88ad0>, 65: <matplotlib.text.Text object at 0x92e02d0>, 66: (510, 55, 198), 67: (510, 198), 68: (200, 198), 70: 200, 71: sklearn.cross_validation.KFold(n=200, n_folds=63), 74: array([False, False, False, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), 75: (200,), 76: (200,), 77: array([[[ 0.      ,  0.      ,  0.      , ...,  0.160672,  0.054283,\n          0.060093],\n        [ 1.61    ,  0.12    ,  0.12    , ...,  0.246306,  0.448241,\n          0.377197],\n        [ 1.12    ,  0.31    ,  0.12    , ...,  0.281271,  0.484713,\n          0.431599],\n        ..., \n        [ 0.9     ,  0.19    ,  0.07    , ...,  0.119027,  0.084617,\n          0.074685],\n        [ 0.87    ,  0.22    ,  0.08    , ...,  0.122028,  0.058538,\n          0.080691],\n        [ 0.83    ,  0.25    ,  0.08    , ...,  0.125018,  0.043205,\n          0.088569]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.405808,  0.188892,\n          0.209284],\n        [ 0.95    , -0.18    ,  0.15    , ...,  0.42738 ,  0.348119,\n          0.34322 ],\n        [ 1.04    , -0.18    ,  0.15    , ...,  0.463135,  0.439758,\n          0.449271],\n        ..., \n        [ 0.87    , -0.01    ,  0.1     , ...,  0.447247,  0.132313,\n          0.208433],\n        [ 0.83    ,  0.      ,  0.05    , ...,  0.445714,  0.153232,\n          0.138243],\n        [ 0.97    , -0.05    ,  0.05    , ...,  0.445714,  0.155649,\n          0.138243]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.934708,  0.084538,\n          0.154596],\n        [ 2.75    ,  0.25    ,  0.      , ...,  0.859673,  0.675959,\n          0.553122],\n        [ 2.22    ,  0.24    ,  0.      , ...,  0.800801,  0.754047,\n          0.652951],\n        ..., \n        [ 6.09    , -0.13    ,  0.      , ...,  0.717239,  0.111535,\n          0.55109 ],\n        [ 6.22    , -0.13    ,  0.      , ...,  0.712795,  0.116218,\n          0.388987],\n        [ 5.75    , -0.17    ,  0.      , ...,  0.715292,  0.152665,\n          0.252609]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.199729,  0.051769,\n          0.117898],\n        [-3.29    ,  0.04    ,  0.24    , ...,  0.349317,  0.77501 ,\n          0.659621],\n        [-3.53    ,  0.06    ,  0.37    , ...,  0.460716,  1.013778,\n          0.894228],\n        ..., \n        [-2.21    ,  1.33    ,  0.5     , ...,  0.221407,  0.051251,\n          0.160312],\n        [-2.25    ,  1.27    ,  0.54    , ...,  0.203557,  0.054283,\n          0.14087 ],\n        [-2.42    ,  1.27    ,  0.53    , ...,  0.185629,  0.059889,\n          0.054874]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.52827 ,  0.128219,\n          0.104881],\n        [ 0.17    , -0.06    ,  0.      , ...,  0.520413,  0.180665,\n          0.150702],\n        [ 0.59    , -0.12    , -0.06    , ...,  0.520859,  0.288167,\n          0.243676],\n        ..., \n        [ 0.97    , -0.24    , -0.08    , ...,  0.296868,  0.023381,\n          0.264344],\n        [ 0.82    , -0.24    , -0.08    , ...,  0.297405,  0.037417,\n          0.211529],\n        [ 0.97    , -0.18    , -0.04    , ...,  0.298542,  0.037238,\n          0.132077]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.31634 ,  0.082624,\n          0.108628],\n        [-0.71    ,  0.26    ,  0.74    , ...,  0.307045,  0.20775 ,\n          0.205129],\n        [-1.06    ,  0.19    ,  0.74    , ...,  0.31471 ,  0.277897,\n          0.274672],\n        ..., \n        [-1.04    , -0.08    ,  0.12    , ...,  0.184709,  0.06532 ,  0.16    ],\n        [-0.95    , -0.19    ,  0.12    , ...,  0.178122,  0.028284,\n          0.152315],\n        [-0.84    , -0.18    ,  0.12    , ...,  0.173413,  0.054283,\n          0.123063]]]), 78: (510, 55, 442), 81: (510,), 83: (201,), 84: (309,), 85: (201,), 87: (200,), 88: (310,), 89: (200,), 90: (200,), 92: (200,), 93: (310,), 95: (510, 1), 102: 310, 104: (510,), 108: <matplotlib.text.Text object at 0x918f1d0>, 109: 198, 111: <matplotlib.text.Text object at 0x9894b90>, 113: <type 'list'>, 114: (310,), 116: -3.8199999999999998}, 'Normalize': <class 'matplotlib.colors.Normalize'>, 'spy': <function spy at 0x3196758>, 'train_transformed': array([[  4.00000000e-02,   2.05333333e+02,   3.26666670e+01, ...,\n          6.56650000e-01,   7.30560000e-01,   7.44760000e-02],\n       [ -1.10000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          3.24497000e-01,   2.54928000e-01,   1.47196000e-01],\n       [ -8.00000000e-02,   0.00000000e+00,   0.00000000e+00, ...,\n          9.13311000e-01,   9.19309000e-01,   6.25030000e-02],\n       ..., \n       [ -1.70000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          9.63428000e-01,   9.62613000e-01,   1.33066000e-01],\n       [  1.50000000e-01,   2.19333333e+02,   4.73333330e+01, ...,\n          9.05099000e-01,   6.36617000e-01,   1.27541000e-01],\n       [  1.10000000e-01,   6.95000000e+01,   7.55000000e+01, ...,\n          3.40341000e-01,   2.59492000e-01,   1.30486000e-01]]), 'MinuteLocator': <class 'matplotlib.dates.MinuteLocator'>, 'quiver': <function quiver at 0x3197758>, 'figure': <function figure at 0x3194938>, 'subplot2grid': <function subplot2grid at 0x31955f0>, 'get_sparse_matrix': <function get_sparse_matrix at 0x2c516e0>, 'add_newdoc': <function add_newdoc at 0x236d848>, 'seterrcall': <function seterrcall at 0x21dd2a8>, 'autumn': <function autumn at 0x31966e0>, 'logical_or': <ufunc 'logical_or'>, 'minimum': <ufunc 'minimum'>, 'WRAP': 1, 'tan': <ufunc 'tan'>, 'rms_flat': <function rms_flat at 0x2c51de8>, 'absolute': <ufunc 'absolute'>, 'gca': <function gca at 0x3195488>, 'winter': <function winter at 0x3198aa0>, 'gcf': <function gcf at 0x31949b0>, 'gci': <function gci at 0x31945f0>, 'csd': <function csd at 0x3196e60>, 'RRuleLocator': <class 'matplotlib.dates.RRuleLocator'>, 'get_array_wrap': <function get_array_wrap at 0x23770c8>, 'polymul': <function polymul at 0x238d140>, 'hot': <function hot at 0x3198758>, 'minorticks_off': <function minorticks_off at 0x3195e60>, '_81': (510,), 'get_ipython': <bound method ZMQInteractiveShell.get_ipython of <IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object at 0x2720f90>>, 'get_figlabels': <function get_figlabels at 0x3194aa0>, 'tile': <function tile at 0x23771b8>, 'array_str': <function array_str at 0x21db9b0>, 'eigvalsh': <function eigvalsh at 0x238c7d0>, 'pinv': <function pinv at 0x238cb18>, 'stock': 0, 'longlong': <type 'numpy.int64'>, 'pink': <function pink at 0x31988c0>, 'product': <function product at 0x21da1b8>, 'int16': <type 'numpy.int16'>, 's_': <numpy.lib.index_tricks.IndexExpression object at 0x236fad0>, 'mat': <function asmatrix at 0x236dc80>, 'fv': <function fv at 0x23fbb90>, 'summer': <function summer at 0x3198a28>, '_i123': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random\\nimport smtplib\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', 'yticks': <function yticks at 0x3195d70>, 'docstring': <module 'matplotlib.docstring' from '/usr/local/lib/python2.7/dist-packages/matplotlib/docstring.pyc'>, '_i36': u'plot(normTarget[:,197])', 'asanyarray': <function asanyarray at 0x21c25f0>, 'uint': <type 'numpy.uint64'>, 'negative_binomial': <built-in method negative_binomial of mtrand.RandomState object at 0x7f399f841690>, 'npv': <function npv at 0x23fe0c8>, 'logaddexp': <ufunc 'logaddexp'>, 'flatnonzero': <function flatnonzero at 0x21c28c0>, 'short': <type 'numpy.int16'>, 'correlate': <function correlate at 0x21c29b0>, 'getfigs': <function getfigs at 0x1de1848>, 'fromstring': <built-in function fromstring>, 'pylab_setup': <function pylab_setup at 0x3186cf8>, 'left_shift': <ufunc 'left_shift'>, 'tricontour': <function tricontour at 0x3197c08>, 'subplots': <function subplots at 0x3195578>, 'searchsorted': <function searchsorted at 0x21d1c08>, 'barbs': <function barbs at 0x3197ed8>, 'int64': <type 'numpy.int64'>, 'gamma': <built-in method gamma of mtrand.RandomState object at 0x7f399f841690>, 'may_share_memory': <function may_share_memory at 0x2369500>, '_76': (200,), '__': (310,), 'GridSpec': <class 'matplotlib.gridspec.GridSpec'>, 'help': Type help() for interactive help, or help(object) for help about object., 'xlim': <function xlim at 0x3195b18>, 'copper': <function copper at 0x31985f0>, 'MONTHLY': 1, 'dsplit': <function dsplit at 0x2374f50>, 'intersect1d': <function intersect1d at 0x2369ed8>, 'cosh': <ufunc 'cosh'>, 'window_none': <function window_none at 0x2c4f5f0>, 'can_cast': <built-in function can_cast>, 'performance': [0.73306000000000016], 'ppmt': <function ppmt at 0x23fbde8>, '__package__': None, 'cumsum': <function cumsum at 0x21da410>, 'roots': <function roots at 0x238cd70>, 'Widget': <class 'matplotlib.widgets.Widget'>, 'outer': <function outer at 0x21c2aa0>, 'intc': <type 'numpy.int32'>, 'fix': <function fix at 0x2301488>, 'stineman_interp': <function stineman_interp at 0x2c537d0>, 'busday_count': <built-in function busday_count>, 'cla': <function cla at 0x3197f50>, 'timedelta64': <type 'numpy.timedelta64'>, 'strpdate2num': <class matplotlib.dates.strpdate2num at 0x3025460>, 'Rectangle': <class 'matplotlib.patches.Rectangle'>, 'standard_exponential': <built-in method standard_exponential of mtrand.RandomState object at 0x7f399f841690>, 'subplot_tool': <function subplot_tool at 0x31957d0>, 'choose': <function choose at 0x21d17d0>, '_i': u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', '_i38': u'hist(normTarget)', 'FPE_INVALID': 8, 'recfromcsv': <function recfromcsv at 0x23fb6e0>, 'fill_diagonal': <function fill_diagonal at 0x23742a8>, 'void0': <type 'numpy.void'>, 'get_fignums': <function get_fignums at 0x3194a28>, 'exception_to_str': <function exception_to_str at 0x2994b18>, 'SECONDLY': 6, 'logaddexp2': <ufunc 'logaddexp2'>, 'greater': <ufunc 'greater'>, 'suptitle': <function suptitle at 0x31950c8>, '_109': 198, 'get_backend': <function get_backend at 0x2a00668>, '_i83': u'train.shape', 'matrix_power': <function matrix_power at 0x236dcf8>, 'histogram2d': <function histogram2d at 0x230d9b0>, 'LogFormatter': <class 'matplotlib.ticker.LogFormatter'>, 'polyint': <function polyint at 0x238cde8>, 'nonzero': <function nonzero at 0x21d1ed8>, '_88': (310,), 'rank': <function rank at 0x21da848>, 'quiverkey': <function quiverkey at 0x31977d0>, 'datetime64': <type 'numpy.datetime64'>, '_84': (309,), 'complexfloating': <type 'numpy.complexfloating'>, 'is_numlike': <function is_numlike at 0x29929b0>, '_i50': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],0))', 'ndindex': <class 'numpy.lib.index_tricks.ndindex'>, 'ctypeslib': <module 'numpy.ctypeslib' from '/usr/local/lib/python2.7/dist-packages/numpy/ctypeslib.pyc'>, 'waitforbuttonpress': <function waitforbuttonpress at 0x3194f50>, '_i120': u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'PZERO': 0.0, 'relativedelta': <class 'dateutil.relativedelta.relativedelta'>, 'MonthLocator': <class 'matplotlib.dates.MonthLocator'>, 'asfarray': <function asfarray at 0x23015f0>, 'gmail_user': 'mcintoshlane@gmail.com', 'radians': <ufunc 'radians'>, 'sin': <ufunc 'sin'>, 'fliplr': <function fliplr at 0x230d500>, 'alen': <function alen at 0x21da668>, '_13': (510, 55, 198), 'recarray': <class 'numpy.core.records.recarray'>, 'fmod': <ufunc 'fmod'>, '_10': 200, '_i73': u'for i,j in cv:\\n    print i,j', 'bone': <function bone at 0x3198500>, 'mean': <function mean at 0x21daa28>, 'griddata': <function griddata at 0x2c53668>, 'poly_below': <function poly_below at 0x2c538c0>, 'square': <ufunc 'square'>, 'isvector': <function isvector at 0x2c52320>, 'ogrid': <numpy.lib.index_tricks.nd_grid object at 0x236f950>, 'bytes': <type 'str'>, 'nanargmin': <function nanargmin at 0x236cc08>, 'r_': <numpy.lib.index_tricks.RClass object at 0x236f990>, 'hanning': <function hanning at 0x236d230>, 'trainInput': array([[[ -8.00000000e-01,   5.00000000e+00,   0.00000000e+00, ...,\n           2.99584000e-01,   3.88160000e-02,   8.13090000e-02],\n        [  1.33333300e+00,   3.00000000e+00,   0.00000000e+00, ...,\n           3.14446000e-01,   2.51952000e-01,   2.06263000e-01],\n        [  6.66666000e-01,   3.00000000e+00,   5.00000000e+00, ...,\n           3.57783000e-01,   5.10176000e-01,   4.29069000e-01],\n        ..., \n        [  6.66666000e-01,   3.00000000e+00,   0.00000000e+00, ...,\n           2.69088000e-01,   1.26912000e-01,   1.03441000e-01],\n        [  0.00000000e+00,   2.00000000e+00,   1.00000000e+00, ...,\n           2.62727000e-01,   1.33116000e-01,   1.11704000e-01],\n        [  1.50000000e+00,   2.00000000e+00,   5.00000000e+00, ...,\n           2.59782000e-01,   1.21326000e-01,   1.24544000e-01]],\n\n       [[  2.92682000e-01,   4.10000000e+01,   0.00000000e+00, ...,\n           3.20344000e-01,   7.12740000e-02,   5.78310000e-02],\n        [  3.33333000e-01,   3.00000000e+00,   0.00000000e+00, ...,\n           4.10495000e-01,   6.34182000e-01,   5.21483000e-01],\n        [  2.00000000e+00,   1.00000000e+00,   3.00000000e+00, ...,\n           4.78352000e-01,   7.94850000e-01,   6.90853000e-01],\n        ..., \n        [  0.00000000e+00,   1.10000000e+01,   0.00000000e+00, ...,\n           2.31589000e-01,   6.77250000e-02,   9.07990000e-02],\n        [  3.33333000e-01,   1.50000000e+01,   1.00000000e+00, ...,\n           2.31602000e-01,   7.23880000e-02,   1.00995000e-01],\n        [  7.89473000e-01,   1.90000000e+01,   0.00000000e+00, ...,\n           2.25328000e-01,   4.84420000e-02,   8.36660000e-02]],\n\n       [[  4.41860000e-01,   4.30000000e+01,   0.00000000e+00, ...,\n           1.96550000e-01,   1.50555000e-01,   1.20830000e-01],\n        [  6.66666000e-01,   3.00000000e+00,   5.00000000e+00, ...,\n           1.94066000e-01,   1.53753000e-01,   1.28841000e-01],\n        [  0.00000000e+00,   1.00000000e+00,   5.00000000e+00, ...,\n           1.87594000e-01,   1.53753000e-01,   1.32288000e-01],\n        ..., \n        [ -1.11111000e-01,   9.00000000e+00,   5.00000000e+00, ...,\n           1.83963000e-01,   7.37560000e-02,   8.12400000e-02],\n        [  0.00000000e+00,   6.00000000e+00,   5.00000000e+00, ...,\n           1.77811000e-01,   6.03320000e-02,   6.61650000e-02],\n        [  5.00000000e-01,   1.20000000e+01,   0.00000000e+00, ...,\n           1.74681000e-01,   6.12100000e-02,   6.00000000e-02]],\n\n       ..., \n       [[  4.87500000e-01,   8.00000000e+01,   0.00000000e+00, ...,\n           1.50991000e-01,   7.33940000e-02,   6.70820000e-02],\n        [ -5.00000000e-01,   6.00000000e+00,   0.00000000e+00, ...,\n           1.50545000e-01,   6.69330000e-02,   6.70820000e-02],\n        [  7.77777000e-01,   1.80000000e+01,   0.00000000e+00, ...,\n           1.50910000e-01,   6.88960000e-02,   6.91210000e-02],\n        ..., \n        [  7.30769000e-01,   2.60000000e+01,   0.00000000e+00, ...,\n           1.97203000e-01,   7.31210000e-02,   8.36660000e-02],\n        [  2.85714000e-01,   2.80000000e+01,   5.00000000e+00, ...,\n           1.98655000e-01,   7.48330000e-02,   6.92820000e-02],\n        [  3.23529000e-01,   3.40000000e+01,   0.00000000e+00, ...,\n           1.98691000e-01,   9.95990000e-02,   8.00000000e-02]],\n\n       [[  0.00000000e+00,   2.40000000e+01,   0.00000000e+00, ...,\n           1.50959000e-01,   8.94430000e-02,   9.51020000e-02],\n        [ -2.50000000e-01,   4.00000000e+00,   2.33333300e+00, ...,\n           1.91609000e-01,   2.67133000e-01,   2.41753000e-01],\n        [  0.00000000e+00,   2.00000000e+00,   0.00000000e+00, ...,\n           2.23181000e-01,   3.15383000e-01,   2.98794000e-01],\n        ..., \n        [  1.42857000e-01,   1.40000000e+01,   0.00000000e+00, ...,\n           1.88956000e-01,   6.28230000e-02,   5.56780000e-02],\n        [  6.00000000e-01,   1.00000000e+01,   1.00000000e+00, ...,\n           1.91981000e-01,   6.62320000e-02,   5.81190000e-02],\n        [  2.94117000e-01,   1.70000000e+01,   4.00000000e+00, ...,\n           1.91485000e-01,   6.28230000e-02,   6.00000000e-02]],\n\n       [[  6.00000000e-01,   1.50000000e+01,   0.00000000e+00, ...,\n           1.10484000e+00,   5.42830000e-02,   9.48680000e-02],\n        [  0.00000000e+00,   3.00000000e+00,   3.40000000e+00, ...,\n           1.35640700e+00,   1.78215200e+00,   1.46147600e+00],\n        [  0.00000000e+00,   1.00000000e+00,   3.00000000e+00, ...,\n           1.52380800e+00,   2.13168200e+00,   1.81240200e+00],\n        ..., \n        [ -3.33333000e-01,   3.00000000e+00,   3.40000000e+00, ...,\n           5.75108000e-01,   3.00311000e-01,   3.10644000e-01],\n        [ -7.14285000e-01,   7.00000000e+00,   1.00000000e+00, ...,\n           5.69777000e-01,   2.76743000e-01,   2.84429000e-01],\n        [  1.60000000e+00,   5.00000000e+00,   0.00000000e+00, ...,\n           5.57479000e-01,   2.14942000e-01,   3.23883000e-01]]]), 'connect': <function connect at 0x3194c08>, '_i72': u'for i in cv:\\n    print i', 'str_': <type 'numpy.string_'>, 'margins': <function margins at 0x3198410>, 'allclose': <function allclose at 0x21dbe60>, 'extract': <function extract at 0x236c9b0>, 'isOutput': [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'float16': <type 'numpy.float16'>, '_i13': u'trainOutput.shape', 'ulonglong': <type 'numpy.uint64'>, 'matrix': <class 'numpy.matrixlib.defmatrix.matrix'>, 'probas': array([[ 0.006,  0.002,  0.   , ...,  0.006,  0.   ,  0.   ],\n       [ 0.002,  0.   ,  0.   , ...,  0.008,  0.018,  0.   ],\n       [ 0.002,  0.004,  0.004, ...,  0.002,  0.002,  0.01 ],\n       ..., \n       [ 0.018,  0.   ,  0.006, ...,  0.006,  0.004,  0.006],\n       [ 0.   ,  0.   ,  0.   , ...,  0.002,  0.024,  0.   ],\n       [ 0.004,  0.02 ,  0.004, ...,  0.004,  0.   ,  0.006]]), 'asarray': <function asarray at 0x21c2578>, 'True_': True, 'IndexLocator': <class 'matplotlib.ticker.IndexLocator'>, 'poly1d': <class 'numpy.lib.polynomial.poly1d'>, 'rf': RandomForestClassifier(bootstrap=True, compute_importances=None,\n            criterion='gini', max_depth=None, max_features='auto',\n            min_density=None, min_samples_leaf=1, min_samples_split=2,\n            n_estimators=500, n_jobs=2, oob_score=False, random_state=None,\n            verbose=0), 'void': <type 'numpy.void'>, '_i28': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', 'promote_types': <built-in function promote_types>, '_i26': u'target.shape', 'rec': <module 'numpy.core.records' from '/usr/local/lib/python2.7/dist-packages/numpy/core/records.pyc'>, '_i24': u'len(trainOutput[0])', 'arange': <built-in function arange>, 'datetime_as_string': <built-in function datetime_as_string>, 'plotting': <function plotting at 0x3196050>, 'math': <module 'math' (built-in)>, '_i21': u'train.shape', 'get_cmap': <function get_cmap at 0x2b80ed8>, 'log2': <ufunc 'log2'>, 'specgram': <function specgram at 0x31979b0>, 'date2num': <function date2num at 0x307bed8>, '__builtins__': {'bytearray': <type 'bytearray'>, 'IndexError': <type 'exceptions.IndexError'>, 'all': <built-in function all>, 'help': Type help() for interactive help, or help(object) for help about object., 'vars': <built-in function vars>, 'SyntaxError': <type 'exceptions.SyntaxError'>, '__IPYTHON__active': 'Deprecated, check for __IPYTHON__', 'unicode': <type 'unicode'>, 'UnicodeDecodeError': <type 'exceptions.UnicodeDecodeError'>, 'memoryview': <type 'memoryview'>, 'isinstance': <built-in function isinstance>, 'copyright': Copyright (c) 2001-2012 Python Software Foundation.\nAll Rights Reserved.\n\nCopyright (c) 2000 BeOpen.com.\nAll Rights Reserved.\n\nCopyright (c) 1995-2001 Corporation for National Research Initiatives.\nAll Rights Reserved.\n\nCopyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\nAll Rights Reserved., 'NameError': <type 'exceptions.NameError'>, 'BytesWarning': <type 'exceptions.BytesWarning'>, 'dict': <type 'dict'>, 'input': <function <lambda> at 0x5cf2398>, 'oct': <built-in function oct>, 'bin': <built-in function bin>, 'SystemExit': <type 'exceptions.SystemExit'>, 'StandardError': <type 'exceptions.StandardError'>, 'format': <built-in function format>, 'repr': <built-in function repr>, 'sorted': <built-in function sorted>, 'False': False, 'RuntimeWarning': <type 'exceptions.RuntimeWarning'>, 'list': <type 'list'>, 'iter': <built-in function iter>, 'reload': <built-in function reload>, 'Warning': <type 'exceptions.Warning'>, '__package__': None, 'round': <built-in function round>, 'dir': <built-in function dir>, 'cmp': <built-in function cmp>, 'set': <type 'set'>, 'bytes': <type 'str'>, 'reduce': <built-in function reduce>, 'intern': <built-in function intern>, 'issubclass': <built-in function issubclass>, 'Ellipsis': Ellipsis, 'EOFError': <type 'exceptions.EOFError'>, 'locals': <built-in function locals>, 'BufferError': <type 'exceptions.BufferError'>, 'slice': <type 'slice'>, 'FloatingPointError': <type 'exceptions.FloatingPointError'>, 'sum': <built-in function sum>, 'getattr': <built-in function getattr>, 'abs': <built-in function abs>, 'print': <built-in function print>, 'True': True, 'FutureWarning': <type 'exceptions.FutureWarning'>, 'ImportWarning': <type 'exceptions.ImportWarning'>, 'None': None, 'hash': <built-in function hash>, 'ReferenceError': <type 'exceptions.ReferenceError'>, 'len': <built-in function len>, 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n    for supporting Python development.  See www.python.org for more information., 'frozenset': <type 'frozenset'>, '__name__': '__builtin__', 'ord': <built-in function ord>, 'super': <type 'super'>, 'TypeError': <type 'exceptions.TypeError'>, 'license': Type license() to see the full license text, 'KeyboardInterrupt': <type 'exceptions.KeyboardInterrupt'>, 'UserWarning': <type 'exceptions.UserWarning'>, 'filter': <built-in function filter>, 'range': <built-in function range>, 'staticmethod': <type 'staticmethod'>, 'SystemError': <type 'exceptions.SystemError'>, 'BaseException': <type 'exceptions.BaseException'>, 'pow': <built-in function pow>, 'RuntimeError': <type 'exceptions.RuntimeError'>, 'float': <type 'float'>, 'MemoryError': <type 'exceptions.MemoryError'>, 'StopIteration': <type 'exceptions.StopIteration'>, 'globals': <built-in function globals>, 'divmod': <built-in function divmod>, 'enumerate': <type 'enumerate'>, 'apply': <built-in function apply>, 'LookupError': <type 'exceptions.LookupError'>, 'open': <built-in function open>, 'basestring': <type 'basestring'>, 'UnicodeError': <type 'exceptions.UnicodeError'>, 'zip': <built-in function zip>, 'hex': <built-in function hex>, 'long': <type 'long'>, 'next': <built-in function next>, 'ImportError': <type 'exceptions.ImportError'>, 'chr': <built-in function chr>, 'xrange': <type 'xrange'>, 'type': <type 'type'>, '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\", 'Exception': <type 'exceptions.Exception'>, '__IPYTHON__': True, 'tuple': <type 'tuple'>, 'UnicodeTranslateError': <type 'exceptions.UnicodeTranslateError'>, 'reversed': <type 'reversed'>, 'UnicodeEncodeError': <type 'exceptions.UnicodeEncodeError'>, 'IOError': <type 'exceptions.IOError'>, 'hasattr': <built-in function hasattr>, 'delattr': <built-in function delattr>, 'setattr': <built-in function setattr>, 'raw_input': <function <lambda> at 0x7f39504c2578>, 'SyntaxWarning': <type 'exceptions.SyntaxWarning'>, 'compile': <built-in function compile>, 'ArithmeticError': <type 'exceptions.ArithmeticError'>, 'str': <type 'str'>, 'property': <type 'property'>, 'dreload': <function reload at 0x2725c08>, 'GeneratorExit': <type 'exceptions.GeneratorExit'>, 'int': <type 'int'>, '__import__': <built-in function __import__>, 'KeyError': <type 'exceptions.KeyError'>, 'coerce': <built-in function coerce>, 'PendingDeprecationWarning': <type 'exceptions.PendingDeprecationWarning'>, 'file': <type 'file'>, 'EnvironmentError': <type 'exceptions.EnvironmentError'>, 'unichr': <built-in function unichr>, 'id': <built-in function id>, 'OSError': <type 'exceptions.OSError'>, 'DeprecationWarning': <type 'exceptions.DeprecationWarning'>, 'min': <built-in function min>, 'UnicodeWarning': <type 'exceptions.UnicodeWarning'>, 'execfile': <built-in function execfile>, 'any': <built-in function any>, 'complex': <type 'complex'>, 'bool': <type 'bool'>, 'get_ipython': <bound method ZMQInteractiveShell.get_ipython of <IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object at 0x2720f90>>, 'ValueError': <type 'exceptions.ValueError'>, 'NotImplemented': NotImplemented, 'map': <built-in function map>, 'buffer': <type 'buffer'>, 'max': <built-in function max>, 'object': <type 'object'>, 'TabError': <type 'exceptions.TabError'>, 'callable': <built-in function callable>, 'ZeroDivisionError': <type 'exceptions.ZeroDivisionError'>, 'eval': <built-in function eval>, '__debug__': True, 'IndentationError': <type 'exceptions.IndentationError'>, 'AssertionError': <type 'exceptions.AssertionError'>, 'classmethod': <type 'classmethod'>, 'UnboundLocalError': <type 'exceptions.UnboundLocalError'>, 'NotImplementedError': <type 'exceptions.NotImplementedError'>, 'AttributeError': <type 'exceptions.AttributeError'>, 'OverflowError': <type 'exceptions.OverflowError'>}, 'rec_join': <function rec_join at 0x2c526e0>, 'acorr': <function acorr at 0x31967d0>, 'cumproduct': <function cumproduct at 0x21da488>, 'diagonal': <function diagonal at 0x21d1d70>, 'atleast_1d': <function atleast_1d at 0x22741b8>, '_i116': u'pred[0]', '_i115': u'yoda = np.asarray(predicted_probs)\\nluke = np.zeros((310,198))\\nluke[:,0] = yoda', 'meshgrid': <function meshgrid at 0x236d8c0>, 'eventplot': <function eventplot at 0x3196f50>, '_i112': u'numStocks', '_i111': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", 'column_stack': <function column_stack at 0x2374c08>, 'put': <function put at 0x21d18c0>, '___': <type 'list'>, 'smtpserver': <smtplib.SMTP instance at 0x7f393945a7a0>, 'remainder': <ufunc 'remainder'>, '_i19': u'fullInput[509,54,244+197]', 'get_scale_docs': <function get_scale_docs at 0x2fc7140>, '_i118': u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'row_stack': <function vstack at 0x2274758>, 'expm1': <ufunc 'expm1'>, 'ion': <function ion at 0x3194500>, 'insert': <function insert at 0x236d9b0>, 'semilogx': <function semilogx at 0x31978c0>, 'semilogy': <function semilogy at 0x3197938>, 'ndfromtxt': <function ndfromtxt at 0x23fb578>, 'sometrue': <function sometrue at 0x21da230>, 'place': <function place at 0x236ca28>, 'DataSource': <class 'numpy.lib._datasource.DataSource'>, 'newaxis': None, 'arccos': <ufunc 'arccos'>, 'epoch2num': <function epoch2num at 0x307fa28>, '_i59': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", 'signedinteger': <type 'numpy.signedinteger'>, '_i119': u'import smtplib', 'ndim': <function ndim at 0x21da7d0>, 'rand': <built-in method rand of mtrand.RandomState object at 0x7f399f841690>, 'irfft': <function irfft at 0x23fef50>, 'ranf': <built-in method random_sample of mtrand.RandomState object at 0x7f399f841690>, 'subplots_adjust': <function subplots_adjust at 0x3195758>, 'rint': <ufunc 'rint'>, 'fill_between': <function fill_between at 0x31970c8>, 'Axes': <class 'matplotlib.axes.Axes'>, 'MaxNLocator': <class 'matplotlib.ticker.MaxNLocator'>, 'arctan2': <ufunc 'arctan2'>, 'little_endian': True, 'ldexp': <ufunc 'ldexp'>, 'lognormal': <built-in method lognormal of mtrand.RandomState object at 0x7f399f841690>, 'lookfor': <function lookfor at 0x23697d0>, 'hfft': <function hfft at 0x2409050>, 'array': <built-in function array>, 'common_type': <function common_type at 0x2301b90>, 'size': <function size at 0x21da8c0>, 'logical_xor': <ufunc 'logical_xor'>, '_i51': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))', 'geterrcall': <function geterrcall at 0x21dd320>, 'sheet': [['fileId', 'O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8', 'O9', 'O10', 'O11', 'O12', 'O13', 'O14', 'O15', 'O16', 'O17', 'O18', 'O19', 'O20', 'O21', 'O22', 'O23', 'O24', 'O25', 'O26', 'O27', 'O28', 'O29', 'O30', 'O31', 'O32', 'O33', 'O34', 'O35', 'O36', 'O37', 'O38', 'O39', 'O40', 'O41', 'O42', 'O43', 'O44', 'O45', 'O46', 'O47', 'O48', 'O49', 'O50', 'O51', 'O52', 'O53', 'O54', 'O55', 'O56', 'O57', 'O58', 'O59', 'O60', 'O61', 'O62', 'O63', 'O64', 'O65', 'O66', 'O67', 'O68', 'O69', 'O70', 'O71', 'O72', 'O73', 'O74', 'O75', 'O76', 'O77', 'O78', 'O79', 'O80', 'O81', 'O82', 'O83', 'O84', 'O85', 'O86', 'O87', 'O88', 'O89', 'O90', 'O91', 'O92', 'O93', 'O94', 'O95', 'O96', 'O97', 'O98', 'O99', 'O100', 'O101', 'O102', 'O103', 'O104', 'O105', 'O106', 'O107', 'O108', 'O109', 'O110', 'O111', 'O112', 'O113', 'O114', 'O115', 'O116', 'O117', 'O118', 'O119', 'O120', 'O121', 'O122', 'O123', 'O124', 'O125', 'O126', 'O127', 'O128', 'O129', 'O130', 'O131', 'O132', 'O133', 'O134', 'O135', 'O136', 'O137', 'O138', 'O139', 'O140', 'O141', 'O142', 'O143', 'O144', 'O145', 'O146', 'O147', 'O148', 'O149', 'O150', 'O151', 'O152', 'O153', 'O154', 'O155', 'O156', 'O157', 'O158', 'O159', 'O160', 'O161', 'O162', 'O163', 'O164', 'O165', 'O166', 'O167', 'O168', 'O169', 'O170', 'O171', 'O172', 'O173', 'O174', 'O175', 'O176', 'O177', 'O178', 'O179', 'O180', 'O181', 'O182', 'O183', 'O184', 'O185', 'O186', 'O187', 'O188', 'O189', 'O190', 'O191', 'O192', 'O193', 'O194', 'O195', 'O196', 'O197', 'O198'], ['201', -3.82, -0.88, 0.54, 0.08, -1.65, -2.8, -1.74, -5.108279403464041, -4.58, -5.23, 1.78, -3.49, -1.71, -0.32, 0.35428571428571426, -5.32, -1.46, -3.82, -2.64, -4.65, -6.76, -2.19, -0.9256947683993239, -2.17, -4.67, -2.91, -6.9, -5.18, -3.43, -2.06, -1.41, -6.98, -3.19, -5.5, -4.35, -6.32, -8.4, -3.9, -2.75, -3.88, -4.834514634175348, -8.81, -1.81, 1.84, 3.29, 3.98, -1.89, 2.1, -0.34, 0.88, -1.2, -3.39, 1.35, 2.6471428571428572, 1.37, -3.15, -4.75, -4.42, -5.05, -3.59, 1.42, 2.1, -3.67, 0.25, -2.14, -0.95, -2.99, -5.14, -0.48, 0.71, -0.46, -5.02, -4.93, 0.67, -5.02, -1.15, -3.51, -2.33, -4.35, -6.47, -1.88, -0.7, -1.86, -6.76, -11.6, 11.63, -5.57, -5.65, -1.81, -4.15, -2.98, -4.98, -7.09, -2.53, -1.36, -2.51, -1.3273809523809526, 0.09, 4.07, 1.58, 2.83, 0.71, -1.4673734626473065, 3.31, 4.54, 3.33, -1.34, 0.0, -5.22, -3.09, -3.15, -3.04, -3.83, -2.39, -1.19, -3.23, -5.38, -0.73, 0.45, -0.72, -3.03, -1.47, 1.22, -0.86, -3.06, 1.69, 2.91, 1.71, -4.7, -4.57, -0.18, -3.76, -2.65, -1.5696768707482993, -1.01, 5.73, -5.73, -2.89, -2.1, -7.4, 1.2, 6.14, 3.12, -1.91, -2.13, -9.34, 9.31, 9.23, -3.1, 8.58, -6.09, -3.55, 1.78, -11.41, 25.62, 7.66, 11.19, -1.1, -2.67, -2.06, -4.23, 0.47, 1.67, 0.49, -9.21, -0.61, -2.21, 2.58, 3.81, 2.6, 1.64, 4.91, 6.16, 4.93, -4.6, -5.86, -3.12, 1.2, 0.02, -3.01, -3.17, -5.0, 12.86, -4.81, -12.61, -4.07, -3.55, -4.181362551799029, -1.16, -3.5, -2.83, -2.03, -1.53, -2.5, -3.14, -6.31, -4.71, -3.53], ['202', 7.014285714285714, -1.9, -0.6387782843795413, 0.5821428571428573, -0.08, -1.74, -0.8458847420401708, -1.17, -1.91, -0.5, 3.17, -0.07, 1.07, 1.35, 2.39, -2.31, 3.2, 0.84, 0.74, 1.0, -1.16, 3.18, 2.54, 1.5721746031746033, -2.59, -2.91, -3.55, -3.14, -2.03, -1.77, -0.75, -5.31, 0.03, -2.26, -2.36, -2.1, -4.2, 0.01, -0.61, -1.55, -2.3, -3.1750638007838266, -0.42, 1.15, 1.42, 2.47, -2.24, 3.27, 0.92, 0.81, 1.07, -1.09, 3.26, 2.62, 1.65, -0.82, -2.27, -0.17, -1.49, -1.55, 0.27, 1.3, -3.35, 2.1, -0.23, -0.33, -0.07, -2.21, 2.09, 1.46, 0.49, -1.68, -1.6042857142857143, 1.03, -3.61, 1.82, -0.5, -0.6, -0.35, -2.47, 1.81, 1.18, 0.22, -3.28, -9.13, 9.15, -2.82, -4.59, 0.79, -1.4957142857142858, -1.62, -1.36, -3.47, 0.77, 0.15, -0.8, -0.74, 1.86, 5.64, 3.23, 3.12, 3.39, 1.18, 5.62, 4.97, 3.97, -0.97, 1.77, -4.3342762881169605, -1.94, -2.32, -2.04, -3.58, -2.28, -2.39, -2.13, -4.22, -0.02, -0.63, -1.57, -3.54, -1.33, -0.11, 0.15, -1.98, 2.32, 1.69, 0.72, -3.13, -2.54, -0.28, -3.84, -1.37, -1.66, -0.96, 3.48, -3.41, -1.73, -3.69, -1.07, 2.85, 4.0, 1.93, 3.911438775510204, -1.52, -6.48, 6.48, 5.95, -1.98, 5.25, -3.93, -4.63, 2.01, -10.86, 10.55, 7.371428571428571, 11.015714285714285, -3.14, -1.22, 0.26, -1.88, 2.43, 1.79, 0.83, -6.0, -1.48, -2.14, 2.16, 1.53, 0.57, 0.67, 4.39, 3.9828571428571427, 2.76, -1.93, -2.26, -3.56, -0.62, -1.56, -1.92, -2.27, -1.18, 5.3, -4.25, -5.42, -1.7, -2.77, -2.96, -0.95, -2.09, -1.44, -0.67, -1.779047619047619, -2.33, -2.04, -5.38, -5.58, -2.6], ['203', 2.06, -0.11, 0.37, -0.13, 0.36, 0.82, 0.97, 1.61, 1.14, 2.93, 1.87, 2.06, 1.96, 1.85, 0.97, 2.26, 2.17, 2.29, 0.5, 0.92, 3.2, 2.66, 2.12, 2.55, 1.05, 1.03, 1.0726583949931126, 0.19, 0.09, -0.02, -0.88, 0.39, 0.3, 0.41, -1.34, -0.92, 1.31, 0.78, 0.25, 0.67, 1.63, 0.020062111801242236, 0.85, -0.1, -0.21, -1.07, 0.19, 0.11, 0.22, -1.53, -1.11, 1.12, 0.59, 0.06, 0.47, 1.0700628463056765, 1.55, 0.95, 1.7, 0.95, -0.11, -0.97, 0.29, 0.2, 0.32, -1.43, -1.02, 1.21, 0.69, 0.16, 0.57, 1.8, 1.06, -0.8592857142857143, 0.4, 0.32, 0.43, -1.32, -0.91, 1.33, 0.8, 0.27, 0.69, 0.74, 2.18, -2.2694285714285716, 1.94, 1.27, 1.18, 1.3, -0.47, -0.05, 2.21, 1.67, 1.14, 1.56, 1.95, 0.66, -0.09, 0.03, -1.72, -1.3, 0.92, 0.4, -0.13, 0.28, 0.58, 0.65, 0.03, 0.55, 0.63, 0.45, 0.74, 0.12, -1.63, -1.22, 1.01, 0.48, -0.05, 0.37, 0.26, 0.63, -1.74, -1.33, 0.89, 0.37, 0.0657142857142857, 0.25, 0.87, 0.68, -0.35, 0.4, 6.0, 0.27, 0.16, -1.08, 0.97, 0.52, 0.35, 1.67, -3.9, -1.17, -0.57, 1.04, 0.3, 1.58, -1.69, -1.74, 0.55, -1.66, 1.17, 1.08, -0.54, 2.23, 1.14, -1.55, -2.29, 3.89, 2.41, 0.42, 2.68, 2.15, 1.61, 2.03, 1.65, 1.99, 2.26, 1.72, 1.3340034013605442, 1.61, -0.26, -0.52, -1.05, -0.63, 1.13, 1.31, 0.26, -0.53, -0.12, 0.53, 0.58, 1.52, 0.6, 0.46, -0.88, 1.06, 0.69, 0.79, 0.42, 0.99, 0.47021978021978017, 0.29, -0.05, 0.5, 0.37, 0.88, 0.93, 0.67], ['204', -0.62, -0.06, 0.09122171562045875, 0.26, -0.37, 0.2984196236737595, 7.22, -0.29, 0.79, -1.71, -1.87, -5.55, -1.43, -1.81, -1.65, -1.51, -2.13, -1.83, -1.94, -0.14, -1.65, -2.61, -2.17, -2.08, -0.22, -0.2, 0.16, -3.76, 0.45, 0.05, 0.22, 0.36, -0.26, 0.04, -0.07, 1.76, 0.22, -0.76, -0.31, -0.22, -0.23, 0.7949361992161734, 4.07, 4.37, 3.96, 4.13, 4.28, 3.63, 3.95, 3.83, 5.73, 4.14, 3.11, 3.59, 3.68, 0.3, 0.04, -0.22, -0.17, -0.29, -0.39, -0.23, -0.08, -0.71, -0.41, -0.52, 1.3, -0.22, -1.21, -0.75, -0.66, -2.12, 0.11, 0.16, 0.31, -0.32, -0.01, -0.13, 1.7, 0.17, -0.82, -0.36, -0.27, 0.21, 1.33, -1.35, -0.06, 0.14, -0.48, -0.18, -0.29, 1.54, 0.01, -0.98, -0.52, -0.3759922724755494, 3.21, -0.2, -0.63, -0.32, -0.43, 1.39, -0.14, -1.12, -0.67, -0.58, 0.15, -0.17, 0.09, 0.21, 0.32, 0.13567351865003197, 0.43, 0.31, 0.19, 2.03, 0.49, -0.5, -0.04, 0.05, 0.89, 0.17307674813036728, -0.11, 1.72, 0.18, -0.8, -0.35, -0.26, 0.31, 0.46, 0.53, 0.33, 9.51, -0.07, 0.06, 0.19, -0.17, -0.02118982899237888, 0.36, 0.9, 3.11, -0.38, -0.26, -0.31, 0.58, 0.66, -0.71, -0.6, 0.21, 0.21, 0.42, -1.98, 0.98, 1.3, 1.71, -0.86, -1.2, -3.15, 0.24, 1.83, 0.3, -0.69, -0.23, -0.15, 0.61, -1.57, -1.51, -2.48, -2.03, -1.94, -0.06, -0.99, -0.53, -0.44, 0.75, -0.04154645354645334, 0.93, 0.46, 0.55, 0.21, 0.23, -0.19, 0.69, 0.16, -0.6, 0.71, -0.36, 0.47, 0.09, 0.26, -0.08, 0.45, 0.67, 0.22, 0.38, 0.96, -0.42, 1.06], ['205', -0.6857142857142857, -0.84, -0.38877828437954126, 0.44, -2.77, -1.44, -1.7058847420401708, -2.17, -3.19, -2.51, 1.03, -0.44, -1.05, -0.66, -0.29, -2.35, -0.95, -2.16, -2.09, 1.65, -4.09, -0.64, -0.29, -1.17, -2.81, -2.37, -3.51, -1.46, -2.07, -1.68, -1.31, -3.35, -1.96, -3.16, -3.09, 0.61, -5.07, -1.66, -1.31, -2.136158276802161, -1.89, -4.975063800783826, -2.08, -0.62, -0.23, 0.15, -1.92, -0.52, -1.73, -1.66, 2.1011904761904763, -3.67, -0.21, 0.15, -0.74, -0.88, -2.12, -2.17, -2.85, -1.47, 0.39, 0.77, -1.31, 0.1, -1.12, -1.05, 2.73, -3.07, 0.41, 0.77, -0.12, -2.29, -1.86, 0.38, -1.7, -0.29, -1.51, -1.43, 2.33, -3.45, 0.02, 0.38, -0.51, -4.18, -6.1, 6.13, -2.23, -2.07, -0.66, -1.87, -1.8, 1.94, -3.81, -0.35, 0.0, -0.89, -1.33, -0.16, 1.43, 0.2, 0.27, 4.1, -1.78, 1.75, 2.11, 1.21, -0.35, -0.13, -1.87, -1.73, -1.72, -1.57, -1.57, -1.22, -1.15, 2.62, -3.17, 0.31, 0.67, -0.23, -1.87, -0.36, 0.07, 3.89, -1.97, 1.55, 1.91, 1.01, -1.95, -1.46, 0.47, -1.49, -2.57, -0.26, -0.84, 3.32, -3.31, -1.7, -0.94, -2.48, 7.87, 3.45, 1.73, -0.06856122448979596, -1.67, -4.94, 5.08, 5.1, -1.7, 5.02, -3.43, -2.87, 1.48, -4.66, 14.77, 3.13, 4.68, -8.0, -0.43, 3.82, -2.04, 1.48, 1.84, 0.93, -5.15, -4.09, -5.64, -2.26, -1.8601904761904762, -2.78, 1.65, 3.59, 3.96, 3.04, -3.31, -3.7, -1.88, 0.36, -0.53, -1.69, -1.66, -1.99, 7.36, -1.88, -7.51, -2.23, -2.3589064979199876, -2.23, -0.89, -1.34, -1.77, -1.55, -1.1552380952380952, -1.28, -1.35, -2.4, -2.61, -1.3], ['206', -1.64, -0.62, -0.07984710169072946, 0.09, -1.39, -0.93, -0.89, -1.8, -2.11, -0.67, 2.95, 0.17, 1.61, 1.89, 1.82, -0.97, 1.46, -0.45, -1.4, 1.72, -1.68, 0.84, 1.46, 0.35, -1.09, -2.04, -3.51, -2.7, -1.29, -1.02, -1.09, -3.81, -1.45, -3.3, -4.22, -1.19, -4.49, -2.05, -1.44, -2.52, -1.13, -2.1, -0.84, 1.44, 1.72, 1.65, -1.14, 1.29, -0.29945408163265297, -1.56, 1.55, -1.85, 0.67, 1.29, 0.18, 0.1, -0.53, -1.4, -1.81, -2.25, 0.27, 0.21, -2.55, -0.15, -2.03, -2.96, 0.1, -3.24, -0.76, -0.15, -1.24, -1.96, -2.51, -0.07, -2.81, -0.43, -2.3, -3.23, -0.17, -3.51, -0.9485714285714286, -0.43, -1.51, -3.24, -5.68, 5.61, -2.45, -2.75, -0.36, -2.23, -3.16, -0.1, -3.44, -0.97, -0.36, -1.45, -2.6, 0.31, 2.45, 0.53, -0.43, 2.72, -0.71, 1.83, 2.46, 1.34, -0.22, 0.37, -2.44, -1.3984018193170984, -1.6, -1.37, -2.09, -1.88, -2.81, 0.26, -3.09, -0.61, 0.0, -1.09, -1.49, -0.22, -0.95, 2.18, -1.24, 1.29, 1.92, 0.8, -1.95, -1.86, 0.17, -1.85, -7.74, -0.12, -0.07, 3.7, -3.68, -1.84, -1.87, -2.75, 4.93, 2.88, 1.48, -0.88, -0.9, -4.43, 4.33, 4.33, -1.46, 5.55, -2.89, -1.51, 0.77, -6.35, 17.7, 4.12, 6.24, -4.85, 0.74, 3.16, -0.29, 2.27, 2.9, 1.77, -4.246832100439243, -2.2156457669314813, -3.34, -0.87, -0.25, -1.35, 1.03, 2.56, 3.19, 2.07, -2.1, -2.91, -1.49, 0.62, -0.48, -1.44, -1.56, -1.73, 11.01, -2.12, -10.56, -1.58, -2.34, -2.1, -1.09, -1.75, -1.7354471401614255, -0.72, -0.77, -0.52, -1.01, -3.55, -3.3, -1.69], ['207', -0.27, 0.42, 0.08, 0.02, -0.25, 0.44, 1.96, 0.46, 0.44, 0.2, 0.19, -0.88, -0.8, -0.12, -1.0, 0.35, -0.27, 0.11, 4.04, 0.56, -0.09266451791264106, -0.08, 0.43, -0.23, 0.57, 0.07, 0.01, -1.07, -0.99, -0.31, -1.19, 0.16, -0.46, -0.09, 3.84, 0.37, -0.32, -0.27, 0.24, -0.42, 1.32, 1.8549361992161735, 1.09, 0.07, 0.77, -0.13, 1.24, 0.61, 0.99, 4.96, 1.45, 0.75, 0.8, 1.32, 0.65, 0.73, 1.18, 1.19, 0.11, 1.02, 0.69, -0.2, 1.17, 0.54, 0.92, 4.88, 1.38, 0.68, 0.73, 1.2527347454133169, 0.58, 0.11, 0.32, -0.89, 0.47, -0.15, 0.22, 4.16, 0.68, -0.02, 0.04, 0.55, -0.05644035827487928, 0.08, 0.01, 0.06, 1.22, 1.37, 0.74, 1.12, 5.09, 1.58, 0.88, 0.93, 1.45, 0.78, -0.83, -0.15, -0.62, -0.25, 3.67, 0.21, -0.49, -0.43, 0.08, -0.58, 0.15, -0.12, 1.31, 0.3215981806829015, 0.2, 0.48567351865003194, 0.5418094764861292, 0.37, 4.32, 0.83, 0.13, 0.19, 0.7, 0.04, 0.35, 0.1, 3.93, 0.46, -0.24, -0.19, 0.33, -0.33, -0.41, -0.21, 0.04, 0.5, -2.57, 0.29, 0.18, -0.78, 0.77, 0.39, 0.14, -0.03, 0.72, -0.5, -0.27, -0.11, 0.18, 0.78, -0.76, -0.74, 0.25, -1.16, 0.49, -0.02, 0.02, 1.45, -0.52, -0.88, -1.47, -0.69, -3.69, -3.34, -4.01, -3.96, -3.46, -4.1, 0.69, -0.36, -0.69, -0.64, -0.13, -0.79, 0.34, 0.05, 0.57, -0.1, 0.46, 0.22, 0.28, 0.52, -0.15, 0.29, 0.32, 0.5825760496238783, 0.22, 1.4901996269574993, -0.21, 0.62, -0.41, -0.23, -0.66, 0.96, 0.22, 0.18, -0.35, 0.88, 0.515957527023814, 0.15, -1.11, 0.33], ['208', -2.38, 0.11, -0.028778284379541254, 0.06, -0.82, 0.54, -0.21, 0.23, 0.57, 0.0, -0.62, 0.16, -0.42, -0.19, 0.41, 1.5, -0.38, -0.15, 2.98, 1.14, 0.14, 0.3, -0.06, -0.81, 0.69, 0.06, 0.63, 0.79, 0.21, 0.43, 1.04, 2.14, 0.24, 0.48, 3.62, 1.78, 0.77, 0.93, 0.56, -0.18, 0.42, 0.68, -0.16, -0.58, -0.36, 0.25, 1.34, -0.54, -0.31, 2.81, 0.98, -0.03, 0.14, -0.23, -0.97, 0.7400628463056765, 1.07, 0.68, 0.57, 0.42, 0.23, 0.83, 1.93, 0.04, 0.27, 3.41, 1.57, 0.56, 0.72, 0.36, -0.39, 0.54, 0.19, 0.6, 1.7, -0.19, 0.05, 3.18, 1.34, 0.33, 0.49, 0.13, -0.61, 0.74, 0.14, -0.17, -0.41, 1.09, -0.79, -0.55, 2.56, 0.73, -0.27, -0.11, -0.47, -1.21, -0.4, -1.48, -1.86, -1.63, 1.45, -0.36, -1.35, -1.19, -1.54, -2.28, 0.11, -1.49, -0.39, 0.38, 0.37, 0.37, 0.38, 0.23, 3.3701587301587304, 1.53, 0.52, 0.68, 0.32, -0.42, -0.19, 0.15, 3.13, 1.29, 0.29, 0.45, 0.08, -0.66, -0.22, -0.33, 0.1, 0.37, -1.2, 0.12, -0.03, -1.02, 0.94, 0.48, 0.21, -0.47, 2.23, -0.74, -0.38, -1.18, 0.33, 1.18, -1.29, -1.28, 0.37, -1.53, 0.76, -0.45, 0.19, 1.11, -3.54, -0.81, -1.18, -2.18, -2.89, -1.78, -2.76, -2.6, -2.95, -3.67, 1.23, -1.13, -0.99, -0.83, -1.19, -1.93, -0.14, 0.16, -0.2, -0.94, 0.6, 0.73, -0.3, -0.36, -1.0277512446849837, 0.4, 0.36, 0.17, -1.09, -0.11980037304250064, 1.17, 0.01, 0.37, 0.06, -0.74, 0.6, 0.23, 0.76, 0.1, 0.43, 0.895957527023814, 0.24, 0.11, 1.17], ['209', -2.49, -0.54, -0.16877828437954126, 0.17, -1.32, -1.11, -1.2, -2.51, -2.01, -1.55, 1.25, -0.12, 0.47, 1.35, 1.77, -0.91, -0.16, -1.06, -1.55, -0.36, -2.22, -0.52, -0.2, -0.71, -2.68, -1.72, -2.77, -1.36, -0.77, 0.1, 0.51, -2.13, -1.39, -2.28, -2.77, -1.59, -3.43, -1.75, -1.43, -1.94, -1.38, -3.0550638007838264, -1.43, 0.59, 1.47, 1.89, -0.78, -0.04, -0.94, -1.43, -0.24, -2.1, -0.4, -0.08, -0.59, -1.57, -2.3142857142857145, -2.26, -1.6, -2.01, 0.88, 1.3, -1.37, -0.63, -1.52, -2.01, -0.82, -2.68, -0.98, -0.66, -1.18, -3.04, -2.86, 0.8402278911564625, -2.22, -1.49, -2.37, -2.86, -1.68, -3.52, -1.84, -1.52, -2.03, -2.66, -3.37, 3.416, -3.27, -2.63, -1.9, -2.78, -3.27, -2.09, -3.92, -2.25, -1.93, -2.44, -2.19, -0.65, 0.75, -0.15, -0.65, 0.55, -1.33, 0.39, 0.71, 0.19, -0.73, -0.71, -1.6, -1.02, -1.02, -0.95, -1.4, -0.9, -1.3998412698412697, -0.2, -2.07, -0.36, -0.04, -0.55, -0.93, -0.5, -0.5, 0.7, -1.18, 0.54, 1.0957142857142856, 0.35, -1.4, -1.63, 0.0, -1.15, -6.82, -0.30774866403437834, -0.22, 1.61, -1.7, -0.86, -0.15, -2.73, 2.39, 2.04, 1.04, -1.25, -0.73, -3.05, 3.0, 2.97, -1.0, 2.49, -2.02, -3.06, 1.55, -4.12, 14.86, 2.84, 4.16, -2.27, 0.0, 1.21, -0.68, 1.05, 1.38, 0.85, -3.03, -1.2, -1.87, -0.16, 0.16, -0.36, 0.68, 1.74, 2.07, 1.54, -1.99, -2.12, -1.04, 0.33, -0.19, -0.99, -1.07, -2.46, 7.4, -1.53, -7.58, -2.2, -1.44, -1.36, -0.52, -1.18, -0.86, -0.66, -0.43, -0.47, -0.85, -3.67, -0.88, -0.75], ['210', 2.72, -0.11, 0.08122171562045875, 0.19, 0.17, -0.31, -0.45, 0.5217205965359587, -0.77, 0.05, 1.62, 0.15, 0.843913265120849, 0.43, -0.76, -0.51, 0.47, 0.35, 1.49, -0.77, -0.32, 0.7, 0.47, -0.5, 0.43, -0.93, -1.54, -1.44, -0.4123253968253967, -1.17, -2.33, -2.09, -1.13, -1.24, -0.12, -2.34, -1.9, -0.9, -1.13, -2.09, 0.75, -1.74, -0.1, 0.62, 0.28, -0.91, -0.66, 0.31, 0.2, 1.34, -0.92, -0.47, 0.54, 0.32, -0.66, 0.34, -0.24, 0.78, -0.82, -0.72, -0.34, -1.52, -1.28, -0.31, -0.42, 0.71, -1.53, -1.09, -0.08, -0.3, -1.27, 0.78, -0.38, -1.18, -0.94, 0.04, -0.08, 1.06, -1.19, -0.75, 0.27, 0.04, -0.93, -1.52, -1.08, 1.03, 0.81, 0.3380874332127649, 1.23, 1.12, 2.26, -0.01, 0.6052352330209474, 1.46, 1.24, 0.25, -1.33, 0.57, 0.99, 0.87, 2.01, -0.26, 0.19, 1.22, 0.99, 0.01, -0.28, 0.56, -1.25, -0.21, -0.52, 0.08, -0.42, -0.11, 1.02, -1.23, -0.78, 0.23, 0.0, -0.97, -0.66, -0.3, 1.13, -1.12, -0.67, 0.34, 0.12, -0.86, -0.7610416300368755, -0.78, 0.19, -0.43, -4.41, 0.1, -0.1, -0.95, 0.91, 0.48, -0.46, -0.07, -1.5894817511227284, 0.41, 0.22, 1.42, -0.41, -0.64, 0.63, 0.65, -0.21, -1.29, -0.4, -1.29, 0.64, -1.21, 4.18, 0.89, 1.21, 1.69, -1.42, -2.22, -1.78, -0.78, -1.01, -1.97, -0.6, 0.82, 0.45, 1.47, 1.25, 0.26, 0.37, 1.02, 0.79, -0.19, -0.82, -1.21, -0.5527253150925656, -0.23, -1.19, -0.27, -0.17560369872470916, 0.4, 2.35, 0.1, -2.21, -0.55, -0.61, -0.42, -0.97, -0.43, 0.15, -0.41, -0.99, -0.16, 0.56, -0.95, -1.07, -0.15], ['211', 0.75, -1.4, 0.07122171562045874, 0.11, -1.33, -0.49, -1.84, -1.6, -1.79, -2.88, -0.78, -1.42, -1.73, -1.4429761904761904, -1.11, -3.65, -1.77, -2.83, -2.3, -0.82, -3.32, -2.05, -1.91, -1.93, -1.82, -0.76, -2.0873416050068876, -0.64, -0.96, -0.68, -0.34, -2.89, -1.0, -2.07, -1.53, -0.04, -2.56, -1.28, -1.14, -1.16, -1.6, -3.58, -1.49, -0.32, -0.03, 0.31, -2.26, -0.36, -1.44, -0.89, 0.6, -1.93, -0.64, -0.5, -0.52, -0.7, -0.97, -1.39, -1.11, -1.17, 0.29, 0.7348467679404526, -1.95, -0.04, -1.12, -0.57, 0.93, -1.62, -0.32, -0.18, -0.2, -0.63, -1.45, 0.35, -2.23, -0.32, -1.4, -0.86, 0.64, -1.9, -0.61, -0.47, -0.48, -2.48, -2.52, 2.45, -1.789129077338006, -2.481912566787235, -0.66, -1.74, -1.2, 0.29, -2.23, -0.95, -0.81, -0.83, 1.95, 0.8, 1.95, 0.85, 1.4005714285714286, 2.94, 0.34, 1.66, 1.8, 1.79, -0.08, 0.83, -0.78, -0.71, -0.78, -0.84, -1.14, -0.9534006093113236, -0.54, 0.96, -1.58, -0.29, -0.15, -0.16, -0.9, -0.05, 0.55, 2.07, -0.5, 0.81, 0.95, 0.93, -1.21, -1.05, 0.21, -1.06, 5.74, -0.14, 0.0, 2.39, -2.42, -1.19, -1.47, -1.32, 4.290518248877271, 1.4, 0.7, 0.33, -0.25, -2.3285238095238094, 2.08, 2.08, -0.7, 3.64, -1.42, -1.45, 0.71, -3.48, 9.03, 2.37, 3.4, -4.09, -0.6, 1.51, -1.05, 0.25, 0.39, 0.38, -2.1, -2.08, -2.52, -1.24, -1.1, -1.12, 0.45, 1.31, 1.46, 1.44, -1.73, -1.8, -0.85, 0.14, 0.12, -0.71, -0.84, -1.45, 4.6, -1.08, -4.80347619047619, -1.34, -1.09, -0.99, -0.02, -0.85, -0.9, 0.38, -0.32, -0.58, -0.97, -1.36, -0.89, -0.46], ['212', 8.94, -0.21, -0.8687782843795413, 0.35, 0.51, -0.83, -1.305884742040171, -1.16, -0.81, 0.42, 0.520608843537415, 1.46, 1.09, 1.95, 1.02, -2.39, 1.89, 2.07, -0.84, -1.7974455782312924, 0.41, 1.2, 2.08, 1.74, -1.72, -0.79, -0.09, 0.95, 0.58, 1.43, 0.5, -2.88, 1.37, 1.55, -1.34, -2.63, -0.09, 0.69, 1.56, 1.23, -0.87, -0.85, -1.03, -0.37, 0.48, -0.44, -3.8, 0.42, 0.59, -2.27, -3.54, -1.03, -0.26, 0.61, 0.28, -0.89, -0.58, -0.93, -0.36, -0.5907547529341225, 0.9531047225355607, -0.07, -3.44, 0.79, 0.96, -1.91, -3.19, -0.67, 0.11, 0.98, 0.64, -1.44, -1.5, -0.91, -4.25, -0.06, 0.12, -2.73, -4.0, -1.5, -0.73, 0.13, -0.2, -0.68, -4.34, 4.4, -0.6, -3.37, 0.86, 1.04, -1.84, -3.12, -0.6, 0.18, 1.05, 0.72, 2.71, 2.87, 4.38, 4.56, 1.59, 0.26, 2.87, 3.68, 4.721108978323264, 4.23, -1.2, 2.94, -2.03, -1.04, -1.06, -1.04, -1.44, 0.18, -2.6698412698412697, -3.95, -1.44, -0.67, 0.19, -0.14, -0.59, -1.62, -2.84, -4.11, -1.62, -0.85, 0.01, -0.32, -1.8410416300368755, -1.88, 0.43, -1.2, 5.57, -0.2696768707482993, 0.29, 2.53, -2.358279874187437, -1.23, 0.54, -2.17, -4.91, 2.06, 1.09, 4.5, -0.48, -3.13, 3.19, 3.09, -1.04, 3.64, -2.02, -3.26, 1.62, -4.34, 7.93, 2.93, 4.24, 4.9, 1.26, -1.31, 1.26, 2.06, 2.94, 2.765761712843646, -3.17, 2.6, 2.6, 3.41, 4.3, 3.96, 0.0, 0.78, 1.66, 1.32, -0.75, -0.65, -0.78, 0.87, 0.53, -1.11, -0.9456036987247092, -1.13, 4.02, -1.9698003730425007, -3.9, -1.03, -1.0688174603174603, -1.63, -0.33, -1.14, -1.04, -0.51, -0.62, -1.01, -1.3, -2.14, -2.66, -1.2669832262926028], ['213', -2.57, 0.12, -0.08, -0.3, 0.6929790809910596, 0.24, -1.095884742040171, -0.7, -0.24, -0.81, -1.04, 0.07, 0.37, -0.5, -0.42, 0.08, -1.58, -0.83, -1.3, -2.33, -0.58, -1.86, -0.79, -1.29, -0.18, -0.19, 0.23, 1.12, 1.43, 0.54, 0.62, 1.13, -0.54, 0.21, -0.27, -1.31, 0.46, -0.83, 0.25, -0.25, -0.42, -0.9250638007838266, -0.88, 0.3, -0.58, -0.49, 0.01, -1.65, -0.91, -1.38, -2.4, -0.66, -1.93, -0.86, -1.36, -0.15, -0.63, -0.59, 0.06, -1.18, -0.87, -0.79, -0.29, -1.94, -1.21, -1.67, -2.7, -0.95, -2.22, -1.16, -1.66, -2.52, -0.31, 0.08, 0.59, -1.08, -0.33, -0.8, -1.84, -0.08, -1.36, -0.29, -0.79, 0.07, 0.08, -0.08, -0.39, 0.5, -1.16, -0.42, -0.89, -1.92, -0.16, -1.44, -0.37, -0.87, -1.36, -0.89, -1.65, -0.91, -1.38, -2.41, -0.66, -1.93, -0.87, -1.37, -0.48, -0.7906317967746538, 0.18572371188304004, 0.27, 0.22, 0.38, 0.8518094764861293, 0.75, 0.28, -0.77, 1.01, -0.28, 0.8, 0.29, 0.91, 0.03, -0.47, -1.51, 0.25, -1.03, 0.05, -0.46, 0.1, 0.53, 0.05603717887804044, 0.7, -3.75, -1.14, -0.29, -1.12, 1.1, 0.56, 0.39, -0.44, -3.12, -0.63, -0.3, -1.29, 0.41, 0.92, -0.93, -0.85, 0.27, -1.74, 0.55, 0.26, -0.4, 2.38, -2.66, -1.66, -2.29, 3.07, 0.8203786848072563, -1.04, 0.73, -0.56, 0.52, 0.17576171284364575, 0.8, 1.56, 1.79, 0.49, 1.58, 1.07, -0.23, -1.28, -0.21, -0.71, -0.13, 0.0, 1.07, 1.09, 0.58, 0.26, 0.32, -0.54, -1.3, -0.09, 1.49, 0.41189489941485546, 0.4, -0.02, -0.51, 0.12, 0.55, 0.12, 0.73, 0.23, 0.48, -0.45, 1.08, 0.24], ['214', 0.94, 0.16, 0.21122171562045874, 0.19, 0.47, 0.46, 0.7141152579598291, 0.88, 0.86, 0.77, -0.25, -0.72, 0.36, -0.86, -0.32, 0.21, -0.34, 0.62, 1.09, 0.09, 0.94, 0.69, 0.23, 0.29, 0.26, 0.83, 1.0526583949931125, -0.48, 0.6, -0.62, -0.022180028704908802, 0.46, -0.09, 0.87, 1.34, 0.34, 1.19, 0.94, 0.47, 0.54, 0.85, 1.8549361992161735, 1.5, 1.08, -0.14, 0.4, 0.94, 0.39, 1.35, 1.82, 0.82, 1.67, 1.42, 0.95, 1.02, 0.2, -0.15, 0.28, 0.36, 0.41, -1.21, -0.67, -0.15, -0.69, 0.26, 0.73, -0.26, 0.58, 0.34, -0.13, -0.06, 1.01, 1.64, 0.55, 1.08, 0.53, 1.5, 1.97, 0.96, 1.82, 1.57, 1.1, 1.17, 1.54, 1.01, -1.07, 1.09, 0.53, -0.01, 0.94, 1.42, 0.41, 1.27, 1.02, 0.55, 0.62, 2.81, 0.56, -0.54, 0.41, 0.88, -0.12, 0.73, 0.48, 0.02, 0.08, 0.17, 0.53, 0.12017700342548367, 0.5315981806829014, 0.5551790696343399, 0.565673518650032, 1.11, 0.96, 1.43, 0.43, 1.28, 1.03, 0.56, 0.63, -0.15, 0.15, 0.47, -0.52, 0.32, 0.07, -0.39, -0.33, 0.48, 0.33, 0.19, 0.73, 8.71, 0.09, 0.14, -2.03, 2.07, 1.01, -1.42, 1.81, -1.49, -1.03, -0.48, 0.5, 0.07, 1.42, -1.54, -1.4, 0.47, -3.0, 0.9898783572413152, -1.13, 0.54, 3.33, -5.69, -2.27, -3.28, 1.48, -0.32, -0.99, -0.15, -0.4, -0.86, -0.79, 1.42, 0.68, 0.85, 0.6, 0.14, 0.2, -0.17, -0.25, -0.71, -0.64, 0.89, 0.86, 0.07, -0.46, -0.4, 0.5, 0.53, 0.88, -2.63, 0.52, 2.54, 1.3872638105244333, 0.5, 0.54, 0.07, 0.38, 1.0, 0.22, -0.2, 0.03, 0.47, 3.34, 1.61, 0.83], ['215', 0.8, 0.12, 0.05122171562045875, 0.13, 1.12, -0.34, -0.62, -0.27, -0.03, -0.76, -0.96, -0.59, -1.23, -0.48, -0.25, -1.04, -0.56, -0.67, 1.79, -1.54, -0.49, -0.99, -0.3556947683993239, -0.25, 0.18, 0.21937141458889198, 0.2, 0.37, -0.28, 0.48, 0.7678199712950912, -0.08, 0.41, 0.29, 2.77, -0.59, 0.47, -0.04, 0.51, 0.71, -0.42, -0.37506380078382656, -0.16, -0.64, 0.11, 0.34, -0.45, 0.04, -0.08, 2.39, -0.5203333333333333, 0.1, -0.4, 0.14, 0.34, 0.28, -0.16, -1.09, 0.13, 0.5592452470658775, 0.76, 1.0, 0.2, 0.69, 0.57, 3.06, -0.31, 0.75, 0.24, 0.79, 0.99, -0.38, -0.27, 0.23, -0.56, -0.07, -0.18, 2.28, -1.06, -0.01, -0.51, 0.03, 0.23, 0.04, -0.48, 0.45, -0.51, -0.79, -0.31, -0.42, 2.04, -1.29, -0.2261298384155527, -0.74, -0.2, 0.0, 0.04, 0.28, 0.49, 0.37, 2.885904761904762, -0.51, 0.55, 0.04, 0.59, 0.79, -0.19, 0.27, 0.0, -0.13, -0.18, -0.14, -0.1990429599640126, -0.11, 2.36, -0.99, 0.06, -0.44, 0.11, 0.31, 0.26, -0.09, 2.47, -0.88, 0.17, -0.33, 0.22, 0.42, -0.27, -0.25, 0.32, -0.38, 0.0, 0.28, 0.2, 0.18, -0.21, -0.11, 0.76, 0.46, -1.58, 0.26, 0.1, 0.42, -0.39, -0.44, 0.47, 0.46, -0.15, 0.06, -0.26, -1.83, 0.9647652642842468, -0.59, -5.25, 0.36, 0.61, 1.69, -2.5, -3.27, -2.24, -2.73, -2.2, -2.0, -0.45, 0.8, 1.06, 0.55, 1.1, 1.31, -0.26, -0.5, 0.04, 0.24, 0.03, 0.12, 0.24, 0.55, 0.75, -0.16, -0.16, -0.19, -1.71, -0.69, 1.75, -0.12273618947556672, 0.7310935020800124, -0.31, 0.2, -0.56, 0.04, -0.3047020479520478, -0.35, 0.08, -0.5, -0.94, 1.1730376647162362, -0.54], ['216', -5.56, 0.22, -0.36877828437954124, 0.07, -0.38, 0.26, 1.25, -0.32, 0.27, 1.76, 2.15, 1.0, 2.03, 1.88, 2.03, 3.81, 1.46, 1.84, 0.56, 1.85, 1.51, 1.22, 1.12, 1.3921746031746032, -1.1, -0.96, -0.38, -1.13, -0.12, -0.27, -0.12, 1.63, -0.68, -0.31, -1.56, -0.29, -0.63, -0.91, -1.01, -0.74, 0.49, 0.52, 0.75, 1.02, 0.86, 1.02, 2.78, 0.46, 0.83, -0.44, 0.84, 0.5, 0.22, 0.12, 0.39, -1.1, -0.61, -0.43, 0.21, -0.26, -0.15, 0.0, 1.75, -0.56, -0.19, -1.44, -0.17, -0.51, -0.79, -0.89, -0.63, -0.66, -0.11, 0.15, 1.9, -0.41, -0.04, -1.29, -0.02, -0.36, -0.64, -0.74, -0.47, 0.0, 1.7, -1.3344319727891159, -0.26, 1.75, -0.56, -0.19, -1.44, -0.17, -0.51, -0.79, -0.89, -0.63, -3.34, -1.97, -2.26, -1.9, -3.13, -1.89, -2.22, -2.5, -2.59, -2.33, 0.02, -1.99, 0.31, 0.28, 0.42, 0.22, 0.3, 0.37, -0.89, 0.3905357142857143, 0.04, -0.24, -0.34, -0.07, 0.39, -0.07, -1.25, 0.02, -0.32, -0.6, -0.7, -0.44, 0.57, 0.46, 0.27, 0.34, -10.1, -0.1, -0.68, 0.38, -0.3, -0.19, -0.4, -1.28, 0.1, -0.57, -0.28, -2.86, 0.4, 0.84, -0.87, -0.95, 0.28, 0.62, 0.57, -1.14, 0.59, 0.92, 1.7127091836734694, -0.67, -0.97, -0.14, 1.19, 1.29, 0.94, 0.66, 0.55, 0.83, 0.85, -0.09, -0.34, -0.62, -0.72, -0.45, 0.25, -0.27711507143650005, -0.38, -0.12, 0.19, 0.23, 0.53, -0.1, 0.17, 0.3, 0.3, -0.37, 1.16, 0.44, -1.22, 0.37, -0.49, 0.64, 0.34278685149693167, 0.23, -0.13, 0.77, 0.91, 0.53, 0.37, -1.12, -0.28, 0.75], ['217', 5.23, 0.0, 0.05122171562045875, 0.17, 1.0, 0.28, -0.08, 0.68, 0.51, 1.11, 0.07, 1.31, 0.84, 0.69, 1.16, -0.21, 0.86, 1.37, -0.01, -0.32, 1.61, 0.44, 0.37, 1.19, 1.27, 0.78, 1.04, 1.24, 0.78, 0.63, 1.1, -0.28, 0.79, 1.3, -0.08, -0.39, 1.55, 0.37, 0.3, 1.12, -0.3125315746467892, 0.22, -0.2, -0.46, -0.61, -0.15, -1.5, -0.45, 0.05, -1.31, -1.61, 0.3, -0.87, -0.93, -0.12, 0.91, 1.27, 0.987827972809784, 0.52, 0.33924524706587755, -0.15, 0.32, -1.04, 0.01, 0.52, -0.85, -1.15, 0.76, -0.4, -0.47, 0.34, 0.58, 0.41, 0.47, -0.9, 0.16, 0.67, -0.7, -1.01, 0.91, -0.26, -0.32, 0.49, 0.54, 1.83, -1.86, -0.05, -1.36, -0.3, 0.2, -1.16, -1.47, 0.44, -0.72, -0.79, 0.0740077275244506, 2.32, 1.32, 1.07, 1.58, 0.2, -0.11, 1.83, 0.65, 0.58, 1.4, -0.12, 1.37, -1.75, 0.24, -0.13, -0.2, 0.25, 0.5, -0.86, -1.17, 0.75, -0.42, -0.48, 0.33, 0.54, -0.25, -1.36, -1.66, 0.25, -0.92, -0.98, -0.17, -0.25, -0.46, 0.3, 0.32, 6.91, 0.18, 0.07, 0.39, -0.32, -0.18, 0.29, 1.51, -2.75, -0.49, -0.23, 2.55, 0.03, 0.75, -0.81, -0.64, 0.26, 0.54, 0.52, -1.88, 0.95, 1.64, -25.189348639455783, -1.12, -1.69, 2.72, 1.12, -0.31, 1.63, 0.45, 0.38, 1.2, 0.74, 1.43, 1.94, 0.76, 0.69, 1.51, -0.5, -1.1571150714365, -1.23, -0.42, 0.5, 0.72, 0.67, -0.07, 0.75, 0.3, 0.25, 0.66, -5.82, -1.29, 5.91, 0.89, 1.2, 0.74, 0.82, 0.13, -0.17, 0.12, 0.0, 0.16, -0.08, 1.83, 1.96, -0.25], ['218', -0.88, 0.11, -0.21, 0.25, 0.44, 0.24, 1.2441152579598291, 0.05, 0.36, 2.45, 2.6, 1.85, 1.49, 1.83, 2.73, 2.22, 1.63, 2.2, 4.2, 1.97, 1.99, 1.55, 0.25, 1.25, 1.61, -0.44, -0.15, -0.73, -1.09, -0.76, 0.13, -0.38, -0.95, -0.2727410958555916, 1.56, -0.61, -0.6, -1.02, -2.29, -1.32, -0.62, 0.71, 0.58, -0.36, -0.03, 0.86, 0.35, -0.22, 0.34, 2.3, 0.11, 0.13, -0.3, -1.58, -0.6, -0.22, -0.34, -0.94, 0.12, 0.95, 0.44310472253556066, 1.3348467679404525, 0.72, 0.14, 0.8026050661400617, 2.68, 0.48, 0.49, 0.38746485260770963, -1.22, -0.23, 0.05, 0.61, 0.89, 0.38, -0.19, 0.37, 2.33, 0.14, 0.16, -0.04285714285714287, -1.55, -0.57, 0.17, 5.63, -5.62, -0.27, -0.4119125667872351, -1.07, -0.52, 1.43, -0.74, -0.72, -1.15, -2.3890238095238097, -1.44, -2.62, 0.23, -0.57, -0.01, 1.94, -0.24, -0.22, -0.65, -1.93, -0.95, 0.781141873999017, 0.2, 0.77, 0.44, 0.75, 0.19, 0.81, 0.56, 2.53, 0.34, 0.35, -0.08, -1.36, -0.38, 1.0165360710717855, 0.24, 1.96, -0.22, -0.21, -0.64, -1.91, -0.93, 2.1789583699631248, 1.59, 0.62, 0.83, -8.17, 0.43, 0.29, -0.34, 0.36, 0.17, 0.78, -0.96, -0.93, -0.87, -0.44, -0.35, -0.44, 1.38, -1.61, -1.37, 0.42, -0.47, 0.88, -2.23, 1.12, 2.39, -3.4, -1.63, -2.41, 0.83, -1.3596213151927437, -2.14, -2.13, -2.54, -3.8, -2.83, 1.32, 0.47, 0.02, -0.41, -1.69, -0.71, 0.45, -0.43, -1.71, -0.72, 0.7601351386708531, 0.11, 0.89, -1.28, -0.3, 0.43, 0.47, 0.05, -1.62, 1.57, 1.88, -0.35, 0.4, 2.2, 1.0, 0.21, 0.32, -0.11, -0.8, -0.64, 1.19, 0.24, 1.24, 1.48], ['219', -5.8, -0.09, -0.07, 0.02, -1.32, -0.37, -0.5258847420401709, -1.6082794034640413, -1.17, -1.37, -0.03, -0.54, -1.096086734879151, 0.2, 0.58, -0.47, -0.5, -1.14, -1.08, 0.77, -1.55, -1.22, -1.99, -1.53, -2.02, -0.770628585411108, -1.3173416050068876, -0.51, -1.14, 0.23, 0.61, -0.44, -0.47, -1.11, -1.05, 0.8, -1.53, -1.19, -1.97, -1.5, -1.77, -1.36, -0.84, -0.63, 0.74, 1.13, 0.07, 0.04, -0.6, -0.54, 1.32, -0.9919345319135571, -0.68, -1.4257142857142857, -0.99, -1.24, -1.32, -1.62, -1.3, -0.21, 1.4831047225355605, 1.77, 0.7, 0.67, 0.02, 0.08, 1.96, -0.39, -0.06, -0.84, -0.37, -1.5063939988582844, -1.57, 0.39, -0.67, -0.7, -1.34, -1.276904761904762, 0.57, -1.75, -1.42, -2.19, -1.73, -1.05, 1.13, -1.1, -1.95, -1.05, -1.08, -1.72, -1.66, 0.19, -2.13, -1.79, -2.56, -2.1, 0.73, -0.91, -0.03, -0.68, -0.61, 1.25, -1.09, -0.75, -1.53, -1.07, -0.04, -0.97, -1.19, -0.32, -0.17, -0.44432648134996805, -0.88, -0.64, -0.58, 1.28, -1.06, -0.72, -1.5, -1.03, -0.26, -0.24, 0.06, 1.94, -0.42, -0.08, -0.86, -0.39, 0.04, -0.45, -0.28, -0.73, 1.83, -0.07, -0.02, 0.25, -0.19, -0.1, 0.14, -2.44, 4.25, 0.66, 0.3, -2.94, 0.13307978986877905, -1.04, 1.09, 0.89, -0.32, 0.36, -0.65, 0.14, -0.1, -2.64, 0.32, 1.74, 2.57, -4.29, -0.3, 1.87, -0.48, -0.14, -0.92, -0.45, -0.94, -2.13, -2.31, -1.98, -2.75, -2.28, 0.18, 0.34, -0.45, 0.02, -1.16, -1.14, -0.16, -0.78, -0.31, -0.28, -0.4, -1.54, -1.19, -0.93, 1.14, -0.62, -1.73, 0.63, 0.47, -1.13, -0.33, -0.03, 0.2, -0.35, 0.16, -1.85, -2.62, 0.64], ['220', -3.78, -0.47, 0.2, -0.1, -0.18, 0.21, 2.49, -0.54, 0.29, -1.87, -2.44, -2.88, -1.83, -1.27, -1.85, -0.82, -1.9, -1.87, 0.64, -2.1, -1.9, -1.79, -2.16, -2.38, -0.36, -0.27, 0.58, -0.44, 0.62, 1.21, 0.61, 1.67, 0.56, 0.58, 3.16, 0.35, 0.56, 0.67, 0.29, 0.10384172319783916, 0.74, -0.14, 1.03, 1.07, 1.66, 1.06, 2.12, 1.01, 1.03, 3.62, 0.8, 1.01, 1.12, 0.74, 0.51, -0.07, 0.37, -1.0, 0.0, -0.04, 0.58, -0.02, 1.04, -0.06, -0.04, 2.52, -0.27, -0.06, 0.05, -0.33, -0.56, -1.18, -0.62, -0.59, 0.45, -0.64, -0.62, 1.93, -0.85, -0.64, -0.53, -0.9, -1.13, 0.38, 0.66, -0.63, -0.02, 1.05, -0.05, -0.02, 2.54, -0.25, -0.05, 0.06, -0.31, -0.54, -2.75, -1.07, -1.09, -1.07, 1.47, -1.29, -1.09, -0.98, -1.35, -1.58, 0.07, -1.04, 0.13, -0.16, 0.27, -0.48, 0.02, 0.02, 2.59, -0.21, 0.0, 0.11, -0.27, -0.49, -0.03, 0.0, 2.56, -0.23, -0.02, 0.09, -0.29, -0.52, 0.12, -0.2, -0.01, 0.17, -8.24, -0.15, -0.13, 2.81, -2.93, -1.44, -0.47, 0.24616353211204947, -0.49, 0.31, 0.16, -1.89, 0.14, -0.48, 0.35, 0.49, -0.09670919513614704, 4.31, -0.27, 0.37, -0.19, 0.04, 9.6, -0.09, -0.11, 0.6, -2.5, -2.72, -2.52, -2.41, -2.78, -3.0, -0.44, 0.23, 0.21, 0.32, -0.06, -0.29, 0.02, 0.11, -0.27, -0.49, 0.35, 0.25, -0.09, -0.38, -0.6, -0.15, -0.09, -0.49, 5.3, 0.49, -5.46, 0.07, 0.13, 0.29, -0.15721314850306833, 0.35, -1.75, 0.11, 0.27, 0.49, 0.605957527023814, -2.17, -0.59, 0.69], ['221', -2.36, 0.45, 0.16, 0.02, -0.79, 0.2384196236737595, -1.19, -0.26, 0.34, 0.45, -0.13, 0.91, 0.43, 0.39, 1.81, 1.15, 0.31, 0.33, 1.82, -0.33, 0.8, 0.25, 0.5, 0.33, -0.3, 0.28, 0.58, 1.04, 0.56, 0.52, 1.94, 1.28, 0.44, 0.45, 1.95, -0.2, 0.9307606837606838, 0.38, 0.63, 0.46, 0.35, 0.6, -0.46, -0.48, -0.52, 0.89, 0.24, -0.6, -0.58, 0.9, -1.23, -0.11, -0.66, -0.41, -0.57, 0.47, 0.17, -0.22, 0.66, 0.01, -0.04, 1.37, 0.71, -0.12, -0.11, 1.38, -0.76, 0.37, -0.18, 0.07, -0.1, -0.54, 0.06, 1.41, 0.76, -0.08, -0.07, 1.42, -0.72, 0.41, -0.14, 0.11, -0.06, 0.77, 0.01, 0.0, -1.339129077338006, -0.65, -1.47, -1.46, 0.01, -2.1, -0.99, -1.53, -1.28, -1.45, -0.74, -0.7, -0.83, -0.82, 0.66, -1.47, -0.34, -0.89, -0.64, -0.81, 0.05, -0.64, -0.8398953488372093, 0.19, 0.22, 0.27, 0.14, 0.02, 1.51, -0.64, 0.49, -0.06, 0.19, 0.02, 0.21, 0.17307674813036728, 1.49, -0.65, 0.48956235827664396, -0.07, 0.18, 0.01, -0.32, -0.16, -0.11, 0.38, -2.29, 0.31, 0.2, -0.08, 0.1, 0.04, 0.24, 0.47, -1.67, -0.39, -0.2, -1.23, 0.48, 0.62, -0.64, -0.57, 0.2, -0.12, 0.4, 0.48, -0.24, 0.44, 0.57, -0.25, -0.43, 1.64, -1.35, -2.11, -1.0, -1.54, -1.29, -1.46, 0.64, 0.78, 1.14, 0.59, 0.84, 0.67, -0.35, -0.55, -0.3, -0.47, 0.5901351386708531, 0.86, 0.19, 0.25, 0.08, 0.22, 0.2, -0.23, 0.25, -0.5088836208193301, -0.3, 0.28, 0.29, -0.06, -0.17, 0.31, 0.07, 0.2, 0.69, 0.59, 0.11, -0.93, -0.02, 0.13], ['222', 2.92, 0.01, -0.07877828437954125, 0.07, -0.1170209190089404, 0.5, 0.36411525795982913, -0.82, -0.63, -0.84, -0.15939115646258506, -1.4, -0.68, 0.12, 0.97, -1.78, -1.34, -0.72, 1.72, -0.66, -1.39, -1.61, -0.29, -0.404883372579801, -0.58, -0.19, -0.67, -1.23, -0.51, 0.3, 1.14, -1.61, -1.17, -0.54, 1.89, -0.48, -1.22, -1.44, -0.12, -0.38, -0.8, -3.02, 0.769303232481804, 0.73, 1.54, 2.4, -0.38, 0.06, 0.69, 3.16, 0.76, 0.01, -0.21, 1.12, 0.86, -0.2, -0.87, -0.13, 0.14291666666666658, -0.16, 0.81, 1.66, -1.1, -0.67, -0.03, 2.41, 0.03, -0.72, -0.93, 0.39, 0.13, 0.53, -0.96, 0.85, -1.9, -1.46, -0.84, 1.59, -0.78, -1.52, -1.73, -0.41, -0.67, -1.24, -0.95, 0.9, -1.79, -2.72, -2.29, -1.67, 0.74, -1.416255228898086, -2.34, -2.55, -1.25, -1.51, 1.66, 0.96, 0.44, 1.08, 3.56, 1.14, 0.39, 0.18, 1.6511089783232642, 1.25, 0.05, 0.98, -0.23, 0.12, -0.16, 0.47, 0.51, 0.64, 3.1, 0.7, -0.05, -0.19969498055271245, 1.07, 0.81, 0.68, -0.12, 2.45, 0.06, -0.68, -0.9, 0.43, 0.17, -0.54, 0.47, 0.06, 0.69, 3.31, -0.13, -0.15, -0.6, 0.6, 0.32, 0.82, -0.82, 0.36, -0.25, -0.12, 1.53, 0.37, 0.58, -0.51, -0.4, 0.13, -1.07, 0.26, -0.84, 0.38, 1.49, 2.87, -1.02, -1.43, -0.37, -2.51, -2.33, -3.06, -3.27, -1.97, -2.23, 0.32, -0.045645766931481174, -0.74, -0.96, 0.37, 0.11, 0.56, -0.21, 1.12, 0.86, -0.55, -0.95, 0.78, 1.33, 1.07, 0.14, 0.17, -0.57, 1.33, -0.05, -0.7707193877551022, 0.48, -0.3688174603174603, -0.55, -0.26, 0.61, 0.38, 0.64, 0.09, 0.33, -0.29, -0.09, -0.46, 0.33], ['223', 4.64, -0.4, -0.18877828437954128, -0.12, -0.66, -0.97, -1.2558847420401709, -1.24, -1.68, -0.68, 1.24, 0.55, 0.2, 0.45, -0.22, -1.23, 0.74, -0.31, -0.6, 0.91, -1.09, 0.1, 0.95, 0.54, -1.13, -1.38, -1.9, -0.69, -1.03, -0.78, -1.44, -2.44, -0.49, -1.53, -1.82, -0.33, -2.235546329921431, -1.12, -0.29, -0.6461582768021608, -0.5, -3.18, -1.22, -0.35, -0.09, -0.76, -1.77, 0.2, -0.85, -1.14, 0.3607142857142857, -1.601934531913557, -0.44, 0.4, 0.0, -2.69, -1.17, -1.39, -1.37, -0.88, 0.26, -0.42, -1.43, 0.55, -0.5, -0.79, 0.71, -1.29, -0.09, 0.75, 0.34, -1.8863939988582845, -1.13, -0.67, -1.68, 0.29, -0.76, -1.05, 0.45, -1.54, -0.35, 0.49, 0.1435596417251207, -2.18, -4.47, 4.58, -0.46, -1.01, 0.97, -0.09, -0.38, 1.13, -0.88, 0.32, 1.17, 0.77, 1.48, 0.56, 2.0, 0.94, 0.64, 2.17, 0.14, 1.35, 2.21, 1.8, -0.35, 0.55, -1.6042762881169599, -1.04, -1.19, -0.96, -1.41, -1.04, -1.33, 0.16, -1.83, -0.64, 0.2, -0.2, -0.9, -0.37, -0.29, 1.22, -0.79, 0.41, 1.26, 0.85, -1.74, -1.32, -0.46, -1.29, 2.95, -0.53, -0.35, 1.76, -1.77, -0.9, -1.29, -2.04, 3.1, 2.03, 1.03, 2.41, -0.56, -3.2, 3.18, 3.02, -1.03, 2.63, -2.03, 1.86, -0.97, -4.21, 5.55, 2.88, 4.23, -3.06, -0.08, 1.51, -0.5, 0.7, 1.56, 1.15, -3.05, -1.57, -1.99, -0.8, 0.04, -0.36, 0.42, 1.21, 2.07, 1.66, -1.76, -2.25, -0.78, 0.85, 0.44, -1.0, -1.0456036987247093, -1.3, 2.94, -1.49, -2.98, -1.34, -0.44, -1.62, -0.4, -1.23, -0.69, -0.8, -0.93, -1.14, -1.22, 0.29, -0.76, -0.98], ['224', 2.98, 0.06, 0.011221715620458745, -0.29, 0.6, 1.0684196236737595, 0.97, 0.93, 0.93, 0.25, -1.36, 0.1, -1.17, -0.7, -0.94, -0.06, -0.9, 0.48, 1.15, 0.02, 0.43, -0.51, -1.31, -0.39, 1.0, 0.66, 1.63, 1.48, 0.2, 0.68, 0.4878199712950912, 1.32, 0.47, 1.87, 2.55, 1.4, 1.82, 0.87, 0.05, 0.99, 0.35, 0.7849361992161734, 0.34930323248180406, -1.26, -0.79, -1.03, -0.16, -1.0, 0.39, 1.06, -0.08, 0.34, -0.61, -1.41, -0.48, 0.21, 0.65, 0.67, 0.27, 1.43, 0.48, 0.23, 1.12, 0.27, 1.67, 2.35, 1.2, 1.62, 0.7296581632653062, 0.015338978481835797, 0.8141848072562359, 0.3736060011417156, 0.95, -0.24, 0.64, -0.21, 1.19, 1.86, 0.72, 1.14, 0.19, -0.62, 0.31, 1.7, 4.05, -3.99, 1.2, 0.89, 0.04, 1.43, 2.11, 0.97, 1.38, 0.43, -0.38, 0.56, 1.45, 0.31, -0.84, 0.54, 1.21, 0.08, 0.49, -0.45, -1.26, -0.33, -0.1, 0.31, 0.04, 1.05, 0.99, 1.09, 1.16, 1.4, 2.08, 0.93, 1.35, 0.4, -0.41, 0.52, 0.73, -0.23, 0.67, -0.36775528629437304, -0.05, -0.99, -1.79, -0.87, 1.33, 1.24, -0.25, 0.87, 4.38, -0.2, 0.07, -2.51, 2.51, 1.28, 0.37, 1.1, -0.45, -2.07, -1.05, 1.53, 0.72, 3.17, -3.12, -3.13, 1.03, -3.88, 2.07, 1.33, -0.91, 3.47, -9.74, -2.29, -3.5, 0.43, -0.5796213151927438, -1.12, -0.5127867132867132, -1.64, -2.44, -1.52, 3.15, 0.23, 0.41, -0.53, -1.33, -0.41, -0.19, -0.8511214088935782, -1.74, -0.82, 0.98, 1.3184535464535465, 0.76, -0.81, 0.12, 1.05, 1.04, 0.92, -6.14, 0.6603332627840632, 6.15, 1.2, 0.96, 1.58, 1.0127868514969316, 1.0, 1.36, 0.7, 0.33, 0.91, 0.64, 1.58, 1.13, 0.22], ['225', 5.29, 0.13, -0.05, -0.22, 1.34, 0.28, -3.59, 1.08, 0.3, 0.68, -0.09, 3.1, 2.07, 0.07, -0.49, -1.25, 0.84, 1.72, 0.77, -1.05, 1.62, 0.34, 1.52, 0.97, 2.17, 0.72, 0.77, 3.2001785714285718, 2.16, 0.16, -0.4, -1.16, 0.94, 1.81, 0.87, -0.96, 1.71, 0.43, 1.62, 1.06, 0.61, 1.45, -2.35, -1.0, -2.94, -3.4191849704247237, -4.22, -2.19, -1.34, -2.26, -4.03, -1.44, -2.68, -1.53, -2.07, 1.44, 1.4, 1.25, 0.93, -1.36, -1.96, -2.51, -3.25, -1.2, -0.34, -1.27, -3.0497619047619047, -0.44, -1.69, -0.53, -1.08, 1.77, 0.61, -0.56, -1.32, 0.77, 1.65, 0.7, -1.12, 1.55, 0.27, 1.45, 0.9, 0.86, -2.4, 2.36, 1.18, -0.76, 1.35, 2.23, 1.28, -0.56, 2.12, 0.84, 2.03, 1.47, 2.44, 1.96, 2.12, 3.01, 2.05, 0.21, 2.91, 1.61, 2.81, 2.25, -0.79, 2.04, -2.01, -0.06, -0.09, -0.18432648134996804, -0.16, 0.87, -0.07, -1.88, 0.77, -0.5, 0.67, 0.12, 0.06, -1.02, -0.6763144197072768, -2.72, -0.1, -1.36, -0.19, -0.74, -1.23, -0.79, -0.49, -0.86, 7.8, -1.34, -1.09, 1.09, -1.13, -0.56, -1.49, 1.7, -3.53, 0.07, 0.0, 2.67, 0.38307978986877905, -0.18, 0.19, 0.17, -0.05, 1.55, -0.15, -0.73, 0.13, -0.45, 5.91, 0.28, 0.41, 3.47, -0.09, -1.81, 0.84, -0.38270294784580494, 0.74, 0.19, -0.17, 1.75, 2.69, 1.4, 2.6, 2.04, -0.8555102040816327, -1.26, -0.09, -0.64, 0.43, 0.86, 0.34, 1.3732337781266353, 0.63, -0.05, -0.22, 0.92, 3.28, -1.94, -3.16, -0.27, 0.31, -0.83, -0.4772131485030684, -0.21, -0.13, 0.52, 0.75, 0.2, -0.29, 0.07, 0.22, -0.49], ['226', -0.34, 0.33, 0.25, 0.03, 0.47, 0.46, 0.73, 0.88, 1.04, 0.11, -1.37, 0.0019344980416409752, -1.11, -1.19, -1.0, 0.11, -0.7, -0.12, -0.8, -0.78, 0.7, -1.38, 0.47, -0.33, 0.68, 0.46, 1.5326583949931125, 1.19, 0.26, 0.18, 0.38, 1.51, 0.68, 1.27, 0.58, 0.6, 2.1, 0.0, 1.87, 1.06, 0.51, 1.7549361992161734, 0.31, -0.91, -0.99, -0.79, 0.32, -0.19134863945578234, 0.08, -0.6, -0.58, 0.9, -1.18, 0.7042857142857143, -0.13, 0.55, 0.62, -0.7, 0.87, 1.23, -0.08, 0.12, 1.24, 0.41, 1.0, 0.32, 0.33, 1.83, -0.27, 1.6, 0.79, -0.38, 1.32, 0.2, 1.32, 0.5, 1.08, 0.4, 0.41, 1.92, -0.19, 1.68, 0.87, 1.45, -0.35, 0.19, 1.11, 1.12, 0.29, 0.88, 0.2, 0.21, 1.71, -0.38, 1.48, 0.67, -0.56, -0.01, -0.81, -0.24, -0.9084761904761905, -0.9, 0.59, -1.49, 0.36, -0.44, 0.2, 0.0, 2.12, 0.37, 0.34, 0.38, 0.82, 0.58, -0.1, -0.08, 1.41, -0.68, 1.18, 0.38, 1.33, 0.23, -0.68, -0.66, 0.82, -1.25, 0.59, -0.21, 0.26, 1.06, 0.03, 0.58, -1.82, 0.2980695494981211, 0.05, -0.22, 0.23, 0.11, 0.37, 1.47, -1.83, -0.77, -0.36, -0.16, 0.86, 1.0, -1.04, -1.04, 0.38, -0.35, 0.72, 0.09, -0.08, 2.41, -4.61, -1.63, -2.41, 1.7, 0.91, 0.01, 1.51, -0.58, 1.28, 0.47, 1.2, 0.9, 1.5, -0.6, 1.26, 0.46, -0.59, -2.06, -0.23, -1.02, 0.98, 1.25, 1.5, 1.87, 1.06, 0.4, 0.42, 0.91, -2.89, 0.19, 3.04, 0.27, 0.07, -0.36, -0.7172131485030684, 0.96, 0.14, 0.99, 1.07, 0.59, 0.525957527023814, -0.93, -0.49, 0.2], ['227', -1.11, 0.46, 0.41, -0.14, 0.46, 0.98, 1.48, 1.4, 1.63, 1.19, -0.97, -0.15, 0.31, 0.61, -0.15, 1.21, -0.08, 0.5, 2.4, -0.59, 1.28, 0.06, -0.73, -0.43, 1.55, 1.29, 2.18, 0.8301785714285714, 1.29, 1.59, 0.83, 2.2, 0.9, 1.48, 3.41, 0.39, 2.28, 1.04, 0.24, 0.5838417231978392, 0.71, 2.96, 1.5493032324818041, 0.46, 0.76, 0.0, 1.37, 0.08, 0.65, 2.56, -0.44, 1.44, 0.21, -0.58, -0.28, 1.26, 0.8, 2.02, 1.96, 0.88, 0.3, -0.45, 0.9, -0.38, 0.19, 2.09, -0.89, 0.97, -0.25, -1.04, -0.74, 1.44, 0.58, -0.7353571428571428, 0.6, -0.68, -0.11, 1.78, -1.19, 0.67, -0.55, -1.33, -1.03, 1.94, 5.12, -5.07, 1.34, 1.36, 0.07, 0.65, 2.55, -0.44, 1.43, 0.2, -0.58, -0.29, -0.91, -0.02, -1.27, -0.71, 1.18, -1.78, 0.07, -1.14, -1.92, -1.62, 0.64, -0.05, 3.98572371188304, 1.08, 1.19, 1.065673518650032, 1.27, 0.57, 2.48, -0.51, 1.36, 0.13, -0.65, -0.36, 1.17, 0.69, 1.9, -1.08, 0.78, -0.44, -1.22, -0.92, 2.13, 1.89, -0.2, 1.23, -2.63, 0.29, 0.42, -1.43, 1.4224623233908948, 0.7688101710076211, 0.79, 2.12, -3.58, -2.08, -1.05, -0.54, 0.5, 3.3, -3.25, -3.19, 1.123290804863853, -2.27, 2.15, 1.82, -0.91, 3.69, -5.48, -2.58, -3.76, 3.62, -1.18, -2.92, -1.09, -2.29, -3.023374458874459, -2.77, 3.13, 1.79, 1.88, 0.65, -0.14, 0.16, -0.09, -1.21, -1.99, -1.7, 1.59, 2.05, 1.14, -0.79, -0.49, 1.08, 1.11, 1.4, -4.19, 3.1711163791806696, 4.37, 1.4618948994148555, 0.54, 1.94, 0.3, 1.54, 0.85, 0.48, 0.2, 0.6, 1.63, 1.56, -0.06, 1.68], ['228', 2.85, -1.09, -0.10877828437954125, 0.03, -0.23, 0.54, -0.46, 0.31, 0.62, 0.08, -1.36, 0.4, -0.18, -0.26, -0.46, -1.37, -0.6, -0.14, 3.72, -0.07, 0.84, 0.46, -1.33, -0.27, 0.64, 0.6, 1.4926583949931125, 1.78, 1.19, 1.11, 0.91, -0.02, 0.77, 1.24, 5.14, 1.31, 2.23, 1.84, 0.03, 1.1, -0.57, 1.4949361992161734, -0.31, -0.58, -0.66, -0.86, -1.76, -0.99, -0.53, 3.31, -0.46, 0.44, 0.06, -1.72, -0.66, 0.09, 0.29, -0.14, 0.84, 0.27, -0.08, -0.28, -1.19, -0.41, 0.05, 3.91, 0.12, 1.02, 0.64, -1.091735383663955, -0.08, 1.16, 0.34, -0.2, -1.12, -0.34, 0.12, 3.99, 0.19, 1.1, 0.72, -1.07, -0.01, 1.3, 3.62, -3.66, 0.55, -0.92, 0.2999013605442177, 0.33, 4.2, 0.4016746031746032, 1.31, 0.92, -0.8390238095238095, 0.19, 4.84, 1.48, 0.79, 1.25, 5.16, 1.32, 2.24, 1.86, 0.04, 1.12, 0.33, 1.44, 0.49, 0.69, 0.83517906963434, 0.61, 0.68, 0.46, 4.34, 0.53, 1.44, 1.1203050194472877, -0.74, 0.33, -0.37, 0.22, 3.86, 0.16224471370562701, 0.97, 0.59, -1.19, -0.13, 1.56, 1.19, 0.11, 0.76, 14.887738095238095, 0.25, 0.07, -1.86, 1.79, 0.91, 0.36, 0.72, -0.36, -1.35, -0.72, 1.41, 0.57, 2.06, -2.14, -2.03, 0.69, -2.69, 1.4198783572413154, 0.26, -0.14, 1.94, -0.75, -1.35, -1.97, 0.32, -3.5, -3.65, -2.78, -3.14, -4.86, -3.84, 1.99, 0.15, 0.91, 0.53, -1.26, -0.2, -0.75, -0.38, -2.15, -1.1, 0.66, 1.04, -0.37, -1.78, -0.72, 0.71, 0.71, 0.14, -0.49, 0.58, 0.52, 0.5172638105244333, -0.07, 1.43, 1.07, 0.85, 0.99, 0.02, 0.79, 0.81, 0.35, 1.23, -0.48, 0.43], ['229', 1.62, -1.01, -0.25, 0.37, -1.72, -1.0215803763262405, -1.81, -1.6, -1.99, -2.59, 0.3, -1.4792857142857143, -0.7, -0.07, -0.95, -3.43, -1.05, -2.13, -0.35, 0.55, -3.17, -0.72, -0.78, -1.29, -2.22, -1.62, -2.8473416050068874, -1.78, -0.99, -0.36, -1.25, -3.71, -1.34, -2.42, -0.65, 0.26, -3.46, -1.01, -1.07, -1.58, -1.42, -2.98, -1.12, 0.8, 1.44, 0.54, -1.948956349206349, 0.44, -0.66, 1.15, 2.07, -1.71, 0.78, 0.8071428571428572, 0.2, 0.14, -1.81, -2.28, -2.26, -1.91, 0.63, -0.15515323205954745, -2.75, -0.35, -1.45, 0.34, 1.2602380952380952, -2.49, -0.02, -0.08, -0.59, -1.3, -2.52, -0.88, -3.36, -0.98, -2.07, -0.29, 0.62, -3.11, -0.65, -0.71, -1.22, -2.78, -5.04, 5.07, -1.65, -2.5, -0.1, -1.19, 0.6, 1.52, -2.24, 0.24, 0.18, -0.34, 0.93, 0.87, 2.46, 1.34, 3.18, 4.12, 0.26, 2.8124285714285713, 2.74, 2.22, -0.57, 0.86, -3.8542762881169597, -1.19, -1.28, -1.19, -1.4881905235138708, -1.1, 0.7, 1.62, -2.15, 0.34, 0.27, -0.24, -1.85, -0.46, 1.82, 2.75, -1.06, 1.5757995496566926, 1.39, 0.87, -2.04, -1.77, 0.21, -1.68, 2.76, -0.42, -0.35, 1.31, -1.29, -0.62, -0.74, -2.37, 6.48, 2.42, 1.21, 0.89, -0.56, -3.88, 3.56, 3.49, -1.17, 1.91, -2.35, -4.57, 2.35, -4.66, 5.57, 3.1, 4.51, -6.3, -2.24, 0.91, -2.83, -0.36, -0.42, -0.93, -3.52, -3.13, -3.7, -1.26, -1.32, -1.83, 0.6, 2.54, 2.47, 1.95, -1.99, -2.44, -1.89, -0.06, -0.57, -1.21, -1.27, -1.66, 4.11, -3.07, -4.28, -1.1627361894755668, -2.75, -1.83, -0.43721314850306836, -1.41, -0.53, -0.62, -0.5, -0.55, -1.234042472976186, -2.74, -3.96, -1.75], ['230', 0.47, 0.94, -0.07877828437954125, -0.08, -0.47, 0.92, 0.09, 1.24, 0.85, 1.2770884353741496, 0.12, 0.52, -1.04, -0.52, -2.15, -0.14, -0.35, 0.68, 2.93, 2.44, 0.83, 0.13, -0.32, 1.62, 0.91, 1.43, 0.72, 0.4, -1.16, -0.64, -2.27, -0.25, -0.47, 0.56, 2.81, 2.32, 0.794453670078569, 0.01, -0.43, 1.5, 1.26, 0.6049361992161734, 0.5093032324818041, -1.55, -1.03, -2.66, -0.65, -0.87, 0.16, 2.4, 1.91, 0.31, -0.39, -0.83, 1.09, -0.1476426685347185, 0.25, 0.78, 1.21, 1.89, 0.52, -1.12, 0.91, 0.69, 1.74, 4.01, 3.51, 1.89, 1.1959625850340136, 0.7882646163360448, 2.68, -0.09, 1.36, -1.64, 0.39, 0.17, 1.21, 3.47, 2.97, 1.36, 0.66, 0.21, 2.15, 0.98, 3.22, -3.23, 3.05, 2.06, 1.84, 2.895714285714286, 5.2, 4.69, 3.05, 2.33, 1.9109761904761904, 3.85, 0.91, 0.97, -0.22, 0.833095238095238, 3.07, 2.58, 0.97, 0.27, -0.18, 1.75, 0.37, 1.08, 1.33, 0.58, 0.94, 0.26, 1.19, 1.03, 3.3, 2.8, 1.19, 0.49, 0.04, 1.98, 0.64, 0.15, 2.24, 1.75, 0.15956235827664397, -0.54, -0.99, 0.93, 1.41, 2.279561224489796, 0.0, 0.8, 1.51, 0.38, 0.24, 0.67, -0.64, -0.33, 0.62, 3.16, 2.84, -1.09, -0.57, 0.2, 0.4, 1.71, -1.82, -1.88, 0.59, 1.11, 1.19, 1.69, -0.83, 3.49, -2.54, -2.26, -3.63, -2.93, -2.04, -0.48, -2.04, -2.72, -3.16, -1.28, 1.73, -1.56, -1.56, -2.25, -2.69, -0.8, 0.0, -0.7, -1.14, 0.78, 0.85, 1.1, 0.7, -0.45, 1.48, 0.57, 0.59, 1.27, -1.28, 2.0, 0.96, 1.02, 1.34, 1.15, 1.94, 0.4, 0.12, 0.55, 0.61, 1.37, -0.77, 1.23, 2.321595238095238, -0.52], ['231', 0.5, -0.51, 0.08, 0.32, -0.19702091900894042, -0.91, -1.48, -1.49, -1.76, -4.04, -1.36, -2.97, -2.72, -2.92, -3.2, -5.088928571428571, -2.22, -3.596530612244898, -1.58, -2.62, -4.13, -3.28, -1.96, -3.44, -2.77, -1.36, -2.72, -1.6294545454545453, -1.38, -1.58, -1.87, -3.78, -0.87, -2.28, -0.23, -1.28, -2.81, -1.94, -0.61, -2.1, -1.16, -2.92, -1.11, 0.25, 0.05, -0.24, -2.18, 0.77, -0.339454081632653, 1.43, 0.36, -1.2, -0.32, 1.04, -0.48, -0.38, -2.35, -2.44, -1.09, -1.36, -0.2, -0.49, -2.43, 0.52, -0.91, 1.17, 0.11, -1.45, -0.5103418367346938, 0.78, -0.73, -0.31, -1.16, -0.29, -2.2285714285714286, 0.72, -0.71, 1.6274764481550195, 0.31, -1.25, -0.37, 0.99, -0.53, -2.51, -5.48, 5.42, -0.87, -1.95, 1.02, -0.42, 1.67, 0.6, -0.96, -0.08, 1.28, -0.24, -0.97, 1.1, 3.02, 1.56, 3.69, 2.6, 1.0, 1.91, 3.29, 1.74, -0.52, 1.04, 0.17, -1.16, -1.26, -1.19, -1.87, -1.42, 0.65, -0.41, -1.96, -1.08, 0.26, -1.25, -0.88, -0.39692325186963273, 2.1, 1.03, -0.54, 0.35, 1.71, 0.18, -2.25, -1.71, 0.46, -1.58, -1.76, -0.32, 0.0, 2.5, -2.37, -1.2, -0.64, -2.47, 2.67, 2.34, 1.11, 0.26, -0.51, -3.68, 3.61, 3.47, -1.17, 3.6, -2.35, -3.12, 1.58, -5.6, 5.75, 3.74, 5.61, -2.73, -2.5, -1.05, -2.59, -1.72, -0.38, -1.88, -3.47, -1.46, -1.55, -0.67, 0.68, -0.84, 0.1, 0.89, 2.27, 0.73, -1.84, -2.01, -0.79, 1.36, -0.16, -1.05, -1.23, -1.47, 3.08, -0.95, -3.07, -1.46, -2.01, -2.12, -1.51, -1.63, -1.3, 0.1, -0.43, -0.43, -0.63, -2.58, -3.76, -1.65], ['232', 0.18, 0.44, -0.09877828437954125, -0.01, 0.21, 0.92, 1.4, 0.83, 1.18, 1.24, -0.17, 0.37, 0.72, -0.39, 0.19, 1.4, -0.56, 0.82, -1.44, 1.19, 1.47, 0.13, -0.11, 0.81, 0.54, 1.21, 1.41, 0.55, 0.89, -0.22, 0.36, 1.57, -0.39, 0.99, -1.27, 1.36, 1.64, 0.3, 0.06, 0.98, 0.68, 1.06, 0.86, 0.34, -0.76, -0.18, 1.02, -0.93, 0.44, -1.81, 0.81, 1.09, -0.25, -0.48, 0.44, 0.33006284630567656, 0.24, -0.15, 1.33, 0.52, -1.1, -0.52, 0.67, -1.27, 0.1, -2.14, 0.47, 0.75, -0.59, -0.82, 0.09, 0.26, 1.63, 0.58, 1.79, -0.18, 1.21, -1.05, 1.58, 1.86, 0.52, 0.28, 1.2, 1.28, 3.44, -3.48, 1.05, 1.2, -0.75, 0.62, -1.63, 1.193744771101914, 1.28, -0.06, -0.3, 0.62, 2.48, -0.15, -1.93, -0.57, -2.8, -0.21, 0.07, -1.25, -1.48, -0.58, 0.32, -0.12, -0.56, 1.04, 1.11, 1.07, 1.81, 1.39, -0.88, 1.76, 2.04, 0.69, 0.46, 1.38, 0.96, 0.47307674813036726, -2.24, 0.37, 0.8286030199958774, -0.68, -0.92, 0.0, 2.06, 2.55, -0.14, 1.53, 7.728670068027211, 0.07, -0.07, -2.82, 2.79, 1.428810171007621, 0.59, 0.96, -0.19, -2.13, -1.02, 0.12, 0.67, 3.27, -3.24, -3.08, 1.03, -4.2, 2.05, 1.59, -0.78, 5.38, -5.440028911564625, -3.53, -5.3, 0.26, 2.72, 2.66, 2.95, 1.59, 1.35, 2.28, 3.18, 0.05, 0.28, -1.05, -1.28, -0.37, -0.23, -1.32, -1.55, -0.65, 1.13, 1.29, 1.11, -0.23, 0.68, 0.99, 1.13, 0.8, -2.64, 0.55, 2.41, 1.66, 1.19, 1.35, 0.92, 0.79, 1.41, 0.75, 1.27, 0.62, 0.505957527023814, 2.67, 1.86, 1.03], ['233', -0.8, 0.0, 0.011221715620458745, -0.24, -1.23, 0.04, 1.63, -0.23, 0.82, -0.42, -1.45, -1.4, -0.9, -0.42, 2.6, -0.06, -0.63, -0.78, 0.37, 2.55, -0.38, -0.6, -1.11, -0.49, -0.04, 0.04, 1.04, 0.05, 0.56, 1.04, 4.11, 1.41, 0.83, 0.68, 1.85, 4.06, 1.08, 0.86, 0.35, 0.97, 0.06, 2.39, 0.990204081632653, 0.5, 0.99, 4.05, 1.36, 0.78, 0.62, 1.8871355564861205, 4.0, 1.03, 0.81, 0.29, 0.92, -0.07, 0.29, 0.16, 0.84, 0.48, 0.48, 3.53, 0.85, 0.28, 0.12, 1.28, 3.48, 0.52, 0.3, -0.21, 0.41, -0.11, 0.0, 3.04, 0.37, -0.2, -0.36, 0.8, 2.99, 0.04, -0.18, -0.68, -0.07, 1.24, 1.85, -1.9, -2.95, -2.59, -3.15, -3.3, -2.17, -0.05, -2.91, -3.12, -3.61, -3.01, -0.21, -0.37, -0.57, -0.73, 0.43, 2.61, -0.32, -0.55, -1.05, -0.44, 0.31, -0.33, -0.26, 0.0, 0.06, -0.09, 0.2, -0.16, 1.0, 3.2, 0.25, 0.09030501944728757, -0.48, 0.14, 0.03, 0.36, 1.16, 3.36, 0.409562358276644, 0.18, -0.33, 0.29, 0.51, 0.3, -0.01, 0.13, -0.74, 0.23, 0.22, -0.52, 0.49, 0.26, -0.53, -1.72, 5.59, 0.0, 0.03, -0.4, -0.58, 0.09, 0.0, 0.04, -0.01, -0.82, -0.17, 0.63, -0.26, 0.56, -3.08, -0.35, -0.62, -5.57, -0.4696213151927438, 2.17, -0.75, -0.97, -1.47, -0.86, -0.04, -2.9, -2.86, -3.07, -3.57, -2.97, -0.04, -0.22, -0.73, -0.11, 0.87, 1.0, 0.18, -0.51, 0.11, -0.09, -0.03, -0.08, -1.9728571428571429, -0.43, 1.77, -0.11, -0.23, 0.69, 0.62, -0.23, 0.24, -0.67, -0.9, -0.21, 0.07, 1.02, -0.5, 0.39], ['234', -2.21, -1.53, -0.18877828437954128, 0.07, -0.42, -0.34, -0.62, -0.8482794034640413, -0.9, -1.31, -0.59, -1.16, 0.19, -0.8, 0.75, -1.01, -0.94, -1.1, 2.45, -0.34, -1.92, -1.14, -1.07, -0.93, -0.46, -0.53, -0.72, -0.57, 0.79, -0.2, 1.35, -0.42, -0.34, -0.51, 3.06, 0.25, -1.33, -0.54, -0.48, -0.34, -0.76, -2.56, -0.15, 1.37, 0.5378753944468231, 1.94, 0.15, 0.23, 0.06, 3.65, 0.83, -0.76, 0.03, 0.09, 0.23, 0.0, -0.69, -0.22, -0.71, -1.5, -0.99, 0.56, -1.2, -1.13, -1.29, 2.25, -0.53, -2.11, -1.33, -1.26, -1.13, -0.43, -0.52, 1.56, -0.22, -0.14, -0.31, 3.27, 0.46, -1.13, -0.34, -0.28, -0.14, -1.48, -0.98, 1.0, -2.05, -1.7494795918367347, -1.68, -1.84, 1.68, -1.09, -2.65, -1.87, -1.8014761904761905, -1.68, -0.12, -0.3, 0.07, -0.09, 3.49, 0.67, -0.92, -0.13, -0.06, 0.08, -0.27, -0.35, -0.83, -0.28, -0.32, -0.23, -0.38, -0.17, 3.42, 0.6, -0.99, -0.2, -0.13, 0.0, -0.24, -0.21, 3.59, 0.77, -0.82, -0.04, 0.03, 0.17, 0.12, 0.16, 0.17, -0.22, -0.46, 0.0, 0.02, 0.69, -0.67, -0.34, -1.33, -1.3, 2.01, 0.54, 0.22, -1.1, 0.0, -0.87, 0.93, 0.83, -0.28, 0.97, -0.56, -0.37160934502005916, 0.24, -1.14, 1.59, 0.78, 1.01, -2.04, -3.67, -2.72, -4.26, -3.5, -3.43, -3.3, -0.81, -0.97, -1.58, -0.8, -0.73, -0.6, 0.62, 0.8, 0.86, 1.0, -0.88, -1.19, -0.17, 0.07, 0.2, -0.3, -0.23560369872470915, -0.86, 1.17, -0.84, -1.2, -0.71, -0.10890649791998751, -0.24, 0.14, -0.24399479488765202, -0.42, 0.38, 0.25, -0.55, -0.38, -0.76, -0.4, -0.28], ['235', -1.17, -0.6, -0.14, 0.14, -0.78, -1.19, -1.33, -0.67, -1.45, -0.37, 1.61, 0.83, 0.93, 0.63, 0.34, -0.36, 1.04, -0.01, -2.8, -0.55, -0.85, 0.05, 0.45, 0.35, -1.05, -1.05, -1.95, -0.77, -0.67, -0.96, -1.25, -1.94, -0.56, -1.6, -4.34, -2.12, -2.42, -1.54, -1.14, -1.24, -0.55, -4.04, -1.19, 0.1811974674961171, -0.2, -0.49, -1.18, 0.2, -0.84, -3.6, -1.37, -1.67, -0.78, -0.38, -0.48, -0.49, 0.55, -1.07, -1.56, -1.29, -0.3, -0.5792006802721088, -1.28, 0.11, -0.94, -3.69, -1.4697619047619048, -1.76, -0.88, -0.48, -0.58, -0.25, -0.99, -0.29, -0.99, 0.4, -0.64, -3.41, -1.17, -1.47, -0.58, -0.18, -0.29, -2.37, -2.49, 2.46, -0.6733017616146798, -0.7, 0.69, -0.35, -3.13, -0.89, -1.19, -0.3, 0.11, 0.0, -0.1, 0.0, 1.41, 0.35, -2.44, -0.18, -0.49, 0.41, 0.82, 0.71, -0.118858126000983, -0.07, -1.98, -1.17, -1.33, -1.06, -1.39, -1.04, -3.8, -1.57, -1.87, -0.98, -0.58, -0.69, -0.45, -0.35, -2.78, -0.53, -0.84, 0.06, 0.46, 0.36, -0.28, -0.56, 0.2, -1.5, -0.25, -0.36, -0.07, 1.61, -1.69, -0.82, 0.13, -1.68, -0.31, 2.34, 1.15, -0.57, -1.0, -3.46, 3.48, 3.52, -1.17, 2.49, -2.35, -1.69, 0.83, -4.14, 7.46, 2.8, 4.35, 0.39, 2.5, 2.31, 2.0, 2.92, 3.34, 3.23, -3.5, 0.18, -0.3, 0.6, 1.0, 0.9, 0.49, 0.9, 1.31, 1.2, -1.49, -1.79, -0.41, 0.4, 0.3, -1.067919965685943, -1.22, -0.68, 4.84, -2.2, -5.06, -1.59, -2.27, -0.81, -0.1, -1.45, -1.16, -0.54, -0.85, -1.44, -0.71, -3.24, -2.71, -1.01], ['236', -3.53, 0.4, 0.17122171562045874, -0.24, -0.04, 0.13, 0.17411525795982916, 0.69, 0.78, 0.66, 0.66, 0.33, 0.47, 0.07, 0.05, 1.27, 1.37, 0.91, 3.48, -0.8690034013605442, 0.57, 0.6, 0.39, 0.875116627420199, 0.69, 0.19, 0.0, -0.33, -0.19, -0.59, -0.61, 0.6, 0.71, 0.25, 2.8, -1.54, -0.09, -0.06, -0.27, 0.07, 0.42, 0.95, 0.33, 0.14, -0.26, -0.28, 0.94, 1.04, 0.58, 3.14, -1.21, 0.25, 0.27, 0.06, 0.4, 0.26006284630567655, 0.76, 0.82, 1.19, 0.19, -0.4, -0.42, 0.8, 0.9, 0.44, 3.0, -1.35, 0.1, 0.13, -0.08, 0.26, 0.88, 0.59, -0.02, 1.3555085034013605, 1.3, 0.84, 3.41, -0.95, 0.5, 0.53, 0.32, 0.66, 0.74, 0.35, -0.35857142857142854, 0.61, 1.22, 1.3417857142857144, 0.86, 3.43, -0.93, 0.53, 0.55, 0.34, 0.68, -1.14, -0.5226334687834371, 0.1, -0.36, 2.18, -2.13, -0.69, -0.6575714285714286, -0.87, -0.53, -0.25, -0.64, -0.93, 0.14, 0.25, -0.09, -0.7, -0.46, 2.08, -2.0302873118944547, -0.79, -0.76, -0.97, -0.63, 0.09, -0.25, 2.55, -1.78, -0.33, -0.31, -0.52, -0.18, 0.28, 0.15, -0.35, -0.4, -3.64, -0.43, -0.14, 0.22, -0.22, -0.09, 0.27, 0.6, -3.09, -0.26, -0.14, -1.73, -0.14, 0.47, -0.5, -0.47, 0.14, 0.27, 0.29, 0.82, -0.65, -2.13, -1.12, 1.35, 2.14, 3.29, -2.72, -4.22, -2.81, -2.78, -2.99, -2.66, 0.43, 1.56, 1.47, 1.5, 1.28, 1.63, 0.09, 0.03, -0.18, 0.16, 0.73, 0.84, 0.06, -0.21, 0.13, 0.14, 0.01, 0.75, -1.47, -0.38, 1.5, 0.43, 0.76, 0.27, 0.34, -0.13, -0.07, -0.31, -0.24, 0.36, -0.07, 0.7, 0.47, -0.58], ['237', 2.1, -0.24, 0.06122171562045875, -0.08, 0.69, 0.5384196236737595, 1.7000361663652803, 1.61, 1.9, 1.55, -1.48, 0.281934498041641, 0.01, 0.65, -0.26, 0.72, 0.41, 0.88, 3.07, 1.18, 2.17, 2.2, 0.96, 0.64, 1.29, 1.63, 3.08, 1.59, 1.51, 2.17, 1.24, 2.24, 1.93, 2.4, 4.63, 2.700714285714286, 3.71, 3.74, 2.48, 2.16, 1.02, 2.42, 1.47, 0.01119746749611708, 0.57, -0.34, 0.64, 0.33, 0.8, 2.99, 1.09, 2.09, 2.12, 0.88, 0.56, 0.68, 2.33, 0.94, 1.17, 1.54, 0.7431047225355607, -0.27, 0.71, 0.41, 0.88, 3.07, 1.17, 2.16, 2.19, 0.96, 0.64, 2.12, 0.89, -0.91, 0.07, -0.24, 0.23, 2.41, 0.52, 1.51, 1.54, 0.31, -0.01, 2.78, 1.61, -1.62, 1.82, 0.98, 0.68, 1.15, 3.35, 1.44, 2.44, 2.47, 1.23, 0.91, 1.01, 0.82, -0.3, 0.16, 2.34, 0.45, 1.44, 1.47, 0.24, -0.08, 0.44, 0.79, 3.12, 0.8915981806829014, 0.75, 0.99, 1.13, 0.47, 2.65, 0.76, 1.75, 1.78, 0.55, 0.23, -0.3134639289282145, 0.66, 2.17, 0.29, 1.28, 1.31, 0.08, -0.24, 0.82, 0.8, 0.14, 1.09, 3.11, 0.54, 0.28, -2.04, 2.062462323390895, 1.04, -1.0, 2.13, -0.75, -1.65, -0.91, 1.14, 0.53, 2.63, -2.63, -2.52, 0.84, -3.06, 1.72, 1.48, -0.77, 3.45, -6.12, -2.33, -3.37, 0.84, -1.48, -1.84, -0.87, -0.85, -2.033374149659864, -2.36, 2.53, 0.37, 0.99, 1.01, -0.21, -0.53, -0.61, 0.03, -1.18, -1.5, 1.92, 2.24, -0.64, -1.21, -1.52, 0.85, 0.93, 1.78, -3.84, 2.310199626957499, 3.78, 1.33, 0.68, 0.58, -0.32, 1.29, 0.97, 0.6, 0.26, 1.2, 0.9, 0.96, 1.7, 0.88], ['238', -1.93, -0.36, -0.028778284379541254, 0.08, -0.46, -0.44, -0.16588474204017084, -1.01, -0.52, -0.76, -0.38, -0.6, 0.52, -0.15, -0.02, -0.15, -0.26, -0.73, 0.18, -0.33, -0.67, -0.53, -0.53, -0.57, -1.26, -0.77, -0.38, -0.22, 0.9108333333333334, 0.23, 0.36, 0.23, 0.12, -0.36, 0.56, 0.05, -0.3, -0.16, -0.15, -0.19, -0.19, -0.5350638007838266, -0.16, 1.12, 0.45, 0.58, 0.45, 0.34, -0.14, 0.79, 0.27, -0.041934531913557026, 0.07, 0.07, 0.03, -0.36, 0.11, -0.55, -0.41, -1.27, -0.5568952774644393, -0.53, -0.66, -0.77, -1.24, -0.33, -0.84, -1.18, -1.04, -1.04, -1.08, -1.1863939988582846, -0.61, 0.13, 0.0, -0.11, -0.59, 0.33, -0.18, -0.52, -0.39, -0.38, -0.42, -0.42, -0.51, 0.52, -0.7033017616146798, -0.13, -0.24, -0.71, 0.2, -0.31, -0.65, -0.51, -0.51, -0.55, -1.11, -0.61, -0.11, -0.59, 0.33, -0.18, -0.52, -0.38, -0.38, -0.42, -0.04, -0.63, -0.23, -0.3, -0.38482093036566006, -0.2, -0.5, -0.48, 0.44, -0.07, -0.41, -0.27, -0.27, -0.25141531611693435, -0.06, -0.03, 1.1736855802927233, 0.41, 0.06, 0.2, 0.21, 0.17, -0.32, -0.44, 0.01, -0.48, -3.09, -0.1, -0.07, 0.1, -0.14, -0.06, 0.67, -0.5238364678879506, 0.83, 0.49, 0.28, -0.95, -0.29, -0.9, 0.95, 0.9, -0.31, 0.17, -0.6, -0.92, 0.47, -1.48, -3.85, 1.04, 1.55, -0.76, -0.94, -0.51, -0.85, -0.71, -0.71, -0.75, -0.96, -0.43, -0.34, -0.2, -0.2, -0.24, -0.09, 0.14, 0.15, 0.1, -0.52, -0.47, -0.23, 0.01, -0.04, -0.29, -0.31, -0.94, -1.84, -0.16, 1.84, -0.97, -0.7, -0.15136255179902908, -0.04, -0.57, 0.17455285983857427, -0.22, -0.37, -0.52, -0.19, -2.59, -1.31, -0.5], ['239', -1.72, 0.49, 0.18, -0.09, -0.72, 0.17, 0.49411525795982914, -0.11, 0.2, -0.45, -0.85, 0.05, -1.03, -0.03, -0.38, 0.34, -1.09, -0.55, -3.41, -0.66, -0.59, -0.44, -1.14, -0.63, 0.2, 0.26, 0.4, 0.91, -0.18, 0.82, 0.47, 1.21, -0.24, 0.4172589041444084, -2.58, 0.19, 0.26, 0.42, -0.29, 0.23, 0.68, 0.9049361992161734, -0.51, -1.09, -0.09, -0.43, 0.29, -1.14, -0.6, -3.46, -0.71, -0.64, -0.49, -1.19, -0.68, 0.25, -0.22, -0.51, 0.5, 0.59, 1.01, 0.66, 1.39, -0.06, 0.49, -2.4, 0.38, 0.45, 0.6, -0.11, 0.41, -0.53, -0.42, -0.35, 0.38, -1.06, -0.52, -3.38, -0.62, -0.55, -0.4, -1.11, -0.59, 0.6, 2.08, -2.09, -0.03330176161467985, 0.73, -0.71, -0.17, -3.04, -0.28, -0.21, -0.06, -0.76, -0.1859922724755494, -1.06, -0.8, -1.43, -0.89, -3.74, -1.0, -0.93, -0.78, -1.48, -0.97, 0.06, -0.86, 0.88, 0.31, 0.55, 0.11, 0.65, 0.55, -2.35, 0.44, 0.51, 0.66, -0.05, 0.5285846838830657, 0.17, 0.1, -2.88, -0.11, -0.04, 0.11, -0.59, -0.07, 1.05, 0.96, -0.11, 0.57, -3.26, 0.2, 0.27, 0.54, -0.57, -0.3, 1.34, -0.1, -0.43, -0.67, -0.33, -0.65, 0.48307978986877903, 0.82, -0.93, -0.94, 0.29, 0.75, 0.59, 0.21, -0.07, 1.93, -3.81, -1.29, -1.92, 0.46, 3.06, 2.85, 2.92, 3.08, 2.35, 2.89, 0.91, 0.21, 0.07, 0.22, -0.49, 0.03, 0.14, 0.15, -0.56, -0.04, 0.16, 0.48, -0.02, -0.71, -0.19, 0.31, 0.43439630127529083, -0.11, -1.81, 0.69, 1.62, 0.81, 1.1410935020800126, 0.7, 0.52, 0.7100774025227806, -0.4, 0.25, 0.51, 0.39, 0.17, 0.48, 0.99, 0.66], ['240', 3.13, 0.12, 0.2912217156204588, 0.19, -0.29, -0.09, 0.18, 0.44, 0.32, 0.55, 0.06060884353741497, 0.14, -0.05, -0.08, -0.78, -0.13, -0.02, 0.55, -5.2, 2.03, 0.54, 0.59, -0.08, 0.71, 0.04, 0.11, 0.5, 0.09, -0.1, 0.013189937047079991, -0.83, -0.18, -0.07, 0.5, -5.24, 1.98, 0.49, 0.54, -0.13, 0.66, 0.08746842535321082, 0.0, 0.42, -0.19, -0.22, -0.92, -0.27, -0.15, 0.42, -5.32, 1.89, 0.409654729237061, 0.45, -0.21, 0.57, 0.97, 0.3, 0.73, 0.12, 0.61, -0.03, -0.73, -0.08, 0.04, 0.61, -5.14, 2.09, 0.59, 0.64, -0.02, 0.76, 0.55, 0.64, -0.7, -0.05, 0.07, 0.64, -5.11, 2.12, 0.62, 0.67, 0.01, 0.79, 0.56, 2.01, -2.03, 1.3766982383853201, 0.65, 0.77, 1.34, -4.45, 2.83, 1.33, 1.38, 0.71, 1.5, 1.38, 0.69, 0.12, 0.69, -5.07, 2.17, 0.68, 0.72, 0.06, 0.84, 0.08, 0.68, 0.3, 0.14, 0.12, 0.18567351865003195, 0.57, 0.57, -5.18, 2.05, 0.56, 0.6, -0.06, 0.72, 0.05, 0.0, -5.72, 1.47, -0.01, 0.15579954965669268, -0.63, 0.15, 0.56, 0.84, 0.24, 0.07, 4.26, 0.21, 0.18, -0.38, 0.38, 0.18, 0.51, -0.45, 3.03, -0.29, -0.15, 1.59, 0.0, 0.6305968614718616, -0.53, -0.39, 0.14, -0.67, 0.29, -0.08, 0.03, 1.65, -4.49, -1.19, -1.65, -3.0, 6.06, 7.62, 6.05, 6.1, 5.4, 6.22, 0.44, -1.45, -1.46, -1.42, -2.06, -1.3, 0.01, 0.05, -0.61, 0.17, 0.23, 0.22, -0.03, -0.66, 0.19224875531501634, 0.14, 0.18439630127529083, 0.56, -2.33, 1.13, 2.29, -0.002736189475566718, 0.48, 0.63, 0.78, 0.05, 0.29, 0.35, -0.06, -0.53, -0.15, 1.69, 0.29, 0.05], ['241', -3.36, 0.38, 0.18122171562045875, 0.08, 0.07, 0.02, -0.49588474204017086, -0.84, -0.36, -1.03, -0.59, -0.28, -0.59, -1.19, 1.2242857142857142, -0.7, -1.5071428571428571, -0.85, 0.77, -3.49, -0.9526645179126411, -1.17, -0.58, -0.65, -0.3, 0.98, -0.45, 0.31, 0.0, -0.61, 1.82, -0.11, -0.93, -0.26, 1.37, -2.92, -0.4, -0.59, 0.02, -0.06, -1.74, 0.23, -0.75, -0.31, -0.92, 1.5, -0.42, -1.23, -0.57, 1.05, -3.22, -0.681934531913557, -0.89, -0.29, -0.37, -0.15, -0.59, -1.4580521152823784, -0.36, -0.45, -0.61, 1.82, -0.11, -0.93, -0.26, 1.36, -2.92, -0.4, -0.59, 0.01, -0.07, -0.97, 0.16, 2.44, 0.5, -0.32, 0.35, 1.99, -2.33, 0.21, 0.02, 0.63, 0.55, -0.03, -1.13, 1.1305714285714286, -2.22, -1.9, -2.7, -2.04, -0.44, -4.66, -2.18, -2.36, -1.77, -1.85, -0.02, -0.33, -0.82, -0.15, 1.48, -2.81, -0.29, -0.23718300350443208, 0.13, 0.05, -0.28, -0.4, 2.51, -0.06, -0.05, 0.03, 0.48, 0.67, 2.31, -2.01, 0.53, 0.34, 0.95, 0.87, 0.23, -0.18, 1.63, -2.67, -0.14, -0.32, 0.28, 0.44217743764172346, 1.04, 1.46, -0.33, 0.37, 0.03, -0.07, -0.14, 0.42, -0.41, -0.22, 0.62, -0.03, -5.1, 0.1, 0.05, -1.74, 0.04, -0.06, 0.06, 0.21, -0.06, 0.54, -0.15, -0.07, 0.06, 1.43, 0.13, -0.92, -1.38, 5.14, -1.4696213151927437, -4.23, -1.5427867132867132, -1.93, -1.33, -1.41, -0.08, 2.55, 2.6, 2.41, 3.03, 2.94, -0.05, -0.10112140889357832, 0.42, 0.34, -0.24, -0.23, 0.14, 0.6, 0.52, -0.09, -0.03, -0.78, 0.09, 1.4, 0.0, -0.66, 0.73, -0.46, -0.08, 0.06, -0.04, 0.27, -0.11, -0.41, -0.38, -0.25, 1.79, -0.24], ['242', -3.4, 0.11, 0.09122171562045875, 0.07, -0.6570209190089404, -0.26, -0.82, -0.49, -0.26, 1.05, 1.07, 1.92, 0.52, 2.15, 2.57, 1.71, 1.86, 1.01, 5.22, 1.77, 0.78, 1.84, 1.57, 1.34, -0.8, -0.73, -0.02, 0.8401785714285714, -0.54, 1.07, 1.48, 0.64, 0.78, -0.06, 4.1, 0.7, -0.29, 0.76, 0.5, 0.27, -0.67, -0.66, -0.86, -1.37, 0.22, 0.63, -0.21, -0.06, -0.9, 3.23, -0.15, -1.0919345319135572, -0.08, -0.34, -0.57, -0.14, 0.56, -1.31, 0.06, 0.52, 1.62, 2.03, 1.19, 1.33, 0.48, 4.67, 1.25, 0.26, 1.32, 1.05, 0.82, -0.3, -1.08, 0.41, -0.43, -0.29, -1.12, 3.0, -0.37, -1.34, -0.3, -0.57, -0.79, -0.23, -1.61, 1.57, -1.48, -0.83, -0.69, -1.52, 2.59, -0.7683253968253968, -1.74, -0.7, -0.97, -1.19, -1.49, -0.66, 0.14, -0.69, 3.45, 0.06, -0.92, 0.13, -0.14, -0.36, -0.15, -0.65, -1.98, -0.46, -0.49, -0.44, -0.8, -0.84, 3.3, -0.08, -1.06, -0.01, -0.28, -0.51, -0.83, 0.04, 4.17, 0.76, -0.22, 0.83, 0.56, 0.33, -0.46, -0.44, 0.07, -0.69, -4.57, -0.08, -0.24, 1.14, -1.13, -0.56, -0.08, -0.22383646788795053, 1.29, 1.01, 0.44, -1.7, 0.13, -1.38, 1.34, 1.41, -0.47, 1.5, -0.93, -0.29, 0.14, -2.42, 0.2721071428571429, 1.57, 2.22, -1.18, -3.97, -3.27, -4.22, -3.21, -3.46, -3.68, -1.4, -0.72, -0.97, 0.07, -0.2, -0.42, 0.26, 1.05, 0.78, 0.56, -0.29, 0.07, -0.78, -0.27, -0.49, -0.47, -0.5, -0.37, 0.84, -1.45, -0.83, -1.0, -1.03, -0.52, -0.23, -0.94, -0.64, 0.26, 0.38, -0.38, -0.29, -1.97, -2.36, -0.05], ['243', 1.92, -0.07, 0.08015289830927054, 0.15, -0.53, -0.07, -0.44588474204017087, -0.74, 0.33, -1.34, -2.31, -1.02, -1.06, -0.5, -0.11, -1.48, -1.55, -1.44, 0.97, -0.7, -1.28, -1.57, -1.57, -1.39, -0.44, 0.14, 0.99, 1.32, 1.28, 1.86, 2.25, 0.85, 0.78, 0.89, 3.35, 1.65, 1.06, 0.76, 0.76, 0.95, -0.03253157464678917, 0.95, -0.32, -0.03, 0.53, 0.92, -0.46, -0.53, -0.42, 2.01, 0.32, -0.26, -0.56, -0.55, -0.37, -0.61, -0.76, -0.47, 0.53, -0.29, 0.56, 0.95, -0.43, -0.5, -0.39, 2.04, 0.36, -0.22, -0.52, -0.52, -0.33, -0.96, -0.85, 0.39, -0.99, -1.06, -0.95, 1.47, -0.2, -0.78, -1.08, -1.08, -0.89, 1.04, 0.72, -0.7, -1.23, -1.37, -1.44, -1.33, 1.08, -0.59, -1.17, -1.46, -1.46, -1.27, -0.42, 0.14, -0.07, 0.04, 2.48, 0.79, 0.21, -0.09, -0.09, 0.1, 0.06, 0.09, -0.97427628811696, 0.17, 0.17517906963433993, 0.2, 0.21, 0.11, 2.55, 0.86, 0.28, -0.02, -0.02, 0.2285846838830657, 0.2, 0.1, 2.44, 0.75, 0.17, -0.13, -0.13, 0.06, 0.83, 0.29, 0.29, 0.14, -1.11, 0.13, 0.2, -0.54, 0.56, 0.25, 0.34, -0.6638364678879505, 1.22, -0.37, -0.19, 0.94, 0.17, 0.57, -0.54, -0.49, 0.22329080486385297, -0.87, 0.33, -1.44, 0.69, 0.72, -1.59, -0.41, -0.65, -1.26, -2.29, -1.65, -2.22, -2.51, -2.51, -2.33, 0.5, -0.64, -0.4358074110763185, -0.88, -0.87, -0.69, -0.07, -0.3, -0.3, -0.11, 0.33, 0.8084535464535467, 0.23, 0.0, 0.26224875531501635, 0.17, 0.11, -0.76, -1.32, -0.38, 1.27, -0.39, 0.22, 0.23, 0.19, -0.08, 0.29, 0.29, 0.33, 0.18, 0.04, -1.31, 0.68, 0.07], ['244', -0.53, 0.15, 0.13122171562045873, 0.03, 0.0, 0.31, 0.51, -0.58, 0.1, -0.6, -0.71, -0.96, -0.58, 0.41, -0.16, -0.69, -0.52, -0.68, -0.7, -0.22, -0.42, -0.47, -1.3, -0.86, 0.36, 0.4, 0.12, -0.25, 0.14011904761904762, 1.14, 0.56, 0.02, 0.2, 0.04, 0.02, 0.5, 0.3, 0.24, -0.59, -0.15, 0.2, -0.24, 0.37, 0.38, 1.39, 0.8, 0.27, 0.45, 0.28, 0.27, 0.75, 0.54, 0.49, -0.34, 0.1, 0.03, -0.44, -0.07, 0.22, -0.01, 1.0, 0.42, -0.11, 0.07, -0.1, -0.11, 0.37, 0.16, 0.11, -0.72, -0.28, -0.5263939988582844, -1.01, -0.57, -1.1, -0.92, -1.09, -1.1, -0.63, -0.83, -0.88, -1.5769045181009465, -1.2164403582748793, 0.0, 1.73, -1.77, -0.43, -0.53, -0.35, -0.52, -0.53, -0.06, -0.26, -0.31, -1.14, -0.7, -0.4, 0.1, 0.18, 0.02, 0.0, 0.48, 0.28, 0.22, -0.61, -0.17, 0.02, 0.11, 0.04, 0.26, 0.41, 0.13567351865003197, -0.08, -0.16, -0.18, 0.3, 0.1, 0.04, -0.79, -0.35, 0.03, 0.08, -0.02, 0.46, 0.26, 0.21, -0.62, -0.18, 0.74, 0.63, 0.08, -0.04, -1.12, 0.01, -0.07, 0.0, 0.05, 0.0, 0.52, -0.85, 0.79, -0.45, -0.26, -0.3, 0.19, 0.76, -0.78, -0.74, 0.26, -0.09, 0.5, -0.27, 0.12, -0.21, -5.32, 0.2, 0.23, -0.73, 0.1, 0.48, 0.28, 0.22, -0.61, -0.17, 0.79, -0.38, -0.2, -0.26, -1.08, -0.64, -0.18, -0.05, -0.88, -0.44, 0.16, 0.11, -0.12, -0.83, -0.39, 0.26, 0.21, -0.45, -3.66, 0.52, 3.66, 0.3718948994148555, 0.08, 0.7104317111459968, 0.44, 0.29, -0.07, 0.16, 0.21, 0.38, 0.27, -0.29, 0.07, -0.03], ['245', -2.01, 0.34, -0.028778284379541254, -0.28, -0.1, 0.06, 0.044115257959829166, 0.09, 0.31, 0.28, -0.6, 0.23, 0.35, 0.02, 0.46, 0.6, 0.23, 0.28, -3.83, -0.6, 0.21, 0.31, -0.19, -0.4, -0.86, -0.28, 0.89, 0.84, 0.96, 0.63, 1.07, 1.21, 0.84, 0.89, -3.25, 0.0, 0.82, 0.92, 0.41, 0.21, 0.36, 0.75, 0.05, 0.20119746749611708, -0.21, 0.22, 0.37, 0.0, 0.05, -4.05, -0.83, -0.02, 0.08, -0.42, -0.63, 0.35, 0.54, -0.19, 0.34, -0.07, -0.33, 0.11, 0.25, -0.11, -0.07, -4.16, -0.95, -0.13, -0.03, -0.54, -0.74, 0.76, 0.26, 0.44, 0.58, 0.21, 0.26, -3.85, -0.62, 0.19, 0.29, -0.21, -0.35644035827487924, 0.89, 1.3, -1.39, -0.17, 0.14, -0.22, -0.17, -4.27, -1.06, -0.24, -0.14, -0.65, -0.85, -1.49, -0.2426334687834371, -0.36, -0.32, -4.4, -1.2, -0.38, -0.28, -0.79, -0.99, -0.02, -0.26, 0.23572371188304003, 0.18, 0.38, -0.024326481349968038, 0.12180947648612922, 0.05, -4.05, -0.84, -0.02, 0.08, -0.43, -0.5714153161169343, 0.08, 0.0, -4.1, -0.88, -0.07, 0.03, -0.47, -0.68, 0.54, 0.59, -0.26, 0.01, -4.48, 0.26, 0.21, 0.72, -0.71, -0.35, 0.65, -0.19, -1.76, -0.43, -0.18, -0.98, 0.3, 0.37, -0.4, -0.58, 0.18, 1.07, 0.39, 0.73, -0.39, 0.14, -2.67, -0.07, -0.07, 1.78, 4.28, 3.3548095238095237, 4.206609977324264, 4.31, 3.78, 3.57, 0.56, 0.89, 0.82, 0.92, 0.41, 0.21, 0.07, 0.1, -0.41, -0.61, 0.32, 0.26, -0.03, -0.51, -0.71, 0.18, 0.11, 0.13, -1.37, 0.73, 1.21, 0.047263810524433285, 0.37, 0.48, -0.2, 0.32, 0.0, -0.03, 0.0, -0.24, 0.68, -1.31, 0.58, 0.77], ['246', -8.0, -1.26, -0.28, -0.18, -0.51, -1.11, -0.5258847420401709, -2.018279403464041, -2.3, -2.19, 0.4, -1.92, 0.4, 1.59, -0.2, 0.61, -1.33, -1.68, -1.55, -2.94, -2.69, -0.88, -1.14, -1.55, -3.32, -2.36, -2.5473416050068876, -2.3, 0.0, 1.18, -0.59, 0.21, -1.72, -2.07, -1.9392857142857143, -3.32, -3.07, -1.27, -1.53, -1.8961582768021608, -1.8025315746467891, -4.55, -0.28, 2.36, 3.57, 1.75, 2.57, 0.6, 0.24, 0.38, -1.04, -0.79, 1.06, 0.79, 0.37, -1.3199371536943236, -2.44, -1.37, -1.94, -2.510754752934122, 1.18, -0.6, 0.2, -1.73, -2.07, -1.8313219954648525, -3.33, -3.08, -1.28, -1.54, -1.95, -1.99, -3.72, -1.76, -0.97, -2.87, -3.21, -3.08, -4.46, -4.21, -2.43, -2.69, -3.09, -3.64, -3.87, 3.21, -2.0, 0.8, -1.14, -1.48, -1.35, -2.75, -2.5, -0.68, -0.95, -1.36, -4.1, -2.78, -1.93, -2.27, -2.14, -3.52, -3.27, -1.48, -1.74, -2.15, -1.08, -2.81, -1.36427628811696, -1.06, -1.09, -1.09, -0.87, -0.35, -0.22, -1.63, -1.37, 0.46, 0.19, -0.23, -1.43, -0.53, 0.13, -1.29, -1.03, 0.81, 0.54, 0.12, -0.61, -0.5, -0.13, -1.31, -8.21, -2.0219304505018787, -1.86, 1.28, -1.24, -0.62, -0.47, -1.32, -1.33, 2.13, 1.05, -4.1, -0.98, -3.34, 3.37, 3.32, -1.06, 2.04, -2.19, -0.63, 0.26, -2.65, 11.22, 1.73, 2.69, 1.63, -0.66, -1.42, -1.16, 0.68, 0.41, -0.01, -3.14, 0.77, 0.26, 2.12, 1.85, 1.43, 0.51, 1.86, 1.59, 1.16, -2.46, -2.88, -1.33, -0.27, -0.68, -1.11, -1.0, -1.94, 5.58, -0.9098003730425006, -5.46, -2.05, -1.66, -1.06, -0.42, -1.743994794887652, -0.68, -1.03, -0.46, -1.03, -0.65, -2.84, -1.97, -0.44], ['247', -2.09, 0.12, 0.09122171562045875, 0.08, 0.15, -0.63, -1.0058847420401709, -0.77, -1.12, -1.73, 1.05, -1.42, -1.61, -1.77, -0.32273809523809527, -1.36, -1.012857142857143, -1.66, -1.39, -1.7233571428571428, -2.01, -0.62, -0.29, -1.33, -0.42, -1.2, -2.76, -2.44, -2.2123253968253964, -2.79, -1.37, -2.38, -2.08, -2.68, -2.42, -2.76, -3.02, -1.66, -1.33, -2.36, -1.79, -3.1750638007838266, -0.32, -0.19, -0.35, 1.1, 0.06, 0.38, -0.24, 0.03, -0.32, -0.6, 0.81, 1.14, 0.09, -1.02, -0.65, -0.08, -0.35, -0.13, -0.16, 1.3, 0.26, 0.57, -0.05, 0.22, -0.13, -0.4, 1.0, 1.34, 0.28, 1.25, 0.03, 1.46, 0.42, 0.73, 0.11, 0.38, 0.03, -0.24, 1.16, 1.5, 0.44, -2.62, -3.39, 3.63, -1.4, -1.02, -0.72, -1.33, -1.06, -1.41, -1.68, -0.27428571428571424, 0.04, -1.0, -0.7473809523809524, -0.38, 0.31, -0.31, -0.04, -0.38, -0.66, 0.74, 1.08, 0.03, -0.19, -0.41, -0.17989534883720928, -0.62, -0.7, -0.36, -0.69, -0.62, -0.35, -0.69, -0.97, 0.43, 0.76, -0.29, -1.02, -0.08, 0.27, -0.08, -0.35, 1.05, 1.39, 0.33, -1.11, -1.05, 0.13, 0.11, -1.59, 0.3580695494981211, 0.22, 0.46, -0.47, -0.26, -0.37, 0.36, -0.32, 1.25, 0.61, -0.98, -0.56, -1.6, 1.54, 1.93, -0.63, 0.69, -1.28, 0.3, -0.18, -2.12, 2.45, 1.43, 2.04, 0.19, -0.34, -0.34, -0.62, 0.78, 1.12, 0.06, -1.85, 0.0, -0.28, 1.13, 1.47, 0.41, 0.28, 1.4128849285635, 1.75, 0.69, -1.18, -1.54, -1.12, 0.33, -0.71, -0.69, -0.52, -0.78, 1.3, 0.0, -1.16, -0.03, -0.27, -1.45, -1.04, -0.77, -0.46, -0.42, -0.68, -0.64, -0.41, 1.13, 0.5, -0.64], ['248', -0.53, 0.12, -0.43877828437954125, 0.06, 0.07, -0.41, 1.5, 0.69, 0.45, 2.23, 2.33, 0.32, 2.17, 2.46, 0.9, 1.75, 2.68, 2.47, 6.64, 1.71, 2.05, 2.8010442176870747, 2.37, 2.19, 0.13, 0.28, -0.09, -1.96, -0.16, 0.13, -1.39, -0.57, 0.35, 0.14, 4.22, -0.6, -0.27, 0.43, 0.05, -0.13, 1.95, -0.15, 1.91, 1.84, 2.13, 0.58, 1.42, 2.35, 2.14, 6.3, 1.38, 1.72, 2.43, 2.05, 1.86, -0.28, 0.39, 1.28, 0.12, 0.07, 0.29, -1.24, -0.41, 0.51, 0.3, 4.38, -0.45, -0.11, 0.59, 0.2, 0.02, 1.1, -0.22, -1.52, -0.7, 0.22, 0.01, 4.08, -0.73, -0.4, 0.3, 0.05309548189905343, -0.27, -0.2, -0.24, 0.19, 1.32, 0.84, 1.77, 1.55, 5.69, 0.8, 1.14, 1.85, 1.46, 1.27, 0.36, 0.48, 0.92, 0.71, 4.8459047619047615, -0.04, 0.3, 1.0, 0.62, 0.43, 0.18114187399901702, 0.54, 0.56, -0.1, -0.06, -0.03, -0.44, -0.21, 3.86, -0.95, -0.4442217465074606, 0.08, -0.3, -0.48, -0.48, -0.23, 4.08, -0.74, -0.41, 0.29, -0.09, -0.27, 0.37, 0.45, 0.06, 0.05, 0.92, 0.18, -0.28, -0.17, 0.18, 0.11, 0.21406627346681525, 1.05, -0.9, 0.12, 0.1, -0.25, -0.39, -0.14, 0.14, 0.26, -0.08, -0.22, -0.2, -0.5, 0.25, -1.23, 8.05, 0.87, 1.21, 1.3056150793650794, -4.14, -4.63, -4.31, -3.64, -4.0, -4.18, -0.25, 0.6543542330685188, 0.33, 1.04, 0.65, 0.47, 0.18, 0.7, 0.32, 0.14, 0.41, 0.09, -0.52, -0.38, -0.56, -0.07, -0.09, 0.64, 4.812857142857143, -0.3, -4.13, 0.3, 0.05, -0.14, -0.18, -0.88, 0.18, 0.03, -0.29, -0.03, 0.04, -0.21, 1.5030376647162362, -0.43], ['249', -0.59, 0.63, 0.04, -0.06, 0.41, 0.27, 1.17, 0.65, 0.51, -0.62, -1.48, -1.17, -1.63, -0.09, -2.94, -0.25, -1.19, -0.79, -0.52, -1.2033571428571428, -0.35, -0.77, -1.16, -1.47, 0.45, 0.63, 0.9126583949931124, 0.32, -0.14535714285714285, 1.42, -1.4221800287049087, 1.26, 0.29, 0.8272589041444084, 0.97, 0.28, 1.15, 0.72, 0.33, 0.053841723197839156, 0.88, 1.64, 0.56, -0.46, 1.1, -1.79, 0.94, -0.02, 0.39, 0.7571355564861204, -0.04, 0.83, 0.41, 0.01, -0.3, 1.05, -0.44, 0.3, -0.11, 1.03, 1.56, -1.33, 1.4, 0.44, 0.85, 1.1371802721088435, 0.42, 1.3, 1.1974648526077096, 0.48273474541331685, 0.18418480725623584, 0.14, -0.53, -2.849285714285714, -0.16, -1.11, -0.7, -0.4269047619047619, -1.12, -0.26, -0.68, -1.07, -1.38, 1.05, 1.721742947528662, -1.58, 2.4266982383853204, 2.78, 1.8, 2.22, 2.49, 1.78, 2.67, 2.23, 1.83, 1.51, -0.13, -0.37, -0.95, -0.54, -0.28, -0.97, -0.11, -0.53, -0.92, -1.23, 0.25, -0.45, 2.3157237118830403, 0.49, 0.53, 0.585673518650032, 0.6618094764861292, 0.41, 0.68, -0.02, 0.85, 0.43, 0.04, -0.22141531611693435, 0.25, 0.17, 0.27, -0.43, 0.44, 0.02, -0.38, -0.69, 0.5, 0.43, -0.16, 0.55, -0.37, 0.1, 0.1, -0.9, 0.7, 0.45, -0.26, 0.95, -1.33, -0.98, -0.52, -0.21, 0.5, 1.46, -1.49, -1.47, 0.47, -1.4, 0.9, 1.36, -0.7, 1.74, -6.02, -1.1, -1.59, 1.22, -0.09, -0.69, 0.17, -0.25, -0.64, -0.95, 1.4708051948051948, 0.6, 0.87, 0.45, 0.05, -0.26, 0.176501700680272, -0.42, -0.81, -1.12, 0.55, 0.64, 0.16, -0.39, -0.7, 0.49, 0.53, 0.6, -4.07, 2.05, 4.14, 0.51, 0.37, 0.55, -0.32, -0.14, 0.36, 0.83, 0.57, 0.67, 0.87, 0.39, 0.4, 1.23], ['250', 2.04, -0.18, 0.12, 0.05, 0.18, -0.42, -2.1758847420401706, -0.99, -0.7, -0.15, 0.5, 1.35, 0.28, 0.89, 2.03, -1.09, 0.05, -0.12, 1.18, -0.09, -0.29, 0.19, 0.26, 0.19, -0.8, -0.17, -0.65, 0.85, -0.22, 0.38, 1.52, -1.58, -0.45, -0.5027410958555916, 0.68, -0.59, -0.705546329921431, -0.31, -0.24, -0.31, -0.56, 0.07, -1.48, -0.9788025325038829, -0.46, 0.67, -2.41, -1.28, -1.46, -0.17, -1.43, -1.62, -1.14, -1.08, -1.15, -0.68, -0.59, -1.28, -0.66, -0.43, 0.61, 1.74, -1.36, -0.23, -0.4, 0.9, -0.37, -0.57, -0.09, -0.02, -0.09, -0.75, -1.03, 1.13, -1.96, -0.83, -1.0, 0.29, -0.97, -1.16, -0.69, -0.62, -0.69, -0.36, -1.09, 1.11, -2.13, -3.05, -1.94, -2.11, -0.83, -2.08, -2.1047647669790526, -1.8, -1.73, -1.8, 0.18, 0.95, 1.15, 0.98, 2.29, 1.01, 0.81, 1.29, 1.36, 1.29, -0.07, 0.87, -0.11, -0.4, -0.41, -0.3, -0.2, -0.17, 1.13, -0.14, -0.34, 0.14, 0.21, 0.14, -0.12346392892821456, -0.03, 1.31, 0.03, -0.16, 0.32, 0.39, 0.31, -0.6, -0.51, 0.07, -0.3, 0.4, 0.07, 0.24, 0.53, -0.49, -0.29, 0.14, -0.98, 0.0, 0.8, 0.39, 1.04, -0.45, -1.15, 1.09, 1.17, -0.39, 0.82, -0.77, -0.95, 0.48, -0.57, -1.7, 0.42, 0.49, -0.07, -1.32, -1.26, -1.45, -0.98, -0.91, -0.98, -1.12, -0.06, -0.2, 0.29, 0.35, 0.28, 0.14, 0.48, 0.55, 0.48, -0.6772046485260771, -0.41, -0.34, 0.07, 0.0, -0.36, -0.36, -0.93, -0.87, -0.11, 0.85, 0.08, -0.59, -0.41, -0.07, -0.7999225974772194, -0.53, -0.2, -0.34, 0.07, -0.34, -1.41, 0.07, -0.28], ['251', -7.91, -0.4, -0.3487782843795412, 0.18, -2.26, -1.24, -0.32588474204017087, -1.05, -1.7, 0.8470884353741497, 2.84, 0.86, 1.59, 2.27, 0.97, 2.54, 0.71, 0.1, 3.72, 3.7, -0.57, 2.63, 2.04, 0.74, -2.16, -1.95, -2.37, -1.93, -1.22, -0.56, -1.82, -0.29, -2.07, -2.67, 0.85, 0.84, -3.319239316239316, -0.2, -0.78, -2.04, -0.28, -2.85, -0.250696767518196, 0.73, 1.4, 0.11, 1.67, -0.14, -0.75, 2.84, 2.82, -1.41, 1.76, 1.17, -0.11, -0.97, -0.75, -1.41, -1.62, -1.17, 0.66, -0.61, 0.94, -0.87, -1.47, 2.09, 2.08, -2.13, 1.02, 0.44, -0.84, -1.57, -1.82, -1.27, 0.27, -1.52, -2.12, 1.42, 1.4, -2.78, 0.36, -0.22, -1.49, -2.64, -4.67, 4.63, -0.56, 1.56, -0.25, -0.86, 2.72, 2.71, -1.53, 1.65, 1.06, -0.22, -3.37, -2.09, -1.79, -2.377880952380952, 1.14, 1.13, -3.04, 0.09, -0.49, -1.76, 0.13, -2.11, 0.73572371188304, -1.53, -1.32, -0.76, -0.31, -0.61, 2.98, 2.97, -1.28, 1.91, 1.32, 0.03, -1.99, 0.3, 3.61, 3.6, -0.67, 2.53, 1.94, 0.64, -1.59, -1.72, 0.19, -0.55, -6.78, -0.18, -0.01, 0.24, -0.23, -0.1, -3.25, -2.36, 6.18, 2.16, 1.1, -4.03, -1.4, -2.94, 3.07, 3.14, -1.07, 0.36, -2.14, -1.37, 0.68, -0.93, 6.33, 0.6, 0.9, -6.38, -3.19, -0.01, -4.13, -1.04, -1.62, -2.87, -3.31, -3.18, -4.1164625850340135, -1.03, -1.61, -2.85, 0.98, 3.22, 2.62, 1.32, -1.79, -2.03, -2.17, -0.58, -1.84, -1.03, -0.97, -1.28, 3.23, 0.5, -3.19, -1.4, -2.15, -1.6, -1.27, -1.03, -0.2, -1.51, -0.9897755102040815, -0.64, -0.34, -1.28, -1.68, 0.35], ['252', 5.65, 0.68, 0.26122171562045876, -0.15, 2.2929790809910595, 2.69, 1.7841152579598292, 2.9117205965359587, 2.09, 2.0, -2.82, 0.65, 0.04, -1.12, -1.77, 0.54, -1.52, 0.94, 2.6, -1.66, 2.947335482087359, -0.79, -1.45, -0.6, 0.23, 1.079371414588892, 4.96, 3.56, 2.94, 1.75, 1.08, 3.46, 1.33, 3.87, 5.57, 1.18, 5.89, 2.08, 1.41, 2.28, 1.96, 3.3549361992161733, 1.35, -0.6, -1.5921246055531768, -2.4, -0.1, -2.16, 0.29, 1.94, -2.3, 2.25, -1.43, -2.08, -1.24, -0.83, 0.46, -1.14, 1.47, 1.96, -1.16, -1.81, 0.5, -1.56, 0.9, 2.56, -1.7097619047619048, 2.87, -0.84, -1.49, -0.64, 4.3, 3.16, -0.65, 1.68, -0.41, 2.09, 3.76, -0.55, 4.08, 0.33, -0.33, 0.53, 3.26, 9.54, -9.47, 3.84, 2.35, 0.25, 2.76, 4.45, 0.1, 4.76, 0.99, 0.32, 1.19, 3.18, 1.527366531216563, -2.05, 0.4, 2.05, -2.2, 2.36, -1.33, -1.98, -1.13, 1.08, 1.48, 5.43, 2.76, 2.79, 2.78, 3.58, 2.5, 4.19, -0.15, 4.5, 0.74, 0.07, 0.94, 2.88, 1.05, 1.64, -2.58, 1.95, -1.5942004503433074, -2.37, -1.53, 3.6418280382942037, 3.59, 0.0, 3.26, 9.477952380952381, 0.32225133596562167, 0.09, -5.66, 5.67, 2.8688101710076213, 1.8, 4.3, -7.34, -5.59, -2.77, 2.88, 1.82, 8.460596861471862, -8.34, -8.28, 2.79, -8.56, 5.54, 5.0, -2.49, 10.64, -10.42, -7.14, -10.58, 7.36, -0.58, -4.16, 0.3, -3.31, -3.95, -3.12, 8.37, 3.73, 4.65, 0.89, 0.22, 1.09, -0.88, -3.6, -4.24, -3.41, 3.33, 3.55, 2.82, -0.66, 0.27224875531501636, 2.8, 2.874396301275291, 3.74, -5.39, 4.9, 5.41, 3.66, 3.85, 3.5, 0.86, 3.22, 2.82, 1.82, 1.91, 1.96, 2.61, 4.87, 4.73, 2.56], ['253', -0.16, 0.15, 0.05122171562045875, -0.24, 0.28, 0.91, 0.82, 1.65, 0.8, 2.54, 1.83, 1.92, 1.76, 1.08, -0.33, 2.92, 1.91, 2.78, 3.06, 1.33, 2.387335482087359, 2.0, 1.52, 1.59, -0.2, 0.6, 0.7, 0.09, -0.07, -0.74, -2.12, 1.07, 0.08, 0.93, 1.21, -0.49, 0.51, 0.17, -0.31, -0.23, 1.73, 1.68, 0.61, -0.15, -0.82, -2.21, 0.97, -0.01, 0.84, 1.12, -0.58, 0.448065468086443, 0.08, -0.4, -0.32, 1.4, -0.08, 1.43, 1.03, 0.76, -0.67, -2.06, 1.13, 0.15, 1.0, 1.28, -0.43, 0.58, 0.24, -0.24, -0.17, 0.8, 1.44, -1.4, 1.81, 0.83, 1.68, 1.96, 0.24, 1.26, 0.91, 0.43, 0.51, 0.94, 3.3, -3.29, 2.88, 3.26, 2.26, 3.13, 3.41, 1.67, 2.7, 2.35, 1.86, 1.93, -1.51, -0.2826334687834371, -0.97, -0.13, 0.14, -1.54, -0.55, -0.88, -1.36, -1.29, -0.13, -0.34, 2.46, 0.92, 0.82, 1.17, 0.61, 0.85, 1.13, -0.58, 0.43, 0.09, -0.39, -0.26141531611693436, 0.36, -0.24, 0.5236855802927234, -1.41, -0.42, -0.76, -1.23, -1.16, 0.97, 1.279561224489796, -0.41, 2.34, -4.36, -0.4, 0.07, -2.71, 2.63, 1.37, -0.2, 0.61, -2.2, -1.82, -0.89, -0.13, 0.07, 2.76, -2.77, -2.79, 0.93, -4.22, 1.82, 1.09, -0.8, 1.84, -8.55, -1.25, -1.9, 2.3, -0.51, -1.68, -0.69, -1.03, -1.5, -1.43, 2.76, 1.2, 1.01, 0.67, 0.19, 0.26, 0.18, -0.34, -0.82, -0.74, 0.78, 0.89, 0.52, -0.48, -0.4, 0.91, 1.0, 1.45, -5.81, 2.72, 5.46, 1.75, 0.29, 1.01, 0.07, 1.59, 1.56, 0.01, -0.79, 0.64, 0.93, 3.26, 0.28, 1.41], ['254', -1.08, 0.0, 0.13122171562045873, -0.11, -0.04, 0.9484196236737595, 2.82, 0.25, 0.8, -0.95, -1.66, -2.95, -0.9, -0.04, -1.01, 0.3, -2.31, -0.95, -0.5341378641200069, -1.37, -0.9, -2.01, -1.5, -1.97, -0.24, 0.54, 0.72, -1.31, 0.7714285714285715, 1.64, 0.66, 1.99, -0.66, 0.72, 0.96, 0.29, 0.77, -0.35, 0.16, -0.32, 0.81, 0.8649361992161734, 2.06, 2.11, 3.167875394446823, 2.0, 3.35, 0.66, 2.06, 2.31, 1.62, 2.11, 0.97, 1.5, 1.01, -0.19, 1.05, 0.15, 0.37, -0.05, 0.87, -0.1, 1.21, -1.42, -0.05, 0.3086780045351474, -0.48, 0.0, -1.11, -0.5972652545866831, -1.08, 0.64, -0.91, -0.96, 0.34, -2.27, -0.91, -0.67, -1.33, -0.86, -1.97, -1.46, -1.93, 0.79, 2.12, -2.18, 0.06, 1.31, -1.32, 0.06, 0.3, -0.37, 0.1, -1.01, -0.5, -0.97, -2.73, -1.24, -2.6, -1.24, -1.0, -1.67, -1.2, -2.3, -1.79, -2.26, 0.02, -1.25, 0.39, 0.8115981806829015, 0.74, 0.8656735186500321, 1.39, 1.39, 1.64, 0.96, 1.6157782534925393, 0.31, 0.83, 0.35, 0.97, 0.0, 0.24, -0.43, 0.05, -1.07, -0.55, -1.03, 0.98, 1.14, -0.12, 0.93, -8.11, 0.2, 0.03, -1.71, 1.74, 0.89, 1.25, 0.78, -0.77, -1.52, -0.76, -0.52, 0.51, 2.23, -2.42, -2.28, 0.77, -2.57, 1.56, -0.56, 0.26, 4.13, -0.68, -2.66, -4.09, 0.86, -0.24, -0.67, -0.2, -1.31, -0.79, -1.27, 2.3, 0.43, 0.48, -0.64, -0.12, -0.6, -0.05, -1.11, -0.6, -1.08, 0.77, 0.5, 1.08, 0.52, 0.04, 0.76, 0.81, 0.06257604962387836, -0.59, 0.7, 0.72, 0.42, 0.69, 0.56, -0.48, 1.18, 0.85, 0.34, 0.66, 0.66, 1.04, 0.42, 0.9, 0.73], ['255', -1.19, -0.12, 0.06, 0.26, 0.17, 0.63, -0.1, 1.07, 0.92, 0.61, 0.41, -1.07, -0.6160867348791511, -0.74, 0.08, 1.41, -0.4, 0.2, -0.29, 0.22, 0.88, -0.84, -0.09, -0.44, 2.45, 1.26, 0.19, -1.48, -1.09, -1.15, -0.33, 0.99, -0.81, -0.21, -0.7, -0.19, 0.46, -1.24, -0.5, -0.85, 1.17, 0.8749361992161734, 1.69, 0.3936589811608609, 0.49787539444682316, 1.16, 2.5, 0.67, 1.28, 0.79, 1.3, 1.97, 0.23, 0.99, 0.9508287981859411, 0.4, 1.46, -0.11, 0.75, 1.29, -0.06, 0.77, 2.1, 0.28, 0.89, 0.4, 0.91, 1.57, -0.16, 0.6, 0.25, -0.2, 1.35, 0.83, 2.16, 0.34, 0.95, 0.45, 0.97, 1.63, -0.1, 0.65, 0.3, 0.37, 2.35, -2.36, 0.52, 1.32, -0.49, 0.12, -0.37, 0.14, 0.8, -0.92, -0.17, -0.4659922724755494, -0.88, -0.79, -1.78, -1.19, -1.67, -1.17, -0.52, -2.21, -1.47, -1.82, 0.58, -0.81, 2.84, 0.73, 0.8, 0.7, 1.0109570400359875, 0.61, 0.12, 0.63, 1.29, -0.43, 0.32, 0.028584683883065676, 1.73, 0.4, -0.49, 0.02, 0.68, -1.04, -0.29, -0.64, 0.58, 0.71, 0.49, 1.19, -2.65, 0.88, 1.06, -1.27, 1.29, 0.64, 3.67, 1.3561635321120495, -0.7, -1.43, -0.74, -0.6, 0.81, 2.13, -2.2, -2.16, 0.72, -1.89, 1.43, -1.94, 1.0, 2.96, -4.49, -1.97, -2.98, 0.6738095238095239, 0.89, 0.51, 1.17, -0.55, 0.2, -0.15, 2.16, 0.38, 0.66, -1.06, -0.31, -0.66, -0.27, -1.6111214088935784, -0.96, -1.3, 0.87, 0.45, 1.45, 0.75, 0.4, 0.72, 0.79, 1.24, -2.97, 2.49111637918067, 2.9, 0.83, 0.71, 0.69, -0.27721314850306833, 0.84, 0.62, 0.59, 0.88, 0.77, 1.04, 0.73, 0.79, 1.06], ['256', -7.27, -1.02, -0.37, 0.21, -1.48, -1.52, -1.91, -3.6, -3.27, -4.18, 0.45, -3.2, -1.27, -0.59, -0.28, -2.25, -2.18, -3.35, -4.17, -2.46, -4.67, -3.09, -1.72, -2.63, -3.61, -2.76, -4.61, -3.63, -1.71, -1.04, -0.73, -2.69, -2.62, -3.78, -4.61, -2.9, -5.1, -3.53, -2.16, -3.07, -3.5, -4.755063800783826, -1.01, 1.99, 2.69, 3.01, 0.98, 1.05, -0.15, -1.01, 0.76, -1.491934531913557, 0.11, 1.53, 0.59, -2.03, -3.57, -2.68, -3.36, -2.95, 0.69, 1.0, -0.99, -0.92, -2.11, -2.95, -1.21, -3.45, -1.85, -0.46, -1.38, -3.32, -3.61, 0.31, -1.67, -1.6, -2.77, -3.61, -1.88, -4.11, -2.52, -1.14, -2.05, -4.56, -6.54, 6.47, -3.9, -1.97, -1.9, -3.07, -3.9, -1.996255228898086, -4.4, -2.82, -1.44, -2.35, -2.85, -1.97, 0.07, -1.0246649659863944, -1.97, -0.22, -2.48, -0.87, 0.54, -0.39, -1.11, -2.04, -2.78, -1.56, -1.72, -1.49, -2.04, -1.19, -2.04, -0.29, -2.55, -0.94, 0.47, -0.46, -1.2, -0.8069232518696328, -0.86, 0.92, -1.37, 0.26, 1.68, 0.74, -2.54, -2.5, -0.21, -1.88, -8.44, -0.98, -0.63, 2.16, -2.24, -1.12, -1.07, -5.74, 3.35, 3.03, 1.53, -3.64, -0.8, -4.78, 4.65, 4.67, -1.56, 3.32, -3.12, -2.53, 1.25, -6.04, 5.28, 4.1, 6.07, -3.2, 0.0, 1.79, -0.52, 1.13, 2.56, 1.61, -4.67, -1.76, -2.27, -0.65, 0.76, -0.17, 0.52, 1.65, 3.1, 2.14, -3.17, -3.81, -1.12, 1.42, 0.48, -1.4379199656859432, -1.62, -3.63, 6.82, -2.82, -6.95, -2.02, -1.92, -2.5, -0.93, -2.24, -0.9954471401614257, -0.78, -0.51, -1.42, -1.59, -2.66, -2.21, -1.32], ['257', -5.73, -0.83, -0.45, 0.1, -1.32, -1.69, -1.2458847420401709, -2.91, -2.54, -2.4, 0.27, -0.36, 0.55, 1.45, -0.22, -1.9, 0.33, -1.39, -3.76, -0.94, -3.5, -0.19, -0.09, -0.86, -3.15, -2.61, -2.66, -0.63, 0.28, 1.18, -0.48, -2.16, 0.07, -1.5327410958555914, -4.01, -1.2, -3.75, -0.46, -0.35, -1.12, -1.51, -3.8350638007838267, -2.05, 0.91, 1.82, 0.15, -1.54, 0.7, -1.03, -3.41, -0.57, -3.14, 0.17, 0.28, -0.5, -1.0, -2.7557142857142853, -3.76, -2.4, -2.93, 0.9, -0.76, -2.43, -0.21, -1.93, -3.990306689342404, -1.47, -4.02, -0.73, -0.63, -1.4, -3.9, -3.8, -1.65, -2.8633418367346937, -1.1, -2.8, -5.13, -2.35, -4.88, -1.62, -1.52, -2.28, -3.31, -6.68, 6.73, -2.19, -1.68, 0.55, -1.17, -3.55, -0.72, -3.28, 0.03, 0.13, -0.5859922724755494, -2.19, -0.51, 2.28, 0.52, -1.89, 0.98, -1.63, 1.74, 1.84, 1.06, -1.25, -0.53, -3.5198953488372093, -1.78, -1.83, -1.79, -2.73, -1.72, -4.08, -1.27, -3.82, -0.52, -0.42, -1.19, -2.13, -1.03, -2.4, 0.46, -2.14, 1.21, 1.32, 0.54, -2.89, -3.06, -0.54, -2.41, -4.28, -1.3, -1.1, 3.72, -3.59, -1.82, -1.84, -1.53, 2.93, 3.54, 1.8645476190476191, -2.89, -1.28, -5.52, 5.42, 5.34, -1.75, 5.49, -3.52, -1.78, 0.87, -8.16, 5.32, 5.52, 8.18, -3.0, 1.41, 2.93, 0.27, 3.7, 4.129638579674294, 3.01, -5.39, -1.48, -2.59, 0.75, 0.85, 0.08, 1.13, 3.42, 3.53, 2.8014285714285716, -2.57, -2.75, -2.21, 0.1, -0.67, -1.8, -1.94, -2.82, 2.69, -2.89, -2.68, -2.13, -2.56, -2.32, -0.77, -2.07, -2.02, -0.87, -1.39, -1.05, -1.56, -4.3, -3.9, -2.05], ['258', 1.72, 0.12, 0.73, 0.4, 0.21, 1.69, -0.18, 0.39, 1.69, -0.98, -3.69, -0.62, -1.3, -2.3, -1.0, 0.06856009070294794, -1.85, -0.92, -0.1, -2.12, -0.8426645179126411, -1.66, -1.05, -2.67, 0.84, 0.28, 2.8526583949931124, 3.18, 2.48, 1.44, 2.79, 3.5733503401360545, 1.91, 2.87, 3.72, 1.63, 2.9844536700785693, 2.11, 2.74, 1.06, 1.07, 3.2349361992161736, -0.35, -0.68, -1.68, -0.38, 0.46052947845804987, -1.23, -0.3, 0.52, -1.51, -0.23193453191355703, -1.04, -0.43, -2.06, 0.42, 1.66, -0.98, 2.4, 0.33, -1.01, 0.3, 1.27, -0.56, 0.38, 1.21, -0.83, 0.42, -0.36, 0.25, -1.39, -1.42, 1.35, 1.33, 2.1, 0.46, 1.41, 2.25, 0.18, 1.45, 0.66, 1.28, -0.38, 3.42, 0.21, -0.27, 0.03, 0.76, -0.85, 0.08, 0.91, -1.13, 0.12, -0.66, -0.05, -1.69, -1.04, -0.73, -1.6, -0.67, 0.15, -1.88, -0.63, -1.41, -0.8, -2.43, -0.21, -0.81, 0.95, 1.27, 0.93, 1.59, 0.89, 0.94, 1.8869325674325674, -0.28, 1.1557782534925394, 0.19, 0.81, -0.84, 0.53, -0.05, 0.83, -1.21, 0.04, -0.74, -0.13, -1.76, -0.78, -1.71, 0.77, 0.79, -2.44, 1.44, 0.73, -2.78, 2.67, 1.34, 0.51, 1.11, -2.3222410208838777, -2.61, -1.3, 0.82, 0.92, 3.67, -3.78, -3.77, 1.24, -4.32, 2.46, -3.33, 1.8, 2.46, -4.47, -1.82, -2.84, 2.45, -0.87, -2.0151904761904764, -0.78, -1.56, -0.95, -2.57, 3.7, 1.17, 1.27, 0.47, 1.09, -0.56, -0.09, -0.78, -0.17, -1.8, 1.85, 2.32, 0.69, 0.62, -1.03, 1.29, 1.2, 0.26, -2.25, 1.85, 2.27, 1.2, 1.49, 0.08, -1.5672131485030683, 2.27, 1.06, 1.48, 0.18, 1.444626243824729, 1.74, 1.48, 1.22, 0.7], ['259', -0.46, 0.26, 0.16, 0.06, 0.48, 0.61, 0.6941152579598292, 1.23, 0.29, 0.11, -0.13, -0.54, -1.35, -0.69, -1.08, 0.58, 0.09, 0.06, -1.97, -1.29, 0.15, -0.64, -0.38, -0.17, 0.11, 0.43, 0.27265839499311245, -0.41, -1.23, -0.56, -0.95, 0.72, 0.22, 0.30725890414440843, -1.84, -1.16, 0.28, -0.51, -0.25, -0.04, 1.47, -1.25, 0.66, -0.82, -0.15, -0.55, 1.13, 0.63, 0.61, -1.44, -0.75, 0.69, -0.1, 0.16, 0.37, 1.23, 1.06, 1.03, 0.17, 1.49, 0.68, 0.28, 1.96, 1.47, 1.44, -0.62, 0.07, 1.52, 0.72, 0.99, 1.2, 1.39, 0.8, -0.3853571428571429, 1.28, 0.78, 0.76, -1.29, -0.61, 0.84, 0.04, 0.31, 0.52, -0.14, 1.5, -1.5, 1.2466982383853202, 1.68, 1.19, 1.16, -0.89, -0.21, 1.24, 0.44, 0.71, 0.92, -1.22, -0.47, -0.49, -0.52, -2.54, -1.86, -0.43, -1.22, -0.96, -0.75, 0.12, -0.45, -0.33, 0.58, 0.58517906963434, 0.59, 0.02, -0.03, -2.06, -1.3794642857142856, 0.06, -0.74, -0.47, -0.20141531611693433, 0.69, 0.05, -2.03, -1.35, 0.08, -0.71, -0.45, -0.24, 0.3, 0.11, 0.02, 0.33, -3.64, 0.05, 0.04, -0.87, 0.9, 0.48, 0.72, -0.33, -2.8, -1.16, -0.61, -0.22, 0.68, 1.79, -1.85, -1.79, 0.58, -1.46, 1.16, -0.27, 0.14, 0.12, -3.6, -0.09, -0.1, 2.84, 2.12, 0.69, 2.166609977324263, 1.35, 1.62, 1.83, 1.913167899560757, 1.42, 1.45, 0.65, 0.92, 1.13, -0.04, -0.79, -0.53, -0.32, 0.29, 0.19, 0.76, 0.26, 0.48, 0.59, 0.57, 1.07, -1.98, 0.0, 2.15, 0.41, 0.8, 0.5, 0.21, 0.41, 0.58, 0.76, 0.68, 1.05, 0.29, -0.35, 0.85, -0.33], ['260', -3.6, -0.96, 0.04, 0.04, -1.18, -0.75, -0.63, -1.7382794034640414, -0.99, -2.15, -0.63, -2.0, -0.9860867348791511, -0.04, -0.4, -0.86, -1.06, -1.67, -2.43, -0.36, -2.21, -1.29, -1.87, -1.17, -0.56, -1.29, -1.4973416050068875, -1.38, -0.42, 0.6, 0.24, -0.22, -0.43, -1.04, -1.81, 0.27, -1.58, -0.66, -1.25, -0.54, -1.2525315746467893, -0.74, -0.15, 0.97, 2.0, 1.64, 1.17, 0.96, 0.34, -0.438347866419295, 1.67, -0.20034527076293904, 0.73, 0.14, 0.85, -1.08, -0.4, -0.36, -1.74, -1.11, 1.02, 0.66, 0.2, -0.01, -0.62, -1.39, 0.7, -1.17, -0.24, -0.83, -0.12, -1.14, -2.11, -0.36, -0.81, -1.02, -1.63, -2.39, -0.32, -2.17, -1.25, -1.83, -1.13, -1.4, -1.02, 1.03, -1.759129077338006, -0.46, -0.67, -1.27, -2.04, 0.03, -1.82, -0.9, -1.48, -0.77, -2.02, -1.31, -0.21, -0.82, -1.59, 0.5, -1.36, -0.44, -1.02, -0.31, -0.37, -1.4, 0.13, -0.82, -0.81, -0.9, -1.1, -0.61, -1.38, 0.9097126881055455, -0.9842217465074605, -0.23, -0.82, -0.051415316116934326, -0.85, -0.49, -0.78, 1.33, -0.55, 0.38, -0.21, 0.51, 0.4418280382942037, 0.35, -0.21, -1.04, -6.03, -0.01, -0.01, 1.54, -1.51, -0.74, -0.09, -3.42, 3.42, 1.73, 0.79, -1.77, -0.686920210131221, -2.57, 2.56, 2.38, -0.83, 2.39, -1.65, 0.15, -0.025234735715753215, -3.22, 16.43, 2.14, 3.26, -3.49, 0.29, 2.12, 0.23, 1.17, 0.58, 1.3, -2.51, -1.79, -1.85, -0.93, -1.51, -0.81, 0.06, 0.94, 0.34, 1.06, -0.98, -1.27, -0.87, -0.59, 0.12, -0.84, -0.8856036987247091, -1.71, 7.56, -0.51, -7.100719387755102, -1.82, -1.68, -0.28, 0.72, -1.54, -0.62, -0.35, -1.03, -0.56, -0.99, -2.3, -2.67, -1.41], ['261', -0.15, 0.18, 0.15122171562045875, -0.08, 0.06297908099105959, 0.47, -1.1458847420401708, 0.46, 0.58, 1.09, 0.2, 1.54, 1.1, 0.65, 0.6, 1.15, 0.59, 0.69, 2.03, 0.48, 1.497335482087359, 0.46, 0.24, 0.69, 0.25, 0.57, 0.88, 1.3305454545454547, 0.89, 0.45, 0.4578199712950912, 0.95, 0.38, 0.48, 1.82, 0.28, 1.25, 0.25, 0.03, 0.48, 0.25, 1.5, -0.44, -0.43, -0.87, -0.92, -0.38, -0.93, -0.83, 0.48, -1.04, -0.08, -1.06, -1.28, -0.84, 0.48, 0.43, 0.44, 0.93, -0.01, -0.44, -0.3751532320595474, 0.06, -0.5, -0.4, 0.92, -0.6, 0.36, -0.63, -0.85, -0.4, 0.24, 0.43, -0.05, 0.5, -0.07, 0.04, 1.36, -0.17, 0.8, -0.19, -0.42, 0.08355964172512072, 1.49, 2.18, -2.1, 0.48, 0.55, -0.02, 0.08, 1.41, -0.12, 0.85, -0.15, -0.37, 0.08, 0.55, -0.07, -0.56, -0.46, 0.86, -0.66, 0.3, -0.69, -0.91, -0.46, 0.25, -0.14, 4.1, 0.26, 0.56517906963434, 0.04567351865003196, 0.5, 0.1, 1.43, 0.09971268810554554, 0.86, -0.06969498055271243, -0.35, 0.1, 0.51, 0.39, 1.5836855802927234, -0.2, 0.76, -0.23, -0.45, 0.0, 0.74, 0.56, -0.18, 0.38, 1.56, 0.09, 0.06, 0.44, -0.47, -0.24, 0.53, 0.16, -1.19, -0.52, -0.27, -0.07, 0.19, 0.74, -0.72, -0.77, 0.30329080486385296, 0.7, 0.5, 0.62, -0.32, 1.44, -2.37, -1.02, -1.31, 1.16, -0.92, -1.51, -0.56, -1.54, -1.76, -1.31, 0.7508051948051948, 0.6, 0.97, -0.03, -0.25, 0.2, -0.36, -0.98, -1.2, -0.76, 0.61, 1.12, 0.62, -0.22, 0.23, 0.27, 0.26, 0.34, -0.91, 3.06, 0.88, 0.15, 0.36, 0.85, 0.45, 0.49, -0.07, -0.01, 0.34, 0.15462624382472906, 0.4, 0.7, -0.47, 0.0], ['262', -0.8, -0.03, -0.05, -0.01, -0.45, -0.42, -0.44, -0.1, 0.3, 0.0, -0.66, 0.5593248299319729, 0.29, 0.28, 0.28, 0.17, 0.13, 0.01, -1.24, 0.06, 0.17, -0.42, -0.13, 0.34, -0.46, -0.1, 0.66, 1.21, 0.9708333333333333, 0.94, 0.95, 0.84, 0.79, 0.67, -0.59, 0.72, 0.83, 0.24, 0.53, 1.01, -0.16, 1.04, -0.55, -0.2563410188391391, -0.27, -0.26, -0.37, -0.42, -0.53, -1.78, -0.49, -0.37, -0.96, -0.67, -0.20495238095238094, 0.54, -0.07, 0.04, 0.06, -0.29, -0.01, 0.0, -0.11, -0.16, -0.27, -1.52, -0.23, -0.11, -0.7, -0.41, 0.05, -0.67, -0.27, 0.01, -0.1, -0.14, -0.26, -1.51, -0.22, -0.1, -0.69, -0.4, 0.07, 0.82, 0.33174294752866196, -0.17, -0.28, -0.11, -0.15, -0.27, -1.52, -0.23, -0.11, -0.7, -0.41, 0.06, -0.98, -0.17, -0.04, -0.16, -1.41, -0.12, 0.06262653735269351, -0.59, -0.3, 0.17, 0.1, -0.17, 0.41, -0.14, 0.0, -0.21, -0.13, -0.12, -1.37, -0.07, 0.04, -0.55, -0.26, 0.26858468388306567, 0.5, -0.01, -1.25, 0.05, 0.16, -0.43, -0.14, 0.33, 0.13, 0.14, 0.02, 0.22, -2.79, 0.05, -0.01, 0.36, -0.4, -0.19, 0.66, 0.07, 0.17, 0.35, 0.2, -0.39, 0.02, -0.45, 0.53, 0.49, -0.15, 0.57, -0.39, 0.05, -0.02, -0.39, 1.3, 0.11, 0.34, -0.14, 1.25, 1.31, 1.43, 0.83, 1.12, 1.6, -0.56, -0.06, 0.11, -0.48, -0.19, 0.28, -0.17, -0.59, -0.3, 0.17, 0.18, 0.5, 0.42, 0.29, 0.76, -0.16, -0.14, -0.19, 0.68, 0.0, -0.77, -0.87, -0.2, 0.13, 0.47, -0.26, -0.26, -0.21, 0.17, 0.2, -0.34, -1.08, 0.14, -0.64], ['263', -0.06, 0.04, 0.00015289830927053559, -0.09, 0.0, 0.22, 0.57, -0.38, -0.1, -0.84, -0.79, -1.32, -0.4, 1.14, -0.54, -0.47, -1.49, -1.01, -2.51, 0.06, -1.02, -1.0, -1.2, -1.42, 0.02, -0.05, -0.017341605006887542, -0.53, 0.39, 2.09318993704708, 0.25, 0.32, -0.71, -0.22, -1.73, 0.85, -0.23, -0.21, -0.41, -0.63, 0.2, -0.09, 0.49, 0.93, 2.5, 0.79, 0.86, -0.17, 0.31, -1.2, 1.4, 0.31, 0.32, 0.12, -0.1, -0.27, 0.69, 0.16, -0.12, -0.43, 1.6531047225355606, -0.14, -0.07, -1.09, -0.61, -2.11, 0.46, -0.62, -0.6, -0.8, -1.02, 0.76, -1.96, -1.67, -1.6, -2.6, -2.13, -3.61, -1.07, -2.14, -2.12, -2.31, -2.53, -0.46, 1.02, -0.96, -0.3, 0.07, -0.96, -0.47, -1.98, 0.6, -0.48, -0.46, -0.66, -0.88, -0.55, -0.36, -1.02, -0.54, -2.04, 0.53, -0.55, -0.53, -0.73, -0.95, 0.11, -0.31, 0.84, 0.28, 0.3, 0.24, 0.66, 0.4913469387755102, -1.03, 1.57, 0.48, 0.5, 0.3, 0.07, 0.2, 0.18, -1.51, 1.08, -0.01, 0.01, -0.19, -0.41, 0.89, 0.97, -0.25, 0.23, -1.4, 0.19, 0.06, -0.5, 0.48, 0.26, 0.6, -0.94, 1.57, -0.5, -0.24, -0.05, 0.25, 0.7914761904761906, -0.86, -0.84, 0.29, -0.71, 0.56, 1.0, -0.49, 1.96, -2.68, -1.18, -2.0, -1.66, 1.71, 2.63, 1.53, 1.55, 1.35, 1.12, 0.84, -0.89, -1.08, -1.06, -1.25, -1.48, 0.18, 0.02, -0.18, -0.41, -0.07, -0.22, 0.16, -0.2, -0.42, 0.3620800343140569, 0.33, -0.32, -1.81, 0.86, 1.81, 0.51, -0.44, 0.36, -0.23, 0.22, 0.42, 0.06, 0.01, 0.65, 0.675957527023814, -0.46, -0.52, 0.62], ['264', -3.75, -0.57, -0.22877828437954126, -0.34, -0.34, -0.03, -2.21, -1.33, -1.58, -2.004642857142857, -0.939391156462585, -0.15, -2.23, 0.58, -0.40285714285714286, -0.64, -2.02, -1.53, -1.47, -1.47, -2.54, -1.5, -1.635694768399324, -2.2, -1.64, -0.93, -1.0973416050068874, 0.81, -1.29, 1.55, 0.54, 0.31, -1.08, -0.59, -0.53, -0.53, -1.61, -0.56, -0.79, -1.27, -0.6, -1.9, -1.92, -2.08, 0.73, -0.27, -0.49, -1.87, -1.38, -1.2228644435138796, -1.33, -2.39, -1.36, -1.58, -2.06, -0.74, -2.03, -0.29, -1.31, 0.16, 2.88, 1.85, 1.62, 0.21, 0.72, 0.770952380952381, 0.77, -0.32, 0.74, 0.51, 0.02, -0.58, -2.64, -0.99, -1.22, -2.59, -2.1, -2.04, -2.05, -3.1, -2.08, -2.3, -2.77, -1.71, -1.01, 0.98, -1.66, -0.23, -1.61, -1.12, -1.06, -1.06, -2.13, -1.09, -1.31, -1.8, -2.23, -1.43, -1.38, -0.89, -0.83, -0.84, -1.91, -0.87, -1.09, -1.57, -0.58, -1.38, -0.04, -0.16, -0.27, 0.055673518650031964, -0.05, 0.5, 0.56, 0.55, -0.53, 0.52, 0.3, -0.19, -0.5, -0.55, 0.06, 0.05, -1.03, 0.02, -0.2, -0.69, -0.38, -0.36, -0.6, 0.08, -6.66, -0.52, -0.47, -0.13, 0.16246232339089484, 0.11881017100762112, -1.5, -1.85, 1.16, 0.37, 0.19, -1.87, -0.036920210131220946, -0.48, 0.58, 0.52, -0.16, -0.19, -0.34, 2.13, -1.02, -0.14, 0.38, 0.11, 0.18, -1.19, -0.6, 0.0, -1.08, -0.03, -0.26, -0.74, -0.55, -0.6, -1.08, -0.03, -0.25, -0.74, 0.48, 1.06, 0.83, 0.34, -1.57, -1.55, -0.57, -0.22, -0.71, -0.18, -0.15, -1.2874239503761218, 0.27, 0.42, -0.26, -0.35, -0.4989064979199875, -0.35, -0.49, 0.3, 0.19, -0.83, 0.55, -0.445373756175271, 0.14, -1.09, -0.57, 0.69], ['265', 4.4, -1.33, -0.08, 0.23, 0.78, -1.25, -3.27, -1.87, -2.29, -0.86, 1.95, 0.47, -0.43, 1.74, 1.46, -1.64, 0.63, -0.66, -2.73, 0.51, -1.08, 0.6, 1.29, 0.58, -2.13, -1.38, -2.76, -1.45, -2.33, -0.2, -0.48, -3.52, -1.29, -2.56, -4.59, -1.41, -2.895546329921431, -1.33, -0.64, -1.34, -1.56, -4.855063800783826, -1.33, -0.9, 1.27, 0.99, -2.1, 0.16, -1.12, -3.19, 0.04071428571428572, -1.511934531913557, 0.12, 0.82, 0.11, -0.89, -1.69, -2.05, -1.69, -0.43, 2.18, 1.9, -1.21, 1.06, -0.23, -2.31, 0.94, -0.65, 1.03, 1.73, 1.01, -3.28, -2.56, -0.28, -3.32, -1.09, -1.9206972789115644, -4.4, -1.21, -2.78, -1.13, -0.44, -1.15, -3.33, -5.71, 5.69, -2.29, -3.05, -0.82, -2.09, -4.13, -0.94, -2.5, -0.85, -0.17, -0.87, 1.52, 0.79, 2.31, 1.0, -1.11, 2.18, 0.57, 2.27, 3.121108978323264, 2.25, -0.27, 0.78, -1.05, -1.6, -1.66, -1.55, -1.48, -1.28, -3.34, -0.12, -1.7, -0.03, 0.66, 0.008584683883065672, -0.66, -0.2, -2.09, 1.17, -0.42, 1.26, 1.96, 1.24, -2.36, -1.81, 0.2, -1.89, 4.69, 0.03, -0.14, 3.75, -3.71, -1.86, -0.37, -1.57, 2.96, 3.19, 1.61, 2.18, -0.74, -4.9, 4.99, 4.81, -1.6, 5.51, -3.2, -2.7, 1.32, -4.4, 7.27, 2.88, 4.38, -2.85, 1.92, 3.33, 1.7, 3.42, 4.14, 3.4, -4.78, -1.36, -1.58, 0.09, 0.78, 0.07, 0.22, 1.69, 2.4, 1.68, -2.21, -2.72, -1.45, 0.69, -0.02, -2.17, -2.12, -1.79, 7.19, -1.36, -6.3186904761904765, -1.26, -2.57, -2.13, -0.71, -1.73, -1.9, -0.63, -0.32, -1.16, -1.43, -2.44, -2.91, -1.61], ['266', 3.93, 0.24, 0.13122171562045873, 0.04, 0.36, 0.03, 0.76, 0.1, -0.09, 1.68, 1.4, 1.07, 1.61, 1.53, 1.01, 1.39, 1.8, 1.78, -0.45, 1.8, 1.807335482087359, 1.54, 2.2843052316006762, 1.54, -0.07, 0.07, 0.3126583949931125, -0.33, 0.21, 0.13, -0.3321800287049088, -0.01, 0.39, 0.4872589041444084, -1.82, 0.4, 0.37, 0.14, 0.78, 0.14, -0.2, -0.98, 0.61, 0.54, 0.46, -0.06, 0.32, 0.72, 0.7, -1.5, 0.73, 0.7280654680864429, 0.47, 1.11, 0.47, -0.33, -0.88, -0.51, -0.54, 0.07, -0.08, -0.6, -0.22, 0.18, 0.16, -2.03, 0.19, 0.16, -0.07, 0.57, -0.07, -0.27, 0.15, -0.52, -0.14, 0.26, 0.24, -1.95, 0.26, 0.24, 0.01, 0.65, 0.0, -0.18, -0.99, 1.14, 0.7066982383853202, 0.38, 0.78, 0.76, -1.44, 0.79, 0.76, 0.53, 1.17, 0.53, 0.48, 0.29, 0.4, 0.38, -1.81, 0.4, 0.38, 0.15, 0.79, 0.14, -0.11, 0.25, -0.68, -0.2184018193170985, -0.08, -0.36, -0.11, -0.02, -2.2, 0.0, -0.02, -0.25, 0.38, -0.26, 0.02, -0.09, -2.18, 0.11224471370562701, 0.0, -0.23, 0.41, -0.23, 0.04, 0.28, -0.06, -0.01, 1.67, -0.1, -0.07, 1.44, -1.47, -0.6911898289923789, -0.34, 0.74, 0.18, 0.53, 0.27, 1.92, 0.12, -0.84, 0.72, 0.82, -0.27, 2.18, -0.55, 0.12, -0.07, -0.31, -1.3, 0.24, 0.33, -0.2, 2.14, 2.26, 2.23, 2.0, 2.65, 1.99, -0.7168321004392431, -0.12, -0.03, -0.25, 0.38, -0.26, -0.09, -0.23, 0.41, -0.23, -0.06, -0.28, 0.13, 0.63, 0.06224875531501633, -0.25, -0.23, 0.19, -0.57, -0.36, 0.65, -0.03, -0.33, -0.5, -0.64, 0.09, -1.0, 0.33, -0.01, 0.22, 0.14, -0.6, -0.16, -0.05], ['267', -2.43, -0.79, 0.15, 0.26, -0.7, -1.27, -1.1758847420401708, -1.75, -1.94, -1.62, 1.62, -0.68, -1.3, 0.19, -0.16, -0.77, -0.77, -1.32, 5.65, 0.07, -1.92, -0.99, 0.03, -1.3178253968253968, -0.7214063389924734, -0.99, -3.18, -2.26, -2.87, -1.41, -1.75, -2.35, -2.35, -2.89, 3.97, -1.52, -3.48, -2.57, -1.57, -2.89, -0.8125315746467892, -5.31, -0.95, -0.63, 0.87, 0.52, -0.09, -0.09, -0.65, 6.37, 0.75, -1.25, -0.32, 0.71, -0.65, -0.8499371536943234, -0.99, -1.07, -1.49, -0.32, 1.51, 1.15, 0.54, 0.54, -0.02, 7.040952380952381, 1.39, -0.63, 0.31, 1.34, -0.02, -2.6, -1.8, -0.35, -0.95, -0.96, -1.51, 5.45, -0.12, -2.1, -1.18, -0.16, -1.51, -3.79, -4.41, 4.422833333333334, -1.46, -0.61, -0.61, -1.16, 5.83, 0.23, -1.76, -0.83, 0.19, -1.16, 0.54, -0.86, 0.0, -0.56, 6.47, 0.84, -1.16, -0.23, 0.8, -0.56, -0.53, -0.84, 1.19, -1.29, -1.53, -1.04, -0.85, -0.55, 6.47, 0.85, -1.16, -0.22, 0.8, -0.56, -0.64, -0.3, 7.07, 1.41, -0.61, 0.33, 1.36, 0.0, -1.9, -1.68, 0.13, -1.21, 2.12, -0.01, 0.0, 1.74, -1.75, -0.88, -0.61, -1.98, 3.2, 2.58, 1.34, -1.21, -1.18, -3.92, 3.9, 4.0, -1.28, 2.61, -2.61, -1.9, 0.94, -2.62, 5.18, 1.74, 2.6, -3.2, -6.88, -5.29, -7.17, -6.29, -5.33, -6.6, -3.98, -1.69, -1.99, -1.06, -0.04, -1.39, 0.756501700680272, 0.94, 1.98, 0.61, -1.83, -2.46, -0.63, 1.03, -0.33, -1.29, -1.23, -1.72, 2.55, -0.04, -2.45, -1.92, -2.39, -1.64, -1.2772131485030684, -1.26, -1.1297802197802196, -1.02, -1.23, -1.35, -0.3, -2.74, -4.03, -1.3], ['268', 0.39, -0.19, 0.04, 0.19, -0.19702091900894042, -0.27, -0.41, -0.17, -0.48, 0.12, 0.32, 0.71, -0.12, -0.4, 0.39, -0.37, -0.06, 0.11, 5.8, 0.83, -0.41, -0.34, -0.56, 0.06, 0.45, -0.51, -0.2, 0.39, -0.44, -0.72, 0.07, -0.68, -0.38, -0.21, 5.46, 0.51, -0.72, -0.66, -0.88, -0.26, -0.32, -0.05506380078382657, -0.59, -0.82, -1.1, -0.31, -1.07, -0.76, -0.6, 5.06, 0.13, -1.11, -1.04, -1.26, -0.65, -0.71, 0.0, -0.07, -1.25, 0.24, -0.28, 0.51, -0.25, 0.06, 0.23, 5.93, 0.96, -0.29, -0.22, -0.44, 0.18, -1.11, 0.52, 0.79, 0.03, 0.34, 0.51, 6.22, 1.24, -0.01, 0.06, -0.16, 0.46, -0.46, 1.59, -1.58, -0.27, -0.76, -0.45, -0.28, 5.39, 0.44, -0.8, -0.73, -0.95, -0.33, -0.43738095238095237, 0.49, 0.31, 0.48, 6.19, 1.21, -0.04, 0.03, -0.19, 0.43, -0.07, 0.44, 3.82, -0.11, 0.08, -0.2, 0.18, 0.17, 5.86, 0.89, -0.35, -0.28, -0.5, 0.12, 0.63, 0.01, 5.69, 0.73, -0.51, -0.45, -0.67, -0.05, 0.07, -0.29, 0.09, 0.06, -0.87, 0.08, -0.27, -0.14, 0.19, 0.07, 0.09, -0.14, 1.33, 0.22, 0.1, 0.15, -0.31, -0.26, 0.27, 0.33, -0.1, -0.17, -0.22, -2.43, 1.19, 0.51, 2.46, -0.31, -0.55, -1.28, -5.37, -4.69, -5.87, -5.8, -6.01, -5.43, -0.38, -0.71, -1.23, -1.16, -1.38, -0.77, 0.53, 0.07, -0.15, 0.47, -0.54, -0.7815464535464534, 0.46, -0.22, 0.4, -0.1, -0.03, -0.14, 1.24, 1.8, -1.33, 0.96, -1.49, 0.68, 0.6927868514969316, 0.12, 0.12, -0.61, -0.47, -0.05537375617527095, 0.06, 0.32, -1.73, -0.34], ['269', -13.632857142857144, -0.43, -0.41877828437954123, -0.1, -1.96, -0.76, 0.21, -2.13, -0.77, -2.3, -1.21, -3.03, 0.08, -0.2, 0.87, 0.26071428571428573, 0.17, -1.4294285714285713, -0.89, 0.08, -2.52, -1.18, -0.88, -1.47, -1.93, -2.3, -1.1, -1.84, 1.3, 1.02, 2.11, 1.48, 1.4014285714285712, -0.22, 0.33, 1.31, -1.33, 0.03, 0.33, -0.26, -4.05, -0.5, 0.76, 3.2, 2.92, 4.02, 3.39, 3.3, 1.65, 2.21, 3.21, 0.53, 1.9, 2.22, 1.61, -1.68, -3.1657142857142855, -1.62, -1.49, -2.37, -0.27, 0.79, 0.43142857142857144, 0.09, -1.5, -0.96, 0.01, -2.59, -1.26, -0.96, -1.54, -2.66, -2.1, 1.07, 0.45, 0.37, -1.23, -0.69, 0.28, -2.33, -0.99, -0.69, -1.27, -0.73, -4.21, 4.14, -3.14, -0.61, -0.69, -2.28, -1.74, -0.78, -3.36, -2.04, -1.74, -2.32, -3.29, -2.55, 0.5385714285714286, -1.68, -1.14, -0.17, -2.77, -1.44, -1.14, -1.72, -0.82, -2.54, -2.46, -1.19, -1.3, -1.34, -2.46, -1.6, -1.06, -0.09, -2.68, -1.35, -1.05, -1.64, -1.09, -0.88, 0.55, 1.53, -1.11, 0.25, 0.6328571428571429, -0.04, -1.64, -2.43, -0.24396282112195955, -2.45, -6.49, -0.33967687074829933, -0.22428571428571428, 1.49, -1.43, -0.74, -0.63, -3.76, 4.55, 2.49, 1.19, -6.488561224489796, -0.38, -3.95, 3.97, 3.58, -1.23, 2.18, -2.41, 0.29, -0.08, -7.29, 6.623125850340137, 4.87, 7.23, -4.75, -1.42, 0.98, -1.64, -0.3, 0.01, -0.59, -3.45, -2.38, -2.6, -1.27, -0.96, -1.55, 0.23, 1.37, 1.68, 1.08, -0.74, -1.04, -1.13, 0.31, -0.29, -1.19, -1.41, -2.04, 3.25, -2.56, -3.1, -3.84, -2.09, -1.43, -0.5172131485030683, -1.71, -0.69, -1.06, -0.27, -1.02, -0.84, -5.84, -3.81, -1.9], ['270', -8.31, 0.04, -0.08, 0.0, -1.74, -0.5, -0.22, -0.45, -0.7, 0.22, 1.0, 0.8293248299319728, -0.4, 0.81, 0.4, 2.38, 1.27, 0.14, 3.97, 2.39, -0.47, -0.89, 0.37, -0.38, -1.02, -0.56, -0.78, -0.18, -1.39, -0.19, -0.59, 1.3633503401360545, 0.27, -0.85, 2.94, 1.37, -1.45, -1.87, -0.62, -1.37, 0.0, -1.57, -0.6, -1.21, -0.01, -0.42, 1.7842665945165948, 0.45, -0.68, 3.12, 1.55, -1.28, -1.7, -0.4157142857142857, -1.19, -1.28, -0.75, -1.06, -0.73, 0.62, 1.22, 0.81, 2.79, 1.68, 0.54, 4.39, 2.8, -0.06, -0.49, 0.78, 0.02, 0.03, -0.59, -0.4, 1.56, 0.46, -0.67, 3.14, 1.56, -1.26, -1.68, -0.43, -1.18, -0.71, -0.28, 0.19, -0.19, 1.97, 1.2999013605442178, -0.26, 3.55, 1.98, -0.86, -1.28, -0.03, -0.78, -3.48, -2.11, -1.08, -2.19, 1.55, 0.01, -2.78, -3.19, -1.96, -2.7, 0.03, -2.11, -1.17, -0.36, -0.38482093036566006, -0.34, -1.04, -1.12, 2.66, 1.1, -1.72, -2.13, -0.89, -1.63, 0.9, 0.08, 3.83, 2.24, -0.6, -0.8942004503433073, 0.23, -0.52, -0.42, -0.74, -0.07, -0.99, -10.48, -0.05, 0.04, 0.67, -0.71, -0.33, -0.56, -0.64, 4.02, 0.76, 0.32, -4.15, -0.11, -1.08, 0.97, 1.1, -0.37, 1.08, -0.76, 0.44, -0.21, -3.12, -2.93, 1.98, 3.09, -4.02, -3.61, -1.52, -4.27, -4.67, -3.46, -4.19, -0.9268321004392431, -2.12, -2.79, -3.2, -1.97, -2.7, 0.7444897959183674, -0.42, 0.84, 0.08, -0.62, -0.67, 1.11, 1.27, 0.51, -0.34, -0.48, -0.44, -0.03, -0.85, 0.06, -1.44, -1.44, -0.16, -0.75, -0.4, -0.55, 0.0, -0.47, -0.05, 0.6, -3.1, -1.47, -0.5], ['271', 3.11, 0.05, -0.028778284379541254, 0.28, -0.41, -0.64, 1.0641152579598292, -0.86, -0.75, 0.0, 1.56, -0.46, -0.22, -0.63, 2.0, -1.62, 0.63, -0.01, -4.37, 0.75, 0.3473354820873589, -0.06, 0.87, 0.97, -1.72, -1.05, -1.54, -1.99, -1.75, -2.16, 0.43, -3.13, -0.91, -1.54, -5.84, -0.8, -1.23, -1.59, -0.68, -0.58, -2.92, 0.68, 0.46, 0.24, -0.18, 2.47, -1.148956349206349, 1.1, 0.45, -3.93, 1.6496666666666666, 0.77, 0.4, 1.33, 1.7508287981859412, 0.95, -0.52, -0.9, -0.74, 0.22, -0.42, 2.22, -1.4, 0.85, 0.21, -4.16, 0.97, 0.53, 0.16, 1.09, 1.19, -2.51, 0.64, 2.65, -0.9892857142857143, 1.28, 0.63, -3.75, 1.4, 0.95, 0.58, 1.51, 1.62, -1.06, -2.52, 2.51, -1.96, -3.55, -1.34, -1.97, -6.24, -1.22, -1.65, -2.01, -1.11, -1.0, -0.17, 1.64, 2.29, 1.64, -2.79, 2.41, 1.96, 1.59, 2.53, 2.63, -0.09, 1.68, -0.26, -0.82, -0.71, -0.9, -0.63, -0.64, -4.97, 0.12, -0.32, -0.69, 0.23, 0.34, -0.14, 0.01, -4.36, 0.76, 0.32, -0.05, 0.88, 0.98, -0.75, -0.46, 0.46, -0.59, -0.5090476190476191, 0.0, -0.07, 2.58, -2.57, -1.26, 0.11, -0.9138364678879505, 1.52, 1.66, 0.83, 1.58, -0.31692021013122096, -2.46, 2.41, 2.47, -0.82, 3.95, -1.64, -5.03, 2.5, -1.82, 4.687380952380952, 1.25, 1.8, -1.6161904761904764, 4.56, 5.35, 4.89, 4.51, 5.47, 5.58, -2.52, -0.75, -0.44, -0.8, 0.12, 0.22, -0.31, -0.37, 0.56, 0.66, -0.71, -0.89, 0.06, 0.93, 1.03, -0.8, -0.77, -0.77, 3.24, -0.49, -3.23, -0.73, -0.16, -0.86, 0.1, -0.71, -1.18, -0.78, 0.1, -0.77, -0.97, -0.23, 0.94, -0.7], ['272', -1.72, 0.53, 0.09122171562045875, -0.24, -0.94, 0.3, 0.7, -0.22, 0.17, -1.84, -2.08, -1.95, -1.75, -0.79, -1.54, -0.86, -1.64, -1.9597942176870748, -4.39, -0.63, -2.53, -2.1440578231292515, -3.1, -2.59, -0.28, -0.04, 0.27265839499311245, 0.13, 0.33, 1.32, 0.56, 1.25, 0.45, 0.09, -2.36, 1.49, -0.46, -0.18, -1.04, -0.52, -0.62, 1.2349361992161734, 0.11, 0.2, 1.19, 0.42, 1.12, 0.32, -0.04, -2.48, 1.35, -0.59, -0.32, -1.17, -0.66, 0.22, 0.55, 0.08, 0.19, -0.09, 0.99, 0.22, 0.92, 0.12, -0.24, -2.571321995464853, 1.15, -0.79, -0.52, -1.37, -0.85, 0.4736060011417156, -1.06, -0.76, -0.07, -0.86, -1.22, -3.63, 0.16, -1.76, -1.49, -2.33, -1.82, 0.25, 3.59, -3.59, -0.31, 0.6905204081632652, -0.1, -0.47, -2.9, 0.92, -1.01, -0.74, -1.58, -1.07, -0.16, -1.0, -0.79, -1.15, -3.56, 0.23, -1.69, -1.42, -2.1188910216767356, -1.75, 0.26, -1.03, 2.02, 0.42, 0.58, 0.31, -0.21, -0.36, -2.8, 1.03, -0.91, -0.64, -1.4040121365844473, -0.97, 0.46, 0.16, -2.44, 1.4, -0.55, -0.27, -1.12, -0.61, 1.6689583699631245, 0.87, -0.21, 0.43, -0.3, 1.06, 0.65, -0.4, 0.38, 0.18, 0.29, -0.91, 2.7405182488772715, -0.88, -0.45, -0.83, 0.57, 1.2, -1.37, -1.3, 0.44, -0.53, 0.88, 2.55, -1.29, -0.52, -2.93, 0.36, 0.52, -2.5161904761904763, 2.66, 3.93, 1.94, 2.22, 1.366625850340136, 1.88, 1.24, -1.22, -1.91, -1.65, -2.49, -1.98, 0.7, 0.27, -0.58, -0.07, 0.2, 0.02, 0.43, -0.85, -0.34, 0.42, 0.38, -0.21, -1.3, 1.79, 0.97, 0.0, -0.08, 1.29, 0.5927868514969317, 0.54, 0.07, 0.3, 0.73, 0.27, 0.855957527023814, -2.65, -1.0784047619047619, 0.58], ['273', -8.33, 0.98, 0.0, -0.27, 0.15, 1.03, 3.55, -0.65, 1.06, -1.41, -2.31, -5.0, -1.87, 0.05, -0.75, 0.67, -1.97, -1.47, -0.64, -2.75, -1.55, -0.58, -2.46, -2.6, -0.86, 0.07, 0.92, -2.75, 0.45, 2.42, 1.59, 3.365035714285714, 0.34, 0.86, 1.71, -0.45, 0.78, 1.77, -0.15, -0.3, -0.83, 0.46493619921617346, 3.77, 3.29, 5.32, 4.47, 5.97, 3.19, 3.72, 4.59, 2.37, 3.63, 4.65, 2.68, 2.52, 0.28, -0.15, 0.27, 0.7, 0.47, 1.96, 1.14, 2.5942857142857143, -0.1, 0.41, 1.25, -0.89, 0.33, 1.31, -0.6, -0.74, -1.91, -1.47, -0.8, 0.62, -2.02, -1.52, -0.69, -2.8, -1.6, -0.63, -2.51, -2.5964403582748794, 0.63, 2.56, -2.6, -0.67, 1.43, -1.23, -0.72, 0.11, -2.01, -0.8, 0.17, -1.72, -1.86, -4.03, -2.07, -2.63, -2.12, -1.31, -3.39, -2.21, -1.007183003504432, -3.11, -3.25, 0.21, -2.1, -0.05, 0.89, 0.77, 1.02, 0.57, 0.52, 1.36, -0.79, 0.43, 1.42, -0.49, -0.64, -0.82, 0.05, 0.84, -1.3, -0.08, 0.9, -1.01, -1.15, 0.9, 0.8, -0.38, 0.6, -11.69, 0.42, 0.39, -2.07, 2.13, 1.06, -1.6, -0.2, -2.77, -1.71, -0.92, -4.22, 0.45, 2.67, -2.71, -2.61, 0.88, -3.29, 1.75, 2.69, -1.36, 1.65, -6.99, -1.16, -1.65, 2.77, -0.78, -2.12, -0.91, 0.06, -1.83, -1.97, 2.72, 1.37, 1.23, 2.22, 0.3, 0.15, 0.14, 0.98, -0.92, -1.07, 0.93, 0.49, -0.84, -1.89, -2.03, 0.94, 0.87, -0.46, -3.61, 0.23, 3.64, 0.58, 0.85, 1.07, -0.15, 1.46, 0.64, 0.87, -0.05, 0.69, 1.22, -1.64, 1.34, 1.14], ['274', -5.39, 0.06, 0.17122171562045874, 0.0, 0.11, -0.1, 0.11, 0.06, 0.13, 1.24, 0.79, 1.57, 1.89, 1.89, 0.29, 2.08, 1.67, 0.97, 3.53, 0.09, 1.33, 0.99, 1.52, 1.47, 0.34, -0.16, 0.45, 0.78, 1.09, 1.09, -0.5, 1.28, 0.88, 0.19, 2.72, -0.69, 0.54, 0.2, 0.73, 0.7238417231978392, -0.26, 0.0, -0.33, 0.31, 0.47787539444682314, -1.27, 0.5, 0.09, -0.59, 1.92, -1.46, -0.24, -0.58, -0.05, -0.1, 0.0, 0.59, 0.74, 0.17, -0.64, 0.0, -1.57, 0.19, -0.21, -0.9, 1.61, -1.77, -0.55, -0.89, -0.36, -0.41, 0.05, -0.64, -1.57, 0.19, -0.21, -0.9, 1.61, -1.77, -0.55, -0.88, -0.36, -0.41, 0.25, -0.42, 0.5, 0.95, 1.79, 1.38, 0.69, 3.23, -0.2, 1.04, 0.7, 1.23, 1.18, -1.62, -0.83, -0.4, -1.08, 1.42, -1.95, -0.74, -1.07, -0.54, -0.6, 0.18, -0.89, -0.88, -0.13, -0.08, -0.05432648134996804, -0.4290429599640126, -0.69, 1.83, -1.56, -0.34, -0.67, -0.14, -0.13141531611693433, 0.33, 0.26, 2.53, -0.88, 0.35, 0.01, 0.55, 0.49, -0.3, -0.48, 0.12603717887804045, -0.18681321637643203, -4.73, 0.01, 0.1, 0.31, -0.3175376766091052, -0.15, 0.08, 1.09, -2.29, 0.25, 0.15, -2.64, 0.22, -0.42, 0.35, 0.33, -0.12, 0.45, -0.24, 0.4, -0.22, -1.26, 4.71, 0.92, 1.2, 2.3, -2.21, -3.32, -2.12, -2.45, -1.93, -1.98, -0.4, 1.15, 1.24, 0.9, 1.44, 1.39, -0.09, -0.34, 0.19, 0.14, 0.15, 0.09, 0.25, 0.53, 0.48, -0.09, -0.14, 0.06257604962387836, 1.96, -0.62, -2.13, 0.11, -0.14, -0.20136255179902912, 0.02278685149693166, -0.23, -0.24, 0.14, 0.29, 0.1, -0.144042472976186, 0.0, -0.58, -0.32], ['275', 2.73, 0.24, 0.17122171562045874, 0.14, 2.02, -0.34, -0.85, -0.46, -0.4, -0.58, -0.48, 0.11, -1.06, 0.36, 0.89, -1.06, -0.26, -0.71, -3.61, -2.68, -0.37, -0.51, -0.17, -0.08, -0.59, -0.44062858541110805, -0.1, 0.6, -0.58, 0.84, 1.38, -0.58, 0.23, -0.23, -3.14, -2.21, 0.11, -0.03, 0.31, 0.4, -0.78, 0.7749361992161734, -0.7, -1.17, 0.24, 0.78, -1.17, -0.37, -0.82, -3.71, -2.79, -0.48, -0.62, -0.28, -0.2, 0.71, -0.88, -0.08, -0.43, 0.48, 1.43, 1.97, 0.0, 0.81, 0.35, -2.5628197278911564, -1.64, 0.7, 0.55, 0.9, 0.98, -0.71, -0.94, 0.53, -1.41, -0.61, -1.07, -3.95, -3.03, -0.72, -0.86, -0.53, -0.44, -0.04, -1.45, 1.44, -1.4233017616146797, -1.93, -1.14, -1.59, -4.46, -3.54, -1.25, -1.39, -1.05, -0.97, -0.25, 0.48, 0.81, 0.35, -2.58, -1.64, 0.69, 0.55, 0.89, 0.98, -0.02, 0.52, -0.58, -0.23, -0.4, -0.11, -0.3290429599640126, -0.46, -3.36, -2.43, -0.11, -0.25, 0.09, 0.17, -0.03, 0.13, -2.91, -1.98, 0.35, 0.2, 0.55, 0.64, -1.23, -1.24, 0.11, -0.4, -0.76, -0.18, 0.27, 0.25, -0.26, -0.14, 0.21, -0.42, -4.25, 0.5, 0.19, 1.33, -0.22, -0.67, 0.66, 0.67, -0.22, 0.32, -0.43, -1.63, 0.83, -0.95, -4.09, 0.67, 0.97, 4.48, 3.13, 0.96, 3.36, 3.21, 3.56, 3.66, -0.68, 2.15015873015873, 2.37, 2.23, 2.58, 2.67, -0.22, -0.14, 0.2, 0.29, -0.48, -0.19, -0.08, 0.34, 0.43, -0.18, -0.27, -0.52, -1.68, -0.46, 2.129280612244898, -0.57, -0.36, -0.33136255179902907, 0.09, 0.010077402522780693, -0.21, -0.2, -0.32, 0.45, -0.5, -0.67, -0.16, -0.45], ['276', -7.06, -0.93, -0.58, 0.23, -1.54, -1.91, -1.14, -2.06, -2.52, -2.35, 2.6903184712113286, -1.51, 0.84, 0.6, -0.95, -2.11, 0.5071428571428571, -0.6, 0.95, -0.23, -3.12, -0.14, 1.25, -0.41, -3.12, -3.43, -4.72, -3.9, -1.5898809523809525, -1.84, -3.35, -4.48, -1.96, -3.0, -1.5, -2.65, -5.46, -2.55, -1.2, -2.82, 1.51, -6.38, -0.85, 2.39, 2.15, 0.6408150295752765, -0.61, 2.02, 0.93, 2.5, 1.3, -1.63, 1.4, 2.8, 1.12, -3.03, -3.6957142857142857, -1.16, -1.8, -3.17, -0.24, -1.78, -2.93, 0.3114285714285714, -1.42, 0.11, -1.06, -3.92, -0.9540374149659864, 0.4, -1.24, -1.54, -2.93, -1.54, -2.7, -0.13, -1.19, 0.34, -0.83, -3.69, -0.73, 0.64, -1.01, -4.65, -10.15, 10.23, -1.42, -1.17, 1.44, 0.36, 1.91, 0.73, -2.19, 0.82, 2.22, 0.54, -0.97, -0.25, 2.64, 1.55, 3.12, 1.92, -1.03, 2.02, 3.43, 1.74, -1.9, -0.24, -2.99, -2.21, -2.59, -2.04, -2.81, -1.06, 0.47, -0.7, -3.57, -0.61, 0.77, -0.88, -2.15, -1.77, 1.55, 0.37, -2.54, 0.46, 2.0485714285714285, 0.18, -3.69, -3.16, 0.03, -2.97, -1.94, -2.02, -1.07, 4.44, -4.37, -2.21, -1.79, -3.85, 4.17, 4.651428571428572, 2.264547619047619, -3.51, -1.72, -6.99, 7.607142857142857, 6.924285714285714, -2.2, 6.68, -4.39, -4.27, 1.78, -8.43, 28.87, 5.58, 8.48, -4.28, -3.27, -1.17, -4.02, -1.07, 0.3, -1.35, -6.7, -2.13, -2.89, 0.1, 1.48, -0.18, 0.79, 3.08, 4.5, 3.0285714285714285, -2.72, -3.33, -2.22, 1.39, -0.28, -2.25, -2.41, -2.1, 14.37, -3.9, -14.29, -2.12, -2.89, -3.56, -1.64, -2.42, -2.26, -1.34, -1.72, -1.3, -1.95, -3.22, -3.9, -0.7], ['277', -1.68, 0.22, -0.15, -0.01, -0.36, -0.39158037632624054, 0.0, 0.43, 0.25, 1.75, 1.99, 1.54, 2.43, 1.41, 1.32, 1.33, 1.88, 1.72, 8.06, 2.64, 1.52, 1.5, 1.35, 2.1, -0.2, -0.04, -0.23, -0.44, 0.43, -0.57, -0.66, -0.65, -0.11, -0.26, 5.95, 0.64, -0.46, -0.48, -0.63, 0.11, 0.12, 0.40493619921617346, 0.409303232481804, 0.88, -0.13, -0.22, -0.21, 0.34, 0.18, 6.43, 1.09, -0.02, -0.03, -0.18, 0.55, 0.5, 0.41, 1.32, 0.39, -0.67, -1.0, -1.09, -1.08, -0.54, -0.69, 5.5, 0.2, -0.89, -0.91, -1.06, -0.33, -0.04, 0.34, -0.09, -0.08, 0.46, 0.31, 6.56, 1.21, 0.11, 0.09, -0.06, 0.68, 0.24, 0.93, -0.89, 0.43, 0.01, 0.56, 0.4, 6.66, 1.31, 0.2, 0.18, 0.04, 0.77, -0.14, 0.42, 0.54, 0.39, 6.65, 1.3, 0.2526265373526935, 0.17, 0.02, 0.76, 0.17, 0.42, -2.14, -0.3, -0.26, -0.33, -0.13, -0.15, 6.07, 0.75, -0.35, -0.37, -0.52, 0.22, 0.15, 0.03, 6.23, 0.9, -0.2, -0.22, -0.37, 0.37, 0.0, 0.08, 0.28, -0.22, -0.84, 0.19, 0.2, 0.23, -0.24, -0.14, 0.67, 0.23, 1.8005182488772715, 0.59, 0.31, -0.95, -0.23, -0.9, 0.83, 0.87, -0.3, 0.45, -0.55, -1.92, 0.91, -0.33, 0.28, 0.21, 0.33, -1.75, -5.84, -5.02, -6.05, -6.07, -6.21, -5.52, -0.87, -0.87, -1.09, -1.11, -1.26, -0.53, 0.23, -0.02, -0.17, 0.57, 0.5701351386708531, 0.37, 0.3272746849074344, -0.15, 0.6622487553150163, -0.25, -0.18560369872470917, 0.5625760496238783, 0.19, -1.74, -0.23, -0.3, -0.73, 0.39, 0.74, -0.55, -0.11, -0.59, -0.1, -0.17, -0.25404247297618604, -1.22, -0.69, -1.42], ['278', -12.888571428571428, 0.021428571428571422, -0.26877828437954127, 0.01, -2.11, -1.44, 0.06, -1.98, -0.92, -2.51, -1.66, -2.51, -0.98, -0.79, -0.42, 0.06, -1.13, -1.86, -4.05, 0.51, -2.6, -0.76, -0.68, -0.88, -2.11, -2.46, -0.86, -0.86, 0.7208333333333333, 0.89, 1.26, 1.76, 0.54, -0.2, -2.43, 2.210714285714286, -0.95, 0.92, 1.0, 0.8438417231978392, -1.66, -0.96, 0.0, 1.57, 1.77, 2.14, 2.64, 1.42, 0.67, -1.58, 3.09, -0.09, 1.8, 1.88, 1.67, -1.49, -1.55, -1.75, -1.54, -1.55, 0.19, 0.5607993197278912, 1.05, -0.15, -0.89, -3.1, 1.5, -1.64, 0.22, 0.3, 0.1, -1.01, -1.5242857142857142, 0.37, 0.86, -0.35, -1.08, -3.29, 1.3, -1.83, 0.03, 0.11, -0.1, -1.0010901360544218, -4.99, 4.93, -2.1, 0.49, -0.2800986394557823, -1.41, -3.65, 0.93, -2.19, -0.34, -0.26, -0.46, -3.65, -2.57, -1.19, -1.92, -4.11, 0.44, -2.66, -0.82, -0.74, -0.94, -0.8, -2.62, -1.34, -1.77, -1.53, -1.93, -1.4, -0.74, -2.95, 1.65, -1.49, 0.38, 0.45, 0.25, -1.72, -0.66, -2.24, 2.41, -0.75, 1.12, 1.2, 0.99, -0.79, -0.3, -0.65, -1.68, -7.35, -0.33, -0.36, 4.87, -4.87, -2.43, -0.78, -2.68, 5.72, 3.57, 1.76, -6.314778911564626, -1.01, -5.25, 5.37, 5.38, -1.77, 7.16, -3.42, -2.15, 1.02, -4.16, 9.65, 2.797142857142857, 4.435714285714286, -5.99, 1.61, 4.75, 1.51, 3.43, 3.51, 3.3, -5.35, -3.0, -3.09, -1.26, -1.18, -1.38, 0.09, 1.89, 2.202857142857143, 1.76, -0.99, -1.12, -1.77, 0.08, -0.13, -1.66, -1.71, -1.83, 4.89, -1.47, -4.93, -2.58, -2.32, -1.84, -0.2, -1.91, -2.22, -0.64, -0.949047619047619, -1.59, -1.64, -3.01, -3.38, -1.05], ['279', -1.09, -0.23, 0.011221715620458745, 0.15, -1.61, 0.29, -0.12, -0.17, 0.42, -0.22, -0.7, -0.43, -0.31, 0.37, -1.5, -0.19, -0.12, -0.17, -0.06, 3.93, 0.01, 0.06, -0.38, -1.16, 0.7, -0.14, 0.49, 0.27, 0.4, 1.08, -0.81, 0.52, 0.59, 0.53, 0.65, 4.67, 0.72, 0.77, 0.33, -0.46, 0.43, 0.40493619921617346, 0.21, 0.12, 0.8, -1.08, 0.24, 0.32, 0.26, 0.37, 4.809666666666667, 0.44, 0.5, 0.06, -0.73, 0.48, 0.29, 0.3, 0.28, 0.09, 0.68, -1.2, 0.12, 0.2, 0.14, 0.25, 4.26, 0.32, 0.37, -0.06, -0.85, 0.23, -0.58, -1.86, -0.56, -0.48, -0.54, -0.18252355184498031, 3.55, -0.36, -0.3, -0.74, -1.52, 0.47, 0.42, -0.41, 1.3, 1.33, 1.41, 1.35, 1.46, 5.52, 1.54, 1.59, 1.15, 0.35, 0.61, -0.03, 0.08, 0.02, 0.13, 4.13, 0.2, 0.25, -0.18, -0.97, -0.06, 0.0, 2.55, 0.2, 0.22, 0.29, -0.1, -0.06, 0.05, 4.05, 0.13, 0.18, -0.26, -1.05, -0.28, -0.05, 0.11, 4.11, 0.18, 0.24, -0.2, -0.99, 0.31, 0.17, 0.2860371788780405, 0.24, 1.89, 0.07, 0.0, -0.49, 0.41, 0.23, 0.06, -1.92, 8.13, -0.44, -0.21, -0.56, 0.5, 0.49, -0.6, -0.6, 0.21, -0.78, 0.4, -0.8116093450200591, 0.47, -0.24, -1.35, 0.16, 0.36, -8.09, -0.16, 4.0, 0.07, 0.12, -0.31, -1.1, 0.57, -3.99, -3.77, -3.72, -4.14, -4.9, -0.23, 0.05, -0.39, -1.17, 0.34, 0.56, -0.28, -0.44, -1.22, 0.19, 0.2, -0.14, -0.79, 1.78, 0.91, 0.58, -0.85, 0.16, -0.79, 0.29, 0.16, 0.5, 0.21, 0.42, 0.95, -0.56, -0.99, 0.95], ['280', 4.518571428571429, -1.87, 0.27, 0.6521428571428572, 0.88, -0.16, 0.25, 0.44, -0.06, 0.47, 1.25, 0.15, -0.36, -0.56, -0.19, -1.48, 1.56, 1.09, 2.71, -0.19, 0.42, 0.87, 0.96, 0.62, 0.13, 0.46, -0.77, -1.09, -1.59, -1.78, -1.42, -2.7, 0.31, -0.15, 1.45, -1.42, -0.82, -0.37, -0.28, -0.62, 1.09, 1.23, 0.32, -0.51, -0.7, -0.34, -1.63, 1.7186513605442175, 0.94, 2.56, -0.34, 0.27, 0.72, 0.8442857142857143, 0.48, -0.15, -0.16, -0.38, -0.48, 0.83, -0.2, 0.17, -1.13, 1.92, 1.46, 3.08, 0.17, 0.78, 1.2314285714285713, 1.33, 0.99, -0.55, 1.6757142857142857, 0.37, -0.93, 2.13, 1.66, 3.29, 0.37, 0.99, 1.44, 1.53, 1.19, -0.24109013605442178, -1.07, 1.14, 0.66, -1.29, 1.75, 1.32, 2.91, 0.0, 0.62, 1.07, 1.16, 0.82, 2.76, 1.98, 3.08, 2.61, 4.26, 1.31, 1.93, 2.39, 2.48, 2.15, -0.45, 1.98, 0.74, -0.18, -0.13, -0.34, -1.07, -0.46, 1.14, -1.72, -1.12, -0.68, -0.59, -0.92, -0.41, -0.62, 1.6, -1.27, -0.66, -0.22, -0.13, -0.47, -0.05, -0.21, -0.2, -0.87, 5.531102040816326, -0.42, -0.62, 0.46, -0.44, -0.22, -0.39, 0.81, -1.43, 0.35, 0.22, 2.23, -0.04, -0.63, 0.73, 0.42, -0.17, 0.74, -0.35, -2.37, 1.18, -3.16, 1.52, 2.2342857142857144, 3.275714285714286, 1.45, -2.18, -2.82, -2.23, -1.79, -1.7, -2.03, -0.46, 0.66, 0.61, 1.06, 1.15, 0.81, 0.05, 0.45, 0.7728571428571429, 0.2, -0.08, -0.38, -0.4, 0.09, -0.25, -0.19, -0.34, 0.33, 0.9157142857142857, -0.31, -0.67, -0.09, -0.38, -0.49, -0.34, -0.64, -0.31, 0.06, 0.06095238095238095, 0.54, -0.15, -0.35, -0.77, -0.49], ['281', 0.68, -0.07, 0.17122171562045874, 0.15, 0.3, -0.08, -1.72, -1.64, -1.14, -1.8, -1.13, -0.37, -0.53, -0.92, 0.22, -1.27, -1.01, -1.48, -3.54, -1.53, -2.1, -2.2, -0.98, -1.51, -1.61, -1.09, -0.67, 0.77, 0.61, 0.22, 1.37, -0.14, 0.12, -0.35, -2.43, -0.4, -0.98, -1.08, 0.2588796134390452, -0.3461582768021609, -1.3525315746467892, -1.89, -1.43, -0.15, -0.55, 0.6, -0.9, -0.64, -1.11, -3.18, -1.16, -1.73, -1.83, -0.61, -1.15, -0.5099371536943235, -0.3957142857142858, -1.91, -1.22, -1.28, -0.39, 0.75, -0.75, -0.49, -0.95, -3.03, -1.0, -1.58, -1.68, -0.45, -0.99, -2.55, -0.89, 1.15, -0.36, 0.04948941254823622, -0.56, -2.65, -0.61, -1.19, -1.29, -0.06, -0.6, -1.1, -1.82, 1.8, -2.02, -1.49, -1.23, -1.69, -3.75, -1.74, -2.32, -2.42, -1.2, -1.6759922724755494, -1.84, -0.54, 0.26, -0.21, -2.3, -0.26, -0.84, -0.94, 0.3, -0.25, -0.23, -0.65, 1.7, -0.4, -0.42, -0.43, -0.8, -0.47, -2.55, -0.52, -1.1, -1.2, 0.03, -0.51, 0.45, -0.33, -2.1, -0.05, -0.63, -0.73, 0.51, 0.2021774376417234, -1.01, -0.74, 0.29, -0.46, -5.7, 0.05, 0.14, 1.91, -1.91, -0.95, 0.14, -0.4938364678879505, 0.4, 0.75, 0.46, 0.46, 0.11, -1.28, 1.45, 1.22, -0.42, 2.9, -0.87, -1.27, 0.67, -2.36, 0.76, 1.62, 2.39, -0.5661904761904761, 1.8, 2.09, 1.49, 1.39, 2.66, 2.1, -1.28, -0.2798412698412699, -0.58, -0.68, 0.9794625850340136, 0.01, 0.3, -0.1, 1.14, 0.6, -1.19, -1.07, 0.41, 1.25, 0.7, -0.42, -0.51, -1.63, 0.5, 1.19, -0.63, -0.82, -0.55, -0.83, -0.54, -0.23, -0.92, 0.06, 0.11, 0.27, -0.29, -1.65, -1.4, -1.25], ['282', -4.332857142857143, 0.31, 0.09015289830927053, -0.1, 0.05, 0.29, -0.47, -1.27, -0.5, -0.9229115646258504, -1.42, -0.49, -0.61, -0.59, 0.49, -0.94, -1.23, -1.17, -5.26, -0.92, -1.46, -0.64, -1.03, -1.6, -1.59, -0.58, 0.05, 0.94, 0.82, 0.85, 1.94, 0.49, 0.19, 0.25, -3.9, 0.5, -0.04, 0.79, 0.4, -0.18, -1.16, -0.34, -0.88, -0.12, -0.1, 0.99, -0.42895634920634923, -0.7371428571428571, -0.68, -4.79, -0.43, -0.941934531913557, -0.15, -0.5242857142857144, -1.11, -1.56, -1.55, -1.86, -0.36, -0.76, 0.03, 1.12, -0.32, -0.62, -0.56, -4.68, -0.31, -0.85, -0.03, -0.42, -0.99, -3.35, -0.79, 1.09, -0.35, -0.65, -0.59, -4.7, -0.34, -0.88, -0.05, -0.44, -1.02, -0.27, -0.83, 0.95, -1.86, -1.42, -1.72, -1.66, -5.73, -1.41, -1.95, -1.13, -1.52, -2.08, -0.18, -0.44, -0.3, -0.24, -4.37, 0.01, -0.53, 0.3, -0.09, -0.67, -0.27, -0.45, 0.18, 0.05, 0.09, -0.08, -0.14, 0.06, -4.08, 0.31, -0.23, 0.6, 0.21, -0.37, -0.67, -0.2, -4.14, 0.25, -0.29, 0.54, 0.14, -0.43, 0.07, 0.22, 0.04, -0.21, -1.4022619047619047, 0.16, -0.24, 1.03, -1.04, -0.53, 0.07, -0.66, 0.94, -0.12, -0.07, -2.0707142857142857, 0.41, 0.01, 0.0, -0.13, 0.04, 1.53, 0.08, 0.64, -0.32, -0.36, 5.63, 0.21, 0.44, -1.02, 4.1, 4.58, 4.01, 4.88, 4.47, 3.87, 0.1, -0.45, -0.54, 0.29, -0.11, -0.68, 0.09, 0.83, 0.44857142857142857, -0.14, -0.49, -0.1, -0.74, -0.39, -0.97, -0.02, -0.02, -1.34, 2.84, 0.28, -2.89, -0.56, 0.12, -0.35, -0.4972131485030683, 0.4, -0.42, 0.5, 0.25, 0.3, 0.23, -1.76, -0.41, -0.08], ['283', -9.94, -0.26, 0.13, 0.29, -0.96, -0.89, -0.8058847420401708, -1.3382794034640413, -1.46, -1.32, 1.09, -0.21, -0.45, 1.03, 0.39, 0.72, -0.24, 0.09, -0.62, 0.45, -2.202664517912641, -0.54, -0.41, -0.46, -2.53, -1.33, -2.38, -1.28, -1.52, -0.05, -0.69, -0.36, -1.31, -0.98, -1.69, -0.63, -3.29, -1.61, -1.48, -1.53, -0.4, -1.81, -1.11, -0.24, 1.25, 0.6708150295752765, 0.94, -0.03, 0.3, -0.41, 0.66, -2.011934531913557, -0.33, -0.2, -0.25, -0.08, -1.1, -1.86, -1.24, -0.88, 1.49, 0.84, 1.18, 0.21, 0.54, -0.17, 0.91, -1.8, -0.09, 0.04, -0.01, -0.94, -2.33, -0.64, -0.31, -1.26, -0.93, -1.64, -0.58, -3.24, -1.56, -1.43, -1.47, -1.87, -2.64, 2.69, -1.71, 0.33, -0.63, -0.3, -1.01, 0.061674603174603174, -2.62, -0.93, -0.8, -0.84, -3.18, -2.03, -0.96, -0.63, -1.33, -0.27, -2.94, -1.25, -1.13, -1.17, -0.23, -2.0, -1.19, -0.9, -0.94, -0.94, -1.0081905235138708, 0.33, -0.38, 0.7, -2.0, -0.3, -0.17, -0.22, -0.79, -1.41, -0.71, 0.36, -2.33, -0.63, -0.5, -0.55, -1.05, -1.05, 0.28, -1.09, -9.82, -0.09, -0.12, 1.62, -1.61, -0.82, -1.92, -1.82, 3.37, 1.78, 0.9, -5.06, -0.4069202101312209, -2.83, 2.82, 2.71, -0.93, 2.43, -1.89, -3.37, 1.64, -3.17, 5.88, 2.07, 3.01, -3.42, -0.71, 1.08, -1.63, 0.08, 0.21, 0.16, -2.59, -1.77, -2.68, -0.99, -0.86, -0.91, 0.94, 1.8288785911064216, 1.87, 1.83, -1.51, -1.36, -0.79, 0.13, 0.08, -0.92, -0.8856036987247091, -1.46, 3.05, -1.29, -2.8085714285714287, -1.98, -1.63, -0.92, -0.05, -1.12, -0.67, -0.34, -0.26, -0.95, -0.87, -3.12, -2.04, -0.62], ['284', -2.1, 0.13, -0.23877828437954127, -0.01, 0.96, 0.32, 0.26, -0.37, 0.31, -1.98, -2.55, -2.09, -3.56, -1.14, -1.05, -2.06, -1.35, -2.24, -3.64, -3.6, -1.76, -1.43, -1.45, -1.8648833725798009, 1.06, 0.93, 0.6126583949931124, 0.47, -1.04, 1.45, 1.54, 0.5, 1.23, 0.4272589041444084, -1.12, -1.08, 0.81, 1.15, 1.12, 0.56, -0.5145146341753485, -0.17, 0.11, -1.51, 0.97, 1.06, 0.03, 0.75, -0.16, -1.59, -1.55, 0.33965472923706097, 0.67, 0.65, 0.08, -0.6, 0.04, -0.42, 0.51, 1.64, 2.52, 2.61, 1.56, 2.3, 1.37, -0.08, -0.04, 1.87, 2.22, 2.19, 1.62, 2.25, -0.85, 0.09, -0.93, -0.21, -1.12, -2.53, -2.49, -0.63, -0.29, -0.32, -0.88, 0.22, -1.79, 1.88, -0.94, -1.02, -0.3, -1.2, -2.62, -2.58, -0.72, -0.38, -0.41, -0.97, 0.32, 0.08, 0.73, -0.18, -1.61, -1.57, 0.31, 0.65, 0.62, 0.06, 0.35, 0.07, 1.12, 0.21159818068290148, 0.22, 0.09567351865003196, -0.64, -0.9, -2.3198412698412696, -2.28, -0.41, -0.08, -0.1, -0.66, -0.59, 0.27, -1.43, -1.39, 0.49, 0.83, 0.81, 0.24, -0.75, -0.59, -0.07, -0.13, 0.75, -0.39, -0.43, 1.56, -1.59, -0.8, -0.24, 0.09, -3.16, -0.32, -0.14, -1.06, 0.58, 0.4514761904761905, -0.48, -0.55, 0.18, 2.4, 0.36, -0.11, 0.01, -1.83, -1.89, 1.31, 1.82, 3.32, 1.73, 0.04, 1.95, 2.3, 2.27, 1.7, 0.42, 1.68, 1.91, 2.26, 2.23, 1.66, -0.22, 0.34, 0.31, -0.25, 0.26, 0.31, -0.56, -0.02, -0.59, 0.18, 0.16, -0.36, -0.92, 0.58, 1.17, 0.12, 1.52, -0.46136255179902913, -0.56, 0.0, -0.68, 1.07, 0.89, 0.28, 0.03, -0.12, 1.07, -0.89], ['285', -9.07, 1.5, 0.29, 0.3, -0.43, 0.93, -0.59, 1.34, 0.33, -1.4558571428571427, -2.08, -1.09, -3.08, -3.11, -3.23, 2.2, -2.0, -1.81, -2.06, -1.22, -1.93, -2.75, -2.58, -2.55, 1.04, 0.49, 0.6726583949931124, 1.01, -1.02, -1.05, -1.17, 4.38, 0.09, 0.28, 0.03, 0.88, 0.15, -0.68, -0.5, -0.43615827680216085, 1.41, 0.5149361992161734, -0.37, -2.01, -2.04, -2.16, 3.33, -0.91, -0.72, -0.97, -0.13, -0.85, -1.68, -1.5, -1.48, 1.17, 0.27, 0.7878279728097839, 0.11, 1.68, -0.03, -0.15, 5.45, 1.12, 1.31, 1.06, 1.92, 1.18, 0.34, 0.52, 0.54, -0.29, 1.71, -0.12, 5.49, 1.15, 1.35, 1.09, 1.95, 1.22, 0.37, 0.56, 0.58, 0.94, 3.4, -3.47, 1.83, 5.61, 1.27, 1.47, 1.21, 2.07, 1.3638701615844473, 0.49, 0.6785238095238095, 0.7, -4.53, -3.58, -4.11, -3.92, -4.17, -3.35, -4.05, -4.85, -4.68, -4.65, 0.73, -3.55, 0.27, 0.42, 0.9151790696343399, 1.065673518650032, 0.6218094764861293, 0.2, -0.06, 0.79, 0.07, -0.77, -0.59, -0.5114153161169342, 0.37, 0.36, -0.25, 0.6, -0.13, -0.96, -0.78, -0.76, 0.81, 0.74, 0.88, 0.913186783623568, -13.35, 1.27, 1.07, -1.76, 1.7, 0.888810171007621, -2.68, 0.16, 0.35, -1.82, -0.94, -4.46, 1.12, 2.76, -2.67, -2.76, 0.973290804863853, -2.59, 1.76, -1.59, 0.75, 1.55, -4.18, -1.07, -1.62, -0.31, 0.61, 0.85, 0.13660997732426305, -0.71, -0.53, -0.51, 2.68, -0.24, -0.72, -1.55, -1.37, -1.35, 0.49, -0.83, -0.66, -0.63, 0.34, 0.57, 1.33, 0.18, 0.2, 0.94, 0.91, 1.67, -1.99, 0.73, 2.03, 0.36, 0.5, 1.15, 0.02, 0.99, 0.48, 1.02, 1.23, 1.46, 1.13, -1.95, 0.26, 0.54], ['286', -0.64, 0.55, 0.16, -0.04, -0.04, -0.54, -1.4499638336347196, -0.9182794034640412, -0.57, -1.07, -0.55, -0.21, -1.15, -0.06, -0.16, -0.45, -0.51, -1.1, -0.8, -1.13, -0.8, -1.19, -0.46, -0.46, -0.61, -0.42, -0.49734160500688757, 0.34, -0.6, 0.49, 0.39, 0.1, 0.04, -0.55, -0.26, -0.58, -0.25, -0.64, 0.09, 0.09, -0.05, -1.04, -0.86, -0.94, 0.15, 0.12081502957527657, -0.24, -0.3, -0.89, -0.59, -0.92, -0.59, -0.8861344435209981, -0.25, -0.25, -0.37, -0.94, -1.68, -0.33, 0.08, 1.1, 1.000799319727891, 0.71, 0.64, 0.05, 0.35, 0.02, 0.35, -0.04, 0.7, 0.7, -0.91, -1.01, -0.1, -0.39, -0.45, -1.04, -0.75, -1.07, -0.74, -1.13, -0.4, -0.4, -0.57, -1.44, 1.49, -0.91, -0.29, -0.35, -0.94, -0.64, -0.97, -0.64, -1.03, -0.3, -0.3, -1.32, -0.63, -0.06, -0.65, -0.36, -0.68, -0.35, -0.74, -0.01, -0.01, -0.05, -0.62, 0.01, -0.5184018193170985, -0.69, -0.33432648134996806, -0.56, -0.59, -0.29, -0.6194642857142857, -0.29, -0.68, 0.05, 0.05, 0.03, 0.03, 0.3, -0.03, 0.3, -0.09, 0.65, 0.65, -0.76, -0.92, 0.12, -0.43, -4.12, -0.15, 0.07, 0.6, -0.63, -0.2811898289923789, -0.33, -1.49, -0.28, 1.07, 0.54, -0.34, -0.66, -1.68, 1.61, 1.61, -0.4867091951361471, 0.98, -1.1, -0.36, 0.17, -1.67, 1.99, 1.15, 1.58, 0.23, -0.27, -0.33, 0.0, -0.39, 0.35, 0.35, -1.67, 0.06, 0.33353741496598643, -0.06, 0.68, 0.68, -0.27, -0.39, 0.34, 0.35, -0.52, -0.3415464535464533, 0.12, 0.74, 0.74, -0.54, -0.5, -0.99, 0.94, -1.09, -0.85, -0.4, -1.07, -0.62, 0.0, -0.59, -0.41, -0.86, -1.17, 0.12, -0.62, 0.04, -0.84, -1.27], ['287', -8.23, -0.97, -0.4998471016907295, 0.07, -1.54, -2.78, -1.89, -4.0, -2.98, -4.92, -1.64, -2.74, -1.14, -1.75, -1.1157142857142859, -1.85, -1.2885714285714285, -3.82, -6.35, -2.5574455782312926, -5.17, -1.87, -2.06, -2.63, -3.82, -2.97, -3.33, -1.1194545454545455, 0.5146428571428572, -0.12, 0.52, -0.22, -0.3, -2.22, -4.8, -1.27, -3.59, -0.24, -0.43, -1.01, -3.23, -3.79, -2.24, 1.64, 1.01, 1.66, 0.92, 0.83, -1.11, -3.72, -0.15, -2.5, 0.89, 0.7, 0.11, -2.93, -2.7457142857142856, -4.49, -3.44, -3.82, -0.62, 0.02, -0.72, -0.8, -2.71, -5.28, -1.77, -4.08, -0.74, -0.93, -1.5, -4.44, -3.22, 0.64, -0.1, -0.18, -2.1, -4.68, -1.15, -3.48, -0.12, -0.31, -0.89, -3.28, -8.36, 8.4, -3.84, -0.73, -0.82, -2.72, -5.29, -1.78, -4.09, -0.6742857142857143, -0.94, -1.52, -3.22, -3.13, -0.09, -2.007880952380952, -4.59, -1.06, -3.38, -0.02, -0.21, -0.79, -1.2, -3.16, -2.28, -2.52, -2.51, -2.45, -3.04, -1.92, -4.51, -0.97, -3.3, 0.06, -0.13, -0.71, -2.96, -1.14, -2.64, 0.97, -1.41, 2.02, 1.83, 1.24, -3.45, -3.75, -0.38, -2.78, -6.32, -1.1796768707482992, -0.7942857142857144, 5.09, -5.1, -2.56, -1.88, -6.04, 4.24, 5.06, 2.9582806122448977, -4.14, -1.62, -7.5, 7.44, 7.55, -2.5, 7.64, -5.05, -2.14, 1.1, -9.07, 8.073125850340135, 6.07, 9.16, -4.18, 1.54, 3.7048095238095238, 1.27, 4.79, 4.59, 3.98, -7.5, -2.09, -2.35, 1.05, 0.86, 0.27, 0.7165017006802721, 3.48, 3.28, 3.331428571428572, -2.95, -3.32, -3.1, -0.19, -0.77, -2.46, -2.51, -3.93, 3.99, -3.19, -4.06, -2.66, -3.05, -2.92, -0.58, -3.07, -2.42, -1.79, -1.7, -2.13, -2.35, -4.94, -4.24, -2.12], ['288', -2.41, -0.01, -0.01, -0.05, -0.65, -0.07, 1.26, -0.99, 0.2, -1.01, -1.64, -1.11, -0.77, 0.51, 0.42, -0.25, -0.7, -1.11, -4.77, -0.37, -0.62, -0.73, -0.37, -0.92, -0.98, -0.21, 0.64, 0.54, 0.89, 2.19, 2.09, 1.42, 0.95, 0.54, -3.18, 1.29, 1.04, 0.93, 1.29, 0.7738417231978392, -0.82, 0.6449361992161734, 0.1, 0.35, 1.64, 1.6108150295752766, 0.87, 0.41, 0.0, -3.71, 0.75, 0.49, 0.48386555647900187, 0.75, 0.19, -0.39, -0.72, -0.88, -0.05, -0.17075475293412243, 1.28, 1.19, 0.52, 0.06, -0.35, -4.04, 0.4, 0.15, 0.04, 0.4, -0.16, -0.82, -1.51, -0.09, -0.75, -1.2, -1.61, -5.01252355184498, -0.87, -1.12, -1.23, -0.7369045181009466, -1.3764403582748792, 0.77, -1.64, 1.68, -1.42, -0.66, -1.12, -1.52, -5.17, -0.78, -1.03, -1.14, -0.78, -1.34, -0.09, -0.77, -0.46, -0.87, -4.54, -0.12, -0.3173734626473065, -0.48, -0.13, -0.68, 0.09, -0.83, -0.29427628811696, -0.2, -0.3, -0.09, -0.31, -0.41, -4.1, 0.34, 0.08, -0.03, 0.33, -0.22, -0.23, 0.11, -3.7, 0.75, 0.5, 0.5157995496566927, 0.75, 0.19, -1.22, -1.33, 0.08, -0.29, -0.39, 0.14, 0.07, -0.04, 0.0, -0.01, 0.07, -0.83, 1.27, 0.41, 0.21, -1.16, -0.21, -0.66, 0.59, 0.64, -0.15670919513614703, 0.03, -0.44, -0.85, 0.45, -0.88, -0.17, 0.6, 0.92, -1.3, 3.95, 4.63, 4.36, 4.25, 4.62, 4.04, -0.6391948051948052, -0.64, -0.26, -0.36, 0.0, -0.56, -0.39, -0.11, 0.25, -0.3, 0.18, 0.35, -0.28, 0.36, -0.2, -0.22, -0.2, -0.9, 0.3, -0.25, -0.31, -0.3781051005851445, -0.16, -0.64, -0.56, -0.48, 0.05, 0.17, -0.19, -0.26, -0.09, -1.61, -0.2, -0.14698322629260274], ['289', 0.91, -0.53, -0.12, 0.08, -0.01, 0.57, -1.0299638336347197, -0.5482794034640412, -0.05062194561298938, -0.93, -1.03, -0.11, -1.05, -1.1, -0.41, -0.71, -0.84, -0.91, -0.43, 0.1, -0.95, -0.96, -0.93, -0.87, -0.04, -0.82, 0.1, 0.93, -0.02, -0.08, 0.6878199712950912, 0.33, 0.19, 0.12, 0.6, 1.14, 0.08, 0.07, 0.1, 0.16, -0.15, -1.11, -0.82, -0.94, -0.99, -0.29, -0.59, -0.73, -0.79, -0.32, 0.21, -0.84, -0.84, -0.82, -0.76, -0.2, 0.0, -0.52, 0.16, 0.12, -0.05, 0.65, 0.35, 0.21, 0.15, 0.63, 1.16, 0.1, 0.1, 0.12, 0.18, -1.33, 0.18, 0.71, 0.4, 0.27, 0.2, 0.68, 1.22, 0.15, 0.15, 0.18, 0.24, -0.41, -0.12, 0.08, -0.53, -0.2119125667872351, -0.43, -0.5, -0.03, 0.51, -0.3847647669790526, -0.55, -0.53, -0.47, -1.85, -0.23, -0.13, -0.2, 0.28, 0.81, -0.25, -0.25, -0.23, -0.17, -0.12, -0.24, 1.3, 0.13, -0.13, 0.40567351865003193, -0.09, -0.07, 0.41, 0.94, -0.12, -0.12, -0.01401213658444736, -0.03, 0.05, -0.02, 0.48, 1.01, -0.05, -0.05, -0.02, 0.04, -0.39, -0.64, 0.19603717887804045, 0.08, -5.17, -0.05, 0.0, -1.23, 1.25, 0.6588101710076211, -0.03, 0.29, 1.88, -0.27, -0.11, 0.48, -0.2, 0.5505968614718616, -0.47, -0.4, 0.14, -1.88, 0.3, 0.22, -0.12, -0.25, -5.18, 0.22, 0.35, -1.9428690476190476, -0.5, 0.53, -0.513390022675737, -0.53, -0.5, -0.44, 0.42, -1.03, -1.05, -1.05, -1.03, -0.97, 0.02, 0.0, 0.02, 0.08, -0.19, 0.04, 0.03, 0.03, 0.09, 0.15, 0.12, -0.71, -1.98, 0.67, 1.94, -0.33, -0.42, 0.0, 0.06, 0.11, 1.15, -0.07, -0.28, -0.12, -0.06, -0.68, -0.76, 0.02], ['290', 5.23, -1.59, -1.08, 0.09, -1.9570209190089405, -2.0315803763262403, -2.55, -2.23, -2.3, -1.2592857142857143, 2.04, 1.42, 0.17, 0.65, 0.77, -5.16, 1.57, 0.2, 1.58, 2.93, -1.11, 1.0, 2.35, 1.81, -1.73, -1.74, -3.23, -0.61, -1.83, -1.36, -1.24, -7.05, -0.46, -1.8, -0.45, 0.88, -3.09, -1.02, 0.31, -0.22, -1.6, -1.3650638007838265, -2.64, -1.23, -0.75, -0.64, -6.48, 0.15, -1.2, 0.16, 1.5, -2.49, -0.41, 0.92, 0.39, -1.66, -2.49, -3.81, -1.96, -1.43, 0.48, 0.6, -5.32, 1.39, 0.13260506614006173, 1.4271802721088434, 2.76, -1.28, 0.83, 2.18, 1.64, -2.09, -1.9, 0.12, -5.77, 0.91, -0.45, 0.92, 2.5891309523809523, -1.75, 0.34, 1.69, 1.15, -2.58, -9.65, 9.62, -1.9833017616146797, -5.88, 0.79, -0.57, 0.8, 2.15, -1.87, 0.23, 1.57, 1.03, 6.74, 4.11, 7.09, 5.65, 7.11, 8.53, 4.27, 6.49, 7.92, 7.35, -1.41, 4.13, -6.78, -2.27, -2.26, -2.46, -2.7790429599640123, -1.35, 0.01, 1.35, -2.64, -0.56, 0.77, 0.24, -2.21, -1.46, 1.38, 2.73, -1.31, 0.8, 2.15, 1.61, -4.571041630036876, -4.24, 0.12, -2.876813216376432, 20.08, -1.0, -0.56, 4.77, -4.81, -2.39, -1.17, -2.47, 8.14, 4.62, 2.31, 2.71, -1.39, -6.94, 6.89, 6.87, -2.27, 7.25, -4.54, -4.08, 1.83, -8.37, 13.81, 5.51, 8.28, -8.11, -2.8, 1.33, -2.65, -0.57, 0.76, 0.23, -6.88, -4.08, -3.93, -1.88, -0.56, -1.09, -0.15, 2.13, 3.5, 2.95, -2.2, -2.25, -2.24, 1.34, 0.8, -2.31, -2.39, -2.06, 7.3, -5.75, -7.19, -1.75, -2.03, -3.4513625517990287, -0.53, -2.54, -2.29, -1.81, -0.31, -1.65, -3.02, 0.66, -4.34, -3.48], ['291', -2.27, 0.11, 0.11122171562045875, 0.1, -1.48, -0.08, -0.17588474204017085, -0.27, -0.04, -1.27, -1.27, -1.05, -1.21, -0.88, -2.22, -0.51, -0.47, -1.44, 0.15, -0.22, -1.13, -1.04, 0.26, -1.19, -0.41, -0.63, 0.03265839499311246, 0.22, 0.07011904761904762, 0.39, -0.96, 0.76, 0.8, -0.18, 1.43, 1.06, 0.14, 0.23, 1.55, 0.08, -0.44, -0.22506380078382657, -0.22, -0.16, 0.16, -1.18, 0.54, 0.58, -0.4, 1.3071355564861205, 0.84, -0.08034527076293904, 0.01, 1.32, -0.15, -0.24, 0.15, -0.62, -0.17, -0.06, 0.33, -1.02, 0.7, 0.74, -0.24, 1.3871802721088435, 1.0, 0.08, 0.17, 1.49, 0.02, -0.85, -0.39, -1.34, 0.37, 0.41, -0.56, 1.04, 0.67, -0.25, -0.16, 1.16, -0.31, -0.03, -3.76, 3.82, 0.97, 1.74, 1.78, 0.79, 2.42, 2.04, 1.1338701615844473, 1.2, 2.54, 1.05, -1.58, -0.76, 0.04, -0.93, 0.66, 0.29, -0.62, -0.53, 0.78, -0.68, 0.22, -0.78, -1.1298229965745161, -0.35, -0.69, -0.05, -0.8, -0.97, 0.62, 0.26, -0.66, -0.57, 0.74, -0.72, -0.28, 0.23307674813036727, 1.61, 1.24, 0.31, 0.41, 1.73, 0.25, -2.76, -2.97, 0.22, -0.78, -4.588897959183674, -0.08, -0.07, -0.14, 0.14, 0.08, -1.11, -0.93, 2.07, 0.71, 0.32, -1.16, -0.25, -1.03, 1.08, 1.03, -0.35, -0.08, -0.71, -1.07, 0.53, -2.45, 0.11, 1.58, 2.37, -2.08, -1.41, -0.37, -1.28, -1.19, 0.12, -1.34, -1.01, -1.05, -0.91, -0.82, 0.49, -0.98, -0.14, 0.09, 1.41, -0.06, 0.12013513867085306, -0.11, -0.23, 1.32, -0.16, -0.35, -0.42, -0.26, 0.77, -1.12, -0.63, -0.57, -0.73, -1.53, -1.45, 0.07, -0.01, 0.11, -0.44, -0.11, -0.08, -2.37, -1.02, -0.61], ['292', 3.82, 0.58, 0.12, 0.3821428571428573, 0.76, 0.33, 1.6, 0.72, 1.28, 0.56, -0.98, -0.05806550195835902, -0.39, -0.15, -0.61, -0.68, 0.66, 0.41, -1.56, -0.47, 1.67, 0.74, -0.47, 0.31, 0.94, 0.84, 1.55, 0.72, 0.6, 0.83, 0.37, 0.3, 1.65, 1.4, -0.59, 0.51, 2.67, 1.73, 0.51, 1.3, 0.55, 2.75, 0.82, -0.13, 0.11, -0.35, -0.42, 0.92, 0.67, -1.3, -0.21, 1.93, 1.0938655564790019, 0.4214285714285715, 0.57, 0.59, 1.02, 1.78, 1.160952380952381, 0.95, 0.24, -0.22, -0.29, 1.05, 0.8, -1.17, -0.08, 2.06, 1.13, -0.08, 0.7, 1.12, 0.71, -0.46, -0.53, 0.81, 0.56, -1.41, -0.32, 1.82, 0.89, -0.32, 0.46, 1.77, 2.35, -2.29, 1.17, -0.0694795918367347, 1.27, 1.02, -0.96, 0.14, 2.29, 1.35, 0.14, 0.92, 2.23, 1.25, 1.35, 1.1, -0.88, 0.21, 2.36, 1.43, 0.21, 1.0, 0.12, 1.3, -0.81, 0.41, 0.59, 0.12, -0.1, -0.25, -2.2, -1.12, 1.0, 0.14030501944728757, -1.12, -0.35, -0.09, 0.15, -1.96, -0.88, 1.25, 0.33, -0.88, -0.1, 0.8689583699631245, 0.45, -0.02, -0.06, 6.59, 0.1, 0.11, -0.21, 0.24, 0.1, 0.28, 0.5, -2.04, -0.8, -0.42, 1.86, 0.35, 1.23, -1.28, -1.26, 0.4, -0.4, 0.81, 0.53, -0.3, -0.25, -2.04, 0.13, 0.25, 2.09, 2.15, 1.1, 3.27, 2.33, 1.1, 1.9, 1.22, 1.0301587301587303, 2.15, 1.21, 0.0, 0.78, -1.09, -0.91, -2.1, -1.33, 1.24, 1.51, -0.18, -1.2, -0.42, 0.42, 0.33, 0.65, -1.58, -0.43, 1.57, 0.15, 0.7810935020800125, 1.03, 0.78, 0.15, 0.03, 0.37, 0.14, 0.68, 0.335957527023814, -0.26, 1.3830376647162361, -0.29], ['293', 5.93, 0.75, 0.05, -0.18, 1.9, 0.59, 1.36, 0.96, 1.68, 0.34, -1.48, -1.12, -1.53, -0.34, 0.72, -0.32, 0.017142857142857144, -0.16, 1.35, -2.32, 0.9, -0.57, -1.24, -0.39, 1.71, 2.22, 1.85, 0.37, -0.05, 1.16, 2.23, 1.18, 1.4914285714285713, 1.34, 2.87, -0.85, 2.42, 0.93, 0.24, 1.11, 0.6374684253532109, 2.1449361992161733, 1.47, -0.42, 0.79, 1.86, 0.81, 1.11, 0.96, 2.5, -1.21, 2.068065468086443, 0.56, -0.13, 0.74, 0.13, 1.16, 1.12, 1.56, 1.9, 1.21, 2.28, 1.23, 1.54, 1.39, 2.93, -0.8, 2.6334211542425834, 0.98, 0.4553389784818358, 1.16, 1.07, 0.68, 1.06, 0.02, 0.32, 0.17, 1.69, -1.99, 1.25, -0.23, -0.91, -0.05, 1.98, 4.42, -4.46, -0.38, -1.02, -0.73, -0.88, 0.63, -3.01, 0.19, -1.27, -1.95, -1.1, 3.06, 0.66, 0.3, 0.15, 1.67, -2.01, 1.22, -0.25, -0.93, -0.07, 0.86, 0.68, -1.63, 0.79, 0.94, 0.7, 0.35, -0.15, 1.37, -2.3, 0.92, -0.55, -1.23, -0.37, 0.97, 0.5, 1.52, -2.15, 1.07, -0.4, -1.08, -0.22, 1.76, 0.48, -0.3, 0.943186783623568, 6.05, 0.18, -0.06, -0.84, 0.81, 0.43, 0.96, 0.71, -5.31, -1.53, -0.81, 2.94, 0.41, 2.43, -2.47, -2.37, 0.78, -1.23, 1.57, 0.88, -0.44, 1.07, -9.29, -0.75, -1.14, 5.293809523809524, -1.0, -3.62, -0.44, -1.89, -2.56, -1.72, 2.37, 2.7201587301587304, 3.3, 1.79, 1.1, 1.97, -0.56, -1.46, -2.13, -1.28, 1.74, 1.88, 0.91, -0.68, 0.18, 0.81, 0.76, 0.9225760496238784, -4.66, -0.61, 4.6, 1.75, 1.47, 1.6, 0.86, 0.58, 0.36, 0.54, 0.39, 0.06, 0.73, 2.46, 2.92, 0.3730167737073973], ['294', 3.64, 0.18, 0.4012217156204588, 0.05, 0.8129790809910595, 0.46, 1.2441152579598291, 0.93, 0.94, 3.73, 3.08, 2.558992063492063, 3.1, 2.4, 3.45, 3.21, 2.6599999999999997, 3.37, 7.7, 1.9966428571428572, 3.9, 3.33, 3.17, 3.36, 0.77, 0.64, 0.63, -0.52, 0.02, -0.66, 0.36, 0.13, -0.43, 0.28, 4.48, -1.06, 0.79, 0.24, 0.09, 0.27, 0.26, 2.08, 1.16, 0.54, -0.14, 0.88, 0.65, 0.09, 0.81, 5.03, -0.55, 1.32, 0.76, 0.61, 0.8, 0.14, 1.13, 1.43, 0.97, 0.61, -0.68, 0.34, 0.11, -0.45, 0.27, 4.46, -1.08, 0.77, 0.22, 0.2353389784818358, 0.25, 0.88, 1.3, 1.03, 0.79, 0.23, 0.95, 5.17, -0.4, 1.46, 0.9, 0.76, 0.94, 1.08, 1.55, -1.5, 0.27, -0.23, -0.79, -0.08, 4.11, -1.42, 0.43, -0.12, -0.27, -0.09, 0.19, 0.5, -0.56, 0.16, 4.35, -1.19, 0.67, 0.11, -0.04, 0.15, 0.43, 0.51, 0.15, 0.58, 0.49, 0.61, 1.07, 0.72, 4.94, -0.63, 1.23, 0.68, 0.53, 0.71, 0.39, 0.35, 4.18, -1.34, 0.51, -0.05, -0.18428571428571427, -0.01, 0.47, 0.55, 0.05, 0.59, 0.47, 0.1, 0.02, -1.44, 1.41, 0.72, 0.53, 0.5561635321120495, -3.3, -1.14, -0.6, 1.84, 0.4, 1.63, -1.74, -1.76, 0.57, -2.1, 1.14, -0.22, 0.12, 3.21, -3.08, -2.12, -3.24, 3.25, -3.68, -5.3, -3.53, -4.06, -4.2, -4.03, 1.71, 1.71, 1.87, 1.31, 1.16, 1.35, -0.16, -0.55, -0.7, -0.52, 0.98, 1.01, 0.39, -0.15, 0.03, 0.52, 0.61, 0.94, -1.26, -0.1, 1.24, 0.91, 0.31, 0.54, 0.18, 0.61, 0.65, 0.59, 0.58, 0.8, 0.36, 0.81, 0.81, -0.58], ['295', -0.38, -0.23, 0.011221715620458745, -0.12, -1.09, 0.29, 1.78, -0.02, -0.17, -0.77, -0.2, -1.45, -0.19, -0.58, 0.38, -0.34, -1.09, -0.64, 0.07, 1.01, -1.12, -0.87, -1.16, -1.2, 0.0, 0.18, -0.5373416050068875, -1.25, 0.01, -0.39, 0.58, -0.14, -0.9, -0.45, 0.27, 1.21, -0.92, -0.67, -0.96, -1.0, -0.29, -1.77, 0.7, 1.28, 0.88, 1.86, 1.13, 0.3992789115646258, 0.82, 1.54, 2.490714285714286, 0.34, 0.59, 0.39714285714285713, 0.26, 0.0, 0.07, 0.0, -0.61, -0.57, -0.39, 0.57, -0.14, -0.9, -0.45, 0.26, 1.2, -0.93, -0.68, -0.97, -1.01, 0.06, -0.18, 0.97, 0.25, -0.51, -0.06, 0.66, 1.6, -0.54, -0.28, -0.58, -0.62, -0.61, 1.01, -1.05, -1.14, -0.71, -1.47, -1.02, -0.31, 0.62, -1.49, -1.24, -1.53, -1.57, -0.62, -0.43, -0.76, -0.31, 0.41, 1.35, -0.79, -0.53, -0.83, -0.87, -0.28, -0.46, 0.62, 0.31, 0.25, 0.22, 0.33, 0.5865993906886765, 1.18, 2.12, -0.03, 0.23, -0.07, -0.051415316116934326, 0.0, -0.12, 0.72, 1.66, -0.48, -0.22, -0.52, -0.56, 0.04, 0.1, -0.013962821121959568, -0.45, -2.36, -0.22, -0.13, -0.65, 0.71, 0.34, -0.2859337265331848, -0.28, 3.32, -0.61, -0.28, -0.15, 0.26307978986877906, 0.63, -0.87, -0.94, 0.3, -1.1, 0.63, -1.01, 0.26, 0.92, 3.46, -0.51, -0.94, -3.28, -0.5096213151927438, 0.94, -1.19, -0.93, -1.23, -1.27, 0.91, -1.75, -2.1, -1.85, -2.14, -2.18, 0.36, 0.26, -0.04, -0.08, -0.18, -0.45, 0.1, -0.3, -0.34, 0.29, 0.23, 0.02, 1.63, 0.39, -1.84, 0.08, -0.34, 0.4, -0.04, -0.22, 0.19, 0.31, 0.05, 0.6, 0.44, -2.29, -0.36, 0.03], ['296', -1.04, -1.24, 0.03, -0.01, -0.26, 0.5, 0.21, 0.84, 0.2, 0.95, 0.18, 0.61, -0.16, -0.7, -0.31, 2.3, 0.41, 0.87, 3.32, 1.4, 1.04, 0.42, 0.19, 0.3, -1.08, 0.49937141458889195, 0.77, 0.43, -0.34, -0.87, -0.49, 2.12, 0.24, 0.69, 3.14, 1.22, 0.86, 0.24, 0.01, 0.17384172319783917, 0.92, 1.1549361992161733, 0.34, -0.76, -1.3, -0.91, 1.68, -0.19, 0.26, 2.7, 0.78, 0.458065468086443, -0.18, -0.42, -0.3, 0.96, 0.21, 0.32, 0.1, 1.11, -0.54, -0.15, 2.46, 0.58, 1.03, 3.49, 1.56, 1.2, 0.58, 0.35, 0.46, 0.46, 1.66, 0.39, 3.02, 1.1816609275411798, 1.58, 4.05, 2.11, 1.75, 1.13, 0.89, 1.01, 0.51, 2.3, -2.31, 1.3066982383853203, 2.62, 0.73, 1.18, 3.65, 1.71, 1.36, 0.74, 0.5, 0.62, -2.96, -1.31, -1.84, -1.4, 1.0, -0.88, -1.23, -1.83, -2.06, -1.95, -0.04, -1.1606317967746538, 0.0, 0.5315981806829014, 0.69517906963434, 0.39, 0.53, 0.45, 2.9, 0.98, 0.62, 0.01, -0.22, -0.11, 0.49, 0.08, 2.44, 0.53, 0.17, -0.44, -0.67, -0.56, 1.15, 1.17, -0.06, 0.69, -8.78, 0.19, 0.0, -0.13, 0.09246232339089482, 0.04, 0.49, 1.69, 0.76, -0.98, -0.47, -0.45, 0.68, 1.52, -1.55, -1.49, 0.48, -0.21, 0.99, 0.8, -0.32523473571575323, 1.63, -3.4, -1.11, -1.62, -0.89, -2.3, -1.87, -2.21, -2.81, -3.03, -2.92, 1.48, -0.44, -0.35, -0.96, -1.19, -1.08, -0.09, -0.61, -0.84, -0.73, 0.21, 0.5184535464535467, 0.53, -0.23, -0.047751244684983665, 0.51, 0.51, 0.98, -1.36, 0.05, 1.27, 0.83, 0.8, 0.7604317111459968, 0.11, 0.87, -0.03, 0.64, 0.79, 0.14, 0.65, -0.72, 1.23, 0.52], ['297', 0.29, 0.17, 0.04, 0.04, 0.97, -0.1, 1.0641152579598292, 0.59, 0.97, 0.49, -0.82, -0.51, 1.63, -0.38, -0.45, -0.4, 0.25, 0.32, 1.23, -1.63, 0.58, 0.25, -0.06, 0.52, 1.49, 1.19, 1.31, 0.3, 2.46, 0.44, 0.37, 0.4233503401360544, 1.07, 1.14, 2.07, -0.82, 1.4, 1.07, 0.8688796134390452, 1.35, 0.55, 0.27, 1.01, 2.1536589811608606, 0.13, 0.13081502957527658, 0.1264030612244898, 0.77, 0.83, 1.8571355564861205, -1.12, 1.128065468086443, 0.76, 0.46, 1.04, 0.39, 0.65, 0.37, 0.49, -1.12, -1.98, -2.04, -1.99, -1.36, -1.29, -0.39, -3.2, -1.03, -1.36, -1.65, -1.08, 0.76, 0.87, -0.07, -0.02, 0.63, 0.7, 1.62, -1.25, 0.96, 0.63, 0.33, 0.91, 1.09, 1.62, -1.66, 0.94, 0.05, 0.7, 0.77, 1.69, -1.18, 1.03, 0.7, 0.4, 0.98, 4.66, 0.89, 0.65, 0.72, 1.64, -1.23, 0.98, 0.65, 0.35, 0.93, 0.17, 0.95, 0.47, 0.1, 0.2751790696343399, -0.04, 0.24, 0.07, 1.0869325674325676, -1.87, 0.33, 0.0, -0.3, 0.28, 0.24, 0.17, 0.91, -1.94, 0.26, -0.07, -0.37, 0.21, 0.73, 0.39, 0.1, 0.23, 14.207619047619048, 0.01, 0.0, 0.0, -0.02, 0.0, 0.12, 2.7361635321120494, -4.22, -0.21, -0.13, 0.18, 0.09, 0.26, -0.42, -0.34, 0.1, 0.06, 0.19, -0.48, 0.3147652642842468, 0.78, -2.11, -0.59, -0.78, 4.23, -0.74, -2.83, -0.65, -0.98, -1.27, -0.7, 0.3, 2.15, 2.24, 1.9, 1.6, 2.19, -0.09, -0.33, -0.63, -0.05, 0.89, 0.86, 0.24, -0.3, 0.28, 0.11, 0.16, 0.63, -0.63, 0.54, 0.61, 1.27, 1.44, 0.54, 0.58, 0.98, 0.11455285983857427, -1.05, 0.63, -1.26, -0.04, 3.08, 2.4330376647162364, 0.25], ['298', 1.37, -0.28, 0.0, -0.17, -0.4, -0.41, -0.6658847420401709, 0.02, -0.38, 1.05, 0.81, 1.42, 1.34, 0.43, 1.5, 0.42, 1.59, 1.17, 1.6, 1.6, 1.21, 1.53, 1.61, 1.44, -1.04, 0.08, 0.23, 0.6, 0.53, -0.38, 0.68, -0.39, 0.77, 0.36, 0.78, 0.78, 0.39, 0.71, 0.79, 0.63, 0.22, -2.0150638007838264, -0.37, -0.08, -0.98, 0.08, -0.99, 0.17, -0.24, 0.18, 0.17, -0.21, 0.11, 0.19, 0.02, -0.07, -0.07, -0.52, -0.28, -0.29, -0.9, 0.16, -0.91, 0.24, -0.17, 0.25, 0.25, -0.14, 0.18, 0.26, 0.1, -0.73, 0.62, 1.07, -0.01, 1.16, 0.74, 1.17, 1.16, 0.78, 1.1, 1.18, 1.01, -0.55, -1.72, 1.69, -0.41330176161467985, -1.07, 0.09, -0.32, 0.1, 0.09, -0.29, 0.03, 0.11, -0.06, -0.74, 0.63, 1.17, 0.75, 1.18, 1.17, 0.78, 1.1124285714285715, 1.19, 1.02, -0.19, 0.63, -0.21427628811695995, -0.26, -0.39, -0.16, -0.54, -0.41, 0.01, 0.0, -0.38, -0.06, 0.02, -0.15, -0.64, -0.12, 0.42, 0.42, 0.03, 0.35, 0.43, 0.27, -0.32, -0.23, -0.2, -0.25, -1.34, -0.36, -0.35, -0.17, 0.2, 0.08, -1.29, 0.1, 1.0, 0.51, 0.27, 0.69, -0.24, -0.89, 0.87, 0.83, -0.26, -0.23, -0.53, 1.44, -0.71, -1.63, 4.72, 1.1, 1.65, -1.11, -0.54, 0.0, -0.39, -0.07, 0.01, -0.15, -0.8, -0.54, -0.38, -0.06, 0.02, -0.15, -0.16, 0.32, 0.4, 0.23, -0.42, -0.39, -0.47, 0.08, -0.09, -0.27, -0.28, 0.10257604962387837, 2.31, -0.47980037304250067, -2.36, -0.03, 0.14, -0.55, -0.17, 0.22, -0.07, -0.69, 0.55, -0.73, -0.39, -0.54, 0.32, -0.49], ['299', 2.98, 0.43, -0.32877828437954126, 0.38, 1.04, -0.011580376326240524, -0.44588474204017087, -0.1, -0.96, -0.25, 1.31, 0.06, 0.65, -1.2, 0.1, -2.46, 0.11, -0.12, -1.48, -1.52, -0.77, 0.43, 0.79, -0.17, -0.79, 0.68, -1.4973416050068875, -1.23, -0.64, -2.47, -1.1321800287049086, -3.71, -1.18, -1.4, -2.75, -2.79, -2.05, -0.87, -0.51, -1.4061582768021608, 0.12, -1.29, -0.31, 0.59, -1.0921246055531768, 0.03, -2.52, 0.05, -0.18, -1.538347866419295, -1.58, -0.83, 0.36, 0.72, -0.23, -0.5, -0.35, -0.22, -0.62, -0.89, -1.84, -0.55, -3.09, -0.54, -0.77, -2.12, -2.16, -1.41, -0.23, 0.13, -0.81, -0.6, 0.96, 1.31, -1.27, 1.33, 1.1, -0.28, -0.33, 0.44, 1.64, 2.01, 1.0935596417251208, -1.28, -2.54, 2.47, -0.30330176161467987, -2.55, 0.02, -0.21, -1.57, -1.62, -0.86, 0.33, 0.69, -0.26, 1.24, 2.27, 2.63, 2.4, 1.0, 0.96, 1.73, 2.95, 3.32, 2.35, 0.05, 2.29, 0.89, -0.2, -0.38, -0.02, -0.3590429599640126, -0.23, -1.59, -1.63, -0.88, 0.31, 0.67, -0.28, -0.64, -0.13, -1.36, -1.41, -0.65, 0.54, 0.9, -0.05, -1.16, -1.49, 0.6360371788780403, -0.19681321637643204, 2.43, 0.11, 0.4, -0.56, 0.621720125812563, 0.2788101710076211, -0.07, 0.52, -2.58, 0.44, 0.18, 1.52, 0.08, -0.56, 0.66, 0.62, -0.22, -0.77, -0.39, -3.21, 1.61, -1.19, 2.93, 0.66, 1.02, 2.62, 1.25, 0.2871787775716348, 0.72, 1.93, 2.3, 1.33, -0.65, 1.3, 0.77, 1.98, 2.34, 1.38, 0.53, 1.2, 1.57, 0.61, -0.92, -1.33, -0.67, 0.36, -0.59, -0.18, -0.19, -0.05, 1.45, 0.07, -1.36, 0.17, -0.52, -1.02, -0.94, 0.05, 0.08, 0.2, -0.06, -0.09, -0.08, 0.0, -0.43, -0.33], ['300', -6.47, 0.31, -0.13877828437954126, 0.43, -2.0070209190089403, -1.78, -1.6358847420401708, -3.58, -3.0406219456129895, -3.25, 1.3803184712113286, -1.42, -1.12, 0.16, 0.4642857142857143, -1.42, -1.1328571428571428, -3.02, -2.95, -0.09, -4.0, -1.4, -0.15, -2.18, -3.75, -2.34, -4.37, -2.56, -2.26, -1.0, -0.7, -2.56, -2.32, -4.14, -4.07, -1.24, -5.11, -2.54, -1.31, -3.32, -2.98, -4.065063800783826, -1.650696767518196, 0.31, 1.6, 1.91, 0.01, 0.25, -1.62, -1.54, 1.36, -2.61, 0.02, 1.29, -0.77, -4.09, -3.98, -3.68, -3.18, -2.15, 1.29, 1.6, -0.3, -0.05, -1.92, -1.85, 1.05, -2.91, -0.29, 0.98, -1.08, -4.45, -3.4, 0.3, -1.57, -1.33, -3.17, -3.1, -0.24, -4.15, -1.56, -0.31, -2.34, -4.12, -8.17, 8.28, -3.6533017616146797, -1.86, -1.62, -3.46, -3.39, -0.54, -4.406129838415552, -1.85, -0.61, -2.63, -0.84, -1.86, 0.24, -1.63, -1.55, 1.35, -2.62, 0.01, 1.4211089783232642, -0.78, -0.07885812600098302, -1.79, -1.52427628811696, -1.7, -2.05, -1.33, -2.1, -1.87, -1.79, 1.2997126881055456, -2.86, -0.23, 1.03, -1.02, -1.71, -0.24, 0.07, 3.02, -1.01, 1.7857995496566925, 2.96, 0.86, -3.23, -3.6, 0.66, -1.84, -1.66, -0.82, -0.43, 1.21, -1.2, -0.63, -0.73, -3.45, 6.35, 3.32, 1.72, -3.28, -1.22, -5.09, 5.04, 5.08, -1.69, 1.83, -3.38, -5.16, 2.51, -6.26, 11.05, 4.21, 6.28, -6.34, -0.31, 2.95, -1.08, 1.59, 2.88, 0.78, -5.07, -3.16, -3.91, -1.32, -0.06, -2.1, 0.78, 2.7, 4.01, 1.89, -3.09, -3.61, -1.87, 1.27, -0.79, -1.63, -1.72, -3.37, 5.54, -1.99, -5.66, -2.46, -2.27, -3.1, -2.04, -1.99, -0.88, -1.28, -0.82, -1.52, -1.09, -3.48, -2.76, -1.66], ['301', -3.58, 0.25, 0.011221715620458745, 0.02, 0.0, 0.38, 1.26, 0.09, 0.39, -3.2192857142857143, -3.61, -3.79, -4.1, -3.94, -4.840234693877551, -2.04, -3.8342857142857145, -3.15, -5.368518140589569, -2.7192857142857143, -3.62, -3.58, -3.63, -3.85, 0.67, -0.12, 0.4326583949931125, -0.18, -0.4891666666666667, -0.34, -1.44, 1.63, -0.25, 0.48, -1.84, 0.92, -0.01, 0.04, -0.02, -0.25, 0.9, 0.35, 0.59, -0.32, -0.15, -1.26, 1.82, -0.07, 0.66, -1.66, 1.1, 0.18, 0.22, 0.16, -0.06, 0.69, -0.15, 0.3, 0.53, 0.92, 0.17, -0.94, 2.15, 0.25, 0.99, -1.34, 1.43, 0.5, 0.8674648526077097, 0.49, 0.26943877551020406, -0.21, 0.75, -1.11, 1.98, 0.09, 0.82, -1.5, 1.26, 0.33, 0.37, 0.32, 0.1435596417251207, 0.42, 1.25, -1.27, 1.87, 3.12, 1.2, 1.95, -0.4, 2.583744771101914, 1.45, 1.5, 1.44, 1.21, -2.12, -1.1326334687834372, -1.86, -1.14, -3.41, -0.7, -1.62, -1.57, -1.63, -1.85, -0.07, -1.22, 0.0, 0.5815981806829015, 0.5351790696343399, 0.54, 0.66, 0.73, -1.59, 1.17, 0.24, 0.29, 0.23, 0.01, 0.41, -0.07, -2.3, 0.44, -0.3013969800041226, -0.44, -0.5, -0.72, 0.77, 0.73, -0.11, 0.48, -5.94, 0.09, -0.0642857142857143, -1.24, 1.27, 0.61, 0.53, -0.68, 1.03, -1.04, -0.52, -1.8, 0.46, 1.52, -1.59, -1.53, 0.573290804863853, -1.94, 1.04, 0.27, -0.14, 1.84, -1.28, -1.29, -2.02, -0.99, 2.28, 2.81, 1.86, 1.91, 1.85, 1.62, 1.57, -0.51, -0.9164625850340137, -0.87, -0.93, -1.15, 0.41, 0.04, -0.01, -0.24, 0.43, 0.32, 0.37, -0.06, -0.28, 0.52, 0.52, 0.11257604962387836, -0.91, 0.38, 1.01, 0.68, 0.7, 0.43, -0.22, 0.44, 0.47, 0.47, 0.63, 0.57, 0.65, -0.46, 1.23, 0.49301677370739727], ['302', 0.94, 0.48, 0.02, -0.18, 1.22, 0.5, 0.6141152579598291, 0.8017205965359587, 0.79, 2.72, 1.66, 2.62, 1.87, 3.06, 1.7, 2.18, 2.55, 2.72, 2.79, 2.0, 2.94, 1.66, 2.33, 2.05, 0.64, 0.16, 1.0726583949931126, 0.94, 0.2, 1.37, 0.04, 0.51, 0.87, 1.04, 1.11, 0.33, 1.25, 0.0, 0.66, 0.38, 0.26, 0.75, 0.1, -0.73, 0.42, -0.9, -0.43, -0.07, 0.1, 0.17, -0.61, 0.3, -0.94, -0.28, -0.56, 1.53, 0.7, 0.8078279728097839, 0.58, 0.9192452470658775, 1.17, -0.16, 0.3, 0.67, 0.84, 0.91, 0.13, 1.213421154242583, -0.2, 0.46, 0.18, 0.54, -0.32, -1.32, -0.85, -0.49, -0.32, -0.01252355184498033, -1.03, -0.12, -1.35, -0.7, -0.98, 1.15, 1.18, -1.16, 1.01, 0.47, 0.84, 1.01, 1.07, 0.29, 1.21, -0.04, 0.62, 0.34, 0.59, 0.53, 0.36, 0.53, 0.6015238095238095, -0.18, 0.74, -0.51, 0.15, -0.13, 0.03, 0.44, -1.08, 0.49, 0.52, 0.41, 0.17, 0.17, 0.24, -0.54, 0.37, -0.87, -0.21, -0.49, 1.0, 0.0, 0.07, -0.71, 0.21, -1.03, -0.38, -0.66, -0.19, -0.38, -0.1, 0.37, 1.82, 0.28, 0.2, -0.1, 0.07, 0.03, 0.22, 0.69, -1.3194817511227284, -1.0, -0.47, 0.54, 0.52, 1.43, -1.43, -1.54, 0.48, -0.09, 0.95, 1.81, -0.92, 0.46, -0.27, -0.36, -0.46, 1.4, -0.07, -0.7751904761904762, 0.14, -1.1, -0.45, -0.73, 1.45, 0.71, 0.92, -0.33, 0.33, 0.05, -0.21, -1.24, -0.58, -0.86, 0.68, 1.1684535464535466, 1.04, 0.66, 0.38, 0.47, 0.5443963012752908, 0.88, -3.24, -0.48, 3.7892806122448977, 0.49, 0.83, 0.38, -0.28, 0.59, 0.0, 0.7, 0.34, 0.83, 0.66, 0.0, 0.74, -0.21], ['303', -3.2, 0.32, 0.05122171562045875, 0.01, 0.26, 0.2, 0.45, 0.72, 0.63, 0.68, 0.47, -0.27, -1.02, 0.52, -0.54, 1.38, 0.95, 0.71, -1.66, 1.19, 0.77, 0.08, 0.04, -0.47, 1.3, 0.32937141458889196, 0.21, -0.73, -1.48, 0.05, -1.0, 0.9, 0.48, 0.24, -2.12, 0.72, 0.3, -0.39, -0.42, -0.94, 0.7, 0.0, 0.95, -0.76, 0.79, -0.27, 1.65, 1.22, 0.98, -1.4, 1.46, 1.04, 0.34, 0.31, -0.21, -0.04, 0.44, 0.51, 1.02, 1.72, 1.6631047225355606, 0.49, 2.42, 1.99, 1.75, -0.64, 2.23, 1.81, 1.11, 1.08, 0.56, 0.79, 0.16, -1.05, 0.85, 0.43, 0.19, -2.17, 0.67, 0.25, -0.44, -0.48, -0.99, 0.01, 1.69, -1.79, 1.23, 1.9205204081632652, 1.5017857142857143, 1.25, -1.13, 1.73, 1.31, 0.62, 0.58, 0.06, -1.99, -0.68, -0.42, -0.66, -3.0, -0.18, -0.6, -1.28, -1.32, -1.82, -0.06, -0.48063179677465384, 3.25, 0.46, 0.0, -0.02, -0.18819052351387078, -0.24, -2.58, 0.24, -0.17, -0.86, -0.9, -1.3514153161169342, 0.62, -0.02, -2.35, 0.48, 0.06, -0.5042004503433073, -0.66, -1.17, 0.76, 0.84, 0.16, 0.55, -5.57, 0.13, 0.14, -0.98, 1.1117201258125629, 0.5188101710076211, 0.0, 1.9661635321120494, 0.89, -0.95, -0.46, -1.65, 0.44, 1.42, -1.43, -1.32, 0.46, -1.29, 0.9498783572413152, 0.32, -0.16, 0.6607142857142857, -1.85, -0.45, -0.65, -0.9, 2.38, 2.9, 2.47, 1.8172970521541951, 1.73, 1.21, 1.37, -0.5, -0.41, -1.1, -1.13, -1.64, -0.09, -0.69, -0.72, -1.23, 0.57, 0.43, 0.61, -0.03, -0.55, 0.43, 0.45, 0.74, -1.95, 2.25, 2.01, 0.24, 0.9, 0.64, -0.51, 0.0, 0.1, 0.3, 0.42, 0.31, 1.16, -0.57, 0.94, 0.74], ['304', -2.26, 0.35, 0.11, 0.13, -0.39, -0.1, -1.0158847420401709, -0.14, -0.73, -1.34, 0.16, -0.54, -1.05, -0.83, -1.73, -0.87, -1.67, -1.51, 2.59, -1.51, -1.74, -0.96, -1.62, -1.48, 0.6, -0.38, -1.4673416050068875, -0.7, -1.21, -0.99, -1.8321800287049088, -1.03, -1.83, -1.67, 2.42, -1.67, -1.9, -1.12, -1.78, -1.64, -0.2, -1.94, -0.81, -0.52, -0.29, -1.2, -0.33, -1.14, -0.98, 3.14, -0.98, -1.21, -0.32613444352099813, -1.09, -0.94, -0.14, -0.07, 0.59, -0.73, -0.29, 0.22, -0.69, 0.19, -0.63, -0.46, 3.68, -0.46, -0.7, 0.1, -0.57, -0.43, 0.48, -0.51, -0.91, -0.04, -0.85, -0.69, 3.45, -0.68, -0.92, -0.13, -0.79, -0.65, -1.23, 0.66, -0.6, 0.4366982383853202, 0.88, 0.06, 0.23, 4.4, 0.23, -0.01, 0.79, 0.12, 0.26, 0.52, -0.48, -0.82, -0.65, 3.48, -0.65, -0.89, -0.09, -0.76, -0.62, -0.06, -0.56, -0.04, 0.07, 0.07517906963433994, 0.1, 0.34, 0.17, 4.33, 0.17, -0.07, 0.73, 0.06, 0.2, -0.37, 0.17, 4.16, 0.0, -0.24, 0.56, -0.11, 0.03, -0.04, -0.02, 0.29, 0.19, 1.57, -0.01, 0.0, 0.04, 0.0, -0.03, -0.34, -1.13, -0.25, -0.15, -0.07, -1.18, -0.21, 0.17, -0.29, -0.19, 0.05, 0.03, 0.1, -1.69, 0.89, 1.01, -2.18, -0.71, -0.96, 0.31, -3.83, -3.99, -4.22, -3.45, -4.1, -3.96, 0.17, 0.17, -0.24, 0.56, -0.11, 0.03, 0.41, 0.8, 0.13, 0.27, -0.77, -0.97, -0.39, -0.67, -0.53, 0.07, 0.09, -0.13, -1.16, -0.38, 1.16, -0.39, 0.8, 0.28, 0.14, 0.05, -0.27, 0.29, -0.93, 0.15, 0.14, 1.52, 0.29, 0.18], ['305', -1.99, -0.33, 0.05122171562045875, 0.0, -0.04, -0.11158037632624052, 0.44, -0.59, -0.31, -0.95, -0.91, -1.6, -0.29, -0.34, -1.01, -0.61, -0.52, -0.83, -3.2, -1.16, -1.23, -1.57, -1.11, -0.66, -0.28, -0.52, -0.00734160500688754, -0.69, 0.63, 0.58, -0.1, 0.3, 0.4, 0.08, -2.31, -0.25, -0.32, -0.66, -0.2, 0.25, -0.49, -1.0050638007838266, 0.65, 1.33, 1.28, 0.6, 1.0, 1.1, 0.78, -1.63, 0.45, 0.37, 0.03, 0.5, 0.95, -0.54, -0.59, -0.98, -0.54, -0.67, -0.05, -0.7192006802721088, -0.33, -0.23, -0.55, -2.92, -0.87, -0.94, -1.29, -0.82, -0.38, -0.1, -0.62, -0.67, -0.27, -0.18, -0.49, -2.87, -0.82, -0.89, -1.23, -0.77, -0.32, -0.38, 0.21, -0.25, 0.05, 0.4, 0.5, 0.18, -2.21, -0.15, -0.22, -0.57, -0.1, 0.35, -2.26, -0.26263346878343713, 0.1, -0.22, -2.6, -0.55, -0.62, -0.96, -0.49, -0.05, -0.08, -0.38, 0.61, -0.4, 0.08, -0.88, -0.44, -0.32, -2.7, -0.64, -0.72, -1.06, -0.59, -0.15, 0.66, -0.06692325186963273, -2.39, -0.33, -0.4, -0.74, -0.28, 0.17, 0.13, 0.0, -0.06, -0.26, -6.67, 0.1, 0.0, 2.9, -2.84, -1.44, 0.75, -0.17, -0.32, 0.8, 0.42, -1.0, -0.07, -1.21, 1.16, 1.19, -0.356709195136147, 4.22, -0.78, 0.49, -0.23, -1.25, 0.1527091836734694, 0.83, 1.37, 0.39, 2.32, 2.11, 2.04, 1.68, 2.16, 2.62, -1.24, 0.21, -0.07, -0.42, 0.05, 0.5, 0.28, -0.35, 0.12, 0.57, -0.29, -0.38, 0.63, 0.47, 0.92, -0.39, -0.39, -0.53, 0.27, 0.46, -0.33, -0.05, -0.2, 0.15, 0.5227868514969317, 0.2, -1.35, -0.62, 0.21, -0.13, -0.3, 0.62, -0.44, -0.24], ['306', 4.25, 0.14, 0.02, -0.07, 0.61, -0.05, 0.07, 0.07, 0.4, -0.10291156462585038, -0.81, -1.16, 1.05, -1.31, -1.4757142857142858, -2.6, -0.61, -0.56, -2.03, -0.9974455782312925, -0.03, -0.48, -0.75, -0.2, 1.0, 1.099371414588892, 0.3026583949931125, -0.35, 1.88, -0.5, -0.68, -1.8, 0.18, 0.25, -1.22, -0.52, 0.79, 0.33, 0.07, 0.62, 0.84, 0.7549361992161734, 0.62, 2.24, -0.15, -0.33, -1.46, 0.53, 0.61, -0.88, -0.17, 1.15, 0.68, 0.42, 0.97, 0.64, 0.42, -0.21, 0.39, -1.58, -2.34, -2.51, -3.61, -1.67, -1.59, -3.04, -2.35, -1.06, -1.52, -1.78, -1.24, 0.12, 0.77, -0.18, -1.31, 0.68, 0.76, -0.73, -0.02, 1.3, 0.84, 0.57, 1.12, 0.28, 0.43, -0.44, 0.95, -1.13, 0.86, 0.94, -0.55, 0.16, 1.48, 1.01, 0.75, 1.3, 4.59, 2.11, 2.01, 2.09, 0.6255850340136054, 1.31, 2.64, 2.17, 1.9, 2.46, 0.01, 2.11, -1.12, -0.04, 0.02, -0.14, 0.09, 0.08, -1.4, -0.69, 0.62, 0.16, -0.11, 0.44, -0.21, 0.01, -1.47, -0.77, 0.54, 0.20579954965669267, -0.19, 0.36, 0.49, 0.55, -0.07, -0.04, 13.52, 0.04, 0.05, 0.77, -0.75, -0.38, -1.19, 1.26, -1.58, 0.12, 0.03, 2.31, -0.3, -0.11, 0.0, 0.13, -0.02, 1.27, -0.07, -0.24, 0.1547652642842468, 0.26, 1.2006513605442177, -0.17, -0.29, 1.61, 1.51, 0.71, 2.04, 1.57, 1.31, 1.86, -0.08, 0.79, 1.32, 0.85, 0.59, 1.14, -0.52, -0.46, -0.72, -0.18, 0.44, 0.25, -0.06, -0.26, 0.28, 0.07208003431405688, -0.05, 0.14, 0.67, -0.89, -0.59, 0.07, 1.19, 0.2, 0.55, 0.34, -0.16, -0.86, -0.29, -0.57, -0.35, 3.1202406343656346, 1.93, 0.62], ['307', 5.131428571428571, -6.06, -2.47, 0.34, -2.15, -3.84, -4.15, -7.21, -5.86, -4.56, 4.350608843537414, -1.3, 2.46, 4.17, 1.3371428571428572, -7.799285714285714, 1.19, -0.37942857142857145, -4.49, -0.45, -4.69, 1.9, 3.57, 0.67, -6.37, -4.4, -8.52, -5.4, -1.8, -0.16, -2.89, -11.63, -3.02, -4.52, -8.46, -4.59, -8.65, -2.34, -0.73, -3.52, -4.22, -7.35, -3.3, 3.8, 5.54, 2.65, -6.568956349206349, 2.52, 0.93, -3.24, 0.8607142857142857, -3.44, 3.24, 4.93, 1.99, -5.57, -5.6499999999999995, -5.78, -5.81, -6.85, 1.67, -1.11, -9.799999999999999, -1.24, -2.77, -6.78, -2.84, -6.98, -0.4903418367346939, 1.09, -1.75, -8.72, -8.38, -2.73, -11.426705782312926, -2.86, -4.36, -8.32, -4.44, -8.51, -2.18, -0.57, -3.3064403582748794, -7.98, -22.21, 22.31, -5.8, -9.0, -0.13, -1.67, -5.74, -1.75, -5.93, 0.57, 2.22, -0.64, 2.51, 3.52, 10.378571428571428, 8.05, 3.59, 7.97, 3.37, 10.52, 12.33, 9.18, -4.35, 3.5, -7.25, -4.92, -5.58, -4.78, -5.68, -1.55, -5.62, -1.62, -5.81, 0.7, 2.36, -0.52, -6.05, -4.2, -4.13, -0.08, -4.33, 2.28, 4.042857142857143, 1.05, -8.66, -5.98, -0.75, -6.16, 5.1, -8.9796768707483, -7.28, 9.334285714285715, -8.66, -4.31, -5.08, -12.13, 8.36, 10.021428571428572, 4.954547619047619, 2.635221088435374, -3.6, -15.56, 16.117142857142856, 14.994285714285715, -4.92, 13.507142857142858, -9.85, -5.21, 2.63, -17.13, 28.92, 11.37, 17.15, -8.37, -0.07, 4.23, -0.21, 6.69, 8.45, 5.4, -14.83, -4.12, -4.26, 2.36, 4.040857142857143, 1.7685714285714287, 0.14, 6.91, 8.67, 5.8585714285714285, -6.05, -6.97, -6.33, 1.64, -1.21, -4.95, -5.32, -7.24, 14.53, -7.55, -14.36, -5.76, -6.64, -7.85, -2.81, -5.21, -4.11, -2.4, -3.82, -3.93, -5.19, -6.76, -9.7, -6.94], ['308', 1.31, 0.68, -0.038778284379541256, 0.08, 0.25, 1.05, 0.8741152579598291, 0.41, 1.15, 1.37, -0.28, 0.58, 2.37, 1.74, 0.8, -0.09, 0.91, 1.21, 2.21, 0.4, 1.497335482087359, 0.35, 0.41, 0.25, 1.0, 0.739371414588892, 1.65, 0.86, 2.65, 2.02, 1.08, 0.19, 1.19, 1.49, 2.5, 0.68, 1.74, 0.63, 0.69, 0.53, 0.3374684253532108, 1.0249361992161734, 0.78, 1.78, 1.15, 0.22, -0.67, 0.33, 0.62, 1.62, -0.1788095238095238, 0.87, -0.13613444352099813, -0.17, -0.33, -0.12, 0.92, 0.46, 1.66, -0.98, -0.62, -1.53, -2.4, -1.43, -1.13, -0.15, -1.92, -0.726578845757417, -1.97, -1.92, -2.07, 1.75, -0.37, -0.92, -1.8, -0.82, -0.52, 0.47, -1.31, -0.27, -1.36, -1.31, -1.46, 1.15, 3.06, -3.02, 0.56, -0.88, 0.11, 0.41, 1.4, -0.39, 0.66, -0.44, -0.39, -0.54, 4.41, 1.46, 1.0, 1.3, 2.31, 0.49, 1.55, 0.44, 0.5, 0.34, 0.29, 1.55, 1.52, 1.08, 1.03, 0.97, 0.46, 0.3, 1.29, -0.5, 0.55, -0.55, -0.42401213658444736, -0.5914153161169343, 0.94, 0.16, 0.99, -0.8, 0.25, -0.85, -0.79, -0.95, 0.94, 0.51, 0.11, 0.48, 8.924476190476192, -0.05, 0.14, -1.53, 1.54, 0.8, 0.16406627346681524, 0.96, -1.86, -2.06, -1.05, 0.7, 1.61, 2.95, -2.85, -3.16, 1.02, -2.23, 2.08, -0.27, 0.13, 1.4, -4.23, -0.93, -1.45, 1.81, -0.83, -1.77, -0.74, -1.82, -1.77, -1.92, 3.2, 0.96, 1.05, -0.05, 0.01, -0.15, -0.09, -1.09, -1.04, -1.19, 1.09, 1.43, 1.01, 0.06, -0.1, 1.05, 0.89, 0.64, -2.14, 0.9, 2.05, 0.26, 0.57, 0.96, -0.16, 0.41, 1.0, 1.11, 2.46, 1.8, 1.195957527023814, -1.35, 0.46, 0.26], ['309', -5.53, 1.06, -0.31877828437954125, -0.4078571428571427, 1.53, 3.39, 3.33, 4.95, 4.03, 3.810714285714286, -0.99, 0.7, -0.46, -0.3, -0.14, 7.0, -0.05, 2.95, 0.44, 1.05, 3.87, -0.6069251700680272, -1.14, -0.28, 4.75, 2.75, 4.882658394993112, 1.8284685082657772, 0.53, 0.69, 0.86, 8.07, 0.95, 3.98, 1.44, 2.06, 4.91, 0.46, -0.15, 0.71, 3.01, 5.28, 3.090204081632653, -1.15, -1.0, -0.83, 6.26, -0.75, 2.24, -0.26, 0.35, 3.15, -1.31, -1.8142857142857143, -0.6691712018140588, 3.26, 2.6, 4.81, 5.2, 4.29, 0.16, 0.33, 7.5, 0.42, 3.43, 0.91, 1.52, 4.35, -0.15, -0.68, 0.18, 6.37, 4.13, 0.17, 7.33, 0.26, 3.27, 0.75, 1.36, 4.19, -0.31, -0.84, 0.02, 4.5650595238095235, 12.41, -13.77, 3.95, 7.15, 0.09, 3.09, 0.58, 1.19, 4.01, -0.39428571428571424, -1.0, -0.15, -0.64, -2.98, -6.59, -3.777880952380952, -6.13, -5.56, -2.93, -7.12, -7.61, -6.158571428571428, 0.62, -2.96, 3.54, 3.91, 4.11, 3.69, 3.86, 3.0, 0.49, 1.1105357142857144, 3.92, -0.57, -0.4614285714285715, -0.23, 4.19, 0.83, -2.44, -1.84, 0.899562358276644, -3.46, -3.98, -3.14, 4.43, 3.12, -2.16, 4.05, -1.49, 2.12, 1.03, -8.34, 8.35, 4.17, 3.05, 4.38, -4.961283898641042, -7.75, -3.85, -2.7, 2.93, 11.89, -11.69, -11.55, 3.93, -12.34, 7.81, 1.92, -1.19, 11.31, 20.58, 1.91, 1.86, 5.47, 3.36, 0.61, 3.42, -1.05, -1.5687142857142857, -0.72, 11.36, 2.73, 2.79, -1.65, -2.17, -1.33, -0.06, -4.32, -4.587142857142857, -4.0, 4.06, 4.39, 4.45, -0.53, 0.33, 3.84, 3.81, 5.13, -3.24, 3.88, 3.5, 4.02, 4.42, 5.01, 0.87, 3.6, 3.82, 2.5, 3.2409523809523813, 3.7, 4.11, 3.75, 6.34, 4.26], ['310', 11.188571428571429, 0.19, 0.13122171562045873, 0.05, 1.67, 0.84, 1.8641152579598292, 2.28, 2.08, 1.7370884353741496, -1.34, -0.89, -0.33, -0.7, -0.73, 0.23, 0.13, 0.71, -0.73, -0.43, 2.42, 1.76, 0.38, 0.07, 2.53, 1.98, 2.66, 0.46, 1.03, 0.65, 0.62, 1.59, 1.49, 2.08, 0.6377619047619048, 0.92, 3.81, 3.15, 1.75, 1.43, 1.11, 3.34, 2.19, 0.5736589811608608, 0.19, 0.16, 1.13, 1.02, 1.61, 0.16, 0.46, 3.34, 2.68, 1.28, 0.97, 1.53, 1.47, 1.36, 1.85, 1.62, -0.38, -0.4, 0.55, 0.45, 1.04, -0.3990476190476191, -0.10976190476190477, 2.75, 2.1, 0.7127347454133168, 0.4, 2.45, 2.0, -0.03, 0.94, 0.83, 1.4232142857142855, -0.02, 0.27, 3.14, 2.5614285714285714, 1.09, 0.78, 2.37, 2.69, -2.72, 2.03, 0.96, 0.86, 1.44, 0.0, 0.3, 3.17, 2.51, 1.572517006802721, 0.81, 4.31, 1.06, -0.1, 0.48, -0.95, -0.66, 2.19, 1.5563946608946608, 0.15, -0.15, 0.7, 1.09, 0.8, 0.91, 0.86, 0.995673518650032, 1.16, 0.5813469387755101, -0.85, -0.56, 2.29, 1.63, 0.25, -0.05, -0.24, 0.58, -1.1663144197072766, -1.13, 1.709562358276644, 1.05, -0.32, -0.63, 1.16, 1.14, 0.31603717887804045, 0.91, 8.52, 0.4, 0.35, -1.88, 1.961720125812563, 0.94, 0.81, 1.7, -3.49, -1.84, -0.9, 5.59, 0.36, 2.73, -2.76, -2.69, 0.9, -2.83, 1.79, 0.25, -0.13, 3.5, -4.68, -2.35, -3.46, 3.46, 2.03, 0.3, 3.17, 2.51, 1.12, 0.8, 2.7631678995607567, 1.8643542330685188, 2.86, 2.21, 0.82, 0.51, -1.11, -0.64, -1.99, -2.29, 2.340135138670853, 2.09, -0.47, -1.36, -1.66, 1.03, 0.91, 2.18, -2.31, 0.87, 2.31, 1.52, 1.4211825396825397, 0.9, -0.31, 1.03, 0.81, 0.27, 0.22, 0.84, 1.21, 3.31, 2.37, 1.25], ['311', 8.06, 0.48, 0.19, 0.02, 0.38, 1.08, 1.02, 2.33, 1.3, 1.8, 0.74, 0.38, -0.15, -0.4, -0.69, -0.2792857142857143, 0.44, 1.5505714285714287, 3.76, 0.9, 2.31, 0.7230748299319728, 0.15, 0.81, 1.46, 1.58, 1.05, -0.24153149173422278, -0.89, -1.13, -1.42, -1.02, -0.3, 0.8, 3.0, 0.16, 1.56, -0.02, -0.59, 0.07, 1.53, 1.4749361992161734, 1.41, -0.53, -0.78, -1.06, -0.66, 0.06, 1.16, 3.37, 0.52, 1.92, 0.34, -0.23, 0.43, 1.8, 1.42, 1.44, 1.76, 1.95, -0.25, -0.53, -0.13, 0.6, 1.7, 3.92, 1.06, 2.47, 0.88, 0.3, 0.96, 2.36, 2.21, -0.27535714285714286, 0.12, 0.85, 1.95, 4.18, 1.31, 2.72, 1.13, 0.55, 1.21, 1.19, 4.56, -4.474, 2.5008709226619943, 0.41, 1.14, 2.25, 4.48, 1.6016746031746032, 3.02, 1.42, 0.84, 1.5, 4.2, 2.08, 0.73, 1.83, 4.06, 1.19, 2.6, 1.01, 0.43, 1.09, 0.4, 2.02, 1.81, 1.17, 1.21, 1.14, 1.35, 1.1, 3.31, 0.46, 1.86, 0.28, -0.29, 0.36, 1.08, 0.25, 2.18, -0.64, 0.75, -0.6842004503433073, -1.38, -0.73, 1.52, 1.1, 0.29, 0.88, 12.64, 0.13, 0.15, -2.44, 2.43, 1.22, 0.39, 2.35, -1.82, -2.41, -1.17, 4.1, 0.813079789868779, 3.57, -3.78, -3.6, 1.18, -3.78, 2.38, 1.98, -0.98, 4.09, -10.73, -2.76, -4.18, 1.8, -1.9, -2.76, -1.4, -2.93, -3.49, -2.85, 3.57, 0.89, 1.5441925889236814, -0.18, -0.75, -0.09, -0.5, -1.55, -2.11, -1.47, 1.29, 1.25, 1.07, -0.57, 0.08, 1.22, 1.16, 2.13, -5.02, 1.61, 5.13, 2.2, 1.24, 1.65, 0.66, 0.79, 1.21, 1.34, 0.76, 0.81, 0.98, 4.1, 1.78, 1.14], ['312', -3.94, -0.24, -0.08877828437954126, 0.16, -1.47, -1.59, -2.3, -1.91, -2.11, -1.28, 1.28, 0.78, -0.21, 1.17, 0.29, -0.15, -0.49, -0.97, -3.37, 2.03, -1.78, -0.34, 0.4, -0.53, -1.42, -1.58, -2.53, -0.49, -1.47, -0.11, -0.98, -1.41, -1.75, -2.22, -4.6, 0.74, -3.02, -1.6, -0.87, -1.79, -0.81, -2.935063800783827, -2.0497959183673466, -0.98, 0.39, -0.49, -0.92, -1.26, -1.73, -4.12, 1.24, -2.54, -1.11, -0.38, -1.31, -0.6, -0.89, -2.4, -1.95, -1.08, 1.38, 0.49, 0.06, -0.28, -0.76, -3.17, 2.24, -1.58, -0.13, 0.61, -0.33, -2.42, -2.43, -0.88, -1.31, -1.65, -2.12, -4.5, 0.85, -2.92, -1.49, -0.77, -1.69, -2.57, -4.44, 4.44, -1.57, -0.4294795918367347, -0.77, -1.25, -3.65, 1.74, -2.06, -0.62, 0.11, -0.82, -2.25, -1.062633468783437, -0.34, -0.82, -3.23, 2.18, -1.64, -0.19, 0.6911089783232642, -0.39, -0.33, -1.13, -1.01, -1.22, -1.48, -0.88, -0.8, -0.48, -2.9, 2.54, -1.3, 0.15, 0.89, -0.04, -0.94, -0.32, -2.43, 3.03, -0.82, 0.64, 1.38, 0.44, -1.47, -1.35, 0.08, -0.8, -6.76, -0.25, -0.34, 0.98, -0.96, -0.47, -0.69, -2.77, 6.59, 2.45, 1.23, -1.93, -0.82, -3.63, 3.7, 3.67, -1.22, 1.5, -2.44, -2.18, 1.1, -2.44, 11.59, 1.62, 2.43, -6.33, 2.16, 5.6, 1.8472132867132867, 3.14, 3.9, 3.1057617128436457, -3.65, -3.25, -3.5958074110763185, -2.32, -1.6, -2.52, 0.5, 1.47, 2.22, 1.27, -1.8998648613291471, -2.41, -0.95, 0.74, -0.2, -1.23, -1.14, -1.87, 6.4, -0.53, -6.63, -2.63, -2.38, -1.68, -0.93, -0.8599225974772193, -0.58, -1.2, -0.84, -1.14, -0.75, -2.85, -2.9, -0.5], ['313', 7.854285714285714, 0.59, 0.22122171562045873, 0.48, 0.78, 0.53, 0.5641152579598292, 1.04, 0.89, 1.69, 0.78, 0.46, 0.68, 0.26, 0.44, -0.38, 0.51, 0.94, -2.96, 0.87, 2.01, 0.49104421768707485, 1.26, 1.0, 2.37, 1.29, 0.9, -0.32, -0.1, -0.52, -0.34, -1.15, -0.27, 0.16, -3.7, 0.09, 1.22, -0.33, 0.48, 0.26384172319783916, 0.7674684253532109, 0.55, 1.22, 0.22, -0.2, -0.02, -0.83, 0.05, 0.48, -3.4, 0.41, 1.54, -0.01, 0.8971428571428572, 0.54, 0.86, 2.33, 0.88, 0.48, 1.0, -0.42, -0.24, -1.05, -0.17, 0.26, -3.61, 0.19, 1.32, -0.23, 0.57, 0.32, 0.64, 1.43, 0.18, -0.63, 0.25, 0.68, -3.2, 0.61, 1.75, 0.19, 1.0, 0.74, 0.88, 1.49, -1.46, 1.24, -0.81, 0.07, 0.5, -3.38, 0.43, 1.56, 0.01, 0.82, 0.56, 4.91, 2.07, 0.89, 1.32, -2.59, 1.25, 2.4, 0.83, 1.64, 1.39, 0.7, 2.09, 2.26, 0.75, 0.53, 1.2, 1.17, 0.43, -3.45, 0.35, 1.49, -0.06, 1.3685714285714285, 0.49, 1.21, 0.74, -3.86, -0.07, 1.06, -0.49, 0.32, 0.06, 0.88, 0.8, 0.71, 0.97, 14.397619047619049, 0.34, 0.14, -2.72, 2.72, 1.36, 0.86, 1.84, -1.62, -1.52, -0.78, 3.829285714285714, 0.69, 2.5, -2.4, -2.27, 0.76, -4.18, 1.52, -1.74, 0.79, 3.48, -6.48, -2.48, -3.45, 1.66, 4.78, 3.94, 5.11, 3.5, 4.34, 4.08, 2.3, 0.81, 1.13, -0.42, 0.39, 0.13, -0.31, -1.53, -0.73, -0.99, 1.010135138670853, 0.6, 1.24, 0.81, 0.55, 0.82, 0.83, 1.02, -3.31, 2.33, 3.4, 1.18, 0.7, 0.42, -0.25, 1.1, 0.97, 0.78, 0.930952380952381, 0.64, 0.68, 3.04, 2.171595238095238, 0.98], ['314', -0.31, -0.08, 0.0, 0.02, -1.44, 0.08, -0.16, -0.41, -0.3, 0.31, 0.41, 0.64, 0.42, 1.31, 0.19, 0.22, 0.41, 0.14, 4.89, 4.01, -0.01, -0.23, -0.55, -0.5, -0.46, -0.49, -0.1, 0.23, 0.01, 0.9, -0.22, -0.19, -0.01, -0.27, 4.46, 3.58, -0.42, -0.63, -0.95, -0.91, 0.52, 0.014936199216173434, -0.33, -0.22, 0.67, -0.44, -0.42, -0.23, -0.5, 4.22, 3.35, -0.65, -0.86, -1.18, -1.14, -0.27, -0.3, -0.22, -0.15, -0.11, 0.89, -0.22, -0.2, -0.01, -0.28, 4.46, 3.58, -0.256578845757417, -0.64, -0.96, -0.91, 0.2, -0.99, -1.1, -1.08, -0.9, -1.16, 3.533095238095238, 2.66, -1.31, -1.52, -1.83, -1.79, -0.29, 2.34, -2.29, 0.11, 0.02, 0.6399013605442176, -0.06, 4.69, 3.81, -0.2, -0.42, -0.74, -0.69, -1.4, 0.09, 0.19, -0.08, 4.66, 3.79, -0.23, -0.44, -0.76, -0.72, 0.27, 0.06, 3.96, 0.32, 0.26, 0.36, -0.1, -0.27, 4.47, 3.59, -0.41, -0.63, -0.95, -0.9, 0.49, 0.17, 4.75, 3.87, -0.15, -0.36, -0.68, -0.64, 1.31, 0.59, -0.07, 0.08, -4.04, 0.05, 0.0, -0.69, 0.69, 0.39, -0.32, -0.99, 6.95, -0.53, -0.29, -0.15, 0.49, 1.0, -0.95, -0.95, 0.32, -1.09, 0.62, 0.19, -0.1, -0.34, 0.68, 0.15, 0.33, -7.06, -4.37, -0.84, -4.67, -4.88, -5.18, -5.14, 0.94, -3.56, -3.87, -4.07, -4.38, -4.34, 0.32, -0.22, -0.54, -0.49, -0.39, -0.39, 0.54, -0.32, -0.28, 0.31, 0.27, -0.31, 0.01, 2.34, -0.06, -0.49, -1.29, 0.86, 0.05, 0.22, 0.34, 0.47, 0.48, 0.62, 0.895957527023814, -1.11, -2.21, 0.43], ['315', 0.43, -0.45, 0.17, -0.17, 0.25, 0.49, -1.325884742040171, 0.63, 0.92, -0.05, -1.52, 0.64, -1.2, -0.59, -1.39, 0.14, -0.6, -0.21, -0.34, -0.34633673469387755, 0.37, -0.33, -1.09, -0.28, 0.84, 0.32, 1.49, 2.2, 0.33, 0.94, 0.13, 1.69, 0.94, 1.34, 1.2, 1.17, 1.92, 1.21, 0.43, 1.26, 0.3874684253532108, 1.66, -0.4906967675181959, -1.83, -1.23, -2.02, -0.5, -1.23, -0.84, -0.98, -1.01, -0.27, -0.96, -1.73, -0.92, 1.1, 0.24, 0.69, 1.66, 1.16, 0.61, -0.2, 1.35, 0.61, 1.0, 0.86, 0.84, 1.58, 0.88, 0.1, 0.93, -0.35, 0.54, -0.81, 0.73, -0.01, 0.39, 0.25, 0.22, 0.96, 0.27, -0.51, 0.31, 1.7289098639455782, 3.03, -2.88, 1.36, 1.55, 0.81, 1.2, 1.06, 1.04, 1.78, 1.08, 0.3, 1.1840077275244505, 0.05, -0.19, -0.74, -0.3269047619047619, -0.48, -0.51, 0.23, -0.46, -1.23, -0.42, 0.19, -0.17, 2.56, 0.67, 0.71, 0.705673518650032, 0.55, 0.39134693877551024, 0.26, 0.23, 0.97, 0.27, -0.5, 0.32, 0.35, 0.16, -0.14, -0.17, 0.57, -0.12, -0.89, -0.07, 1.31, 1.14, -0.36, 0.38, 0.13, 0.04, 0.14, -1.7, 1.69, 0.84, 1.12, 1.38, -0.7, -1.31, -0.66, 0.23, 0.32, 2.12, -1.96, -2.08, 0.67, -2.47, 1.35, 0.95, -0.53, 1.63, -4.33, -1.04, -1.56, 0.74, 0.29, -0.03, 0.71, 0.02, -0.75, 0.06, 2.11, 0.32, 0.74, 0.05, -0.73, 0.09, -0.42, -0.69, -1.46, -0.64, 0.94, 1.51, 0.28, -0.77, 0.05, 0.78, 0.63, 0.64, -2.15, 1.48, 2.35, 0.54, 0.7, 1.06, 0.82, 0.53, 0.77, 0.67, 0.26, 0.62, 0.23, 0.23, 0.14, -0.08], ['316', 0.58, 1.27, -0.20877828437954127, 0.12, 0.99, 1.48, 1.2741152579598292, 1.58, 1.73, -0.51, -2.07, -2.68, -1.32, -1.97, -1.1, -2.041439909297052, -2.97, -1.49, -1.21, -0.93, 0.14733548208735894, -1.92, -1.9, -3.03, 2.75, 0.63, 1.6326583949931126, -0.62, 0.77, 0.11, 0.99, -0.29, -0.91, 0.59, 0.88, 1.17, 2.23, 0.16, 0.2688796134390452, -0.98, 0.77, 1.3349361992161735, 2.23, 1.4, 0.74, 1.62, 0.3464030612244898, -0.29, 1.22, 1.51, 1.8, 2.8980654680864433, 0.79, 0.8, -0.36, -0.14, 1.54, 1.7, 1.48, 0.82, -0.66, 0.22, -1.05, -1.67, -0.18, 0.11, 0.5239757335335068, 1.45, -0.61, -0.59, -1.73, 3.39, 1.49, 0.88, -0.4, -1.02, 0.48, 0.77, 1.06, 2.12, 0.05, 0.06, -1.09, 1.4, 4.66, -4.69, 0.6, -1.27, -1.88, -0.4, -0.11, 0.18, 1.22, -0.82, -0.81, -1.95, 1.02, 1.9, -0.62, 0.89, 1.18, 1.47, 2.53, 0.45, 0.47, -0.69, 0.87, 1.91, 3.13, 1.78, 1.52, 2.24, 2.53, 1.52, 1.81, 2.1, 3.17, 1.08, 1.09, -0.07, 1.6, 1.0, 0.29, 0.57, 1.63, -0.43, -0.42, -1.56, 1.7618280382942038, 2.13, 0.05, 2.82, 2.01, 0.75, 0.48, -5.45, 5.45, 2.7, 1.52, 2.63, -0.6, -3.56, -1.78, 0.35, 1.0330797898687791, 5.76, -5.71, -5.31, 1.75, -8.17, 3.51, -1.38, 0.7, 7.61, -4.46, -4.99, -7.56, 0.8738095238095238, 0.71, 0.6171787775716348, 1.34, -0.72, -0.7, -1.84, 5.36, 0.42, 1.05, -1.0, -0.98, -2.12, -0.62, -2.02, -2.01, -3.14, 1.7, 1.55, 1.44, 0.01, -1.13, 1.64, 2.0, 1.46, -2.2, 3.4101996269574992, 1.89, 2.2, 2.11, 1.42, -1.15, 2.28, 2.19, 1.07, 0.06, 1.46, 2.6, 3.25, 2.74, 3.41], ['317', -2.88, -0.85, 0.011221715620458745, 0.14, -0.55, 0.1, -1.73, -0.96, 0.0, -1.75, -2.06, -1.28, -0.3960867348791511, -0.23, -1.29, -1.4, -1.25, -1.75, -1.09, -1.75, -1.31, -1.52, -1.27, -1.28, -0.33, -0.29, 0.32, 0.8, 1.64, 1.87, 0.79, 0.68, 0.83, 0.32, 0.9907142857142857, 0.32, 0.77, 0.55, 0.81, 0.8, -0.25, 0.45, -0.48, 0.83, 1.06, -0.02, -0.12, 0.03, -0.48, 0.19, -0.48, -0.03, -0.25, 0.01, 0.0, 0.0, 0.42, -0.44, 0.52, -1.3, 0.23, -0.84, -0.95, -0.8, -1.3, -0.64, -1.3, -0.86, -1.07, -0.82, -0.82, -0.77, -1.52, -1.07, -1.17, -1.02, -1.52, -0.86, -1.52, -1.08, -1.3, -1.04, -1.05, 0.14, -1.12, 1.1, -0.46, -0.11, 0.04, -0.46, 0.21, -0.46, -0.02, -0.23, 0.02, 0.02, -3.04, -0.35, 0.15, -0.35, 0.31, -0.35, 0.09, -0.12, 0.13, 0.12, -0.02, -0.46, 1.24, -0.1384018193170985, -0.10482093036566006, -0.21, -0.5, -0.5, 0.16, -0.5, -0.06, -0.27, -0.02, -0.03, -0.33, 0.0, 0.67, 0.0, 0.45, 0.23, 0.49, 0.48, -0.79, -0.82, 0.3, -0.48, -9.03, 0.06, -0.06, 0.54, -0.56, -0.28, 0.08, -0.34, 0.08, 0.37, 0.13, -1.43, -0.06, -0.52, 0.43, 0.53, -0.14670919513614705, 0.86, -0.37, -1.72, 0.87, -1.46, 1.05, 0.95, 1.5, -0.14, -0.66, -0.66, -0.22, -0.43, -0.18, -0.19, -0.55, 0.0, 0.45, 0.23, 0.48, 0.48, -0.44, -0.22, 0.04, 0.03, 0.0, 0.28, -0.23, 0.25, 0.25, -0.18, -0.22, -0.88, 0.13, 0.0, -0.18, -1.042736189475567, -0.23, -0.48, 0.06278685149693167, -0.17, 0.03, 0.1, 0.19, -0.11, -0.48, -1.5, -1.07, -0.5], ['318', -3.31, 0.45, -0.02, -0.18, 0.65, 0.10841962367375949, 1.64, 0.1, 0.34, 0.03, -0.17, -1.21, 0.17, 0.25, -0.71, 1.64, -0.72, -0.05, -2.71, -1.17, -0.43266451791264104, -0.06, -0.83, -0.5, -0.41, 0.0, 0.2, -1.04, 0.34, 0.42, -0.54, 1.81, -0.55, 0.13, -2.55, -1.0, -0.3, 0.11, -0.66, -0.33, 0.4, 0.07, 1.26, 1.4, 1.48, 0.51, 2.89, 0.5, 1.18, -1.52, 0.04, 0.75, 1.16, 0.39, 0.73, -0.18, -0.21, 0.40782797280978395, 0.03, -0.14, 0.08, -0.88, 1.47, -0.89, -0.21, -2.88, -1.2160242664664933, -0.64, -0.23, -1.0, -0.66, -0.14, -0.22, -0.96, 1.39, -0.97, -0.29, -2.95, -1.41, -0.72, -0.31, -1.07, -0.74, 0.27, 2.55, -2.6, 0.7866982383853202, 2.37, -0.01, 0.67, -2.01, -0.46, 0.24, 0.65, -0.12, 0.27400772752445063, -2.69, -1.58, -2.32, -1.66, -4.28, -2.76, -2.08, -1.67, -2.43, -2.1, -0.06, -1.63, 1.15572371188304, 0.49, 0.54, 0.535673518650032, 0.76, 0.68, -2.0, -0.45, 0.25, 0.66, -0.11, 0.23, 0.12, 0.07, -2.67, -1.12, -0.43, -0.02, -0.78, -0.45, 0.97, 0.89, -0.38, 0.713186783623568, -7.99, 0.29, 0.07, -0.89, 0.971720125812563, 0.39, -0.08, 1.19, -2.48, -0.99, -0.52, -1.73, 0.15, 1.46, -1.46, -1.51, 0.5, -1.27, 0.99, 2.04, -1.03, 2.27, -4.02, -1.5, -2.23, 2.52, 2.82, 1.59, 2.3, 2.72, 1.94, 2.28, 1.48, 1.21, 0.7, 1.12, 0.34, 0.68, 0.5, 0.41, -0.36, -0.02, 0.36, 0.17, 0.09, -0.77, -0.43, 0.52, 0.56, 0.02, -2.07, 1.1, 2.1, 0.66, 1.26, 0.86, 0.34, 0.99, 0.47, -0.38, 0.23, 0.06, 0.615957527023814, 0.78, 1.84, 1.03], ['319', 0.1, 0.3, 0.13122171562045873, -0.14, 0.05, 0.23, 0.9241152579598292, 0.73, 1.12, 1.61, 0.63, 0.73, 0.53, 1.48, 0.74, 2.15, 1.09, 1.01, 8.25, 2.016979591836735, 2.02, 1.11, 0.67, 0.94, -0.28, 0.37, 0.97, 0.1, -0.1, 0.84, 0.1, 1.51, 0.45, 0.37, 7.57, 1.785112244897959, 1.38, 0.47, 0.03, 0.3, 2.4, 3.0049361992161736, 0.86, -0.2, 0.74, 0.0, 1.4, 0.35, 0.27, 7.46, 1.23, 1.308065468086443, 0.37, -0.07, 0.2, 0.07, 0.38, 1.54, 0.79, 1.07, 0.94, 0.21, 1.61, 0.55, 0.47, 7.68, 1.43, 1.48, 0.58, 0.13, 0.4, 1.52, 0.12, -0.73, 0.66, -0.39, -0.47, 6.67, 0.49, 0.53, -0.36, -0.8, -0.54, 1.73, 2.48, -2.4640000000000004, 0.86, 1.4, 0.34, 0.27, 7.45, 1.423744771101914, 1.27, 0.37, -0.07, 0.2, -2.217904761904762, -0.53, -1.04, -1.12, 5.97, -0.17, -0.13, -1.02, -1.45, -1.19, 0.36, -0.39063179677465387, -0.37, 0.46, 0.35, 0.68, 0.51, -0.08, 7.09, 0.88, 0.92, 0.03, -0.41, -0.15, 0.65, 0.59, 7.17, 0.96, 1.0, 0.1, -0.34, -0.07, -0.28, -0.53, -0.13, 0.9, -6.93, 0.65, 0.36, -1.29, 1.28, 0.63, 0.76, 0.14, 0.76, -0.96, -0.49, 0.07, -0.12, 1.57, -1.58, -1.4, 0.45, -2.04, 0.94, 2.97, -1.46, 1.56, -4.13, -1.1, -1.6, -0.8, -6.14, -5.8, -5.75, -6.59, -7.0, -6.76, 1.4, -0.36, 0.04, -0.85, -1.28, -1.02, -0.4, -0.89, -1.33, -1.06, 1.04, 1.22, 0.49, -0.44, -0.17, 0.5, 0.57, 0.85, -1.96, 0.13, 2.15, -0.03, 0.37, 0.93, 0.27, 0.95, 0.6, 0.32, -0.86, -0.03, 0.66, 0.6, -0.61, 1.05], ['320', 3.3242857142857143, 0.11, 0.08, 0.04, -0.2270209190089404, 0.75, 1.74, 0.44, 0.6, -0.29, -0.25, -1.65, 0.42, -0.66, -0.27, -1.67, -0.77, -0.59, -0.14, -0.43, -0.36, -0.7, -0.51, -0.9848833725798009, -0.11, 0.21, -0.04, -1.4, 0.67, -0.41, -0.01, -1.1049642857142856, -0.52, -0.33, 0.12, -0.18, -0.11, -0.45, -0.26, -0.88, -0.15, 0.58, 1.38, 2.11, 1.01, 1.41, -0.02, 0.9, 1.08, 1.54, 1.24, 1.31, 1.0538655564790018, 1.16, 0.53, 0.63, 0.29, 0.45, 0.51, -0.71, -1.08, -0.68, -2.08, -1.19, -1.0, -0.55, -0.85, -0.6165788457574171, -1.12, -0.93, -1.55, 1.17, 0.37, 0.4, -1.02, -0.11, 0.07, 0.7774764481550197, 0.23, 0.3, -0.04, 0.15, -0.48, 0.34, 0.78, -0.8, -0.03, -1.41, -0.5, -0.32, 0.3657885487528346, -0.16, -0.09, -0.44, -0.25, -0.87, 1.48, 1.4, 0.91, 1.1, 1.56, 1.26, 1.33, 0.98, 1.18, 0.54, 0.19, 1.42, 3.56, 0.49, 0.47, 0.47, 0.48, 0.19, 0.64, 0.34, 0.41, 0.07, 0.26, -0.37, 0.48, 0.29, 0.45, 0.16, 0.23, -0.12, 0.07, -0.55, 0.28, 0.37, -0.11, 0.39, 4.29, 0.12, 0.2, -0.6, 0.58, 0.3, 0.47, 0.69, -0.52, -0.98, -0.46, 1.3, 0.32, 1.36, -1.45, -1.44, 0.48, -0.98, 0.94, 0.51, -0.23, 1.37, -0.18, -0.85, -1.34, 0.14, -0.16, -0.29, -0.22, -0.57, -0.38, -1.0, 1.45, 0.14, 0.07, -0.27, -0.09, -0.71, 0.07, -0.34, -0.15, -0.78, 0.56, 0.58, 0.41, 0.19, -0.44, 0.45, 0.44, 0.52, 0.16, 2.92, -1.15, 0.94, 0.82, 0.22, -0.62, 0.6, 0.58, 0.09, 0.27, 0.11, 0.85, 0.49, 0.39, 0.17], ['321', 0.81, -0.23, -0.009847101690729465, 0.02, -0.45, 0.39, 1.74, 0.0, 0.87, 0.23, -0.45, -1.4, 0.27, 1.46, 0.5, -0.07, 0.08, 0.24, -0.93, 1.33, 0.61, -0.29, -0.07, -0.81, 0.83, -0.14, 0.68, -0.95, 0.73, 1.93, 0.96, 0.38, 0.54, 0.69, -0.48, 1.8, 1.07, 0.16, 0.38, -0.36, 0.04, 0.65, 1.65, 1.7, 2.91, 1.93, 1.35, 1.51, 1.66, 0.5771355564861204, 2.78, 2.04, 1.13, 1.35, 0.6, 0.5600628463056766, 0.14, 1.14, 0.54, -0.05, 1.19, 0.23, -0.34, -0.19, -0.04, -1.2, 1.06, 0.34, -0.56, -0.34, -1.08, -0.22, -1.22, -0.95, -1.52, -1.36, -1.21, -2.36, -0.13, -0.84, -1.73, -1.51, -2.24, 0.69, 1.06, -1.07, -0.27, -0.57, -0.42, -0.26, -1.43, 0.83, 0.11, -0.79, -0.57, -1.3, -0.92, 0.3, 0.15, 0.31, -0.86, 1.41, 0.68, -0.22, 0.0, -0.74, 0.04, 0.33, 0.22, 0.36, 0.43, 0.35, 0.14, 0.15, -1.01, 1.25, 0.53, -0.37, -0.15, -0.89, 0.45, -0.01, -0.9063144197072766, 1.1, 0.37, -0.4042004503433073, -0.31, -1.04, -0.22, -0.51, 0.12, 0.3, -3.27, 0.12, 0.03, 0.32, -0.21, -0.13, 0.0, -1.3, 2.16, -0.75, -0.36, 0.37, 0.38, 1.12, -1.02, -1.06, 0.35, 0.38, 0.73, -0.43, 0.23, 0.53, -1.72, -0.3, -0.49, -2.14, 1.17, 2.29, 1.55, 0.64, 0.87, 0.12, 1.12, -1.09, -0.72, -1.61, -1.39, -2.12, -0.38, -0.9, -0.68, -1.41, 0.82, 0.68, 0.52, 0.22, -0.52, 0.4720800343140569, 0.38, -0.05, -0.21, 0.4401996269574993, 0.12, 0.54, 0.33, 0.3, -0.74, 0.26, -0.46, 0.57, 0.12, 1.03, 1.04, -0.79, 0.05, 2.48], ['322', -0.37, -0.77, 0.0, 0.1, -1.75, -0.42158037632624057, -0.7158847420401708, -1.1382794034640413, -1.19, -0.8, 1.2, -0.21, 0.07, 0.31, 1.07, -0.3, 0.23, -0.78, 5.03, 2.15, -0.91, -0.26, 0.79, -0.13, -0.81, -1.24, -1.9373416050068875, -1.39, -1.11, -0.87, -0.12, -1.48, -0.95, -1.95, 3.79, 0.94, -2.08, -1.44, -0.4, -1.31, -3.05, -2.92, -0.59, 0.29, 0.52, 1.29, -0.09, 0.45, -0.57, 5.25, 2.36, -0.7, -0.05, 1.0, 0.08, -0.45, -1.32, -2.6, -0.76, -0.87, 0.3431047225355606, 1.0, -0.37, 0.16, -0.85, 4.95, 2.07, -0.99, -0.34, 0.71, -0.21, -1.15, -1.11, 0.76, -0.61, -0.08, -1.08, 4.7, 1.83, -1.22, -0.57, 0.47, -0.44, -1.93, -4.43, 4.38, -1.85, -1.36, -0.83, -1.83, 3.91, 1.07, -1.96, -1.32, -0.28, -1.1359922724755493, -1.08, -0.5, 0.54, -0.48, 5.34, 2.46, -0.61, 0.04, 1.09, 0.17, -0.2, -0.49, -2.38, -0.77, -0.84, -0.67, -1.03, -1.01, 4.78, 1.91, -1.14, -0.5, 0.55, -0.3114153161169343, -0.57, -0.03, 5.85, 2.95, -0.14, 0.52, 1.57, 0.65, -1.57, -1.51, 0.27603717887804047, -0.81, -3.11, -0.28, -0.28, 1.74, -1.74, -0.88, -0.32, -1.5, 5.77, 1.52, 0.78, -0.22, -0.23692021013122094, -2.21, 2.22, 2.28, -0.76, 2.8, -1.53, -1.34, 0.64, -3.07, 7.08, 1.98, 3.11, -5.69, -5.55, -2.74, -5.66, -5.04, -4.04, -4.91, -2.34, -2.89, -3.0, -2.36, -1.33, -2.23, 0.11, 0.66, 1.72, 0.79, -1.24, -1.31, -0.54, 1.05, 0.13, -0.78, -0.6956036987247092, -1.22, 3.58, -1.66, -3.61, -0.9, -1.01, -1.58, -0.91, -0.56, -0.77, -0.42, -0.01, -0.11, -0.67, -1.02, -2.05, -0.9], ['323', 7.08, 0.06, -0.23877828437954127, 0.05, 0.65, -0.17, 0.71, 0.4, -0.12, 0.77, 1.52, -0.17, -0.07, 1.39, 0.69, -0.3792857142857143, 1.06, 1.3205714285714287, 1.48, 0.27, 0.87, 0.8730748299319728, 1.15, 0.75, 0.23, 0.27, -0.73, -1.67, -1.57, -0.13, -0.82, -1.87, -0.44857142857142857, -0.2, -0.03, -1.23, -0.64, -0.64, -0.37, -0.76, 0.73, -0.74, 0.95, 0.1, 1.56, 0.86, -0.1889563492063492, 1.23, 1.49, 1.66, 0.44476190476190475, 1.04, 1.05, 1.32, 0.9250476190476191, 0.6700628463056766, 1.0842857142857143, 0.38, -0.32, 0.84, 1.46, 0.76, 0.3385714285714286, 1.13, 1.39, 1.56, 0.34, 0.94, 0.94, 1.22, 0.82, 1.31, -0.61, -0.69, -1.3133418367346938, -0.32, -0.07, 0.1, -1.1, -0.52, -0.51, -0.24, -0.63, -0.66, -0.85, 0.87, 0.09, -1.06, 0.37, 0.63, 0.79, -0.42, 0.18, 0.2757142857142857, 0.46, 0.06, 1.932095238095238, 1.16, 1.4528571428571428, 1.71, 1.88, 0.65, 1.25, 1.502816996495568, 1.54, 1.13, -0.66, 1.21, 0.65, -0.12, -0.37, 0.05, -0.28, 0.25, 0.42, -0.79, -0.19, -0.19, 0.08, -0.31, -0.02, -0.54, 0.17, -1.04, -0.45, -0.44, 0.41999999999999993, -0.56, -0.49, -0.13, -0.26, -0.29, 4.0, -0.1319304505018789, -0.47, -0.63, 0.55, 0.33, 0.0, 1.12, -1.1, 0.27, 0.14142857142857143, 3.51, -0.25, -0.38, 0.36, 0.38, -0.11, -0.8, -0.24, -0.7516093450200592, 0.48, -0.84, -2.95, 0.56, 0.97, 1.07, -0.7, -1.2, -0.61, -0.6, -0.33, -0.73, -0.31, 0.5, 0.6, 0.6, 0.9298095238095239, 0.48, -0.09, 0.01, 0.28, -0.12, -0.11, -0.51, -0.1, 0.27, -0.12, -0.11, -0.15, 0.52, -1.5, 0.38, 1.18, -0.31, -0.7, -0.37, -0.4, -0.53, 0.0, 0.43, -0.79, 0.43, 0.03, -0.38, -0.44, -0.57], ['324', -1.5, -0.19, 0.1, -0.06, -0.4, 0.19841962367375948, 1.17, -0.69, 0.05, -1.31, -1.08, -2.25, -0.39, -0.74, 0.3, -1.07, -1.82, -1.4, -2.68, -1.34, -1.66, -1.48, -1.61, -1.83, -0.54, -1.05, -0.24, -1.19, 0.7, 0.34, 1.39, 0.01, -0.75, -0.32, -1.62, -0.27, -0.5155463299214309, -0.41, -0.53, -0.76, -0.9, -0.9450638007838266, 0.96, 1.91, 1.55, 2.61, 1.21, 0.44, 0.87, -0.43, 0.93, 0.6, 0.79, 0.66, 0.44, -0.41, -0.29, 0.37, 0.55, -0.93, -0.35, 0.69, -0.69, -1.43, -1.01, -2.3, -0.96, -1.28, -1.1, -1.22, -1.44, -0.3, -0.58, 1.04, 0.09665816326530619, -1.09, -0.66, -1.95, -0.61, -0.93, -0.75, -0.87, -1.1, -0.18, 0.97, -1.03, -1.61, -1.37, -2.11, -1.69, -2.97, -1.64, -1.96, -1.78, -1.9, -2.12, -2.51, -0.24, -0.75, -0.33, -1.62, -0.27, -0.6, -0.42, -0.54, -0.76, 0.06, -0.25, 0.83, 0.24, 0.30517906963433994, 0.38567351865003197, 0.51, 0.43, -0.88, 0.48, 0.16, 0.34, 0.22, -0.01, 0.09, 0.09, -1.3, 0.06, -0.27, 0.035799549656692686, -0.21, -0.43, 0.48, 0.57, -0.07, 0.41, -7.41, 0.11, 0.13, -0.38, 0.39, 0.23881017100762114, 0.16, -0.8, -0.07, -0.45, -0.24, -0.74, 0.32, 0.69, -0.79, -0.67, 0.22, -0.59, 0.5298783572413152, 0.25, -0.15, 1.53, -1.25, -1.04, -1.56, 0.07380952380952381, 1.4, 1.37, 1.04, 1.23, 1.1, 0.87, 0.6808051948051949, 0.03, -0.32, -0.14, -0.27, -0.49, 0.36, 0.18, 0.06, -0.17, 0.05, -0.08, 0.17, -0.13, -0.35, 0.24, 0.28, -0.69, -0.86, 0.5, 0.98, 0.0, -0.11, 0.3, -0.22, 0.43, 0.25, 0.27, 0.37, 0.11, 0.52, -1.53, -0.12, 1.3130167737073972], ['325', -2.51, -0.06, 0.02, -0.24, 0.18, -0.05, -4.53, -0.97, -1.18, -0.36, 0.05, 3.4, 0.26, 0.26, 0.98, -0.6, 1.02, 0.02, -0.45, -0.07, -0.01, -0.18, -0.03, 0.19, -0.24, -0.33, -0.41, 3.35, 0.21, 0.22, 0.93, -0.65, 0.97, -0.03, -0.48223809523809524, -0.12, -0.06, -0.23, -0.08, 0.14, -1.0745146341753484, -0.8350638007838266, -3.64, -3.04, -3.03, -2.34, -3.87, -2.3, -3.27, -3.72, -3.36, -3.3, -3.46, -3.32, -3.11, -1.0, -0.8, -0.15, -0.49, -0.62, 0.11310472253556063, 0.72, -0.85, 0.76, -0.24, -0.709047619047619, -0.33, -0.27, -0.43, -0.29, -0.07, -0.78, -0.62, 0.71, -0.86, 0.75, -0.25, -0.71, -0.34, -0.27, -0.44, -0.3, -0.08, -0.61, -1.29, 1.25, -1.33, -1.5594795918367348, 0.04, -0.95, -1.42, -1.04, -0.98, -1.15, -1.0, -0.78, -1.27, 0.3173665312165629, 1.63, 0.62, 0.15, 0.53, 0.59, 0.42, 0.57, 0.79, -0.46, 0.24, -1.51, -0.31, -0.31, -0.53, -1.37, -0.99, -1.46, -1.08, -1.02, -1.19, -1.04, -0.7614153161169342, -0.2, -0.38, -0.47, -0.09, -0.03, -0.19, -0.05, 0.41217743764172343, -0.91, -1.29, -0.11, -0.98, -3.74, -0.4264527417027417, -0.04, 1.12, -1.06, -0.55, -0.64, -1.0, 0.46, 0.61, 0.34, -1.28, -0.26, -0.91, 0.81, 1.02, -0.31, 1.6, -0.74, -1.26, 0.4547652642842468, -4.03, 0.28, 2.69, 3.99, -0.47286904761904763, 0.09, 0.38, 0.44, 0.28, 0.42, 0.64, -1.03, -0.29, 0.06, -0.1, 0.04, 0.26, -0.35, -0.17, -0.02, 0.2, -1.23, -0.41, -0.18, 0.15, 0.37, -0.33, -0.49, -0.7274239503761217, 0.5, -1.45, -0.55, -0.88, -0.1, -0.33, 0.22, -1.08, -0.46, -0.1, -0.2, -0.07, -0.55, -2.01, -0.98, -0.88], ['326', 2.43, 0.7, -0.15877828437954128, -0.24, 0.4529790809910596, 1.01, 1.5541152579598292, 0.83, 1.01, 0.81, -0.66, -0.04, -0.56, 0.34, 0.86, 0.54, -0.11, 0.56, 4.47, 0.23071428571428573, 0.43, 1.7, -0.6, -0.13, 1.49, 0.88, 1.47, 0.62, 0.09, 1.0, 1.52, 1.2, 0.54, 1.22, 5.16, 0.8907142857142857, 1.09, 2.38, 0.05, 0.53, 0.93, 0.94, 0.85, -0.53, 0.38, 0.89, 0.58, -0.08, 0.6, 4.51, 0.27, 0.47, 1.74, -0.57, -0.09, 0.8500628463056766, 0.72, 0.94, 1.16, 1.4592452470658774, 1.0131047225355607, 1.43, 1.11, 0.45, 1.13, 5.06, 0.8, 1.0, 2.28, -0.04, 0.44, 0.5, 0.47, 0.51, 0.2, -0.46, 0.22, 4.11, -0.11, 0.09, 1.36, -0.94, -0.47, 1.35, 3.43, -3.2971666666666666, -0.05, -0.31, -0.96, -0.29, 3.58, -0.62, -0.42, 0.84, -0.9974829931972791, -0.9259922724755494, 1.89, 0.27, -0.65, 0.02, 3.91, -0.31, -0.11, 1.16, -1.14, -0.67, 0.16, 0.33, 1.07, 1.01, 1.06, 0.87, 0.93, 0.68, 4.59, 0.35, 0.55, 1.82, -0.49, -0.02, -0.79, 0.3030767481303673, 3.89, -0.33, -0.13, 1.14, -1.1542857142857141, -0.69, 1.65, 0.49, -0.37, 0.64, 3.71, -0.1, -0.02, -0.79, 0.8, 0.4, 0.34, 2.52, -1.17, -1.99, -1.0, 1.19, 0.66, 2.87, -2.89, -2.9, 1.0, -1.26, 2.05, 1.31, -0.68, 2.76, -6.94, -1.92, -2.77, 1.15, -3.5, -4.06, -3.87, -2.65, -4.86, -4.4, 3.03, 0.58, 0.2, 1.47, -0.83, -0.36, 0.38, 1.27, -1.03, -0.56, 1.05, 1.4184535464535466, -0.88, -2.27, -1.8, 1.07, 0.97, 0.73, -3.43, 1.45, 3.45, 1.89, 1.5, 1.42, 0.48, 0.92, 0.4845528598385743, 0.92, 0.14, 1.48, 0.94, 1.61, 1.77, 1.67], ['327', 0.17, 0.06, 0.22, -0.15, -0.09, 0.39, 0.03, 0.05172059653595872, -0.05, -0.84, -0.1, -1.1, -1.01, -0.72, -1.09, -1.11, -0.71, -0.81, 0.54, -0.52, -0.98, -1.17, -1.3, -1.04, 0.72, 0.21, -0.73, -1.0, -0.91, -0.62, -0.99, -1.01, -0.61, -0.71, 0.65, -0.42, -0.88, -1.06, -1.2, -0.94, 0.0, -1.49, 0.27, 0.09, 0.38, 0.01, -0.01, 0.39, 0.29, 1.66, 0.59, 0.12, -0.07, -0.2, 0.06, -0.54, 1.11, 0.0, -0.11, 0.18, 0.29, -0.09, -0.1, 0.3, 0.2, 1.57, 0.49, 0.03, -0.16, -0.3, -0.04, 0.35, -0.11, -0.37, -0.39, 0.01, -0.09, 1.28, 0.2, -0.26, -0.45, -0.58, -0.32, -0.62, 1.07, -1.07, 0.26, -0.02, 0.38, 0.29, 1.66, 0.58, 0.12, -0.07, 0.24251700680272095, 0.05, 0.68, 0.3573665312165629, 0.4, 0.3, 1.68, 0.6, 0.13, -0.05, -0.19, 0.07, 0.01, 0.27, 0.4, 0.11, 0.29, -0.11, -0.12, -0.1, 1.27, 0.19, -0.27, -0.45, -0.59, -0.27141531611693437, 0.37, -0.02, 1.37, 0.38224471370562696, -0.17, -0.36, -0.49, -0.24, 0.34, -0.15, -0.16, 0.03, 1.86, 0.05, -0.07, 1.63, -1.44, -0.7, 0.18, 0.37, 0.6, -0.23, -0.15, 0.07, 0.05, 0.2, -0.34, -0.36, 0.11, 2.15, 0.21, 1.71, -0.88, -0.01360430839002269, -2.67, 0.26, 0.45, -0.6, -1.37, -0.7328212224283652, -1.52, -1.7, -1.84, -1.58, 0.39, -0.32, -0.46, -0.65, -0.78, -0.53, 0.15, -0.19, -0.32, -0.07, -0.03, -0.44, 0.33, -0.14, 0.12, 0.09, 0.08, 0.02, -1.21, 0.21, 1.24, 0.7172638105244333, 0.3, 0.47, 0.26, 0.3, -0.69, 0.54, -0.21, 0.05, 0.295957527023814, 0.13, 0.58, -0.18], ['328', 6.37, 1.05, 0.92, -0.32, 2.17, 2.41, 2.1941152579598295, 4.28, 3.65, 3.38, -2.19, 1.09, -0.24, -0.84, -1.41, 1.07, -0.46, 1.123469387755102, 2.19, -0.02, 5.13, -0.45, -0.49, 0.21, 4.43, 3.88, 5.7, 3.35, 2.0, 1.38, 0.8, 3.33, 1.77, 3.38, 4.48, 2.22, 7.490760683760684, 1.78, 1.74, 2.45, 3.56, 6.48, 2.27, -1.31, -1.91, -2.47, -0.02, -1.42071768707483, 0.03, 1.09, -1.09, 4.0, -1.52, -1.56, -0.87, 2.36, 4.44, 3.53, 3.23, 3.63, -0.61, -1.17, 1.31, -0.22, 1.35, 2.43, 0.22, 5.38, -0.22, -0.25, 0.45, 4.6, 4.26, -0.57, 1.93, 0.39, 1.97, 3.06, 1.1491309523809523, 6.03, 0.39, 0.36, 1.06, 5.02, 10.76, -10.89, 4.86, 2.51, 0.97, 2.56, 3.65, 1.41, 6.64, 1.597142857142857, 0.93, 1.64, 3.02, 2.29, -1.51, 0.04, 1.1, -1.08, 4.02, -1.51, -1.54, -0.85, 1.96, 2.29, 3.17, 2.86, 2.91, 2.97, 3.85, 1.57, 2.65, 0.44, 5.61, 0.0, -0.03, 0.67, 3.69, 2.24, 1.06, -1.12, 3.98, -1.55, -1.58, -0.89, 3.96, 4.67, 0.13, 3.36, 6.17, 1.13, 0.88, -6.18, 6.17, 3.09, 2.48, 5.41, -6.64, -5.77, -2.89, 3.11, 2.06, 8.83, -8.7, -8.5, 2.84, -9.27, 5.76, 2.99, -1.51, 11.77, -10.43, -7.7, -11.45, 6.81, 1.17, -1.8328212224283653, 2.88, -2.58, -2.62, -1.94, 8.64, 3.4, 5.15, -0.43, -0.47, 0.23, -1.67, -5.31, -5.35, -4.69, 3.68, 4.34, 3.85, -0.03, 0.66, 2.95, 3.004396301275291, 4.31, -5.31, 4.19, 5.42, 3.67, 4.3210935020800125, 3.968637448200971, 0.7, 3.01, 2.68, 1.36, 1.89, 2.39, 3.17, 4.91, 7.18, 3.13], ['329', 0.62, 0.04, -0.49, 0.2, -0.2, 0.38, 0.64, 1.15, 1.15, 1.8, 0.07, 0.57, 0.7, 1.29, 0.04, 1.69, 0.97, 1.59, 3.55, 1.86, 2.15, 1.51, 1.3, 1.73, 1.08, 0.51, 1.73, 0.49, 0.63, 1.22, -0.03, 1.61, 0.9, 1.52, 3.47, 1.79, 2.08, 1.43, 1.23, 1.66, 1.05, 2.45, 1.23, 0.13, 0.72, -0.45918497042472345, 1.11, 0.4, 1.02, 2.961652133580705, 1.29, 1.58, 0.93, 0.8271428571428572, 1.16, 1.15, 1.69, 1.44, 0.87, 1.1792452470658776, 0.59, -0.66, 0.98, 0.27, 0.89, 2.83, 1.15, 1.44, 0.8, 0.6, 1.03, 0.14, 0.5, -1.2253571428571428, 0.39, -0.32, 0.29, 2.22, 0.56, 0.85, 0.21, 0.01, 0.43, 1.6, 2.12, -2.15, 1.76, 1.65, 0.93, 1.55, 3.51, 1.82, 2.12, 1.47, 1.26, 1.7440077275244505, -0.51, 0.11, -0.71, -0.09, 1.83, 0.17, 0.46, -0.18, -0.38, 0.04, 0.13, 0.13244557823129252, 0.88, 0.63, 0.56, 0.76, 0.83, 0.62, 2.55, 0.88, 1.17, 0.53, 0.33, 0.8185846838830657, 0.24, 0.21, 2.173685580292723, 0.26, 0.7286030199958774, -0.09, -0.28, 0.14, 0.2189583699631245, 0.34, 0.44, 0.53, -1.71, 0.01, -0.66, -1.62, 1.73, 0.61, 0.06, 2.85, -0.09, -1.22, -0.61, 0.25, 0.11, 1.85, -1.93, -1.81, 0.11, -2.53, 1.26, -1.14, 0.58, 2.5, -3.34, -1.68, -2.47, 0.04, -1.68, -1.63, -1.34, -1.97, -2.17, -1.75, 1.84, -0.06, 0.29, -0.35, -0.55, -0.13, -0.34, -0.64, -0.83, -0.41, 1.2, 1.22, 0.29, -0.2, 0.22, 0.6, 0.66, 1.12, -1.55, 0.4, 1.42, 0.5172638105244333, 0.46, 0.49, 0.42, 0.03, 0.5, -0.59, -0.5, -0.03, 0.07, 0.58, 1.46, 0.33], ['330', 0.41, 0.0, 0.24122171562045874, 0.19, -0.3, 0.14, -1.2158847420401708, -0.9482794034640413, -0.55, -3.51, -2.75, -2.98, -3.07, -2.81, -2.29, -3.53, -3.38, -3.44, -0.71, -2.53, -3.762664517912641, -3.46, -4.1, -3.82, 0.29, -0.21, -0.78, -0.23, -0.33, -0.06, 0.47, -0.79, -0.64, -0.7, 2.1, 0.23, -1.07, -0.72, -1.2811203865609546, -1.1, -0.38, -1.5950638007838267, -0.55, -0.09, 0.17, 0.71, -0.56, -0.41, -0.47, 2.34, 0.46, -0.811934531913557, -0.49, -1.15, -0.87, -0.14, -0.59, -0.9, -0.79, -0.45, 0.27, 0.8, -0.47, -0.32, -0.2773949338599383, 2.43, 0.55, -0.75, -0.4, -1.06, -0.78, -1.67, -0.72, 0.53, -0.74, -0.59, -0.65, 2.16, 0.28, -1.01, -0.67, -1.33, -0.9864403582748793, -0.85, 1.33, -1.4, -1.24, -1.26, -1.11, -1.17, 1.62, -0.24832539682539684, -1.54, -1.19, -1.85, -1.57, -0.44, 0.02, 0.15, 0.09, 2.92, 1.03, -0.28, 0.07, -0.59, -0.31, -0.06, -0.03, 1.34572371188304, 0.17, 0.26, 0.02, -0.13, -0.06, 2.76, 0.88, -0.43, -0.08, -0.74, -0.46, -0.07, -0.08, 2.82, 0.94, -0.37, -0.02, -0.68, -0.4, 1.04, 0.67, 0.3460371788780404, 0.02, -1.41, 0.13, -0.03, -0.15, 0.1, 0.06, 0.14, 0.39, 1.89, -0.39, -0.19, 0.2, 0.05, 0.48, -0.49, -0.45, 0.18, -0.31, 0.33, -2.021609345020059, 1.084765264284247, -0.45, 0.06, 0.24, 0.43, -1.98, -2.82, -1.84, -3.11, -2.7283894557823127, -3.403248299319728, -3.13, 0.48, -1.0, -1.29, -0.95, -1.6, -1.32, 0.3, 0.35, -0.31, -0.03, -0.58, -0.82, -0.05, -0.66, -0.38, 0.16, 0.11, -0.97, -0.48, 1.48, 0.57, 0.15726381052443328, -0.17, 0.61, 0.29, 0.3100774025227807, 0.1, 0.09, -0.2, 0.17462624382472908, 0.33, -1.57, 0.07, 0.46], ['331', 3.79, 2.18, 0.25122171562045875, -0.19, 0.52, 1.7, 2.63, 1.69, 1.12, 2.48, 1.82, 0.52, 0.79, 1.41, -0.95, 1.65, -0.21, 1.73, 6.53148185941043, 1.12, 2.36, 1.69, 0.31, 0.91, 0.83, 1.259371414588892, 0.65, -1.28, -1.01, -0.4, -2.72, -0.17, -1.99, -0.09, 4.61, -0.69, 0.53, -0.13, -1.48, -0.8561582768021608, 1.93, 0.79, 2.149303232481804, 0.27, 1.057875394446823, -1.46, 1.12, -0.73, 1.2, 5.97, 0.6, 1.83, 1.16, -0.21, 0.38, 0.4, 1.06, 1.18, 1.12, 1.67, 0.62, -1.73, 0.85, -0.99, 0.93, 5.68, 0.33, 1.56, 0.89, -0.48, 0.11, 2.13, 1.05, -2.33, 0.23, -1.6, 0.31, 5.03, -0.29, 0.94, 0.28, -1.09, -0.5, 0.33, 6.15, -6.06, 3.46, 2.62, 0.75, 2.7, 7.54, 2.09, 3.34, 2.66, 1.27, 1.9240077275244507, 1.49, 0.8973665312165628, -1.83, 0.08, 4.79, -0.52, 0.7, 0.04, -1.1788910216767359, -0.73, 0.85, 0.86, 1.99, 1.71, 1.65, 1.79, 2.69, 1.94, 6.74, 1.33, 2.58, 1.9603050194472875, 0.52, 1.12, 0.99, 0.74, 4.71, -0.6, 0.62, -0.04, -1.4, -0.81, 2.18, 2.72, 0.24603717887804044, 1.85, 4.83, 0.36, 0.21, -4.53, 4.57, 2.3, 2.53, 1.37, -2.72, -3.44, -1.74, 1.91, 1.34, 5.07, -5.1, -4.89, 1.72, -6.83, 3.42, 2.6, -1.31, 8.12, -15.54, -5.38, -8.02, 2.63, -3.79, -5.07, -3.9, -4.53, -5.83, -5.27, 5.17, 1.34, 1.23, 0.56, -0.8, -0.21, 0.11, -0.66, -2.01, -1.42, 1.192795351473923, 0.57, 0.78, -1.36, -0.77, 1.69, 1.79, 1.72, -8.15, 2.48, 8.28802380952381, 1.92, 0.99, 2.16, 0.6627868514969316, 1.85, 2.16, 1.81, 1.12, 1.2, 1.56, 2.19, 1.13, 0.37], ['332', 1.42, -0.11, 0.17122171562045874, 0.0, 0.97, 0.84, 1.11, 0.72, 0.43, 0.99, 0.47, 0.47899206349206347, -0.02, 0.41, 0.39, 0.37, -0.69, 0.57, 7.87, -1.49, 0.35, 0.01, 0.12, 0.05, 0.24, 0.54, 0.52, 0.0, -0.49, -0.06, -0.08, -0.09, -1.15, 0.21725890414440846, 7.36, -1.95, -0.04554632992143094, -0.46, -0.35, -0.42, -0.05, 0.40493619921617346, 0.52, -0.49, -0.06, -0.07, -0.09, -1.15, 0.11, 7.37, -1.95, -0.11, -0.46, -0.34, -0.42, -0.38, 1.54, 0.97, 0.52, 1.01, 0.5331047225355606, 0.42, 0.4, -0.67, 0.6, 7.89, -1.47, 0.38, 0.03, 0.14, 0.07, 0.38, 0.57, -0.02, -0.04, -1.1, 0.16, 7.43, -1.89, -0.06, -0.4, -0.29, -0.36, 0.61, 2.7, -2.76, 0.59, -0.02, -1.08, 0.18, 7.45, -1.6862552288980859, -0.04, -0.39, -0.27, -0.34, 0.37, 0.6873665312165629, -1.06, 0.2, 7.46, -1.86, -0.02, -0.37, -0.25, -0.33, 0.53, 0.63, 3.14, 0.96, 0.89, 1.1, 1.6909570400359875, 1.27, 8.62, -0.81, 1.05, 0.7, 0.8959878634155526, 0.74, 0.7, 0.41, 7.25, -2.05, -0.22, -0.56, -0.45, -0.52, 1.0, 1.25, 0.08603717887804044, 1.04, 1.15, 0.35, 0.25, -2.8, 2.81, 1.41, 0.45, 1.3761635321120496, -5.022241020883878, -1.92, -0.96, 0.79, 0.53, 2.970596861471862, -2.83, -2.84, 0.98, -4.24, 1.95, 0.5883906549799409, -0.23, 4.96, -4.7, -3.32, -5.03, 5.13, -6.38, -8.67, -6.97, -7.29, -7.18, -7.25, 2.89, 2.51, 1.87, 1.52, 1.64, 1.56, 0.63, -0.35, -0.23, -0.3, 0.47, 0.45, 0.98, 0.11, 0.04, 0.99, 1.1143963012752909, 0.82, -3.28, 2.28, 3.57, 0.87, 1.41, 0.86, -0.07, 1.22, 1.28, 0.44, -0.2566666666666667, 1.14, 1.025957527023814, 0.37, 1.71, 1.06], ['333', -16.58, -2.44, -0.77, 0.51, -3.42, -4.18, -2.705884742040171, -7.14, -4.23, -7.18, -2.04, -4.81, 0.05, -0.41, -0.8957142857142857, -4.311439909297052, -3.4771428571428573, -5.462517573696145, -6.28, -1.27, -8.22, -4.56, -3.32, -3.35, -6.12, -6.28, -5.25, -2.83, 2.13, 1.67, 1.16, -2.64, -1.47, -3.82, -4.33, 0.79, -6.31, -2.5, -1.31, -1.34, -4.82, -4.36, -2.49, 5.11, 4.63, 4.11, 0.21104365079365078, 1.4, -1.02, -1.54, 3.72, -3.58, 0.26, 1.57, 1.53, -4.69, -3.7799999999999994, -6.91, -4.88, -7.22, -0.45, -0.95, -4.47, -3.53, -5.83, -6.32, -1.32, -8.27, -4.61, -3.37, -3.4, -9.46, -6.8, -0.5, -4.176705782312926, -3.09, -5.4, -5.9, -0.87, -7.85, -4.18, -2.93, -2.96, -5.13, -13.79, 11.37, -6.34, -3.76, -2.6, -4.93, -5.43, -0.37, -7.39, -3.6842857142857146, -2.44, -2.47, -7.72, -2.67, 1.8285714285714285, -1.21, -1.73, 3.52, -3.76, 0.07, 1.37, 1.34, -1.44, -2.69, -5.48, -4.01, -3.87, -4.32, -3.83, -2.38, -2.9, 2.29, -4.91, -1.12, 0.17, 0.13, -2.71, -1.48, -0.53, 4.79, -2.59, 1.29, 2.6928571428571426, 2.58, -4.1, -2.4, 0.4, -4.34, -15.19, -2.0396768707482993, -1.24, 9.164285714285715, -8.57, -4.28, -0.92, -11.12, 11.68, 8.251428571428571, 4.064547619047619, -8.41, -2.84, -12.3, 12.967142857142857, 12.344285714285714, -4.03, 13.357142857142858, -8.03, -8.53, 4.15, -11.68, 22.44, 7.75, 11.54, -12.15, -0.96, 5.34, -2.07, 1.83, 3.15, 3.12, -12.14, -5.99, -7.04, -3.34, -2.08, -2.0185714285714282, 1.13, 3.98, 5.34, 5.538571428571428, -4.41, -4.74, -2.74, 1.3, 1.27, -3.96, -4.03, -7.3, 11.03, -5.29, -11.18, -6.05, -6.66, -3.99, -0.03, -4.34, -4.0, -2.81, -2.49, -3.08, -3.96, -7.61, -8.94, -3.38], ['334', 1.18, -0.12, -0.1, 0.25, 0.04, -0.24, -0.31, -0.07, -0.07, -0.8629115646258504, -1.87, -0.6406751700680272, 0.23, -0.64, -1.0, -1.73, -1.11, -1.38, -1.13, -1.37, -1.13, -1.45, -1.675694768399324, -1.21, 0.29, 0.78, 0.57, 1.24, 2.14, 1.25, 0.88, 0.14, 0.77, 0.5, 0.75, 0.51, 0.75, 0.43, 0.09, 0.67, -0.99, -0.24, -0.66, 0.89, 0.01, -0.35, -1.08, -0.46, -0.73, -0.48, -0.72, -0.48, -0.8, -1.13, -0.56, -0.2, -1.2, -0.4, -0.29, -1.53, -0.87, -1.23, -1.95, -1.34, -1.61, -1.35, -1.6, -1.35, -1.68, -2.0, -1.231743720565149, 0.6436060011417155, -0.67, -0.36, -1.09, -0.47, -0.74, -0.49, -0.73, -0.49, -0.81, -1.14, -0.57, 0.13, 0.75, -0.74, -0.30912907733800593, -0.74, -0.11, -0.39, -0.13, -0.37, -0.13, -0.45, -0.78, -0.21, 2.99, 0.5073665312165629, 0.63, 0.35, 0.61, 0.36, 0.61, 0.28, -0.05, 0.53, 0.09, 0.46, 1.24, -0.16, -0.01, -0.2, -0.12819052351387078, -0.27, -0.01, -0.26, -0.01, -0.34, -0.67, -0.1, 0.27, 0.07, 0.26, 0.01, 0.26, -0.07, -0.4, 0.17, -0.09, -0.47, 0.21, -0.05, 8.29, 0.25, 0.14, 1.56, -1.54, -0.81, 1.66, -0.64, -0.07, 0.35, 0.17, 0.61, 0.0, -0.61, 0.61, 0.57, -0.21, 2.43, -0.36, -1.25, 0.59, -0.54, 3.34, 0.35, 0.44, 0.06, -0.18, -0.25, 0.0, -0.28838945578231295, -0.66, -0.08, -0.55, 0.06, 0.25, -0.08, -0.41, 0.16, -0.18, -0.33, -0.65, -0.08, -0.12, 0.04, 0.14, -0.33, 0.31224875531501634, -0.19, -0.11, -0.12, 2.73, 1.64, -2.55, -0.36, -0.5088174603174603, 0.48, 0.57, 0.48, -0.41, 0.08, 0.59, -0.87, -0.1, -0.19, -0.93, 0.37], ['335', 4.68, -0.48, -0.04, 0.12, -0.49, -0.87, -0.38588474204017087, -1.06, -0.7, -1.1, -0.07, -0.99, 0.17, 0.72, -0.98, -2.04, -0.26, -0.92, 1.851481859410431, -0.02, -0.85, -0.74, -0.28, -0.41, -1.29, -0.88, -1.03, -0.92, 0.24, 0.79, -0.91, -1.97, -0.19, -0.85, 1.91, 0.05, -0.78, -0.67, -0.21, -0.2961582768021609, -0.06, -1.7650638007838266, -0.11, 1.18, 1.72, 0.01, -1.06, 0.74, 0.07, 2.861652133580705, 0.98, 0.168065468086443, 0.26, 0.72, 0.58, -0.42, -0.61, -0.98, -0.52, -1.27, 0.54, -1.15, -2.21, -0.43, -1.09, 1.66, -0.19, -1.03, -0.91, -0.45, -0.59, -0.7, -1.8, -1.68, -2.74, -0.97, -1.62, 1.12, -0.73, -1.56, -1.44, -0.99, -1.12, -1.23, -2.18, 2.13, -0.08330176161467984, -1.07, 0.73, 0.06, 2.85, 0.97, 0.13, 0.25, 0.71, 0.57, 0.4912233560090703, 1.047366531216563, 1.82, 1.15, 3.96, 2.07, 1.21, 1.33, 1.8, 1.66, -0.15, 0.93, -0.5, -0.8, -0.79, -0.73, -0.84, -0.66, 2.11015873015873, 0.24, -0.59, -0.48, -0.02, -0.15, -0.15346392892821453, -0.18, 2.78, 0.91, 0.07, 0.18, 0.65, 0.51, -1.11, -1.22, 0.20603717887804043, -0.7, 0.61, 0.03, 0.0, 1.49, -1.51, -0.75, 0.07406627346681526, -1.1938364678879505, 2.04, 1.62, 0.81, 2.35, -0.64, -2.43, 2.44, 2.35, -0.8, 2.3, -1.59, -1.1, 0.5747652642842468, -2.46, 5.36, 1.63, 2.46, -2.13, -2.88, -1.82, -2.64, -2.53, -2.08, -2.21, -2.42, -1.08, -0.83, -0.72, -0.26, -0.4, -0.25, 0.12, 0.58, 0.44, -0.65, -0.79, -0.36, 0.6532337781266354, 0.32, -0.79, -0.79, -1.01, 2.5, -0.5, -2.53, -1.56, -1.09, -0.82, -0.14, -0.81, -0.77, -0.75, -1.09, -0.28, -0.68, -1.8497593656343654, -2.01, -1.42], ['336', 4.03, -0.4, -0.36, 0.08, 0.62, -1.08, -0.71, -1.55, -2.05, -2.23, 0.68, -1.1392857142857142, -0.86, -1.62, -1.89, -2.06, -0.83, -1.75, -2.38, -2.08, -2.6, -1.0, -2.42, -1.1, -1.2, -0.35, -2.9, -1.81, -1.53, -2.29, -2.55, -2.73, -1.5, -2.42, -3.05, -2.728642857142857, -3.27, -1.67, -3.08, -1.78, -0.88, -1.7350638007838266, -1.1, 0.29, -0.49, -0.75, -0.93, 0.32285714285714284, -0.61, -1.26, -0.95, -1.48, 0.14, -1.2742857142857142, 0.04, -2.25, -1.04, -2.73, -2.86, -1.39, -0.77, -1.04, -1.21, 0.03, -0.9, -1.5228197278911566, -1.24, -1.76, -0.14, -1.57, -0.25, -1.67, 0.02571428571428569, -0.27, -0.44, 0.81, -0.13, -0.77, -0.47, -1.0, 0.6642857142857143, -0.81, 0.53, -2.51, -0.44, 0.53, -0.35, -0.18, 1.08, 0.17, -0.51, -0.2, -0.73, 0.91, -0.54, 0.8, 1.54, -0.18, 1.26, 0.32, -0.33, -0.03, -0.56, 1.08, -0.37, 0.97, -0.57, -0.16764311878597596, 0.86, -1.03, -0.96, -1.15, -1.42, -0.93, -1.57, -1.27, -1.79, -0.17, -1.6, -0.28, -1.4, -0.49, -0.3963144197072767, -0.34, -0.87, 0.76, -0.68, 0.65, 0.7, -0.85, 0.42, -1.47, 3.02, 1.17, 0.97, 2.33, -2.26, -1.12, -2.25, -1.91, 0.43, 2.06, 1.03, 2.21, -1.39, -3.14, 3.15, 3.01, -1.0, 3.47, -2.01, -1.5, 0.73, -4.27, 3.28, 3.0328571428571425, 4.1814285714285715, -0.28, 0.15, 0.3, -0.23, 1.461610544217687, -0.04, 1.31, -2.93, -0.15, -0.53, 1.11, -0.34, 1.0, 0.38, 1.65, 0.27, 1.54, -2.03, -2.55, -1.25, -1.43, -0.11, -0.99, -1.07, -1.58, 1.66, 0.29, -1.72, -0.42, -1.18, 0.19, 1.35, -1.3, -1.08, -1.09, -1.34, -1.48, -1.14, -0.4, -1.06, -1.2], ['337', 10.69, 2.9, -1.0587782843795412, 0.53, 0.68, -2.19, -2.39, -2.76, -3.83, -1.4529115646258504, 2.980608843537415, 1.08, 1.35, -0.8339200680272107, 2.07, -4.34, 0.46, -1.07, -1.61, -3.31, -2.62, -2.9769251700680273, 1.43, 0.26, -2.5214063389924735, -0.39, -4.697341605006888, -1.84, -1.5491666666666668, -3.99, -0.87, -7.1, -2.43, -3.92, -4.45, -6.1, -5.43, -5.7, -1.49, -2.63, -2.87, -6.33, -2.95, 0.27, -2.2, 0.99, -5.36, -0.30134863945578233, -2.12, -2.66, -4.34, -3.66, -4.01, 0.35, -0.81, -1.9, -3.7, -1.85, -3.69, -3.21, -2.46, 0.71, -5.62, -0.87, -2.38, -2.92, -4.6, -3.92, -4.27, 0.08, -1.08, -4.66, -0.7685714285714286, 3.25, -3.24, 1.6816609275411798, 0.08, -0.48, -2.19, -1.5, -1.86, 2.6, 1.42, -5.41, -8.31, 7.91, -3.9, -6.29, -1.58, -3.065714285714286, -3.61, -5.28, -4.6, -4.864285714285715, -0.63, -1.78, 3.88, 2.55, 5.03, 3.43, 2.8505714285714285, 1.7028571428571428, 1.8, 1.43, 6.04, 4.81, -1.04, 2.54, -5.36, -1.9, -1.88, -1.58, -2.36, -1.52, -2.07, -3.76, -3.07, -3.43, 0.96, -0.2, 0.81, -0.85, -0.55, -2.27, -1.57, -1.93, 2.52, 1.34, -4.32, -4.640438775510204, 0.61, -0.95, 7.72, -0.93, -0.8, 3.19, -3.19, -1.62, -1.55, -5.65, -2.98, 3.86, 1.92, 5.26, -1.16, -5.74, 5.87, 5.84, -1.92, 4.81, -3.78, 0.28, 0.02, -7.19, -4.93, -0.27, -0.06, 2.53, -0.3, -1.73, -1.02, -1.39, 3.09, 1.9, -5.69, 1.45, 0.71, 0.34, 4.900857142857143, 4.338571428571429, 0.74, -0.37, 4.16, 2.96, -3.73, -5.11, 1.11, 4.54, 3.34, -1.94, -1.89, -2.86, 6.04, -3.04, -7.28, -0.62, -1.07, -3.29, -1.15, -2.29, -1.46, -1.73, -0.03, -2.11, -2.16, -0.84, 0.48, -2.07], ['338', 3.83, -0.3, 0.12, -0.03, 0.45, 0.92, 0.6641152579598292, 1.25, 1.06, -1.02, -2.77, -1.47, -2.73, -2.38, -1.7, -2.35, -2.83, -1.47, 0.66, -1.04, -0.57, -0.8, -2.08, -2.18, 1.25, 1.45, 1.8, 1.34, 0.05, 0.4, 1.1, 0.44, -0.06, 1.34, 3.53, 1.78, 2.27, 2.03, 0.71, 0.61, 1.68, 1.8149361992161734, 0.46, -1.28, -0.93, -0.24, -0.89, -1.38, 0.0, 2.16, 0.43, 0.91, 0.7738655564790019, -0.62, -0.72, 0.83, 0.86, -0.74, 1.09, 1.76, 0.35, 1.05, 0.39, -0.1, 1.29, 3.507180272108844, 1.7302380952380951, 2.22, 1.98, 0.67, 0.56, 0.93, 1.4, 0.7, 0.04, -0.46, 0.94, 3.12, 1.37, 1.86, 1.62, 0.31, 0.21, 1.35, 3.351742947528662, -3.19, 0.7366982383853201, -0.66, -1.14, 0.24, 2.41, 0.67, 1.16, 0.92, -0.38, -0.49, 1.29, 1.36, -0.49, 0.9, 3.08, 1.34, 1.82, 1.59, 0.28, 0.17, 0.48, 1.35, -0.07, 0.5615981806829015, 0.98517906963434, 1.08, 1.86, 1.4, 3.59, 2.0397126881055456, 2.5057782534925392, 2.09, 0.77, 0.67, -0.24346392892821456, 0.46, 2.16, 0.43, 0.91, 0.68, -0.62, -0.72, 0.84, 1.09, 0.24, 1.2, 3.81, 0.12, -0.06, -2.53, 2.54, 1.3088101710076212, -2.44, 1.9961635321120494, -0.06, -1.96, -1.0, 1.92, 0.57, 2.91, -2.91, -2.91, 0.97, -3.87, 1.9698783572413152, 1.13, -0.56, 5.47, -10.92, -3.75, -5.55, 0.1, -1.67, -1.7, -1.22, -1.45, -2.72, -2.83, 2.88, 0.02, 0.48, 0.25, -1.04, -1.15, -0.45, -0.23, -1.52, -1.62, 1.1, 1.4, -0.22, -1.29, -1.39, 0.51, 0.61, 1.15, -6.42, 1.1, 6.27, 0.89, 0.29, 1.08, -0.11, 1.29, 1.04, 0.46, 0.26, 1.39, 1.19, 0.14, 0.2, 1.69], ['339', 3.3, 0.32, 0.47, -0.07, 0.5, 1.38, 1.91, 3.83, 2.21, 4.06, 0.52, 3.04, 1.01, 0.13, -0.56, 3.21, 2.26, 1.94, 7.21, 3.53, 4.88, 1.55, 0.93, 2.14, 3.0, 3.05, 3.5626583949931123, 2.51, 0.49, -0.23681006295292, -1.07, 2.68, 1.74, 1.42, 6.66, 3.0, 4.34, 1.03, 0.42, 1.62, 4.01, 2.76, 0.99, -1.97, -2.82, -3.49, 0.17, -0.75, -1.06, 4.05, 0.48, 1.79, -1.45, -2.04, -0.87, 2.53, 2.87, 1.5, 2.08, 3.02, -0.87, -1.55, 2.18, 1.24, 0.93, 6.15, 2.5, 3.83, 0.54, -0.07, 1.12, 3.99, 3.93, -0.68, 3.08, 2.13, 1.81, 7.08, 3.4, 4.74, 1.42, 0.8, 2.01, 3.88, 8.45, -8.35, 4.64, 3.79, 2.83, 2.51, 7.81, 4.11, 5.46, 2.12, 1.5, 2.71, 1.28, 0.83, -0.92, -1.23, 3.88, 0.31, 1.62, -1.61, -2.21, -1.04, 2.04, 0.81, 2.5257237118830402, 1.58, 1.73, 1.45, 1.76, -0.31, 4.84, 1.24, 2.56, -0.7, -1.3, -0.12, 2.25, 2.08, 5.17, 1.55, 2.88, -0.39, -0.99, 0.19, 3.89, 3.06, -0.1, 1.98, 2.5, 1.11, 0.73, -2.54, 2.5, 1.28, 0.4, 4.04, -0.99, -3.15, -1.59, 1.69, 0.66, 4.980596861471861, -4.84, -4.71, 1.59, -3.91, 3.17, 3.76, -1.88, 5.25, -14.99, -3.5, -5.19, 1.02, -2.94, -3.44, -2.18, -5.29, -5.86, -4.73, 4.82, 0.52, 1.3, -1.91, -2.51, -1.34, -0.78, -3.17, -3.76, -2.61, 2.41, 2.88, 2.48, -0.61, 0.58, 1.61, 1.65, 3.66, -7.49, 2.41, 7.41, 1.76, 1.54, 3.1, 1.19, 1.97, 1.29, 1.12, 0.14, 0.76, 1.88, 3.15, 2.9, 1.24], ['340', 1.88, -0.14, -0.03, 0.23, 0.06, 0.05, -1.23, 0.01, -0.32, 0.42, 0.5903184712113286, 1.49, 1.24, 0.11, 0.75, 0.82, 0.33, 0.25, 4.16, -0.41, 0.68, 0.69, 0.62, 1.16, -0.85, 0.5, 0.04, 1.1001785714285715, 1.2676746031746031, -0.27, 0.37, 0.44, -0.05, -0.13, 3.76, -0.79, 0.29, 0.31, 0.24, 0.77, -0.13, 0.15, -1.05, -0.25, -1.36, -0.72, -0.65, -1.14, -1.22, 2.63, -1.87, -0.8, -0.78, -0.85, -0.32, -0.78, -0.46, 0.61, 0.23, -0.7307547529341225, -1.11, -0.48, -0.41, -0.9, -0.97, 2.89, -1.62, -0.55, -0.54, -0.61, -0.08, 1.13, 0.31, 0.64, 0.72, 0.22, 0.5793027210884354, 4.05, -0.52, 0.57, 0.5814285714285714, 0.52, 1.05, -0.2, -0.52, 0.46, -0.32912907733800595, 0.07, -0.4082142857142857, -0.5, 3.38, -1.15, -0.07, -0.06, -0.13, 0.4, 0.992095238095238, -0.4, -0.49, -0.57, 3.31, -1.22, -0.15, -0.13, -0.2, 0.33, 0.36, -0.37, -1.74427628811696, -0.08, 0.02, -0.21, 0.09, -0.08, 3.82, -0.74, 0.35, 0.36, 0.29, 0.83, -0.19, 0.17, 3.9, -0.66, 0.42, 0.44, 0.37, 1.1421774376417235, 0.14, 0.14, 0.55, -0.09, 2.77, 0.2, 0.01, -0.53, 0.53, 0.26, 1.39, -1.55, -1.79, 0.21, 0.1, 1.03, -0.27, -0.28, 0.3, 0.26, -0.08, -0.79, -0.18, -2.52, 1.23, 0.2, -0.08, -0.17, -0.23, 1.74, -3.59, -4.39, -3.34, -3.33, -3.39, -2.88, -0.26, 0.83, 1.09, 1.11, 1.04, 1.57, -0.25, 0.022884928563499992, -0.05, 0.48, -0.36, -0.04, -0.27, -0.07, 0.46, 0.022080034314056876, -0.07, -0.07, -0.05, -1.42, 0.04, -0.16, -0.14, -0.2, 0.53, -0.11, 0.88, -0.33, -0.37, -0.61, -0.73, 0.63, -0.32, -0.64], ['341', 1.03, 0.12, 0.07122171562045874, 0.08, 0.07, -0.13, -1.18, -0.23, -0.12, -0.92, -1.31, 0.05, -0.95, -0.38, -0.9, -1.05, -1.27, -0.89, -0.28, -1.42, -0.45, -1.15, -0.98, -1.24, 0.42, 0.18, 0.4, 1.38, 0.37, 0.94, 0.41, 0.27, 0.04, 0.42, 1.05, -0.11, 0.8707606837606837, 0.17, 0.33, 0.07, -0.06, 0.95, -0.97, -1.0, -0.43, -0.95, -1.1, -1.32, -0.95, -0.33, -1.47, -0.5, -1.2, -1.04, -0.9891712018140588, -0.07, 0.08, -0.87, -0.09, 0.03, 0.57, 0.05, -0.1, -0.32, 0.06, 0.68, -0.47, 0.5, -0.2, -0.03, -0.3, 0.3, -0.54, -0.52, -0.67, -0.89, -0.51, 0.1, -1.04, -0.07, -0.77, -0.61, -0.87, 0.38, 0.23, -0.16, -0.02, -0.14, -0.37, 0.01, 0.63, -0.52, 0.46, -0.25, -0.08, -0.34, 0.11, 0.13, -0.23, 0.16, 0.77, -0.37, 0.6, -0.1, 0.06, -0.2, 0.161141873999017, 0.17, 0.11, -0.04, -0.01, 0.03, 0.36, 0.38, 1.0, -0.15, 0.83, 0.13, 0.29, 0.03, 0.19, -0.03, 0.62, -0.53, 0.44, -0.26, -0.09, -0.36, 0.31, 0.58, 0.18, 0.35, 0.4, -0.03, 0.07, 0.0, 0.07, 0.01, 0.34, -0.25, -0.92, 0.01, 0.03, 0.57, 0.07, -0.11, 0.05, 0.1, -0.05, -0.13, -0.09, -1.14, 0.59, 0.88, 1.55, -0.72, -0.97, 0.91, -0.64, -1.14, -0.17, -0.87, -0.71, -0.97, -0.13, 0.51, 0.98, 0.27, 0.44, 0.17, -0.47, -0.7, -0.53, -0.8, -0.15, 0.02, 0.23, 0.17, -0.1, -0.03, 0.06, -0.26, 1.03, 0.09, -0.99, -0.2627361894755667, -0.12, 0.07, -0.26, -0.22, -0.13, 0.22, -0.22, -0.06, 0.33, -0.17, 0.24, 0.53], ['342', -3.32, -2.45, -0.26, -0.61, 0.14, 1.14, 1.22, 0.16, 2.25, 0.74, -1.99, -0.57, -0.94, 0.11, 1.64, 0.61, 0.83, 0.51, 1.015862135879993, 0.26, 1.54, 1.44, 1.0, -0.2, 0.09, -0.66, 2.78, 1.45, 1.07, 2.14, 3.71, 2.65, 2.88, 2.55, 2.88, 2.29, 3.6, 3.5, 3.05, 1.83, -2.58, 6.59, 1.31, -0.37, 0.69, 2.23, 1.19, 1.41, 1.09, 1.42, 0.8984761904761904, 2.13, 2.02, 1.58, 0.38, -0.21, -0.28, -2.69, 1.68, 1.69, 1.06, 2.6, 1.56, 1.79, 1.46, 1.79, 1.21, 2.5, 2.4159625850340136, 2.115338978481836, 0.75, 0.09, 0.62, 1.53, 0.5, 0.72, 0.4, 0.73, 0.15, 1.43, 1.33, 0.89, -0.31, 4.27, -1.97, 0.91, -0.89, -1.02, -0.8, -1.11, -0.79, -1.36, -0.1, -0.2, -0.63, -1.81, 0.05, 0.12, 0.22, -0.1, 0.22, -0.35, 0.93, 0.82, 0.38, -0.8, 0.24, 0.12, -0.19, 0.92, 0.67, 0.81, -0.1, -0.32, 0.0, -0.57, 0.7, 0.6, 0.16, -1.02, -0.42, 0.22, 0.32, -0.25, 1.02, 0.92, 0.48, -0.71, -0.82, -0.43, -1.34, -0.38, 0.06, -1.38, -0.9, -0.88, 0.93, 0.46, 0.07, -0.25, -0.83, -1.2114285714285715, -0.865452380952381, -1.75, 1.39, 1.97, -2.2600000000000002, -2.1057142857142854, 0.94, -1.29, 1.86, 4.36, -2.17, -0.39, 3.39, 0.02, 0.06, 0.82, -0.1, -0.57, 0.7, 0.6, 0.16, -1.02, 2.78, 0.47, 1.28, 1.18, 0.7408571428571429, -0.46, -0.79, -0.1, -0.54, -1.71, 2.57, 3.37, -0.69, -0.43, -1.61, 0.93, 0.69, -0.03, 1.77, 0.74, -3.05, 1.34, 0.72, -0.26, -1.18, 1.18, 0.45, 2.0, 1.14, 1.87, 0.93, -0.94, -1.3, 1.11], ['343', 0.23, 0.4, 0.09122171562045875, -0.04, 0.18, 0.2784196236737595, 0.51, -0.31, -0.46, -0.91, -0.72, -0.53, -0.91, -1.02, -0.03, -0.66, -0.86, -0.84, -1.37, -0.62, -1.36, -0.64, -0.81, -1.47, -0.26, -0.17, -0.19, 0.19, -0.19, -0.3, 0.7, 0.06, -0.14, -0.12, -0.65, 0.1, -0.64, 0.09, -0.08, -0.75, -0.33, -1.3150638007838267, -0.38, -0.38, -0.49, 0.51, -0.13, -0.33, -0.31, -0.84, -0.09, -0.83, -0.11, -0.27, -0.94, -1.25, 0.27, -0.31, -0.2, 0.0, -0.11, 0.89, 0.25, 0.05, 0.07, -0.46, 0.29, -0.45, 0.28, 0.11, -0.57, 0.83, 0.11, 1.0, 0.36, 0.16, 0.18, -0.36, 0.4, -0.34, 0.38, 0.22, -0.46, -0.53, -0.36, 0.31, -0.88, -0.5419125667872351, -0.83, -0.81, -1.34, -0.59, -1.33, -0.61, -0.77, -1.44, 1.05, -0.25, -0.2, -0.18, -0.71, 0.04, -0.7, 0.02, -0.14, -0.82, -0.06, -0.35, 0.79, 0.18, 0.04, 0.28, -0.05, 0.02, -0.51, 0.24, -0.5, 0.22, 0.06, -0.62, -0.043463928928214546, -0.07, -0.53, 0.22, -0.52, 0.2, 0.04, -0.64, 0.04, -0.12, 0.11, 0.06, 3.03, 0.02, -0.13, -0.91, 0.94, 0.48, -0.28, 0.4061635321120495, 0.47, -0.37, -0.2, 0.04, -0.47, 0.63, -0.55, -0.5, 0.17, -1.44, 0.34, -1.07, 0.52, -0.09, 1.92, 0.05, 0.09, -0.5461904761904762, 0.47, 0.76, 0.02, 0.74, 0.57, -0.1, 0.51, -0.29, -0.74, -0.02, -0.18, -0.86, 0.45, 0.73, 0.56, -0.12, -0.44, -0.44, -0.28, -0.17, -0.84, 0.19, 0.13, -0.25, 0.94, 0.8, -0.93, 0.25, 0.3, -0.11, -0.67, 0.46, 0.35, -0.46, -1.15, 0.42, 0.57, 0.28, 0.38, 0.3], ['344', 3.92, 0.49, 0.17122171562045874, -0.09, 1.07, 0.66, 1.2541152579598291, 1.75, 1.4293780543870107, 1.89, 0.74, 0.53, 0.35, 1.45, -0.6, 0.44, 0.68, 1.28, -1.19, -0.23, 2.26, 0.92, 0.62, 0.57, 2.03, 1.48, 1.14, -0.21, -0.38857142857142857, 0.7, -1.33, -0.3, -0.06, 0.54, -1.91, -0.96, 1.52, 0.18, -0.11, -0.16, 2.1574684253532106, 1.67, 1.35, -0.18, 0.91, -1.13, -0.09, 0.15, 0.75, -1.71, -0.76, 1.72, 0.39, 0.09, 0.04, 1.6, 1.88, 1.4, 1.09, 1.54, 1.09, -0.95, 0.09, 0.33, 0.93, -1.53, -0.58, 1.91, 0.5859625850340136, 0.2727347454133169, 0.22, 2.36, 0.44, -2.02, -0.99, -0.75, -0.16, -2.6, -1.65, 0.81, -0.51, -0.81, -0.86, 1.28, 3.51, -3.5, 2.51, 1.05, 1.29, 1.9, -0.59, 0.37, 2.89, 1.54, 1.24, 1.18, 2.27, 1.44, 0.24, 0.84, -1.62, -0.67, 1.82, 0.48, 0.18, 0.13, 0.88, 1.46, 2.200104651162791, 1.01, 1.0, 1.1, 1.2, 0.6, -1.86, -0.91, 1.7457782534925395, 0.24, -0.06, -0.11, 0.84, 0.6, -2.44, -1.5, 0.97, -0.35, -0.65, -0.7, 1.33, 1.12, 0.01, 1.16, 6.71, 0.15, 0.17, -2.76, 2.68, 1.33, 0.11, 2.64, -4.06, -2.11, -1.0, 2.04, 0.28, 3.03, -3.04, -3.03, 1.0, -4.03, 2.0, 1.56, -0.82, 3.54, -13.39, -2.37, -3.57, 4.13, 3.12, 0.97, 3.5, 2.14, 1.84, 1.78, 2.99, 2.13, 2.5, 1.16, 0.86, 0.81, -0.37, -1.31, -1.6, -1.65, 1.39, 1.38, 0.96, -0.3, -0.35, 1.04, 1.1143963012752909, 1.77, -7.83, 2.100199626957499, 8.01, 1.197263810524433, 1.4611825396825397, 1.26, -0.05, 0.77, 1.27, 0.43, -0.11, 0.77, 1.31, 1.64, 2.38, 1.12], ['345', 2.54, -0.47, -0.05, 0.2, 0.26, -0.37, -0.8758847420401709, -0.94, -0.52, 0.49, 1.21, 0.8, 1.79, 2.08, 2.41, -0.15, 1.39, 0.42, 0.06, 0.11, 0.49, 1.06, 0.49, 1.32, 0.04, -0.5, -0.71, -0.4, 0.58, 0.86, 1.19, -1.34, 0.18, -0.78, -1.13, -1.09, -0.71, -0.15, -0.71, 0.11, -1.14, -1.72, -0.31, 0.98, 1.27, 1.6, -0.94, 0.58, -0.37, -0.73, -0.69, -0.31, 0.26, -0.31, 0.52, -0.03, -0.68, 0.08, -0.57, -1.28, 0.28, 0.61, -1.91, -0.4, -1.34, -1.7, -1.66, -1.28, -0.72, -1.28, -0.46, -0.98, -1.55, 0.33, -2.18, -0.68, -1.62, -1.97, -1.93, -1.55, -1.0, -1.55, -0.74, -0.73, -0.25, 0.22, -1.88, -2.5, -1.0, -1.94, -2.3, -2.25, -1.88, -1.32, -1.88, -1.07, 0.96, 0.64, 1.54, 0.58, 0.21, 0.26, 0.64, 1.21, 0.7811089783232642, 1.47, -0.04, 0.66, -1.05, -0.48, -0.37, -0.67, -0.88, -0.95, -1.31, -1.26, -0.88, -0.32, -0.88, -0.06, -0.2534639289282145, 0.07, -0.36, -0.32, 0.07, 0.63, 0.07, 0.89, -0.35, -0.62, -0.09, -0.84, 2.85, -0.07, -0.14, 1.44, -1.41, -0.71, 0.54, -0.98, -0.81, 0.94, 0.46, 1.3, -0.11, -1.4, 1.48, 1.44, -0.47, 2.11, -0.96, -2.11, 1.03, -2.62, -0.69, 1.78, 2.63, 0.7, 0.43, 0.04, 0.43, 1.0, 0.7496385796742939, 1.26, -1.46, 0.38, 0.38, 0.95, 0.38, 1.21, 0.0, 0.56, 0.0, 0.83, -0.61, -0.55, -0.56, -0.56, 0.26, -0.49, -0.57, -0.86, -0.62, -1.25, 0.32, -0.97, -0.93, 0.0, 0.83, -0.55, -0.52, -0.38, 1.1402244897959184, -0.76, -0.82, -1.3, -1.08, -1.5], ['346', 0.49, -0.69, 0.04, 0.06, -0.95, 0.94, -0.18588474204017086, -0.08, 1.04, 0.8321428571428571, -0.95, 0.27, 0.92, 1.0670238095238096, 1.49, 1.11, 0.15, 0.51, -0.53, 0.83, 1.25, -1.1, -0.48, 0.95, 0.82, 0.11, 1.8, 1.23, 1.89, 2.03, 2.46, 2.08, 1.12, 1.47, 0.43, 1.8, 2.22, -0.15, 0.48, 1.92, 0.26, 0.95, 0.57, 0.65, 0.79, 1.21, 0.84, -0.07072108843537415, 0.24, -0.79, 0.57, 0.98, -1.37, -0.75, 0.68, -0.07, 0.31, -0.08, 1.25, -0.08, 0.14, 0.56, 0.19, -0.76, -0.41, -1.44, -0.08, 0.32, -2.01, -1.39, 0.03, 0.2736060011417156, -0.22, 0.42, 0.05, -0.9, -0.38017346938775515, -1.57, -0.22, 0.18, -2.14, -1.53, -0.11, 1.45, 3.28, -3.3, -0.64, -0.37, -1.31, -0.9642857142857143, -1.99, -0.64, -0.24, -2.55, -1.94, -0.53, -1.56, -0.27, -0.95, -0.6, -1.62, -0.27, 0.13, -2.19, -1.4388910216767359, -0.16, 0.13, -0.26, 1.12, 0.33, 0.71, -0.08, 0.68, 0.35, -0.68, 0.68, 1.09, -1.26, -0.64, 0.79, 1.71, 0.3830767481303673, -1.03, 0.33, 0.74, -1.6, -0.98, 0.44, 1.5, 1.55, 0.09, 0.67, -4.63, 0.23, 0.07, 1.56, -1.57, -0.79, 0.44, -1.43, 0.06, -0.68, -0.36, 0.16, 0.62, 0.99, -0.89, -1.12, 0.32, 2.46, 0.61, -0.64, 0.32, 2.04, -3.28, -1.407142857142857, -2.08, 0.2656150793650793, 1.37, 1.37, 1.78, -0.58, 0.05, 1.48, 0.91, 0.0, 0.41, -1.92, -1.31, 0.11, -0.41, -2.32, -1.71, -0.29, 1.05, 1.25, 1.96, 0.63, 2.07, 0.26, 0.28, -0.07, -3.01, 0.92, 2.99, 0.8, 0.0, 1.32, 1.44, 0.81, -0.54, 0.7, 1.22, 0.26462624382472905, -0.11, 0.64, -0.96, 0.42], ['347', 1.71, 0.83, 0.02, -0.42, 1.38, 1.04, 2.6341152579598295, 1.14, 1.13, 0.18, -1.9, -1.44, -2.34, -0.54, -1.16, 0.33071428571428574, -1.64, 0.47748242630385496, 0.53, -1.69, 0.27, -0.23, -0.83, -1.1, 1.08, 0.76, 2.1626583949931124, 0.48, -0.45, 1.39, 0.8178199712950912, 2.28, 0.27, 2.11, 2.48, 0.22, 2.22, 1.71, 1.1, 0.82, 1.08, 0.9349361992161734, 1.65, -0.92, 0.91, 0.28, 1.8, -0.21, 1.62, 1.99, -0.26, 1.749654729237061, 1.23, 0.62, 0.34, -0.14, -0.62, 0.78, 1.18, 2.59, 1.84, 1.21, 2.74, 0.72, 2.56, 2.94, 0.66, 2.68, 2.17, 1.55, 1.27, 1.01, 0.73, -0.62, 0.8807142857142857, -1.1, 0.71, 1.08, -1.16, 0.82, 0.32, -0.28, -0.56, 1.6, 2.68, -2.7, 1.3966982383853201, 1.51, -0.48, 1.34, 1.71, -0.54, 1.45, 0.95, 0.34, 0.06, 0.06, -0.15, -1.97, -0.17, 0.19, -2.02, -0.06, -0.3171830035044322, -1.16, -1.43, 0.14, -0.07, 0.9, 1.1815981806829015, 1.03, 1.2456735186500318, 1.85, 1.83, 2.2, -0.05, 1.95, 1.44, 0.83, 0.54, 0.14, 0.02, 0.37, -1.85, 0.11, -0.39, -0.98, -1.26, 0.84, 1.17, -0.78, 1.42, 0.08, 0.12, 0.07, -2.49, 2.51, 1.3188101710076212, -2.37, 1.94, -4.1, -2.18, -1.16, 0.87, 0.53, 3.35, -3.25, -3.35, 1.1832908048638529, -3.77, 2.24, 4.57, -2.32, 5.56, -4.21, -3.69, -5.51, 4.09, -0.34, -2.21, -0.25, -0.75, -1.35, -1.62, 3.4131678995607566, 1.91, 2.0, 1.49, 0.88, 0.6, -0.09, -0.5, -1.1, -1.38, 1.15, 1.23, 0.41, -0.6, -0.8077512446849837, 1.182080034314057, 1.11, 1.05, -2.25, 1.28, 2.3, 1.89, 1.91, 1.02, -0.28, 1.94, 1.07, 0.58, 0.22, 0.58, 1.3, 2.83, 2.66, 1.65], ['348', 1.63, 0.49, 0.3412217156204588, -0.04, 0.61, 1.51, 1.34, 1.24, 1.76, 3.22, 0.74, 2.5819344980416408, 1.633913265120849, 2.66, 1.93, 3.31, 1.01, 2.62, 5.97, 1.92, 3.357335482087359, 2.06, 1.62, 2.01, 1.42, 2.33, 2.4926583949931125, 1.63, 0.82, 1.9, 1.18, 2.55, 0.27, 1.86, 5.635702380952381, 1.17, 2.56, 1.31, 0.87, 1.25, 1.01, 3.76, 0.82, -0.8, 0.27, -0.44, 0.9, -1.24071768707483, 0.23, 3.5971355564861205, -0.45, 0.91, -0.32, -0.10857142857142854, -0.37, 0.69, 1.33, 0.15, 2.04, 1.63, 1.08, 0.36, 1.71, -0.55, 1.04, 4.34, 0.35, 1.72, 0.49, 0.06, 0.43, 0.96, 0.55, -0.71, 0.63, -1.61, -0.04, 3.22, -0.72, 0.64, -0.59, -1.01, -0.64, 2.22, 4.62, -4.62, 1.27, 1.35, -0.9, 0.68, 3.96, -0.01, 1.36, 0.13, -0.3, 0.07, 1.74, -0.08, -2.22, -0.66, 2.58, -1.34, 0.01, -1.21, -1.63, -1.26, 0.65, -0.06, 1.81, 1.6, 1.39, 1.8, 2.19, 1.59, 4.91, 0.9, 2.28, 1.04, 0.61, 0.99, 1.13, 0.59, 3.26, -0.68, 0.68, -0.55, -0.97, -0.6, 2.31, 2.74, 0.07, 2.02, 5.47, 0.1, -0.07, -4.12, 4.122462323390895, 2.07, 0.66, 0.7, -2.43, -3.22, -1.64, 0.78, 0.88, 4.85, -4.67, -4.7, 1.643290804863853, -6.21, 3.22, 0.48, -0.24, 6.46, -7.74, -4.39, -6.51, 2.42, -2.59, -3.82, -2.5, -3.69, -4.1, -3.74, 4.83, 1.28, 1.37, 0.13, -0.29, 0.08, -0.09, -1.22, -1.64, -1.27, 1.81, 2.15, 1.14, -0.43, -0.05, 1.6, 1.68, 1.13, -5.79, 1.6711163791806698, 5.78, 1.85, 1.84, 1.57, 0.38, 1.7, 2.1, 1.15, 0.46, 1.2, 1.19, 3.1202406343656346, 2.25, 2.23], ['349', -0.03, -0.12, -0.3098471016907295, 0.07, 0.84, -0.08, -0.04588474204017083, -0.71, -0.24, -0.55, 0.0, -1.35, 0.013913265120848936, -0.71, 0.27, -0.98, -0.47, -0.48, -1.5, -2.23, -0.41, -1.32, -0.91, -0.63, -1.03, 0.55, -0.5173416050068875, -1.35, -0.05, -0.71, 0.27, -0.98, -0.47, -0.48, -1.4992857142857143, -2.23, -0.41, -1.32, -0.91, -0.5761582768021608, -0.44, 1.43, 0.81, 1.32, 0.66, 1.65, 0.38, 0.89, 0.89, -0.15, -0.89, 0.95, 0.03, 0.45, 0.74, -0.07, -0.58, -1.49, -0.72, -0.42075475293412246, -0.66, 0.33, -0.93, -0.42, -0.43, -1.3413219954648525, -2.18, -0.36, -1.27, -0.86, -0.57, -1.26, 0.16, 0.99, -0.28, 0.24, 0.23, -0.8, -1.53, 0.3, -0.62, -0.07690451810094656, 0.08, -0.45, 1.03, -1.06, -0.82, -1.25, -0.75, -0.75, -1.77, -2.306255228898086, -0.69, -1.59, -1.19, -0.8459922724755494, 2.19, 0.44, 0.51, 0.51, -0.52, -1.26, 0.57, -0.34, 0.07, 0.36, -0.03, 0.48, 0.42572371188304003, -0.04, 0.18517906963433994, -0.22432648134996808, -0.08, 0.0, -1.03, -1.76, 0.06, -0.85, -0.44, -0.15, 0.6, -0.08, -1.03, -1.76, 0.06, -0.85, -0.44, -0.15, 0.47, 1.43, 0.12, -0.15, 4.46, -0.2419304505018789, -0.42, 0.77, -0.76, -0.41, -0.32593372653318475, 0.08025974025974027, -3.53, 0.1, 0.05, 0.03, 0.28, -0.24, 0.23, 0.19, -0.05, 1.21, -0.13, -0.25, 0.09, -0.12, 1.2, 0.15, 0.09, 3.46, 0.96, -0.74, 1.1, 0.18, 0.59, 0.89, -0.22, 1.72, 1.86, 0.93, 1.35, 1.64, -0.14, -0.91, -0.5, -0.21, -0.19, -0.53, 0.78, 0.41, 0.7, -0.04, -0.07, -0.6074239503761216, 0.6, -0.2498003730425007, -0.75, -0.18, 0.01, 0.37, 0.29, -0.77, -0.44, 0.01, 0.57, 0.37, 0.07, 0.4, 0.6, 0.07], ['350', -1.99, -0.44, -0.17877828437954127, 0.17, -0.31, 0.19, -0.74, -0.95, -0.72, -0.83, -0.21, -0.38, -0.06, 0.48, -0.19, -0.67, -0.55, 0.13, 2.59, -0.19, -1.0, -0.19, -0.3956947683993239, -0.49, -1.26, -1.21, -0.62, -0.17, 0.15, 0.69, 0.02, -0.46, -0.34, 0.35, 2.81, 0.02, -0.79, 0.02, -0.28, -0.28, -0.76, -0.47, -0.45, 0.32, 0.86, 0.19, -0.29, -0.17, 0.52, 2.99, 0.19, -0.62, 0.19, -0.11, -0.11, -0.14993715369432348, -1.34, -1.5021720271902161, -1.2, -0.77, 0.54, -0.12920068027210885, -0.61, -0.49, 0.19, 2.65, -0.12976190476190477, -0.95, -0.14, -0.43, -0.43, -1.25, -1.3, -0.2497721088435375, -1.14, -1.02, -0.34, 2.11, -0.67, -1.47, -0.67, -0.97, -0.96, -0.48, -0.97, 1.0, -0.64, -0.48, -0.36, 0.33, 2.79, 0.0, -0.81, 0.0, -0.3, -0.3, -2.64, -0.16, 0.12, 0.81, 3.3159047619047617, 0.48, -0.34, 0.7228169964955679, 0.18, 0.18, -0.82, -0.14, 1.33, -0.13, -0.14, -0.24, -0.28, 0.69, 3.16, 0.36, -0.46, 0.36, 0.06, 0.06, -0.7, -0.96, 2.46, -0.32, -1.13, -0.33, -0.62, -0.62, -0.43, 0.33, -0.08, -0.38, -5.12, -0.4796768707482993, -0.3, 0.82, -0.88, -0.41, -0.2, -0.66, 1.38, 0.35, 0.14, -0.95, 0.37, -0.58, 0.56, 0.34, -0.13, 1.16, -0.27, -0.98, 0.45, -0.83, 9.49, 0.53, 0.81, -1.39, -3.34, -2.71, -3.51, -2.72, -3.01, -3.0, -0.36, -0.64, -0.81, 0.0, -0.3, -0.3, 0.18, 0.82, 0.52, 0.52, -0.66, -0.79, -0.64, -0.3, -0.29, 0.09208003431405688, -0.18, -1.02, 4.75, 0.17, -4.86, -1.3, -0.06, -0.34, 0.0, 0.06, -0.34, 0.61, 0.58, -0.17, -0.34, -2.2, -0.42, -0.14], ['351', 0.88, 0.0, 0.17122171562045874, -0.04, 0.18, 0.39, 0.9841152579598291, -0.1, 0.28, 0.23, -0.2, 0.17, -0.07, 1.5, -1.22, 0.15, -0.13, 0.23, -1.22, -0.02, 0.21733548208735892, 0.53, 0.29, -0.12, 0.04, 0.51, 0.42, 0.37, 0.13, 1.7, -0.9721800287049088, 0.35, 0.07, 0.42, -1.03, 0.17, 0.37, 0.72, 0.49, 0.08, 0.8, 0.6749361992161734, 0.05, -0.24, 1.32, -1.39, -0.02, -0.3, 0.05, -1.39, -0.2, 0.0, 0.35, 0.12, -0.29, -0.41, 0.19, -0.86, 0.26, 0.3, 1.57, -1.15, 0.22, -0.06, 0.3, -1.15, 0.05, 0.25, 0.6, 0.36, -0.05, -0.15, -1.25, -2.68, -1.33, -1.6, -1.25, -2.68, -1.5, -1.3, -0.96, -1.19, -1.59, 0.33, -0.06, 0.05, 1.460870922661994, 1.39, 1.11, 1.46, 0.23578854875283461, 1.21, 1.41, 1.77, 1.53, 1.12, 1.12, 0.08, -0.27, 0.08, -1.37, -0.17, 0.03, 0.38, 0.14, -0.27, 0.0, 0.05, -0.25, 0.2515981806829015, 0.18, 0.31, 0.35, 0.35, -1.1, 0.1, 0.3, 0.65, 0.42, 0.01, -0.25, 0.053076748130367266, -1.45, -0.25, -0.05, 0.3, 0.06, -0.34, -0.39, -0.48, 0.04, 0.29, 3.19, -0.03, 0.07, -0.51, 0.54, 0.25, 0.29, 1.04, -0.47, -0.4, -0.21, 0.44, -0.11, 0.54, -0.55, -0.58, 0.19, -0.76, 0.44, 0.31, -0.12, 1.05, -3.15, -0.72, -1.12, 0.52, 1.47, 1.21, 1.42, 1.77, 1.53, 1.12, 0.58, 0.25, 0.2, 0.55, 0.31, -0.09, 0.05, 0.35, 0.11, -0.29, 0.24, 0.37, -0.3, -0.23, -0.64, 0.22, 0.26, -0.07, 0.29, 0.06, -0.33, 0.15, 0.51, -0.06, -0.41, 0.35, 0.42, 0.14, -0.82, 0.06, 0.34, 0.84, 0.66, 0.7730167737073972], ['352', 11.16, 0.74, 0.8112217156204587, -0.45, 3.17, 2.9184196236737594, 3.05, 6.77, 5.59, 6.21, -1.89, 2.401934498041641, 0.94, -0.99, -0.49, 4.52, 0.57, 4.5, 5.19, 2.49, 8.27, 1.67, 0.23, 3.23, 7.5, 3.98, 8.26, 4.18, 2.88, 0.92, 1.43, 6.54, 2.51, 6.52, 7.230714285714286, 4.47, 10.36, 3.64, 2.17, 5.22, 4.53, 8.1, 3.92, -1.24, -3.12, -2.63, 2.27, -1.6, 2.25, 2.93, 0.7096666666666667, 5.93, -0.52, -1.93, 1.01, 5.21, 6.43, 4.94, 3.98, 5.22, -1.91, -1.41, 3.55, -0.37, 3.53, 4.22, 1.54, 7.26, 0.73, -0.7, 2.27, 6.79, 7.27, 0.51, 5.57, 1.57, 5.54, 6.25, 3.52, 9.35, 2.69, 1.23, 4.26, 8.048909863945578, 16.38, -16.33, 6.73, 5.03, 1.06, 5.01, 5.71, 3.0, 8.8, 2.17, 0.72, 3.74, 1.93, 1.61, -3.78, -0.02, 0.64, -1.94, 3.6426265373526934, -2.73, -4.1, -1.23, 1.5911418739990169, 1.66, 5.57, 3.44, 3.76, 3.31, 5.61, 3.91, 4.6, 1.92, 7.66, 1.1, -0.33, 2.65, 4.1, 1.64, 0.67, -1.92, 3.61, -2.7, -4.08, -1.21, 5.59, 5.78, 0.17, 4.75, 3.82, 1.97, 1.15, -6.1, 6.05, 3.04, 1.83, 7.19, -7.2, -6.85, -3.46, 5.57, 2.13, 10.55, -10.5, -10.32, 3.43, -9.09, 6.87, 6.64, -3.28, 16.77, -26.49, -11.15, -16.6, 7.02, 0.96, -2.57, 2.92, -3.35, -4.72, -1.87, 10.27, 3.62, 5.63, -0.8, -2.21, 0.72, -1.9, -6.09, -7.42, -4.65, 5.61, 6.11, 4.46, -1.42, 1.53, 3.4, 3.6, 6.78, -13.22, 4.91, 13.33, 5.44, 4.23, 5.96, 2.99, 4.780077402522781, 3.35, 0.87, 2.46, 1.98, 2.965957527023814, 9.05, 6.743037664716236, 4.46], ['353', -3.39, 1.04, -0.008778284379541255, 0.07, 0.06, 0.52, -0.5, 0.31, 0.72, 0.56, 0.09031847121132863, 0.42, -0.49, 0.71, 0.29, 1.06, 0.33, 0.49, 0.36, -0.25, 1.12, 1.04, 0.3543052316006761, -0.49, 1.33, 0.28, 0.68, 0.5401785714285715, -0.37, 0.83, 0.41, 1.19, 0.45, 0.61, 0.48, -0.13, 1.25, 1.16, 0.38, -0.37, 0.6174684253532109, 2.0, 0.14, -0.91, 0.29, -0.13, 0.64, -0.09, 0.07, -0.07, -0.67, 0.7, 0.62, -0.16, -0.91, 0.55, 0.45, 0.15, 0.75, 1.06, 1.21, 0.78, 1.56, 0.82, 0.98, 0.85, 0.24, 1.62, 1.54, 0.75, 0.0, 0.93, -0.15, -0.42, 0.35, -0.38, -0.22, -0.3469047619047619, -0.96, 0.41, 0.33, -0.45, -1.19, 1.05, 1.02, -1.02, 0.27, 0.77, 0.04, 0.2, 0.07, -0.54, 0.83, 0.75, -0.03, -0.78, -0.71, -0.5, -0.73, -0.57, -0.7, -1.3, 0.06, -0.02, -0.79, -1.54, -0.05, -0.49, -0.16, 0.61, 0.47, 0.7, 0.23, 0.16, 0.03, -0.58, 0.8, 0.71, -0.07, -0.7514153161169344, 0.39, 0.12307674813036727, -0.13, -0.74, 0.63, 0.55, -0.23, -0.97, 0.13, 0.32, 0.04, 0.25, -1.87, 0.07, 0.17, -1.76, 1.78, 0.91, 0.89, -0.5, -1.4494817511227285, -1.23, -0.64, -1.67, 0.49, 1.85, -1.79, -1.8, 0.62, -2.68, 1.24, -0.27, 0.13, 0.71, -1.7, -0.5, -0.74, 1.5738095238095238, 0.21, -0.61, 0.77, 0.68, -0.1, -0.84, 1.87, 0.82, 1.38, 1.3, 0.51, -0.24, -0.56, -0.08, -0.86, -1.6, 0.27, 0.36, -0.47, -0.77, -1.52, 0.17, 0.06, 0.12, -0.33, 0.43019962695749936, 0.39, -0.03, 0.64, 0.3, -0.75, 0.58, 0.63, 0.78, 0.08, 0.61, 1.06, -0.39, 0.35, 0.67], ['354', -7.13, -0.22, -0.19877828437954126, -0.17, -0.05, 1.22, -0.41, -0.6982794034640413, 0.32, -1.13, -2.29, -0.92, -1.76, -0.58, 0.59, 1.65, -0.57, -1.21, -3.38, -1.51, -1.402664517912641, -0.67, -2.47, -1.57, 0.6, -0.27, 1.18, 1.4, 0.54, 1.75, 2.94, 4.03, 1.76, 1.1, -1.12, 0.79, 0.87, 1.66, -0.18, 0.73, -1.8345146341753484, 1.33, -0.20979591836734693, -0.7588025325038829, 0.35, 1.52, 2.6, 0.36, -0.29, -2.478347866419295, -0.6, -0.53, 0.25, -1.56, -0.66, -2.0476426685347184, -1.76, -2.77, 0.48, 0.64, 1.2, 2.38, 3.47, 1.8814285714285712, 0.55, -1.65, 0.25, 0.32, 1.1114285714285714, -0.72, 0.19, -1.11, -0.56, 1.17, 2.24, 0.01, -0.4701734693877551, -2.82, -0.94, -0.87, -0.08857142857142856, -1.9, -1.0, 0.98, 2.82, -2.95, -1.71, 1.06, -1.15, -1.79, -3.94, -2.09, -2.02, -1.25, -3.04, -2.15, -0.94, -2.74, -2.18, -2.82, -4.95, -3.11, -3.04, -2.2775714285714286, -4.05, -3.17, -0.19, -2.78, -0.08427628811695997, 0.08, 0.73, 0.24567351865003195, -0.57, -0.65, -2.83, -0.95, -0.88, -0.1, -1.91, -1.01, -0.43, 0.08, -2.2, -0.3, -0.23, 0.55, -1.27, -0.37, 1.44, -0.26, -0.26, -0.18, -1.9, -0.5196768707482994, -0.75, 1.52, -1.57, -0.78, -3.31, -0.59, -0.66, -1.29, -0.67, -2.27, 1.02, 1.4905968614718617, -1.49, -1.9, 0.68, 2.49, 1.31, 2.98, -1.52, -1.64, -0.59, 1.25, 1.76, 0.64, 2.650378684807256, 1.93, 2.01, 2.81, 0.94, 1.87, 1.78, 0.39, 0.07, 0.86, -0.97, -0.06, 0.32, 0.78, -1.04, -0.13, 0.37, 0.9, -0.47, -1.81, -0.91, 0.62, 0.43, -1.03, -0.32, 0.37, 0.17, 0.79, 0.4411825396825397, 1.37, 0.92, 0.85, -0.47, 1.3952979520479523, 0.51, 0.82, 0.45, -0.69, -0.7184047619047619, 1.52], ['355', 0.88, 0.4, 0.16015289830927054, 0.11, 0.53, -0.1, 0.41, 0.02, -0.17, 1.14, 1.42, 0.93, 1.59, 1.48, 0.31, 1.16, 1.01, 1.06, -1.09, 0.85, 0.67, 1.2, 1.37, 1.3, -0.12, 0.03, -0.28, -0.48, 0.17, 0.06, -1.09, -0.26, -0.4, -0.35, -2.47, -0.56, -0.73, -0.21, -0.04, -0.12, 0.15, -0.28, 0.2, 0.65, 0.54, -0.61, 0.22, 0.08, 0.13, -2.0, -0.08, -0.26, 0.27, 0.44, 0.36, -0.65, -0.37, 0.26, -0.17, -0.45, -0.11, -1.26, -0.43, -0.57, -0.52, -2.531321995464853, -0.73, -0.9, -0.38, -0.21, -0.29, -0.73, -0.33, -1.15, -0.32, -0.46, -0.41, -2.53, -0.62, -0.79, -0.27, -0.1, -0.17, -0.2, -0.69, 0.69, 0.8566982383853201, 0.84, 0.7, 0.75, -1.39, 0.53, 0.36, 0.89, 1.06, 0.98, 0.18, 0.05736653121656289, -0.14, -0.09, -2.22, -0.31, -0.48, 0.05, 0.22, 0.14, 0.02, 0.0, 0.13, 0.0, 0.05, -0.06, 0.12, 0.05, -2.08, -0.16, -0.33, 0.19, 0.36, 0.29, -0.04, 0.07, -2.13, -0.22, -0.39, 0.14, 0.31, 0.23, -0.67, -0.71, 0.11, 0.08, 0.3, 0.1, 0.13, 0.76, -0.7475376766091052, -0.3511898289923789, 0.14, 0.93, -0.51, -0.02, 0.03, 0.45, 0.16, 0.0, -0.07, -0.06, 0.03, 1.15, 0.08, -1.31, 0.67, 0.33, -7.56, -0.21, -0.26, 0.6, 2.25, 1.95, 1.78, 2.32, 2.49, 2.41, 0.04, 0.29, -0.17, 0.36, 0.52, 0.45, 0.46, 0.53, 0.69, 0.62, -0.12, -0.08154645354645335, -0.07, 0.17, 0.09, 0.03, 0.03, 0.06257604962387836, -4.66, 0.0, 4.65, 0.23, 0.52, -0.23, -0.07, 0.54, -0.46, 0.03, 0.42, 0.09, -0.16, 0.35, -0.02, 0.26], ['356', 0.23, -0.37, -0.2, 0.05, -0.21, -0.42, -0.54, 0.14, -0.48, -0.22, 0.04, -0.28, 0.21, -0.17, 0.39, -0.02, -0.08, 0.25, 4.4, 0.43, -0.3426645179126411, -0.08, 0.47, 0.35, -0.57, -0.71, -0.22734160500688755, -0.31, 0.17, -0.2, 0.36, -0.05, -0.12, 0.21, 4.37, 0.39, -0.42, -0.12, 0.44, 0.32, -2.0, -0.6850638007838266, 0.05, 0.49, 0.11, 0.67, 0.26, 0.2, 0.53, 4.69, 0.71, -0.11, 0.2, 0.75, 0.63, -0.75, 0.31, 0.13, -0.63, -0.43, -0.38, 0.18, -0.23, -0.29, 0.04, 4.19, 0.22, -0.59, -0.29, 0.26, 0.14, -0.61, -0.06, 0.5607142857142857, 0.15, 0.09, 0.42, 4.58, 0.59, -0.22, 0.08, 0.64, 0.52, -0.45, -1.53, 1.75, -0.61, -0.41, -0.47, -0.14, 4.0, 0.04, -0.77, -0.47, 0.08, -0.04, -1.15, -0.21, -0.06, 0.27, 4.42, 0.45, -0.37, 0.1728169964955679, 0.49, 0.37, -0.22, 0.17, -0.82, -0.41, -0.42482093036566004, -0.34, -0.14, 0.33, 4.49, 0.51, -0.3, 0.0, 0.56, 0.43, -0.28, -0.47, 4.15, 0.18, -0.63, -0.33, 0.23, 0.1, -2.3, -0.93, 0.05, -0.13, -4.29, 0.03, -0.08, -0.36, 0.37, 0.23, -0.4, -0.75, -0.16, 0.61, 0.39, -0.11, -0.15, -1.0885238095238097, 0.89, 0.75, -0.35, -0.95, -0.84, -1.0, 0.47, -0.31, -6.17, 0.35, 0.0, -1.37, -4.43, -3.81, -4.59, -4.3, -3.76, -3.88, -0.92, -0.65, -0.81, -0.51, 0.05, -0.08, 0.16, 0.3, 0.86, 0.74, -0.49, -0.51, -0.14, 0.56, 0.44, -0.43, -0.43, -0.07742395037612165, -1.41, -0.84, 1.11, 0.11, -1.09, -0.69, -0.12, -0.27, 0.21, -0.9, 1.05, -0.67, -0.57, -1.06, -1.56, -1.61], ['357', -2.92, -0.52, 0.22122171562045873, 0.14, -1.51, -2.8, -1.8758847420401707, -3.3, -3.33, -3.84, 1.1, -1.76, -0.23, 0.12, -1.27, -3.49, -0.67, -3.29, -2.29, -1.53, -4.85, -0.78, -0.9256947683993239, -1.09, -3.26, -2.560628585411108, -4.89, -2.83, -1.32, -0.97, -2.35, -4.54, -1.76, -4.35, -3.35, -2.6, -5.89, -1.86, -2.1, -2.17, -2.602531574646789, -6.22, -1.920696767518196, 1.55, 1.91, 0.49, -1.76, 1.11, -1.56, -0.54, 0.24, -3.15, 1.0, 0.75, 0.68, -1.63, -3.38, -1.88, -2.46, -3.62, 0.35, -1.039200680272109, -3.27, -0.44, -3.06, -2.06, -1.3, -4.63, -0.55, -0.79, -0.86, -4.47, -3.96, -1.39, -3.61, -0.79, -3.41, -2.4, -1.64, -4.97, -0.9, -1.14, -1.21, -5.16, -8.09, 8.17, -2.6, -2.24, 0.61, -2.04, -0.7842114512471654, -0.25, -3.62, 0.5, 0.26, 0.18, -0.9, -0.36, 2.92, 0.21, 1.25, 2.04, -1.41, 2.81, 2.56, 2.48, -0.47, -0.38, -3.28427628811696, -2.68, -2.57, -2.6443264813499683, -3.19, -2.64, -1.63, -0.86, -4.21, -0.11, -0.35, -0.43, -2.76, -0.57, 1.04, 1.82, -1.61, 2.6, 2.35, 2.27, -2.8281719617057965, -3.05, 0.21, -2.81, -1.76, -0.5677486640343783, -0.61, 4.68, -4.72, -2.371189828992379, -0.19, -4.19, 4.56, 5.33, 2.66, -1.39, -2.5, -7.96, 7.96, 8.01, -2.63, 7.06, -5.25, -1.4, 0.73, -9.5, 17.62, 6.39, 9.49, -4.59, -1.59, 0.78, -2.62, 1.54, 1.3, 1.3857617128436457, -7.886832100439243, -2.35, -3.38, 0.76, 0.51, 0.44, 1.06, 4.28, 4.03, 3.95, -3.079864861329147, -3.88, -3.09, -0.24, -0.32, -2.71, -2.64, -3.48, 8.84, -3.22, -8.53, -2.95, -3.32, -2.771362551799029, -0.08, -2.5599225974772195, -2.17, -2.38, -2.43, -2.85, -2.78, -2.88, -3.54, -2.06], ['358', 3.93, -0.9, 0.13, -0.02, -0.52, 0.2, 0.8141152579598292, -0.05, -0.39, 0.3970884353741497, 0.36, -0.77, 0.28, -0.05, -0.28, -1.04, 0.53, 0.03, 1.66, 1.83, -0.44, 0.13, 0.89, -0.26, 0.49, -0.45, -0.41, -1.13, -0.08, -0.41, -0.64, -1.4, 0.17, -0.33, 1.3, 1.47, -0.8, -0.23, 0.53, -0.5761582768021608, -0.55, -1.98, 0.730204081632653, 1.06, 0.73, 0.49, -0.27, 1.31, 0.81, 2.45, 2.63, 0.33, 0.91, 1.67, 0.51, 0.04, 0.08, 1.07, -0.25, -0.33, -0.33, -0.56, -1.32, 0.25, -0.25, 1.38, 1.55, -0.72, -0.15, 0.61, -0.54, 1.37, 0.0, -0.23, -0.99, 0.58, 0.08, 1.71, 1.88, -0.39, 0.18, 0.94, -0.22, -1.0, -1.86, 1.77, 0.23, -0.6719125667872351, 0.81, 0.31, 1.95, 2.12, -0.16, 0.41, 1.17, 0.02, 1.66, 1.0773665312165628, 1.59, 1.08, 2.73, 2.91, 0.61, 1.18, 1.95, 0.79, -0.01, 1.02, -0.67, 0.2, 0.02, 0.16, -0.57, -0.5, 1.13, 1.3, -0.9593197278911564, -0.4, 0.36, -0.79, -0.18, -0.08, 1.63, 1.8, -0.47, 0.1, 0.86, -0.29, -1.86, -2.03, 0.17, -0.63, 3.28, -0.21, 0.07, -1.04, 1.05, 0.32, -0.51, -1.18, 3.62, -0.31, -0.16, 1.91, 0.65, 0.31, -0.29, -0.7, -0.32, -1.57, 0.39, -0.91, 0.48, -1.64, -2.93, 1.11, 1.58, -3.69, -1.68, 0.17, -2.07, -1.51, -0.76, -1.9, 0.53, -1.85, -2.23, -1.68, -0.93, -2.06, 0.39, 0.57, 1.33, 0.18, -0.43, -0.73, -0.18, 0.76, -0.39, 0.14, 0.04, 0.05, -1.44, -0.5898003730425007, 1.4165238095238095, -0.75, -1.11, -0.93, -1.14, -0.3, 0.1, -0.06, -0.06, -0.18, 0.22, -1.26, -1.3, -0.06], ['359', -0.46, 0.33, 0.13122171562045873, -0.3, 0.28, 0.85, -0.13588474204017084, 1.22, 0.65, 0.55, -0.61, 1.38, -0.96, -0.43, -0.89, 0.85, -0.76, 0.85, -2.02, -0.78, 0.43, -1.15, -1.19, -0.5, 0.59, 0.85, 1.16, 2.0, -0.36, 0.18, -0.29, 1.47, -0.15, 1.46, -1.42, -0.17, 1.04, -0.55, -0.59, 0.1, 1.17, 0.83, -0.6206967675181959, -2.31, -1.78, -2.24, -0.52, -2.11, -0.52, -3.35, -2.13, -0.94, -2.49, -2.53, -1.85, 0.35, 0.55, 0.86, 1.08, 1.52, 0.54, 0.07, 1.83, 0.21, 1.83, -1.07, 0.18, 1.4, -0.19, -0.23, 0.46, 1.2, 0.98, -0.46, 1.29, -0.33, 1.28, -1.6, -0.35, 0.86, -0.73, -0.76, -0.07, 1.17, 4.95, -4.91, 1.48669823838532, 1.76, 0.14, 1.76, -1.14, 0.11, 1.33, -0.26, -0.3, 0.39, 0.39, -0.3, -1.6, 0.0, -2.85, -1.62, -0.42, -1.99, -2.02, -1.34, -0.029020408163265305, -0.31, 2.4157237118830404, 1.08, 1.3, 0.79, 1.31, 1.62, -1.27, -0.02, 1.2, -0.4, -0.35401213658444736, 0.26, 1.42, -0.3, -2.85, -1.62, -0.42, -1.8542004503433074, -2.02, -1.34, 1.57, 1.39, -0.23, 1.18, 1.22, -0.26, 0.07, -1.34, 1.32, 0.67, 0.43, 0.77, -2.52, -2.11, -1.09, -0.2, 0.56, 3.320596861471862, -3.16, -3.26, 1.08, -1.92, 2.16, 1.45, -0.95, 3.9, -6.0, -2.65, -3.86, 2.57, 2.62, 1.27, 2.5, 0.89, 0.85, 1.55, 3.26, 1.34, 1.22, -0.37, -0.41, 0.28, 0.12, -1.5671150714365, -1.61, -0.93, 0.72, 1.01, 1.72, -0.04, 0.66, 1.09, 1.1, 1.27, -3.2, 2.2311163791806696, 3.26, 1.0572638105244332, 2.13, 1.76, 0.7, 0.68, 0.77, 0.5, 0.67, 0.53, 1.05, 1.71, 2.09, 0.83], ['360', -4.66, -0.29, 0.19122171562045873, 0.23, -1.18, -0.19, -0.45, -0.47, -1.09, -1.02, 0.38, -0.08, -0.87, -1.16, -0.63, -0.85, 0.37, -0.86, -1.92, 1.51, -1.73, -0.88, -0.76, -0.84, -0.88, -0.95, -1.4, -0.46, -1.25, -1.54, -1.01, -1.23, -0.01, -1.24, -2.3, 1.12, -2.1, -1.25, -1.13, -1.22, -0.6, -1.1450638007838265, -0.95, -0.7188025325038829, -1.09, -0.55, -0.77, 0.45, -0.79, -1.85, 1.59, -1.65, -0.7061344435209982, -0.68, -0.76, -0.08, -0.39, -1.23, -1.31, -0.15, -0.29, 0.25, 0.03, 1.26, 0.01, -1.06, 2.4, -0.86, 0.0, 0.12, 0.03, -0.2763939988582844, 0.14, 0.54, 0.32, 1.55, 0.3, -0.77, 2.7, -0.57, 0.29, 0.41, 0.33, -1.47, -1.04, 0.97, -0.4, -0.22, 1.0, -0.24, -1.31, 2.15, -1.11, -0.25, -0.13, -0.21, -2.03, -0.17, 1.23, -0.02, -1.08, 2.38, -0.88, -0.03, 0.09, 0.01, -0.26, -0.15, -1.3, -0.32, -0.39, -0.37, -1.3890429599640124, -1.23, -2.29, 1.13, -2.09, -1.24, -1.12, -1.21, 0.12653607107178547, -0.10692325186963274, -1.07, 2.482244713705627, -0.87, -0.01, 0.11, 0.03, -0.76, -1.12, 0.12, -0.75, -6.13, 0.13, 0.06, 0.21, -0.25, -0.12, 0.45, 0.3, 5.01, 0.63, 0.38, -2.38, -0.09, -1.12, 1.05, 1.01, -0.33, 0.49, -0.65, -1.79, 0.88, -4.13, -0.18, 2.76, 4.13, -4.87, 0.92, 3.5, 0.2, 1.07, 1.19, 1.11, -0.98, -2.49, -3.19, -2.35, -2.23, -2.31, 0.72, 0.87, 0.99, 0.9, -1.08, -1.24, -0.15, 0.12, 0.11224875531501632, -0.33, -0.45, -0.42, 0.47, -1.21, -0.66, -0.43, -1.32, -0.27, -0.08, -0.67, -0.08, 0.01, -0.03, -0.3, -0.18, -1.72, -1.81, -0.02], ['361', 4.91, 0.01, -0.12, 0.47, -0.23, -1.47, -0.6, -2.42, -2.12, -2.05, 1.65, -1.68, 0.42, 0.5170238095238096, -0.16, -3.559285714285714, 0.25, -1.1294285714285712, -0.83, -0.01, -2.28, 0.35, -0.15, 0.68, -2.85, -1.68, -3.65, -3.28, -1.22, -1.12, -1.78, -5.13, -1.38, -2.74, -2.45, -1.64, -3.87, -1.29, -1.78, -0.96, -1.11, -3.42, -0.38, 2.13, 2.23, 1.55, -1.91, 1.96, 0.56, 0.86, 1.7, -0.61, 2.06, 1.55, 2.4, -0.89, -1.41, -1.8980521152823784, -2.16, -2.46, 0.1, -0.57, -3.96, -0.17, -1.54, -1.24, -0.42, -2.69, -0.07, -0.57, 0.26, -2.64, -2.55, -0.67, -4.05, -0.11051058745176379, -1.63, -1.34, -0.52, -2.78, -0.17, -0.67, 0.17, -3.46, -5.95, 5.861428571428572, -1.9, -3.41, 0.41, -0.97, -0.68, 0.15, -2.13, 0.51, 0.0, 0.84, 2.75, 1.57, 3.95, 2.52, 2.83, 3.68, 1.33, 4.05, 3.53, 4.4, -1.07, 1.61, -2.83, -1.82, -1.96, -1.84, -2.29, -1.37, -1.08, -0.26, -2.53, 0.1, -0.4, 0.43, -2.2, -0.93, 0.3, 1.13, -1.17, 1.49, 0.99, 2.0721774376417237, -2.37, -1.17, 0.86, -2.27, 5.47, -0.13, 0.0, 3.88, -3.94, -1.94, -0.71, -2.75, 4.07, 3.72, 1.82, 2.38, -1.11, -5.66, 5.66, 5.57, -1.83, 5.83, -3.66, -5.46, 2.73, -6.88, 9.96, 4.59, 6.92, -3.9228690476190478, -1.23, 0.83, -1.46, 1.19, 0.69, 1.53, -5.5, -2.04, -2.27, 0.36, -0.15, 0.69, 0.24, 2.69, 2.18, 3.03, -2.18, -2.63, -2.39, -0.5, 0.33, -1.86, -1.91, -2.32, 4.82, -3.23, -4.58, -2.03, -1.99, -1.9, 0.84, -2.55, -1.55, -0.83, -1.02, -1.91, -2.71, -1.81, -2.68, -3.39], ['362', 0.92, 0.37, 0.26122171562045876, 0.36, -0.65, 0.02, -0.13588474204017084, -0.7, -0.99, 0.05, 1.6, 0.35, -1.11, -1.74, 1.05, -0.01, 0.32, 0.23, -3.45, 0.46, -0.04, 0.63, 0.44, 1.06, -1.15, 0.21, -1.53, -1.23, -2.67, -3.29, -0.54, -1.58, -1.26, -1.35, -4.97, -1.12, -1.61, -0.95, -1.14, -0.53, 0.54, -2.76, -0.3, -1.46, -2.08, 0.7, -0.3590816326530612, 0.009278911564625847, -0.12, -3.79, 0.11476190476190476, -0.39, 0.28, 0.7214285714285714, 0.71, -0.14, 0.47, -1.52, -1.199047619047619, 1.17, -0.64, 2.19, 1.12, 1.45, 1.36, -2.37, 1.59, 1.09, 1.76, 1.57, 2.2, -0.98, 1.82, 2.84, 1.76, 2.1, 2.01, -1.74, 2.25, 1.74, 2.41, 2.22, 2.85, -1.81, -1.22, 1.2, -0.99, -1.0494795918367348, -0.72, -0.81, -4.46, -0.58, -1.08, -0.42, -0.61, 0.01, 2.55, 0.06, 0.33, 0.24, -3.45, 0.47, -0.03, 0.64, 0.45, 1.07, -0.008858126000982985, 0.02, -1.68, -0.13, -0.18, 0.0, -0.27, 0.04659939068867647, -3.77, 0.14, -0.35931972789115646, 0.31, 0.12, 0.74, -0.31, -0.18, -3.68, 0.23, -0.27, 0.4, 0.21, 0.83, -0.73, -1.03, 0.51, -0.52, 5.08, 0.05, 0.29, 0.19, -0.25, -0.1, 0.38, -1.36, 0.78, 0.21, 0.07, 0.44, -0.39, -0.36, 0.3, 0.27, -0.11, 0.27, -0.18, -2.24, 1.164765264284247, -0.93, -1.01, 0.61, 0.82, -0.7, 3.950378684807256, 4.06, 3.54, 4.23, 4.04, 4.68, -0.32, -0.41, -0.5, 0.17, -0.02, 0.6, 0.09, 0.67, 0.48, 1.1, -1.02, -1.46, -0.58, -0.19, 0.43, -0.1, -0.09, -0.6, -0.41, -2.0, 0.27, 0.73, 0.5510935020800125, -0.39, 0.62, -0.15, 0.11, -0.33, -0.47523809523809524, 0.38, -1.0, 2.66, 0.013037664716236297, -2.24], ['363', -0.29, -0.21, -0.12984710169072947, 0.18, -0.3, -0.17, 0.69, -0.59, -0.51, -0.25, 1.47, -1.05, 0.27, 0.27, 0.57, -0.45, 0.04, 0.03, -0.95, -0.05, -0.57, -0.25, 0.07, -0.35, -0.44, 0.01, -1.7, -2.48, -1.18, -1.19, -0.89, -1.89, -1.41, -1.42, -2.38, -1.5, -2.01, -1.7, -1.38, -1.7461582768021608, -0.13, -1.14, 0.81, 1.34, 1.4978753944468233, 1.63, 0.61, 1.1, 1.09, 0.1, 1.01, 0.48, 0.81, 1.13, 0.71, -1.52, -0.29, 0.22, 0.0, -0.52, -0.01, 0.29, -0.72, -0.24, -0.24, -1.22, -0.32, -0.676578845757417, -0.52, -0.21, -0.62, -0.98, -0.52, 0.3, -0.71, -0.23, -0.23, -1.21, -0.32, -0.84, -0.52, -0.2, -0.62, -1.37, -0.48, 0.41, -0.81, -1.01, -0.53, -0.53, -1.51, -0.61, -1.13, -0.81, -0.5, -0.91, 0.35, 0.2, 0.49, 0.48, -0.5, 0.4, -0.12, 0.2, 0.52, 0.1, -0.17, 0.22, -0.56, -0.26, -0.17, -0.26, -0.29, -0.01, -0.99, -0.09, -0.61, -0.29, 0.03, -0.3314153161169343, -0.09, -0.28, -0.98, 0.012244713705627006, -0.6, -0.28, 0.04, -0.38, -0.12, -0.1, 0.27, 0.23318678362356798, 0.98, -0.02, 0.0, 0.99, -1.02, -0.49, 0.2, -0.8497402597402597, 0.3, 0.46, 0.27, -0.12, 0.003079789868779062, -0.77, 0.71, 0.79, -0.26, 1.42, -0.53, -1.24, 0.61, -0.88, 2.76, 0.5, 0.75, -0.3, 0.7, 0.91, 0.38, 0.7, 1.03, 0.6, -0.72, -0.2, -0.52, -0.2, 0.12, -0.3, 0.32, 0.32, 0.64, 0.22, -0.45, -0.83, 0.0, 0.32, -0.1, -0.26, -0.21, -0.65, 1.6, -0.59, -1.44, -0.23, -0.79, -0.32, -0.42, -0.25, -0.24, -0.05, -0.12, -0.23, 0.1, 1.64, -0.41, -0.18], ['364', -0.69, -0.32, 0.05122171562045875, 0.07, -0.1170209190089404, 0.85, 1.0041152579598291, 1.41, 0.48, 0.85, 0.47, 0.42, 0.46, -0.51, -2.7, 1.14, 0.87, 0.67, -3.77, 1.47, 0.71, 1.27, -0.42, 1.08, 0.48, 0.54, 0.38, -0.05, 0.0, -0.97, -3.15, 0.67, 0.4, 0.21, -4.22, 1.0, 0.24, 0.8, -0.89, 0.61, 2.01, -0.5250638007838266, 0.43, 0.05, -0.92, -3.1, 0.72, 0.46, 0.26, -4.17, 1.05, 0.29, 0.9438655564790018, -0.84, 0.67, 0.68, 0.74, 0.66, 0.73, 0.38, -0.96, -3.15, 0.67, 0.41, 0.21, -4.21, 1.01, 0.25, 0.81, -0.88, 0.62, 0.94, 1.36, -2.21, 1.65, 1.39, 1.19, -3.28, 1.99, 1.22, 1.79, 0.08, 1.6, 0.37, 2.9, -2.92, 3.65, 3.95, 3.67, 3.47, -1.1, 4.29, 3.51, 4.08, 2.34, 3.89, -2.4, -0.29, -0.26, -0.46, -4.85, 0.33, -0.42, 0.13, -1.54, -0.05, 0.03, -0.36, -2.09, 0.36, 0.78, -0.14, -0.02, -0.2, -4.6, 0.6, -0.16, 0.4, -1.29, 0.21, -0.41, 0.17, -4.41, 0.8, 0.04, 0.59, -1.09, 0.6521774376417234, 0.74, 0.45, 0.23, 0.32, -7.08, 0.0, -0.14, 1.55, -1.54, -0.76, -0.45, 2.18, 1.37, -0.73, -0.35, -0.31, 0.71, 1.02, -1.01, -1.11, 0.36, 2.3, 0.77, -0.33, 0.14, -0.12, -3.4, 0.0, 0.13, -1.27, 4.8, 5.45, 4.65, 5.24, 3.47, 5.04, 1.08, -0.62, -0.75, -0.2, -1.87, -0.38, 0.14, 0.56, -1.13, 0.37, 0.58, 0.53, -0.42, -1.67, -0.19, 0.36, 0.3, 1.44, -0.98, -1.86, 1.03, -1.0, 0.77, 1.28, 1.52, 1.2, -0.69, 0.32, 1.78, 0.55, -0.23, 0.46024063436563456, 2.9, -0.33], ['365', -5.08, 0.04, -0.028778284379541254, 0.09, -1.06, -0.11, 0.6700361663652803, -0.41, -0.2, -0.15, 0.28, -1.14, 0.66, 1.25, 0.46, 1.46, 0.45, -0.23, -0.56, 2.33, -0.55, -0.35, 0.41, 0.42, -1.14, -0.87, -0.43, -1.4098214285714286, 0.3846428571428572, 1.10318993704708, 0.18, 1.18, 0.17, -0.51, -0.84, 2.05, -0.83, -0.63, 0.13, 0.13, -0.42, -1.19, 1.189303232481804, 1.82, 2.41, 1.61, 2.63, 1.61, 0.92, 0.58, 3.51, 0.59, 0.79, 1.56, 1.57, -0.42, 0.04, 0.15, -0.6, -0.81, 0.58, -0.2, 0.8, -0.21, -0.88, -1.21, 1.66, -1.21, -1.01, -0.25, -0.21581519274376415, 1.45, -1.38, -0.78, 0.21, -0.78, -1.46, -1.79, 1.07, -1.78, -1.58, -0.83, -0.82, -0.64, -1.5, 1.49, -0.61, 1.0, 0.0, -0.68, -1.01, 1.87, -1.01, -0.81, -0.05, -0.04, -3.2679047619047616, -1.512633468783437, -0.99, -1.67, -1.99, 0.86, -1.99, -1.79, -1.04, -1.03, 0.07, -1.61, -3.589822996574516, -0.47, -0.52482093036566, -0.39, -0.5381905235138708, -0.68, -1.01, 1.87, -1.0, -0.8, -0.05, -0.04, -0.09, 0.07, -0.33, 2.57, -0.33, -0.13, 0.64, 0.64, -0.49, -0.04, 0.15603717887804044, -0.65, -9.63, -0.03, -0.09, 1.5, -1.52, -0.73, -0.43, -1.8297402597402599, 4.84, 0.94, 0.45, -2.51, 0.3, -1.47, 1.49, 1.36, -0.46, 2.22, -0.93, -0.42, 0.18, -1.84, 5.97, 1.29, 1.79, -4.88, 0.41, 2.91, 0.01, 0.21, 0.97, 0.98, -1.46, -2.43, -2.82, -2.63, -1.8712346938775508, -1.8785714285714286, 0.4, 0.2, 0.97, 0.97, -0.22, -0.42, 0.2, 0.76, 0.77, -0.47, -0.51, -0.38, 3.65, -2.45, -3.65, -1.84, -1.16, -0.56, 0.01, -0.48, -0.63, 0.24, 0.53, -0.15, -0.57, -3.48, -2.07, -0.61], ['366', -2.89, -0.35, 0.011221715620458745, 0.23, -1.19, -0.31158037632624047, -0.6858847420401708, -1.45, -1.16, -1.92, -0.36, -1.72, -1.35, -0.8, 0.91, -1.46, -1.31, -1.97, -0.89, -1.04, -2.37, -0.93, -0.6356947683993238, -1.73, -1.1, -0.540628585411108, -1.5373416050068875, -1.36, -0.99, -0.29681006295292, 1.3278199712950913, -1.11, -0.96, -1.62, -0.54, -0.68, -2.02, -0.57, -0.37, -1.38, -1.4, -1.41, -0.21, 0.38, 0.94, 2.67, 0.26, 0.41, -0.26, 0.84, 0.69, -0.67, 0.8938655564790019, 1.0, -0.02, -1.45, -1.13, -0.75, -1.25, -0.58, 0.56, 2.28, -0.12, 0.03, -0.63, 0.46, 0.31, -1.04, 0.42, 0.62, -0.39, -1.6763939988582846, -1.14, 1.72, -0.67, -0.3705105874517638, -1.19, 0.14747644815501967, -0.24, -1.59, -0.13, 0.06, -0.94, -1.71, -3.26, 3.22, -2.7633017616146796, -2.35, -2.2, -2.85, -1.78, -1.93, -3.25, -1.82, -1.62, -2.61, -0.77, -0.3926334687834371, 0.15, -0.52, 0.8866683673469387, 0.43, -0.93, 0.54, 0.74, -0.27, -0.12, -0.41, -1.69, -0.42, -0.62, -0.23, -0.61, -0.66, 0.43, 0.28, -1.07, 0.39, 0.59, -0.42, -0.8334639289282145, 0.05, 1.1, 0.95, -0.41, 1.06, 1.26, 0.24, -0.68, -0.54, 0.06, -0.37, -2.16, -0.24, -0.21, -0.26, 0.24, 0.13, -0.29, -1.43, 1.8, 0.8, 0.38, -1.4, -0.38692021013122097, -1.29, 1.27, 1.23, -0.44, -0.39, -0.86, -3.33, 1.68, -1.76, 4.31, 1.19, 1.77, -1.7, -1.04, -0.15, -1.49, -0.04, 0.16, -0.85, -1.25, -0.89, -1.35, 0.11, 0.31, -0.7, 0.46, 1.48, 1.68, 0.66, -1.14, -1.56, -1.0, 0.3932337781266354, -0.81, -0.42, -0.44, -1.41, 2.03, -1.35, -2.05, -0.11, -0.7989064979199876, -1.2, -1.01, -0.58, 0.3, -0.47, -0.56, -0.29, -0.19, -1.13, -1.15, -0.27], ['367', 5.21, 0.56, 0.07122171562045874, 0.03, 0.99, 1.25, 0.6, 2.16, 1.69, 2.39, 0.7303184712113286, 1.82, 1.26, 0.13, -0.9, 1.28, 0.86, 1.85, 2.46, 1.87, 3.04, 1.21, 0.95, 1.33, 2.49, 2.27, 1.87, 1.3, 0.74, -0.39, -1.4, 0.76, 0.34, 1.32, 1.94, 1.35, 2.51, 0.69, 0.44, 0.81, 2.21, 1.95, 0.56, -0.56, -1.66, -2.67, -0.54, -0.95, 0.02, 0.63, 0.05, 1.19, -0.6, -0.85, -0.49, 1.9800628463056764, 1.93, 1.16, 2.03, 1.12, -1.11, -2.12, 0.02, -0.39, 0.58, 1.19, 0.61, 1.76, 0.09295748299319728, -0.3, 0.07, 1.13, 2.26, -1.02, 1.15, 0.73, 1.71, 2.33, 1.74, 2.91, 1.08, 0.82, 1.2, 1.7, 4.0, -3.96, 3.32, 2.19, 1.77, 2.77, 3.39, 2.79, 3.97, 2.13, 1.87, 2.24, 3.57, 1.11, -0.41, 0.56, 1.17, 0.59, 1.74, -0.06, -0.32, 0.05, 0.6, 1.18, 2.48, 1.14, 1.22, 1.24, 1.52, 0.98, 1.59, 1.01, 2.16, 0.35, 0.09, 0.46, 1.17, 0.54, 0.61, 0.03, 1.17, -0.62, -0.88, -0.51, 1.35, 1.13, 0.23, 1.76, 10.77, 0.6, 0.9428571428571428, -1.79, 1.71, 0.87, 0.52, 1.41, -1.05, -2.33, -1.17, 2.58, 0.49, 3.69, -3.58, -3.37, 1.14, -2.66, 2.3, 0.25, -0.1, 4.48, -8.49, -3.0, -4.53, 0.97, -0.07, -0.58, 0.56, -1.22, -1.47, -1.11, 3.46, 0.51, 1.14, -0.65, -0.9, -0.54, -0.62, -1.77, -2.02, -1.66, 1.76, 1.88, 1.17, -0.26, 0.11, 1.12, 1.29, 2.04, -4.9, 2.44, 5.0, 2.73, 2.23, 1.43, 0.37, 1.97, 0.99, 0.26529795204795226, 0.29, 0.49, 1.05, 4.74, 3.3, 1.05], ['368', -0.08, 0.42, -0.07984710169072946, -0.01, -0.29, 0.08, 0.5, 0.71, 0.37, 0.43, 0.52, -0.06, 0.11, -0.03, -0.61, 0.87, 0.6, 0.31, 1.55, 1.55, 0.39, 0.36, 0.06, 0.41, 0.8, 0.23937141458889197, -0.09, -0.58, -0.42, -0.55, -1.0721800287049086, 0.34, 0.07, -0.21, 1.03, 1.02, -0.13, -0.17, -0.46, -0.11, 2.24, 0.4808975626058773, 0.5, 0.17, 0.03, -0.55, 0.93, 0.66, 0.37, 1.62, 1.61, 0.45, 0.42, 0.12, 0.47, 0.9900628463056765, 0.22, 0.87, 0.52, 0.33, -0.14, -0.72, 0.76, 0.49, 0.21, 1.4671802721088434, 1.44, 0.28, 0.25, -0.05, 0.31, 0.75, 0.47, -0.58, 0.9, 0.63, 0.34, 1.59, 1.58, 0.42, 0.39, 0.09, 0.45, -0.1, 1.0, -1.03, 1.05, 1.49, 1.22, 0.93, 2.18, 2.17, 1.01, 0.98, 0.67, 1.03, -0.81, -0.43, -0.27, -0.55, 0.68, 0.68, -0.47, -0.5, -0.8, -0.45, 0.19, -0.42, 1.31, 0.1, 0.19517906963433995, 0.10567351865003197, -0.16, -0.28, 0.95, 0.95, -0.21, -0.24, -0.54, -0.12141531611693432, 0.17, 0.17307674813036728, 1.24, 1.23, 0.08, 0.05, -0.25, 0.1, 0.51, 0.57, -0.1, 0.0, -2.58, -0.08, -0.14, 0.03, -0.04, 0.0, 0.98, -0.09383646788795053, 1.92, -0.18, -0.12, -0.07, -0.04, 0.28, -0.39, -0.25, 0.11, 0.02, 0.19, 1.06, -0.55, -0.56, 0.83, 0.36, 0.57, -1.94, -1.1, -0.01, -1.15, -1.18, -1.48, -1.12, 0.28, -1.09, -1.14, -1.17, -1.47, -1.12, 0.05, -0.03, -0.33, 0.02, 0.36, 0.22, 0.08, -0.3, 0.06, 0.11, 0.04, 0.77, -0.19, 0.5, -0.19, 0.6872638105244333, -0.13, 0.38, 0.36, -0.25, -0.21978021978021978, 0.16, -0.14, 0.694626243824729, 0.02, -0.6697593656343656, -0.51, -0.18], ['369', 2.85, 0.3, -0.29, 0.26, 0.35, -0.49, -0.35, 0.62, -0.62, -0.56, 0.46, 0.1, -0.34, -1.16, -1.75, -2.319285714285714, -1.17, -0.5594285714285715, -0.35, -0.4, -0.56, -1.3738418367346938, -0.17, -0.22, -0.18, 0.67, -1.02, -0.36, -0.79, -1.61, -2.19, -2.76, -1.62, -1.02, -0.8, -0.85, -1.02, -1.84, -0.62, -0.68, 1.06, -0.68, -0.66, -0.43, -1.26, -1.84, -2.3989563492063493, -1.27, -0.66, -0.44, -0.5, -0.66, -1.49, -0.26, -0.32, 0.68, 0.9157142857142857, 0.0, -0.94, -0.23, -0.82, -1.41, -1.9857142857142858, -0.84, -0.23, -0.01, -0.06, -0.23, -1.06, 0.17273474541331685, 0.11, 0.47, 0.6, -0.59, -1.18, -0.01, 0.6, 0.82, 0.77, 0.6, -0.24, 1.0, 0.95, -0.97, 1.01, -1.1, 1.2, -0.58, 0.59, 1.2, 1.42, 1.37, 1.2, 0.44571428571428573, 1.61, 1.55, 1.82, 1.8, 1.18, 1.8, 2.02, 1.97, 1.8, 0.95, 2.2, 2.15, -0.11, 1.83, 1.44, 0.12, 0.23, 0.21, 0.61, 0.61, 0.83, 0.78, 0.61, -0.23, 1.02, 0.96, 0.69, 0.0, 0.22, 0.17, 0.0, -0.83, 0.5985714285714285, 0.34, 0.11, 0.73, 0.5, 0.54, 5.34, -0.2496768707482993, -0.22, -1.18, 1.2, 0.28, 0.39, -0.56, 0.35, -0.28857142857142853, 0.3082806122448981, 1.48, -0.24, 0.56, -0.3771428571428571, -0.3042857142857143, -0.49, -1.69, 0.21, -2.56, 1.31, 1.81, -0.8172908163265306, -1.18, -1.84, -0.51, -0.22, -0.05, -0.22, -1.05, 0.18, 0.12, 0.46, -0.17, -0.17, -1.0, 0.23, 0.18, 0.0, -0.83, 0.4, 0.34142857142857147, -0.63, -0.96, 0.84, 1.24, 1.19, 0.07, 0.32, 0.62, -0.41, 0.97, 0.33, -0.22, 0.05, -0.4, -0.06, -0.38, -0.28, -1.07, -1.48, -0.71, -0.34, 1.11, 1.38, 0.23], ['370', -1.62, 1.26, 0.25, -0.18, 1.01, 1.12, 0.9641152579598291, 2.12, 2.23, 1.35, -1.74, 0.35, -1.3, -2.26, -0.21, 1.6711360544217686, -0.8, 0.47020578231292515, 6.41, 0.01, 2.39, 0.51, -0.67, 0.0, 2.12, 2.33, 3.14, 2.13, 0.45, -0.53, 1.56, 3.44, 0.96, 2.22, 8.29, 1.78, 4.2, 2.29, 1.09, 1.8138417231978392, 1.46, 4.274936199216174, 0.990204081632653, -1.65, -2.6, -0.56, 1.28, -1.14, 0.08, 6.03, -0.34, 2.03, 0.15, -1.02, -0.35, 1.6900628463056764, 1.94, 1.7, 2.51, 2.69, -0.97, 1.11, 2.97, 0.51, 1.76, 7.81, 1.33, 3.74, 1.83, 0.64, 1.32, 2.23, 3.6914285714285713, 2.1, 3.98, 1.5, 2.76, 8.87, 2.32, 4.76, 2.8314285714285714, 1.62, 2.31, 3.18, 5.47, -5.48, 1.56, 1.85, -0.59, 0.65, 6.63, 0.4137447711019141, 2.61, 0.72, -0.46, 0.21, -0.21, -0.28, -2.39, -1.18, 4.7, -1.6, 0.74, -1.11, -2.27, -1.61, 0.74, -0.28, 1.81, 0.79, 1.23, 1.31, 2.16, 1.24, 7.26, 0.81, 3.21, 1.31, 0.12, 0.8, 0.17653607107178546, 0.91, 5.94, -0.43, 1.94, 0.07, -1.1, -0.44, 2.18, 1.98, -0.08, 1.4, -0.44, 0.31, 0.21, -2.71, 2.75, 1.38, -2.37, 1.47, -2.68, -2.5, -1.27, -0.82, 0.58, 3.97, -3.9, -3.83, 1.26, -4.15, 2.57, 2.73, -1.38, 6.42, -3.73, -4.25, -6.46, 2.6171309523809523, -4.75, -6.01, -3.77, -5.55, -6.65, -6.02, 3.81, 1.34, 2.38, 0.5, -0.68, -0.01, -1.02, -1.84, -2.99, -2.34, 2.13, 2.84, 0.84, -1.17, -0.5, 1.31, 1.36, 2.03, -2.35, 1.89, 2.18, 2.16, 1.62, 2.03, 0.68, 1.74, 1.12, 0.12, 0.51, 1.15, 1.35, 3.4, 2.51, 1.62], ['371', -0.38, 0.0, 0.09122171562045875, 0.05, -0.89, -0.11, -0.4558847420401708, 0.07, -0.19, -0.23, -0.09939115646258503, -0.18, -0.52, -0.85, 0.28, -0.4, 0.13, -0.08, 4.49, 1.19, -0.09, -0.13, 0.14, 0.08, -0.47, -0.11, -0.12, -0.07, 0.007674603174603278, -0.73, 0.39, -0.2897142857142857, 0.24, 0.04, 4.61, 1.3, 0.03, -0.01, 0.25, 0.19, -1.04, -0.25506380078382657, -0.05, -0.25880253250388296, -0.67, 0.46, -0.22, 0.31, 0.1, 4.68, 1.37, 0.09, 0.05, 0.32, 0.26, -0.17, -0.38, 0.48, 0.29, 0.29, -0.33, 0.8, 0.11, 0.65, 0.44, 5.04, 1.8339757335335067, 0.44, 0.39, 0.66, 0.6, 0.55, 0.62, 1.13, 0.45, 0.98, 0.77, 5.39, 2.05, 0.77, 0.73, 0.99, 0.93, -0.18, -0.91, 0.95, -0.51, -0.68, -0.15, -0.35, 4.21, 0.9, -0.36, -0.4, -0.14, -0.2, 0.38, 0.17, 0.54, 0.33, 4.92, 1.6, 0.32, 0.28, 0.54, 0.49, -0.23, 0.12, -1.38, -0.07840181931709851, -0.14, -0.09, -0.36, -0.21, 4.36, 1.05, -0.21, -0.26, 0.01, -0.05, -0.08, -0.16, 4.58, 1.26, -0.01, -0.05, 0.21, 0.16, -0.45, -0.48, 0.27, -0.14, 1.27, -0.09, -0.15, 0.37, -0.23827987418743707, -0.18, 0.14, -0.68, 2.71, 0.27, 0.11, -0.2, 0.16307978986877908, -0.35, 0.37, 0.33, -0.07670919513614705, 0.49, -0.24, -1.14, 0.56, -1.07, -1.12, 0.71, 1.04, -2.344384920634921, -4.52, -3.17, -4.38, -4.42, -4.17, -4.22, -0.34, -1.4, -1.26, -1.3, -1.04, -1.09, -0.15, -0.04, 0.22, 0.17, -0.15, -0.02, -0.11, 0.26, 0.21, -0.11, -0.11, 0.14, -0.52, -1.16, 0.58, -0.17, -0.29, -0.37, -0.05, 0.14, -0.07, -0.2, 0.05, 0.25, -0.31, -0.38, -0.8584047619047619, -0.79], ['372', 9.71, 0.0, 0.04, -0.03, 1.29, 0.58, 0.75, 1.18, 0.87, 0.4453571428571429, -0.6, -0.5606751700680271, -1.19, -0.1, -1.64, -2.05, -0.75, 0.11, -0.5, -1.55, 0.64, 0.31, -0.83, -0.75, 0.95, 1.32, 0.98, 0.03, -0.6, 0.5, -1.05, -1.45, -0.15, 0.71, 0.1, -0.96, 1.25, 0.91, -0.23, -0.15, 1.5, 0.55, 0.96, -0.5388025325038829, 0.47, -1.08, -1.48, -0.17, 0.69, 0.08, -0.98, 1.22, 0.89, -0.26, -0.18, 0.77, 1.91, 0.88, 1.36, 1.59, 1.11, -0.45920068027210886, -0.86, 0.45, 1.32, 0.7, -0.23602426646649322, 1.86, 1.52, 0.37, 0.45, 1.69, 0.48, -1.54, -1.95, -0.65, 0.21, -0.4, -1.45, 0.75, 0.41, -0.73, -0.65, 0.59, 2.89, -2.93, 2.0966982383853203, -0.41, 0.91, 1.79, 1.17, 0.09, 2.33, 1.99, 0.83, 0.91, 3.24, 2.47, 1.33, 2.3053350340136056, 1.58, 0.5, 2.75, 2.4, 1.24, 1.32, 0.28, 2.44, 2.53, 0.82, 0.82, 0.87, 1.13, 0.86, 0.25, -0.81, 1.4, 1.06, -0.08, -0.01, 0.26, 0.27, -0.61, -1.66, 0.53, 0.2, -0.94, -0.86, 0.68, 0.68, 0.02, 0.99, 9.72, 0.05, -0.03, -1.51, 1.47, 0.72, 0.25406627346681526, 0.8, -3.8094817511227284, -1.65, -0.89, 4.77, 0.34, 2.45, -2.61, -2.51, 0.82, -2.25, 1.67, 0.97, -0.51, 3.42, -2.17, -2.33, -3.37, 4.04, 0.88, -1.06, 1.15, 0.81, -0.33, -0.26, 2.51, 1.9601587301587302, 2.23, 1.89, 0.74, 0.81, -0.27, -0.33, -1.46, -1.39, 0.89, 0.89, 0.07, -1.13, -0.9877512446849838, 0.84, 0.86, 1.13, -1.16, 1.72, 1.28, 1.78, 1.18, 1.21, 0.08, 0.95, 0.7, 0.42, 0.24, 0.68, 1.14, 2.55, 1.88, 2.1], ['373', 1.5, -0.25, -0.31877828437954125, -0.01, 0.83, 0.54, 0.07411525795982916, 0.72, 0.07, -1.34, -1.24, -1.5, -1.66, -2.46, -2.96, -1.28, -2.6, -1.06, 0.11, -3.08, -1.75, -2.69, -2.13, -1.73, 0.48, -0.36, -0.1, -0.26, -0.42, -1.23, -1.73, -0.04, -1.37, 0.19, 1.37, -1.86, -0.51, -1.47, -0.9, -0.49, 1.1574684253532108, 0.0, 0.16, -0.16, -0.97, -1.48, 0.22, -1.12, 0.45, 1.64, -1.6, -0.25, -1.21, -0.64, -0.23, 0.52, 0.25, 0.78, 0.73, 0.32, -0.82, -1.32, 0.38, -0.96, 0.7126050661400617, 1.8, -1.45, -0.09, -1.05, -0.48, -0.07, 0.33, 1.15, -0.51, 1.21, -0.15, 1.44, 2.64, -0.64, 0.73, -0.24, 0.34, 0.75, -0.48, 2.53, -2.6, 1.69669823838532, 1.72, 0.36, 1.96, 3.16, -0.13, 1.25, 0.27, 0.85, 1.27, 0.0, 0.017366531216562897, -1.33, 0.23, 1.41, -1.82, -0.47, -1.43, -0.86, -0.45, -0.39, -0.06, 0.72, 0.68, 0.6, 0.86, 1.29, 1.59, 2.79, -0.49, 0.88, -0.09, 0.48, 0.9, 1.3, -0.29, 1.18, -2.05, -0.7, -1.65, -1.09, -0.68, 0.89, 1.34, -0.13, 1.21, 0.03, 0.13225133596562166, -0.62, -2.19, 2.23, 1.1, 1.01, 0.69, -3.55, -1.35, -0.67, 0.72, 0.04, 2.04, -2.13, -1.93, 0.69, -3.25, 1.39, 0.45, -0.31, 3.88, -1.96, -2.51, -3.83, 3.55, -1.45, -3.19, -1.86, -2.8, -2.24, -1.84, 2.01, 1.8, 1.38, 0.4, 0.98, 1.4, 0.41, -0.96, -0.39, 0.02, 0.0927953514739229, 0.14, 1.39, 0.57, 0.99, 0.63, 0.69, 0.69, -0.96, 1.0101996269574993, 1.1, 0.31, 0.4611825396825397, 0.81, 0.42, 0.68, 1.23, 0.38, 0.01, 0.3846262438247291, 0.39, 1.37, 1.14, 0.56], ['374', 0.79, -0.99, 0.12, -0.11, -0.81, 0.33841962367375944, 1.39, 0.44, 0.1, 0.65, 0.01, -0.26, 0.29, -1.74, 0.06, 0.5, 0.52, 0.64, 2.135862135879993, 1.66, 0.23733548208735894, 0.98, -0.08, 0.62, 0.37, 0.14, 0.6726583949931124, -0.27, 0.28, -1.75, 0.05, 0.5, 0.51, 0.63, 1.96, 1.65, 0.19, 0.97, -0.08, 0.61, 0.3, -0.06506380078382656, 0.91, 0.55, -1.48, 0.32, 0.77, 0.78, 0.91, 2.23, 1.93, 0.46, 1.24, 0.19, 0.88, 0.07, 0.44, -0.07, -0.61, 0.43924524706587753, -2.02, -0.22, 0.22, 0.23, 0.36, 1.67, 1.37, -0.08, 0.69, -0.36, 0.33, -0.82, 2.43, 1.83, 2.29, 2.3, 2.43, 3.77, 3.46, 1.98, 2.77, 1.7, 2.4, 0.0, 1.6, -1.61, 0.59, 0.44, 0.46, 0.58, 1.9, 1.6, 0.14, 0.92, -0.14, 0.56, 2.84, 0.14, 0.01, 0.14, 1.45, 1.15, -0.3, 0.47, -0.58, 0.12, -0.02, 0.16, 0.38, 0.15, 0.33, -0.03, 0.13, 0.12, 1.44, 1.14, -0.32, 0.46, -0.59, 0.1, -0.45, 0.01, 1.31, 1.01, -0.44, 0.34, -0.71, -0.02, 0.34, 0.17, -0.26, 0.13, 8.22, 0.0, -0.07, 0.46, -0.4, -0.21, -0.66, 0.54, 1.92, -0.26, -0.13, 0.4, -0.32, 0.38, -0.39, -0.41, 0.13, 0.62, 0.29, 1.63, -0.81, 0.44, 0.93, -0.24, -0.4, -1.85, -1.29, -0.3, -1.73, -0.97, -2.0, -1.32, 0.35, -0.99, -1.43, -0.67, -1.71, -1.02, 0.45, 0.78, -0.28, 0.42, 0.11, -0.34, -0.33, -1.04, -0.36, 0.16, 0.22439630127529087, 0.5, 0.27, 0.24, -0.23, 0.88, -0.08, 0.72, 0.7, 0.12, -0.15, -0.17, -0.31, 0.25, 0.03, 2.9, 0.43, -0.35], ['375', -2.67, -0.06, 0.21, 0.15, 0.19, 0.51, 0.32, 1.23, 0.68, 1.51, 0.82, 1.21, 0.68, 0.33, 0.4742210884353741, 2.29, 1.1271428571428572, 1.43, 2.24, 0.87, 1.48, -0.08, -0.55, 1.3, 1.1685936610075265, 1.47, 0.68, 0.39, -0.14, -0.49, -0.78, 1.45, 0.26, 0.6, 1.41, 0.05, 0.65, -0.9, -1.36, 0.47, 0.92, 1.09, 0.29020408163265304, -0.53, -0.87, -1.16, 1.06, -0.13, 0.21, 1.02, -0.34, 0.26, -1.28, -1.75, 0.08, 1.6023573314652815, 0.82, 0.78, 0.88, 0.82, -0.35, -0.64, 1.6, 0.4, 0.74, 1.55, 0.19, 0.79, -0.76, -1.219795918367347, 0.61, 0.9, 1.17, -0.29, 1.95, 0.75, 1.1, 1.91, 0.54, 1.14, -0.41, -0.88, 0.97, 1.13, 5.05, -5.2, 1.47, 2.25, 1.04, 1.39, 2.2, 0.83, 1.44, -0.12, -0.59, 1.26, -1.06, -0.76, -1.18, -0.84, -0.05, -1.38, -0.79, -2.32, -2.78, -0.97, 0.36, -0.76, -0.08, 0.19, 0.4, 0.19, 0.42, 0.34, 1.14, -0.21, 0.39, -1.16, -1.62, 0.21, 0.46, 0.08, 0.8, -0.55, 0.05, -1.49, -1.917142857142857, -0.13, 3.04, 3.07, 0.39, 1.07, -3.29, 1.468069549498121, 0.9628571428571429, -1.49, 1.45, 0.73, -2.11, 0.0, -1.31, -1.67, -0.81, -1.33, 0.11, 2.61, -2.58, -2.49, 0.81, -2.19, 1.61, -0.74, 0.37, 2.77, -2.34, -1.79, -2.84, 1.2, -0.72, -1.34, -0.75, -2.27, -2.73, -0.92, 2.4, 0.63, 0.6, -0.95, -1.41, 0.42, 0.03, -1.54, -2.0, -0.18, 0.61, 0.89, 1.59, -0.47, 1.38, 0.75, 0.85, 0.97, -1.01, 0.65, 0.59, 0.95, 1.18, 2.07, 1.86, 0.96, 0.96, -0.34, 0.17, 0.47, 0.21, 2.2, 1.16, -0.23], ['376', 2.87, 0.0, -0.08, -0.03, 0.64, 0.53, 1.144115257959829, 1.34, 1.45, 1.62, -0.26, 0.36, 0.73, 0.75, 0.36, 1.69, 0.71, 1.31, 1.71, 2.02, 2.29, -0.1, 0.95, 0.63, 1.28, 0.76, 1.89, 0.63, 0.99, 1.02, 0.63, 1.96, 0.98, 1.58, 1.98, 2.29, 2.644453670078569, 0.17, 1.21, 0.9, 0.53, 2.0800621118012423, 1.25, 0.36, 0.39, -0.01, 1.32, 0.35, 0.94, 1.34, 1.64, 1.9480654680864429, -0.46, 0.58, 0.27, 0.8, 1.01, 1.4, 1.38, 0.89, 0.03, -0.25515323205954743, 0.96, -0.01, 0.58, 0.98, 1.28, 1.56, -0.82, 0.22, -0.09, 0.86, 0.86, -0.39, 0.93, -0.04, 0.55, 0.95, 1.25, 1.53, -0.85, 0.19, -0.12, 1.94, 2.1, -2.07, 1.26, 1.33, 0.35, 0.95, 1.35, 1.65, 1.93, -0.46, 0.58, 0.27, 0.15, -0.07, -0.96, -0.37, 0.02, 0.32, 0.59, -1.76, -0.73, -1.04, 0.12, -0.01, 0.16, 0.56, 0.62, 0.51, 0.91, 0.59, 1.0, 1.29, 1.57, -0.8, 0.23, -0.08, 1.82, 0.31, 0.4, 0.7, 0.97, -1.39, -0.36, -0.67, 0.77, 0.86, 0.15603717887804044, 0.88, 0.3, 0.03, 0.0, -0.64, 0.61, 0.3, 0.13, 3.1102597402597403, 0.72, -1.13, -0.57, 1.4, 0.53, 1.77, -1.73, -1.7, 0.55, -1.0, 1.07, 0.3, -0.14, 2.77, -5.3, -1.82, -2.79, -0.88, -0.09, 0.3, 0.57, -1.78, -0.76, -1.06, 1.69, -0.38, 0.27, -2.07, -1.05, -1.36, -0.66, -2.34, -1.32, -1.62, 1.37, 1.49, 1.72, 1.05, 0.73, 0.58, 0.63, 1.42, -2.56, 0.51, 2.58, 1.11, 0.9, 0.67, -0.31, 0.55, 0.22, 0.3, 0.67, 0.66, 0.98, 1.03, 0.96, 0.89], ['377', 2.53, 0.69, -0.08, -0.13, 1.95, 0.99, 0.024115257959829165, 1.62, 0.91, 1.46, 0.39, 1.94, -0.39, -0.28, 0.87, 0.55, 0.11, 1.22, -2.58, -1.56, 1.93, -0.42, 0.89, 0.41, 1.62, 2.04, 1.07, 1.54, -0.7598809523809524, -0.67, 0.48, 0.16, -0.27, 0.83, -2.96, -1.94, 1.53, -0.8, 0.5, 0.02, 1.01, 2.6849361992161733, -0.47, -2.28, -2.18, -1.05, -1.36, -1.79, -0.71, -4.428347866419295, -3.44, -0.01, -2.31, -1.03, -1.5, 1.13, 1.54, 0.63, 1.3, 1.86, 0.11, 1.27, 0.94, 0.5, 1.7126050661400618, -2.2, -1.18, 2.33, -0.03, 1.282734745413317, 0.8, 2.43, 1.75, 1.16, 0.83, 0.39, 1.5, -2.31, -1.29, 2.21, -0.14, 1.17, 0.69, 1.12, 1.83, -1.94, 0.58, -0.32, -0.75, 0.34, -3.42, -2.42, 1.2152352330209475, -1.28, 0.01, -0.46, 2.49, 0.91, -0.44, 0.67, -3.11, -2.1, 1.37, -0.96, 0.33, -0.14, 0.48, 0.92, 0.41, 1.22, 1.02, 1.44, 1.35, 1.11, -2.69, -1.67, 1.81, -0.53, 0.77, 0.29, 1.87, 0.24, -3.75, -2.75, 0.7, -1.62, -0.33, -0.8, 0.11, 0.28, -0.26, 1.43, 5.21, -0.03, -0.37, -2.68, 2.7, 1.37, 0.57, 3.79, -5.6794817511227285, -2.43, -1.27, 1.23, 0.41, 3.64, -3.68, -3.61, 1.2, -4.14, 2.4, 2.43, -1.19, 3.99, -8.62, -2.77, -3.97, 5.883809523809524, 4.15, 1.04, 4.63, 2.532096371882086, 3.56, 3.06, 3.57, 3.07, 3.55, 1.17, 2.49, 2.0, -0.46, -2.3, -1.02, -1.49, 0.89, 1.39, 1.88, 1.31, 0.82, 1.2, 1.28, 1.52, -4.24, 1.56, 4.35, 1.96, 2.95, 0.57, -0.48, 1.46, 1.53, 0.39, 0.83, 0.49, 1.05, 2.15, 4.5130376647162365, 1.06], ['378', 1.35, -0.12, 0.09122171562045875, -0.05, 0.1, 0.65, 0.19, 1.26, 1.27, 1.42, -0.81, 0.81, 0.63, 0.02, 0.26, 0.94, 1.01, 0.84, -4.22, 0.85, 2.16, 1.12, 0.64, 1.18, 1.66, 0.46, 2.2826583949931125, 1.63, 1.45, 0.84, 1.08, 1.77, 1.83, 1.66, -3.439285714285714, 1.68, 3.0644536700785694, 1.94, 1.46, 2.0, 0.95, 2.45, 0.61, -0.17, -0.78, -0.54, 0.14, 0.2, 0.03, -4.99, 0.05, 1.34, 0.31, -0.16, 0.37, 0.87, 1.21, 1.32, 0.75, 0.78, -0.61, -0.37, 0.31, 0.37, 0.21, -4.82, 0.22, 1.52, 0.48, 0.01, 0.54, 1.23, 1.4, 0.24, 0.92, 0.99, 0.82, -4.24, 0.83, 2.14, 1.09, 0.62, 1.16, 2.01, 2.12, -2.09, 1.15, 0.68, 0.74, 0.57, -4.47, 0.7837447711019141, 1.89, 0.85, 0.37, 0.91, 0.68, 0.47, 0.06, -0.1, -5.12, -0.09, 1.2, 0.17, -0.3, 0.23, 0.58, 0.48, 0.8, 0.44, 0.54, 0.33, 0.41, -0.17, -5.18, -0.15, 1.14, 0.11, -0.36, 0.17, 0.3, 0.57, -5.02, 0.01, 1.31, 0.27, -0.2, 0.5821774376417235, 0.51, 0.31, 0.08, 0.21, 1.91, 0.05, -0.2, -0.36, 0.3, 0.15, 0.39, 1.37, -1.1, -0.9, -0.48, 0.66, 0.09, 1.38, -1.41, -1.31, 0.44, -0.59, 0.9, 0.9183906549799409, -0.42, 1.16, -4.77, -0.84, -1.21, 1.19, 5.89, 5.3, 6.66, 5.57, 5.08, 5.64, 1.34, 0.56, 1.29, 0.26, -0.21, 0.32, -0.72, -1.02, -1.48, -0.96, 1.24, 1.53, 0.3, -0.47, 0.06, 0.47, 0.41, 1.18, -0.75, 0.66, 0.63, 0.52, 1.09, 0.848637448200971, 0.53, 0.72, 0.55, 0.0, -0.09, 0.2, 0.24, 1.34, 1.81, -0.02], ['379', 5.8, 0.52, 0.04015289830927054, -0.2, 1.86, 1.2, 0.5741152579598292, 1.0, 0.99, 0.73, -0.35, 0.51, 0.4, -0.6, 0.22, -1.11, -0.1, 0.6454705215419502, 0.21, -2.68, 0.93, 0.6370289115646258, -0.42, 0.13, 1.4, 0.71, 1.09, 0.87, 0.76, -0.25, 0.57, -0.76, 0.26, 0.89, 0.56, -2.34, 1.29, 0.7, -0.06, 0.49, 1.37, 1.7249361992161734, 0.22, -0.028802532503882913, -1.11, -0.29, -1.61, -0.61, 0.02, -0.3, -3.18, 0.41, -0.17, -0.93, -0.38, 0.07, 0.38, 1.25, 1.09, 0.33, -1.0, -0.18, -1.5, -0.49, 0.13, -0.19, -3.07, 0.683421154242583, -0.06, -0.82, -0.25056122448979595, 1.5, 1.34, 0.82, -0.51, 0.51, 1.14, 0.81, -2.1, 1.53, 0.94, 0.18, 0.74, 1.21, 3.09, -3.11, 0.52, -1.32, -0.31, 0.32, -0.01, -2.89, 0.71, 0.12, -0.64, -0.08, 1.82, 1.86, 1.02, 1.66, 1.3315238095238096, -1.59, 2.06, 1.46, 0.7, 1.26, 0.21, 1.83, 0.33, 0.95, 1.08, 0.77, 0.83, 0.63, 0.3, -2.59, 1.02, 0.43, -0.32, 0.23, 0.17, 0.2, -0.32, -3.2, 0.39, -0.2, -0.95, -0.4, 1.27, 1.54, -0.25, 1.01, 5.27, 0.1, 0.07, -0.93, 0.94, 0.47, -1.71, 1.17, -6.98, -1.91, -1.0, 2.91, 0.75, 2.84, -2.81, -2.84, 0.95, -1.49, 1.89, 0.89, -0.46, 2.5, -7.059348639455782, -1.73, -2.57, 6.9, 0.53, -2.88, 0.72, 0.13, -0.63, -0.07, 2.82, 3.51, 3.71, 3.3471428571428574, 2.33, 2.89, -0.19, -0.58, -1.33, -0.78, 0.96, 1.07, 0.4, -0.75, -0.2, 0.95, 0.92, 0.89, -4.08, 0.43, 3.86, 1.24, 1.82, 1.16, 0.56, 1.47, 0.8645528598385742, 0.74, 0.39, 0.47, 0.6, 1.78, 1.61, 1.36], ['380', -28.17857142857143, -0.37, 0.15122171562045875, -0.15, -1.35, 0.61, 0.6441152579598292, 2.23, 1.11, 1.81, 1.06, 1.05, -0.55, 0.02, -0.18, 7.230714285714286, 0.92, 1.52, 2.2, 1.45, 1.99, 2.1270289115646257, 0.45, -0.12, 1.45, -0.62, 0.74, -0.01, -1.5798809523809525, -1.03, -1.23, 6.1, -0.14, 0.45, 1.137761904761905, 0.39, 0.92, 0.76, -0.61, -1.17, 2.88, 1.44, 0.75, -1.5763410188391391, -1.02, -1.21, 6.354266594516595, 0.17865136054421765, 0.47, 1.13, 0.4, 0.93, 0.77, -0.59, -1.16, 0.99, 3.16, 2.29, 0.75, 2.37, 0.57, 0.37, 7.82, 1.48, 2.08, 2.76, 2.01, 2.56, 2.39, 1.0, 0.43, 1.97, 1.8, -0.19, 7.21, 0.91, 1.51, 2.18, 1.44, 1.98, 1.81, 0.43, -0.07644035827487929, 1.11, 3.61, -3.52, 1.99, 7.42, 1.1, 1.7, 2.38, 1.63, 2.17, 2.01, 0.6385238095238095, 0.06, -5.8, -5.05, -5.88, -5.32, -4.69, -5.39, -4.88, -4.797183003504432, -6.32, -6.85, 0.65, -5.07, 1.93572371188304, 0.93, 0.5, 0.47, 0.88, 0.59, 1.26, 0.53, 1.06, 0.9, -0.47, -1.03, -0.04, 0.29, 0.9136855802927233, -0.07, 0.47, 0.3, -1.06, -1.62, 1.64, 0.84, -0.36, 1.25, -11.682380952380951, 0.28, 0.15, -2.61, 2.64, 1.33, 0.23, 0.77, -0.38224102088387807, -1.75, -0.91, -14.094778911564626, 0.69, 2.87, -2.7, -2.64, 0.93, -3.95, 1.85, 2.77, -1.33, 3.69, 0.65, -2.3885714285714283, -3.7542857142857144, 0.66, -0.38, -0.73, -0.2, -0.3543095238095238, -1.71, -2.26, 2.61, 0.35, 0.53, 0.37, -0.99, -1.55, -0.18, -0.16, -1.51, -2.07, 1.19, 0.94, -0.02, -1.35, -1.91, 0.37, 0.43, 2.0, 0.2, 2.34, -0.32, 0.53, 0.08, 1.35, -0.57, 1.24, 1.18, 0.2, 1.25, 0.35, 1.93, 0.45, -0.46, 1.89], ['381', -1.09, -0.17, -0.3, -0.01, -0.29, -0.07, -3.4, -1.2, -1.06, -0.55, 0.21, 1.63, 0.99, 0.16, 1.38, -0.23, -0.43, -0.26, -0.038518140589569164, -0.28, -0.51, 0.03, -0.38, -0.11, -3.7, -0.36, -0.76, 1.42, 0.78, -0.05, 1.17, -0.44, -0.64, -0.47, -0.26, -0.49, -0.72, -0.18, -0.59, -0.32, -0.83, -0.9, -2.15, -0.63, -1.2821246055531768, -0.25, -1.83, -2.03, -1.86, -1.66, -1.89, -2.11, -1.58, -1.98, -1.72, -0.91, -0.99, -0.87, -0.52, -1.53, -0.82, 0.39, -1.2, -1.41, -1.24, -1.03, -1.26, -1.48, -0.95, -1.35, -1.09, -0.66, -0.71, 1.22, -0.39, -0.59, -0.42, -0.21, -0.45, -0.67, -0.13, -0.54, -0.2264403582748793, -0.59, -0.49, 0.45, -1.8733017616146799, -1.59, -1.79, -1.62, -1.41, -1.64, -1.87, -1.34, -1.73, -1.48, -1.19, -0.33, -0.2, -0.03, 0.18, -0.06, -0.28, 0.26, -0.15, 0.11, -0.18, -0.26, -0.6, -0.23, -0.26, -0.19, -0.12, 0.17, 0.38, 0.15, -0.08, 0.46, 0.05, 0.32, -0.66, -0.29, 0.21, -0.03, -0.25, 0.29, -0.12, 0.14, 0.09, 0.22276190476190477, 0.02, -0.49, -3.2922619047619044, 0.21, 0.27, 0.4, -0.43, -0.2, -0.97, -1.22, 0.58, 0.43, 0.21, -0.55, -0.34, -0.72, 0.78, 0.69, -0.22, 0.6, -0.49, -0.64, 0.34, -0.34, 0.3, 0.12, 0.28, -0.48, -0.5, -0.23, -0.46, 0.08, -0.32, -0.06, -0.69, -0.27, -0.22, 0.31, -0.09, 0.17, -0.04, 0.54, 0.13, 0.4, -0.99, -0.33, -0.58, -0.4, -0.14, -0.22, -0.25, -1.25, 0.37, -0.57, -0.44, -0.32, -0.66, -0.18, 0.26, -0.293994794887652, -0.28, 0.8, -1.13, -0.27, -0.44, -0.73, -0.91, -0.93], ['382', -3.52, -0.57, 0.04, 0.12, -1.01, -0.46, -1.1, -1.68, -1.26, -1.7, -0.15, -0.9, -0.09, 1.31, -0.46, -0.56, -1.08, -1.2, 1.28, -0.33, -2.07, -1.3, -0.49, -1.1, -0.26140633899247345, -1.2, -1.5273416050068875, -0.75, 0.06, 1.46, -0.32, -0.42, -0.93, -1.06, 1.875702380952381, -0.18, -1.93, -1.15, -0.35, -0.95, -1.55, -2.2, -0.81, 0.82, 2.23, 0.44, 0.34, -0.18, -0.31, 2.2, 0.58, -1.18, -0.4, 0.41, -0.2, -0.9, -1.48, -1.4, -1.07, -1.62, 1.4, -0.38, -0.48, -0.99, -1.12, 1.37, -0.24, -1.99, -1.21, -0.4072652545866831, -1.01, -1.01, -2.97, -1.75, -1.85, -2.35, -2.48, -0.03, -1.62, -3.34, -2.57, -1.78, -2.38, -1.87, -3.17, 3.23, -1.25, -0.1, -0.61, -0.74, 1.75, 0.13, -1.62, -0.84, -0.03, -0.64, -2.15, -1.15, -0.52, -0.64, 1.85, 0.24, -1.52, -0.74, 0.07, -0.54, -0.66, -1.127643118785976, -0.35, -0.49, -0.56, -0.47, -0.63, -0.13, 2.38, 0.75, -1.01, -0.22, 0.59, -0.02, -0.47, -0.51, 2.51, 0.88, -0.88, -0.09, 0.72, 0.1, -1.23, -0.9, 0.14, -0.58, -6.67, -0.63, -0.47, 0.48, -0.49, -0.29, -0.26, -2.5838364678879504, 2.79, 0.99, 0.51, -1.73, -0.15, -1.57, 1.49, 1.48, -0.49, 0.75, -1.02, -2.2, 1.09, -1.96, 6.0, 1.31, 2.01, -2.7, -2.94, -1.59, -3.31, -2.54, -1.75, -2.35, -1.41, -1.38, -1.75, -0.97, -0.16, -0.77, 0.38, 0.79, 1.61, 0.99, -1.2, -1.54, -0.41, 0.81, 0.2, -0.47, -0.56, -1.6174239503761216, 3.78, -0.79, -3.76, -0.63, -1.22, -1.22, -0.61, -0.48, -0.28, -0.07, 0.17, 0.0, -0.61, -0.64, -1.8, -0.35], ['383', 2.97, 0.5, -0.30877828437954125, -0.3, 2.11, 0.81, 0.9141152579598292, 1.4, 0.78, 3.04, 2.13, 2.56, 2.02, 2.69, 1.84, 2.87, 1.36, 2.71, 5.01, 1.28, 3.19, 1.71, 1.43, 1.53, 1.79, 1.1, 0.9, 0.42, -0.11, 0.55, -0.28, 0.73, -0.75, 0.57, 2.82, -0.83, 1.04, -0.4, -0.68, -0.58, 0.7, 0.77, 0.47, -0.53, 0.13, -0.7, 0.3, -1.17, 0.15, 2.39, -1.25, 0.61, -0.82, -1.1, -1.0, 0.91, 1.35, 0.72, 0.56, 1.0, 0.66, -0.17, 0.84, -0.64, 0.68, 2.94, -0.72, 1.15, -0.3, -0.58, -0.47, 1.66, 0.34, -0.83, 0.17, -1.3, 0.02, 2.26, -1.38, 0.48, -0.95, -1.23, -1.13, 0.89, 4.4, -4.38, 1.21669823838532, 1.01, -0.47, 0.85, 3.11, -0.55, 1.32, -0.12, -0.4, -0.3, 1.18, 0.17, -1.47, -0.16, 2.08, -1.55, 0.31, -1.12, -1.4, -1.3, 0.2, 0.2, 2.18, 1.04, 1.01, 1.11, 1.66, 1.33, 3.6, -0.08, 1.8, 0.35, 0.14598786341555264, 0.17, 1.26, 0.32, 2.24, -1.39, 0.46, -0.8442004503433073, -1.25, -0.8978225623582765, 1.75, 1.63, 0.0, 1.07, 2.23, 0.2, 0.14, -2.66, 2.66, 1.35, 0.6, 2.33, -3.399481751122728, -2.2, -1.09, 1.54, 0.39, 3.25, -3.22, -3.24, 1.06, -4.07, 2.09, 0.62, -0.31, 4.99, -6.6, -3.33, -4.95, 3.44, -1.88, -3.56, -1.74, -3.14, -3.41, -3.31, 3.19, 1.74, 2.0241925889236816, 0.43, 0.15, 0.25, -0.14, -1.3411214088935783, -1.7, -1.6, 0.82, 1.0084535464535467, 1.3, -0.28, -0.18, 1.192080034314057, 1.09, 1.27, -3.24, 1.11, 3.22, 1.63, 1.3, 1.59, 0.17278685149693168, 1.13, 1.2845528598385743, 0.7, 0.15, -0.06, 1.49, 2.15, 2.05, 2.82], ['384', 0.86, -0.19, -0.14877828437954127, 0.14, -0.8570209190089404, -0.24, -0.88, -0.49, -1.09, -0.05, 1.27, 0.92, 0.32, 0.63, 0.47, 0.65, 0.68, 0.27, -2.87, 1.63, -0.37, 0.01, 0.43, 0.48, -0.25, -0.52, -1.3, -0.34, -0.93, -0.63, -0.7221800287049088, -0.6, -0.58, -0.98, -4.08, 0.36, -1.62, -1.24, -0.7311203865609548, -0.77, -0.11, -2.3, -0.96, -0.59, -0.29, -0.44, -0.26, -0.24, -0.64, -3.75, 0.71, -1.28, -0.9, -0.49, -0.43, -0.29993715369432344, -0.11571428571428577, -0.45, -0.92, -0.37, 0.3, 0.15, 0.33, 0.36, -0.05, -3.18, 1.4339757335335068, -0.69, -0.31, 0.11, 0.16, -0.1, -0.68, -0.15, 0.03, 0.05, -0.35, -3.47, 1.0, -0.99, -0.61, -0.2, -0.14, -1.48, -1.43, 1.37, -0.53, 0.18, 0.2117857142857143, -0.2, -3.33, 1.15, -0.84, -0.47, -0.05, 0.01, -0.23, -0.7, 0.03, -0.38, -3.5, 0.97, -1.02, -0.64, -0.22, -0.17, -0.36, -0.58, -3.01, -0.5, -0.42, -0.5, -0.73, -0.41, -3.53, 0.95, -1.05, -0.67, -0.25, -0.2, -0.14, -0.32, -3.13, 1.36, -0.64, -0.26, 0.16, 0.21, -0.64, -0.66, 0.21, -0.7, -0.55, -0.13, -0.2, 1.67, -1.7, -0.84, -0.42, -1.2638364678879506, 3.26, 1.03, 0.49, 0.44, 0.03, -1.48, 1.4, 1.43, -0.49, 2.56, -0.98, -2.1, 1.03, -2.15, 5.05, 1.42, 2.24, -3.34, 2.9, 4.63, 2.57, 2.96, 3.4, 3.45, -1.51, -1.66, -1.97, -1.6, -1.18, -1.13, 0.38448979591836735, 0.38, 0.81, 0.86, -1.11, -1.25, -0.06, 0.42, 0.47, -0.48, -0.53, -0.52, 1.95, -2.07, -2.08, -0.46, -1.03, -0.48, 0.05, -0.3, -0.68, 0.2, 0.3, -0.35, -0.53, 0.79, -1.87, -0.36], ['385', -1.8, 0.18, 0.4112217156204588, -0.23, 0.67, -0.33, -1.7558847420401709, -0.42, -0.8, 0.13, 1.44, 1.02, 0.22, 0.88, 1.96, 0.19, 0.52, 0.15, -0.49, -1.35, 0.19, 0.4, 0.28, 0.15, -0.28, 0.43, -1.3, -0.41, -1.2, -0.55, 0.51, -1.23, -0.91, -1.27, -1.8992857142857142, -2.75, -1.23, -1.02, -1.14, -1.27, -1.05, -1.5650638007838267, -0.89, -0.79, -0.14, 0.93, -0.82, -0.5, -0.86, -1.49, -2.34, -0.82, -0.61, -0.73, -0.86, -0.5, 0.46, 3.03, -0.57, -0.09, 0.66, 1.74, -0.03, 0.3, -0.07, -0.7, -1.56, -0.03, 0.18, 0.06, -0.07, 0.48, -0.75, 1.07, -0.68, -0.36, -0.72, -1.35, -2.21, -0.2381462585034016, -0.47, -0.59, -0.72, -1.16, -0.57, 0.58, -1.8, -1.6519125667872352, -1.41, -1.77, -2.4, -3.24, -1.73, -1.53, -1.65, -1.77, -0.55, -0.06, 0.33, -0.04, -0.67, -1.53, 0.0, 0.21, 0.09, -0.04, 0.0, -0.06, 0.83, -0.28, 0.26, -0.81, -0.39, -0.37, -1.0, -1.86, -0.33, -0.12, -0.16401213658444735, -0.37, -0.05, -0.03, -0.64, -1.5, 0.04956235827664399, 0.25, 0.13, 0.0, 0.52, 0.72, -0.26396282112195957, -0.41, -1.27, 0.2480695494981211, 0.22, 4.17, -4.2, -2.11, 0.61, -1.28, -3.04, 0.55, 0.27, -0.83, 0.65, -0.86, 0.91, 0.8, -0.28, 6.2, -0.53, 2.29, -1.1, -1.22, -5.56, 0.72, 1.11, 2.94, 0.61, -0.86, 0.68, 0.89, 0.77, 0.64, -0.83, 1.49, 1.56, 1.77, 1.65, 1.52, -0.07, 0.21, 0.09, -0.04, -4.11, -5.19, -0.28, -0.12, -0.25, -0.25, -0.85, -2.56, -2.65, 0.54, 2.47, -0.27, 0.68, -0.08136255179902908, -0.13, -0.3599225974772193, -2.34, 0.93, 1.21, 0.38, -0.03, -0.72, 0.7030376647162363, -0.42], ['386', 2.39, -0.22, -0.30877828437954125, -0.07, 0.55, -0.45, 0.54, -0.63, -0.13, -0.17, -0.39, 0.29, 0.43, 0.57, -0.33, -0.42, 0.82, -0.22, -0.84, -1.48, -0.03, 0.9, 0.4, 0.31, -0.78, -1.08, 0.23, 0.68, 0.82, 0.96, 0.06, -0.02, 1.22, 0.18, -0.45, -1.1, 0.36, 1.29, 0.8, 0.7, 0.0, 0.67, -0.44979591836734695, 0.14, 0.28, -0.62, -0.7, 0.53, -0.5, -1.13, -1.76, -0.32, 0.61, 0.11, 0.02, -0.91, -0.77, -0.39, -0.35007142857142853, -0.59, 0.14, -0.76, -0.84, 0.39, -0.64, -1.26, -1.9, -0.46, 0.47, -0.03, -0.12, 0.05, -0.73, -0.9, -0.98, 0.25, -0.78, -1.4, -2.04, -0.4469183673469388, 0.33, -0.17, -0.20644035827487928, 0.47, -1.94, 1.89, 0.17, -0.08, 1.5899013605442176, 0.12, -0.51, -1.15, 0.3, 1.23, 0.74, 0.64, -2.8, 0.25, 1.24, 0.30533503401360546, -0.43, -1.07, 0.39, 1.32, 0.82, 0.73, -0.08, 0.3, -1.28, -0.37, -0.37, -0.47, -0.98, -1.03, -1.65, -2.28, -0.84, 0.08, -0.42, -0.51, -1.15, 0.05, -0.63, -1.27, 0.19, 1.12, 0.62, 0.52, -0.66, -0.49, 0.21603717887804044, -0.74, -8.4, -0.43, -0.47, 0.37, -0.41, -0.19, -2.62, -0.23, -2.62, 0.71, 0.39, 1.19, -0.37, -1.05, 1.15, 1.15, -0.38, 0.58, -0.63, 0.76, -0.4, -2.88, -3.76, 1.98, 2.94, 2.5771309523809522, 0.68, -0.65, 0.82, 1.75, 1.25, 1.16, -1.09, 1.34, 1.47, 2.42, 1.91, 1.82, -0.14, 0.93, 0.43, 0.34, -0.08, -0.04, -1.05, -0.49, -0.59, -0.35, -0.44, -0.56, -1.01, -1.07, 1.1314285714285712, -0.4327361894755667, -0.04, -0.56, -0.09, -0.97, 0.01, -0.23, -0.38, -0.61, -0.47, -1.1, 0.43, -0.17], ['387', -5.61, 0.62, -0.05877828437954126, -0.19, 0.49, 1.29, 1.0641152579598292, 0.8, 1.97, 1.2, -2.28, 0.2, -0.09, 0.47, 0.7, 3.42, 0.45, 1.18, 4.831481859410431, 0.3, 1.86, 0.13, -0.45, -0.2, 1.63, 1.52, 3.6026583949931124, 2.55, 2.25, 2.82, 3.05, 5.83, 2.8, 3.55, 7.27, 2.64, 4.24, 2.47, 1.87, 2.13, 1.03, 3.84, 1.0, -0.29, 0.27, 0.49, 3.21, 0.24, 0.97, 4.6, 0.09, 1.65, -0.08, -0.66, -0.41, -0.97, 0.99, 1.63, 1.66, 1.29, 0.56, 0.79, 3.51, 0.6185714285714285, 1.27, 4.91, 0.39, 1.95, 0.22, -0.37, -0.11, 0.9, 0.73, 0.23, 2.93, -0.02, 0.7, 4.32, -0.17, 1.8218537414965983, -0.34, -0.92, -0.67, 3.17, 4.35, -4.24, 0.5, 2.7, -0.25, 0.48, 4.09, -0.4, 1.15, -0.57, -1.1414761904761903, -0.9, -1.27, -2.14, -2.87, -2.16, 1.35, -3.01, -1.51, -3.18, -3.74, -3.5, 0.471141873999017, -2.14, 0.73, 1.31, 1.34, 1.18, 0.75, 0.73, 4.35, -0.15, 1.4, -0.32, -0.9, -0.65, 1.07, 0.07307674813036727, 3.59, -0.87, 0.67, -1.04, -1.62, -1.37, 1.19, 0.71, -0.27, 0.88, -2.63, 0.87, -0.11, -2.66, 2.63, 1.34, 0.37, 0.48, -1.59, -2.67, -1.31, -2.84, 0.71, 3.84, -3.87, -3.96, 1.31, -4.03, 2.62, 2.13, -1.06, 2.37, -6.39, -1.5, -2.23, 1.85, -3.44, -4.31, -2.82, -4.47, -5.03, -4.624238287156354, 3.99, 0.9, 1.56, -0.17, -0.75, -0.5, -0.64, -1.7, -2.27, -2.02, 1.94, 2.28, 1.08, -0.58, -0.33, 1.3, 1.27, 0.83, -3.27, 0.34, 3.2421428571428574, 1.15, 1.56, 1.67, 0.25, 1.6200774025227807, 1.36, 0.82, 1.49, 0.67, 1.41, 0.6502406343656345, 2.12, 0.83], ['388', -2.27, -0.98, -0.04, -0.23, -0.32, -0.86, -1.1658847420401708, -1.29, -1.96, -1.17, 1.37, 0.12, -1.41, 0.64, 0.05, -0.9, 1.07, -0.95, -0.63, 0.07, -1.932664517912641, 0.53, 0.25, -0.14, -0.69, -2.23, -2.4673416050068875, -1.2294545454545454, -2.74, -0.72, -1.242180028704909, -2.23, -0.29, -2.29, -1.97, -1.28, -3.29, -0.83, -1.1, -1.49, -0.43, -4.075063800783826, -1.29, -1.53, 0.52, -0.07, -1.02, 0.95, -1.07, -0.75, -0.05, -2.09, 0.41, 0.14, -0.26, -0.53, -0.07, -0.55, -1.82, 0.24, 2.08, 1.48, 0.52, 2.52, 0.47, 0.8, 1.5, -0.57, 1.97, 1.69, 1.29, -1.07, -1.8, -0.59, -1.53, 0.43, -1.58, -1.26, -0.57, -2.59, -0.11, -0.38, -0.78, -2.67, -4.46, 4.47, -1.18330176161468, -0.95, 1.02, -1.0, -0.68, 0.02, -2.02, 0.48, 0.21, -0.19, -2.62, -0.28, 1.99, -0.05, 0.27, 0.97, -1.08, 1.44, 1.16, 0.76, -0.42, -0.1506317967746538, -1.86427628811696, -1.35, -1.26, -1.53, -2.22, -1.9986530612244897, -1.68, -1.0, -3.01, -0.54, -0.81, -1.2, -1.75, -0.22, 0.33, 1.03, -1.03, 1.49, 1.22, 0.82, -1.48, -1.54, -0.39, -2.09, -5.09, -0.48, -0.39, 3.58, -3.59, -1.81, -1.48, -1.22, 2.45, 2.69, 1.37, -1.15, -0.56, -4.28, 4.24, 4.02, -1.34, 5.37, -2.69, 1.1183906549799407, -0.48, -6.64, 7.48, 4.43, 6.57, -2.44, -0.55, 0.7, -1.35, 1.16, 0.89, 0.49, -3.9891948051948054, -1.24, -2.04, 0.46, 0.19, -0.21, 0.82, 2.55, 2.27, 1.87, -1.97, -2.35, -1.69, -0.27, -0.67, -1.32, -1.46, -1.21, 3.91, -1.48, -3.8, -1.67, -1.26, -1.42, -0.4, -1.94, -1.79, -0.64, -0.22, -1.14, -1.03, -2.62, -1.94, -2.0569832262926027], ['389', 1.84, 0.44, 0.44, -0.14, 1.09, 1.52, 1.19, 1.0, 2.52, 1.21, -2.95, 0.24, -0.72, 0.88, -0.42, -0.32, -0.89, 0.45, 0.62, -0.77, 1.77, 0.02, -0.11, 0.27, 1.99, 2.28, 4.29, 3.408468508265777, 2.3, 3.95, 2.61, 2.7133503401360546, 2.12, 3.51, 3.69, 2.25, 4.86, 3.07, 2.92, 3.32, 0.12, 5.16, 0.97, -0.96, 0.64, -0.65, -0.56, -1.13, 0.21, 0.39, -1.0, 1.53, -0.21, -0.35, 0.03, 0.66, 0.74, -0.31, 2.24, 1.94, 1.61, 0.31, 0.4, -0.17, 1.18, 1.36, -0.05, 2.51, 0.75, 0.61, 1.0, 0.13, 0.32, -0.8697721088435375, -1.2, -1.76, -0.43, -0.25, -1.64, 0.88, -0.85, -0.99, -0.6, 4.6, 4.01, -4.2, 1.63, 0.09, -0.48, 0.87, 1.04, -0.36, 2.19, 0.44, 0.3, 0.69, 2.4, 1.54, -0.57, 0.78, 0.95, -0.44, 2.1, 0.35, 0.21, 0.6, 0.95, 1.53, 1.04, 1.52, 1.51, 1.61, 2.12, 1.35, 1.53, 0.12, 2.68, 0.92, 0.78, 1.17, 1.19, 0.75, 0.17, -1.21, 1.31, -0.43, -0.56, -0.18, 1.8, 2.11, -0.02, 2.17, 4.89, 0.3580695494981211, -0.14, -3.28, 3.19, 1.63, 1.09, 1.56, -3.71, -3.05, -1.5385714285714287, 0.93, 1.53, 4.61, -4.680000000000001, -4.65, 1.5, -4.78, 3.03, 2.99, -1.47, 6.22, -5.952619047619048, -4.19, -6.19, 3.59, 0.58, -1.39, 1.14, -0.6, -0.73, -0.35, 4.52, 1.99, 2.56, 0.8, 0.66, 1.05, -0.10349829931972804, -1.72, -1.85, -1.4685714285714286, 2.49, 2.96, 1.18, -0.14, 0.25, 1.5, 1.62, 1.18, -2.94, 1.57, 3.11, 1.81, 2.09, 1.32, 0.39, 2.26, 1.87, 1.07, 1.47, 1.03, 0.93, 2.53, 2.46, -0.23], ['390', 3.11, 0.53, 0.06, -0.28, 0.22, 1.0, 1.14, 2.33, 1.86, 3.54, 0.84, 2.68, 1.6, 0.84, 1.47, 3.42, 1.44, 3.48, 5.61, 4.17, 4.08, 2.72, 1.51, 3.06, 1.5485936610075264, 1.03, 2.67, 1.822860544217687, 0.75, 0.0, 0.62, 2.56, 0.6, 2.62, 4.73, 3.3, 3.21, 1.86, 0.66, 2.2, 1.3, 2.4849361992161736, 0.840204081632653, -1.05, -1.78, -1.17, 0.72, -1.2, 0.79, 2.86, 1.46, 1.37, 0.04, -1.13, 0.38, 1.35, 1.36, 1.88, 2.07, 1.91, -0.74, -0.12, 1.79, -0.15, 1.86, 3.95, 2.53, 2.44, 1.1, -0.08, 1.44, 1.88, 2.67, 0.62, 2.55, 0.59, 2.62, 4.72, 3.3, 3.2, 1.86, 0.66, 2.2535596417251207, 2.61, 5.49, -5.48, 2.04, 1.92, -0.03, 1.98, 4.08, 2.66, 2.57, 1.23, 0.04, 1.57, 0.76, 0.11, -1.91, 0.06, 2.12, 0.72, 0.64, -0.68, -1.84, -0.35, -0.1, 0.12235688121402405, 2.22, 1.21, 1.43, 1.13, 2.06, 2.01, 4.11, 2.69, 2.59, 1.26, 0.07, 1.59, 0.55, 0.10307674813036727, 2.05, 0.66, 0.57, -0.74, -1.9, -0.16782256235827656, 1.99, 2.13, -0.03, 1.87, 2.11, 0.08, 0.31, -2.04, 2.03, 1.01, 0.22, 3.2202597402597406, 1.24, -2.5, -1.22, 1.58, 0.85, 3.88, -3.81, -3.66, 1.22, -3.07, 2.45, 1.94, -1.25, 6.23, -6.44, -4.17, -6.13, -1.27, -1.96, -1.36, -1.45, -2.74, -3.88, -2.41, 3.61, -0.61, -0.09, -1.39, -2.55, -1.06, -0.52, -1.3, -2.46, -0.98, 1.86, 2.36, 0.79, -1.18, 0.40224875531501636, 1.25, 1.37, 2.5, -3.32, 3.05, 3.17, 1.53, 0.88, 1.99, 1.53, 1.49, 1.22, 1.2652979520479524, 0.5, 1.29, 0.46, 2.4, 0.31, 1.09], ['391', -1.84, 0.92, -0.028778284379541254, -0.06, -0.5, 0.13, -0.21, 0.04, -0.4, -0.15, 1.0503184712113285, 0.1, -0.88, -1.38, -0.42, 0.52, -0.63, -0.08, 0.85, -0.39, -0.61, -0.61, -0.3, -0.96, 0.21, -0.19, -0.98, -0.73, -1.7, -2.2, -1.25, -0.32, -1.45, -0.91, 0.01, -1.21, -1.43, -1.44, -1.12, -1.78, -0.81, -0.20506380078382658, -0.25, -0.98, -1.48, -0.44918497042472344, 0.41, -0.73, -0.18, 0.74, -0.49, -0.71, -0.71, -0.4, -1.06, 0.33, 0.14, -0.36, -0.55, 0.74, -0.5, 0.46, 1.41, 0.25, 0.81, 1.74, 0.5, 0.28, 0.27, 0.59, -0.08, -1.15, 1.25, 0.97, 1.92, 0.76, 1.32, 2.26, 1.01, 0.78, 0.78, 1.1, 0.43, -0.65, 0.65, -0.72, 0.27, 0.94, -0.21, 0.35, 1.28, 0.04, -0.18, -0.19, 0.13, -0.54, -1.53, -0.66, -1.14, -0.59, 0.33, -0.9, -1.12, -1.12, -0.81, -1.46, 0.02, -0.67, 1.13572371188304, 0.15, 0.26517906963433996, 0.26, 0.5518094764861292, 0.56, 1.49, 0.25, 0.03, 0.02, 0.34, -0.33, 0.35, -0.07, 0.92, -0.31, -0.53, -0.54, -0.22, -0.88, 0.08, -0.03, -0.29, 0.67, -4.6, 0.28, 0.17, -0.14, 0.08, 0.06, 1.06, 0.23, -0.51, -0.3, -0.21, -0.87, 0.31, 0.53, -0.51, -0.6, 0.14, -0.16, 0.52, 1.08, -0.54, 1.52, -3.48, -1.09, -1.38, 0.5, -0.99, -1.22, -1.44, -1.45, -1.13, -1.79, 0.52, 0.24, -0.22, -0.23, 0.09, -0.57, 0.906501700680272, -0.01, 0.31, -0.35, -0.45, -0.57, 0.47, 0.32, -0.35, 0.19, 0.26, 0.14, -1.18, 1.3301996269574994, 0.97, 0.0, 0.6, 0.15, -0.66, 0.72, 0.06, -0.17, 0.23, 0.05, 0.81, 0.93, 1.38, 1.62], ['392', 5.9, 0.48, -0.05, 0.0, 1.3129790809910595, 0.6, 1.67, 1.21, 1.39, 0.9253571428571429, -1.41, -0.55, -0.61, 0.75, -0.79, 0.23, 1.15, 0.91, 0.85, -1.66, 0.91, -0.13, -0.64, 2.76, -0.44, 0.35, 2.3, 0.87, 0.81, 2.19, 0.63, 1.66, 2.6, 2.36, 2.29, -0.25, 2.35, 1.3, 0.78, 4.273841723197839, 1.14, 3.1, 1.619303232481804, -0.06, 1.3, -0.24, 0.78, 1.71, 1.47, 1.4, -1.12, 1.47, 0.42, -0.1, 3.33, 0.98, 0.18, 0.91, 0.6, 1.5592452470658775, 1.37, -0.18, 0.85, 1.78, 1.53, 1.47, -1.05, 1.53, 0.48, -0.03, 3.39, 2.7, 0.11, -1.53, -0.51, 0.4, 0.17, 0.1, -2.39, 0.16, -0.87, -1.38, 2.0, 2.6189098639455786, 3.29, -3.37, 1.66, 1.03, 1.96, 1.72, 1.65, -0.87, 1.71, 0.67, 0.15, 3.58, 0.86, 0.63, 0.92, 0.68, 0.62, -1.88, 0.68, -0.36, -0.87, 2.52, -0.02, 0.64, 1.21, 0.03, 0.65, -0.69, -0.29, -0.24, -0.3, -2.78, -0.24, -1.27, -1.78, 1.59, 0.84, -0.05, -0.06, -2.55, 0.0, -1.04, -1.54, 1.83, 1.81, 2.35, 0.17, -0.38, 1.4, 0.56, 0.07, 3.24, -3.37, -1.65, 0.45, 3.6, -5.08, -0.12, -0.04, 2.88, 0.63, -0.16, 0.18, -0.2, 0.05, 4.96, 0.15, -2.041609345020059, 1.08, -0.95, 0.82, 0.49, 0.76, 5.11, 0.01, -2.49, 0.06, -0.97, -1.48, 1.9, 0.12, 2.56, 2.61, 1.55, 1.03, 4.49, -0.05, -1.03, -1.54, 1.83, 1.44, 2.08, 0.99, -0.51, 2.89, 0.0, -0.12, 1.12, 0.32, 0.0, -0.17, -0.36, 0.35, 1.51, 3.43, 0.54, -0.82, 0.34, 1.14, 0.28, -1.85, 0.17, -1.74, -2.2], ['393', 1.45, 0.34, 0.09122171562045875, -0.22, 0.0, -0.15, 0.45411525795982915, 0.67, 0.77, -0.05, -0.61, -0.7, -0.39, -0.47, -1.36, -0.21, -0.36, -0.2, -0.86, 0.06, 0.48733548208735894, 0.53, -0.85, -0.47, 1.51, 0.94, 0.56, -0.1, 0.22, 0.14, -0.7021800287049088, 0.4, 0.24, 0.41, -0.25, 0.67, 1.07, 1.14, -0.25, 0.18384172319783917, 0.27, 1.7949361992161734, 0.66, 0.32, 0.24, -0.66, 0.5, 0.34, 0.51, -0.15, 0.77, 1.17, 1.24, -0.15, 0.24, 0.8, 0.3, 0.15, 0.73, 0.34, -0.08, -0.98, 0.18, 0.02, 0.19, -0.47, 0.45, 0.85, 0.92, -0.47, -0.08, 0.5, 0.42, -0.9, 0.26, 0.11, 0.27, -0.39, 0.54, 0.93, 1.0, -0.39, 0.01, 0.98, 2.05, -2.04, 1.33, 1.17, 1.01, 1.18, 0.51, 1.45, 1.84, 1.92, 0.52, 0.91, 0.34, 0.16, -0.15, 0.01, -0.6484761904761905, 0.28, 0.67, 0.74, -0.64, -0.25, 0.23, 0.18, 2.45, 0.21, 0.61, -0.22, 0.31, 0.16, -0.49, 0.43, 0.82, 0.9, -0.49, -0.1, -0.29, 0.15, -0.66, 0.27, 0.66, 0.73, -0.65, -0.26, 1.01, 0.9, -0.04, 0.4, 0.97, 0.03, 0.0, 0.53, -0.5275376766091052, -0.26, 1.4240662734668152, 1.3561635321120495, 0.22, -0.45, -0.18, 0.78, 0.553079789868779, 0.7, -0.66, -0.63, 0.2, 0.78, 0.46, 1.79, -0.89, 0.92, 0.0, -0.67, -0.87, -0.26, 0.81, 0.93, 1.32, 1.4, 0.0, 0.4, 0.64, -0.12, 0.39, 0.46, -0.92, -0.53, -0.51, 0.07, -1.3, -0.92, 0.77, 0.76, -0.58, -1.37, -0.99, 0.23, 0.28439630127529086, 0.66, -0.66, 1.5, 0.77, 0.5272638105244333, 0.83, 0.81, 0.46278685149693166, 0.36, -0.75, 0.37, 1.35, -0.07, 0.49595752702381396, 1.12, 0.87, 0.0], ['394', -7.48, -0.71, -0.2787782843795412, 0.21, -1.78, -1.37, 0.07411525795982916, -3.92, -4.12, -1.09, 3.94, 0.71, 1.85, 3.53, 2.6342857142857143, 1.25, 1.13, -0.8, -2.76, 2.02, -1.92, 0.32, 0.5, 0.875116627420199, -4.96, -3.770628585411108, -4.84, -3.11, -2.01, -0.39, -1.26, -2.59, -2.7, -4.56, -6.45, -1.8286428571428572, -5.64, -3.48, -3.31, -3.09, -4.55, -3.89, -1.789795918367347, 1.13, 2.81, 1.9, 0.54, 0.42, -1.5, -3.45, 1.3, -2.62, -0.39, -0.21, 0.02, -2.46, -4.15, -2.54, -4.42, -2.89, 1.66, 0.77, -0.59, -0.7, -2.6, -4.53, 0.17, -3.7, -1.5, -1.33, -1.09, -2.3, -4.47, -0.88, -2.21, -2.32, -4.19, -6.08, -1.46, -5.27, -3.1, -2.94, -2.71, -4.71, -4.66, 4.67, -3.63, -1.34, -1.45, -3.34, -5.25, -0.59, -4.43, -2.25, -2.08, -1.85, -4.06, -2.32, -0.12, -2.03, -3.97, 0.76, -3.14, -0.92, -0.75, -0.51, -0.38, -2.35, -2.65, -1.5684018193170985, -1.51, -1.86, -2.2, -1.92, -3.85, 0.88, -3.02, -0.8, -0.63, -0.4, -1.41, -0.29, -1.98, 2.84, -1.13, 1.13, 1.31, 1.55, -1.63, -1.91, 0.35, -2.25, -11.87, -0.16, 0.06, 3.55, -3.6, -1.8, -0.44, -3.36, 6.23, 3.17, 1.62, -3.89, -0.67, -4.98, 5.03, 4.89, -1.64, 5.4, -3.29, -1.47, 0.68, -6.52, 4.45, 4.23, 6.41, -6.4, 1.72, 4.92, 0.86, 3.17, 3.35, 3.6, -4.91, -3.05, -3.87, -1.67, -1.49, -1.26, 0.85, 2.29, 2.47, 2.71, -1.91, -1.98, -1.41, 0.18, 0.41, -1.59, -1.65, -2.73, 6.5, -3.99, -7.12, -2.7, -3.3, -1.58, 0.24, -1.53, -1.63, -0.73, -0.55, -0.99, -1.81, -4.28, -4.46, -2.19], ['395', 0.18, -0.23, -0.10877828437954125, 0.17, -0.48, -0.31, 0.05, -1.23, -0.73, -3.26, -2.35, -3.58, -2.19, -2.58, -1.25, -3.68, -2.37, -3.17, -5.53, -1.98, -3.56, -2.3, -2.33, -2.14, -2.29, -0.5706285854111081, -0.93, -1.26, 0.16, -0.23, 1.13, -1.37, -0.02, -0.84, -3.25, 0.38, -1.24, 0.05, 0.02, 0.22, -0.44, -1.7891024373941227, 0.33, 1.44, 1.04, 2.42, -0.11, 1.26, 0.43, -2.02, 1.66, 0.02, 1.33, 1.3, 1.5, -0.14, -0.21, -1.06, 0.06, -1.09, -0.39, 0.97, -1.52, -0.18, -1.0, -3.41, 0.22, -1.4, -0.11, -0.14, 0.06, -0.96, -0.7, 1.36, -1.14, 0.21, -0.61, -3.03, 0.61, -1.01, 0.28, 0.26, 0.45, -0.9373265306122449, -2.6, 2.55, -2.04, -2.47, -1.13, -1.95, -4.33, -0.74, -2.34, -1.06, -1.09, -0.9, 0.27, 0.44, 1.36, 0.53, -1.91, 1.77, 0.13, 1.44, 1.41, 1.61, -0.16, 0.49, 0.13, -0.65, -0.68, -0.67, -0.91, -0.82, -3.23, 0.4, -1.22, 0.07, 0.04, 0.2985846838830657, -1.0, -0.1, -2.43, 1.23, -0.4, 0.9, 0.87, 1.07, -0.3, 0.0, 0.23, -0.7, 1.1, -0.03, 0.0, 1.59, -1.57, -0.78, -1.27, -1.79, 2.63, 1.3, 0.68, 0.07, -0.07, -1.86, 1.89, 1.93, -0.65, 2.32, -1.31, -2.04, 0.98, -2.68, 2.65, 1.71, 2.45, -2.56, 2.4, 3.75, 2.08, 3.42, 3.39, 3.59, -2.01, -1.31, -1.61, -0.33, -0.35, -0.16, 0.31, 1.31, 1.28, 1.48, -0.65, -0.76, -0.98, -0.03, 0.17, -0.65, -0.7, -1.26, 3.75, -0.45, -3.77, -1.01, -1.67, -0.96, 0.19, -0.58, -0.63, 0.44, -0.05, -0.27, -1.15, -2.24, -2.27, -1.46], ['396', 2.42, 0.18, 0.2, 0.13, -0.42, 0.55, 0.89, 1.6, 1.3, 0.59, -1.22, -0.23, -1.22, -1.29, -0.31, 0.23, -0.67, 0.28, 0.95, 1.01, 1.297335482087359, 0.01, -0.64, -0.59, 1.16, 0.869371414588892, 1.83, 1.01, 0.0, -0.07, 0.92, 1.47, 0.55, 1.51, 2.2, 2.25, 2.51, 1.25, 0.59, 0.64, 1.13, 1.4449361992161733, 0.82, -1.0, -1.06, -0.08, 0.46, -0.45, 0.5, 1.18, 1.24, 1.49, 0.24, -0.42, -0.36, 1.42, 1.33, 0.82, 1.17, 1.83, -0.07, 0.92, 1.47, 0.55, 1.6126050661400617, 2.4896933106575965, 2.25, 2.6734211542425825, 1.25, 0.58, 0.64, 1.07, 1.9, 0.99, 1.54, 0.62, 1.58, 2.27, 2.33, 2.58, 1.32, 0.66, 0.71, 1.76, 3.22, -3.22, 0.9, 0.54, -0.37, 0.59, 1.26, 1.32, 1.57, 0.32, -0.33, -0.28, 0.17, 0.36, -0.9, 0.04, 0.72, 0.77, 1.02, -0.22, -0.87, -0.82, 0.18, 0.31, 3.62, 0.72, 0.78, 0.82, 1.3418094764861292, 0.95, 1.64, 1.69, 1.95, 0.69, 0.03, 0.08, 0.55, 0.31, 0.68, 0.73, 0.98, -0.26, -0.91, -0.86, 0.66, 0.61, 0.0, 1.19, 0.56, 0.43, 0.21, -2.16, 2.17, 1.09, 0.31, 1.86, 0.81, -1.43, -0.73, 1.27, -0.01, 2.38, -2.27, -2.16, 0.73, -3.26, 1.47, 1.2583906549799408, -0.57, 3.79, -5.86, -2.51, -3.69, -0.83, -0.36, 0.05, 0.3, -0.93, -1.58, -1.53, 2.2108051948051948, -0.41, 0.3941925889236815, -0.98, -1.63, -1.58, -0.66, -1.23, -1.88, -1.83, 1.45, 1.43, 0.58, -0.65, -0.6, 0.71, 0.8, 1.61, -2.97, 2.98, 2.99, 0.61, 0.94, 1.24, 0.05, 0.56, 1.11, -0.06, -0.41, 0.14, 1.265957527023814, 1.43, 1.26, 1.58], ['397', 2.67, -0.12, 0.1, 0.21214285714285727, -0.72, -0.09, -0.25, -0.79, -0.34, -0.21, 0.06, 0.26, 0.22, 0.99, 0.51, -0.68, 0.88, -0.24, -0.36, 2.21, 0.07, 0.5130748299319728, -0.01, 0.16, -0.78, -0.5, -0.27, 0.2, 0.16, 0.93, 0.45, -0.74, 0.82, -0.3, -0.42, 2.15, 0.01, 0.45, -0.07, 0.1, -0.22, -0.57, -0.47, -0.03, 0.73, 0.26, -0.94, 0.63, -0.49, -0.61, 1.9507142857142856, -0.19, 0.25, -0.27, -0.1, 0.0, 0.06, -0.47, -0.23, -0.43, 0.76, 0.29, -0.9, 0.66, -0.46, -0.58, 1.98, -0.16, 0.29, -0.24, -0.07, -0.46, -1.1885714285714286, -0.47, -1.66, -0.1, -1.2067857142857144, -1.33, 1.21, -0.91, -0.47, -0.99, -0.82, -0.36, -0.87, 0.86, -0.72, -1.19, 0.37, -0.75, -0.87, 1.69, -0.44, 0.0, -0.52, -0.35, -0.54, 0.47, 1.58, 0.45, 0.33, 2.92, 0.76, 1.2, 0.68, 0.85, -0.09, 0.45, -0.64, -0.28, -0.28, -0.54, -1.09, -1.11, -1.23, 1.32, -0.81, -0.37, -0.89, -0.72, -0.82, 0.02, -0.12, 2.46, 0.31, 0.75, 0.23, 0.4, -0.68, -1.56, -0.45, -0.86, -1.18, -0.18, -0.19, 1.61, -1.65, -0.81, -1.28, -0.75, 4.6, 0.54, 0.39, 1.5, 0.16, -1.01, 1.05, 0.77, -0.27, 2.4, -0.55, 2.32, -1.13, -3.07, 6.27, 2.2142857142857144, 3.2314285714285713, -4.82, 0.15, 2.58, 0.43, 0.87, 0.35128571428571426, 0.52, -0.74, -2.37, -2.1, -1.67, -2.18, -2.01, -0.28, 0.44, 0.15285714285714286, 0.09, -0.35, -0.41, -0.72, -0.32676622187336457, -0.35, -0.47, -0.41, -0.75, 3.197142857142857, -0.56, -3.25, -0.73, 0.03, -0.2, 0.17, -0.79, -0.61, -0.16, 0.04, 0.12, -0.37, -2.03, -1.05, -1.02], ['398', 1.09, 0.19, 0.09122171562045875, -0.45, 1.59, 1.04, 1.03, 1.09, 0.87, 1.07, -0.17, 0.18, -0.36, -0.77, 0.69, 0.92, -0.22, 0.72, -0.49, -0.21, 1.42, 0.49, 0.74, -0.51, 1.59, 1.41, 1.2826583949931125, 0.35, -0.19, -0.6, 0.87, 1.1, -0.05, 0.89, -0.32, -0.04, 1.5907606837606838, 0.67, 0.91, -0.2961582768021609, 0.5, 1.21, 0.89, -0.54, -0.95, 0.51, 0.74, -0.4, 0.54, -0.67, -0.39, 1.24, 0.31, 0.56, -0.69, 1.28, 0.45, 0.14, 0.88, 1.44, -0.41, 1.06, 1.29, 0.14, 1.08, -0.14, 0.15, 1.78, 0.86, 1.1, -0.15, 0.6, 1.86, 1.48, 1.71, 0.56, 1.5, 0.28, 0.56, 2.21, 1.27, 1.52, 0.26, 1.23, 1.16, -1.16, 0.38, 0.23, -0.91, 0.02, -1.18, -0.9, 0.72, -0.2, 0.04, -1.19, 0.93, 0.15, -1.13, -0.2, -1.4, -1.13, 0.49, -0.42, -0.18, -1.42, 0.32, 0.21, 1.26, 1.08, 0.86517906963434, 1.5356735186500319, 1.3, 0.94, -0.28, 0.01, 1.64, 0.72, 0.96, -0.29, 0.61, 0.35, -1.2, -0.92, 0.8786030199958773, -0.22, 0.02, -1.22, 0.17, 0.42, -0.66, 1.45, 2.0, 0.54, 0.27, -2.58, 2.5324623233908947, 1.28, 0.13, 1.6902597402597401, -2.74, -2.16, -1.09, 0.49, 0.49, 3.41, -3.4, -3.28, 1.133290804863853, -3.91, 2.2398783572413152, 1.49, -0.74, 3.93, -6.22, -2.63, -3.89, 2.61, 1.58, 0.28480952380952385, 1.92, 0.99, 1.24, -0.01, 3.32, 1.29, 1.64, 0.71, 0.95, -0.3, -0.34, -0.91, -0.67, -1.9, 1.1101351386708531, 0.98, 0.58, 0.24, -1.0, 1.12, 1.18, 1.0825760496238783, -3.15, 1.04, 3.1, 1.32, 2.34, 0.34, -1.24, 1.31, 1.0, 0.1, 0.48, 1.49, 1.59, 2.13, 2.67, 1.51], ['399', -4.36, 1.46, 0.04, -0.16, 0.33, 0.82, 1.44, 0.02, -0.07, 0.5, -0.56, 0.23, -0.62, 0.16, 0.13, 2.28, -0.82, 0.43, -0.88, 0.06, 0.86, -0.1, -0.54, -0.65, -3.11, -1.0, 1.07, 0.8005454545454546, -0.05, 0.73, 0.7, 2.86, -0.25, 1.0, 0.12570238095238095, 0.63, 1.43, 0.46, 0.03, -0.08, -0.88, 0.69, 0.26, -0.85, -0.07, -0.1, 2.04, -1.05, 0.2, -1.11, -0.17, 0.62, -0.34, -0.77, -0.88, -0.03, -2.23, -2.04, -0.53, 1.12, 0.78, 0.75, 2.91, -0.2, 1.1526050661400618, -0.27, 0.68, 1.48, 0.51, 0.08, -0.03, -0.26, 0.33, -0.04, 2.11, -0.98, 0.27, -1.04, -0.1, 0.69, -0.27, -0.7, -0.81, 0.82, 2.82, -2.9, 0.37, 2.15, -0.94, 0.3, -1.01, -0.06832539682539683, 0.73, -0.23, -0.66, -0.78, -2.15, -1.74, -3.03, -1.8, -3.09, -2.17, -1.39, -2.33, -2.75, -2.86, 0.09, -1.76, 1.95, 0.96, 0.89, 1.08, 1.32, 1.26, -0.07, 0.88, 1.69, 0.72, 0.28, 0.17, 0.53, 0.06, -1.31, -0.37, 0.42, -0.54, -0.97, -1.08, 1.3, 1.14, -0.25, 1.27, -6.37, 0.11, 0.04, -2.76, 2.81, 1.428810171007621, 0.28, 1.29, -1.04, -1.93, -0.97, -2.21, 0.46, 2.75, -2.79, -2.89, 0.97, -4.26, 1.94, 2.37, -1.18, 3.96, -6.51, -2.62, -3.96, 1.0, 1.39, 0.95, 1.75, 0.78, 0.6696385796742939, 0.23, 2.89, 0.44, 0.8, -0.16, -0.6, -0.71, -0.36, -0.96, -1.38, -1.49, 1.032795351473923, 1.01, 0.6, -0.43, -0.54, 0.93, 1.02, 0.49, -3.11, 1.84, 3.11, 1.0, 1.56, 1.04, -0.11, 1.11, 1.2, 0.08, 0.7316666666666667, 0.8, 1.15, 1.38, 2.29, 1.24], ['400', -4.13, 1.15, 0.32122171562045876, -0.34, 0.3, 1.82, 1.414115257959829, 2.64, 1.88, 3.32, 0.89, 2.31, 1.67, 0.46, 0.85, 5.34, -0.42, 2.25, 5.46, 1.07, 3.28, 1.08, 0.11, 1.06, 2.34, 1.6993714145888918, 2.41, 1.41, 0.77, -0.43, -0.04, 4.41, -1.3, 1.34, 4.53, 0.18, 2.434453670078569, 0.19, -0.77, 0.16, 1.77, 2.1649361992161733, 0.99, -0.63, -1.81, -1.42, 2.96, -2.67, -0.06, 3.08, -1.21, 0.94, -1.2, -2.15, -1.23, 0.5, 1.6, 2.05, 2.16, 1.63, -1.19, -0.8, 3.62, -2.05, 0.57, 3.74, -0.59, 1.58, -0.57, -1.53, -0.6, 3.6, 2.85, 0.39, 4.86, -0.88, 1.78, 4.98, 0.61, 2.8, 0.62, -0.34, 0.6, 2.28, 9.31, -9.26, 2.4508709226619945, 4.45, -1.27, 1.38, 4.57, 0.21, 2.4, 0.23, -0.74, 0.2, -0.7, -1.92, -5.47, -2.94, 0.12, -4.06, -1.96, -4.04, -4.97, -4.07, 0.95, -1.93, 3.47, 2.3, 2.62, 2.255673518650032, 3.831809476486129, 2.68, 5.91, 1.5, 3.71, 1.51, 0.54, 1.49, 2.09, 1.06, 3.15, -1.15, 1.01, -1.14, -2.09, -1.16, 3.21, 3.67, 0.22, 3.15, -1.55, 1.18, 0.87, -4.63, 4.67, 2.37, 1.96, 3.13, -4.41, -4.61, -2.34, -2.15, 1.86, 7.12, -7.23, -6.76, 2.3, -7.0, 4.59, 2.74, -1.33, 11.35, -10.33, -7.49, -11.18, 4.46, -2.03, -4.17, -2.08, -4.16, -5.08, -4.18, 6.81, 2.23, 2.18, 0.01, -0.95, -0.01, 0.05, -2.12, -3.06, -2.15, 2.0601351386708533, 2.48, 2.22, -0.96, -0.03, 2.26, 2.47, 2.74, -5.19, 3.7, 5.19, 2.3, 2.08, 3.21, 0.94, 2.55, 2.14, 1.56, 1.72, 2.29, 2.325957527023814, 2.74, 3.47, 2.97], ['401', -1.88, 0.0, -0.07877828437954125, 0.12, -0.9, 0.19, 0.69, -0.06, 0.31, -0.17, 0.37, -1.02, 0.19, 0.27, -0.41, -0.85, 0.28, 0.19, 1.59, -0.07, -0.03, -0.81, -0.24, -0.31, 0.17, 0.16937141458889196, -0.54, -1.39, -0.18, -0.1, -0.78, -1.22, -0.1, -0.18, 1.21, -0.44, -0.4, -1.18, -0.61, -0.68, -0.13, -1.07, 0.860204081632653, 1.22, 1.31, 0.61, 0.17, 1.31, 1.23, 2.64, 0.96, 1.0, 0.22, 0.78, 0.72, -0.4376426685347185, -0.25, 0.08, 0.42, -0.36, 0.08, -0.6, -1.04, 0.09, 0.0, 1.4, -0.25, -0.22, -1.0, -0.43, -0.5, -0.41, -0.44, -0.68, -1.12, 0.0, -0.08, 1.32, -0.34, -0.3, -1.08, -0.52, -0.58, -0.3, 0.65, -0.65, 0.25, -0.44, 0.69, 0.61, 2.01, 0.35, 0.38, -0.4, 0.17, 0.11, -0.02, 0.69, 1.14, 1.05, 2.47, 0.79, 0.83, 0.04, 0.61, 0.55, -0.25, 0.71, 0.19572371188304005, -0.14, 0.0, -0.41, -0.44, -0.08, 1.31, -0.34, -0.31, -1.0196949805527125, -0.52, -0.58, 0.53, -0.36, 1.4, -0.26, -0.22, -1.0, -0.44, -0.5, -0.08, -0.13, 0.38, -0.57, 0.03, -0.19, -0.35, 0.52, -0.59, -0.2411898289923789, -0.08, 0.28, 0.4205182488772715, 0.31, 0.19, -0.94, -0.15, -0.6, 0.67, 0.49, -0.15, 0.94, -0.32, -0.2, 0.08, -1.37, 7.1, 0.9, 1.41, -0.35, -1.73, -1.63, -1.6, -2.36, -1.81, -1.87, -0.49, -0.1, 0.03, -0.74, -0.18, -0.24, -0.14, -0.78, -0.21, -0.28, 0.19, 0.07, 0.64, 0.57, 0.5, -0.21, -0.21, 0.12, 3.45, 0.09019962695749935, -3.36, -0.46, -1.1488174603174601, 0.08, -0.06, -0.68, -0.23, -0.09, -0.28, 0.27, 0.14, -1.15, -1.9884047619047618, 0.15], ['402', 2.15, 0.84, 0.69, -0.07, 0.87, 1.29, 0.76, 1.9917205965359586, 1.8893780543870107, 0.99, -0.94, 0.471934498041641, -0.6860867348791511, -2.04, -1.77, 0.08, -0.72, -0.36, 1.14, -1.27, 2.087335482087359, -1.96, -1.48, 0.24, 3.76, 1.89, 1.9826583949931125, 1.23, 0.19, -1.11, -0.7721800287049088, 1.03, 0.23, 0.59, 2.1, -0.33, 3.02, -1.03, -0.54, 1.2338417231978391, 1.42, 1.6, 0.71, -1.02, -2.31, -2.04, -0.2, -0.99, -0.63, 0.86, -1.54, 1.77, -2.23, -1.75, 0.2808287981859412, 1.31, 1.71, 1.46, 1.48, 1.75, -1.3, -1.03, 0.83, 0.03, 0.39, 1.9, -0.52, 2.82, -1.22, -0.73, 1.0, 1.85, 3.1, 0.28, 2.16, 1.35, 1.72, 3.25, 0.79, 4.18, 0.08, 0.58, 2.33, 2.33, 7.17, -7.08, 2.8466982383853203, 1.88, 1.07, 1.43, 2.96, 0.7037447711019141, 3.88, -0.2, 0.3, 2.04, 2.5, 0.91, -0.79, -0.44, 1.06, -1.34, 1.97, -2.04, -1.55, 0.16, 1.23, 0.94, 2.41, 1.55, 2.1, 1.08, 1.72, 0.36, 1.87, -0.3602873118944545, 2.79, -1.25, -0.6940121365844474, 0.96, 3.0265360710717855, 1.35, 1.5, -0.91, 2.598603019995877, -1.4842004503433075, -1.12, 0.6, 3.35, 2.54, -0.06, 1.75, 4.94, 1.4, 0.8, -1.45, 1.49, 0.71, 2.58, 3.2, -4.55, -3.1, -1.6, 1.05, 1.27, 4.83, -4.76, -4.67, 1.55, -2.38, 3.12, 1.74, -0.85, 5.18, -7.23, -3.51, -5.05, 4.47, -0.15, -2.38, 0.9, -3.07, -2.59, -0.89, 4.72, 2.29, 3.3635374149659865, -0.7, -0.21, 1.53, -1.04, -3.93, -3.45, -1.77, 1.79, 1.88, 3.01, 0.5, 2.3222487553150164, 1.57, 1.58, 2.01, -3.7, 2.03, 3.77, 0.9172638105244333, 3.03, 2.5, 1.74, 1.05, 1.2, 1.07, 2.93, 1.16, 0.75, 2.72, 3.75, 0.3], ['403', -4.38, 0.95, 0.04015289830927054, 0.1, -0.3, 0.44, 1.52, 0.02, 0.19, -1.29, -1.7, -1.77, -0.07, -2.02, -0.85, 0.29, -1.5, -1.5, -3.9, -0.71, -1.33, -1.94, -1.71, -1.94, -0.78, 0.64, 0.42, -0.07, 1.6808333333333332, -0.33, 0.86, 2.03, 0.2, 0.2, -2.24, 1.0, 0.37, -0.24, -0.01, -0.24, 0.05, -0.12993788819875776, 0.49, 1.811197467496117, -0.25, 1.0108150295752765, 2.1, 0.28, 0.27, -2.17, 1.08, 0.478065468086443, -0.17, 0.07, -0.17, 0.42, -0.55, 0.6, 0.15, -1.22, -1.95, -0.78, 0.36, -1.43, -1.43, -3.83, -0.64, -1.26, -1.87, -1.64, -1.87, 0.02, 0.75, 1.2, 2.36, 0.53, 0.53, -1.92, 1.34, 0.7, 0.08, 0.32, 0.08, 0.37, 0.95, -0.98, -0.44, 1.15, -0.65, -0.66, -3.08, 0.14, -0.49, -1.1, -0.86, -1.1, -1.92, -1.58, -1.78, -1.776904761904762, -4.17847619047619, -1.0, -1.62, -2.22, -1.99, -2.22, 0.08, -1.47, -0.54, 0.36, 0.37, 0.38567351865003197, 0.2109570400359874, 0.0, -2.4398412698412697, 0.8, 0.17, -0.45, -0.21, -0.45, 0.52, 0.22, -2.44, 0.8, 0.17, -0.44, -0.21, -0.44, -0.03, -0.05, 0.28, 0.35, -5.92, 0.06, 0.07, -0.72, 0.67, 0.34, -1.09, 1.40025974025974, 1.16, -0.7, -0.35, -2.34, 0.22, 1.09, -1.09, -1.07, 0.35, -1.11, 0.69, -1.17, 0.56, 0.6707142857142857, 0.0, -0.46, -0.74, -1.17, 2.72, 3.32, 2.67, 2.04, 2.28, 2.2057617128436457, 1.02, -0.5798412698412698, -0.62, -1.24, -1.0, -1.24, 0.04, -0.62, -0.38, -0.61, 0.23, 0.27, 0.66, 0.24, 0.0, 0.35, 0.34, 0.07, -0.1, 0.07, 0.08, 0.12, 0.5410935020800125, 0.43, -0.24, 0.41, -0.06, 0.12, 0.11, 0.88, 0.745957527023814, 1.6, 0.7030376647162363, 0.93], ['404', -0.16, 0.18, 0.18122171562045875, -0.02, 1.28, 0.04, 0.16, 0.67, 0.76, 0.24, -0.55, -0.41, 1.55, -0.94, -1.9, 0.17, 0.56, 0.19, -0.65, -2.45, 0.24, 1.7960714285714285, 1.2, -0.21, 1.39, 0.85, 0.8, 0.14, 2.11, -0.39, -1.35, 0.72, 1.11, 0.75, -0.09, -1.91, 0.8, 2.36, 1.77, 0.34, 0.66, -0.1, 0.66, 1.97, -0.53, -1.49, 0.58, 0.97, 0.61, -0.23, -2.04, 0.66, 2.21, 1.62, 0.2, 0.12006284630567655, 0.43, 1.01, 0.85, -1.28, -2.45, -3.39, -1.36, -0.97, -1.33, -2.16, -3.93, -1.116578845757417, 0.24, -0.34, -1.73, 1.19, 1.19, -0.97, 1.11, 1.51, 1.14, 0.3, -1.52, 1.19, 2.76, 2.16, 0.74, 0.63, -2.72, 2.69, 2.18, 2.1, 2.5, 2.13, 1.28, -0.56, 2.18, 3.76, 3.16, 1.72, 0.872095238095238, 0.08, 0.39, 0.03, -0.81, -2.61, 0.08, 1.62, 1.04, -0.37, 0.16, 0.04, -2.49, 0.06, -0.31, 0.45, -0.31, -0.36, -1.2, -2.99, -0.31, 1.23, 0.64, -0.76, -1.22, 0.05, -0.84, -2.64, 0.05, 1.59, 1.01, -0.4, -1.36, -1.41, 0.15, -0.08, 2.87, 0.1, 0.08, -1.81, 1.81, 0.9, -0.28, 1.23, -5.67, -0.19, -0.11, -0.11, -0.32, 0.22, -0.19, -0.28, 0.09, -2.71, 0.25987835724131525, 0.61, -0.3, -0.94, 1.28, 0.77, 0.91, 5.66, 0.9, -1.81, 0.9, 2.45, 2.179638579674294, 0.44, 0.26, 2.76, 2.76, 4.35, 3.74, 2.29, 0.0, 1.54, 0.96, -0.45, 0.7, 0.73, -1.52, -0.58, -1.97, 0.08, 0.03, 0.68, -0.14, 0.0, 0.14, 0.71, 0.12, -0.95, -1.4, 0.3, 0.78, -0.45, -0.06666666666666667, -0.21, 0.45, 0.34, 0.55, 0.34], ['405', 2.59, 0.66, 0.0, -0.28538095238095235, -0.1, 0.21, 0.4741152579598292, -0.09, 0.67, -0.93, -1.55, -1.17, -1.41, -1.4, 0.73, -1.18, -2.47, -1.2, -1.99, -1.41, -0.39, -2.02, -2.3, -1.49, 0.63, 0.52, 0.6626583949931124, 0.39, 0.14, 0.16, 2.32, 0.38, -0.93, 0.36, -0.44, 0.15, 1.18, -0.47, -0.76, 0.07, -0.38, 1.3949361992161733, 0.25, -0.24, -0.22, 1.93, -0.01, -1.31, -0.03, -0.82, -0.24, 0.7996547292370609, -0.85, -1.14, -0.31, 0.69, -0.31, -0.14805211528237844, 0.45, 0.49, 0.12310472253556064, 2.18, 0.24, -1.07, 0.22, -0.58, 0.0, 1.04, -0.61, -0.9, -0.07, 0.54, 0.47, 2.16, 0.22, -1.09, 0.2, -0.6, -0.01, 1.02, -0.63, -0.91, -0.09, 0.99, 3.58, -3.66, -1.65, -1.9, -3.18, -1.92, -2.7, -2.13, -1.12, -2.73, -3.01, -2.2, 0.5012233560090703, 0.25, -1.3, -0.02, -0.81, -0.23, 0.8, -0.84, -1.13, -0.31, 0.28, 0.26, -0.33, 0.65, 0.62, 0.67, 1.58, 1.3, 0.5, 1.09, 2.13, 0.47, 0.18, 1.0685846838830657, 0.88, 0.27, -0.79, -0.21, 0.82, -0.82, -1.11, -0.29, 1.36, 1.6, -0.31, 0.77, 0.71, 0.12, 0.28, -1.72, 1.78, 0.9, 0.55, -0.31, -0.93, -1.32, -0.66, 1.3, 0.19, 1.95, -1.95, -1.96, 0.64, -2.56, 1.28, 2.78, -1.37, 4.77, 0.34, -3.25, -4.7, 0.87, 1.08, 0.59, 1.63, -0.03, -0.32, 0.51, 1.97, 0.49, 1.03, -0.61, -0.9, -0.08, -0.54, -1.5411214088935783, -1.91, -1.1, 0.64, 0.72, 1.11, -0.29, 0.54, 0.65, 0.7, -0.22, -6.23, 0.65, 6.25, 0.97, 0.74, 1.4, 0.83, 0.34, 0.8002197802197802, 0.09, -0.12, 0.14, 0.56, 2.9, 1.53, 0.52], ['406', -11.77, 0.0, -0.08, -0.08, -0.74, -0.02, -0.67, 0.52, -0.65, 0.1, 1.03, 1.44, -0.34, 0.89, -0.3, 4.37, 0.5, 0.02, -2.24, 0.64, -0.5, 0.0, -0.17, -0.18, 0.4, -0.03, -0.93, 0.41, -1.35, -0.14, -1.32, 3.31, -0.53, -1.0, -3.229285714285714, -0.39, -1.51, -1.02, -1.19, -1.2, 0.33, -0.48, -1.33, -1.75, -0.55, -1.72, 2.89, -0.93, -1.4, -3.63, -0.79, -1.91, -1.42, -1.4928571428571429, -1.6, 1.24, 1.09, 1.71, -0.11, 0.44, 1.23, 0.04, 4.73, 0.84, 0.4626050661400617, -1.8013219954648525, 0.98, -0.16, 0.34, 0.16, 0.16, 2.02, -0.78, -1.18, 3.45, -0.39, -0.86, -3.1, -0.25, -1.2169183673469388, -0.88, -1.05, -1.0064403582748793, -0.72, 0.81, -0.83, 0.4, 4.69, 0.8, 0.32, -1.94, 0.94, -0.2, 0.3, 0.13, 0.12, -3.58, -4.1, -3.71, -4.17, -6.33, -3.58, -4.67, -4.19, -4.36, -4.36, 0.09, -4.17, 3.29, 0.0, 0.03, 0.0, -0.4, -0.48, -2.72, 0.14, -0.99, -0.5, -0.67, -0.68, 0.18, 0.07, -2.26, 0.62, -0.34139698000412266, -0.02, -0.19, -0.2, 0.58, 0.53, 0.03, 0.08, -10.58204761904762, 0.2, 0.17, -0.03, -0.01, 0.0, -0.3, -0.15, 1.06, 0.0, -0.02, -5.73, 0.27, 0.05, -0.05, -0.02, -0.01, 0.0, 0.02, 1.28, -0.65, -1.2, -2.0, 0.85, 1.22, -1.16, 2.39, 2.94, 1.78, 2.29, 2.4296385796742936, 2.1, 0.0, -0.54, -1.13, -0.64, -0.81, -0.81, 0.6, 0.5, 0.33, 0.32, -0.63, -0.47, 0.1, -0.17, -0.18, 0.0, -0.01, 0.51, -3.27, 2.01, 3.18, -1.57, -0.59, 0.27, -0.01, -0.08, 0.0, 0.56, 0.7702244897959184, -0.11, 0.28, -1.7, -1.26, -0.72], ['407', -2.11, -0.3, 0.08015289830927054, -0.12, -0.44, 0.81, 0.36, 0.56, 0.68, -0.57, -1.76, -0.52, -1.05, -1.24, -1.11, -0.36, -1.64, -0.85, 0.42, -0.16, -0.23, -0.79, -1.28, -0.91, 0.91, 0.63, 1.2, 1.26, 0.71, 0.53, 0.66, 1.42, 0.11, 0.92, 2.22, 1.63, 1.55, 0.99, 0.5788796134390451, 0.86, 0.8574684253532109, 1.7949361992161734, -0.05, -0.54, -0.72, -0.59, 0.16, -1.13, -0.33, 0.95, 0.36, 0.29, -0.27, -0.77, -0.39, 0.5900628463056766, 0.28, 0.29, 0.25, 0.49, -0.18, -0.05, 0.71, -0.6, 0.21, 1.49, 0.91, 0.83, 0.27, -0.23, 0.15, 0.98, 0.67, 0.13, 0.89, -0.41, 0.39, 1.68, 1.09, 1.02, 0.46, -0.05, 0.33, 1.33, 1.72, -1.75, 0.5766982383853202, 0.76, -0.54, 0.26, 1.55, 0.96, 0.88, 0.32, -0.18, 0.2, 0.02, -0.22, -1.29, -0.5, 0.78, 0.2, 0.12, -0.43, -0.93, -0.55, 0.28, -0.24, 0.68, 0.87, 0.65, 1.075673518650032, 1.09, 0.81, 2.1, 1.51, 1.44, 0.87, 0.44598786341555263, 0.8085846838830657, 0.2, 0.28, 1.28, 0.7, 0.62, 0.1957995496566927, -0.44, -0.06, 0.47, 0.69, -0.27, 0.55, 0.24, 0.1, 0.03, -3.28, 3.26, 1.64, -0.12, 0.52, 0.8277589791161221, -1.77, -0.87, -1.01, 0.42, 2.68, -2.71, -2.68, 0.87, -4.94, 1.76, 1.72, -0.86, 3.22, -5.13, -2.22, -3.16, -0.77, -0.99, -0.58, -0.4527867132867132, -1.2, -1.7, -1.33, 2.7, -0.41, -0.07, -0.63, -1.13, -0.75, -0.34, -0.56, -1.05, -0.68, 0.67, 0.8, 0.21, -0.5, -0.12, 0.89, 0.86, 0.57, -3.15, 0.02, 3.14, 0.94, 0.76, 0.72, 0.38, 0.58, 1.7, 0.39, 0.29, 1.16, 0.34, 1.75, 0.74, 0.53], ['408', 3.41, -0.08, -0.14877828437954127, 0.16, -1.45, -0.05, -0.49, -0.61, 0.0, -0.13, -0.33, 0.15, 0.93, 1.77, 1.0, -0.29, -0.33, 0.17, 1.27, 1.37, 0.48, 0.91, -0.13, -0.34, -1.55, -0.3, 0.19, 0.48, 1.26, 2.1, 1.33, 0.04, 0.0, 0.5, 1.6, 1.7, 0.81, 1.24, 0.19, -0.01, -0.75, 0.9749361992161734, -0.28, 0.77, 1.61, 0.84, -0.44, -0.48, 0.02, 1.11, 1.22, 0.33, 0.75, -0.28, -0.49, 0.25006284630567654, -0.71, -0.93, -0.01, -1.05, 0.83, 0.07, -1.2, -1.24, -0.75, 0.34, 0.44, -0.44, -0.02, -1.05, -1.25, -2.1, -1.87, -0.75, -2.02, -2.06, -1.57, -0.49, -0.39, -1.26, -0.84, -1.87, -2.07, 0.42, 0.67, -0.62, -1.12, -1.27, -1.31, -0.82, 0.5057885487528346, 0.37, -0.51, -0.09, -1.12, -1.32, 1.31, 0.2273665312165629, -0.04, 0.46, 1.56, 1.66, 0.77, 1.2, 0.15, -0.05, -0.22, 0.2, -0.09, 0.05, -0.16, 0.24, 0.2, 0.5, 1.6, 1.7, 0.81, 1.24, 0.2, -0.01, -0.9, -0.3, 1.1, 1.2, 0.31, 0.74, -0.3, -0.51, -0.09, 0.91, 0.09, -0.14, 2.64, -0.03, -0.02, -1.11, 1.08, 0.55, 0.86, -1.1797402597402598, 2.8787161013589584, -0.13, -0.05, 1.73, -0.16, 0.11, -0.08, -0.17, 0.1, -1.58, 0.1, -0.28, 0.13, 0.49, 0.8686904761904761, -0.46, -0.57, -2.85, -1.38, 0.1, -0.78, -0.36, -1.38, -1.58, 0.25, -1.48, -0.88, -0.46, -1.48, -1.68, -0.61, 0.43, -0.61, -0.81, 0.0, 0.21, -1.03, -1.03, -1.23, 0.02, 0.09, -0.79, 0.46, 0.16, -0.96, -0.27, -1.36, 0.0, -0.2, 0.3, 0.75, 0.23, -0.49, -0.23, 0.2, -0.78, -1.55, 1.0930167737073972], ['409', 5.44, 0.21, 0.29, -0.17, 1.32, 3.36, 2.4941152579598294, 5.13, 4.14, 3.63, -2.33, 1.0393248299319728, 0.34, -1.04, -1.56, 1.9, -0.8, 2.58, 4.85, 3.07, 4.52, 0.26, -0.81, 1.49, 5.29, 3.6, 6.132658394993112, 3.44, 2.73, 1.32, 0.8, 4.33, 1.56, 5.03, 7.35, 5.53, 7.02, 2.66, 1.55, 3.963841723197839, 3.39, 5.0, 2.57, -0.68, -2.05, -2.56, 0.86, -1.81, 1.54, 3.78, 2.02, 3.46, -0.76, -1.82, 0.46, 5.25, 4.55, 3.29, 3.89, 3.28, -1.37, -1.88, 1.56, -1.14, 2.24, 4.49, 2.72, 4.17, -0.07, -1.15, 1.15, 5.0, 4.72, -0.52, 2.97, 0.24, 3.66, 5.95, 4.15, 5.62, 1.32, 0.23, 2.6135596417251206, 5.36, 12.29, -12.37, 5.260870922661994, 3.51, 0.76, 4.2, 6.5, 4.69, 6.17, 1.85, 0.75, 3.1, 4.98122335600907, 1.7, -2.65, 0.67, 2.89, 1.14, 2.632626537352693, -1.61, -2.66, -0.4, 1.26, 1.9493682032253463, 4.6, 3.21, 3.38517906963434, 3.09, 4.47, 3.41, 5.7, 3.9, 5.37, 1.08, -0.01, 2.32, 3.3, 1.02, 2.21, 0.47, 1.89, -2.26, -3.31, -1.06, 4.33, 5.05, 0.37, 3.84, 9.37, 0.5803231292517006, 0.81, -5.78, 5.78, 2.91, 1.61, 5.15, -1.0094817511227283, -6.49, -3.21, 2.84, 2.0, 9.880596861471862, -9.66, -9.61, 3.19, -8.77, 6.37, 2.45, -1.19, 13.35, -14.71, -8.9, -13.33, 1.14, -1.16, -1.7, -0.31, -4.37, -5.4, -3.2, 9.6, 0.54, 1.41, -2.72, -3.76, -1.53, -0.85, -4.07, -5.1, -2.9, 4.32, 4.63, 3.35, -1.07, 1.23, 3.22, 3.29, 5.1, -7.43, 4.26, 7.65, 4.41, 4.27, 4.5586374482009715, 2.33, 4.3, 2.96, 1.93, 1.74, 2.54, 2.1, 7.83, 4.61, 2.12], ['410', 2.09, 0.62, 0.09122171562045875, -0.17, 0.28, 0.93, 0.22, 1.39, 1.3093780543870106, 2.22, 0.92, 2.16, 0.94, 0.8, 1.04, 1.86, 1.91, 2.52, -1.79, 1.74, 2.45, 3.7130748299319727, 1.41, 1.94, 1.39, 1.07, 1.28, 1.23, 0.02, -0.12, 0.11, 0.93, 0.98, 1.7072589041444086, -2.69, 0.81, 1.594453670078569, 2.76, 0.48, 1.0, 1.1, 2.41, 0.05, -1.2, -1.33, -1.1, -0.3, -0.24, 0.35, -3.87, -0.41, 0.28, 1.52, -0.74, -0.22, 1.65, 0.75, 1.12, 1.09, 1.27, -0.13, 0.1, 0.91, 0.97, 1.57, -2.7, 0.8, 1.5, 2.75, 0.46, 0.99, 1.56, 1.41, 0.6502278911564625, 1.05, 1.1, 1.71, -2.57, 0.93, 1.64, 2.89, 0.6, 1.12, 1.57, 1.71, -1.59, 1.17, 0.81, 0.87, 1.47, -2.8, 0.7, 1.4, 2.65, 0.37, 0.89, 0.71, 0.35, 0.05, 0.66, -3.58, -0.11, 0.58, 1.82, -0.44, 0.08, -0.39, 0.46, -0.34, 0.66, 0.58, 0.45, 0.3, 0.6, -3.63, -0.17, 0.53, 1.76, -0.5, 0.02, -1.2, -0.3, -4.21, -0.76, -0.07, 1.16, -1.09, -0.57, 0.11, -0.31, -0.17, -0.64, 2.04, -0.36, 0.23, -0.4, 0.41, 0.22, 0.13, 2.44, -0.96, -1.25, -0.64, 1.02, 0.3430797898687791, 1.9, -1.96, -1.95, 0.65, -0.63, 1.36, -0.07160934502005914, -0.16, 0.88, -3.37, -0.6, -0.94, 0.97, 4.08, 3.6, 4.32, 5.6, 3.25, 3.79, 2.0, 0.47, 0.7, 1.94, -0.33, 0.19, -0.23, 1.23, -1.02, -0.5, 1.19, 1.32, -1.44, -2.22, -1.71, 0.62, 0.5, 1.39, -1.76, -0.32, 1.7021428571428572, 0.82, 1.2010935020800126, 0.8, 0.52, 0.71, 0.28, 0.8, 0.1, 0.84, 0.28, 1.03, 1.31, -0.05], ['411', -1.3, -0.59, -0.10877828437954125, -0.03, -1.18, -0.71, -4.9, -1.97, -1.33, -2.82, -1.75, -0.77, -1.68, -0.29, -0.94, -2.111439909297052, -1.76, -2.19, -1.21, -1.55, -2.16, -1.57, -1.34, -1.92, -1.67, -0.87, -1.09, 0.99, 0.08, 1.49, 0.82, -0.69, 0.6328571428571429, -0.45, 0.55, 0.21, -0.41, 0.18, 0.42, -0.17, -1.68, -1.74, -2.06, -0.91, 0.49, -0.17, -1.67, -0.99, -1.43, -0.44, -0.78, -1.4, -0.8, -0.57, -1.16, -1.0, -0.76, -0.862172027190216, -1.01, -1.16, 1.41, 0.75, -0.76, -0.08, -0.52, 0.47, 0.13, -0.49, 0.11, 0.34, -0.25, -1.38, -2.54, -0.6592857142857144, -2.1485714285714286, -1.48, -1.91, -0.93, -1.26, -1.88, -1.29, -1.06, -1.64, -1.36, -4.07, 4.06, -1.9, -1.5, -0.82, -1.26, -0.27, -0.61, -1.23, -0.64, 0.05251700680272092, -0.99, -1.34, -0.4, 0.69, 0.24, 1.2415238095238095, 0.9, 0.28, 0.88, 1.11, 0.52, -0.61, -0.45, -2.01, -0.93, -1.03, -0.8, -1.08, -0.44, 0.55, 0.21, -0.41, 0.19, 0.42, -0.17, -1.28, -0.65, 1.0, 0.66, 0.03, 0.63, 0.87, 0.27, -1.09, -1.18, -0.22, -1.11, -3.8578571428571427, -0.96, -1.09, 1.59, -1.64, -0.85, -1.4, -2.49, 2.57, 1.83, 0.9745476190476191, -0.66, -0.67, -2.75, 2.8, 2.74, -0.92, 2.5, -1.83, -1.69, 0.83, -3.26, 10.0, 2.16, 3.25, -2.54, -1.63, -0.34, -0.96, -0.36, -0.13, -0.72, -2.74, -1.29, -0.62, -0.03, 0.21, -0.38, -0.68, 0.6, 0.84, 0.24, -1.34, -1.12, -1.27, 0.24, -0.35, -0.9, -0.96, -2.08, 5.86, -1.72, -5.67, -1.11, -1.53, -1.5, -0.59, -0.89, -0.79, -0.3, -0.47, -0.6, -0.92, -1.77, -2.05, -0.89], ['412', -1.51, 0.35, 0.08, -0.18, 0.48, 0.25, 0.21, 0.26, 0.33, 1.66, 0.58, 2.69, 1.96, -0.04, 1.5, 2.04, 1.4, 1.57, -1.17, 0.61, 2.21, 1.93, 1.16, 1.6, 0.37, 0.31937141458889196, 1.08, 2.1, 1.38, -0.61, 0.92, 1.46, 0.82, 0.98, -1.73, 0.04, 1.62, 1.35, 0.58, 1.02, 0.62, 1.12, -1.0, -0.71, -2.65, -1.15, -0.63, -1.25, -1.09, -3.75, -2.02, -0.47, -0.74, -1.49, -1.05, 0.39, 0.51, 0.14, 0.08, -0.29, -1.96, -0.45, 0.08, -0.55, -0.39, -3.052819727891156, -1.32, 0.24, -0.03, -0.79, -0.35, -0.75, 1.7, 1.5407142857142857, 2.08, 1.44, 1.6, -1.13, 0.65, 2.25, 1.97, 1.2, 1.64, 1.16, 1.05, -1.09, 0.16, 0.53, -0.1, 0.06, -2.63, -0.88, 0.69, 0.42, -0.34, 0.1540077275244506, -0.69, -0.37, -0.63, -0.47, -3.15, -1.4, 0.16, -0.11, -0.87, -0.43, 0.09, -0.44, 0.21, 0.17, 0.27, 0.09, 0.26, 0.16, -2.53, -0.78, 0.8, 0.52, -0.24, 0.2, -0.22, 0.15307674813036726, -2.69, -0.94, 0.8086030199958774, 0.36, -0.4, 0.04, 0.91, 0.78, -0.27, 0.22, -2.37, 0.05, -0.03, -0.26, 0.31, 0.15, 0.2, -0.11, -2.17, -0.37, -0.16, -0.75, -0.07, 0.48, -0.58, -0.51, 0.17, -0.44, 0.35, 1.61, -0.77, 0.75, -2.97, -0.48, -0.8, 2.09, 2.86, 1.8, 3.42, 3.14, 2.35, 2.81, 0.5, 1.04, 1.59, 1.31, 0.54, 0.99, -0.53, -0.27, -1.03, -0.59, 0.3, 0.84, -0.26, -0.76, -0.32, 0.16, 0.19, 0.31, -1.56, -0.23, 1.64, 0.5372638105244333, 0.6610935020800125, 0.5, 0.44, 0.1, 0.15, -0.08, -0.35, 0.04, 0.06, 0.86, 2.27, 0.42], ['413', 3.007142857142857, -0.58, 0.13122171562045873, 0.26, 0.88, -0.52, 0.28, 0.57, 0.7, -0.83, -1.72, -1.29, -0.9, -1.26, -1.96, -0.98, -0.33, -1.2, -0.46, -1.75, -0.02, -1.18, -0.84, -0.54, 1.09, -0.46, 0.9, 0.44, 0.83, 0.47, -0.24, 0.76, 1.41, 0.53, 1.28, -0.03, 1.73, 0.55, 0.9, 1.2, 0.38, 1.22, 0.4602040816326531, 0.39, 0.03, -0.68, 0.32, 0.97, 0.09, 0.9371355564861203, -0.47, 1.28, 0.11, 0.45, 0.76, 0.2, 0.91, 1.44, 1.0, 0.07, -0.36, -1.07, -0.08, 0.57, -0.3, 0.45, -0.85, 0.89, -0.28, 0.06, 0.36, 0.56, 0.43, -0.71, 0.29, 0.94, 0.06, 0.81, -0.49, 1.25, 0.08, 0.43, 0.73, 0.62, 0.52, -0.51, 1.15, 1.0, 1.66, 0.78, 1.53, 0.22, 1.98, 0.8, 1.14, 1.45, 0.35, 0.15, 0.65, -0.22, 0.52, -0.78, 0.96, -0.2, 0.14, 0.44, 0.26, 0.16, -1.54, -0.21, -0.16, -0.21432648134996807, -0.5, -0.87, -0.13, -1.42, 0.3106802721088435, -0.85, -0.51, -0.21, 0.1, 0.37, 0.75, -0.56, 1.19, 0.02, 0.36, 0.67, -0.21, -0.98, 0.5, -0.46, 0.61, 0.15, 0.42, -0.59, 0.63, 0.31, -0.1, 1.41, -1.83, 0.41, 0.22, 1.871438775510204, -0.28, -0.63, 0.64, 0.75, -0.22, -0.8, -0.44, -1.41, 0.74, -1.51, 3.5, 1.0, 1.43, 1.86, -0.3516360544217687, -1.29, 0.44, -0.72, -0.38, -0.08, -0.5468321004392431, 0.93, 1.76, 0.58, 1.3394625850340136, 1.23, -0.81, -1.16, -0.82, -0.52, 0.74, 0.86, 0.35, 0.35, 0.65, -0.23, -0.27, 0.61, 1.68, -1.31, -1.88, -0.73, 0.11, 0.01, 0.3, -1.77, 0.54, 0.015297952047952229, -0.27, -0.62, -0.29, -1.67, 0.31, 0.77], ['414', -1.9, -0.17, -0.04877828437954125, -0.14, -0.24, 0.55, 1.15, 0.51, 0.06, 0.94, 0.63, 0.3, 0.9, 1.02, 0.7, 1.33, 0.0, 1.04, -0.93, 1.27, 0.55, 0.65, -0.42, 0.06, -0.11, -0.18, 0.34265839499311246, -0.33, 0.26, 0.38, 0.07, 0.69, -0.63, 0.4, -1.55, 0.63, -0.09, 0.02, -1.05, -0.57, -0.15, 0.4249361992161734, 0.64, 0.6, 0.72, 0.4, 1.03, -0.3, 0.74, -1.22, 0.97, 0.25, 0.35, -0.72, -0.24, 0.24, 0.14, 0.43, 0.3, 0.04, 0.11, -0.2, 0.43, -0.89, 0.14, -1.81, 0.37, -0.35, -0.25, -1.31, -0.83, 1.57, -0.07, -0.31, 0.31, -1.0, 0.02, -1.92, 0.25, -0.46, -0.36, -1.43, -0.95, 0.03, 3.8, -3.83, 0.24, 0.62, -0.7, 0.34, -1.62, 0.56, -0.15, -0.05, -1.12, -0.64, -0.86, -0.38, -1.31, -0.29, -2.23, -0.06, -0.77, -0.67, -1.73, -1.25, 0.09, -0.26063179677465376, 1.4, 0.8715981806829014, 0.89, 0.825673518650032, 0.94, 1.04, -0.93, 1.27, 0.55, 0.65, -0.43, 0.06, 0.38, -0.1, -1.95, 0.23, -0.49, -0.38, -1.45, -0.97, 1.2, 0.91, -0.13, 0.93, -2.6, -0.26, -0.26, -0.7, 0.67, 0.37, -0.4, -0.07, 0.67, -1.6, -0.82, -0.88, 0.72, 2.38, -2.35, -2.38, 0.81, -1.02, 1.61, 1.04, -0.51, 2.82, -0.38, -1.83, -2.81, -0.61, 1.89, 2.22, 1.49, 1.59, 0.51, 1.0, 2.42, -0.32, -0.72, -0.61, -1.67, -1.19, 0.39, 0.11288492856349999, -0.97, -0.48, 0.19, 0.24845354645354667, 0.29, -1.07, -0.59, 0.8, 0.83, 0.44257604962387836, -0.19, 1.16, 0.13, 1.02, 0.98, 1.37, 0.49, 0.92, 0.3345528598385743, 0.9, 0.45, 0.82, 0.965957527023814, -0.49, 1.59, 1.08], ['415', -2.6, -0.29, 0.13122171562045873, -0.13, 0.78, 0.9, 0.49411525795982914, 0.26, 0.37, -0.61, -0.7993911564625851, -1.28, -1.22, -0.65, -0.84, -0.6, -1.5, -0.97, -11.0, -1.93, -0.43, -1.85, -1.44, -1.72, 0.09, 0.12, 0.21, -0.47, -0.41, 0.17, -0.03, 0.22, -0.69, -0.16, -10.27, -1.13, 0.38, -1.04, -0.64, -0.91, -0.05, 1.9608975626058773, 0.68, 0.06, 0.64, 0.44, 0.69, -0.22, 0.31, -9.85, -0.67, 0.85, -0.58, -0.07285714285714287, -0.45, -0.01993715369432346, 0.0, 0.26, 0.47, 0.62, 0.6831047225355606, 0.38, 0.63, -0.28, 0.25, -9.9, -0.72, 0.8, -0.64, -0.23, -0.5, 0.61, 0.04, -0.2, 0.05, -0.86, -0.33, -10.42, -1.29, 0.22, -1.21, -0.8, -1.08, 0.88, 2.57, -2.63, 0.24, 0.25, -0.66, -0.13, -10.25, -1.1, 0.41, -1.01, -0.6, -0.88, -0.38, -0.01, -0.91, -0.38, -10.47, -1.35, 0.16, -1.26, -0.85, -1.13, 0.62, 0.06, 2.79, 0.78, 0.93, 0.59, 0.9009570400359874, 0.53, -9.65, -0.44, 1.08, -0.36, 0.05, -0.22, 1.19, 0.36, -10.13, -0.97, 0.54, -0.89, -0.48, -0.75, 0.95, 0.85, -0.15, 0.72, -1.17, 0.14, 0.13, -0.74, 0.74, 0.4088101710076211, 0.63, 1.09, -2.6, -1.57, -0.81, -1.29, 0.78, 2.45, -2.3, -2.31, 0.833290804863853, -1.08, 1.57, 0.45, -0.26, 2.7, -2.59, -1.91, -2.64, 2.6, 11.68, 10.517178777571635, 11.88, 10.29, 10.74, 10.43, 2.4208051948051947, 1.35, 1.53, 0.09, 0.5, 0.22, -0.18, -1.42, -1.02, -1.29, 0.37, 0.56, 1.26, 0.41, 0.14, 0.84, 0.8, 0.29, -2.14, 1.84, 2.29, 0.35, 1.26, 0.85, -0.28, 0.55, 0.29, 1.1, 0.64, 1.15, 1.13, 0.44, 2.04, 1.49], ['416', 4.501428571428571, -0.63, -0.08, -0.13, 0.49, 0.48, 1.45, 0.75, 0.79, -0.05, -1.16, -0.74, -0.75, -0.48, -1.2, -0.33, -0.23, -0.35, 0.78, -1.15, 0.27, -0.02, -1.16, -0.74, 0.84, 0.969371414588892, 1.12, 0.42, 0.42, 0.69, -0.04, 0.84, 0.94, 0.83, 1.96, 0.01, 1.524453670078569, 1.15, 0.0, 0.42, 0.26, 1.99, 0.7, 0.0, 0.4378753944468231, -0.46, 0.42, 0.52, 0.4, 1.53, -0.41, 1.02, 0.73, -0.42, 0.0, 0.37, 0.76, 0.95, 0.78, 0.7, 0.27, -0.45, 0.42, 0.52, 0.4, 1.54, -0.41, 1.02, 0.73, -0.42, 0.0, 0.45, 0.43, -0.72, 0.15, 0.25, 0.13, 1.26, -0.68, 0.75, 0.46, -0.69, -0.21644035827487929, 1.24, 2.66, -2.7, 1.19669823838532, 0.88, 0.98, 0.86, 2.0, 0.05, 1.48, 1.19, 0.04, 0.46, 2.83, 0.28, 0.1, -0.02, 1.11, -0.82, 0.6, 0.5528169964955679, -0.83, -0.42, 0.43, 0.24, 3.05, 0.65, 0.82, 0.43567351865003195, 0.18, -0.11, 1.01, -0.92, 0.5, 0.21, -0.93, -0.51, 0.14, 0.29, 1.13, -0.81, 0.62, 0.33, -0.82, -0.4, 1.0189583699631244, 0.65, -0.08, 0.26, 8.541102040816327, 0.15, 0.02, -0.51, 0.52, 0.30881017100762115, -0.63, 1.96, -2.23, -1.25, -0.65, 2.6014387755102044, 0.25, 1.95, -1.88, -1.88, 0.63, -0.77, 1.27, 1.56, -0.76, 0.58, -3.25, -0.44, -0.62, 2.21, -0.82, -1.91, -0.5, -0.79, -1.92, -1.51, 1.9, 1.1101587301587303, 1.44, 1.14, -0.01, 0.41, -0.32, -0.29, -1.42, -1.01, 0.83, 0.92, -0.03, -1.14, -0.72, 0.64, 0.53, 0.76, -0.66, 2.08, 0.66, 0.52, 1.06, 1.12, 0.42, 0.82, 0.31, 0.11, 0.5, 0.37, 0.7, 1.2, 0.87, -0.05], ['417', -4.34, -1.12, -0.09, 0.08, -0.96, -1.03, -1.825884742040171, -2.03, -1.95, -3.62, -1.57, -2.28, -0.12, -1.65, -0.99, -1.56, -2.68, -3.3, -3.85, -2.41, -3.78, -3.18, -2.4, -1.98, -2.32, -2.61, -2.08, -0.72, 1.48, -0.08, 0.6, 0.02, -1.12, -1.76, -2.31, -0.85, -2.24, -1.63, -0.84, -0.42, -1.27, -2.59, -1.37, 2.21, 0.65, 1.32, 0.75, -0.4, -1.05, -1.61, -0.13, -1.53, -0.92, -0.12, 0.3, -0.41, -0.86, -1.86, -2.369047619047619, -3.51, -1.53, -0.87, -1.44, -2.56, -3.087394933859938, -3.74, -2.29, -3.66, -3.06, -2.28, -1.87, -1.65, -2.0, 0.67, 0.1, -1.04, -1.68, -2.24, -0.77, -2.006918367346939, -1.56, -0.76, -0.34, -1.96, -3.42, 3.39, -2.66, -0.57, -1.71, -2.34, -2.89, -1.44, -2.82, -2.21, -1.43, -1.01, -4.05, -2.1, -1.14, -1.78, -2.33, -0.87, -2.26, -1.65, -0.86, -0.44, -0.35, -2.12, -1.78, -1.09, -1.01, -1.23, -0.97, -0.64, -1.21, 0.27, -1.13, -0.52, 0.28, 0.7685846838830657, -0.48, -0.27692325186963274, -0.57, 0.92, -0.480437641723356, 0.13, 0.94, 1.36, -1.08, -0.5, 0.19, -1.09, -12.24, -0.08, -0.07, 2.2, -2.2, -1.08, 0.2, -1.17, 2.53, 2.09, 1.09, -2.19, -0.41, -3.29, 3.26, 3.21, -1.06, 3.27, -2.19, -1.38, 0.68, -2.9, 6.6, 2.08, 2.8, -2.55, 0.24, 1.5, 0.08, 0.7, 1.51, 1.94, -3.29, -1.24, -1.4, -0.79, 0.01, 0.44, 0.16, 0.62, 1.43, 1.86, -1.94, -2.09, -0.46, 0.8, 1.23, -1.12, -1.12, -1.88, 3.91, -1.82, -3.97, -1.65, -2.0, -1.25, 0.43, -1.01, -1.02, -0.32, -0.06, -0.54, -1.67, -2.87, -2.86, -1.18], ['418', -0.13, 0.07, -0.2, -0.11, -0.96, -0.3315803763262405, -0.51, -0.66, -0.24, -1.3029115646258504, -2.16, -1.11, -1.75, -1.62, -0.14, -1.34, -1.59, -1.75, -3.69, 0.84, -1.84, -1.84, -1.88, -1.98, -0.78, -0.29, 0.42, 1.08, 0.42, 0.55, 2.06, 0.84, 0.58, 0.42, -1.56, 3.07, 0.32, 0.33, 0.29, 0.19, -0.75, -0.8850638007838266, -0.65, -0.65, -0.52, 0.98, -0.23, -0.49, -0.65, -2.61, 1.97, -0.74, -0.73, -0.78, -0.88, -0.21, -0.54, -0.7, 0.06, 0.0, 0.13, 1.640799319727891, 0.42, 0.16, 0.0, -1.97, 2.64, -0.09, -0.08, -0.13, -0.23, -0.25, -0.13, 1.5, 0.29, 0.03, -0.13, -2.1, 2.5, -0.23, -0.22, -0.26, -0.36, 0.13, 0.18, -0.28, -1.61, -1.2, -1.45, -1.61, -3.55, 1.173744771101914, -1.7, -1.69, -1.74, -1.84, -1.29, -0.3426334687834371, -0.26, -0.42, -2.38, 2.2, -0.4473734626473065, -0.51, -0.55, -0.65, -0.11, -0.39, 2.39, -0.34, -0.28, -0.3, -0.16, -0.16, -2.13, 2.47, -0.0742217465074606, -0.25, -0.29, -0.39, 0.08, 0.053076748130367266, -1.97, 2.64, -0.09, -0.08, -0.13, -0.23, 0.61, 0.78, -0.11, 0.05, -4.02, 0.04, 0.16, 0.86, -0.84, -0.42, -0.79, -0.66, 5.07, 0.69, 0.4, -0.03, -0.31, -1.07, 1.12, 1.11, -0.35, 1.26, -0.7, 1.12, -0.56, -0.29, -0.94, 0.24, 0.46, -5.12, 2.0, 4.7, 1.91, 1.92, 1.87, 1.77, -0.95, -2.57, -2.66, -2.65, -2.7, -2.79, 0.09, 0.01, -0.04, -0.14, -0.33, 0.0, 0.08, -0.05, -0.14, -0.35, -0.32, -0.64, -0.28, 1.85, 0.22, -0.28, -0.91, 0.13, -0.1, -0.36, -0.91, -0.06, -0.6, 0.2, 0.23, -1.4, -0.81, -0.26], ['419', -1.77, -0.36, -0.2, 0.07, -1.96, -1.04, -1.61, -2.46, -2.12, -2.82, 0.51, -1.44, -1.5060867348791511, -0.16, -0.83, -2.33, -1.32, -2.53, -2.35, -0.25, -3.07, -1.96, -1.79, -1.44, -2.18, -1.5106285854111081, -3.31, -1.94, -2.07, -0.66, -1.33, -2.82, -1.82, -3.03, -2.85, -0.75, -3.56, -2.45, -2.29, -1.94, -1.86, -2.72, -1.4, -0.13, 1.3, 0.62, -0.9, 0.12, -1.11, -0.93, 1.21, -1.65, -0.52, -0.36, 0.0, -0.76, -1.36, -2.88, -2.32, -1.27, 1.44, 0.7507993197278912, -0.77, 0.26, -0.8773949338599383, -0.8, 1.4639757335335069, -1.52, -0.39, -0.23, 0.13, -2.83, -2.67, -0.68, -2.18, -1.16, -2.38, -2.2, -0.1, -2.92, -1.8, -1.64, -1.29, -2.75, -3.11, 3.07, -2.0, -1.51, -0.49, -1.71, -1.53, 0.59, -2.26, -1.13, -0.97, -0.61, -2.24, -0.4226334687834371, 1.03, -0.21, -0.03, 2.13, -0.76, 0.38, 0.55, 0.91, -0.33, -0.42, 0.89, -1.15, -1.15, -1.15, -1.52, -1.0934006093113235, -1.05, 1.08, -1.78, -0.65, -0.48, -0.13, -0.76, -0.29, 0.19, 2.34, -0.55, 0.59, 0.76, 1.12, -1.45, -1.44, -0.2839628211219596, -1.34, -6.58, -0.46, -0.65, 2.65, -2.72, -1.35, 0.27, -4.3, 5.08, 2.21, 1.13, -0.91, -1.01, -3.45, 3.39, 3.45, -1.13, 4.01, -2.28, -1.06, 0.47, -4.48, 13.09, 3.02, 4.42, -5.15, -0.47, 2.15, -0.73, 0.41, 0.58, 0.93, -3.42, -2.57, -2.83, -1.71, -1.55, -1.2, 0.26, 1.15, 1.32, 1.68, -2.19, -2.5, -0.88, 0.17, 0.52, -1.12, -1.17, -2.31, 6.74, 0.09, -6.72, -1.55, -1.48, -1.04, 0.36, -0.4, -1.04, -1.03, -0.82, -1.36, -1.39, -1.87, -2.99, -1.27], ['420', 2.73, 0.42, 0.26, 0.01, 0.3429790809910596, 0.58, 1.214115257959829, 0.95, 1.02, 0.94, -0.02, 0.13, 0.12, 0.67, 0.41, 0.4, 0.2, 0.66, 2.6, 0.09, 0.99, 0.81, -0.23, 0.1, 0.35, 0.14, 0.9926583949931125, 0.2684685082657772, 0.14, 0.69, 0.43, 0.42, 0.23, 0.68, 2.62, 0.12, 1.01, 0.83, -0.21, 0.16384172319783916, 0.92, 1.69, 0.820204081632653, -0.01, 0.54, 0.28, 0.27, 0.08, 0.53, 2.47, -0.03, 0.86, 0.68, -0.36, -0.02, 0.41, 0.49, 0.91, 1.01, 0.82, 0.55, 0.29, 0.28, 0.08, 0.54, 2.48, -0.03, 0.87, 0.69, -0.35, -0.02, 1.06, 0.27, -0.26, -0.27, -0.46, -0.01, 1.92, -0.57, 0.32, 0.14, -0.9, -0.57, 1.33, 3.13, -3.2, 0.53, -0.01, -0.21, 0.25, 2.18, -0.32, 0.57, 0.4, -0.64, -0.31, 0.21, 0.54, -0.19, 0.26, 2.19, -0.3, 0.59, 0.41, -0.63, -0.3, 0.25, 0.55, 3.01, 0.64, 0.73, 0.62, 0.8118094764861292, 0.45, 2.39, -0.11, 0.78, 0.6, -0.43, -0.04141531611693433, 0.13, 0.28, 1.93, -0.56, 0.33, 0.15, -0.89, -0.56, 1.81, 1.77, 0.03, 0.81, 0.3, 0.28, 0.34, -1.45, 1.43, 0.7888101710076211, 0.78, 2.11, -1.71, -1.35, -0.65, 1.31, 0.06, 2.02, -2.05, -2.09, 0.65, -2.36, 1.28, 0.59, -0.34, 2.15, -3.68, -1.53, -2.28, 1.7, -1.6016360544217687, -2.44, -1.3727867132867133, -1.75, -2.76, -2.44, 1.91, 0.85, 0.89, 0.72, -0.33, 0.01, -0.05, -0.18, -1.21, -0.88, 1.02, 1.18, 0.13, -1.03, -0.7, 0.63, 0.72, 1.01, -3.19, 2.25, 3.11, 0.19, 0.81, 1.2586374482009708, 0.33, 0.94, 0.73, -0.02, -0.23, 0.31, 0.84, 0.14, 1.75, 0.25], ['421', 0.48, 0.05, -0.06877828437954125, 0.2, -0.07, -1.09, -2.72, -1.58, -2.28, -1.52, 1.34, 0.85, -0.98, 0.31, 0.03, -1.67, -0.35, -1.12, -2.77, -0.47, -2.16, -0.87, -0.15, -0.48, -1.06, -0.890628585411108, -2.82, -0.48, -2.29, -1.01, -1.29, -2.97, -1.66, -2.42, -4.05, -1.78, -3.45, -2.18, -1.47, -1.8, -1.13, -5.315063800783826, -2.34, -1.81, -0.53, -0.81, -2.5, -1.18, -1.95, -3.59, -1.3, -2.98, -1.71, -0.99, -1.32, -1.2, -1.11, -0.83, -1.79, -0.54, 1.3, 1.02, -0.7, 0.64, -0.14, -1.81, 0.52, -1.19, 0.11, 0.84, 0.5, -1.4, -1.82, -0.28, -1.98, -0.65, -1.43, -3.07, -0.78, -2.46, -1.18, -0.32690451810094656, -0.79, -3.36, -3.46, 3.38, -1.54, -1.7, -0.37, -1.15, -2.8, -0.49, -2.19, -0.9, -0.18, -0.51, 0.41, 0.16, 1.35, 0.56, -1.12, 1.23, -0.49, 0.81, 1.55, 1.21, -0.41, 0.19, 1.51, -0.88, -0.74, -0.97, -1.18, -0.78, -2.43, -0.12, -1.82, -0.53, 0.2, -0.14, -0.46, -0.4, -1.67, 0.66, -1.05, 0.25, 0.98, 0.64, -1.78, -1.28, 0.17, -0.83, 1.13, -0.09, 0.27, 1.98, -1.97, -1.0, 0.55, -1.58, 2.1, 1.64, 0.89, 0.3, -0.63, -2.62, 2.65, 2.58, -0.84, 2.94, -1.7, -2.54, 1.24, -3.49, 9.12, 2.33, 3.49, -1.9828690476190476, 1.3083639455782314, 2.37, 0.8272132867132869, 1.95, 2.7, 2.35, -2.53, -1.05, -1.7, -0.41, 0.32, -0.02, 0.66, 1.31, 2.06, 1.71, -2.197204648526077, -2.48, -0.65, 0.73, 0.39, -0.83, -0.88, -1.53, 5.1, -0.12, -5.23, -0.62, -0.15, -1.37, -0.34, -0.96, -0.86, -0.69, 0.21, -1.37, -1.04, -1.1, -0.46, -1.3], ['422', -0.06, 0.0, -0.008778284379541255, -0.05, 0.01, -0.04, 0.014115257959829165, 0.0, -0.01, 0.05, -0.03, 0.05, 0.02, -0.07, 0.08, 0.05, -0.04, 0.03, 0.0, 0.05, 0.11733548208735894, 0.07, 0.24, 0.01, 0.16, -0.04, 0.12265839499311246, 0.09, 0.06, -0.04, 0.16781997129509119, 0.09, -0.01, 0.06, 0.03, 0.09, 0.11, 0.1, 0.28, 0.08384172319783915, 0.0, 0.014936199216173434, 0.0, -0.03, -0.13, 0.03, 0.0, -0.1, -0.02, -0.05, 0.0, 0.04806546808644298, 0.02, 0.19, -0.04, 0.03, 0.07, 0.08, 0.06, 0.03, -0.1, 0.06, 0.03, -0.07, 0.0, -0.02, 0.03, 0.05, 0.05, 0.22, -0.01, -0.03, 0.13, 0.16, 0.13, 0.03, 0.1, 0.07, 0.13, 0.15, 0.14, 0.32, 0.13355964172512072, 0.0, -0.42, 0.34, 0.00669823838532016, -0.03, -0.13, -0.05, -0.08, -0.03, 0.0, -0.01, 0.16, -0.07, -0.18, 0.0, -0.1, -0.03, -0.05, 0.0, 0.02, 0.02, 0.19, -0.04, 0.11, 0.0, 0.07572371188304003, 0.01, -0.06, 0.13567351865003197, 0.1718094764861292, 0.07, 0.14693256743256752, 0.1, 0.12, 0.11, 0.29, 0.10858468388306568, 0.06, 0.02, -0.03, 0.03, 0.05, 0.04, 0.22, -0.02, 0.0, 0.04, 0.07, 0.11, 0.0, 0.02, 0.0, -0.1, 0.15, 0.14881017100762112, 0.0, 0.0, 0.07, 0.0, 0.0, 0.0, 0.11, 0.12, -0.11, -0.04, 0.02, -0.26, -0.01, 0.16, -0.11, 0.23, 0.01, -0.15, -0.31, -0.04, 0.05, 0.06, 0.08, 0.07, 0.25, 0.01, 0.04, 0.0, 0.02, 0.02, 0.19, -0.04, -0.02, -0.01, 0.17, -0.07, 0.04, 0.02, -0.02, 0.17, -0.06, 0.02, -0.01, 0.0, -0.09, 0.15019962695749933, 0.06, 0.06, -0.14, -0.19, -0.23, -0.08, -0.03, 0.0, 0.0, 0.04, 0.04, 0.02, 0.06, 0.03], ['423', -1.52, 2.0214285714285714, 0.07, 0.01, 0.44, -0.01, 1.82, 0.07, -0.17, -0.95, -0.18, -2.6, -1.78, -0.37, -1.26, -1.01, -1.34, -1.13, -3.4, -2.53, -1.15, -1.57, -1.28, -1.54, -0.25, 0.48, -0.78, -2.43, -1.61, -0.19, -1.08, -0.84, -1.16, -0.95, -3.23, -2.36, -0.98, -1.4, -1.1, -1.37, 0.08, -1.42, 1.69, 0.84, 2.29, 1.38, 1.63, 1.29, 1.51, -0.8183478664192949, 0.07119047619047619, 1.48, 1.05, 1.35, 1.08, -0.14, -0.08, -0.47, -0.53, 0.84, 1.44, 0.53, 0.78, 0.45, 0.67, -1.65, -0.76, 0.64, 0.21, 0.51, 0.24, -0.25, -0.59, -0.8753571428571428, -0.65, -0.97, -0.76, -3.04, -2.17, -0.79, -1.21, -0.91, -1.18, -0.8395238095238095, 1.54, -1.55, 0.31, 0.25, -0.06821428571428571, 0.13, -2.17, -1.29, 0.11, -0.32, 0.010976190476190473, -0.29, 0.74, 0.06, -0.33, -0.12, -2.41, -1.53, -0.0773734626473065, -0.56, -0.27, -0.54, 0.2, -0.05, 2.85, 0.43, 0.35, 0.58, 0.39, 0.21, -2.09, -1.21, 0.19, -0.17969498055271244, 0.06, -0.21, 1.1, 0.18, -2.3, -1.42, -0.03, -0.45, -0.15, -0.42, 0.58, 0.61, 0.11, 0.52, 2.09, 0.82, 0.83, -0.99, 1.05, 0.5, 4.1, 0.87, -3.2, -0.84, -0.42, -0.73, 0.67, 1.27, -1.19, -1.21, 0.41, -1.5, 0.86, -0.12, 0.1447652642842468, 1.18, -5.07, -0.86, -1.18, 3.2, 2.53, 0.9, 2.33, 1.89, 2.2, 1.92, 1.24, 1.62, 1.41, 0.98, 1.290857142857143, 1.0114285714285713, 0.2, -0.42, -0.13, -0.4, 0.010135138670853056, -0.7, 0.63, 0.3, 0.03, 0.42, 0.48, 0.07, -3.14, 2.1, 3.32, 0.17, -0.06, 0.33, -0.27, 0.28, 0.25, 0.61, 0.77, 0.83, 0.6, 0.3, 0.12, 0.2], ['424', 6.1, 1.26, 0.16, -0.08, 0.94, 0.87, 1.894115257959829, 2.08, 1.28, 4.11, 2.230608843537415, 3.47, 2.39, 2.54, 2.35, 1.91, 2.71, 3.77, 4.39, 3.32, 5.0, 2.58, 2.83, 2.96, 2.47, 1.759371414588892, 1.85, 1.22, 0.16, 0.31, 0.13, -0.31, 0.48, 1.51, 2.12, 1.08, 2.72, 0.35, 0.6, 0.72, 0.78, 2.44, 0.62, -1.04, -0.9, -1.08, -1.51, -0.73, 0.29, 0.89, -0.14, 1.48, -0.86, -0.62, -0.48495238095238097, 1.44, 1.09, 2.02, 1.17, 1.68, 0.15, -0.03, -0.47, 0.31, 1.35, 1.96, 0.92, 2.55, 0.18, 0.43, 0.56, 2.84, 1.53, -0.18, -0.62, 0.16, 1.2, 1.8, 0.76, 2.4, 0.03, 0.28, 0.4, 1.68, 3.58, -3.6, 1.72, -0.44, 0.35, 1.38, 1.99, 0.95, 2.613870161584447, 0.22, 0.9225170068027209, 0.59, 0.86, 2.16, 0.79, 1.83, 2.44, 1.39, 3.04, 0.66, 0.91, 1.03, 0.41, 2.1923568812140237, 1.06572371188304, 1.23, 1.11, 1.36, 1.36, 1.03, 1.64, 0.6, 2.23, -0.13, 0.12, 0.24, 1.46, 0.33, 0.6, -0.43, 1.19, -1.0242004503433073, -0.9, -0.78, 0.93, 1.04, -0.14, 1.26, 2.12, 0.21, 0.17, -2.56, 2.51, 1.27, 1.78, 0.85, -1.38, -2.46, -1.23, 3.44, 1.22, 3.64, -3.74, -3.7, 1.24, -3.77, 2.47, 1.37, -0.6652347357157532, 3.86, -10.36, -2.75, -4.05, 1.39, -0.27, -1.02, 0.59, -1.74, -1.49, -1.37, 3.53, 0.76, 1.62, -0.72, -0.48, -0.36, -0.85, -2.31, -2.07, -1.95, 1.37, 1.49, 1.5, 0.25, 0.37, 1.24, 1.26, 2.06, -5.55, 1.2001996269574993, 2.54, 1.82, 1.1, 1.25, 0.12, 1.17, 1.12, 1.67, 1.01, 1.23, 1.12, 0.98, 1.68, 0.85], ['425', 2.41, 0.29, 0.08, 0.14, 0.59, -0.18, -0.6858847420401708, -0.44, -0.02, 0.9, 1.6, 1.5293248299319728, 1.26, 1.22, 1.02, 1.03, 1.53, 1.0, -4.42, 1.63, 0.77, 0.45, 1.32, 1.475116627420199, 0.13, 0.11, -0.6573416050068874, -0.08, -0.34, -0.37, -0.57, -0.57, -0.07, -0.47274109585559154, -5.93, 0.02, -0.82, -1.13, -0.28, -0.27, 0.51, 0.4808975626058773, -0.61, -0.26, -0.29, -0.49, -0.49, 0.01, -0.51, -5.85, 0.11, -0.74, -1.05, -0.2, -0.19, -0.35, 0.27, -0.74, 0.42, -0.35, -0.03, -0.23, -0.23, 0.27, -0.25, -5.6, 0.37, -0.48, -0.79, 0.06, 0.07, -0.55, -0.32, -0.2, -0.2, 0.3, -0.22, -5.5669047619047625, 0.7191309523809524, -0.45, -0.76, 0.09, 0.1, -0.44, -0.67, 0.65, -0.12, 0.0, 0.5, -0.02, -5.38, 0.7937447711019141, -0.25, -0.57, 0.29, 0.3, 1.09, -0.12, 0.5, -0.02, -5.39, 0.6, -0.25, -0.57, 0.29, 0.3, -0.23, 0.029368203225346196, -1.46427628811696, -0.11840181931709852, -0.16482093036566006, -0.16, -0.62, -0.52, -5.86, 0.1, -0.75, -1.06, -0.21, -0.2, 0.29, -0.1, -5.37, 0.62, -0.23, -0.55, 0.31, 0.32, -0.11, -0.55, 0.31603717887804045, -0.39, 3.45, 0.1, 0.26, 0.48, -0.46, -0.24, 0.02, -0.95, 1.36, 0.33, 0.15, 1.17, 0.07, -0.27940313852813836, 0.5, 0.5, -0.11670919513614705, 0.65, -0.35, -1.04, 0.49, -1.86, 2.4, 1.16, 1.77, -1.41, 5.57, 6.33, 5.43, 5.09, 6.0, 6.01, -0.46, -0.71, -0.84, -1.16, -0.31, -0.3, 0.13, -0.32, 0.54, 0.55, -0.06, 0.0, 0.45, 0.86, 0.87, -0.12, -0.2, -0.52, 2.22, -1.78, -2.14, -0.28, -0.07, -0.41, 0.01, -0.46, 0.0, 0.34, 0.32, -0.59, -0.42, 0.18, 0.23, -0.07], ['426', -52.74, 0.11, 0.04, 0.12, 0.18, -0.4, -0.5958847420401708, -1.2, -0.49, -1.9, -1.13, -1.9, -1.35, -0.57, -0.52, -1.16, -1.36, -1.21, -2.58, -1.57, -2.03, -0.6240578231292517, 0.67, -1.72, -0.08140633899247347, -1.58, -0.77, -0.77, -0.23, 0.57, 0.62, -0.03, -0.23, -0.08, -1.46, -0.44, -0.91, 0.4, 1.82, -0.59, -0.8525315746467891, -2.5950638007838265, 0.0, 0.55, 1.35, 1.4, 0.75, 0.55, 0.7, -0.7, 0.34, -0.14, 1.18, 2.6557142857142857, 0.18, -0.09993715369432345, -1.19, -1.18, -0.06, -0.55, 0.8, 0.85, 0.2, 0.0, 0.15, -1.24, -0.22, -0.69, 0.63, 2.05, -0.37, -1.1, -1.34, 0.05, -0.5885714285714285, -0.8, -0.65, -2.02, -1.01, -1.47, -0.17, 1.25, -1.16, -0.95, -6.34, 6.55, -1.38, -0.64, -0.8282142857142857, -0.69, -2.07, -1.05, -1.52, -0.22, 1.2, -1.2, -1.97, -0.6726334687834371, -0.2, -0.05, -1.44, -0.41, -0.88, 0.43, 1.85, -0.56, -0.66, -0.73, -1.39427628811696, -0.5, -0.85, -0.13, -0.54, 0.15, -1.24, -0.21, -0.68, 0.63, 2.6885714285714286, -0.36, -1.14, -0.69, -1.38, -0.36, -0.83, 0.48, 1.91, -0.51, -3.1, -2.52, 0.11, -0.28, -3.59, -0.61, -0.22, -0.8, 0.8, 0.41, -0.95, -0.9, 0.64, 0.95, 0.49, -2.74, -0.16, -1.45, 1.45, 1.5, -0.47, -1.06, -0.95, -2.39, 1.2, -1.69, 2.83, 1.06, 1.53, -0.77, 0.7, 1.04, 0.56, 1.89, 3.34, 0.89, -1.45, -0.33, -0.47, 0.84, 2.27, -0.15, 0.14, 1.32, 2.76, 0.32, -0.42, -0.76, -1.17, 1.42, -0.99, -0.56, -0.43, -1.25, 1.35, -0.95, -1.21, -1.08, -0.59, -2.55, -2.37, -1.22, 0.55, -0.13, -0.01, -0.09, -0.18, -1.04, -0.5, -0.93], ['427', 0.57, 0.0, 0.4712217156204588, 0.07, 0.19, -0.21158037632624052, 0.22411525795982914, 0.47, 0.47, -1.01, -1.73, -1.59, -1.23, -2.09, -1.21, -2.32, -1.34, -1.13, 0.52, -0.99, -0.67, -1.5, -0.84, -0.91, 0.33, 1.549371414588892, 0.73, 0.14, 0.51, -0.37, 0.53, -0.6, 0.39, 0.62, 2.29, 0.75, 1.08, 0.23, 0.9, 0.84, 0.45, -0.14506380078382658, 0.59, 0.36, -0.3421246055531769, 0.38, -0.74, 0.25, 0.47, 2.14, 0.6, 0.94, 0.09, 0.76, 0.69, 0.83, -0.73, -0.68, 0.27, 0.22, -0.7668952774644393, 0.02, -1.1, -0.11, 0.11, 1.77, 0.24, 0.57, -0.27, 0.39, 0.33, 0.29, 1.11, 0.9, -0.23, 0.77, 0.99, 2.67, 1.12, 1.46, 0.61, 1.28, 1.21, 0.5, -0.64, 0.55, 0.2, -1.12, -0.13, 0.09, 1.75, 0.22, 0.55, -0.29, 0.37, 0.3, 0.37, 1.34, 1.0, 1.22, 2.9, 1.35, 1.69, 0.84, 1.51, 1.44, 0.12, 1.28, -0.17, -0.09, -0.11, 0.07567351865003197, 0.34, 0.22, 1.88, 0.35, 0.68, -0.16, 0.51, 0.44, 0.37, 0.12, 1.66, 0.13, 0.46, -0.38, 0.29, 0.22, -0.33, -0.32, 0.38, 0.11, 1.31, 0.05354725829725827, 0.07, -0.16, 0.2, 0.09, -0.08, 1.3461635321120495, -0.01, 0.06, 0.08, 0.37, -0.27, -0.19, 0.21, 0.29, -0.1, -0.35, -0.2, -0.5, 0.26, 0.99, 1.94, -0.66, -1.07, -0.022869047619047622, -1.52, -1.5, -1.18, -2.01, -1.35, -1.42, -0.28, -0.02, 0.33, -0.51, 0.15, 0.09, -0.35, -0.84, -0.18, -0.24, 0.49, 0.36, 0.5872746849074344, 0.67, 0.6722487553150163, -0.05, -0.06, 0.37, 1.06, -0.35, -1.05, 0.26726381052443327, 0.36, -0.17, -0.07, -0.27, 0.04, -0.55, -0.4, 0.06, -0.1, 1.13, 0.6, -0.06], ['428', 3.12, 0.36, -0.04, -0.21, 0.64, 0.55, 1.6, 0.75, 1.24, 0.47, -0.96, -1.05, 0.1, -0.52, 1.14, -0.31, -0.41, 0.27, 0.68, -0.7763367346938775, 0.87, 0.13, -0.23, -0.34, 1.41, 1.36, 1.45, -0.08, 1.08, 0.45, 2.13, 0.66, 0.56, 1.24, 1.66, 0.17, 1.85, 1.1, 0.74, 0.63, -0.06, 2.58, 1.53, 1.16, 0.54, 2.21, 0.74, 0.64, 1.33, 1.75, 0.25, 1.968065468086443, 1.19, 0.82, 0.71, 0.27, 0.45, 0.71, 0.41, 0.37, -0.62, 1.04, -0.42, -0.51, 0.16, 0.58, -0.9, 0.76, 0.02, -0.33, -0.44, 0.94, 0.99, 1.67, 0.2, 0.1, 0.79, 1.2, -0.29, 1.39, 0.65, 0.29, 0.18, 2.05, 1.65, -1.63, -0.6233017616146799, -1.44, -1.54, -0.86, -0.45, -1.92, -0.27, -1.0, -1.36, -1.47, 3.15, 0.78, -0.1, 0.58, 1.0, -0.49, 1.18, 0.44, 0.08, -0.03, 0.21, 0.77, 2.890104651162791, 0.65, 0.70517906963434, 0.685673518650032, 0.88, 0.68, 1.1, -0.39, 1.29, 0.54, 0.18, 0.07, 0.29, 0.2, 0.41, -1.06, 0.6, -0.14, -0.5, -0.61, 0.58, 0.58, -0.4, 0.84, 9.54, 0.12, -0.09, -2.16, 2.18, 1.09, -0.52, 0.58, -2.54, -1.36, -0.66, 1.59, -0.04, 2.0905968614718615, -1.86, -1.97, 0.683290804863853, -3.21, 1.3, 2.02, -1.01, 2.62, -1.11, -1.79, -2.62, 2.54, -0.21, -1.47, 0.19, -0.55, -0.91, -1.02, 1.96, 1.28, 1.68, 0.93, 0.57, 0.46, -0.4, -0.74, -1.09, -1.2, 1.16, 1.16, 0.34, -0.36, -0.47, 0.62, 0.64, 0.8, -0.51, 2.82, 0.31, 1.447263810524433, 0.92, 0.7, -0.11, 0.9, 1.19, -0.03, -0.11, -0.3, 0.81, 2.29, 1.47, 0.6830167737073972], ['429', 1.04, 0.31, -0.48877828437954124, -0.1, 0.06, 0.64, 0.014115257959829165, 0.7, 0.64, 1.39, 0.58, 1.62, 0.99, 1.07, 1.9, 1.61, 0.32, 0.81, 1.61, 2.23, 1.53, -0.22, 0.75, 0.81, 0.27, -0.12, 0.81, 1.1484685082657773, 0.41, 0.49, 1.31, 1.02, -0.26, 0.22, 1.03, 1.64, 0.95, -0.8, 0.17, 0.23, -0.5025315746467891, 0.9649361992161734, -0.22, -0.62, -0.54, 0.28, -0.01, -1.28, -0.8, 0.0, 0.6, -0.08, -1.81, -0.85, -0.79, 1.3, 0.0, -0.68, 0.67, 0.4, 0.08, 0.9, 0.62, -0.66, -0.18, 0.62, 1.23, 0.54, -1.2, -0.24, -0.18, 0.37, 0.32, 0.82, 0.53, -0.74, -0.26, 0.54, 1.15, 0.46, -1.28, -0.32, -0.26, 0.97, 1.88, -1.88, -0.5, -0.28, -1.55, -1.07, -0.28, 0.33, -0.36, -2.08, -1.12, -1.07, -0.97, -0.21, -1.27, -0.79, 0.0, 0.61, -0.08, -1.8, -0.85, -0.79, 0.54, -0.19, 2.4957237118830404, 0.55, 0.67, 0.46, 1.07, 0.49, 1.29, 1.9, 1.21, -0.54, 0.43, 0.49, 1.49, 0.58, 0.8, 1.41, 0.72, -1.02, -0.05, 0.0, 1.23, 1.88, -0.04, 1.03, -3.26, 0.22, -0.8, 0.08, -0.1, -0.04, 0.62, 3.57, 1.54, -1.1, -0.57, 0.57, 0.6, 1.76, -1.67, -1.55, 0.54, 0.09, 1.09, 1.31, -0.73, 3.23, -7.53, -2.21, -3.24, -1.45, -0.22, 0.9371787775716347, -0.08, -1.8, -0.85, -0.79, 1.66, -0.82, -0.68, -2.4, -1.45, -1.39, -0.14, -1.7271150714365, -0.77, -0.71, 0.59, 0.87, 1.62, 0.97, 1.03, 0.57, 0.51, 0.74, -3.73, 2.02, 4.16, 0.65, -0.27, 0.64, 0.13278685149693165, 0.86, 0.0, 1.05, 1.23, 1.11, 0.58, -0.09, -0.35, 1.18], ['430', 1.24, -0.31, -0.1, -0.13, 0.62, 0.02, 0.45, 0.55, 0.0, -0.87, -0.2, -0.9, -0.75, -0.42, -1.01, -0.75, -1.27, -0.92, 2.02, -2.09, -1.05, -0.9, -1.35, -0.66, 0.57, 0.29, -0.67, -0.69, -0.55, -0.22, -0.81, -0.55, -1.07, -0.72, 2.22, -1.89, -0.85, -0.7, -1.15, -0.45, 0.16, 0.18493619921617344, 0.02, 0.15, 0.48, -0.11, 0.15, -0.38, -0.03, 2.94, -1.21, -0.16, -0.01, -0.46, 0.24, 0.2, 0.31, 1.77, -0.23, -0.12, 0.33, -0.26, 0.0, -0.53, -0.17, 2.79, -1.35, -0.3, -0.16, -0.61, 0.09, 0.49, -0.45, -0.16977210884353744, -0.33, -0.85, -0.5, 2.45, -1.68, -0.63, -0.48, -0.93, -0.23, -0.03, 1.19, -1.15, 0.14, 0.26, -0.27, 0.09, 3.06, -1.09, -0.04, 0.11, -0.35, 0.36, -0.91, -0.12, -0.53, -0.17, 2.79, -1.35, -0.24737346264730647, -0.16, -0.61, 0.09, -0.16, -0.06, -1.12, 0.38, 0.31, 0.44, 0.4, 0.35, 3.33, -0.83, 0.39577825349253937, 0.37, -0.004012136584447365, 0.62, 0.05, 0.05, 2.97, -1.18, -0.13, 0.02, -0.43, 0.27, 0.37, 0.48, -0.34, 0.4, -2.56, 0.21806954949812107, 0.0, -1.4, 1.46, 0.73, 0.31406627346681526, 0.89, -2.49, -0.78, -0.37, 0.62, 0.07, 1.1, -1.1, -1.11, 0.37, -2.23, 0.76, 0.68, -0.35, 1.14, -0.68, -0.77, -1.17, 2.34, -2.83, -3.7028212224283656, -3.01, -2.86, -3.3, -2.62, 1.1, 1.25, 1.06, 1.21, 0.76, 1.47, 0.18, 0.15, -0.3, 0.4, 0.09, 0.11, 0.03, -0.45, 0.25, 0.35, 0.41, 0.58, -0.22, -0.66, 0.36, 0.14, 0.46, 0.48, 0.7, 0.5, 0.74, 0.22, -0.33, 0.45, -0.22, 0.81, 0.83, -0.24], ['431', 0.09, 0.53, 0.13122171562045873, 0.0, 0.36, 0.34, 1.0841152579598292, 0.74, 0.7, 1.28, 0.52, 0.9, 1.03, 0.15, 1.36, 0.97, 0.82, 1.2377619047619046, 0.31, 0.51, 1.23, 0.97, 0.47, 0.6, 1.6, 0.64, 0.76, 0.38, 0.51, -0.36, 0.84, 0.45, 0.3, 0.68, -0.21, -0.01, 0.71, 0.45, -0.04, 0.08, -0.65, 1.56, 0.37, 0.12, -0.74, 0.46, 0.07, -0.08, 0.3, -0.59, -0.39, 0.33, 0.07, -0.43, -0.3, 0.83, 0.72, 0.63, 0.53, 0.25, -0.87, 0.34, -0.05, -0.2, 0.18, -0.71, -0.51, 0.21, -0.05, -0.55, -0.42, 0.19, 1.13, 1.2246428571428571, 0.82, 0.67, 1.05, 0.16, 0.36, 1.08, 0.82, 0.32, 0.45, 1.1, 2.33, -2.33, -0.08, -0.39, -0.54, -0.16, -1.04, -0.84, -0.13, -0.39, -0.88, -0.76, 0.4226190476190476, 0.3, -0.15, 0.23, -0.66, -0.46, 0.26, 0.0, -0.5, -0.37, -0.07, 0.3024455782312925, -0.73427628811696, 0.46, 0.7, 0.23, 0.46, 0.38, -0.5, -0.31, 0.41, 0.15, -0.34, -0.16141531611693433, 0.34, 0.08, -0.88, -0.69, 0.03, -0.23, -0.72, -0.6, 1.06, 1.2, -0.15, 0.33, 1.26, 0.2, 0.14, 0.39, -0.46, -0.2, 1.14, 2.36, -1.48, -0.93, -0.49, 0.05, 0.79, 1.38, -1.4, -1.41, 0.46, 0.48, 0.89, 0.62, -0.29, 1.4, -4.61, -0.9, -1.45, 1.57, 0.97, 0.2, 0.92, 0.66, 0.16, 0.29, 1.29, 0.77, 0.72, 0.46, -0.04, 0.12571428571428572, 0.05, -0.26, -0.75, -0.63, 0.66, 0.77, 0.31, -0.49, -0.37, 0.46, 0.47, 0.66, -3.21, -0.09, 3.35, 0.03, 1.05, 0.8, 0.12, 0.43, -0.54, 0.83, 1.2, 0.76, 0.68, 0.26, 0.57, 0.63], ['432', 2.96, -0.03, 0.05122171562045875, 0.19, -0.69, -0.08, -0.12588474204017086, -0.26, -0.55, -0.66, 0.41, -0.66, -0.18, -0.53, 0.04, -1.21, -0.09, -0.63, 0.4, 0.21, -0.86, 0.35, 0.02, -0.07, -0.45, -0.41, -1.0373416050068875, -1.07, -0.59, -0.94, -0.37, -1.61, -0.5, -1.04, -0.01, -0.2, -1.27, -0.06, -0.39, -0.48, 0.17548536582465155, -3.2, 0.0, 0.48, 0.12, 0.7, -0.55, 0.57, 0.02, 1.06, 0.87, -0.18193453191355702, 1.02, 0.69, 0.59, -0.27, 0.11, 0.07, -0.22, -0.47, -0.35, 0.23, -1.03, 0.1, -0.45, 0.59, 0.4, -0.5165788457574171, 0.54, 0.21, 0.12, -0.12, -0.12, 0.58, -0.68, 0.45, -0.1, 0.94, 0.75, -0.33, 0.89, 0.56, 0.47, -1.5, -1.75, 1.78, -0.7, -1.25, -0.13, -0.67, 0.36, 0.17, -0.9, 0.31, -0.02, -0.11, -0.15, 0.637366531216563, 1.13, 0.58, 1.63, 1.44, 0.4126265373526935, 1.58, 1.25, 1.15, 0.05, 0.58, -1.43427628811696, -0.3, -0.43, -0.2, -0.57, -0.55, 0.49, 0.3, -0.78, 0.44, 0.11, 0.02, -0.95, -0.02, 1.04, 0.85, -0.23, 0.99, 0.66, 0.57, -0.33, 0.2, 0.2, -0.706813216376432, -0.39, 0.08, 0.24, 0.19, -0.06827987418743707, -0.05118982899237888, -0.32, -0.46, 1.74, 0.53, 0.24, 1.49, 0.11, -0.68, 0.85, 0.81, -0.29, 0.23, -0.57, -0.8, 0.38, -1.8, -0.97, 1.16, 1.86, -1.66, -1.05, -0.19, -1.26, -0.05, -0.37, -0.47, -0.85, -0.7356457669314812, -1.07, 0.14, -0.19, -0.28, 0.21, 1.22, 0.9, 0.8, -0.55, -0.81, -1.0, -0.32, -0.42, -0.3, -0.34, -0.23742395037612163, -0.83, -1.54, 0.7, -0.87, -1.41, -0.68, -0.09, -0.29, -0.07, 0.54, -0.41, 0.43, -0.59, -1.65, -2.86, -1.2], ['433', -2.32, -1.34, 0.0, -0.24, 0.37, -0.44, 0.7141152579598291, 0.0, 0.28, 1.3470884353741497, 1.22, 0.691934498041641, 0.58, 0.66, 1.86, 1.43, 1.74, 0.74, -2.89, 0.26, 1.21, 1.95, 2.15, 1.24, 0.44, -1.17, -0.32, -0.72, -0.6091666666666666, -0.55, 0.63, 0.2, 0.51, -0.48, -4.06, -0.95, -0.01, 0.72, 0.92, 0.02, -0.64, 2.17, 0.4, 0.09, 0.17, 1.36, 0.93, 1.24, 0.24, -3.36, -0.22880952380952382, 0.71, 1.45, 1.65, 0.74, -0.44, 0.22, -1.16, -0.13, 0.32, 0.08, 1.3848467679404526, 0.84, 1.15, 0.16, -3.45, -0.32, 0.62, 1.36, 1.56, 0.65, -0.49, 0.24, 1.19, 0.76, 1.07, 0.08, -3.52, -0.4, 0.54, 1.28, 1.48, 0.57, 0.83, -3.23, 3.29, -0.95, -0.43, -0.12, -1.1, -4.66, -1.57, -0.64, 0.09, 0.28, -0.61, -0.47, -0.52, 0.31, -0.68, -4.25, -1.15, -0.22, 0.52, 0.8511089783232642, -0.19, 0.12097959183673469, -0.57, -4.09, -0.53, -0.69, -0.59, -0.83, -0.98, -4.55, -1.45, -0.52, 0.21, 0.47598786341555266, -0.49, -1.02, 0.16, -3.6, -0.47, 0.47, 1.21, 1.4, 0.5, -1.8610416300368755, -1.7, -0.71, -1.26, -1.58, -0.15, -0.07, 0.19, -0.23, -0.17, -0.58, 1.08, -1.21, 0.95, 0.54, -1.16, -0.11, -1.94, 1.96, 1.59, -0.52, 0.26, -1.03, 1.5, -0.84, -2.48, -0.19, 1.57, 2.56, 1.29, 3.9, 3.24, 4.22, 4.98, 5.18, 4.25, -1.6, 0.64, 0.94, 1.69, 2.2994625850340134, 0.9814285714285714, -0.3, 0.74, 0.93, 0.03, 0.26, 0.31, -1.03, 0.19, -0.6277512446849837, -0.61, -0.7, -0.09, -0.93, -2.92, 0.96, -0.85, -0.85, -1.22, -0.89, -1.48, -0.11, -0.12, 0.16, -0.11, -0.34, -1.64, -1.85, -0.88], ['434', -2.95, 0.59, 0.011221715620458745, 0.0, -0.61, 1.03, -0.07, 0.72, 0.77, 1.26, 0.27, 1.56, 0.55, 1.14, 0.26, 2.4, -0.03, 1.2, 0.99, 1.1, 1.44, 0.57, 0.04, -0.18, 0.68, 0.72, 0.99, 1.28, 0.29, 1.01318993704708, -0.01, 2.13, -0.3, 0.93, 0.72, 0.83, 1.17, 0.3, -0.22, -0.45, 1.94, 1.3, -0.3, -0.99, -0.4, -1.28, 0.83, -1.56, -0.35, -0.56, -0.44, -0.12, -0.97, -1.49, -1.71, 1.09, 1.1, 0.67, 1.03, 0.7, 0.59, -0.3, 1.84, -0.58, 0.64, 0.43, 0.55, 0.88, 0.01, -0.51, -0.73, 1.08, 0.11, -0.88, 1.24, -1.16, 0.05, -0.15, -0.032285714285714286, 0.29, -0.57, -1.09, -1.31, 1.4, 3.45, -3.25, 1.0366982383853203, 2.14, -0.29, 0.94, 0.73, 0.85, 1.18, 0.31, -0.21, -0.44, -1.93, -1.12, -2.38, -1.18, -1.38, -1.27, -0.94, -1.79, -2.3, -2.53, 0.24, -1.13, 1.85, 1.07, 1.15, 1.08, 1.29, 1.23, 1.02, 1.14, 1.47, 0.6, 0.08, -0.15, 0.78, 0.06, -0.21, -0.09, 0.24, -0.62, -1.14, -1.37, 1.02, 1.169561224489796, 0.07, 1.43, -5.57, 0.08, 0.02, -2.14, 2.14, 1.1088101710076212, 0.75, 0.18, -0.27, -2.12, -1.04, -1.48, 0.8, 3.19, -3.23, -3.19, 1.06, -3.24, 2.12, -0.21, 0.12, 3.71, -9.67, -2.43, -3.71, 0.31, 0.26, 0.11, 0.44, -0.42, -0.94, -1.16, 3.25, 0.15, 0.33, -0.53, -1.05, -1.27, -0.18, -0.86, -1.37, -1.6, 0.85, 1.05, 0.68, -0.52, -0.6777512446849837, 1.07, 1.1, 0.62, -5.17, 1.95, 5.25, 1.69, 1.31, 1.21, -0.23, 1.66, 0.71, 0.5, 0.87, 1.06, 1.44, 0.98, 1.97, 1.57], ['435', -1.93, -0.55, 0.25122171562045875, -0.04, -0.55, -0.16, -0.69, -0.91, -0.78, -1.34, -0.88, -0.92, -0.82, -0.41, -0.05, -0.19143990929705207, -1.23, -1.14, -2.46, -0.62, -1.67, -1.6, -0.72, -1.23, -0.31, -0.03, -0.47, -0.04, 0.06, 0.47, 0.83, 0.6850357142857143, -0.36, -0.27, -1.59, 0.26, -0.8, -0.73, 0.16, -0.35, -1.16, -2.11, -0.43, 0.1911974674961171, 0.6878753944468231, 0.88, 0.42, -0.31, -0.22, -1.55, 0.31, -0.76, -0.68, 0.21, -0.31, -0.28, -0.59, -0.47, -0.79, -0.53, 0.41, 0.77, 0.31, -0.42, -0.33, -1.66, 0.20023809523809524, -0.86, -0.79, 0.10273474541331684, -0.41, -0.83, -0.94, 0.36, -0.1, -0.82, -0.74, -2.06, -0.21, -1.27, -1.19, -0.31, -0.82, -1.43, -1.51, 1.4793333333333334, -1.29, -0.45, -1.18, -1.09, -2.41, -0.56, -1.62, -1.55, -0.66, -1.1159922724755493, 2.84, -0.84, -0.73, -0.64, -1.96, -0.11, -1.17, -1.1, -0.21, -0.72, -0.21, -0.96, 1.09, -0.15, -0.24, -0.04, -0.11, 0.09, -1.24, 0.62, -0.45, -0.37, 0.52, 0.01, 0.22, -0.2, -1.33, 0.53, -0.53, -0.33420045034330736, 0.43, -0.08, -0.96, -1.11, -0.23, -0.11, 8.07, -0.14, -0.21, 0.0, 0.01, -0.02, 0.43, -1.57, 1.53, 0.37, 0.6182806122448982, -0.89, 0.04, -0.49, 0.49, 0.51, -0.15, 0.0, -0.29, 0.17, -0.14, -0.43, 2.992107142857143, 0.28, 0.45, -1.44, 1.14, 1.89, 0.81, 0.88, 1.78, 1.26, -0.51, -0.73, -1.06, -0.99, -0.1, -0.61, 0.33, 0.07, 0.97, 0.45, -0.85, -1.04, 0.26, 0.89, 0.38, -0.13, -0.12, -1.02, 1.11, 0.61, -1.14, -0.04, -0.11, -0.63, -0.51, -0.4, 0.35, -0.06, 0.39, -0.46, -0.12, 1.41, 0.32, 0.65], ['436', -0.64, -0.29, 0.03, 0.03, 0.48, 0.35, 0.0, 0.4, 0.79, 1.49, 0.5, 1.25, 1.06, 2.17, 0.48, 1.2, 0.88, 1.43, -1.33, 0.98, 1.9, 0.87, 1.19, 1.44, -0.33, 0.85, 1.0226583949931125, 0.75, 0.56, 1.66, -0.01, 0.7, 0.38, 1.0472589041444085, -1.82, 0.48, 1.4, 0.37, 0.69, 0.9738417231978392, 0.05, 1.5549361992161734, 0.24, -0.19, 0.9, -0.76, 0.04052947845804987, -0.37, 0.18, -2.55, -0.27, 0.64, -0.37, -0.06, 0.18, -0.27, 0.37, -0.04, 1.88, 0.43, 1.09, -0.57, 0.14, -0.18, 0.37, -2.37, -0.08, 0.84, -0.18, 0.13, 0.37, -0.02, -0.66, -1.65, -0.94, -1.26, -0.72, -3.42, -1.16, -0.26, -1.27, -0.8169045181009466, -0.71, 1.09, 1.04, -1.13, 1.0, 0.72, 0.39, 0.94, -1.81, 0.49, 1.41, 0.39, 0.7, 0.95, 1.57, 0.29, -0.32, 0.23, -2.51, -0.23, 0.69, -0.3036053391053391, -0.01, 0.23, 0.06, 0.32, 1.4, 0.31, 0.37, 0.28, 0.61, 0.55, -2.19, 0.1, 1.02, 0.0, 0.31, 0.55, 0.56, 0.06, -2.476314419707277, -0.45, 0.46, -0.55, -0.24, 0.0, 0.19, 0.53, 0.08, 0.49, 4.59, 0.18, 0.2, -0.41, 0.4, 0.22, 0.45, 0.56, -1.12, -0.62, -0.29, -0.32, 0.17, 0.9, -0.99, -0.95, 0.32, -0.59, 0.63, -0.09, 0.06, 1.8, -0.75, -1.29, -1.89, 1.07, 2.86, 2.34, 3.28, 2.23, 2.56, 2.8, 0.93, 0.51, 0.92, -0.1, 0.21, 0.46, -0.4, -1.01, -0.7, -0.46, 0.93, 1.22, 0.62, 0.31, 0.56, 0.4220800343140569, 0.35, 0.44, -0.68, 0.88, 0.66, 0.43, 1.04, 0.3, 0.24, 0.21, 0.51, 0.21, 0.12, -0.16, 0.06, 0.27, 2.23, 0.55], ['437', 1.18, -0.18, 0.08, 0.12, -0.56, -0.17, -0.14, -0.9, -0.83, -1.03, 0.03, -0.84, -0.4, -0.17, 0.71, -1.88, -0.68, -0.96, -2.64, -1.09, -1.6, -0.52, -0.16, -0.39, -1.08, -0.63, -1.0273416050068875, -0.8694545454545455, -0.43, -0.2, 0.68, -1.9, -0.71, -0.98, -2.67, -1.12, -1.63, -0.55, -0.19, -0.41, -1.38, -1.45, -0.19, 0.44, 0.67, 1.56, -1.05, 0.16, -0.12, -1.82, -0.25, -0.77, 0.32, 0.68, 0.46, -0.56, -0.8, -0.97, -0.38, -0.63, 0.23, 1.12, -1.48, -0.28, -0.56, -2.25, -0.69, -1.21, -0.12, 0.24, 0.01, -0.54, -0.86, 0.88, -1.71, -0.51, -0.79, -2.47, -0.6008690476190477, -1.43, -0.35, 0.01, -0.22, -1.17, -2.2, 2.22, -1.73, -2.57, -1.39, -1.66, -3.33, -1.79, -2.3, -1.23, -0.87, -1.09, 0.34, 0.86, 1.22, 0.94, -0.78, 0.8, 0.28, 1.38, 1.8911089783232642, 1.52, -0.03, 0.84, 0.25, -0.41, -0.45, -0.31, -0.35, -0.28, -1.97, -0.41, -0.92, 0.16, 0.52, 0.3, -0.38, -0.07, -1.7, -0.13, -0.65, 0.44, 0.8, 0.58, -0.85, -0.88, 0.23, -0.18, 1.3, -0.02, 0.03, 0.27, -0.31, -0.16, 0.13, -2.6, -0.15, 0.83, 0.36, 0.58, -0.21692021013122098, -1.22, 1.12, 1.18, -0.42, 0.38, -0.81, -1.11, 0.54, -1.03, 5.06, 0.76, 1.08, 0.05, 1.65, 1.59, 1.07, 2.18, 2.546751700680272, 2.31, -1.24, 0.06, -0.52, 0.57, 0.94, 0.71, 0.58, 1.1, 1.46, 1.23, -0.78, -0.99, -0.4227253150925656, 0.36, 0.14, -0.4, -0.4, -0.8174239503761216, 2.83, 0.3403332627840632, -2.84, -0.72, -0.53, -0.791362551799029, -0.22, -0.34, 0.07, -0.23, -0.31, -0.4, -0.65, 0.02, 0.03, -0.32], ['438', -3.11, 1.0, -0.12, 0.24, 0.25, -0.06158037632624053, 1.87, 0.32, 0.53, 0.99, 0.79, 0.0, 1.33, -0.65, 0.92, 1.32, 1.35, 1.07, 2.97, -0.9, 1.06, 0.76, 1.05, 1.15, -0.04, 0.32, 0.2, -0.79, 0.54, -1.28681006295292, 0.13, 0.53, 0.56, 0.28, 2.16, -1.68, 0.27, -0.03, 0.26, 0.36, 0.0, 0.99, 1.0, 1.34, -0.65, 0.93, 1.33, 1.36, 1.07, 2.97, -0.9, 1.07, 0.77, 1.06, 1.15, 0.07, -0.22, -0.67, 0.33, -0.34, -1.96, -0.41, -0.01, 0.02, -0.26, 1.61, -2.21, -0.27, -0.56, -0.28, -0.18, 0.48, 1.66, 1.59, 1.99, 2.02, 1.73, 3.64, 0.0691309523809524, 1.73, 1.42, 1.72, 1.81, 0.68, -0.07, 0.0, 0.0708709226619941, 0.4, 0.43, 0.14, 2.02, -1.81, 0.14, -0.16, 0.13, 0.27400772752445063, -0.76, -0.33, 0.03, -0.25, 1.62, -2.2, -0.26, -0.55, -0.27, -0.17, 0.0, -0.34, -0.37, -0.89, -0.92, -0.82, -0.36, -0.28, 1.59, -2.23, -0.29, -0.58, -0.3, -0.2, -1.14, -0.01692325186963274, 1.88, -1.95, 0.0, -0.1742004503433073, -0.01, 0.08, 0.04, 0.42, 0.4060371788780404, 0.2, -2.32, 0.15, -0.14, 0.31, -0.39, -0.18, -2.08, -0.33, -3.65, 0.54, 0.25, -1.53, -0.28, -0.75, 0.74, 0.77, -0.24, 0.46, -0.48, -0.96, 0.48, 1.48, 5.66, -1.09, -1.46, 3.73, -1.92, -3.76, -1.85, -2.14, -1.853248299319728, -1.76, -0.74, 1.91, 1.98, 1.68, 1.97, 2.07, -0.07, -0.3, -0.01, 0.09, 0.58, 0.45845354645354663, 0.23, 0.29, 0.38, -0.28, -0.10560369872470916, 0.33, 3.39, 0.3, -3.4, -0.1027361894755667, -0.08, -0.06, 0.1, -0.06, -0.07, -0.67, -0.46, -0.63, -0.074042472976186, -0.4, -0.14, 0.36], ['439', 4.62, 0.13, 0.13, -0.2, 0.03, 0.43, 1.0841152579598292, -0.35, 1.05, -0.4, -1.5196815287886714, -2.03, -0.48, -0.37, -0.38, -1.78, -1.7028571428571428, -0.93, -2.54, -2.08, -0.01, -0.37, -1.16, -1.3378253968253968, 0.08, 0.96, 1.35, -0.31, 1.2714285714285714, 1.38, 1.38, -0.05, -0.01, 0.81, -0.82, -0.36, 1.75, 1.39, 0.58, 0.44384172319783916, 0.43, 2.03, 1.66, 1.59, 1.7, 1.69, 0.2764030612244898, 0.3, 1.13, -0.51, -0.05, 2.06, 1.7, 0.89, 0.71, -0.87, -0.49, -1.6, 0.19, 0.07, 0.11, 0.1, -1.31, -0.5985714285714286, -0.45, -1.7803066893424033, -1.61, 0.47, 0.1259625850340136, -0.69, -0.87, -0.15, -0.03, -0.009285714285714286, -0.9733418367346938, -1.37, -0.56, -2.1669047619047617, -1.72, 0.36, 0.0, -0.8, -0.97, 1.19, 1.85, -1.85, -0.03, -1.41, -1.37, -0.56, -2.17, -1.71, 0.36, 0.01, -0.79, -0.97, 1.1812233560090704, 1.4, 0.04, 0.86, -0.77, -0.31, 1.79, 1.44, 0.63, 0.45, 0.35, 1.3, 0.43, 0.88, 0.94, 1.05, 1.36, 0.82, -0.81, -0.35, 1.75, 1.39, 0.59, 0.41, -0.11, 0.53, -1.62, -1.16, 0.92, 0.57, -0.031428571428571445, -0.41, 1.47, 1.62, -0.29, 1.24, 2.02, 0.04, 0.15, -2.31, 2.33, 1.17, 0.53, -0.67, -3.35, -1.75, -0.89, 2.45, 0.43, 2.9, -2.74, -2.72, 0.88, -3.47, 1.79, 2.83, -1.38, 4.1, -0.16, -2.79, -4.08, 3.39, 2.19, 0.47, 2.59, 2.23, 1.41, 1.23, 2.61, 1.71, 2.11, 1.75, 0.94, 0.76, -0.36773809523809525, -0.35, -1.15, -0.6785714285714286, 1.07, 0.61, -0.04, -0.8, -0.98, 0.81, 0.97, -0.17, 0.0, 1.29, -0.15, 1.73, 0.57, 0.77, -0.18, 1.75, 1.17, 0.1, 0.18, 0.87, 0.95, 2.02, 0.93, 1.54], ['440', 2.49, -0.01, 0.05122171562045875, -0.21, 0.11, 0.04, 1.424115257959829, 1.05, 0.52, 0.92, 0.35, 0.241934498041641, 1.24, -0.44, 0.14, 0.25, 0.7, 0.72, 0.92, 0.67, 0.83, 1.66, 0.73, 0.97, 0.78, 0.84, 0.58, -0.3, 0.89, -0.79, -0.2, -0.09, 0.35, 0.38, 0.58, 0.32, 0.48076068376068376, 1.31, 0.39, 0.62, 0.8, -0.48, 0.88, 1.1936589811608609, -0.48, 0.1, 0.21, 0.66, 0.68, 0.88, 0.63, 0.79, 1.62, 0.69, 1.2308287981859412, 0.87, 0.75, 0.08, 0.86, -0.31, -1.66, -1.08, -0.97, -0.53, -0.51, -0.31, -0.56, -0.4, 0.42, -0.5, -0.27, 2.31, 1.37, 0.59, 0.7, 1.15, 1.17, 1.37, 1.12, 1.28, 2.11, 1.18, 1.42, 0.13, 0.25, -0.34, 0.78, 0.11, 0.56, 0.58, 0.78, 0.53, 0.69, 1.52, 0.59, 0.82, 2.68, 0.67, 0.44, 0.47, 0.67, 0.41, 0.58, 1.41, 0.48, 0.71, 0.22, 0.66, -1.73, 0.23, 0.34, 0.06, 0.22, 0.02, 0.22, -0.03, 0.13, 0.96, 0.03, 0.3285846838830657, -0.75, 0.2, 0.2, -0.05, 0.11, 0.93, 0.01, 0.24, 0.7, 0.48, -0.23, 0.02, 8.12, 0.02, -0.07, -0.46, 0.46, 0.23, -0.29, 0.11, -0.48, -0.48, -0.2, 1.24, 0.22, 0.69, -0.77, -0.74, 0.24, -0.66, 0.48, 1.33, -0.65, 0.62, -3.75, -0.35, -0.71, 0.45, 0.0, -0.25, -0.09, 0.73, -0.19, 0.04, 0.63, 0.25, 0.16, 0.99, 0.06, 0.3, 0.09, 0.83, -0.1, 0.13, 0.51, 0.39, -0.73, -0.92, -0.68, 0.14, 0.22, 0.99, -1.92, -0.73, 1.88, -0.29, 0.62, 0.19, 0.23, 0.26, -0.1, 0.6, 0.08, 0.79, -0.04, 0.63, 0.63, -0.06], ['441', -4.94, 0.19, 0.011221715620458745, -0.24, -0.10702091900894042, 1.31, 0.6941152579598292, 1.75, 2.14, 0.63, -1.54, -0.2, -0.48, -1.78, -0.05, 1.49, -0.31, 0.24, 2.92, -0.84, 1.59, -0.42, -1.79, -0.62, 2.0, 1.46, 2.21, 1.36, 1.07, -0.24, 1.52, 3.08, 1.25, 1.8, 4.547761904761905, 0.71, 3.17, 1.14, -0.25, 0.93, 1.26, 4.97, 0.84, -0.28, -1.58, 0.16, 1.7, -0.11, 0.44, 3.12, -0.64, 1.79, -0.22, -1.59, -0.42, 1.34, 1.87, 1.78, 2.2699285714285713, 1.12, -1.3, 0.44, 1.98, 0.17, 0.72, 3.41, -0.36, 2.08, 0.06, -1.31, -0.14, 0.82, 2.45, 1.76, 3.33, 1.49, 2.05, 4.78, 0.96, 3.42, 1.38, -0.01, 1.18, 3.3, 6.37, -6.3, 0.68, 1.54, -0.27, 0.28, 2.96, -0.79, 1.7952352330209473, -0.37, -1.74, -0.57, -0.48, -0.85, -1.78, -1.24, 1.4, -2.3, 0.09, -1.88, -3.23, -2.08, 0.49, -0.89, 0.42572371188304003, 1.46, 1.77, 1.05, 0.95, 0.55, 3.24, -0.53, 2.0857782534925393, -0.11, -1.48, -0.25141531611693435, 1.1265360710717855, 0.4, 2.67, -1.07, 1.35, -0.65, -2.02, -0.85, 2.23, 1.93, -0.29, 1.04, -0.92, 0.46, 0.35, -1.73, 1.74, 0.85, 0.05, 2.82, -2.87, -2.95, -1.45, -2.53, 1.24, 4.2, -4.18, -4.29, 1.47, -2.57, 2.92, 2.15, -1.05, 2.79, -9.91, -1.86, -2.76, 2.93, -2.22, -3.65, -1.29, -3.24, -4.57, -3.44, 4.41, 1.48, 2.44, 0.42, -0.96, 0.22, -0.94, -1.98, -3.32, -2.17, 2.17, 2.57, 1.1472746849074344, -1.37, -0.2, 1.38, 1.31, 1.58, -5.17, 0.45, 5.12, 1.13, 1.86, 2.47, 1.19, 1.58, 0.83, 0.95, 1.55, 1.88, 1.26, 0.84, 0.91, 0.86], ['442', 1.49, 0.32, -0.22877828437954126, 0.04, 1.09, 0.15, -0.8358847420401708, -1.05, -2.12, -1.06, 1.68, -0.67, -1.21, -0.62, -0.23, -1.39, -1.55, -0.86, 0.7114818594104309, -2.83, -1.11, -1.58, -1.39, -1.11, -1.44, 0.07, -2.7, -2.31, -2.84, -2.11681006295292, -1.88, -3.02, -3.18, -2.5, -0.97, -4.44, -2.74, -3.21, -3.02, -2.75, -1.1, -3.0450638007838267, -0.39, -0.54, 0.05, 0.45, -0.72, -0.88, -0.19, 1.38, -2.17, -0.44, -0.92, -0.72, -0.44, -0.82, -1.91, -0.6, -2.52, 0.15, 0.6, 0.99, -0.18, -0.34, 0.35, 1.93, -1.64, 0.1, -0.38, -0.18, 0.1, -0.36, -0.45, 0.39, -0.78, -0.94, -0.25, 1.32, -2.23, -0.49, -0.97, -0.77, -0.5, -2.49, 0.98, -1.03, -0.8033017616146798, -1.16, -1.32, -0.64, 0.92, -2.61, -0.88, -1.36, -1.16, -0.89, 2.36, 0.33, -0.16, 0.53, 2.11, -1.46, 0.28, -0.2, 0.0, 0.28, -0.13, 0.33, 1.41, 0.2, 0.33, 0.20567351865003197, 0.5, 0.7, 2.28015873015873, -1.3, 0.45, -0.03, 0.16, 0.44, 0.61, -0.2, 1.57, -1.99, -0.25, -0.6042004503433073, -0.53, -0.25, 0.08, 0.08, 0.08, 0.46, 4.75, 0.11, 0.21, -0.17, 0.16, 0.07, 0.94, -0.24, -3.83, -0.33, -0.17, 0.84, -0.04, 0.6514761904761905, -0.65, -0.49, 0.19, -0.23, 0.33, 0.09, 0.0, 1.45, -2.47, -1.02, -1.46, 3.86, -1.74, -3.5, -1.79, -2.26, -2.07, -1.79, 0.53, 1.82, 1.77, 1.29, 1.48, 1.77, 0.05, -0.48, -0.28, 0.0, -0.27, -0.59, 0.53, 0.2, 0.48, 0.17, 0.27, 0.02, -1.07, 0.61, 1.3, 0.5, 0.95, 0.33, 0.28, 0.33, 0.04, -0.29, -0.12, -0.03, 0.05, 1.7, 1.31, -0.11], ['443', -0.76, -0.56, 0.011221715620458745, 0.01, 0.11, 0.12, -0.59, 0.29, -0.08, -0.29, 0.19, 0.09, -0.02, -1.63, -0.61, -0.33, -0.26, -0.39, 1.36, -0.06, -0.42, 0.61, -0.26, 0.22, 0.68, -0.11, -0.48, -0.1, -0.21, -1.82, -0.8, -0.52, -0.45, -0.58, 1.17, -0.25, -0.61, 0.42, -0.44, 0.04, 0.17, -0.47, -0.38, -0.11, -1.72, -0.7, -0.42, -0.35, -0.48, 1.27, -0.15, -0.51, 0.51, -0.35, 0.13, 0.21, -0.34, 0.48, 0.71, -0.27, -1.61, -0.59, -0.31, -0.25, -0.37, 1.38, -0.04, -0.4, 0.63, -0.24, 0.24, 0.32, 1.36, 1.03, 1.32, 1.39, 1.26, 3.04, 1.6, 1.23, 2.27, 1.4, 1.89, -0.52, 0.01, 0.09, 0.3666982383853202, 0.28, 0.35, 0.23, 1.98, 0.56, 0.19, 1.23, 0.36, 0.84, 0.97, 0.04, 0.07, -0.06, 1.7, 0.27, -0.09, 0.94, 0.08, 0.56, 0.21, 0.03, 0.65, 0.08, 0.19, 0.07567351865003197, -0.03, -0.13, 1.63, 0.2, -0.16, 0.87, 0.01, 0.49, -0.79, 0.1, 1.75, 0.33, -0.03, 1.1257995496566926, 0.13, 0.62, 0.18, 0.11, -0.18, 0.09, 2.91, 0.01, 0.05, 0.0, -0.02, -0.02, -0.03, 0.32, 0.45, -0.15, -0.09, -0.38, 0.04, 0.22, -0.26, -0.21, 0.07, -0.08, 0.14, 0.59, -0.24, -0.07, -3.45, 0.03, 0.05, -0.37, -1.63, -1.4, -1.76, -0.74, -1.59, -1.12, 0.22, -0.23, -0.36, 0.7557142857142858, -0.2, 0.28, 0.13, 1.03, 0.17, 0.65, 0.02, 0.04, -0.89, -0.86, -0.38, 0.09, 0.07, 0.4525760496238784, -2.01, 0.3711163791806698, 2.03, 0.25, 0.17, -0.03, 0.48, -0.14, 0.15, 0.53, -0.24, 0.34, -0.51, 0.26, 0.26, 0.34], ['444', 1.57, -1.29, -0.06877828437954125, -0.05, -0.57, -0.53, -3.31, -1.13, -0.8506219456129893, -0.65, -0.05, 1.31, -0.45, 2.63, 0.89, -1.39, 0.12, -0.34, 0.87, 1.11, 0.0, 1.5, -0.98, 0.04, -0.35, 0.25, -0.61, 1.36, -0.4, 2.68, 0.94, -1.35, 0.17, -0.29, 0.92, 1.16, 0.05, 1.55, -0.94, 0.09, -1.85, 0.0, -1.94, -1.73, 1.31, -0.41, -2.67, -1.17, -1.63, -0.43, -0.2, -1.29, 0.19, -2.27, -1.25, -0.72, -1.36, -0.14, -0.91, -0.21, 3.1, 1.35, -0.95, 0.57, 0.11, 1.32, 1.57, 0.45, 1.96, -0.54, 0.49, 0.26, -3.2, -1.7, -3.92, -2.45, -2.9, -1.72, -1.48, -2.57, -1.11, -3.53, -2.52, -0.51, 0.15, -0.22, -1.53, -2.27, -0.76, -1.22, -0.02, 0.22, -0.88, 0.6, -1.86, -0.84, 2.75, 0.75, 1.54, 1.07, 2.3, 2.54, 1.41, 2.93, 0.41, 1.46, -0.42, 0.78, -2.36, -0.45, -0.3, -0.69, -0.78, -0.46, 0.75, 0.99, -0.12, 1.37, -1.11, -0.08, -1.94, -0.32, 1.21, 1.46, 0.34, 1.85, -0.65, 0.38, 0.18, 0.05956122448979598, -0.04, -0.57, 8.17, -0.35, -0.57, 0.63, -0.61, -0.31, -0.07, -1.38, 3.38, 0.88, 0.42, 0.78, -1.36, -1.32, 1.39, 1.37, -0.44, 0.91, -0.88, -1.22, 0.62, -2.29, 1.94, 1.48, 2.28, -3.44, -1.51, 0.24, -0.86, 0.62, -1.84, -0.82, -1.24, -1.75, -1.1, 0.38, -2.07, -1.06, -0.66, 1.5, -0.99, 0.04, -0.97, -0.69, -2.12, -2.45, -1.43, -0.42, -0.52, -1.19, 1.36, -1.85, -0.9107193877551023, -0.22, -0.1, 0.33, 1.04, -0.24, -0.08, -1.56, -1.33, -1.31, -0.7, -0.58, 0.15, -0.47], ['445', 2.74, -0.2, -0.17, 0.01, 0.18, -0.36, 0.4841152579598291, -1.08, -0.26, -0.25, 0.33, -0.5506751700680272, 0.76, 1.55, 1.68, -0.08, 0.24, -0.08, 0.91, -0.4, 0.16733548208735893, 1.88, 0.92, 0.39, -0.64, -0.96, -0.5473416050068876, -0.89, 0.43, 1.21, 1.35, -0.4, -0.09, -0.41, 0.58, -0.73, -0.19, 1.55, 0.58, 0.06, -1.12, 0.34493619921617347, 0.31, 1.33, 2.12, 2.26, 0.49, 0.81, 0.48, 1.49, 0.16, 0.7, 2.46, 1.5871428571428572, 0.96, -0.3876426685347185, -1.26, -0.78, -0.98, -1.0, 0.78, 0.92, -0.83, -0.51, -0.83, 0.15, -1.15, -0.62, 1.11, 0.16, -0.37, -0.83, -1.77, 0.14, -1.5367057823129253, -1.28, -1.6, -0.62, -1.92, -1.39, 0.33, -0.62, -1.14, 0.18, -3.53, 3.53, -1.9, -1.73, -1.42, -1.73, -0.76, -2.05, -1.52, 0.2, -0.75, -1.27, 1.04, -0.18, 0.32, -0.01, 0.99, -0.33, 0.21, 1.96, 1.1311089783232642, 0.47, -0.14, -0.23, 0.0, -0.6, -0.86, -0.42, -0.49, -0.32, 0.67, -0.64, -0.11, 1.64, 0.67, 0.15, -1.99, -0.17, 1.0, -0.32, 0.22, 1.96, 1.0, 0.47, -1.1781719617057962, -1.76, -0.13, -0.91, 1.92, -0.43, -0.29, -0.92, 0.9, 0.46, -0.74, -0.46, -0.5, 1.22, 0.62, 1.34, -0.58, -1.8, 1.91, 1.83, -0.61, -1.32, -1.44, 0.46, -0.2, -1.42, 3.62, 0.96, 1.36, 0.4, -1.1416360544217685, -1.3, -0.77, 0.96, 0.0, -0.52, -1.87, 0.15, 0.54, 2.5371428571428574, 1.32, 0.79, -0.39, 1.74, 0.78, 0.26, -0.19, -0.36, -2.09, -0.95, -1.46, -0.4779199656859431, -0.65, -1.05, 1.84, -0.28, -1.85, -1.96, -1.45, -1.16, -0.52, -1.56, 0.64, -0.29, -0.35, -0.92, -0.64, -2.03, -0.65, -0.71], ['446', -0.75, 0.51, 0.07015289830927054, -0.07, -0.25, -0.3, 1.61, 1.36, 0.56, 1.35, 1.27, 0.64, 0.84, 0.28, -1.88, 0.68, 0.48, 1.33, 2.08, 1.87, 1.22, 0.31, 0.15, 0.32, -0.04, 0.16, 0.11265839499311246, -0.63, -0.43, -0.97, -3.11, -0.58, -0.78, 0.06, 0.8, 0.59, -0.05, -0.95, -1.11, -0.93, 1.99, 1.6849361992161733, 0.71, 0.2, -0.35, -2.5, 0.04, -0.16, 0.69, 1.43, 1.23, 0.58, -0.33, -0.49, -0.31, 0.06, 0.5, 2.74, 0.41, 0.52, -0.55, -2.69, -0.15, -0.35, 0.49, 1.2471802721088434, 1.03, 0.38, -0.52, -0.68, -0.51, 0.82, 1.07, -2.16, 0.39, 0.2, 1.04, 1.79, 1.58, 0.93, 0.02, -0.14, 0.04, 0.78, 3.18, -3.27, 3.3, 2.61, 2.4, 3.27, 4.03, 3.82, 3.16, 2.23, 2.06, 2.25, -0.04, 0.67, -0.2, 0.65, 1.39, 1.18, 0.54, -0.37, -0.53, -0.35, 0.0, 0.63, 2.58, 0.61, 0.65, 0.72, 0.87, 0.85, 1.59, 1.38, 0.74, -0.17, -0.33, -0.15, 0.83, 0.02, 0.74, 0.53, -0.11, -1.01, -1.17, -0.99, 1.18, 1.2, 0.0, 1.343186783623568, -0.24, 0.04, 0.05, -2.39, 2.43, 1.24, -0.15, -0.19, 1.17, -1.24, -0.64, -0.29, 0.83, 1.82, -1.88, -1.92, 0.6, -3.7, 1.23, 0.4, -0.25, 2.6, -8.33, -1.85, -2.62, -1.07, -0.71, -0.2, -0.84, -1.73, -1.89, -1.72, 1.79, -0.5098412698412699, -0.64, -1.53, -1.69, -1.52, 0.13, -0.9, -1.06, -0.88, 0.56, 0.6, 1.05, -0.16, 0.09224875531501633, 0.61, 0.71, 1.35, -5.0, 2.28, 4.72, 0.86, -0.66, 1.21, 0.18, 0.39, 0.03, 1.31, 0.62, 1.07, 1.03, -0.74, -1.08, 1.06], ['447', -8.49, 0.36, 0.05122171562045875, 0.08, -0.29, 0.37, 0.6541152579598292, 0.57, 0.61, -0.1, -0.63, -1.08, -0.36, -0.56, -0.89, 1.32, -0.65, -0.28, -2.81, -0.62, -0.01, -1.24, -1.21, -0.23, 0.56, -0.11, 0.53, -0.45, 0.27, 0.07, -0.27, 1.96, -0.02, 0.35, -2.2, 0.01, 0.62, -0.61, -0.59, 0.4, 0.89, 1.2, 0.98, 0.73, 0.53, 0.18, 2.43, 0.43, 0.81, -1.76, 0.46, 1.08, -0.16, -0.14, 0.86, 0.89, 0.55, 0.0, 0.61, 0.32924524706587754, -0.2, -0.54, 1.68, -0.29, 0.08, -2.47, -0.26, 0.35, -0.88, -0.86, 0.13, -0.13, 0.45, -0.34, 1.89, -0.09, 0.28, -2.27, -0.07, 0.55, -0.69, -0.5269045181009466, 0.33, 0.69, 3.05, -2.96, 0.8008709226619941, 2.24, 0.25, 0.62, -1.94, 0.28, 0.89, -0.35, -0.32, 0.67, -1.72, -1.41, -1.94, -1.58, -4.08, -1.92, -1.32, -2.53, -2.5, -1.53, 0.19, -1.42, 0.1, 0.43, 0.56, 0.26, 0.55, 0.37, -2.18, 0.22971268810554554, 0.8157782534925394, -0.59, -0.4940121365844473, 0.42, 1.05, 0.17, -2.54, -0.34, 0.27, -0.96, -0.94, 0.05, 0.46, 0.24, 0.13, 0.51, -5.2, 0.0, 0.05, -0.14, 0.11, 0.07, 0.29, 1.1961635321120496, -0.97, -0.91, -0.44, -4.22, 0.42, 1.36, -1.31, -1.31, 0.44, -0.2, 0.85, 0.27, -0.14, 1.72, 0.85, -1.1, -1.61, 1.1, 2.79, 2.26, 2.88, 1.62, 1.65, 2.66, 1.35, 0.52, 0.61, -0.62, -0.6, 0.39, -0.09, -1.23, -1.2, -0.22, -0.4, -0.33, 1.2372746849074343, 0.02, 1.02, 0.44, -0.28, -0.2974239503761216, 0.5, -0.19, -0.58, 0.64, 0.58, 1.12, 1.0, 0.34, 0.2, 0.55, 0.28, 0.2, 0.13, -0.09, 0.51, -0.16], ['448', -1.22, -0.18, -0.06, 0.23, -0.2, -0.02, 1.25, -0.31, -0.36, 0.9370884353741497, 0.970608843537415, -0.41, 0.41, 0.6, 0.76, 0.91, 0.57, 0.36, 1.66, 0.37, 0.35, 0.03, 0.87, 0.2, -0.57, -0.48, -0.42734160500688756, -1.35, -0.54, -0.35, -0.1421800287049088, -0.05, -0.39, -0.47274109585559154, 0.7, -0.58, -0.6, -0.92, -0.09, -0.75, 0.28, -1.06, 0.9, 0.82, 1.02, 1.17, 1.32, 0.98, 0.78, 2.08, 0.78, 0.77, 0.44, 1.28, 0.62, -0.9, 0.54, -0.22, -0.74, 0.15924524706587756, 0.19, 0.35, 0.5, 0.16, -0.05, 1.25, -0.04, -0.06, -0.38, 0.46, -0.21, -0.35, -0.11, 0.16, 0.3, -0.04, -0.24, 1.05, -0.23, -0.25, -0.57, 0.26, -0.4, -0.92, -1.11, 1.15, -0.23330176161467986, 0.15, -0.19, -0.39, 0.9, -0.39, -0.4, -0.72, 0.11, -0.55, -0.87, -0.41, -0.34, -0.54, 0.75, -0.54, -0.4873734626473065, -0.87, -0.04, -0.7, 0.16, -0.45, 2.61, 0.03, -0.11, 0.16, -0.0790429599640126, -0.2, 1.09, -0.2, -0.21, -0.53, 0.3, -0.36, 0.4, 0.13, 1.29, 0.0, -0.01, -0.33, 0.5, -0.16, -0.67, -0.35, 0.62, -0.08, -2.34, 0.0, 0.07, -0.94, 0.96, 0.47, -0.44, -1.28, -0.24, -0.08, -0.03, -0.56, 0.3, -0.01, -0.09, -0.17, 0.03, -1.33, 0.04, -1.06, 0.51, -0.38, 16.84, 0.28, 0.36, 0.24, -1.15, -1.27, -1.29, -1.6, -0.78, -1.44, 0.09, 0.12, -0.01, -0.34, 0.5, -0.16, 0.14, -0.32, 0.51, -0.15, -0.32, -0.83, 0.46, 0.84, 0.17, 0.06, 0.11439630127529085, -0.24, 7.56, 1.490333262784063, -7.7, 0.37, -0.73, -0.38, -0.66, 0.01, 0.3, 0.15, 0.63, 0.32, 0.29, 0.12, -1.29, 0.11], ['449', 3.584285714285714, -0.03, 0.13122171562045873, 0.1, 1.42, 0.8, 0.5641152579598292, 1.35, 1.33, 1.5, -0.14, 0.93, 1.78, 0.27, -0.04, 0.49, 0.62, 1.29, -1.67, -0.16, 1.947335482087359, 0.83, 0.96, 0.9, 1.73, 1.39, 1.65, 1.08, 1.93, 0.41, 0.1, 0.63, 0.77, 1.43, -1.53, -0.01, 2.06, 0.97, 1.1, 1.04, 0.79, 3.03, 0.56, 0.84, -0.66, -0.97, -0.44, -0.31, 0.35, -2.58, -1.08, 0.9980654680864429, -0.11, 0.02, -0.04, 0.7, 1.62, 2.217827972809784, 0.99, -0.28, -1.49, -1.79, -1.27, -1.14, -0.49, -3.4, -1.91, 0.12, -0.94, -0.81, -0.8605612244897959, 1.2436060011417156, 1.23, -0.2953571428571429, 0.22, 0.35, 1.01, -1.94, -0.42, 1.64, 0.55, 0.69, 0.62, 2.04, 1.59, -1.58, 1.54, 0.53, 0.66, 1.33, -1.63, -0.12, 1.95, 0.87, 1.0, 0.94, 1.7, 1.01, 0.13, 0.79, -2.15, -0.64, 1.41, 0.33, 0.47, 0.4, 0.15, 0.99, 0.22572371188304005, 0.84, 0.77, 0.9, 0.9418094764861292, 0.66, -2.28, -0.77, 1.28, 0.2, 0.33, 0.27, 0.61, 0.21, -2.92, -1.43, 0.62, -0.46, -0.33, -0.39, 0.4618280382942037, 0.45, 0.04, 0.86, 5.04, 0.32, 0.4, -2.33, 2.38, 1.19, 1.23, 0.23, -3.26, -1.64, -0.87, 1.6, 0.69, 2.53, -2.55, -2.49, 0.84, -3.56, 1.66, 0.03, -0.02, 2.62, -2.77, -1.79, -2.59, 3.26, 3.23, 1.54, 3.64, 2.54, 2.68, 2.61, 2.52, 1.66, 2.07, 0.98, 1.12, 1.05, -0.4, -1.07, -0.94, -1.0, 1.27, 1.52, 0.67, 0.13, 0.07, 0.84, 0.8, 1.31, -1.71, 0.3, 1.86, 1.27, 1.34, 0.54, -0.06, 0.61, 1.5, 0.37, 0.95, 0.61, 0.6, 1.8, 1.93, 0.44], ['450', 1.66, 0.38, 0.12, -0.04, 0.18, 0.56, 1.0041152579598291, 1.51, 1.2, 1.64, 0.46, 0.691934498041641, 0.57, -0.26, 0.24, 1.39, 0.44, 1.41, 2.91, 0.16, 1.96, 0.53, 0.64, 0.87, 1.72, 0.57, 1.2026583949931124, 0.02, 0.11, -0.72, -0.22, 0.92, -0.03, 0.95, 2.43, -0.3, 1.49, 0.07, 0.18, 0.4, 0.73, 0.8449361992161734, 1.14, 0.08, -0.74, -0.25, 0.89, -0.05, 0.92, 2.41, -0.33, 1.46, 0.04, 0.15, 0.38, 0.49, 1.67, 0.99, 1.22, 1.1392452470658776, -0.82, -0.33, 0.81, -0.13, 0.84, 2.32, -0.41, 1.38, -0.04, 0.07, 0.3, 1.85, 1.9, 0.5, 1.65, 0.7, 1.68, 3.17, 0.42, 2.22, 0.79, 0.9, 1.13, 0.94, 2.7, -2.63, 1.42669823838532, 1.15, 0.2, 1.17, 2.66, -0.08, 1.72, 0.29, 0.4, 0.63, -0.44, 0.25, -0.94, 0.03, 1.5, -1.21, 0.56, -0.84, -0.73, -0.51, 0.4, 0.24, 1.9001046511627906, 0.73, 0.68, 0.73, 1.19, 0.97, 2.46, -0.28, 1.52, 0.1, 0.2, 0.43, 1.09, 0.27307674813036725, 1.47, -1.24, 0.54, -0.87, -0.76, -0.29782256235827664, 0.87, 1.33, 0.24, 0.91, -1.55, 0.44, 0.62, -1.65, 1.8017201258125628, 0.84, 1.25, 2.96, -2.75, -1.39, -0.72, 0.82, 0.31, 2.14, -2.12, -2.16, 0.71, -2.45, 1.4, 0.47, -0.23, 3.65, -12.89, -2.49, -3.65, 2.81, -1.23, -2.67, -0.92, -2.31, -2.2, -1.98, 2.14, 1.47, 1.8, 0.37, 0.48, 0.71, -0.32, -1.4, -1.29, -1.07, 1.24, 1.29, 1.1, 0.11, 0.34, 0.76, 0.74, 1.62, -6.51, 1.55, 6.68, 0.49, 0.71, 0.99, 0.23, 1.0, 0.57, 0.43, -0.14, 0.78, 0.76, 0.04, 1.2415952380952382, 0.65], ['451', -12.94, -0.19, -0.5, 0.15, -3.29, -0.89, -0.25, -0.83, -0.88, -1.86, -0.96, -1.43, -0.66, -1.0, -0.88, 1.41, -0.54, -1.7, 2.7, 3.14, -2.03, -2.46, -2.13, -0.85, -1.24, -1.96, -0.8773416050068876, -0.4671394557823129, 0.3, -0.04, 0.07, 2.39, 0.42, -0.75, 3.700714285714286, 4.14, -1.0055463299214311, -1.52, -1.18, 0.11, -0.65, -2.17, -0.24069676751819596, 0.77, 0.44, 0.55, 2.88, 0.9, -0.28, 4.19, 4.63, -0.61, -1.05, -0.71, 0.58, -0.72, -1.04, -0.15, -1.19, -1.2, -0.33, -0.22, 2.09, 0.12, -1.04, 3.39, 3.83, -1.37, -1.4825351473922903, -1.47, -0.19, -1.67, -0.87, 0.11, 2.43, 0.46, -0.71, 3.74, 4.18, -1.04, -1.48, -1.14, 0.15, -1.1, 0.34, -0.33, -0.98, 2.32, 0.35, -0.82, 3.62, 4.06, -1.15, -1.59, -1.25, 0.04, -2.52, -3.22, -1.93, -2.9646649659863944, 1.27, 1.71, -3.39, -3.793605339105339, -3.49, -2.23, -0.25, -3.33, -2.66, -0.82, -0.57, -1.21, -1.32, -1.16, 3.26, 3.7, -1.49, -1.93, -1.59, -0.31, 0.56, -0.10692325186963274, 4.48, 4.92, -0.1613969800041227, -0.77, -0.44, 0.86, 0.16, 0.0, 0.06, -1.29, -7.6, -0.47, -0.48, 2.9, -2.9, -1.4111898289923788, -0.11, 0.17, 9.38, 1.61, 0.87, -6.5, -0.37, -2.73, 2.72, 2.49, -0.82, 4.31, -1.65, -2.63, 1.3, -3.95, 1.2, 2.66, 3.87, -9.52, -4.44, 0.43, -4.61, -5.03, -4.7, -3.46, -2.47, -4.84, -5.01, -5.43, -5.11, -3.87, 0.18, -0.44, -0.1, 1.2, -0.94, -1.08, 0.62, 0.34, 1.65, -0.85, -0.92, -0.92, 0.66, -2.39, -0.72, -0.3227361894755667, -2.59, 0.28, 1.31, -0.91, -1.41, -0.17470204795204777, -0.63, 0.15, -1.01, -1.17, -3.95, -0.83], ['452', -0.12, -0.12, 0.011221715620458745, 0.0, 0.1329790809910596, -0.04, -0.81, -0.87, -0.95, -0.33, 0.540608843537415, 0.69, 0.76, -0.06, 1.43, -0.11, 0.17, -0.06, -0.23, -0.53, -0.95, 1.36, 0.39, 0.05, -1.07, -0.89, -0.86, 0.16054545454545455, 0.23, -0.59, 0.9, -0.64, -0.36, -0.59, -0.75, -1.06, -1.47, 0.82, -0.14, -0.43615827680216085, -1.09, -2.77, -1.01, 0.07, -0.5821246055531769, 0.74, -0.8, -0.52, -0.74, -0.91, -1.21, -1.610345270762939, 0.66, -0.29, -0.64, -1.42, -0.51, -0.28217202719021606, -0.95, -1.08, -0.82, 0.67, -0.87, -0.59, -0.82, -0.98, -1.29, -1.7, 0.59, -0.37, -0.71, -1.25, -0.27, 1.5, -0.05, 0.23, 0.0, -0.16, -0.47, -0.88, 1.42, 0.45, 0.11, -1.17, -2.028257052471338, 2.22, -1.70330176161468, -1.53, -1.25, -1.48, -1.64, -1.94, -2.35, -0.08, -1.03, -1.37, -1.44, -0.22, 0.28, 0.05, -0.11, -0.42, -0.83, 1.47, 0.51, 0.16, -0.3090204081632653, -0.23, 0.09572371188304005, -0.2, -0.19, -0.2843264813499681, -0.42819052351387077, -0.23, -0.39, -0.7, -1.11, 1.19, 0.22, -0.12, -1.38, -0.21692325186963274, -0.16, -0.47, -0.89, 1.42, 0.45, 0.11, -1.2, -0.95, 0.03, -0.76, -4.27, 0.0, -0.07, 0.5, -0.4082798741874371, -0.25, 0.45, -0.4, -0.2, 0.53, 0.22, -0.03, 0.49, -0.65, 0.67, 0.62, -0.2, 0.81, -0.43, -0.61, 0.27, -1.51, 2.38, 0.97, 1.5, 0.44, -0.1, -0.31, -0.72, 1.58, 0.62, 0.27, -0.63, 0.21, -0.42, 1.9, 0.93, 0.58, 0.62, 2.32, 1.35, 1.0, -0.98, -1.06, -1.66, -0.95, -1.29, -0.22, -0.35, -0.86, 0.79, -0.43, -0.9634761904761905, -0.53, 0.08, -0.72, -0.34, -1.15, -0.28, 0.47, 0.47, 0.3646262438247291, -0.38, -1.56, -0.11, -0.37], ['453', -4.54, -0.3, -0.38877828437954126, -0.12, -0.77, -0.18, 0.9, -0.1, -0.27, -0.52, 0.24, -0.52, -1.17, -0.69, -0.65, 1.3, -0.84, -0.44, 0.2, 1.44, -0.662664517912641, -0.49, -0.29, -1.04, 0.04, -0.88, -0.76, -0.76, -1.41, -0.94, -0.9, 1.05, -1.08, -0.69, -0.04, 1.19, -0.94, -0.73, -0.54, -1.28, 0.02, -0.83, 0.0, -0.6463410188391392, -0.18, -0.14, 1.83, -0.33, 0.07, 0.72, 1.97, -0.18, 0.03, 0.22, -0.524952380952381, -0.47, -0.43, 0.0, -0.05, 0.66, 0.48, 0.52, 2.5, 0.33, 0.73, 1.38, 2.64, 0.47, 0.69, 0.88, 0.13, 0.06, 0.18, 0.04, 2.01, -0.15, 0.25, 0.9, 2.15, 0.0, 0.21, 0.4, -0.35, -0.86, -0.25, 0.26, 0.14, 1.97, -0.19, 0.21, 0.86, 2.303744771101914, 0.11523523302094742, 0.17, 0.36852380952380953, -0.39, -3.31, -1.79, -2.11, -1.72, -1.09, 0.14, -1.97, -1.77, -1.57, -2.31, -0.01, -1.75, 0.64, 0.01, -0.13, 0.24567351865003195, 0.33, 0.4, 1.0501587301587303, 2.3, 0.14, 0.36, 0.55, -0.2, 0.07, -0.07, 0.65, 1.982244713705627, -0.26, -0.04, 0.15, -0.6, -0.15, 0.16, -0.15, 0.12, -10.09, 0.0, -0.48, 0.01, -0.03, -0.01, -0.02, -0.87, 3.81, 0.0, -0.03, -2.27, 0.1, 0.021476190476190475, 0.0, -0.03, 0.01, -0.03, 0.03, 1.228390654979941, -0.56, 0.93, -2.25, -0.65, -0.98, -3.77, -0.72, 1.24, -0.9, -0.69, -0.49, -1.24, 0.0, -1.93, -2.11, -1.9, -1.71, -2.45, 0.18, 0.21, 0.41, -0.35, -0.3, -0.32, -0.03, 0.2, -0.56, 0.02, 0.04, 0.0, -1.17, 0.45, 1.13, -0.08, -1.03, -0.22, -0.75, 0.17, 0.1, 0.27, 0.33, 0.2, 0.53, -1.16, -1.76, 1.19], ['454', -1.44, 0.03, 0.16, 0.06, -1.01, -0.63, 0.07411525795982916, -0.95, -0.72, -1.15, 0.03, -0.84, -0.69, -0.07, -0.91, -0.47, 0.02, -1.12, -1.8, 0.53, -1.21, -0.68, -0.34, -1.29, -0.3, -0.5, -1.18, -0.8771394557823129, -0.7253571428571428, -0.11, -0.94, -0.5, -0.02, -1.16, -1.84, 0.49, -1.25, -0.71, -0.38, -1.32, -0.05, -3.14, -0.31, 0.15, 0.78, -0.07, 0.38, 0.87, -0.28, -0.97, 1.38, -0.341934531913557, 0.17, 0.51, -0.45, -0.8399371536943234, -0.47, -1.5580521152823785, 0.29, -0.46, 0.62, -0.22, 0.22, 0.71, -0.43, -1.12, 1.23, -0.53, 0.01, 0.35, -0.6, -0.96, -1.08, -0.84, -0.4, 0.09, -1.05, -1.73, 0.6, -1.14, -0.61, -0.1369045181009466, -1.22, -1.89, -2.29, 2.2, -0.24, 0.44, 0.93, -0.21, -0.9, 1.45, -0.31, 0.23, 0.57, -0.3259922724755494, -1.46, -0.68, 0.49, -0.66, -1.34, 1.0, -0.75, -0.21, 0.13, -0.82, -0.09, -0.7, -1.65, -0.46, -0.58, -0.32, -1.16, -1.14, -1.82, 0.51, -1.23, -0.6396949805527123, -0.36, -1.31, -0.44, -0.03, -0.43631441970727664, 1.67, -0.09, 0.45, 0.79, -0.17, -1.32, -1.54, 0.01, -0.59, -4.2, -0.03, 0.09, 0.81, -0.82, -0.43, 0.07, -1.07, 3.18, 0.97, 0.47, -0.65, -0.3, -1.34, 1.4, 1.5, -0.47, 1.19, -0.93, -0.44, 0.24, -3.49, 1.0486904761904763, 2.3, 3.52, -3.28, 0.67, 2.37, 0.6, 1.14, 1.49, 0.52, -1.35, -1.67, -1.73, -1.2, -0.86, -1.81, 0.07, 0.54, 0.88, -0.08, -0.75, -1.07, -0.47, 0.34, -0.62, -0.48, -0.49, -0.85, 2.39, -1.04, -2.61, -0.44, -0.5, -0.81, -0.95, -0.38, -0.9397802197802197, -0.15, -0.11, -0.22, 0.14, -1.12, -1.76, -0.36], ['455', -0.49, 0.03, 0.12, -0.06, -0.09, 0.51, 0.7, 0.17, 0.74, -0.33, -0.67, -0.94, -0.1, -0.74, -0.7, -0.55, -0.73, -0.43, 1.66, -0.38, -0.05, -1.54, -1.31, 0.29, 0.65, 0.33, 0.35, -0.27, 0.57, -0.06, -0.03, 0.13, -0.06, 0.24, 2.34, 0.29, 0.62, -0.87, -0.64, 0.96, 0.3774684253532108, 2.03, 0.62, 0.85, 0.21, 0.24, 0.4, 0.22, 0.52, 2.63, 0.57, 0.9, -0.5061344435209981, -0.37, 1.24, -0.29993715369432344, 0.31, 0.67, 0.4, -0.22, -0.63, -0.6, -0.44, -0.63, -0.33, 1.76, -0.28, 0.05, -1.44, -1.21, 0.39, 0.18, 0.41, 0.03, 0.19, 0.01, 0.31, 2.6574764481550197, 0.36, 0.69, -0.81, -0.58, 1.03, 1.08, 2.38, -2.29, 0.38, 0.16, -0.03, 0.27, 2.38, 0.33, 0.65, -0.84, -0.61, 1.0, 0.04, 0.22, -0.18, 0.12, 2.22, 0.17, 0.49, -1.0, -0.77, 0.84, 0.0, 0.22, 2.57572371188304, 0.18, 0.56, -0.28, 0.4, 0.3, 2.4, 0.35, 0.68, -0.82, -0.59, 1.02, 1.09, 0.1, 2.1, 0.05, 0.38, -1.11, -0.88, 0.72, 0.92, 1.2, -0.18, 0.09, 0.08, 0.1, 0.04, 1.91, -1.91, -0.94, 0.44, -0.51, 0.0, -0.43, -0.19, -0.28, 0.41, 0.48, -0.41, -0.41, 0.18, 2.68, 0.38, 0.85, -0.46, 1.21, -0.76, -0.81, -1.2, -0.07, -1.95, -1.9951904761904762, -1.68, -3.15, -2.92, -1.35, 0.59, 0.05, 0.32, -1.17, -0.93, 0.67, -0.27, -1.49, -1.26, 0.34, 0.72, 0.73, 1.23, 0.23, 1.85, 0.22, 0.16, 0.19, -0.98, 1.0701996269574994, 1.2, -0.08, 0.7, 1.0, 1.62, 0.93, -0.52, 0.0, 0.75, 0.28, -0.61, 1.09, 0.95, -2.19], ['456', -1.67, -0.03, 0.12, 0.14, 0.18, -0.72, -1.4858847420401708, -1.12, -1.33, 0.12, 1.89, 1.61, 0.74, 0.97, 1.55, -0.02, 0.98, -0.03, -1.41, 0.72, -0.10266451791264107, 0.24, 0.59, 0.59, -1.7, -1.23, -1.74, -0.28, -1.12, -0.9, -0.34, -1.87, -0.9, -1.88, -3.23, -1.15, -1.915546329921431, -1.62, -1.28, -1.28, -1.52, -1.46, -1.46, -0.85, -0.62, -0.06, -1.6, -0.62, -1.61, -2.97, -0.88, -1.691934531913557, -1.35, -1.01, -1.0, -0.52, -1.37, -0.48, -0.76, -0.62, 0.23, 0.9048467679404526, -0.75, 0.23, -0.6673949338599383, -2.13, 0.10397573353350675, -0.88, -0.5, -0.16, -0.15, -1.73, -0.85, 0.57, -0.98, 0.0, -0.99, -2.36, -0.25, -1.1, -0.73, -0.38, -0.38, -1.55, -1.46, 1.43, -1.4, -1.54, -0.56, -1.55, -2.91, -0.81, -1.66, -1.29, -0.95, -0.94, -0.45, 0.14, 0.99, -0.01, -1.39, 0.73, -0.12, 0.26, 0.6, 0.6, 0.02, 0.13, -0.24, -0.68, -0.65, -0.704326481349968, -0.85, -0.99, -2.36, -0.25, -1.11, -0.73, -0.38, -0.3214153161169343, -0.08, 0.15, -1.38, 0.75, -0.11, 0.27, 0.62, 0.62, -0.62, -0.57, 0.13, -0.73, -1.28, -0.1, 0.0, 1.96, -1.96, -0.97, 0.0, -1.83, 1.17, 1.4, 0.72, -0.81, -0.36, -2.06, 2.27, 2.05, -0.69, 2.9, -1.36, -1.45, 0.74, -2.6, 3.57, 1.75, 2.57, -1.17, 1.55, 2.15, 1.28, 1.67, 2.02, 2.02, -2.04, -0.59, -0.85, -0.47, -0.13, -0.13, 0.26, 0.38, 0.73, 0.73, -1.25, -1.02, -0.12, 0.34, 0.35, -0.7, -0.69, -1.14, 1.54, -0.43980037304250064, -1.62, -0.99, -1.2, -0.46, 0.0, -0.84, -1.08, -0.31, -0.3, -0.31, -0.46, -1.89, -1.74, -0.16], ['457', 1.48, -0.72, 0.3412217156204588, 0.03, 0.0, 0.17, -0.015884742040170832, 0.84, 0.1, 0.86, 0.81, 0.75, 1.44, -0.38, -1.34, 1.29, 0.39, 0.6, 2.8, 1.74, 1.13, 1.21, 0.41, 0.86, -0.14, -0.22, 0.05, -0.06, 0.63, -1.18, -2.13, 0.47, -0.41, -0.21, 1.97, 0.93, 0.32, 0.4, -0.39, 0.05, 0.58, -1.0450638007838267, 0.11, 0.7711974674961171, -1.12, -2.08, 0.53, -0.36, -0.15, 2.03, 0.99, 0.38, 0.46, -0.2528571428571429, 0.11, 0.37, -0.94, 0.25, -0.12, -0.57, -1.8, -2.74, -0.15, -1.03, -0.83, 1.34, 0.3, -0.14657884575741703, -0.23, -1.01, -0.57, -0.15639399885828442, 1.25, -0.96, 1.67, 0.78, 0.98, 3.19, 2.13, 1.52, 1.6, 0.8, 1.25, 0.37, 1.24, -1.21, 2.23, 2.66, 1.76, 1.96, 4.19, 3.13, 2.5, 2.59, 1.78, 2.23, 0.27, -0.42, -0.88, -0.68, 1.49, 0.45, -0.16, -0.07, -0.86, -0.42, 0.25, -0.44, 0.7201770034254836, 0.16, 0.29, 0.08, 0.47, 0.2, 2.39, 1.35, 0.73, 0.82, 0.02, 0.47, -0.25, 0.26, 2.19, 1.14, 0.53, 0.61, -0.18, 0.26, 1.39, 1.57, 0.02, 0.52, 0.74, 0.5, 0.01, 0.31, -0.31, -0.16, 0.31, 1.11, 1.82, -0.33, -0.18, 0.84, 0.0, 0.5914761904761905, -0.48, -0.4, 0.16, 0.39, 0.31, -0.58, 0.24, 1.38, -3.43, -0.88, -1.34, -1.68, -1.88, -1.02, -1.62, -1.54, -2.32, -1.88, 0.46, -0.87, -0.6, -0.52, -1.31, -0.87, -0.26, 0.08, -0.71, -0.26, 0.1, 0.27, -0.35, -0.79, -0.35, 0.24, 0.27439630127529085, 0.78, -1.54, 0.75, 1.52, 0.32, 0.47, 0.5286374482009709, 0.5227868514969317, 0.7300774025227806, -0.12, 0.09, 0.06, 0.08462624382472905, 0.085957527023814, 0.27, -0.27, 0.88], ['458', -4.2, -0.56, -0.45, 0.18, -1.3, -0.99, -1.98, -2.05, -1.94, -2.4492857142857143, -0.69, -0.9, -0.44, -1.1, -0.25, -1.22, -1.67, -2.37, -3.42, -0.81, -2.92, -1.58, -1.29, -2.18, -2.22, -0.67, -1.77, -0.22, 0.25, -0.41, 0.44, -0.54, -0.99, -1.7, -2.75, -0.12, -2.25, -0.9, -0.6, -1.5, -1.86, -2.9850638007838266, -1.56, 0.47, -0.2, 0.65, -0.32, -0.78, -1.48, -2.54, 0.09, -2.04, -0.69, -0.3028571428571429, -0.9691712018140588, -1.6, -2.27, -2.5, -2.0, -2.02, -0.66, 0.18079931972789115, -0.79, -1.24, -1.95, -2.7103066893424037, -0.38, -2.5, -1.15, -0.85, -1.75, -2.05, -1.37, 0.85, -0.12, -0.58, -1.135765306122449, -2.35, 0.29, -1.84, 0.16000000000000003, -0.19, -1.09, -2.29, -3.31, 3.36, -2.2, -0.97, -1.42, -2.12, -3.17, -0.56, -2.67, -1.33, -1.04, -1.93, 1.98, -1.25, -0.46, -1.17, -2.23, 0.41, -1.72, -0.37, -0.07, -0.97, -0.04885812600098299, -1.24, 0.33, -0.85, -1.02, -0.66, -0.79, -0.71, -1.78, 0.88, -1.27, 0.15030501944728758, 0.39, -0.51, -0.74, -0.026923251869632736, -1.07, 1.6, -0.5504376417233561, 0.81, 1.11, 0.2, -1.0710416300368755, -1.2, 0.33603717887804047, -0.75, 5.617738095238095, -0.26, 0.07, 1.43, -1.41, -0.72, -0.36, -4.11, 3.13, 1.65, 0.87, -2.09, -0.68, -2.56, 2.55, 2.6, -0.85, 2.23, -1.72, -2.8, 1.39, -2.37, 4.97, 1.71, 2.31, -3.38, 1.0, 2.7, 0.52, 1.9, 2.21, 1.29, -2.53, -1.65, -2.13, -0.78, -0.48, -1.38, 0.49, 1.38, 1.68, 0.77, -1.95, -1.96, -0.88, 0.3, -0.6, -0.81, -0.86, -2.04, 2.72, -0.29, -2.55, -0.22, -1.0, -1.18, -0.9, -0.97, -0.83, -0.59, -0.67, -0.91, -0.28, 0.25, -1.15, -0.14], ['459', -1.87, -0.13, 0.21, -0.09, 0.43, 0.53, 0.30411525795982913, 0.62, 0.98, 0.33, -1.62, 0.07, -0.56, 1.56, -0.15, 0.24, -1.35, -0.2, -2.86, -0.52, 0.42, -0.49, -0.45, -1.06, 1.15, 1.13, 2.0126583949931125, 1.72, 1.08, 3.23, 1.49, 1.89, 0.27, 1.44, -1.25, 1.12, 2.08, 1.16, 1.19, 0.57, 0.5, 3.2249361992161734, 0.26, -0.63, 1.48, -0.23, 0.17, -1.42, -0.27, -2.93, -0.59, 0.35, -0.56, -0.53, -1.13, 0.21, 1.1, 1.42, 0.43, 0.89, 2.13, 0.41, 0.8, -0.8, 0.36, -2.31, 0.04, 0.98, 0.07, 0.1, -0.51, 0.78, -1.21, -1.68, -1.3, -2.87, -1.73, -4.35, -2.05, -1.12, -2.01, -1.98, -2.58, 2.18, 2.68, -2.66, 0.5166982383853201, 0.4, -1.2, -0.05, -2.71, -0.37, 0.58, -0.33, -0.3, -0.91, 1.88, 0.09, -1.59, -0.44, -3.09, -0.76, 0.18, -0.72, -0.69, -1.3, 0.5, 0.09, 1.86, 1.2315981806829015, 0.82517906963434, 1.68, 1.71, 1.17, -1.52, 0.84, 1.8, 0.88, 0.91, 0.29, 0.84, 0.5830767481303673, -2.66, -0.32, 0.63, -0.28, -0.25, -0.86, 1.21, 1.49, -0.04, 1.61, 5.53, 0.21, 0.19, -4.91, 4.86, 2.44, 0.28, 0.34, -1.6, -2.35, -1.18, -1.0, 0.56, 3.63, -3.68, -3.42, 1.2132908048638529, -7.19, 2.399878357241315, 1.67, -0.82, 5.140714285714285, -7.49, -3.47, -5.08, 1.65, 3.28, 2.4, 3.37, 2.44, 2.47, 1.84, 3.49, 0.86, 0.95, 0.04, 0.07, -0.55, -0.09, -0.9, -0.87, -1.48, 0.99, 1.2, 0.82, 0.03, -0.58, 1.15, 1.26, 0.66, -4.84, 1.66, 5.05, 1.86, 0.37, 0.79, -0.61, 0.22, 2.62, 0.62, 0.46, 0.97, 1.41, 1.78, 1.9215952380952381, 1.74], ['460', -4.19, -0.21571428571428575, -0.43877828437954125, -0.5, -0.42, -0.83, -3.57, -2.0, -1.64, -2.33, -1.06, 0.43, -0.29, -0.08, 0.02726190476190476, -1.42, -1.15, -1.62, -0.96, -3.6, -2.46, -1.2269251700680273, -0.65, -1.22, -0.62, -1.69, -1.28, 1.5, 0.78, 1.0, 1.1, -0.36, -0.09, -0.57, 0.11, -2.57, -1.41, -0.09000000000000001, 0.42, -0.16, -1.47, 0.08006211180124224, -2.74, -0.72, -0.5, -0.4, -1.84, -1.57, -2.04, -1.38, -4.01, -2.87, -1.65, -0.4385714285714286, -1.63, -1.7, -2.36, -1.56, -1.06, -2.04, 0.22, 0.32, -1.13, -0.86, -1.33, -0.66, -3.32, -2.17, -0.94, -0.36, -0.92, -2.36, -2.25, 0.5202278911564625, -1.35, -1.08, -1.55, -0.88, -3.53, -2.38, -1.16, -0.57, -1.14, -1.5949404761904762, -4.44, 4.48, -2.35, -1.44, -1.18, -1.65, -0.98, -3.426255228898086, -2.48, -1.1642857142857144, -0.67, -1.1859922724755494, -3.62, -0.92, 0.27, -0.20788095238095236, 0.47, -2.21, -1.05, 0.19, 0.78, 0.21, -1.04, -0.95, -1.81, -1.11, -1.24, -0.91, -1.19, -0.48, 0.2, -2.48, -1.32, -0.08, 0.51, -0.06, -0.11, -0.72, 0.68, -2.01, -0.85, 0.4, 0.99, 0.42, -1.18, -0.4, -0.66, -1.05, -10.622047619047619, -1.11, -1.13, 1.9, -1.94, -0.94, -2.01, -0.62, -2.34, 2.21, 1.14, -2.12, -0.34, -3.37, 3.58, 3.33, -1.06, 2.89, -2.21, -0.39, 0.16, -3.53, 8.56, 2.4742857142857146, 3.6514285714285712, 2.42, -1.38, -2.67, -1.52, -0.28, 0.326625850340136, -0.26, -3.15, 1.3201587301587303, 1.19, 2.7071428571428573, 3.07, 2.48, 0.13, 1.26, 1.892857142857143, 1.27, -3.18, -3.4, -1.11, 0.59, 0.02, -1.64, -1.65, -3.33, 4.37, -2.18, -4.36, -1.67, -1.13, -1.69, -0.57, -1.61, -1.18, -0.29, -0.039047619047619046, -0.48, -1.13, -4.27, -1.43, -1.13], ['461', -0.04, -0.92, -0.1, 0.05, 0.1029790809910596, -1.18, -3.8799638336347195, -1.45, -1.79, -0.79, 0.04, 2.37, 1.42, 0.74, 0.47, -0.94, 0.22, -0.05, -0.75, -1.3, -0.62, -0.25, 0.59, 0.53, -3.0, -1.26, -0.84, 2.32, 1.38, 0.7, 0.43, -0.99, 0.18, 0.017258904144408435, -0.79, -1.34, -0.66, -0.3, 0.6388796134390452, 0.49, -2.83, -0.3891024373941227, -3.09, -0.92, -1.59, -1.85, -3.23, -2.1, -2.36, -3.04, -3.58, -2.92, -2.56, -1.74, -1.79, -0.66, -1.97, -0.35217202719021606, -1.16, -2.19, -0.67, -0.94, -2.33, -1.19, -1.45, -2.14, -2.69, -2.01, -1.65, -0.83, -0.88, -1.5, -1.53, -0.27, -1.67, -0.52, -0.79, -1.48, -2.03, -1.35, -0.99, -0.16, -0.1564403582748793, -1.03, -3.84, 3.8, -1.26, -1.41, -0.25, -0.52, -1.22, -1.76, -1.09, -0.72, 0.11, 0.06, -0.24, 0.15, 1.17, 0.9, 0.19, -0.36, 0.33, 0.69, 1.54, 1.49, -0.8, 0.16, -1.79, -1.07, -1.05, -1.12, -1.01, -0.27, -0.97, -1.52, -0.84, -0.47, 0.36, 0.31, -0.62, -0.74, -0.7, -1.25, -0.57, -0.2, 0.64, 0.58, -1.07, -0.86, -0.1, -0.92, -0.76, -0.48, -0.48, 2.01, -2.04, -1.03, -0.65, -2.1738364678879503, -1.01, 2.15, 1.06, 0.0, -0.76, -3.18, 3.04, 3.19, -1.06, 3.11, -2.14, -1.56, 0.81, -2.97, 5.62, 2.06, 3.05, 0.98, -0.05, -0.56, 0.13, 0.5, 1.34, 1.29, -3.18, 0.51, 0.69, 1.06, 1.91, 1.85, -0.18, 0.37, 1.21, 1.16, -1.84, -1.06, -0.54, 0.84, 0.79, -1.08, -1.08, -1.56, 3.31, -1.03, -3.38, -1.66, -0.61, -1.37, -0.05, -1.41, -0.85, -0.94, -0.59, -1.08, -1.32, -1.56, -1.15, -0.67], ['462', -4.7785714285714285, -0.81, -0.23877828437954127, -0.08, -0.45, -0.2, -0.79, -1.14, -0.43, -0.7946428571428571, -0.13, -0.34, 1.27, 0.67, 0.19, 0.1, 1.17, -0.34, 2.14, -0.74, -0.95, 1.75, 2.3, -0.59, 0.47, -1.6, -0.73, -0.2, 1.4, 0.8, 0.32, 0.24, 1.3, -0.21, 2.28, -0.61, -0.82, 1.89, 2.44, -0.46, 0.61, 0.16089756260587734, -0.529795918367347, 1.61, 1.01, 0.52, 0.44, 1.512857142857143, -0.01, 2.49, -0.4088095238095238, -0.62, 2.1, 2.65, -0.26, 0.0, -0.81, -1.22, 0.32, -2.11, -0.59, -1.07, -1.15, -0.1, -1.59, 0.86, -1.98, -2.19, 0.48, 1.02, -1.84, -0.08, -0.8742857142857143, -0.48, -0.56, 0.5, -1.01, 1.46, -1.4, -1.61, 1.73, 1.62, -1.25, -0.8510901360544217, -8.25, 8.24, -1.05, -0.08947959183673469, 0.98, -0.53, 1.95, -0.93, -1.14, 1.56, 2.11, -0.78, -2.63, -0.97, 1.07, -0.45, 2.04, -0.84, -1.05, 1.65, 2.2, -0.69, -0.47, -0.87, -2.35, -0.74, -1.01, -0.55, -2.01, -1.5, 0.96, -1.89, -2.1, 0.58, 1.12, -1.74, -2.55, -0.52, 2.5, -0.4, -0.61, 2.1, 2.66, -0.25, -3.84, -3.63, 0.16, -1.27, -5.24, -0.01, 0.21428571428571427, 1.08, -1.12, -0.57, -2.41, -0.81, 0.31, 1.47, 0.78, -2.2947789115646255, -0.31, -2.54, 2.46, 2.1, -0.76, 1.78, -1.45, 0.71, -0.36, -6.12, 5.23, 4.104285714285715, 6.325714285714286, -0.33, -2.94, -2.82, -3.03, -0.38, 0.16, -2.68, -2.24, -0.13, -0.22, 2.51, 3.07, 0.15, 0.09, 2.73, 3.9157142857142855, 0.37, -0.48, -0.68, -2.57, 0.54, -2.3, -0.86, -0.86, -1.12, 2.65, -2.06, -2.58, -2.18, -1.65, -3.1, -2.83, -0.46, -0.29, 0.3, 0.18, 0.0, -0.27, -3.43, -2.63, -0.82], ['463', -3.03, -0.09, 0.011221715620458745, 0.19, -2.29, -0.24158037632624055, -0.31, -0.74, -0.49, 0.33, 0.48, 1.04, 1.22, 0.88, 1.4, 0.86, 1.05, 0.35, 2.8, 2.39, 0.22733548208735893, 0.55, 1.11, 0.77, -1.06, -0.51, -0.15, 0.55, 0.74, 0.4, 0.91, 0.38, 0.57, -0.12, 2.310714285714286, 1.9, -0.29, 0.07, 0.62, 0.29, -0.38, -0.43506380078382656, -0.7, 0.18, -0.16, 0.36, -0.18, 0.02, -0.67, 1.75, 1.34, -0.84, -0.48, 0.07, -0.26, -1.0, -0.61, 0.07, -0.06, -0.88, -0.34, 0.17, -0.36, -0.17, -0.7573949338599383, 1.56, 1.15, -1.02, -0.67, -0.12, -0.44, -1.05, -0.54, 0.51, -0.02, 0.18, -0.52, 1.91, 1.49, -0.68, -0.33, 0.23, -0.1, -0.44, -2.17, 2.13, -1.05, -0.53, -0.34, -1.03, 1.39, 0.98, -1.19, -0.83, -0.29, -0.61, -0.32, -0.52, 0.2, -0.5, 1.93, 2.132857142857143, -0.66, -0.31, 0.25, -0.08, -0.01, -0.59, -1.68, -0.29, -0.52482093036566, -0.09, -0.72, -0.6886530612244898, 1.73, 1.32, -0.86, -0.5, 0.05, -0.28, -0.15346392892821453, -0.02, 2.693685580292723, 2.02, -0.16, 0.19, 0.75, 0.42, -1.73, -1.7972380952380953, 0.41, -0.86, -0.722047619047619, -0.13, -0.07, 0.3, -0.32, -0.14, -0.26, -1.37, 4.14, 0.61, 0.3, -1.49, -0.11, -0.88, 0.92, 0.9, -0.28, 0.46, -0.63, -1.92, 0.99, -2.11, -0.81, 1.46, 2.12, -3.98, -2.4, -0.4, -2.54, -2.19, -1.65, -1.97, -0.9, -2.01, -2.14, -1.79, -1.249142857142857, -0.9314285714285715, 0.14, 0.36, 0.91, 0.58, -0.46, -0.32, -0.22, 0.55, 0.22, -0.31, -0.39, -0.5574239503761216, 0.22, -1.35, -0.6, -1.2, -0.59, -0.77, -0.25721314850306837, -0.2999225974772193, -0.07, 0.17, -0.55, 0.35, -0.354042472976186, -2.28, -0.89, -0.75], ['464', -1.13, 1.35, 0.42122171562045874, 0.09, 0.6629790809910596, 0.67, 1.5641152579598292, 0.7, 1.0593780543870106, 0.59, -0.24, -0.19, -1.28, 1.12, -0.74, 0.3, -0.59, 0.24, -1.27, -0.75, 0.28, 0.48, -0.44, 0.78, 1.24, 0.52, 0.83, 0.05, -1.05, 1.36, -0.4421800287049088, 0.54, -0.35, 0.48, -1.03, -0.51, 0.52, 0.72, -0.2, 1.02, 1.58, 1.9849361992161734, 0.78, -1.1, 1.31, -0.47918497042472347, 0.49, -0.4, 0.43, -1.08, -0.56, 0.498065468086443, 0.67, -0.25, 0.97, 0.94, 1.45, 1.02, 0.69, 1.89, 2.43, 0.55, 1.61, 0.7, 1.54, 0.02, 0.54, 1.58, 1.79, 0.85, 2.09, 0.55, -0.53, -1.84, -0.81, -1.69, -0.87, -2.36, -1.84, -0.83, -0.63, -1.54, -0.33, 1.17, 2.83, -2.89, 1.34, 1.05, 0.15, 0.99, -0.53, -0.01, 1.02, 1.23, 0.3, 1.5840077275244506, -0.34, 0.28, -0.89, -0.06, -1.57, -1.05, -0.03, 0.18, -0.74, 0.48, 0.43, 0.32, 1.74, 0.8, 1.06, 0.5, 1.18, 0.9665993906886764, -0.68, -0.16, 0.87, 1.08, 0.15, 1.38, 0.27, 0.35, -1.5, -0.98, 0.04, 0.24, -0.68, 0.54, 1.2089583699631243, 1.37, 0.27603717887804047, 0.6, -1.02, 0.23, 0.41, -1.0, 0.95, 0.5, 0.8240662734668153, 0.56, -2.72, -1.56, -0.82, -0.53, 0.41, 2.24, -2.33, -2.44, 0.8, -1.51, 1.56, -0.32, 0.19, 3.46, -1.89, -2.37, -3.48, 2.74, 1.88, 0.53, 1.56, 1.811610544217687, 0.84, 2.08, 2.37, 1.34, 1.03, 1.24, 0.31, 1.54, 0.31, 0.2, -0.71, 0.51, 0.98, 0.79, 0.1, -0.92, 0.3, 0.82, 0.76, 0.63, -0.39, 1.25, 0.42, 0.93, 1.77, 1.03, 1.23, 1.0600774025227806, 0.53, 0.67, 1.1, 1.29, -0.2, 2.13, 3.13, -0.82], ['465', 1.49, -1.57, 0.2912217156204588, -0.28, 0.97, 0.7384196236737595, 2.2141152579598296, 0.8, 1.29, 1.94, 0.78, 0.2393248299319728, 1.48, 1.59, 0.93, 2.01, 0.51, 1.83, -0.12, -0.32, 2.0, 2.81, 0.75, 0.67, 0.81, 1.62, 1.1826583949931124, -0.54, 0.7, 0.81, 0.15, 1.22, -0.26, 1.05, -0.89, -1.09, 1.22, 2.02, -0.03, -0.11, 1.29, 2.61, 1.7, 1.25, 1.36, 0.69, 1.77, 0.28, 1.6, -0.35, -0.55, 1.77, 2.57, 0.52, 0.44, 0.1, 0.15, 0.81, 0.8, 0.44, 0.1, -0.55, 0.52, -0.96, 0.34, -1.59, -1.7797619047619049, 0.51, 1.31, -0.72, -0.8, 0.9, 0.34, -0.65, 0.41, -1.06, 0.24, -1.69, -1.88, 0.41, 1.2, -0.83, -0.91, 1.84, 2.79, -2.72, 1.0, 1.07, -0.41, 0.9, -1.04, -1.24, 1.07, 1.87, -0.17, -0.26, 0.98, -0.07, -1.46, -0.17, -2.0544149659863944, -2.29, 0.0, 0.79, -1.23, -1.31, -0.02, -0.11, 1.57, 0.8715981806829014, 0.93, 0.8, 1.41, 1.31, -0.64, -0.83, 1.48, 2.28, 0.23, 0.15, -0.82, 0.15307674813036726, -1.92, -2.12, 0.17, 0.96, -1.06, -1.14, 1.82, 1.43, -0.59, 1.34, 3.09, 0.14, -0.1, -2.19, 2.15, 1.09, -0.69, 1.74, -4.44, -1.65, -0.85, 0.74, -0.08, 2.47, -2.46, -2.45, 0.863290804863853, -3.27, 1.6998783572413152, 2.46, -1.27, 4.26, -1.42, -2.9, -4.24, 4.62, 2.06, -0.2, 2.13, 2.94, 0.88, 0.79, 2.4608051948051948, 2.27, 2.33, 3.14, 1.08, 1.0, -0.07, 0.8788785911064217, -1.23, -1.31, 1.27, 1.21, -0.85, -2.0, -2.08, 0.78, 0.93, 0.72, 0.84, 1.95, -0.73, 1.3472638105244332, 1.78, 1.18, -0.08, 1.35, 0.87, -0.10470204795204777, -0.42, 0.09, 1.26, 2.12, 3.04, 1.66], ['466', 8.66, 0.95, 0.26122171562045876, -0.12, 3.89, 1.85, 2.3041152579598294, 3.68, 3.47, 5.28, -0.16, 3.53, 2.79, 0.41, 2.24, 2.38, 2.23, 4.62, 4.66, -1.35, 6.75, 3.06, 3.18, 3.59, 3.68, 2.83, 5.482658394993113, 3.7, 2.960119047619048, 0.57, 2.457819971295091, 2.55, 2.4, 4.79, 4.83, -1.19, 6.92, 3.23, 3.34, 3.75, 2.32, 7.524936199216174, 1.68, -0.72, -3.02, -1.25, -1.11, -1.26, 1.05, 1.09, -4.71, 3.11, -0.46, -0.34, 0.05, 2.37, 2.67, 3.3, 2.2, 2.42, -2.32, -0.54, -0.39, -0.54, 1.78, 1.82, -4.02, 3.86, 0.32965816326530617, 0.38, 0.78, 4.03, 4.85, 1.82, 1.97, 1.82, 4.2, 4.24, -1.75, 6.761853741496599, 2.8671428571428574, 2.76, 3.16, 5.92, 6.01, -5.82, 3.0066982383853205, 0.14052040816326533, -0.01, 2.33, 2.37, -3.5, 4.42, 0.81, 0.92, 1.3740077275244507, 3.09, 2.83, -0.15, 2.19, 2.23, -3.64, 4.27, 0.66, 0.78, 1.18, 0.73, 2.89, 3.94, 2.11, 2.0, 2.31, 2.98, 2.4765993906886763, 2.38, -3.5, 4.42, 0.81, 0.93, 1.32, 1.89, 0.63, 0.04, -5.7, 2.04, -1.49, -1.38, -0.99, 2.0, 2.11, 0.03, 2.76, 9.27, 0.1, 0.02, -5.32, 5.29, 2.65, 0.28, 4.43, -13.65, -4.17, -2.11, 4.17, 1.18, 6.19, -6.22, -6.34, 2.12, -7.91, 4.13, 3.08, -1.52, 8.85, -8.74, -5.9, -8.74, 12.95, 0.59, -5.74, 2.0, -1.53, -1.42, -1.03, 6.41, 6.71, 8.21, 4.47, 4.59, 5.0, -1.38, -3.46, -3.35, -2.97, 3.51, 4.13, 2.15, 0.11, 0.51, 1.98, 2.334396301275291, 3.64, -5.34, 3.8, 5.39, 2.5218948994148556, 2.33, 2.03, 0.39, 3.08, 2.54, 1.55, 0.35, 1.55, 1.7159575270238139, 3.71, 3.53, 3.59], ['467', -8.035714285714285, -0.34, 0.11015289830927054, 0.2, -1.12, -0.18, -1.13, -1.74, -0.36, -1.92, -1.09, -2.08, -0.32, -0.89, -0.99, 1.8810714285714285, -1.3, -1.85, -3.41, 0.39, -1.87, -1.81, -1.29, -2.13, -0.8, -1.55, -0.8073416050068876, -1.0, 0.78, 0.2, 0.1, 3.0, -0.21, -0.6527410958555916, -2.35, 1.5, -0.715546329921431, -0.73, -0.2, -1.06, -0.08, -0.48, 0.17, 1.8, 1.21, 1.12, 4.05, 0.8, 0.24, -1.36, 2.53, 0.21, 0.28, 0.81, -0.05, -1.68, -0.86, -1.36, 0.0, -1.6, -0.58, -0.67, 2.21, -0.98, -1.53, -3.1, 0.71, -1.56, -1.5, -0.97, -1.82, -3.2, -1.03, -0.1, 3.236658163265306, -0.41, -0.96, -2.54, 1.3, -0.99, -0.93, -0.4, -1.25, -0.56, -1.94, 1.92, -0.94, 2.9, -0.31, -0.87, -2.45, 1.4, -0.89, -0.83, -0.3, -1.16, -4.73, -3.73, -3.12, -3.66, -5.19, -1.46, -3.68, -3.593605339105339, -3.11, -3.94, -0.07, -3.81, 0.0, -0.43, -0.53, -0.33, -0.5581905235138708, -0.56, -2.14, 1.71, -0.58, -0.52, 0.01, -0.85, -0.11, -0.07, -1.59, 2.28, -0.03, 0.04, 0.57, -0.29, -1.54, -0.95, 0.44, -0.6, -14.15, 0.04, 0.11, 0.4, -0.4, -0.2, -0.29, -1.21, 4.56, 0.87, 0.46, -4.385357142857143, 0.03, -1.45, 1.46, 1.37, -0.41, 0.7, -0.89, -2.76, 1.36, -1.82, 0.0, 1.26, 1.83, -4.42, 1.55, 3.94, 1.59, 1.701610544217687, 2.2, 1.32, -1.3, -2.3, -2.26, -2.2, -1.67, -2.52, -0.04, 0.06, 0.6, -0.26, -0.34, -0.36, -0.022725315092565576, 0.53, -0.33, -0.41, -0.49, -1.43, -0.32, 0.04033326278406317, 0.28, -1.75, -1.64, -0.64, -0.86, -0.67, -0.56, 0.15, 0.25, 0.07, 0.305957527023814, -2.75, -2.18, -0.36], ['468', 1.49, 0.65, -0.4, 0.21, 0.2929790809910596, -0.22, -2.91, 0.17, -0.02, 0.86, 0.4, 1.34, 0.45, 1.12, 0.76, -0.08, 0.69, 0.73, 5.22, -0.52, 2.21, -0.02, 0.47, 0.68, 0.09, 0.33, 0.46, 0.94, 0.05, 0.72, 0.36, -0.47, 0.3, 0.34, 4.81, -0.91, 1.8, -0.41, 0.08, 0.28, -0.26, -1.3350638007838267, -0.47, -0.88, -0.21, -0.57, -1.4, -0.64, -0.6, 3.83, -1.83, 0.86, -1.34, -0.86, -0.65, 0.64, -0.74, 0.07, -0.3, 0.41, 0.67, 0.32, -0.52, 0.25, 0.29, 4.76, -0.9597619047619047, 1.75, -0.46, 0.03, 0.23, 0.02, -0.26, -0.36, -1.19, -0.42, -0.38, 4.307476448155019, -1.62, 1.07, -1.13, -0.64, -0.44, 0.15, 1.12, -1.02, 0.1, -0.83, -0.07, 0.5971428571428571, 4.43, -1.27, 1.43, -0.77, -0.29, -0.08, 1.5, 0.94, 0.77, 0.81, 5.3, -0.44, 2.28, 0.06, 0.55, 0.75, 0.22, 1.1, 1.73, 0.07, 0.14, 0.09567351865003196, 0.1709570400359874, 0.04, 4.5, -1.2, 1.5, -0.7, -0.22, -0.02, 1.01, 0.12, 4.46, -1.24, 1.46, -0.74, -0.26, -0.06, 0.14, 0.0, 0.58, 0.543186783623568, 4.677738095238095, 0.13, 0.07, 0.68, -0.71, -0.36, 0.88, 0.08, -2.62, -0.17, -0.07, 0.83, 0.29, -0.02, -0.18, -0.24, 0.09, 0.99, 0.07, -1.14, 0.51, 0.7963956916099773, 5.18, -0.38, -0.51, 2.72, -4.15, -5.45, -2.87, -4.98, -4.52, -4.32, 0.41316789956075695, 1.38, 2.73, 0.5, 0.99, 1.2, -1.32, -2.17, -1.7, -1.49, -0.03, 0.06, 0.88, 0.49, 0.7622487553150162, 0.07, 0.12, 0.18, 2.44, 1.37, -2.44, 0.23, -0.11, 0.39, 0.21, 0.12, -0.41, -0.4, 0.72, 0.74, 0.18, 0.08, -0.13, -0.05], ['469', -4.6, -0.68, 0.0, 0.14, -1.0, -0.53, -0.71, -1.57, -0.68, -3.41, -1.99, -3.8, -2.15, -1.53, -1.86, -2.97, -2.4, -3.57, -1.15, -1.67, -3.54, -2.13, -2.235694768399324, -3.09, -0.9414063389924735, -1.44, -1.45, -1.85, -0.17, 0.46, 0.12, -1.0066496598639456, -0.42, -1.62, 0.85, 0.32, -1.59, -0.15, -0.35, -1.12, -0.48253157464678914, -1.41, 0.4, 1.71, 2.35, 2.01, 0.86, 1.45, 0.24, 2.75, 2.21, 0.298065468086443, 1.73, 1.53, 0.74, -0.5, -0.65, -0.13217202719021603, -1.0, -1.29, 0.63, 0.29, -0.84, -0.26, -1.45, 1.02, 0.49, -1.42, 0.02, -0.18, -0.96, -1.26, -1.91, -0.34, -1.46, -0.88, -2.07, 0.38, -0.14, -2.04, -0.61, -0.81, -1.58, -1.32, -2.92, 2.99, -1.5433017616146798, -1.13, -0.55, -1.74, 0.72, 0.2, -1.71, -0.28, -0.48, -1.25, -1.73, -0.45, 0.59, -0.62, 1.87, 1.34, -0.59, 0.86, 0.66, -0.12, 0.22, -0.44, -1.79, -0.69, -0.87, -0.534326481349968, -1.0390429599640125, -1.2, 1.28, 0.7505357142857143, -1.17, 0.27, 0.07, -0.7, -1.24, 0.16, 2.51, 1.97, 0.03, 1.49, 1.29, 0.5, -1.49, -1.63, -0.16, -1.03, -5.23, -0.2196768707482993, -0.17, 0.26, -0.28, -0.13, -0.7, -2.38, 3.49, 1.39, 0.72, -2.33, -0.15, -2.2, 2.21, 2.29, -0.7, 0.63, -1.4, -0.48, 0.23, -3.129285714285714, -16.57, 2.05, 3.13, -3.64, -2.28, -0.52, -2.42, -0.99, -1.19, -1.96, -2.06, -1.77, -1.9, -0.47, -0.67, -1.44, 0.14, 1.46, 1.26, 0.47, -0.71, -1.12, -1.31, -0.2, -0.8977512446849837, -0.7, -0.78, -1.51, 3.27, -1.49, -3.37, -1.6981051005851444, -2.33, -1.11, -0.77, -1.28, -0.17, 0.09, -0.29, -0.12, -0.34, -3.17, -3.38, -0.63], ['470', -0.55, 1.15, 0.011221715620458745, -0.07, 0.15, 0.03, 1.62, -0.01, 0.22, 0.4, 0.23, -0.28, -0.36, 0.77, 0.37, 0.87, 0.08, 0.3, 1.8, 0.28, 0.16, -0.4, 0.18, -0.26, 0.53, -0.07, 0.16, -0.52, -0.59, 0.54, 0.14, 0.63, -0.15, 0.07, 1.57, 0.04, -0.07, -0.64, 0.03887961343904518, -0.5, -0.36, -0.34, 0.68, -0.07, 1.06, 0.66, 1.15, 0.37, 0.59, 2.09, 0.56, 0.45, -0.12, 0.46, 0.02, -0.26, -0.65, -2.41, -0.43, 0.76, 1.13, 0.73, 1.23, 0.44, 0.66, 2.17, 0.64, 0.52, -0.05, 0.54, 0.09, -0.48, -0.37, -0.4, 0.09, -0.69, -0.47, 1.02, -0.49, -0.61, -1.17, -0.59, -1.03, 0.15, 0.99, -0.98, 0.03, 0.5, -0.29, -0.07, 1.43, -0.09, -0.21, -0.77, -0.19, -0.63, -1.54, -0.46, -0.78, -0.56, 0.93, -0.58, -0.7, -1.26, -0.68, -1.12, 0.1, -0.41, 1.74, 0.28, 0.19, 0.4, 0.32, 0.22, 1.72, 0.2, 0.2557782534925394, -0.49, 0.09, -0.35, 0.9765360710717854, 0.1, 1.5, -0.02, 0.038603019995877313, -0.7, -0.12, -0.56, 0.38, 0.13, 0.04, 0.43, -4.45, -0.06, -0.11, -0.42, 0.42, 0.21, 0.12, 0.82, -0.21948175112272847, -0.54, -0.29, -0.3, 0.25, 0.81, -0.79, -0.86, 0.26, -0.59, 0.54, 0.78, -0.42, 0.95, -3.77, -0.68, -0.93, 0.28, -1.38, -1.5, -1.61, -2.17, -1.6, -2.03, 0.82, 0.12, -0.12, -0.68, -0.1, -0.54, 0.24, -0.57, 0.01, -0.43, 0.2227953514739229, 0.08, 0.8972746849074344, 0.58, 0.14, 0.27, 0.29, 0.04, -2.13, 1.54, 2.18, 0.13, 0.36, 0.22043171114599686, -0.36721314850306835, 0.27, 0.07, 0.83, 0.18, -0.22, 0.67, -0.13, 0.89, 0.48], ['471', -1.75, 0.02, 0.20015289830927055, -0.04, -1.0, 1.03, 0.9641152579598291, 0.9117205965359587, 1.6, 1.14, -0.59, 0.08, 0.69, 0.77, 0.08, 1.78, 0.18, 0.56, -0.24, 0.76, 1.697335482087359, 0.5, 0.74, 0.31, 2.18, 0.96, 1.74, 0.67, 1.28, 1.37, 0.67, 2.38, 0.77, 1.16, 0.36, 1.36, 2.27, 1.1, 1.34, 0.91, 1.31, 2.44, 1.06, 0.61, 0.69, 0.0, 1.7, 0.1, 0.48, -0.21286444351387962, 0.69, 1.59, 0.43, 0.67, 0.23, 0.99, 1.33, 1.0, 1.54, 0.45, 0.08, -0.6, 1.08, -0.51, -0.13, -0.92, 0.07, 0.97, -0.18, 0.06, -0.37, 0.99, 0.37, -0.68, 1.0, -0.59, -0.2, -1.0, -0.01, 0.89, -0.26, -0.02, -0.45, 2.02, 0.9, -0.91, 1.06, 1.7, 0.1, 0.48, -0.32, 0.68, 1.58, 0.42, 0.67, 0.23, 0.35, -0.63, -1.57, -1.19, -1.98, -1.0, -0.11, -1.25, -1.01, -1.44, 0.6, -0.73, 0.16, 0.85, 0.78, 0.95, 0.96, 0.38, -0.41, 0.58, 1.49, 0.33, 0.57, 0.13, 0.63, 0.58, -0.79, 0.2, 1.1, -0.06, 0.18, -0.25, 0.29, 0.87, 0.17, 0.89, 0.58, 0.33, 0.42, -2.36, 2.39, 1.19, 0.55, 0.31, -0.73, -1.66, -0.88, -0.85, 0.44, 2.61, -2.62, -2.56, 0.86, -3.49, 1.7, 0.11, 0.03476526428424678, 2.88, -8.55, -1.96, -2.86, 0.69, 1.38, 1.0, 1.91, 0.74, 0.98, 0.55, 2.66, 0.38, 0.9, -0.26, -0.02, -0.45, -0.52, -1.14, -0.9, -1.33, 1.682795351473923, 1.65, 0.63, 0.24, -0.19, 0.87, 0.89, 0.89, -4.25, 0.5, 4.33, 1.16, 1.04, 0.39, -0.43, 1.56, 1.18, 0.55, 0.15, 0.37, 0.83, 1.76, 0.84, 0.66], ['472', -6.98, 0.13, -0.25, 0.11, -1.04, -1.5, -1.29, -2.25, -2.48, -2.24, 0.66, -1.02, -0.35608673487915105, -0.41, 0.49, -1.3, -0.34, -1.48, -3.86, 0.49, -3.162664517912641, 0.39, -0.3, -0.5, -2.28, -2.45, -2.88, -1.66, -1.07, -1.06, -0.16, -1.94, -0.99, -2.12, -4.04429761904762, -0.17, -3.83, -0.27, -0.96, -1.15, -2.7, -3.3, -1.24, 0.6, 0.61, 1.52, -0.28, 0.68, -0.47, -2.87, 1.52, -2.21, 1.42, 0.72, 0.52, -0.8199371536943234, -2.44, -3.1, -3.01, -1.83, 0.01, 0.92, -0.88, 0.08, -1.06, -3.45, 0.92, -2.79, 0.81, 0.12, -0.08, -3.12, -1.84, 0.91, -0.89, 0.07, -1.07, -3.47, 0.9, -2.8, 0.8, 0.11, -0.03644035827487928, -3.33, -5.78, 5.83, -2.72, -1.78, -0.83, -1.96, -4.33, 0.0, -3.67, -0.1, -0.79, -0.99, -2.34, -0.8826334687834371, 0.97, -0.19, -2.6, 1.81, -1.93, 1.7, 1.0, 0.81, -0.67, -0.93, -2.61, -1.54, -1.56, -1.54, -1.8381905235138707, -1.14, -3.53, 0.83, -2.87, 0.73, 0.04, -0.16, -2.52, -0.77, -2.42, 2.0, -1.75, 1.89, 1.19, 0.99, -2.31, -2.26, -0.04, -1.596813216376432, -4.62, -0.22, -0.16, 2.76, -2.78, -1.4, -1.26, -1.88, 5.27, 3.07, 1.55, -3.54, -0.93, -4.56, 4.63, 4.56, -1.466709195136147, 4.25, -3.07, -1.57, 0.77, -5.72, 8.58, 3.85, 5.71, -5.292869047619047, 1.68, 4.52, 0.69, 4.42, 3.7, 3.5, -4.52, -2.72, -3.67, -0.1, -0.79, -0.98, 0.99, 3.798878591106422, 2.99, 2.79, -2.6, -3.05, -2.62, -0.69, -0.88, -1.53, -1.61, -2.2, 4.16, -2.53, -4.2, -1.42, -2.02, -1.94, -0.2, -1.68, -1.23, -0.99, -0.38, -1.75, -1.75, -1.29, -1.86, -1.85], ['473', 2.3, 0.25, 0.18122171562045875, -0.14, 0.3329790809910596, 0.3, 0.97, 0.37, -0.35, 2.89, 3.56, 2.48, 2.14, 3.39, 1.94, 2.29, 1.14, 2.66, 2.44, 2.41, 1.87, 2.18, 1.644305231600676, 2.15, 0.12, 0.49, -0.65, -1.04, -1.37, -0.17, -1.56, -1.23, -2.33, -0.87, -1.08, -1.11, -1.63, -1.33, -1.94, -1.36, 0.17, -2.5050638007838266, 0.4, -0.33, 1.057875394446823, -0.52, -0.19, -1.31, 0.18, -0.04, -0.07, -0.5803452707629391, -0.29, -0.91, -0.32, 0.0, -0.24, 0.13, -0.24, 0.73, 1.22, -0.2, 0.14, -0.98, 0.51, 0.29, 0.26, -0.26, 0.04, -0.58, 0.01, 0.23, -0.48, -1.4, -1.06, -2.17, -0.71, -0.92, -0.95, -1.47, -1.17, -1.78, -1.2, -1.08, 3.49, -3.53, 0.93, 0.34, -0.78, 0.7, 0.49, 0.46, -0.07, 0.24, -0.39, 0.21, -0.04, 0.59, -1.12, 0.36, 0.15, 0.12, -0.41, -0.1, -0.72, -0.13, 0.28, 0.63, 3.6, 0.61, 0.72, 0.56, 1.73, 1.5, 1.28, 1.25, 0.72, 1.03, 0.4, 1.0585846838830657, 0.9265360710717855, 0.27307674813036725, 0.04368558029272332, -0.24, -0.77, -0.46, -1.08, -0.49, 2.0189583699631246, 1.98, -0.19396282112195956, 1.17, -0.29, 0.26, 0.13, -1.05, 1.03, 0.5788101710076211, 0.43, 0.52, -0.88, -1.3, -0.6, 1.25, 0.39, 1.8914761904761903, -1.9, -1.8, 0.6, -1.55, 1.24, 0.92, -0.5, 5.09, -3.79, -3.43, -5.18, 0.9, 0.44, -0.03, -0.55, -0.25, -0.87, -0.28, 1.79, 0.47, -0.38580741107631855, -0.22, -0.84, -0.25, 1.0, 0.31, -0.32, 0.28, -0.36, -0.76, 0.69, -0.62, -0.03, 0.59, 0.71, 0.43, -3.95, 2.62, 3.85, 0.4918948994148555, 0.54, 1.32, 0.6, 0.7200774025227806, 0.52, 0.3, 0.43, 0.42, 0.72, 2.86, 1.38, 1.25], ['474', -0.72, 0.41, 0.12, -0.1, 0.11, 0.1484196236737595, 0.24411525795982916, 0.09, -0.16, -0.08, 0.19, 0.05, 0.61, 0.67, -0.56, -0.14, -0.72, -0.1, 1.35, -0.66, -0.28, -0.53, -1.22, -0.48, -0.91, 0.36, -0.27, -0.14, 0.41, 0.48, -0.75, -0.33, -0.91, -0.29, 1.16, -0.85, -0.47, -0.72, -1.41, -0.67, 0.39, -0.38, -0.13, 0.56, 0.63, -0.6, -0.18, -0.77, -0.15, 1.3, -0.71, -0.301934531913557, -0.58, -1.2357142857142858, -0.53, 6.07, 0.42, 0.017827972809783946, 0.05, -0.68, 0.07, -1.15, -0.74, -1.32, -0.7, 0.74, -1.26, -0.88, -1.13, -1.82, -1.08, -0.41, -0.75, -1.22, -0.8, -1.38, -0.77, 0.67, -1.33, -0.95, -1.19, -1.88, -1.15, -0.23, 2.8, -2.83, 0.48, 0.42, -0.16, 0.46, 1.92, -0.11, 0.28, 0.03, -0.67, 0.07, 0.0, 0.06, -0.58, 0.03, 1.49, -0.53, -0.15, -0.39, -1.09, -0.35, -0.04, 0.07, 0.76, 0.38, 0.46, 0.29567351865003194, 0.64, 0.62, 2.09, 0.06, 0.44, 0.19, -0.51, 0.24, 0.35, 0.07307674813036727, 1.46, -0.56, -0.17043764172335601, -0.42, -1.12, -0.38, 0.92, 1.16, -0.09, 0.53, 0.01, 0.05, 0.04, -1.06, 1.1417201258125629, 0.51, 0.16, -0.18, -1.18, -0.75, -0.36, -0.35, -0.57, 1.14, -1.16, -1.12, 0.37, -1.55, 0.76, 0.83, -0.41, 1.91, -4.38, -1.29, -1.98, 1.23, -1.41, -1.99, -1.61, -1.86, -2.54, -1.6442382871563543, 1.12, 0.59, 0.39, 0.14, -0.56, 0.18, 0.2, -0.25, -0.94, -0.2, -0.1, -0.06, 0.45, -0.7, 0.04, 0.37, 0.42, 0.20257604962387837, -2.05, 0.8, 2.12, 0.2, 0.83, 1.16, 0.75, 0.58, 0.59, -0.67, -1.04, -0.23, 0.41, 0.29, 0.85, 0.13], ['475', -4.772857142857143, -0.07, -0.04, 0.18, -1.52, -1.12, 0.5, -1.29, -0.63, -1.04, 0.61, -1.8, -0.58, 0.55, 0.39, 0.42, 0.29, -0.85, 2.45, 2.3, -1.32, -1.04, 0.4, 0.26, -1.83, -1.35, -1.64, -2.39, -1.18, -0.06, -0.22, -0.19, -0.31, -1.45, 1.83, 1.67, -1.92, -1.64, -0.21, -0.35, -1.06, -0.19, 0.7702040816326531, 1.24, 2.39, 2.23, 2.26, 2.13, 0.96, 4.33, 4.17, 0.48, 0.77, 2.24, 2.1, -0.57, -0.5, -0.84, -1.25, -0.46, 1.14, 0.98, 1.0, 0.88, -0.27, 3.05, 2.89, -0.75, -0.46, 0.99, 0.85, -1.31, -1.58, -0.16, -0.13, -0.25, -1.39, 1.89, 1.74, -1.86, -1.58, -0.15, -0.29, -1.04, -3.71, 3.73, -1.43, 0.03, -0.1, -1.24, 2.05, 1.9, -1.71, -1.43, 0.01, -0.13, -3.54, -1.45, -0.12, -1.26, 2.02, 1.87, -1.73, -1.45, -0.02, -0.16, 0.061141873999016993, -1.5, -0.31, -1.09, -0.93, -1.24, -1.33, -1.0034006093113235, 2.15, 1.99, -1.61, -1.33, 0.11, -0.03, -0.08, -0.19, 3.33, 3.17, -0.48, -0.19, 1.26, 1.12, -1.53, -1.16, 0.35, -0.99, -10.61, -0.03, 0.14, 3.65, -3.63, -1.83, -0.21, -2.27, 6.38, 2.19, 1.1, -2.3747789115646256, -0.55, -3.35, 3.21, 3.33, -1.1, 5.45, -2.18, -1.22, 0.58, -3.89, 2.26, 2.57, 3.83, -6.28, -3.41, -0.15, -3.68, -3.41, -2.0, -2.14, -3.26, -3.26, -3.54, -3.26, -1.85, -1.99, 0.29, 0.29, 1.75, 1.6, -0.61, -1.07, 0.0, 1.46, 1.32, -1.07, -1.09, -1.35, 0.95, -0.39, -1.17, -0.96, -0.56, -1.44, -0.14, -1.09, -1.56, -0.32, 0.12022448979591838, -1.03, -1.3, -0.66, -0.37, -1.36], ['476', 5.09, 0.8, 0.011221715620458745, -0.1, 0.64, 0.56, 0.0, 1.4, 0.54, -0.03, -0.36, 0.801934498041641, -1.35, -2.18, -1.97, -0.84, -0.22, -0.22, 1.57, -0.8, 0.48, -0.18, -0.6, 0.03, 2.0, 1.49, 0.33, 0.96, -1.0, -1.83, -1.62, -0.49, 0.13, 0.13, 1.93, -0.45, 0.84, 0.18, -0.25, 0.38, 0.52, 1.77, -0.62, -1.94, -2.76, -2.55, -1.43, -0.82, -0.82, 0.971652133580705, -1.39, -0.12, -0.78, -1.19, -0.57, 1.11, 1.01, 0.15, 0.83, 1.34, -0.84, -0.62, 0.52, 1.15, 1.14, 2.96, 0.56, 1.86, 1.19, 0.76, 1.4, 1.0, 2.2, 0.22, 1.37, 2.0, 2.0, 3.83, 1.41, 2.72, 2.04, 1.61, 2.26, 0.87, 1.26, -1.29, 1.98, 1.15, 1.78, 1.78, 3.61, 1.19, 2.5, 1.82, 1.39, 2.04, 3.92, 0.82, 0.63, 0.62, 2.43, 0.04, 1.33, 0.67, 0.24, 0.88, 0.26, 0.9593682032253462, -0.73, 0.53, 0.52, 0.51, 0.19, 0.0, 1.8, -0.58, 0.7, 0.04, -0.38, 0.25, 0.11, 0.2, 1.8, -0.58, 0.7, 0.04, -0.38, 0.25, 0.38, 0.0, 0.12, 0.22, 11.79, 0.02, -0.02, -1.62, 1.63, 0.82, -0.06, 1.3661635321120496, -1.45, -1.02, -0.55, 2.51, 0.2, 1.61, -1.62, -1.55, 0.54, -2.4, 1.06, 0.26, -0.055234735715753214, 0.64, -3.65, -0.44, -0.61, 1.47, -1.57, -2.33, -1.07, -1.72, -2.14, -1.52, 1.51, 0.78, 1.29, 0.62, 0.2, 0.83, -0.5, -0.66, -1.07, -0.45, 0.57, 0.72, 0.15, -0.42, 0.21, 0.55, 0.47, 1.4425760496238782, -1.69, -0.68, 1.67, 1.2, 1.05, 0.58, 0.63, 0.34, 0.81, 0.19, 0.08, 0.59, -0.06, 3.63, 1.42, -0.28], ['477', -1.49, 0.06, 0.05122171562045875, 0.05, -0.14, 0.82, 1.79, 0.29, 1.26, 1.2, 0.3, -0.18, 0.64, 0.47, 1.15, 1.41, 0.25, 1.23, 0.1, 1.17, 1.1, 0.31, 0.32, 0.76, 1.67, 0.14, 0.9, -0.48, 0.33, 0.17, 0.85, 1.1, -0.05, 0.92, -0.2, 0.87, 0.8, 0.01, 0.02, 0.45, -0.86, 1.9700621118012422, 1.38, 0.81, 0.65, 1.33, 1.59, 0.43, 1.4, 0.28, 1.35, 1.28, 0.49, 0.5, 0.94, 0.85, 0.51, 0.52, 0.78, 0.56, -0.17, 0.51, 0.77, -0.38, 0.59, -0.53, 0.6539757335335068, 0.46, -0.32, -0.32, 0.12, 0.76, 0.73, 0.68, 0.93, -0.22, 0.75, -0.37, 0.7, 0.63, -0.16, -0.15, 0.29, 1.61, 2.34, -2.24, 0.05, 0.3480874332127649, -0.89, 0.08, -1.04, 0.2137447711019141, -0.04, -0.83, -0.82, -0.39, -0.34, -0.2, -1.14, -0.18, -1.29, -0.23, -0.3, -1.08, -1.07, -0.64, 0.04, -0.17, 0.89, 0.73, 0.71, 0.76, 0.9509570400359874, 0.97, -0.14984126984126983, 0.91, 0.85, 0.06, 0.07, 0.5585846838830657, 0.78, -0.02, -1.11, -0.05, -0.12, -0.9, -0.9, -0.46, 0.86, 0.83, 0.04, 0.8, -0.84, 0.11, 0.0, -1.62, 1.63, 0.82, 0.54, 0.34, -0.01, -1.4, -0.69, -0.75, 0.75, 2.18, -2.12, -2.17, 0.74, -2.43, 1.46, -0.39, 0.19, 2.82, -4.59, -1.86, -2.77, 0.0, 1.1, 1.07, 1.0, 0.21, 0.22, 0.66, 2.16, 0.03, -0.07, -0.85, -0.84, -0.41, 0.1, -0.78, -0.78, -0.34, 1.26, 1.32, 0.89, 0.01, 0.44, 0.73, 0.75, 0.31, -2.73, 1.0501996269574994, 2.69, 1.19, 0.74, 0.88, 0.44, 0.67, 1.06, 0.41, 0.93, 0.39, 0.44, 0.0, 1.33, -0.01], ['478', 3.22, -0.08, -0.17877828437954127, 0.08, -0.33, -0.6115803763262405, -0.71, -1.88, -1.79, -1.61, 1.58, -0.41, -0.11, -0.08, 0.38, -3.39, -0.41, -1.89, -2.3, -1.47, -2.63, -1.14, 0.26, -0.75, -1.85, -0.61, -3.14, -1.96, -1.66, -1.63, -1.18, -4.89, -1.96, -3.42, -3.81, -3.0, -4.149239316239316, -2.68, -1.3, -2.246158276802161, -1.66, -2.3550638007838267, -1.2, 0.3, 0.34, 0.8, -2.99, 0.0, -1.169454081632653, -1.89, -1.06, -2.23, -0.73, 0.67, -0.34, -0.9299371536943234, -1.75, -1.5321720271902162, -1.0, -1.5, 0.04, 0.49, -3.28, -0.3, -1.6773949338599383, -2.19, -1.36, -2.52, -1.03, 0.37, -0.64, -2.44, -1.53, 0.46, -3.31, -0.34, -1.82, -2.22, -1.4, -2.56, -1.07, 0.33, -0.67, -2.14, -4.91, 4.68, -1.98, -3.75, -0.79, -2.26, -2.67, -1.85, -3.0, -1.52, -0.12, -1.12, 1.71, 1.84, 3.08, 1.55, 1.13, 1.98, 0.78, 2.32, 3.77, 2.73, 0.21, 1.87, -1.79427628811696, -0.6584018193170985, -0.85, -0.584326481349968, -1.2, -1.3434006093113235, -1.89, -1.06, -2.23, -0.73, 0.67, -0.33, -0.46, 0.29, -0.41, 0.43, -0.76, 0.8857995496566927, 2.19, 1.17, -2.5, -2.53, -0.33, -0.8, 3.48, -0.56, -0.36, 0.51, -0.48, -0.26, -0.47, -1.21, 0.45775897911612196, 1.42, 0.73, 1.68, -0.12, -2.21, 2.25, 2.12, -0.73, 0.78, -1.45, -0.92, 0.46, -3.79, 2.73, 2.45, 3.54, -0.2, 0.7, 0.84, -0.35, 1.18, 2.61, 1.59, -2.2, -0.14, -1.18, 0.33, 1.75, 0.74, 1.05, 1.53, 2.97, 1.94, -1.83, -1.95, -0.47, 1.41, 0.4, -0.73, -0.79, -1.82, 1.46, -2.05, -1.49, -0.98, -0.82, -1.86, -1.0, -1.46, -0.23, 0.39529795204795226, 0.18, -0.66, -0.87, -0.72, -0.88, -1.3769832262926027], ['479', 3.21, 1.04, -0.04, 0.05, -0.41, -0.6015803763262405, -1.11, -0.9, -0.77, -1.55, -0.28, -1.55, -1.21, -0.09, -0.38, -2.14, -0.69, -1.47, -1.29, -0.44, -1.44, -1.52, -0.73, -0.69, -0.5314063389924735, -0.35, -1.27, -1.27, -0.94, 0.19, -0.1, -1.86, -0.41, -1.2, -1.01, -0.17, -1.16, -1.24, -0.45, -0.42, -0.26, -0.77, 0.0, 0.34, 1.48, 1.18, -0.6, 0.87, 0.39054591836734703, 0.26, 1.12, 0.11, 0.03, 0.83, 0.87, -0.28, 0.3, -0.68, -0.55, -0.34, 1.14, 0.84, -0.94, 0.53, -0.27, -0.08, 0.78, -0.23, -0.31, 0.49, 0.52, -1.46, -1.46, -0.3, -2.05, -0.6, -1.39, -1.2, -0.36, -1.35, -1.43, -0.65, -0.61, -1.36, -2.0, 2.19, -1.17, -1.76, -0.3, -1.1, -0.91, -0.06, -1.06, -1.14, -0.35, -0.2559922724755494, 2.78, 0.6, 1.48, 0.68, 0.87, 1.73, 0.71, 0.64, 1.44, 1.48, -0.16, 0.61, -1.67427628811696, -0.71, -0.71, -0.74, -0.87, -0.79, -0.61, 0.24, -0.76, -0.83, -0.05, -0.01, -0.01, -0.01692325186963274, 0.19, 1.04, 0.04, -0.04, 0.75, 0.79, -0.85, -0.66, 0.05, -0.82, 8.17, 0.05, 0.1, 2.06, -2.04, -1.0, 0.42, 0.29, 2.22, 1.44, 0.75, 1.68, -0.46, -2.09, 2.15, 2.17, -0.71, 3.1, -1.41, -1.49, 0.74, -2.56, 4.750651360544218, 1.83, 2.71, -2.15, -0.26, 0.85, -0.15, -0.23, 0.5966255411255412, 0.6, -2.2, -1.1098412698412699, -1.0, -1.08, -0.29, -0.25, -0.11, -0.08, 0.72, 0.76, -0.79, -1.2, -0.03, 0.8, 0.83, -0.6379199656859431, -0.74, -0.89, 2.65, -1.9196667372159368, -2.64, -1.39, -0.31, -0.82, 0.04, -0.89, -1.06, -0.31, -0.34, -0.58, -0.86, 0.1, -1.05, -1.15], ['480', 1.65, 0.0, 0.3412217156204588, -0.06, 0.61, -0.29, 0.43, 0.55, 0.5793780543870106, 0.23, -0.67, 0.32, -0.27, 0.11, -0.44, -0.31, 0.68, -0.1, -2.42, -1.88, 0.32, 0.19, -0.8, 0.72, 1.04, 0.689371414588892, 0.91, 1.0, 0.4, 0.79, 0.23, 0.36, 1.36, 0.58, -1.76, -1.22, 1.0, 0.86, -0.13, 1.4, 1.22, 1.04, -0.08, -0.59, -0.2, -0.6891849704247235, -0.63, 0.36, -0.42, -2.72, -2.19, 0.0, -0.13, -1.12, 0.4, 0.6900628463056766, 1.85, 0.22, 0.68, 0.51, 0.39, -0.17, -0.04, 0.95, 0.17, -2.15, -1.4960242664664933, 0.59, 0.46, -0.53, 1.0, 0.4336060011417156, 0.12, -0.56, -0.42, 0.56, -0.21, -2.53, -2.0, 0.2, 0.07, -0.92, 0.61, 0.69, 1.98, -2.07, 0.7166982383853202, 0.13, 1.12, 0.34, -1.98, -1.45, 0.77, 0.63, -0.36, 1.2240077275244505, -1.75, 0.54, 0.99, 0.21, -2.11, -1.58, 0.63, 0.5, -0.5, 1.03, 0.38, 0.53, -1.31, 0.12, 0.42, -0.36432648134996803, -0.44, -0.77, -3.07, -2.54, -0.34931972789115645, -0.49, -1.47, 0.04, 0.11, 0.33, -2.32, -1.79, 0.42, 0.29, -0.71, 0.82, 0.97, 0.63, 0.38603717887804045, -0.34, -6.09, 0.18, -0.2, 1.21, -1.31, -0.63, -0.69, 0.7, -4.25, -0.14, -0.09, 0.84, 0.15, 0.3, -0.32, -0.32, 0.13, 1.95, 0.23, -0.53, 0.24, -1.32, -1.91, 0.94, 1.43, 4.15, 2.71, 0.54, 2.8, 2.67, 1.65, 3.21, 0.33, 2.16, 2.25, 2.11, 1.1, 2.65, -0.09, -0.13, -1.12, 0.4, 0.55, 0.55, 0.13727468490743444, -0.99, 0.53, 0.1, 0.06439630127529085, 0.49, -1.17, -0.99, 1.18, -0.15, 1.6, 1.05, 1.54, -0.43, -0.48, -0.03, 0.45, -0.08, -0.404042472976186, 0.13, 1.7930376647162363, -0.79], ['481', -6.64, -0.28, -0.27, 0.09, -1.31, -1.6815803763262405, -1.4458847420401708, -3.76, -3.1, -5.36, -0.37, -3.41, -2.23, -1.64, -1.56, -2.73, -3.26, -4.95, -3.12, -3.8130204081632653, -6.38, -3.21, -2.69, -4.48, -3.28, -2.73, -4.977341605006887, -3.05, -1.87, -1.27, -1.2, -2.37, -2.9, -4.59, -2.76, -3.5, -6.04, -2.85, -2.32, -4.13, -2.73, -5.68, -2.02, 1.301197467496117, 1.83, 1.9808150295752764, 0.7, 0.15, -1.279454081632653, 0.3, -0.47, -3.08, 0.2, 0.75, -1.12, -2.13, -2.34, -1.92, -2.67, -3.2, 0.61, 0.69, -0.51, -1.05, -2.78, -0.91, -1.66, -4.25, -1.0, -0.46, -2.3, -3.53, -3.78, 0.08, -1.11, -1.65, -3.36, -1.5, -2.26, -4.83, -1.6, -1.07, -2.89, -4.38, -7.35, 7.3, -3.86, -1.19, -1.72, -3.44, -1.58, -2.34, -4.9, -1.67, -1.14, -2.9159922724755494, -4.32, -2.7, -0.54, -2.28, -0.4, -1.16, -3.76, -0.49, 0.04, -1.8, -0.47, -2.65, -2.15427628811696, -1.92, -2.06, -1.7543264813499682, -2.17, -1.75, 0.14, -0.62, -3.23, 0.05, 0.59, -1.27, -2.1, -0.43, 1.92, 1.14, -1.51, 1.83, 2.38, 0.49, -1.93, -1.51, -0.1, -2.18, -12.62, -0.5, -0.36, 3.01, -3.017537676609105, -1.53, -0.55, -5.22, 3.1, 3.89, 1.92, -3.42, -1.19, -5.9085238095238095, 5.8, 5.81, -1.94, 4.55, -3.85, -1.97, 1.05, -6.45, 5.04, 4.32, 6.13, -3.07, -2.31, -0.77, -3.37, -0.1, 0.45, -1.41, -5.79, -1.56, -2.63, 0.68, 1.22, -0.65, 1.1, 3.39, 3.95, 2.03, -2.98, -3.71, -2.22, 0.54, -1.32, -1.96, -1.92, -3.63, 2.78, -2.0698003730425008, -2.93, -2.7127361894755664, -3.48, -2.75, -1.85, -2.1199225974772196, -1.58, -1.09, -1.33, -1.39, -0.92, -4.85, -4.77, -0.95], ['482', 1.07, 0.3, -0.20877828437954127, 0.1, -0.17, -0.3, -0.84, -0.16, -1.15, 0.49535714285714283, 1.73, 1.23, 0.51, 0.97, 0.37, 0.92, 0.6, 0.23, -0.85, 1.12, 0.43, 0.66, 1.17, 0.41217460317460314, -1.1, -0.9, -1.28, -0.49, -1.2, -0.74, -1.34, -0.8, -1.11, -1.48, -2.54, -0.6, -1.28, -1.05, -0.56, -1.3, -0.11, -2.3450638007838265, -0.79, -0.71, -0.25, -0.85, -0.31, -0.62, -0.99, -2.06, -0.11, -0.79, -0.56, -0.06, -0.81, -0.61, -0.48, -1.95, -1.19, -0.08, 0.46, -0.15, 0.4, 0.09, -0.28, -1.36, 0.6, -0.08, 0.15, 0.65, -0.1, 1.17, -0.54, -0.17977210884353745, -0.06, -0.37, -0.74, -1.81, 0.14, -0.54, -0.31, 0.19, -0.56, -1.92, -1.4, 1.44, 0.07, 0.55, 0.23, -0.14, -1.21, 0.75, 0.06, 0.29, 0.8, 0.05, -1.55, -0.48, -0.31, -0.68, -1.75, 0.2, -0.48, -0.25, 0.25, -0.5, 0.18, -0.4, -0.04427628811695997, -0.32, -0.5, -0.06, -0.17, -0.37, -1.44, 0.51, -0.17, 0.06, 0.56, -0.13141531611693433, -0.34, 0.2, -1.08, 0.88, 0.2, 0.43, 0.93, 0.18, -0.08, -0.09, -0.01, 0.13, -4.65, 0.09354725829725827, 0.0, -0.12, 0.08, 0.03, -0.01, 0.8, 1.3, 0.61, 0.28, 0.53, -0.24, -0.83, 0.86, 1.02, -0.3, -0.19, -0.61, -0.44, 0.19, -0.53, 1.69, 0.3, 0.53, -1.26, 1.3, 1.98, 1.29, 1.53, 2.03, 1.27, -0.92, -0.67, -0.68, -0.45, 0.05, -0.7, 0.0, 0.23, 0.73, -0.02, -1.067204648526077, -1.28, -0.23, 0.5, -0.25, -0.32, -0.25, -0.11, 1.07, 0.21, -1.06, -0.53, -0.94, -0.72, -0.6672131485030683, -0.48, 0.06, -0.41, -0.01, 0.0, 0.105957527023814, -1.44, -0.9, 0.53], ['483', 1.8842857142857141, -0.54, -0.04, 0.02, -0.89, 0.12, -0.21588474204017086, 0.13, 1.05, -0.31, -1.9, -0.7, -0.56, -0.33, -0.16, -0.87, -0.2, -1.5494285714285714, 1.79, 2.49, 0.29733548208735894, -1.1, -0.68, -0.67, 0.8, -0.1, 1.62, 1.22, 1.37, 1.6, 1.77, 1.05, 1.73, 0.36, 3.76, 4.47, 2.2, 0.82, 1.25, 1.25, -0.03, 2.34, 0.5993032324818041, 0.15, 0.37, 0.54, -0.17, 0.5, -0.85, 2.51, 3.22, 0.97, -0.4, 0.03, 0.03, 1.62, 0.15, 0.0, 0.81, 0.25, 0.22, 0.4, -0.32, 0.36, -1.0, 2.36, 3.06, 0.83, -0.54, -0.12, -0.12, -0.0063939988582844, 0.03, 0.17, -0.54, 0.13, -1.22, 2.13, 2.83, 0.6, -0.77, -0.34, -0.34, 2.21, 1.61, -1.61, -0.14, -0.71, -0.04, -1.39, 1.96, 2.66, 0.43, -0.94, -0.51, -0.51, 0.54, 0.57, 0.67, -0.6778809523809525, 2.69, 3.39, 1.14, -0.23, 0.2, 0.2, 0.96, 0.54, 0.74, 0.26, 0.43, 0.07, -0.1, -1.35, 2.0, 2.7, 0.47, -0.9, -0.47, -0.47, 0.68, 1.26, 3.6436855802927233, 4.1, 1.84, 0.46, 0.89, 0.89, 0.3, 0.93, 0.09, -0.06, 1.2277380952380952, 0.31, 0.21, 0.44, -0.52, -0.48, -0.14, -0.34, 5.45, -0.49, -0.26, 0.81, 0.47, 0.77, -0.74, -0.74, -0.26, 1.01, 0.47, 0.93, -0.54, -0.3, -1.05, 0.17, 0.24, -5.42, -2.06, 0.69, -1.5, -2.84, -2.42, -2.42, 0.78, -2.73, -2.17, -3.5, -3.09, -3.09, -0.57, -1.36, -0.94, -0.93, 1.0, 1.52, 0.8, 0.43, 0.43, 0.22, 0.24, 0.04, -0.23, 0.66, 0.39, -0.71, -0.8, 0.37, 0.07278685149693166, 0.03, -0.45, -0.06, -0.38, -0.34, 0.37, -0.49, -0.2, 1.02], ['484', 5.91, 1.35, 0.46, -0.06, 2.0929790809910593, 1.28, 1.67, 1.41, 1.96, 0.76, -1.55, -0.94, -0.2, -0.26, -1.29, -0.55, -0.84, 0.28, 2.0, -2.08, 1.23, -0.23, -0.67, -0.97, 1.37, 1.55, 2.3826583949931126, 0.63, 1.38, 1.31, 0.26, 1.03, 0.73, 1.87, 3.61, -0.53, 2.83, 1.35, 0.9, 0.6338417231978392, 1.36, 3.13, 1.71, 0.74, 0.68, -0.36, 0.39, 0.1, 1.23, 2.96, -1.15, 2.19, 0.72, 0.27, -0.04, 0.48, 0.9, 0.79, 1.67, 0.96, -0.06, -1.1, -0.35, -0.64, 0.49, 2.2, -1.88, 1.43, -0.03, -0.47, -0.77, 2.1, 1.03, -1.03, -0.28, -0.58, 0.55, 2.27, -1.82, 1.5, 0.04, -0.41, -0.71, 2.55, 4.0, -3.95, 2.08, 0.76, 0.4717857142857143, 1.6, 3.33, -0.79, 2.56, 1.08, 0.63, 0.33, 2.58, 1.3873665312165628, -0.29, 0.83, 2.56, -1.54, 1.79, 0.32, -0.12, -0.43, 1.06, 1.31, 1.43, 1.6115981806829016, 1.4451790696343398, 1.69, 1.6818094764861293, 1.13, 2.86, -1.25, 2.09, 0.62, 0.17, -0.07141531611693433, 0.79, 0.48, 1.71, -2.36, 0.94, -0.51, -0.95, -1.25, 1.33, 1.43, 0.08, 1.51, 7.46, 0.18, 0.34, -3.78, 3.79, 1.89, 0.56, 1.0861635321120495, -5.83, -3.1, -1.54, 2.98, 0.56, 4.61, -4.7, -4.68, 1.54, -5.68, 3.07, 1.01, -0.53, 4.86, -11.72, -3.25, -4.8, 5.75, -1.21, -3.99, -0.75, -2.18, -2.61, -2.91, 4.69, 2.9, 3.38, 1.89, 1.44, 1.13, -0.46, -1.3511214088935783, -1.88, -2.17, 1.94, 2.3, 0.99, -0.44, -0.75, 1.54, 1.53, 1.38, -6.89, 1.93, 6.92, 2.09, 1.84, 1.44, -0.3, 1.55, 2.2, 1.16, -0.01, 0.8746262438247291, 1.75, 2.25, 2.75, 1.96], ['485', 4.95, 0.18, -0.19, -0.17, 0.92, -0.05, 1.47, -0.25, 0.34, 0.35, 0.19, -1.21, 0.73, 1.39, 0.11, -0.64, 0.9, 1.06, -1.37, 0.12, 0.76, 0.97, 0.46, 0.25, 0.08, -0.1, 0.16, -1.4, 0.53, 1.2, -0.09, -0.83, 0.7, 0.86, -1.56, -0.07, 0.57, 0.78, 0.3688796134390452, 0.10384172319783916, 0.1, -1.0250638007838266, 1.58, 1.96, 2.797875394446823, 1.33, 0.58, 2.13, 2.29, -0.16, 1.35, 2.028065468086443, 2.21, 1.69, 1.47, -0.7699371536943234, 0.55, 0.19, 0.0, -0.38, 0.66, -0.61, -1.36, 0.17, 0.33, -2.08, -0.6, 0.04, 0.25, -0.26, -0.47, -0.1, -1.03, -1.27, -2.01, -0.49, -0.33, -2.73, -1.26, -0.62, -0.41, -0.92, -1.13, 0.0, -0.37, 0.32, 0.27669823838532015, -0.75, 0.79, 0.95, -1.48, 0.01, 0.66, 0.87, 0.36, 0.14, 0.47, 0.99, 1.55, 1.71, -0.74, 0.77, 1.41, 1.62, 1.11, 0.89, -0.44, 0.95, -0.73427628811696, -0.05, -0.08, -0.03, -0.54, 0.16, -2.25, -0.77, -0.13, 0.08, -0.43, -0.64, -0.59, -0.7, -2.4, -0.93, -0.29, -0.08, -0.59, -0.8, 0.59, 0.18, -0.34, -0.27, 1.48, -0.15, 0.07, -0.25, 0.21, 0.13, 0.17, -0.97, -0.42, 0.1, 0.06, 2.5, -0.01, -0.18, 0.28, 0.19, 0.003290804863852956, -0.31, -0.1, 1.18, -0.6, -1.62, 5.05, 1.04, 1.53, 0.7956150793650794, 1.74, 1.51, 2.17, 2.38, 1.86, 1.64, -0.15, 0.23, 0.64, 0.85, 0.34, 0.13, -0.41, 0.21, -0.3, -0.51, 0.31, 0.06, -0.62, -0.51, -0.72, -0.06, -0.1, -0.27, 2.76, -0.4, -2.8, -0.13, -0.17, -0.11, -0.21, -0.39, 0.08, 0.08, 0.12, -0.02, 0.1, -0.43, 0.55, -0.68], ['486', -2.65, 0.7614285714285715, 0.7412217156204587, -0.12, 1.04, 2.01, 1.0741152579598292, 2.29, 2.26, 2.18, -0.84, 0.58, 0.57, -0.23602380952380952, 0.8, 5.75, -1.06, 1.49, 0.66, -1.29, 2.71, -0.54, -1.8, 0.09, 3.31, 1.48, 3.05, 1.43, 1.42, 0.61, 1.65, 6.64, -0.23, 2.34, 1.51, -0.45, 3.57, 0.3, -0.97, 0.94, 1.34, 2.8949361992161733, 1.6, -0.01, -0.81, 0.22, 5.14, -1.63, 0.9, 0.08, -1.85, 2.12, -1.11, -2.36, -0.48, 0.92, 2.22, 1.89, 2.31, 1.6, -0.8, 0.23, 5.15, -1.62, 0.91, 0.09, -1.85, 2.13, -1.1, -2.35, -0.47, 3.3, 2.42, 1.04, 6.0, -0.6805105874517637, 1.7332142857142856, 0.9, -1.05, 2.95, -0.3, -1.57, 0.33, 2.5, 11.23, -11.32, 1.37, 4.91, -1.85, 0.68, -0.14, -2.07, 1.89, -1.33, -2.58, -0.6459922724755494, -0.67, -3.37, -6.44, -4.03, -4.82, -6.65, -2.88, -5.95, -7.14, -5.35, 0.81, -3.38, 3.62, 2.38, 2.75, 2.28, 3.28, 2.58, 1.74, -0.22, 3.81, 0.53, -0.74, 1.17, 2.63, 0.69, -0.82, -2.73, 1.2, -1.99, -3.24, -1.37, 5.23, 5.45, 0.28, 3.13, -1.25, 0.92, 0.64, -4.07, 4.05, 2.01, 1.35, 2.08, -7.04, -4.74, -2.44, -1.24, 1.74, 7.5, -7.5, -7.16, 2.36, -6.16, 4.76, 2.55, -1.26, 9.95, -6.62, -6.71, -9.92, 6.8, 1.52, -1.93, 2.04, -1.19, -2.44, -0.56, 7.12, 3.5201587301587303, 4.05, 0.76, -0.52, 1.4, -0.51, -3.16, -4.39, -2.54, 2.33, 2.42, 2.73, -1.27, 0.63, 2.42, 2.55, 2.23, -3.04, 3.32, 3.22, 2.31, 3.21, 4.06, 1.93, 2.6, 2.02, 1.55, 1.13, 2.09, 2.09, 3.89, 5.08, 3.38], ['487', -4.29, -0.06, -0.5687782843795413, 0.29, -1.48, -1.15, -1.36, -2.31, -3.69, -1.94, 2.59, 3.01, 0.37, -0.23, 1.13, -0.87, -1.03, -1.46, -1.62, -1.09, -3.28, -1.95, 0.034305231600676125, -1.52, -3.06, -1.0, -4.42, 0.41, -1.7423253968253969, -2.75, -1.42, -3.37, -3.54, -3.96, -4.1, -3.59, -5.73, -4.43, -2.58, -4.01, -2.7625315746467893, -5.245063800783826, -4.81, -2.478802532503883, -3.14, -1.82, -3.76, -3.93, -4.34, -4.49, -3.98, -6.11, -4.81, -2.98, -4.4, -0.28, -3.36, -1.62, -2.36, -2.31, -0.6, 0.7507993197278912, -1.24, -1.4, -1.83, -1.98, -1.46, -3.65, -2.3067380952380954, -0.43, -1.89, -2.3, -1.72, 1.3746428571428573, -0.64, -0.81, -1.24, -1.39, -0.87, -3.06, -1.72, 0.30309548189905344, -1.3, -4.39, -4.53, 4.52, -3.0033017616146798, -1.98, -2.14, -2.57, -2.72, -2.2, -4.37, -3.04, -1.18, -2.62, -2.32, -1.09, -0.17, -0.6, -0.76, -0.23, -2.44, -1.09, 0.81, -0.66, -0.63, -1.06, -1.71, -1.19, -1.31, -1.01, -0.92, -0.3034006093113235, -0.59, -0.06, -2.27, -0.92, 0.99, -0.49, -0.19, -0.4369232518696327, -0.15, 0.38, -1.85, -0.49, 1.43, -0.06, -0.98, -0.46, 0.06, -0.92, -4.5, -0.71, -0.5, 1.45, -1.41, -0.7, -0.52, -3.41, 1.87, 2.38, 1.17, -2.16, -0.34, -3.42, 3.47, 3.6, -1.17, 2.21, -2.36, -5.09, 2.55, -2.66, 8.93, 1.84, 2.72, -1.97, -0.33, 0.53, -1.7, -0.34, 1.58, 0.1, -3.56, -0.86, -2.21, -0.86, 1.05, -0.43, 1.39, 1.38, 3.34, 1.82, -3.6, -3.29, 0.0, 1.93, 0.43, -1.22, -1.15, -2.34, 4.39, -0.72, -4.56, -2.84, -2.9, -1.89, -1.46, -1.17, -0.87, -0.35, 0.17, -0.77, -0.43, -4.79, -3.76, -0.35], ['488', 1.12, -0.45, -0.038778284379541256, 0.16, 0.02, -0.94, -0.9, -0.63, -0.51, -1.74, -1.52, -0.74, -0.86, -0.86, -2.37, -1.64, -1.52, -1.61, -1.96, -1.45, -1.6, -1.92, -1.65, -1.25, 0.0, -0.91, -0.22, 0.79, 0.6908333333333334, 0.8131899370470801, -0.86, -0.12, 0.0, -0.09, -0.44, 0.07, -0.08, -0.41, -0.13, 0.27, -0.38, -0.41, -1.0, -0.03880253250388291, -0.12, -1.63, -0.9, -0.79, -0.87, -1.22, -0.71, -0.8603452707629391, -1.19, -0.91, -0.51, -0.34, -0.75, -0.91, -0.44, -0.88, 0.0, -1.52, -0.79, -0.67, -0.6573949338599383, -1.0013219954648527, -0.59, -0.75, -1.07, -0.79, -0.4, -1.86, -0.88, -1.52, -0.79, -0.67, -0.76, -1.11, -0.59, -0.75, -1.07, -0.79, -0.39, -0.43, -0.41, 0.41, 0.64, 0.74, 0.86, 0.77, 0.42, 0.94, 0.78, 0.46, 0.74, 1.14, 0.35, -0.02263346878343711, 0.12, 0.03, -0.32, 0.19, 0.04, -0.28, -0.01, 0.39, -0.15, -0.12, 0.53, -0.63, -0.77, -0.53, -0.22, -0.09, -0.44, 0.07, -0.08, -0.33969498055271247, -0.12, 0.27, -0.12, -0.13, -0.35, 0.16, 0.01, -0.31, -0.03, 0.36, 0.03, -0.07, 0.22, -0.48, 1.06, 0.13, 0.1, 1.06, -1.06, -0.53, -2.03, -0.9, 0.63, 1.29, 0.67, 0.58, -0.32, -2.0, 1.99, 1.94, -0.66, 1.65, -1.32, -1.54, 0.73, -0.64, -1.33, 0.44, 0.65, -0.58, 0.22, 0.52, 0.36, 0.04, 0.32, 0.72, -1.94, -0.29, -0.16, -0.48, -0.2, 0.2, -0.14, -0.32, -0.04, 0.36, -0.49, -0.29, 0.19, 0.28, 0.68, -0.71, -0.64, -0.57, -0.97, 0.03019962695749935, 0.94, -1.12, -1.86, -0.09, 0.4, -0.87, -0.48, -0.25, -0.3, -0.98, -0.49, -1.1, -1.5084047619047618, -0.37], ['489', -4.43, 0.34, 0.09122171562045875, 0.13, 1.02, 1.52, 1.0441152579598292, 1.3, 1.59, 2.05, 0.35, 0.77, 1.93, 0.48, 0.91, 3.26, 0.3, 1.75, 2.36, -0.39, 2.48, 1.0570289115646259, 1.15, 0.27, 2.47, 1.7093714145888919, 1.7, 0.42, 1.58, 0.14, 0.57, 2.91, -0.04, 1.4, 2.01, -0.73, 2.13, 0.41, 0.81, -0.08, 1.08, 2.500897562605877, 1.28, 1.16, -0.28, 0.15, 2.48, -0.46, 0.97, 1.59, -1.14, 1.7, -0.01, 0.38, -0.5, 0.4, 1.25, 1.36, 1.1, 0.11, -1.43, -1.0, 1.31, -1.6, -0.18, 0.42, -2.28, 0.54, -1.15, -0.77, -1.64, 1.36, 1.56, 0.43, 2.77, -0.18, 1.26, 1.87, -0.86, 2.143081632653061, 0.28, 0.67, -0.21, 1.64, 2.56, -2.59, 1.13, 2.33, -0.6, 0.83, 1.44, -1.29, 1.55, -0.13428571428571429, 0.24, -0.64, -1.58, -1.18, -2.87, -1.456904761904762, -0.87, -3.54, -0.76, -2.42, -2.04, -2.9, 0.3009795918367347, -1.08, 2.7457237118830404, 1.4, 1.01, 1.8, 1.74, 1.44, 2.05, -0.69, 2.345778253492539, 0.46, 0.85, -0.04, 1.27, 0.3, 0.61, -2.1, 0.729562358276644, -0.97, -0.58, -1.45, 0.62, 0.99, 0.41, 1.56, -3.24, -0.12, 0.05, -4.08, 4.042462323390895, 2.02, 0.71, 2.24, -4.96, -2.67, -1.43, -2.21, 0.89, 4.16, -4.23, -4.15, 1.4, -6.06, 2.73, -2.49, 1.25, 5.16, -7.24, -3.5, -5.2, 4.96, -0.31, -2.69, 0.11, -1.57, -1.18, -1.884238287156354, 4.1, 2.45, 2.88, 1.15, 1.55, 0.66, -0.42, -1.68, -1.29, -2.16, 1.63, 1.68, 1.28, 0.39, -0.49, 1.41, 1.42, 1.2925760496238783, -3.59, 2.19, 3.52, 1.2772638105244332, 1.7, 0.968637448200971, -0.88, 1.12, 2.13, 1.35, 0.57, 0.69, 1.78, 1.59, 2.883037664716236, 1.69], ['490', 7.2, 0.03, -0.02, 0.2, 0.91, 0.56, -0.5558847420401708, 0.87, 0.78, 0.18, -1.07, 0.18, -0.45, 0.03, -0.12, -1.69, -0.14, -0.06, -0.99, -1.6, 0.72, 0.17, -0.22, -0.15, 1.12, 1.29, 1.26, 1.3784685082657773, 0.62, 1.11, 0.96, -0.6266496598639456, 0.94, 1.02, 0.08, -0.54, 1.81, 1.25, 0.86, 0.93, 0.98, 2.9949361992161734, 0.0, -0.63, -0.15, -0.3, -1.87, -0.32, -0.24, -1.17, -1.78, 0.54, -0.02, -0.4, -0.33, 0.76, 1.41, 1.04, 0.24, 0.64, 0.48, 0.33, -1.25, 0.31, 0.4, -0.54, -1.16, 1.343421154242583, 0.62, 0.24, 0.3, 1.04, 0.15, -0.15, -1.72, -0.17, -0.09, -1.02, -1.63, 0.69, 0.14, -0.24, -0.18, 1.58, 0.99, -1.06, 0.33669823838532015, -1.57, -0.02, 0.06, -0.87, -1.48, 0.84, 0.29, -0.09, -0.03, 3.82, 1.91, 1.58, 1.66, 0.71, 0.09, 2.5126265373526935, 1.89, 1.5, 1.57, 0.25, 1.97, 1.51, 0.39, 0.34, 0.45, 0.32, 0.08, -0.85, -1.47, 0.86, 0.31, -0.08, -0.01, 0.03, 0.29307674813036727, -0.94, -1.55, 0.78, 0.22, -0.16, 0.15217743764172342, 0.14, 0.12, 0.36, 0.32, 11.41, 0.1, -0.17, -0.94, 0.92, 0.47, 0.27, 0.15616353211204947, -3.42, -0.76, -0.43, 3.53, 0.17, 1.3, -1.21, -1.17, 0.39, -1.41, 0.8, -1.14, 0.6047652642842468, 0.95, -4.36, -0.65, -0.95, 3.47, 1.5103786848072562, -0.62, 1.73, 1.17, 0.78, 0.85, 1.24, 1.8201587301587303, 2.36, 1.8, 1.41, 1.48, -0.53, -0.55, -0.93, -0.86, 0.8, 0.93, 0.10727468490743443, -0.38, -0.31, 0.42, 0.42, 0.83, -2.57, 1.07, 2.54, 0.85, 0.78, 0.4, 0.07, 0.44, 0.6445528598385742, 0.37, -0.19, 0.1, 0.33, 1.24, 0.73, 0.05], ['491', 4.05, 0.19, 0.44122171562045875, 0.05, 0.44, 1.21, 0.17411525795982916, 1.98, 1.59, 1.3470884353741497, -2.18, 0.11, -0.04, -0.78, -1.0457142857142858, -0.06, 0.8214285714285714, -0.05, 0.78, 0.09366326530612246, 1.47, -1.05, -0.12, -0.73, 1.11, 1.12, 3.15, 2.3405454545454543, 2.19, 1.43, 1.16, 2.1702857142857144, 2.41, 2.18, 3.03, 2.3, 3.73, 1.16, 2.11, 1.48, 2.187468425353211, 1.6649361992161733, 0.79, -0.14, -0.88, -1.15, -0.17, 0.07, -0.16, 0.67, -0.04, 1.36, -1.16, -0.22, -0.83, 0.45, 0.52, 1.13, 1.67, 0.93, -0.74, -1.01, -0.02, 0.21, -0.02, 0.82, 0.11, 1.5, -1.01, -0.08, -0.69, 1.86, 1.69, -0.27, 0.72, 0.96, 0.73, 1.57, 0.86, 2.26, -0.27, 0.67, 0.05, 2.5, 3.06, -3.02, 1.96, 1.0, 1.24, 1.0, 1.85, 1.13, 2.54, 0.0, 0.94, 0.32, 0.96, 0.96, 0.24, 0.01, 0.84, 0.13, 1.53, -0.99, -0.06, -0.67, 0.86, 0.93, 1.66, 0.95, 0.98, 1.01, 0.72, -0.23, 0.6, -0.11, 1.28, -1.1696949805527124, -0.29, -0.8514153161169343, 1.72, 0.95, 0.84, 0.12, 1.52, -1.0, -0.0642857142857143, -0.68, 0.21, 0.9, 0.36603717887804044, 1.1, 1.84, 0.66, 0.01, -0.98, 0.97, 0.48, -0.98, 3.09, -1.56, -2.02, -0.96, 2.02, 1.06, 2.83, -2.85, -2.93, 0.95, -1.35, 1.95, 0.61, -0.28, 2.14, -5.39, -1.4, -2.27, 1.66, 0.11, -0.71, 0.68, -1.82, -0.89, -1.5, 2.97, 0.82, 1.39, -1.12, -0.19, -0.8, -0.11349829931972805, -2.48, -1.56, -2.16, 1.65, 2.18, 1.97, 0.94, 0.32, 0.98, 1.0, 1.95, -2.83, 2.34, 2.68, 1.35, 0.83, 1.02, -0.61, 0.91, 0.5202197802197802, 1.14, 1.23, 1.23, 1.64, 1.03, 1.09, 1.04], ['492', -1.05, -0.66, -0.12, 0.21, -0.8, -0.1, 0.17411525795982916, 0.21172059653595873, 0.15, 0.06, 0.27, -0.67, 1.52, -0.13, -0.27, 0.25, 0.87, 0.68, -1.22, 1.14, 0.09, -0.08405782312925174, -0.22, 0.55, 0.29, -0.16, -0.21, -0.94, 1.25, -0.4, -0.53, -0.02, 0.6, 0.41, -1.49, 0.86, -0.18, -0.47, -0.49, 0.28, -0.25, 0.5149361992161734, 0.74, 2.21, 0.54, 0.4, 0.92, 1.55, 1.35, -0.56, 1.82, 0.76, 0.47, 0.45, 1.23, 0.0, -0.09, 0.42, 0.4, -1.44, -1.63, -1.76, -1.26, -0.64, -0.83, -2.7, -0.38, -1.42, -1.7, -1.72, -0.96, 0.7436060011417156, 0.19, -0.14, 0.38, 1.0616609275411797, 0.81, -1.09, 1.27, 0.22, -0.07, -0.09, 0.68, 0.0, 0.26, -0.36, 0.3308709226619941, 0.52, 1.14, 0.95, -0.96, 1.41, 0.35, 0.07, 0.04, 0.82, -2.06, -0.18, 0.62, 0.43, -1.46, 0.89, -0.16, -0.45, -0.47, 0.3, -0.64, -0.17, -0.99, -0.39, -0.18, -0.69, -0.8, -0.19, -2.07, 0.26, -0.78, -1.06, -1.08, -0.32, 0.18, -0.61, -1.88, 0.46, -0.59, -0.87, -0.9, -0.12, 0.07895836996312448, -0.2, 0.47, -0.81, -6.04, -0.08, 0.06, 1.4, -1.39, -0.67, -0.23, -1.65, 2.15, 0.7, 0.37, -0.48, 0.19, -1.36, 1.29, 1.05, -0.36, 2.0, -0.69, -2.52, 1.25, -2.34, 4.53, 1.6, 2.34, -2.2, 1.3, 2.39, 1.32, 1.03, 1.01, 1.79, -0.99, -1.06, -1.04, -1.32, -1.34, -0.58, -0.02, -0.29, -0.31, 0.47, 0.21, 0.03, 0.26, -0.02, 0.75, -0.33, -0.44, 0.16, 1.75, -1.52, -2.22, -1.0, -0.86, 0.29, 0.78, -0.66, -0.58, -0.09, 0.55, -0.39537375617527093, -0.49, -3.43, -1.18, -1.08], ['493', -3.89, -0.13, -0.15, 0.26, -2.03, -0.79, -1.0158847420401709, -3.09, -2.12, -2.62, 1.1, -0.68, 0.703913265120849, 0.27, 2.29, -2.73, -1.32, -1.7, -1.23, -0.19, -3.19, -1.41, -0.76, -1.11, -1.83, -0.93, -3.68, -1.76, -0.46, -0.6768100629529199, 1.17, -3.79, -2.39, -2.77, -2.31, -1.27, -4.24, -2.48, -1.84, -2.18, -3.4925315746467893, -1.8450638007838267, -1.95, 1.33, 0.96, 3.0608150295752767, -2.0389563492063494, -0.6007210884353742, -1.03, -0.56, 0.5, -2.52, -0.73, -0.08, -0.43, -1.45, -2.11, -2.21, -1.44, -3.1607547529341224, -0.36, 1.64, -3.35, -1.94, -2.33, -1.86, -0.82, -3.8, -2.04, -1.39, -1.74, -2.24, -2.89, 2.01, -2.99, -1.58, -1.97, -1.5, -0.46, -3.45, -1.68, -1.03, -1.38, -2.9, -5.04, 5.11, -4.8, -4.9, -3.52, -3.9, -3.44, -2.42, -5.35, -3.61, -2.98, -3.32, 1.15, 0.11, 1.45, 1.05, 1.5415238095238095, 2.61, -0.47, 1.35, 2.03, 1.67, -1.04, 0.13, -2.5798953488372094, -0.98, -0.98, -0.984326481349968, -1.32, -0.39, 0.08, 1.14, -1.89, -0.039694980552712436, 0.57, 0.21, -1.27, -0.93, 0.48, 1.54, -1.51, 0.3, 0.96, 0.61, -2.08, -1.55, 0.38, -1.27, 2.36, -0.3796768707482993, -0.04, 2.48, -2.51, -1.27, -0.95, -4.8, 4.84, 2.14, 1.08, -2.04, 0.13, -3.15, 3.19, 3.09, -1.05, 3.76, -2.0, -3.18, 1.64, -3.96, 8.22, 2.54, 3.87, -4.81, -1.41, 1.06, -1.98, -0.18, 0.48, 0.13, -3.1, -2.44, -2.9964625850340134, -1.23, -0.57, -0.92, 0.58, 1.83, 2.51, 2.15, -2.07, -2.2, -1.23, 0.66, 0.31, -0.7879199656859431, -1.06, -3.29, 4.09, -2.6, -4.24, -2.1, -1.29, -1.88, -0.35, -1.89, -1.2, 0.17, -0.06, 0.31, -1.53, -2.2297593656343655, -2.17, -1.6269832262926027], ['494', 0.1, 0.01, -0.08, 0.15, 0.1, -0.49, -1.22, -0.31, 0.33, -0.51, -1.8, 0.03, 0.0, -1.42, 1.27, -1.06, 0.54, -0.08942857142857143, 0.56, -0.01, 0.29, -1.16, -0.25, 0.38, -0.12, -0.13, 1.32, 1.87, 1.83, 0.39, 3.187819971295091, 0.75, 2.39, 1.74, 2.41, 1.83, 2.13, 0.65, 1.58, 2.23, -1.24, 1.25, -0.54, 0.041197467496117086, -1.46, 1.24, -1.1, 0.51, -0.13, 0.53, -0.04, 0.25, -1.2, -0.28, 0.355047619047619, 0.07, 0.07, 0.13194788471762156, 0.43, -0.51, -1.42, 1.28, -1.06, 0.55, -0.09, 0.5871802721088435, 0.0, 0.29, -1.16, -0.25, 0.38, -0.51, 0.93, 2.74, 0.36, 2.1494894125482364, 1.35, 2.02, 1.44, 1.74, 0.26, 1.19, 1.8835596417251208, 1.07, -0.86, 0.83, -1.76, -2.31, -0.72, -1.35, -0.7, -1.066255228898086, -0.97, -2.41, -1.5, -0.88, 0.28, 0.56, 1.63, 0.98, 1.65, 1.07, 1.4326265373526936, 0.1428169964955679, 0.82, 1.46, -0.25, 0.52, -0.69, -0.57, -0.5, -0.69, -1.05, -0.63, 0.02, -0.55, -0.26, -1.7, -0.79, -0.16, 0.63, -0.42, 0.66, 0.09, 0.38, -1.07, 0.0657142857142857, 0.47, -0.38, -0.88, 0.23, -0.76, 0.53, 0.04, 0.14, 1.83, -1.79, -0.87, 0.13, -1.14, 1.09, 1.18, 1.028280612244898, 0.25, -0.56, -1.77, 1.71, 1.84, -0.56, 2.62, -1.11, -0.84, 0.44, -3.01, -0.29, 2.1, 3.02, -0.97, -1.07, -0.57, -0.28, -1.72, -0.81, -0.18, -1.67, -0.5, 0.29, -1.16, -0.24, 0.39, -0.79, -1.45, -0.54, 0.09, 0.34, 0.62, 0.66, 0.92, 1.56, -0.4, -0.64, -0.35, -0.18, -1.06, 0.29, -0.83, 0.53, -0.26, 0.63, -0.97, -0.96, -0.87, -0.3, -0.55, -0.89, -1.04, 0.15, -0.79], ['495', -2.12, 0.0, 0.46, 0.06, -0.14, -0.38, 0.18, 0.09172059653595872, -0.56, 1.46, 1.89, 2.4293248299319727, 2.1, 1.44, 1.15, 2.25, 1.15, 1.47, 2.57, 2.53, 1.23, 1.07, 1.93, 1.605116627420199, -0.64, -1.24, -0.39734160500688753, 0.51, 0.2, -0.44, -0.73, 0.35, -0.73, -0.41, 0.66, 0.62, -0.65, -0.81, 0.03, -0.43, 0.24, 0.63, -0.94, -0.31, -0.95, -1.24, -0.16, -1.24, -0.92, 0.15, 0.11, -1.16, -1.31, -0.48, -0.94, -0.5, -0.21, -0.44, -0.33, -0.63, -0.65, -0.94, 0.15, -0.93, -0.62, 0.46, 0.42, -0.85, -1.01, -0.11173538366395512, -0.63, 0.01360600114171559, 0.02, -0.29, 0.8, -0.29, 0.03, 1.11, 1.07, -0.21, -0.37, 0.48, 0.02, -0.7, -0.89, 0.92, 0.31, 1.1780874332127649, 0.01, 0.32, 1.41, 1.37, 0.08, -0.07, 0.7785238095238095, 0.31, -1.7, -0.78, -1.08, -0.76, 0.31, 0.27, -1.0, -1.15, -0.32, -0.78, 0.03, -0.84, 1.67, -0.24, -0.36, 0.015673518650031963, 0.3009570400359874, 0.32, 1.4, 1.36, 0.08, -0.08, 0.76, 0.3, 0.22, -0.01, 1.08, 1.04, -0.24, -0.39, 0.45, -0.01, -1.01, -0.27, 0.28, 0.17, -5.08, 0.03, -0.06, 0.43, -0.45, -0.2, 0.0, -0.24, 2.1, 0.46, 0.23, -0.99, -0.5, -0.68, 0.62, 0.79, -0.25, 0.56, -0.49, 0.1, -0.06, 0.89, 2.22, -0.7, -0.95, -1.98, -1.08, -0.04, -1.3, -1.46, -0.63, -1.08, -0.74, -0.9056457669314812, -1.26, -1.42, -0.59, -1.04, 0.22, -0.16, 0.69, 0.22, -0.56, -0.41, 0.38, 0.84, 0.38, -0.25, -0.16, 0.0, 1.15, 1.34, -1.09, -0.33, -0.53, -0.46, -0.46, -0.14, -0.15, -0.46, -0.89, 0.03, 0.0, -1.23, -0.69, 0.25], ['496', -5.95, 0.0, -0.03984710169072946, 0.06, -0.5070209190089403, -1.07, -1.6158847420401707, -2.138279403464041, -2.03, -3.18, 0.04, -2.08, -1.2, -0.75, -0.19, -2.7, -1.47, -2.85, -5.89, -1.96, -3.432664517912641, -1.61, -2.04, -1.78, -1.69, -1.48, -3.22, -2.11, -1.2191666666666667, -0.79, -0.23, -2.74, -1.51, -2.89, -5.93, -2.0, -3.51, -1.65, -2.08, -1.82, -1.82, -3.84, -1.13, 0.9711974674961171, 1.35, 1.93, -0.64, 0.62, -0.79, -3.9, 0.12, -1.391934531913557, 0.47, 0.04, 0.3, -1.06, -1.59, -1.92, -1.35, -2.01, 0.45, 1.02, -1.52, -0.28, -1.67, -4.75, -0.77, -2.3, -0.42, -0.85, -0.59, -1.8, -2.45, 0.57, -1.97, -0.72, -2.12, -5.18, -1.22, -2.74, -0.87, -1.29, -1.04, -2.81, -3.59, 3.64, -3.0, -2.52, -1.29, -2.67, -5.72, -1.78, -3.29, -1.43, -1.85, -1.6, -2.88, -0.49, 1.27, -0.15, -3.28, 0.76, -0.78, 1.12, 0.69, 0.95, -0.42, -0.48, -2.57, -1.05, -1.04, -1.14, -1.73, -1.4, -4.49, -0.5, -2.03, -0.14, -0.57, -0.32, -1.53, -0.28692325186963274, -3.13, 0.92, -0.63, 1.28, 0.84, 1.1, -0.78, -1.3, 0.04, -1.48, -8.87, -0.03, 0.23, 1.95, -2.02, -0.98, -0.09, -2.67, 2.45, 2.05, 1.04, -2.99, -1.01, -3.2, 3.19, 3.17, -1.05, 2.93, -2.09, -1.51, 0.76, -5.33, 4.58, 3.47, 5.21, -2.28, 2.88, 4.18, 2.58, 4.55, 4.1, 4.535761712843646, -3.1, -1.24, -1.54, 0.35, -0.08, 0.18, 0.3, 1.92, 1.48, 1.74, -1.91, -2.26, -1.59, -0.43, -0.17, -1.03, -1.13, -2.13, 3.99, -1.76, -4.05197619047619, -1.84, -0.3, -1.17, 0.26, -1.31, -0.79, -1.6, -0.66, -0.94, -1.42, -2.58, -0.78, -1.58], ['497', 0.43, 0.0, -0.25877828437954126, 0.1, 0.23, -0.38, -0.49588474204017086, -1.31, -0.65, -0.9, -0.19, -0.59, -0.47, -0.22, 0.95, -0.65, -0.4, -0.73, -1.45, -0.18, -1.03, -0.36, -0.15, -0.83, -0.85, -0.7, -0.71, -0.3998214285714286, -0.28, -0.03, 1.14, -0.46, -0.21, -0.54, -1.27, 0.01, -0.84, -0.17, 0.04, -0.64, -0.99, -1.71, -0.31, 0.12, 0.37, 1.54, -0.06, 0.19, -0.14, -0.87, 0.41, -0.45, 0.23, 0.44, -0.24, -0.82, -0.86, -1.44, -0.56, -0.43, 0.26, 1.43, -0.17, 0.08, -0.26, -0.98, 0.29, -0.56, 0.11, 0.32, -0.36, -1.71, -0.68, 1.17, -0.43, -0.18, -0.51, -1.24, 0.04, -0.82, -0.14, 0.07, -0.61, -1.03, -1.96, 1.89, -1.83, -1.58, -1.33, -1.66, -2.38, -1.12, -1.96, -1.3, -1.09, -1.76, -0.52, -0.25, 0.25, -0.08, -0.81, 0.47, -0.39, 0.29, 0.5, -0.18, -0.05, -0.3, -1.66427628811696, -0.28, -0.37, -0.19, -0.5, -0.33, -1.06, 0.22, -0.64, 0.04, 0.32598786341555264, -0.43, -0.6, -0.17, -0.73, 0.55, -0.13139698000412267, 0.37, 0.58, -0.1, -0.68, -0.81, 0.34, -0.34, -1.36, 0.0, -0.1, 0.36, -0.3675376766091052, -0.15118982899237887, -0.28, -0.71, 1.33, 0.54, 0.26, 0.18, -0.36, -0.79, 0.77, 0.75, -0.21670919513614706, 0.56, -0.47012164275868484, -1.87, 0.93, -1.4, 0.43, 0.86, 1.53, -1.36, 0.56, 1.29, 0.43, 1.11, 1.32, 0.64, -0.6768321004392431, -0.72, -0.85, -0.18, 0.03, -0.65, 0.14, 0.68, 0.89, 0.21, -0.61, -0.75, -0.54, 0.21, -0.39775124468498363, -0.25, -0.23, -1.24, 0.29, -0.59, -0.33, -0.92, 0.41, -0.75, -0.68, -0.32, -0.14, -0.06, -0.47, -0.61, -0.07, -0.95, 0.97, 0.16], ['498', 0.83, -1.24, 0.05122171562045875, 0.3, -1.23, -1.42, -1.6358847420401708, -1.9, -1.82, -1.53, 0.02, -0.62, 1.13, 0.75, 0.29, -2.62, 0.74, -1.17, 2.19, -0.3, -1.59, 0.27, 0.34, 0.47, -1.05, -1.53, -1.55, -0.64, 1.1, 0.73, 0.27, -2.6366496598639455, 0.72, -1.2, 2.17, -0.33, -1.62, 0.25, 0.32, 0.45, -1.8125315746467892, -3.64, -0.92, 1.75, 1.38, 0.91, -2.02, 1.36, -0.56, 2.82, 0.31, -0.99, 0.89, 0.96, 1.1, -1.17, -0.4, -1.67, -2.25, -2.63, -0.37, -0.83, -3.7, -0.38, -2.28, 1.05, -1.41, -2.69, -0.84, -0.78, -0.64, -2.36, -2.27, -0.46, -3.35, -0.01, -1.91, 1.43, -1.05, -2.33, -0.48, -0.41, -0.28, -2.29, -5.37, 5.28, -1.82, -2.9, 0.45, -1.46, 1.9, -0.59, -1.88, -0.02, 0.05, 0.18, 1.18, 1.12, 3.45, 1.48, 4.94, 2.38, 1.05, 2.97, 3.04, 3.18, -0.48, 1.03, -3.44, -1.43, -1.51, -1.5, -2.25, -1.9, 1.44, -1.04, -2.32, -0.46, -0.3240121365844474, -0.26, -1.67, -0.36, 3.41, 0.88, -0.42, 1.47, 1.53, 1.67, -1.84, -1.85, 0.07, -1.98, 3.9, -0.52, -0.35, 2.71, -2.8, -1.38, -0.75, -2.14, 2.4, 2.88, 1.41, 0.36, -0.996920210131221, -4.52, 4.53, 4.28, -1.44, 4.21, -2.84, -2.25, 1.04, -6.74, 13.503125850340135, 4.52, 6.78, -2.37, -3.64, -2.44, -3.71, -1.88, -1.8087142857142857, -1.68, -4.31, -1.23, -1.3, 0.58, 0.64, 0.78, 0.06, 1.9, 1.96, 2.1, -1.75, -2.23, -1.8, 0.06, 0.2, -1.44, -1.6, -1.7674239503761218, 7.11, -3.2398003730425007, -7.02, -1.86, -1.61, -1.86, 0.14, -1.99, -1.2, -0.69, -1.18, -0.84, -2.0, -1.2, -2.45, -2.09], ['499', 9.254285714285714, -0.9, -0.04, 0.07, -0.2, 0.02, 1.174115257959829, 0.98, 0.58, 1.99, 1.24, 0.54, 1.51, 0.4, 0.8, 1.1610714285714285, 2.65, 1.72, 5.24, 3.04, 2.3, 2.9870289115646256, 1.96, 1.71, -0.38, 0.38, 0.7726583949931125, -0.7, 0.26, -0.83, -0.44, -0.08, 1.39, 0.5872589041444084, 3.95, 1.78, 1.04, 1.43, 0.7, 0.46, 1.31, 0.22, 1.45, 0.97, -0.14, 0.26, 0.62, 2.1, 1.18, 4.68, 2.49, 1.75, 2.14, 1.4442857142857142, 1.16, -0.55, 0.24, 1.21, 0.46, 0.47, -1.1, -0.7, -0.35, 1.12, 0.21, 3.67, 1.51, 0.77, 1.16, 0.44, 0.19, 0.62, 1.59, 0.4, 0.76, 2.24, 1.32, 4.82, 2.63, 1.89, 2.28, 1.55, 1.3, 0.47, -0.1, 0.11, 1.18, 0.36, 1.83, 0.92, 4.41, 2.23, 1.6552352330209474, 1.88, 1.15, 0.9, 1.05, 0.82, 1.47, 0.56, 4.04, 1.86, 1.12, 1.51, 0.79, 0.54, 0.22, 0.84, -1.16, 0.05, -0.06, 0.05, -0.64, -0.9, 2.53, 0.38, -0.34, 0.04, -0.67, -0.8614153161169343, -0.69, 0.26, 3.46, 1.3, 0.56, 0.95, 0.23, -0.02, 0.04, -0.3, 0.4660371788780404, -0.54, 3.25, 0.14, 0.35, -1.09, 1.1, 0.56, -0.02, -0.72, 1.94, -0.12, -0.03, 4.469285714285714, -0.05, 0.01, 0.06, -0.1, 0.10329080486385296, -1.79, 0.07, -0.43, 0.22, -1.94, 1.51, 1.22, 1.89, -2.04, -3.09, -2.09, -2.8, -2.42, -3.12, -3.36, 0.18, -1.02, -0.72, -0.34, -1.05, -1.29, -0.3, 0.38, -0.33, -0.58, 0.61, 0.46, -0.68, -0.72, -0.96, 0.05, -0.03, 0.93, 0.32, -0.3, -0.34, -0.03273618947556672, -0.74, 0.03, -0.24, -0.37, 0.42, 0.13, -0.6, 0.39, 0.28, -0.09, -1.83, 0.89], ['500', -0.74, -0.25, 0.13122171562045873, -0.7, -0.36, -0.55, -0.015884742040170832, -0.6, -0.23, -0.42, -0.14, 0.4, 0.08, -0.09, -0.22, -0.65, 0.2, -0.11, 2.73, -0.24, -0.43266451791264104, 0.61, -0.24, -0.59, -0.4, -0.21, -0.2573416050068875, 0.54, 0.22, 0.05, -0.022180028704908802, -0.51, 0.33, 0.03, 2.87, -0.1, -0.33, 0.75, -0.1, -0.4061582768021609, -0.1, -0.7350638007838266, -0.82, -0.32, -0.49, -0.62, -1.04, -0.2, -0.5, 2.32, -0.64, -0.841934531913557, 0.21, -0.64, -0.99, 0.47, 0.22, -0.08, 0.06, -0.5, -0.17, -0.3, -0.73, 0.12, -0.19, 2.64, -0.32, -0.55, 0.53, -0.32, -0.67, -0.18, -0.34, -0.13, -0.56, 0.28, -0.02, 2.82, -0.15, -0.38, 0.7, -0.15, -0.4564403582748793, -0.42, -0.6, 0.66, -0.16330176161467985, -0.43, 0.42, 0.11, 2.95, -0.02, -0.25, 0.83, -0.02, -0.37, -0.89, 0.22, 0.85, 0.54, 3.39, 0.41, 0.18, 1.26, 0.41, 0.06, -0.36, 0.19, -0.26427628811695997, -0.43, -0.19, -0.13432648134996805, -0.62, -0.3, 2.53, -0.43, -0.66, 0.41, -0.44, -0.79, 0.12, -0.32, 2.83, -0.13, -0.36, 0.71, -0.14, -0.49, -0.59, -0.53, -0.06, -0.3, 0.2, -0.1, 0.0, 0.44, -0.56, -0.23, -0.29, -2.71, 0.37, 0.83, 0.38, -0.21, -0.04, -1.29, 1.25, 1.11, -0.45, 0.76, -0.84, 0.27, -0.2, -1.66, -0.8, 0.82, 1.73, -0.29, -3.07, -2.89, -3.11, -2.06, -2.89, -3.23, -1.17, -0.19, -0.23, 0.85, 0.0, -0.35, 0.05, 1.08, 0.23, -0.12, -0.26, 0.19, -1.03, -0.84, -1.19, -1.05, -0.41, -0.35, 0.09, -0.5798003730425006, 0.17, 0.27, -0.93, -0.18, -0.35, -0.42, -0.31, -0.37, -0.31, -0.5, 0.17, -0.47, -1.24, -0.11], ['501', -1.71, -0.18, 0.25122171562045875, 0.04, -1.02, -0.3, 0.22, -0.15, -0.45, -0.48, -0.67, -0.64, 0.54, 1.4, -1.0, 0.08, 0.02, -0.65, 0.62, 1.5, -0.3, -0.27, -0.03, 0.55, 0.13, -0.6, 0.2, 0.14846850826577718, 1.22, 2.09, -0.33, 0.7633503401360544, 0.7, 0.02, 1.3, 2.18, 0.37, 0.41, 0.65, 1.23, 0.06, -0.89, 0.17, 1.19, 2.06, -0.36, 0.72, 0.66, -0.01, 1.27, 2.15, 0.368065468086443, 0.38, 0.62, 1.2, 0.21, 0.08, 0.91, -1.11, -1.01, 0.9531047225355607, -1.53, -0.46, -0.52, -1.19, 0.07, 0.95, -0.84, -0.81, -0.57, 0.01, 2.31, -1.85, -2.37, -1.31, -1.36, -2.02, -0.77, 0.09, -1.68, -1.64, -1.41, -0.84, -0.44, -1.61, 1.51, 0.53, 1.09, 1.03, 0.35, 1.63, 2.52, 0.71, 0.74, 0.98, 1.56, -1.21, -0.55, -0.06, -0.73, 0.54, 1.42, -0.38, -0.34, -0.11, 0.47, -0.14, -0.56, -2.41, -0.3, -0.35, -0.31, -0.49, -0.67, 0.6, 1.48, -0.32, -0.28, -0.05, 0.5885846838830657, -0.29, 0.18, 1.28, 2.16, 0.35, 0.39, 0.63, 1.21, -0.32, -0.11, 0.26, -0.52, -3.53, 0.03, 0.1, -0.32, 0.3, 0.14, -0.13, -1.52, 3.78, 0.64, 0.31, -0.86, -0.64, -0.87, 0.9, 0.93, -0.3, -0.46, -0.6, 0.8283906549799409, -0.37, -1.39, 4.627380952380952, 0.91, 1.42, -3.73, -1.09, 0.87, -0.91, -0.88, -0.64, -0.07, -0.9, -1.94, -1.77, -1.74, -1.5, -0.93, -0.18, 0.03, 0.27, 0.85, -0.46, -0.67, -0.21, 0.24, 0.82, -0.3, -0.33, -0.13, 2.49, -2.23, -2.59, -0.46, -1.01, -0.45, 0.58, -0.11, 0.5945528598385743, -0.32, -0.81, -0.31, -1.02, 0.63, -1.19, -0.4], ['502', -1.99, 0.15, -0.04, 0.07, 0.11, -0.28, -1.1458847420401708, -0.26, -0.8, 0.27, 0.99, 0.69, 0.37, 0.87, 0.43, 0.06107142857142857, 1.19, 0.17, -3.18, 0.38, 0.25, 0.98, 1.19, 0.82, -0.63, -0.6, -0.6773416050068874, -0.3, -0.61, -0.11, -0.55, -0.92, 0.2, -0.81, -4.12, -0.61, -0.73, 0.0, 0.2, -0.11615827680216084, 0.26, -1.5350638007838266, -0.41, -0.31, 0.18, -0.25, -0.63, 0.5, -0.51, -3.84, -0.31, -0.43, 0.29, 0.5, 0.14, -0.4, -0.99, -0.62, -0.94, -0.1, 0.5, 0.060799319727891155, -0.31, 0.81, -0.2, -3.54, 0.0, -0.12, 0.61, 0.81, 0.45, -0.14, -0.59, -0.44, -0.81, 0.32, -0.69, -4.01, -0.49, -0.4669183673469388, 0.11, 0.31, -0.05, -1.33, -2.39, 2.36, -0.16, -0.37, 0.76, -0.26, -3.59, -0.05, -0.18, 0.55, 0.75, 0.39, -1.13, 0.22, 1.13, 0.12, -3.23, 0.32, 0.19, 0.93, 1.13, 0.77, 0.121141873999017, 0.12, -1.65, -0.47, -0.55, -0.5, -0.9, -1.0, -4.32, -0.8, -0.93, -0.2, 0.0, -0.36, -0.67, 0.1, -3.34, 0.292244713705627, 0.08, 0.81, 1.01, 0.65, -1.55, -1.58, 0.08, -0.73, -3.93, 0.13, 0.14, 1.02, -1.01, -0.49, -0.07, 0.1, 0.23, 0.93, 0.5, -0.99, -0.04692021013122094, -1.51, 1.55, 1.55, -0.48, 1.67, -0.95, -0.6, 0.3147652642842468, -2.75, 0.76, 1.82, 2.67, -0.18, 3.56, 3.67, 3.54, 4.3, 4.51, 4.13, -1.38, -0.1, -0.12, 0.61, 0.81, 0.45, 0.02, 0.73, 0.93, 0.57, -0.75, -0.84, -0.7, 0.2, -0.16, -0.5, -0.5156036987247091, -0.26, 1.97, -1.67, -2.05, -0.7, 0.44, -0.9, -0.36, -1.1, -0.6, -0.44, -0.08, -0.21, -0.54, 0.23, 0.61, -0.8], ['503', -1.31, 0.0, -0.08, 0.19, -0.25, -0.32, 0.88, -1.03, -0.98, 0.05, 1.32, 0.36, 1.61, 1.62, 0.48, 0.46, 0.82, 0.0, -3.55, -0.04, -0.54, 1.36, 1.64, 0.38, -1.61, -0.82, -1.25, -0.95, 0.29, 0.29, -0.82, -0.84, -0.49, -1.3, -4.8, -1.34, -1.83, 0.04, 0.32, -0.93, 0.66, -1.1050638007838267, -0.31, 1.25, 1.25, 0.12, 0.11, 0.46, -0.36, -3.89, -0.4, -0.89, 1.0838655564790018, 1.27, 0.02, -1.1, -0.71, -0.73, -0.98, -1.54, 0.0, -1.11, -1.13, -0.78, -1.59, -5.08, -1.63, -2.12, -0.26, 0.02, -1.22, -1.14, -1.54, -1.12, -1.13, -0.78, -1.59, -5.08, -1.63, -2.12, -0.26, 0.02, -1.22, -1.42, -3.6, 3.58, -0.43, -0.02, 0.34, -0.48, -4.01, -0.52, -1.02, 0.87, 1.15, -0.0459922724755494, -1.71, -0.41, 0.35, -0.46, -3.9894285714285718, -0.5, -1.0, 0.89, 1.17, -0.09, 0.231141873999017, -0.36, -1.57, -0.45, -0.56, -0.28, -0.77, -0.82, -4.33, -0.8594642857142857, -1.35, 0.53, 0.81, -0.44, -1.16, 0.10307674813036727, -3.55, -0.04, -0.5304376417233561, 1.36, 1.64, 0.38, -1.18, -1.34, 0.17, -0.34, -5.47, -0.01, 0.07, 0.48, -0.43, -0.22, -0.44, -1.01, -0.19, 0.88, 0.4, -0.67, -0.08, -1.31, 1.21, 1.34, -0.43, 0.67, -0.86, -1.52, 0.75, -2.27, 15.02, 1.5, 2.21, 0.24, 3.73, 3.64, 3.12, 5.08, 5.38, 4.07, -1.33, 0.09, -0.5, 1.4, 1.68, 0.42, 0.59, 1.9, 2.19, 0.92, -0.96, -1.19, -1.29, 0.28, -0.96, -0.48, -0.42, -0.96, 7.65, -1.77, -7.81, -1.59, -0.05, -1.56, -1.24, -0.64, -0.32, 0.12, -0.06, 0.11, -0.33, -2.55, 0.57, 0.35], ['504', 3.65, -1.46, 0.23, -0.24, 0.14, 0.33, 1.2900361663652804, 0.18, 0.43, -1.32, -1.93, -2.23, -1.64, -2.18, -1.04, -2.91, -1.33, -1.55, 1.96, -2.57, -0.67, -1.24, -1.45, -1.85, 0.01, -0.28, 0.63, -0.3, 0.3, -0.25, 0.9, -1.0, 0.61, 0.5072589041444084, 3.96, -0.65, 1.28, 0.71, 0.49, 0.08, -0.12, 1.51, 0.93, 0.6, 0.05, 1.21, -0.7, 0.92, 0.69, 4.28, -0.35, 1.59, 1.01, 0.8, 0.39, 0.12006284630567655, 0.24, 0.57, 0.17, 0.33, -0.55, 0.61, -1.3, 0.32, 0.09, 3.66, -0.94, 0.98, 0.41, 0.19, -0.21, 0.6336060011417156, 0.88, 1.16, -0.75, 0.87, 0.64, 4.23, -0.4, 1.54, 0.96, 0.74, 0.34, 1.03, 0.611742947528662, -0.38, -0.28, -1.89, -0.29, -0.52, 3.03, -1.54, 0.38, -0.2, -0.41, -0.81, -0.027904761904761904, 1.65, 1.63, 1.4, 5.02, 0.36, 2.31, 1.73, 1.51, 1.1, 0.28, 1.6424455782312923, 0.5, 0.29, 0.28, 0.29567351865003194, 0.01, -0.23, 3.33, -1.26, 0.66, 0.09, -0.12, -0.53, -0.08, 0.24, 3.57, -1.03, 0.89, 0.32, 0.1, -0.3, 0.61, 0.45, -0.25, 0.37318678362356794, 0.0, 0.13, 0.05, -0.44, 0.46, 0.23, 0.36, 0.76, -2.62, -0.48, -0.27, 1.86, 0.35, 0.82, -0.72, -0.85, 0.27, -0.7, 0.53, 3.108390654979941, -1.52, 0.06, 0.72, -0.03, -0.05, 2.67, -3.21, -4.44, -2.58, -3.13, -3.34, -3.73, 0.8, 1.28, 1.95, 1.37, 1.15, 0.74, -0.65, -0.57, -0.78, -1.18, 0.63, 0.69, -0.08, -0.22, -0.62, 0.25, 0.24, 0.22257604962387836, 0.4, -0.1, -0.35, -0.03, 0.16, 0.21863744820097092, -0.4, 0.0, 0.32, 0.15, 0.87, 0.29, 0.54, -0.94, 0.58, 0.43], ['505', -3.94, 0.63, 0.041221715620458746, -0.07, -0.5, 0.92, 1.07, 0.5817205965359588, 1.25, 0.27, -1.31, -0.52, -0.25, -1.51, 0.86, 1.27, -0.95, -0.02, 0.27, 0.65, -0.11, -0.42, -1.44, -0.7, 1.56, 0.04, 1.6326583949931126, 0.8, 1.07, -0.2, 2.19, 2.61, 0.36, 1.31, 1.6, 1.98, 1.22, 0.9, -0.14, 0.62, -0.07, 2.1749361992161735, 0.79, 0.27, -1.0, 1.38, 1.8, -0.43, 0.5, 0.79, 1.18, 0.41, 0.1, -0.93, -0.18, 0.19, -0.5, 0.22, 1.51, 0.52, -1.26, 1.11, 1.52, -0.7, 0.23, 0.52, 0.9, 0.14, -0.17, -1.2, -0.45, 0.41, 1.81, 2.4, 2.82, 0.57, 1.51, 1.81, 2.19, 1.42, 1.11, 0.07, 0.82, 2.05, 4.48, -4.45, -0.58, 0.41, -1.79, -0.87, -0.58, -0.2, -0.95, -1.26, -2.28, -1.54, -2.17, -0.99, -2.19, -1.28, -0.99, -0.61, -1.36, -1.67, -2.68, -1.94, 0.36, -0.8406317967746538, 3.39, 0.97, 1.0, 0.89, 1.23, 0.94, 1.23, 1.62, 0.85, 0.54, -0.5, 0.25, 0.67, 0.29, 0.29, 0.67, -0.09, -0.4, -1.42, -0.68, 1.12, 1.4227619047619047, 0.14, 0.98, -6.35, 0.22, 0.2, -2.01, 2.01, 1.0, 0.72, -0.31, 0.67, -1.91, -0.97, -1.99, 0.5030797898687791, 2.98, -2.7, -2.87, 0.99, -3.01, 1.95, 0.4, -0.2, 3.58, -8.25, -2.47, -3.63, -0.67, 0.0, 0.38, -0.38, -0.6483894557823129, -1.71, -0.97, 2.9, -0.38, -0.75, -1.06, -2.08, -1.34, 0.38, -0.31, -1.34, -0.59, 1.28, 1.59, 0.7772746849074343, -1.03, -0.28, 0.95, 1.0643963012752908, 0.5, -4.2, 2.21, 4.27, 0.71, 0.76, 1.74, 0.76, 0.66, 1.12, 0.6, 0.06, 0.79, 0.98, -0.71, 0.58, 1.0], ['506', 1.61, 1.11, -0.17, -0.11, -0.24, 0.24, 1.1, -0.08, 0.29, 0.19, 0.72, -0.6592857142857144, 0.62, -0.53, 0.41, 0.38, -0.73, -0.23, -0.69, 0.38, -0.2, -1.91, -1.43, 0.04511662742019901, 0.72, 1.29, -0.53, -1.38, -0.11, -1.25, -0.32, -0.34, -1.44, -0.95, -1.41, -0.34, -0.92, -2.61, -2.14, -0.81, 0.74, -0.37506380078382656, 0.86, 1.29, 0.13, 1.07, 1.05, -0.06, 0.43, -0.03, 1.05, 0.46, -1.25, -0.78, 0.57, 0.13006284630567655, 0.53, 0.35, 0.33, -0.43, -1.14, -0.21, -0.24, -1.34, -0.85, -1.3, -0.24, -0.82, -2.51, -2.04, -0.71, 0.0, 0.72, 0.94, 0.92, -0.2, 0.3, -0.16, 0.92, 0.33, -1.38, -0.91, 0.44, -0.04, 4.38, -4.42, -0.21, -0.02, -1.13, -0.64, -1.09, -0.03, -0.61, -2.3, -1.83, -0.5, 0.29, -0.19, -1.1, -0.61, -1.07, 0.0, -0.5173734626473064, -2.28, -1.81, -0.48, 0.69, -0.19, 2.55, 0.51, 0.76, 0.37, 0.92, 0.5, 0.03, 1.11, 0.53, -1.19, -0.71, 0.63, 2.02, 0.42, -0.46, 0.61, 0.03, -1.68, -1.2, 0.14, 0.69, 0.44, -0.09, 1.07, 0.68, 0.48, 0.42, -0.44, 0.44, 0.21, 1.29, -0.55, 0.417758979116122, -0.96, -0.54, 0.8, 0.38, 1.81, -1.77, -1.56, 0.54, -0.64, 1.06, 1.87, -0.97, 2.68, -3.08, -1.86, -2.67, -0.4, 0.89, 1.08, 0.49, -1.22, -0.75, 0.6, 1.55, -0.19, -0.58, -2.28, -1.81, -0.47, 0.39, -1.71, -1.23, 0.11, 0.27, -0.08, 2.14, 0.48, 1.85, 0.49, 0.63, 0.0, -1.62, 1.78, 1.53, 0.68, 0.31, 1.65, 1.36, 0.12, 0.47, -0.06, 0.75, 0.34, 0.29, -0.1, 1.44, 0.63], ['507', 2.84, -0.72, -0.028778284379541254, -0.05, -1.06, -0.35, -0.9358847420401708, -1.06, -0.87, -0.09, 0.74, 0.63, 1.35, 1.58, 0.63, -0.32, 0.92, -0.06, -2.85, 1.58, -0.31, 0.74, 1.38, 0.38, -0.21, -1.44, -0.7873416050068875, -0.11, 0.61, 0.84, -0.11, -1.06, 0.18, -0.8, -3.57, 0.83, -1.04, 0.0, 0.63, -0.36, -0.47, -1.99, -0.71, 0.72, 1.1178753944468232, 0.0, -0.94, 0.3, -0.68, -3.46, 0.95, -0.93, 0.12, 0.75, -0.25, -0.37, -1.28, -0.23217202719021607, -0.73, -1.42, 0.23, -0.71, -1.65, -0.42, -1.39, -4.15, 0.23, -1.64, -0.6, 0.03, -0.96, -0.8, -1.64, -0.94, -1.88, -0.65, -1.62, -4.37, 0.0, -1.86, -0.83, -0.2, -1.19, -1.24, -3.78, 3.76, -0.71, -0.95, 0.29, -0.68, -3.46, 1.143744771101914, -0.93, 0.11, 0.75, -0.1959922724755494, -2.2673809523809525, 0.3173665312165629, 1.25, 0.26, -2.54, 1.91, 0.08262653735269351, 1.07, 1.71, 0.7, -0.02, 0.23, -1.45427628811696, -0.72, -0.91, -0.59, -1.0, -0.97, -3.74, 0.65, -1.22, -0.18, 0.45, -0.54, -0.81, -0.02, -2.8, 1.64, -0.25, 0.8, 1.44, 0.44, -1.35, -0.16, -0.22, -0.94, -4.51, -0.13, 0.0, 0.84, -0.85, -0.4, -0.25, -0.11, 3.37, 1.42, 0.67, 1.47, -0.28, -2.17, 2.21, 2.13, -0.7, 1.14, -1.4, 1.31, -0.66, -2.97, 0.29, 1.99, 2.94, -3.34, 2.85, 4.56, 2.62, 3.7, 4.36, 3.33, -2.05, -1.64, -1.86, -0.82, -0.2, -1.19, 0.22, 1.05, 1.69, 0.68, -0.92, -1.0, -0.82, 0.63, -0.36, -0.69, -0.76, -0.95, 0.09, -1.17, -0.19, -0.47, -1.57, -1.45, -0.99, -0.44, -0.43, -0.32, -0.3, -0.51, -0.46, -1.03, -2.41, -0.9269832262926028], ['508', -0.33, 0.23, 0.13122171562045873, -0.02, -0.61, -0.05, -0.46, -1.25, 0.14, -0.8278571428571428, -0.67, -1.1410079365079364, -0.36, 0.25, 1.43, -0.69, -0.75, -0.75, -2.47, 0.37, -0.79, -1.49, -1.17, -1.34, -0.76, -0.67, -0.12734160500688754, -0.48, 0.32, 0.93, 2.167819971295091, -0.02, -0.08, 0.03725890414440844, -1.81, 1.05, -0.12, -0.82, -0.5, -0.6261582768021609, -1.34, -0.7150638007838266, 0.32, 0.8, 1.43, 2.61, 0.47, 0.41, 0.41, -1.33, 1.54, 0.37, -0.34, -0.02, -0.19, -0.1, -1.5, -1.62, 0.11, -0.48, 0.62, 1.79, -0.33, -0.39, -0.4, -2.12, 0.73, -0.43, -1.13, -0.81, -0.98, -1.02, -1.09, 1.17, -0.94, -1.0, -1.01, -2.72, 0.11, -1.04, -1.74, -1.42, -1.5364403582748793, 0.06, 0.9, -1.02, -2.1933017616146797, -2.09, -2.14, -2.15, -3.84, -1.04, -2.19, -2.87, -2.56, -2.73, -2.68, -0.14, -0.06, -0.06, -1.79, 1.07, -0.1, -0.8, -0.48, -0.65, 0.03, -0.19, 1.4101046511627906, 0.07, 0.11, 0.05, -0.09, -0.01, -1.74, 1.12, -0.04, -0.74, -0.43, -0.59, 0.72, -0.08, -1.73, 1.13, -0.04, -0.6142004503433073, -0.42, -0.59, 0.46, 0.16, -0.06, 0.03318678362356798, -7.85, 0.02, 0.12, -0.15, 0.14, 0.07, 0.37, -1.49, 2.46, -0.13, -0.09, -0.12, 0.4, 0.17, -0.15, -0.16, 0.12329080486385297, -0.17, 0.12, 0.78, -0.4, -0.18, -3.95, 0.14, 0.1, -2.46, 1.68, 2.91, 1.72, 1.01, 1.33, 1.16, 0.2, -1.0656457669314812, -1.15, -1.85, -1.53, -1.7, -0.04, -0.7, -0.38, -0.55, 0.08, 0.04, 0.66, 0.32, 0.15, 0.09, 0.08, -1.19, -2.55, 0.40111637918066984, 2.43, -0.36, -0.66, 0.34, -0.17, -0.56, 0.0, 0.42, 0.8, 0.16, 0.51, -1.81, -1.01, 0.3330167737073973], ['509', -1.13, 0.06, 0.011221715620458745, 0.16, 0.78, 0.8284196236737595, -0.06, -0.39, 0.66, -0.18, -1.15, -0.72, 0.47, -0.45, 0.58, 0.46, -1.02, -0.43, -5.43, -0.95, -0.25, 0.6, 0.27, -0.74, 0.74, 0.27, 0.98, 0.43, 1.64, 0.71, 1.75, 1.63, 0.13, 0.73, -4.33, 0.2, 0.91, 1.77, 1.43, 0.41, -0.18, -0.21, 0.55, 1.2, 0.28, 1.31, 1.19, -0.3, 0.3, -4.74, -0.23, 0.47, 1.33, 1.0, -0.02, 0.76, 0.23, -0.8, 0.67, -0.64, -0.91, 0.11, -0.01, -1.48, -0.89, -5.88, -1.41, -0.72, 0.13, -0.2, -1.21, -0.94, 0.27, 1.03, 0.91, -0.58, 0.02, -5.01, -0.5, 0.19, 1.05, 0.71, -0.3, 0.77, -0.9382570524713382, 1.06, -0.75, -0.12, -1.59, -1.0, -5.98, -1.52, -0.83, 0.02, -0.31, -1.32, -1.0187766439909298, -0.5526334687834371, -1.47, -0.88, -5.86, -1.4, -0.71, 0.14, -0.19, -1.2, 0.23, -0.59, -0.82, 0.66, 0.38, 0.93, 0.85, 0.6, -4.46, 0.07, 0.77, 1.64, 1.3, 0.28, -0.8434639289282145, 0.25, -5.03, -0.52, 0.17, 1.03, 0.7, -0.32, -0.36, -0.14, 0.58, 0.77, -4.05, 0.23, 0.2, -2.62, 2.59, 1.31, -0.96, -0.63, -1.72, -1.3, -0.62, -0.53, 0.29, 2.05, -1.91, -2.03, 0.68, -3.95, 1.33, -0.6, 0.26, 2.52, 1.56, -1.72, -2.62, 1.5938095238095238, 5.56, 4.74, 5.48, 6.38, 6.03, 4.96, 2.0931678995607568, 0.78, 0.7, 1.56, 1.22, 0.21, 0.08, 0.86, 0.52, -0.49, 0.6, 0.59, -0.77, -0.33, -1.2577512446849837, 0.64, 0.67, -0.2874239503761216, 0.94, 0.51, -0.97, 0.39, 0.66, -0.44, -1.01, 1.68, 1.66, -0.08, 0.32, 0.19, 0.57, -0.23, 0.92, 1.17], ['510', -7.99, -0.78, 0.01, 0.2, -1.57, -1.0, -2.76, -1.99, -2.44, -1.74, 1.29, 1.1789920634920634, -0.26, -0.23, -0.1, -0.06, 0.21, -1.51, -1.74, 0.6, -2.21, -1.07, -0.23, -0.45, -1.16, -2.15, -2.99, -0.11, -1.53, -1.5, -1.37, -1.33, -1.06, -2.77, -2.99, -0.68, -3.45, -2.33, -1.5, -1.6761582768021608, -1.48, -2.98, -2.88, -1.42, -1.39, -1.26, -1.20359693877551, -0.9107210884353741, -2.66, -2.88, -0.57, -3.34, -2.22, -1.38, -1.61, -1.22, -1.63, -1.99, -2.35, -1.48, 0.03, 0.16, 0.21, 0.48, -1.25, -1.48, 0.86, -1.95, -0.81, 0.04, -0.19, -2.16, -1.51, 0.13, 0.17, 0.44, -1.29, -1.51, 0.83, -1.98, -0.84, 0.0, -0.23, -2.8, -3.94, 4.02, -1.64, 0.04, 0.32, -1.41, -1.64, 0.7, -2.11, -0.97, -0.13, -0.35, -4.9, -1.68, 0.27, -1.46, -1.68, 0.65, -2.15, -1.01, -0.17, -0.4, -0.41, -1.74, -1.31, -1.08, -0.98, -1.25, -1.95, -1.72, -1.95, 0.38, -2.42, -1.28, -0.44, -0.67, -0.64, -0.23, -0.23, 2.14, -0.7, 0.45, 1.31, 1.08, -1.16, -1.46, 0.31, -1.33, -14.62, -0.29, -0.14, 3.27, -3.31, -1.64, -0.27, -2.4, 4.66, 2.15, 1.07, -4.02, -0.26, -3.3, 3.32, 3.15, -1.08, 4.78, -2.16, -2.15, 1.11, -5.77, 9.04, 3.83, 5.7, -4.55, 0.0, 2.38, -0.47, 0.68, 1.54, 1.31, -3.25, -2.32, -2.78, -1.66, -0.82, -1.04, 0.48, 1.16, 2.02, 1.79, -2.37, -2.53, -0.68, 0.85, 0.62, -1.05, -1.2, -2.14, 5.57, -1.37, -5.64, -1.59, -1.43, -1.52, -0.23, -0.8, -1.46, -0.15, -0.01, -0.53, -1.29, -2.57, -2.34, -1.41]], 'figimage': <function figimage at 0x3195140>, 'jet': <function jet at 0x3198848>, 'figaspect': <function figaspect at 0x3183938>, 'Line2D': <class 'matplotlib.lines.Line2D'>, 'exp2': <ufunc 'exp2'>, 'imshow': <function imshow at 0x3197398>, 'axhline': <function axhline at 0x31968c0>, 'bool8': <type 'numpy.bool_'>, 'colormaps': <function colormaps at 0x31961b8>, 'msort': <function msort at 0x236d5f0>, 'alltrue': <function alltrue at 0x21da2a8>, 'zeros': <built-in function zeros>, 'identity': <function identity at 0x21dbde8>, 'False_': False, 'ispower2': <function ispower2 at 0x2c522a8>, 'LogFormatterExponent': <class 'matplotlib.ticker.LogFormatterExponent'>, 'ihfft': <function ihfft at 0x24090c8>, 'nansum': <function nansum at 0x236cb18>, 'bool_': <type 'numpy.bool_'>, '_i78': u'train.shape', '_44': (200, 198), 'inexact': <type 'numpy.inexact'>, 'distances_along_curve': <function distances_along_curve at 0x2c53c08>, 'broadcast': <type 'numpy.broadcast'>, 'copyto': <built-in function copyto>, 'amin': <function amin at 0x21da5f0>, 'arctanh': <ufunc 'arctanh'>, 'typecodes': {'All': '?bhilqpBHILQPefdgFDGSUVOMm', 'Complex': 'FDG', 'AllFloat': 'efdgFDG', 'Integer': 'bhilqp', 'UnsignedInteger': 'BHILQP', 'Float': 'efdg', 'Character': 'c', 'Datetime': 'Mm', 'AllInteger': 'bBhHiIlLqQpP'}, 'number': <type 'numpy.number'>, 'savetxt': <function savetxt at 0x23fb410>, 'copy': <function copy at 0x236c500>, 'int_': <type 'numpy.int64'>, '_i69': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'std': <function std at 0x21daaa0>, 'segments_intersect': <function segments_intersect at 0x2c51848>, 'not_equal': <ufunc 'not_equal'>, 'fromfunction': <function fromfunction at 0x21dbb18>, 'Figure': <class 'matplotlib.figure.Figure'>, 'tril_indices_from': <function tril_indices_from at 0x230db18>, 'double': <type 'numpy.float64'>, 'require': <function require at 0x21c2758>, 'predicted_probs': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.073016773707397273, 0.0, 0.0], 'triplot': <function triplot at 0x3197d70>, 'headers': array(['O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8', 'O9', 'O10', 'O11',\n       'O12', 'O13', 'O14', 'O15', 'O16', 'O17', 'O18', 'O19', 'O20',\n       'O21', 'O22', 'O23', 'O24', 'O25', 'O26', 'O27', 'O28', 'O29',\n       'O30', 'O31', 'O32', 'O33', 'O34', 'O35', 'O36', 'O37', 'O38',\n       'O39', 'O40', 'O41', 'O42', 'O43', 'O44', 'O45', 'O46', 'O47',\n       'O48', 'O49', 'O50', 'O51', 'O52', 'O53', 'O54', 'O55', 'O56',\n       'O57', 'O58', 'O59', 'O60', 'O61', 'O62', 'O63', 'O64', 'O65',\n       'O66', 'O67', 'O68', 'O69', 'O70', 'O71', 'O72', 'O73', 'O74',\n       'O75', 'O76', 'O77', 'O78', 'O79', 'O80', 'O81', 'O82', 'O83',\n       'O84', 'O85', 'O86', 'O87', 'O88', 'O89', 'O90', 'O91', 'O92',\n       'O93', 'O94', 'O95', 'O96', 'O97', 'O98', 'O99', 'O100', 'O101',\n       'O102', 'O103', 'O104', 'O105', 'O106', 'O107', 'O108', 'O109',\n       'O110', 'O111', 'O112', 'O113', 'O114', 'O115', 'O116', 'O117',\n       'O118', 'O119', 'O120', 'O121', 'O122', 'O123', 'O124', 'O125',\n       'O126', 'O127', 'O128', 'O129', 'O130', 'O131', 'O132', 'O133',\n       'O134', 'O135', 'O136', 'O137', 'O138', 'O139', 'O140', 'O141',\n       'O142', 'O143', 'O144', 'O145', 'O146', 'O147', 'O148', 'O149',\n       'O150', 'O151', 'O152', 'O153', 'O154', 'O155', 'O156', 'O157',\n       'O158', 'O159', 'O160', 'O161', 'O162', 'O163', 'O164', 'O165',\n       'O166', 'O167', 'O168', 'O169', 'O170', 'O171', 'O172', 'O173',\n       'O174', 'O175', 'O176', 'O177', 'O178', 'O179', 'O180', 'O181',\n       'O182', 'O183', 'O184', 'O185', 'O186', 'O187', 'O188', 'O189',\n       'O190', 'O191', 'O192', 'O193', 'O194', 'O195', 'O196', 'O197',\n       'O198', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10',\n       'I11', 'I12', 'I13', 'I14', 'I15', 'I16', 'I17', 'I18', 'I19',\n       'I20', 'I21', 'I22', 'I23', 'I24', 'I25', 'I26', 'I27', 'I28',\n       'I29', 'I30', 'I31', 'I32', 'I33', 'I34', 'I35', 'I36', 'I37',\n       'I38', 'I39', 'I40', 'I41', 'I42', 'I43', 'I44', 'I45', 'I46',\n       'I47', 'I48', 'I49', 'I50', 'I51', 'I52', 'I53', 'I54', 'I55',\n       'I56', 'I57', 'I58', 'I59', 'I60', 'I61', 'I62', 'I63', 'I64',\n       'I65', 'I66', 'I67', 'I68', 'I69', 'I70', 'I71', 'I72', 'I73',\n       'I74', 'I75', 'I76', 'I77', 'I78', 'I79', 'I80', 'I81', 'I82',\n       'I83', 'I84', 'I85', 'I86', 'I87', 'I88', 'I89', 'I90', 'I91',\n       'I92', 'I93', 'I94', 'I95', 'I96', 'I97', 'I98', 'I99', 'I100',\n       'I101', 'I102', 'I103', 'I104', 'I105', 'I106', 'I107', 'I108',\n       'I109', 'I110', 'I111', 'I112', 'I113', 'I114', 'I115', 'I116',\n       'I117', 'I118', 'I119', 'I120', 'I121', 'I122', 'I123', 'I124',\n       'I125', 'I126', 'I127', 'I128', 'I129', 'I130', 'I131', 'I132',\n       'I133', 'I134', 'I135', 'I136', 'I137', 'I138', 'I139', 'I140',\n       'I141', 'I142', 'I143', 'I144', 'I145', 'I146', 'I147', 'I148',\n       'I149', 'I150', 'I151', 'I152', 'I153', 'I154', 'I155', 'I156',\n       'I157', 'I158', 'I159', 'I160', 'I161', 'I162', 'I163', 'I164',\n       'I165', 'I166', 'I167', 'I168', 'I169', 'I170', 'I171', 'I172',\n       'I173', 'I174', 'I175', 'I176', 'I177', 'I178', 'I179', 'I180',\n       'I181', 'I182', 'I183', 'I184', 'I185', 'I186', 'I187', 'I188',\n       'I189', 'I190', 'I191', 'I192', 'I193', 'I194', 'I195', 'I196',\n       'I197', 'I198', 'I199', 'I200', 'I201', 'I202', 'I203', 'I204',\n       'I205', 'I206', 'I207', 'I208', 'I209', 'I210', 'I211', 'I212',\n       'I213', 'I214', 'I215', 'I216', 'I217', 'I218', 'I219', 'I220',\n       'I221', 'I222', 'I223', 'I224', 'I225', 'I226', 'I227', 'I228',\n       'I229', 'I230', 'I231', 'I232', 'I233', 'I234', 'I235', 'I236',\n       'I237', 'I238', 'I239', 'I240', 'I241', 'I242', 'I243', 'I244'], \n      dtype='|S10'), '_iii': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'xlabel': <function xlabel at 0x3195a28>, 'typeNA': {<type 'numpy.float16'>: 'Float16', <type 'numpy.int16'>: 'Int16', 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, <type 'numpy.timedelta64'>: 'Timedelta64', <type 'numpy.uint8'>: 'UInt8', 'c16': 'Complex64', <type 'numpy.datetime64'>: 'Datetime64', 'D': 'Complex64', <type 'numpy.int8'>: 'Int8', 'H': 'UInt16', 'L': 'UInt64', <type 'numpy.void'>: 'Void0', <type 'numpy.bool_'>: 'Bool', 'd': 'Float64', 'h': 'Int16', 'l': 'Int64', <type 'numpy.unicode_'>: 'Unicode0', 'c32': 'Complex128', <type 'numpy.string_'>: 'String0', 'Timedelta64': <type 'numpy.timedelta64'>, 'b1': 'Bool', 'M8': 'Datetime64', 'String0': <type 'numpy.string_'>, <type 'numpy.object_'>: 'Object0', 'I': 'UInt32', '?': 'Bool', 'Void0': <type 'numpy.void'>, <type 'numpy.complex256'>: 'Complex128', 'G': 'Complex128', 'O': 'Object0', 'UInt8': <type 'numpy.uint8'>, 'S': 'String0', <type 'numpy.complex128'>: 'Complex64', 'UInt64': <type 'numpy.uint64'>, 'g': 'Float128', <type 'numpy.complex64'>: 'Complex32', 'Float16': <type 'numpy.float16'>, <type 'numpy.float128'>: 'Float128', 'Bool': <type 'numpy.bool_'>, 'u8': <type 'numpy.uint64'>, <type 'numpy.float64'>: 'Float64', 'u4': <type 'numpy.uint32'>, 'Unicode0': <type 'numpy.unicode_'>, 'u1': <type 'numpy.uint8'>, 'u2': <type 'numpy.uint16'>, 'Datetime64': <type 'numpy.datetime64'>, 'Int8': <type 'numpy.int8'>, <type 'numpy.float32'>: 'Float32', 'B': 'UInt8', 'F': 'Complex32', 'c8': 'Complex32', 'Int64': <type 'numpy.int64'>, 'Complex32': <type 'numpy.complex64'>, 'V': 'Void0', <type 'numpy.uint64'>: 'UInt64', 'b': 'Int8', 'f': 'Float32', 'm8': 'Timedelta64', <type 'numpy.int64'>: 'Int64', 'f16': 'Float128', 'UInt32': <type 'numpy.uint32'>, 'f2': 'Float16', 'f4': 'Float32', 'f8': 'Float64', 'Complex128': <type 'numpy.complex256'>, <type 'numpy.uint64'>: 'UInt64', 'Object0': <type 'numpy.object_'>, 'Int16': <type 'numpy.int16'>, <type 'numpy.int64'>: 'Int64', 'Float64': <type 'numpy.float64'>, 'UInt16': <type 'numpy.uint16'>, 'Float32': <type 'numpy.float32'>, 'i8': <type 'numpy.int64'>, <type 'numpy.uint32'>: 'UInt32', 'i1': <type 'numpy.int8'>, 'i2': <type 'numpy.int16'>, 'M': 'Datetime64', 'i4': <type 'numpy.int32'>, 'Q': 'UInt64', 'U': 'Unicode0', <type 'numpy.int32'>: 'Int32', 'e': 'Float16', 'i': 'Int32', 'm': 'Timedelta64', 'q': 'Int64', <type 'numpy.uint16'>: 'UInt16', 'Float128': <type 'numpy.float128'>}, '_i11': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', 'lastObserved': array([[ 2.78,  0.77,  0.1 , ...,  3.25,  3.05,  1.55],\n       [-4.62,  0.06, -0.22, ...,  0.52, -0.56,  0.33],\n       [ 0.02,  0.13,  0.18, ..., -0.47,  0.91,  0.97],\n       ..., \n       [-0.33,  0.23,  0.12, ..., -1.81, -1.01,  0.26],\n       [-1.13,  0.06,  0.  , ..., -0.23,  0.92,  1.17],\n       [-7.99, -0.78,  0.01, ..., -2.57, -2.34, -1.41]]), 'getbuffer': <built-in function getbuffer>, 'xcorr': <function xcorr at 0x3197e60>, 'slogdet': <function slogdet at 0x238cb90>, 'clip': <function clip at 0x21da0c8>, 'tripcolor': <function tripcolor at 0x3197cf8>, '_i27': u'trainInput.shape', 'half': <type 'numpy.float16'>, 'normal': <built-in method normal of mtrand.RandomState object at 0x7f399f841690>, '_i126': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', 'savez_compressed': <function savez_compressed at 0x23fb230>, 'TickHelper': <class 'matplotlib.ticker.TickHelper'>, 'isinteractive': <function isinteractive at 0x3194410>, 'eigvals': <function eigvals at 0x238c758>, 'seed': <built-in method seed of mtrand.RandomState object at 0x7f399f841690>, 'triu_indices_from': <function triu_indices_from at 0x230dc08>, 'conjugate': <ufunc 'conjugate'>, 'clim': <function clim at 0x3196320>, 'array2string': <function array2string at 0x21db050>, 'alterdot': <built-in function alterdot>, 'cross_validation': <module 'sklearn.cross_validation' from '/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc'>, 'asfortranarray': <function asfortranarray at 0x21c26e0>, 'binary_repr': <function binary_repr at 0x21dbc08>, 'angle': <function angle at 0x236c6e0>, '_78': (510, 55, 442), '_i9': u'len(targets)', 'randint': <built-in method randint of mtrand.RandomState object at 0x7f399f841690>, '_i7': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(trainOutput), n_folds=63, indices=False)', '_i6': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(train), n_folds=63, indices=False)', '_i5': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', 'linalg': <module 'numpy.linalg' from '/usr/local/lib/python2.7/dist-packages/numpy/linalg/__init__.pyc'>, 'apply_over_axes': <function apply_over_axes at 0x2374b18>, '_i2': u'ls', '_i1': u'cd /home/lane/Kaggle/03\\\\ Predicting\\\\ Stock\\\\ Prices/', 'yoda': array([ 0.        ,  0.22      ,  0.        ,  0.        ,  0.22      ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.1       ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.02714286,  0.        ,  0.01714286,\n        0.        ,  0.1       ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.02714286,  0.        ,  0.        ,  0.01714286,\n        0.        ,  0.        ,  0.61571429,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.61571429,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.02714286,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.1       ,  0.        ,  0.        ,\n        0.02714286,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.22      ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.02714286,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.61571429,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.1       ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.22      ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.61571429,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'figlegend': <function figlegend at 0x3194de8>, 'ERR_LOG': 5, 'right_shift': <ufunc 'right_shift'>, 'take': <function take at 0x21d16e0>, 'rollaxis': <function rollaxis at 0x21c2c08>, 'set_state': <built-in method set_state of mtrand.RandomState object at 0x7f399f841690>, 'solve': <function solve at 0x238c500>, 'FixedFormatter': <class 'matplotlib.ticker.FixedFormatter'>, 'boxplot': <function boxplot at 0x3196c08>, 'SecondLocator': <class 'matplotlib.dates.SecondLocator'>, 'spectral': <function spectral at 0x3198b18>, 'get_numarray_include': <function get_numarray_include at 0x23691b8>, 'trace': <function trace at 0x21d1de8>, 'Artist': <class 'matplotlib.artist.Artist'>, 'any': <function any at 0x21da320>, 'Button': <class 'matplotlib.widgets.Button'>, 'who': <function who at 0x2369578>, 'compress': <function compress at 0x21da050>, 'NullFormatter': <class 'matplotlib.ticker.NullFormatter'>, 'histogramdd': <function histogramdd at 0x236c2a8>, '_i88': u'test.shape', '_i89': u'y.shape', 'beta': <built-in method beta of mtrand.RandomState object at 0x7f399f841690>, 'amap': <function amap at 0x2c51d70>, 'multiply': <ufunc 'multiply'>, '_i81': u'X.shape', 'mask_indices': <function mask_indices at 0x230da28>, 'detrend_none': <function detrend_none at 0x2c4f7d0>, '_i84': u'test.shape', 'amax': <function amax at 0x21da578>, 'numCols': 442, '_66': (510, 55, 198), 'subplot': <function subplot at 0x3195500>, 'logical_not': <ufunc 'logical_not'>, 'dist_point_to_segment': <function dist_point_to_segment at 0x2c517d0>, 'trainingDays': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510], '_i75': u'traincv.shape', '_i74': u'traincv', '_i77': u'train[traincv]', '_i76': u'testcv.shape', '_i71': u'cv', 'nbytes': {<type 'numpy.float16'>: 2, <type 'numpy.string_'>: 0, <type 'numpy.float128'>: 16, <type 'numpy.uint64'>: 8, <type 'numpy.int16'>: 2, <type 'numpy.timedelta64'>: 8, <type 'numpy.object_'>: 8, <type 'numpy.float64'>: 8, <type 'numpy.int64'>: 8, <type 'numpy.uint8'>: 1, <type 'numpy.datetime64'>: 8, <type 'numpy.complex256'>: 32, <type 'numpy.float32'>: 4, <type 'numpy.uint32'>: 4, <type 'numpy.int8'>: 1, <type 'numpy.void'>: 0, <type 'numpy.complex128'>: 16, <type 'numpy.uint64'>: 8, <type 'numpy.int32'>: 4, <type 'numpy.bool_'>: 1, <type 'numpy.unicode_'>: 0, <type 'numpy.complex64'>: 8, <type 'numpy.int64'>: 8, <type 'numpy.uint16'>: 2}, 'exp': <ufunc 'exp'>, '_ih': ['', u\"get_ipython().magic(u'cd /home/lane/Kaggle/03\\\\\\\\ Predicting\\\\\\\\ Stock\\\\\\\\ Prices/')\", u\"get_ipython().system(u'ls -F --color ')\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(train), n_folds=63, indices=False)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(trainOutput), n_folds=63, indices=False)', u'len(trainOutput)', u'len(targets)', u'len(target)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'trainInput.shape', u'trainOutput.shape', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:197] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:198] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'trainInput[509,54,243]', u'trainInput[509,54,244]', u'trainInput[509,54,243]', u'fullInput[509,54,244+197]', u'train            = np.zeros((510,55,244+198))\\ntrain[:,:,0:198] = trainOutput\\ntrain[:,:,198:]  = trainInput', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(target[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'trainOutput.shape', u'len(trainOutput[0])', u'target.shape', u'target.shape', u'trainInput.shape', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput(:,-1,:)', u'lastObserved = trainOutput[:,-1,:]\\nlastObserved.shape', u'target.shape', u'normTarget   = target - lastObserved[:target.shape[0],:]', u'normTarget.shape', u'target.shape', u'plot(normTarget[:,0])', u'plot(normTarget[:,197])', u'hist(normTarget[:,197])', u'hist(normTarget)', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1)))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1)))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1))', u'yoda.shape', u'normTarget.shape', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-2,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((200*198,1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True)', u\"yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,4)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,6)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nyaxis('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',norm=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',normed=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\nderiv.shape', u'normTarget.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'len(target)', u'cv', u'for i in cv:\\n    print i', u'for i,j in cv:\\n    print i,j', u'traincv', u'traincv.shape', u'testcv.shape', u'train[traincv]', u'train.shape', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201,:]\\ntest  = X[201:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201]\\ntest  = X[201:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'train.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:200]\\ntest  = X[200:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'y.shape', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'train.shape', u'test.shape', u'yoda = X.reshape((X.shape[0],1))', u'yoda.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock].reshape((deriv.shape[0],1))\\ny     = normTarget[:,stock]\\ntrain = X[:200,:]\\ntest  = X[200:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'predicted_probs.shape', u'len(predicted_probs)', u'len(predicted_probs[0])', u'lastObserved[:,stock].shape', u'pred = predicted_probs + lastObserved[200:,stock]', u'pred = predicted_probs + lastObserved[200:,stock]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape[2]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'numStocks', u'type(predicted_probs)', u'yoda = np.asarray(predicted_probs)\\nyoda.shape', u'yoda = np.asarray(predicted_probs)\\nluke = np.zeros((310,198))\\nluke[:,0] = yoda', u'pred[0]', u'## Fit Random Forest and generate predictions\\nnumStocks   = trainOutput.shape[2]\\nperformance = []\\npred        = np.zeros((310,numStocks))\\nfor stock in xrange(numStocks):\\n    \\n    # get stock-specific features\\n    X     = deriv[:,stock].reshape((deriv.shape[0],1))\\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n\\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n\\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import smtplib', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import pybrain', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random\\nimport smtplib\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=500, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=25, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'sheet.shape', u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection'], 'axvspan': <function axvspan at 0x3196a28>, 'FuncFormatter': <class 'matplotlib.ticker.FuncFormatter'>, 'dot': <built-in function dot>, 'int0': <type 'numpy.int64'>, 'pylab': <module 'matplotlib.pylab' from '/usr/local/lib/python2.7/dist-packages/matplotlib/pylab.pyc'>, '_i23': u'trainOutput.shape', 'WE': WE, '_i121': u'import pybrain', 'longfloat': <type 'numpy.float128'>, 'draw_if_interactive': <function wrapper at 0x325c410>, 'rayleigh': <built-in method rayleigh of mtrand.RandomState object at 0x7f399f841690>, 'text': <function text at 0x31981b8>, 'random': <module 'random' from '/usr/lib/python2.7/random.pyc'>, 'demean': <function demean at 0x2c4f6e0>, 'random_integers': <built-in method random_integers of mtrand.RandomState object at 0x7f399f841690>, 'datetime': <module 'datetime' from '/usr/lib/python2.7/lib-dynload/datetime.so'>, 'colors': <function colors at 0x3196140>, 'stackplot': <function stackplot at 0x3197a28>, '_i124': u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", 'locator_params': <function locator_params at 0x3198320>, '_67': (510, 198), '_i125': u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', 'find': <function find at 0x2c51050>, '_i20': u'train            = np.zeros((510,55,244+198))\\ntrain[:,:,0:198] = trainOutput\\ntrain[:,:,198:]  = trainInput', 'pause': <function pause at 0x3194578>, 'randn': <built-in method randn of mtrand.RandomState object at 0x7f399f841690>, 'errstate': <class 'numpy.core.numeric.errstate'>, 'title': <function title at 0x3195938>, 'FPE_UNDERFLOW': 4, '_i108': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_8': 510, '_i113': u'type(predicted_probs)', 'frexp': <ufunc 'frexp'>, 'savefig': <function savefig at 0x3194e60>, 'PolarAxes': <class 'matplotlib.projections.polar.PolarAxes'>, 'DAILY': 3, 'center_matrix': <function center_matrix at 0x2c51500>, '_65': <matplotlib.text.Text object at 0x92e02d0>, 'smtplib': <module 'smtplib' from '/usr/lib/python2.7/smtplib.pyc'>, 'SHIFT_OVERFLOW': 3, 'over': <function over at 0x31952a8>, 'complex256': <type 'numpy.complex256'>, 'plotfile': <function plotfile at 0x31965f0>, '_i96': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock].reshape((deriv.shape[0],1))\\ny     = normTarget[:,stock]\\ntrain = X[:200,:]\\ntest  = X[200:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'get': <function getp at 0x2a9d1b8>, 'luke': array([[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.22,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       ..., \n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ]]), 'NZERO': -0.0, 'ceil': <ufunc 'ceil'>, 'ones': <function ones at 0x21c2410>, 'add_newdoc_ufunc': <built-in function add_newdoc_ufunc>, 'X': array([[  0.04    ,   1.5     ,   2.      , ...,   0.439681,   0.074476,\n          0.142166],\n       [ -0.11    ,   0.789473,  19.      , ...,   0.767666,   0.147196,\n          0.272029],\n       [ -0.08    ,   0.5     ,  12.      , ...,   0.216333,   0.062503,\n          0.062272],\n       ..., \n       [  0.27    ,   0.323529,  34.      , ...,   0.179467,   0.085557,\n          0.083333],\n       [  0.      ,   0.294117,  17.      , ...,   0.195387,   0.076333,\n          0.062539],\n       [  0.31    ,   1.6     ,   5.      , ...,   1.05697 ,   0.411582,\n          0.452769]]), 'count_nonzero': <built-in function count_nonzero>, 'target': array([[ 2.53,  1.03,  0.12, ...,  3.69,  3.56,  2.03],\n       [-4.95,  0.18, -0.24, ...,  1.22, -0.04,  0.38],\n       [ 0.16,  0.  ,  0.2 , ..., -0.04,  1.3 ,  1.61],\n       ..., \n       [-1.02,  1.53,  0.62, ...,  3.85,  4.87,  2.06],\n       [ 0.43,  0.12, -0.08, ..., -0.59, -0.67,  0.2 ],\n       [ 0.11,  0.  ,  0.29, ...,  0.48,  2.58,  0.47]]), '_108': <matplotlib.text.Text object at 0x918f1d0>, 'gray': <function gray at 0x31986e0>, 'qr': <function qr at 0x238c6e0>, 'bar': <function bar at 0x3196aa0>, '_102': 310, 'median': <function median at 0x236d668>, '_i99': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'geterr': <function geterr at 0x21dd140>, 'convolve': <function convolve at 0x21c2a28>, 'twiny': <function twiny at 0x31956e0>, 'logistic': <built-in method logistic of mtrand.RandomState object at 0x7f399f841690>, 'weibull': <built-in method weibull of mtrand.RandomState object at 0x7f399f841690>, 'x': array([ 0.004,  0.02 ,  0.004,  0.002,  0.002,  0.006,  0.002,  0.002,\n        0.008,  0.   ,  0.002,  0.   ,  0.   ,  0.   ,  0.002,  0.004,\n        0.   ,  0.006,  0.002,  0.012,  0.018,  0.006,  0.004,  0.002,\n        0.012,  0.026,  0.006,  0.02 ,  0.012,  0.   ,  0.002,  0.002,\n        0.   ,  0.004,  0.008,  0.002,  0.006,  0.   ,  0.   ,  0.012,\n        0.006,  0.01 ,  0.012,  0.004,  0.006,  0.012,  0.012,  0.   ,\n        0.01 ,  0.002,  0.006,  0.008,  0.014,  0.   ,  0.   ,  0.006,\n        0.008,  0.004,  0.018,  0.008,  0.01 ,  0.002,  0.   ,  0.006,\n        0.   ,  0.016,  0.018,  0.   ,  0.004,  0.004,  0.004,  0.008,\n        0.01 ,  0.012,  0.004,  0.002,  0.004,  0.01 ,  0.002,  0.006,\n        0.006,  0.004,  0.004,  0.004,  0.03 ,  0.008,  0.   ,  0.006,\n        0.004,  0.008,  0.   ,  0.014,  0.03 ,  0.01 ,  0.004,  0.004,\n        0.016,  0.004,  0.002,  0.004,  0.   ,  0.002,  0.004,  0.008,\n        0.002,  0.004,  0.   ,  0.006,  0.004,  0.004,  0.006,  0.002,\n        0.016,  0.004,  0.032,  0.012,  0.   ,  0.01 ,  0.   ,  0.002,\n        0.   ,  0.   ,  0.016,  0.002,  0.004,  0.008,  0.008,  0.   ,\n        0.002,  0.004,  0.01 ,  0.006,  0.002,  0.002,  0.006,  0.002,\n        0.006,  0.004,  0.008,  0.   ,  0.006,  0.002,  0.004,  0.   ,\n        0.002,  0.006,  0.006,  0.   ,  0.   ,  0.   ,  0.002,  0.016,\n        0.004,  0.028,  0.002,  0.004,  0.002,  0.   ,  0.002,  0.01 ,\n        0.002,  0.   ,  0.002,  0.002,  0.   ,  0.012,  0.002,  0.   ,\n        0.016,  0.004,  0.   ,  0.006]), 'isreal': <function isreal at 0x23017d0>, 'where': <built-in function where>, 'rcParamsDefault': RcParams({'agg.path.chunksize': 0,\n          'animation.avconv_args': '',\n          'animation.avconv_path': 'avconv',\n          'animation.bitrate': -1,\n          'animation.codec': 'mpeg4',\n          'animation.convert_args': '',\n          'animation.convert_path': 'convert',\n          'animation.ffmpeg_args': '',\n          'animation.ffmpeg_path': 'ffmpeg',\n          'animation.frame_format': 'png',\n          'animation.mencoder_args': '',\n          'animation.mencoder_path': 'mencoder',\n          'animation.writer': 'ffmpeg',\n          'axes.axisbelow': False,\n          'axes.color_cycle': ['b', 'g', 'r', 'c', 'm', 'y', 'k'],\n          'axes.edgecolor': 'k',\n          'axes.facecolor': 'w',\n          'axes.formatter.limits': [-7, 7],\n          'axes.formatter.use_locale': False,\n          'axes.formatter.use_mathtext': False,\n          'axes.grid': False,\n          'axes.hold': True,\n          'axes.labelcolor': 'k',\n          'axes.labelsize': 'medium',\n          'axes.labelweight': 'normal',\n          'axes.linewidth': 1.0,\n          'axes.titlesize': 'large',\n          'axes.unicode_minus': True,\n          'axes.xmargin': 0,\n          'axes.ymargin': 0,\n          'axes3d.grid': True,\n          'backend': 'Agg',\n          'backend.qt4': 'PyQt4',\n          'backend_fallback': True,\n          'contour.negative_linestyle': 'dashed',\n          'datapath': '/usr/local/lib/python2.7/dist-packages/matplotlib/mpl-data',\n          'docstring.hardcopy': False,\n          'examples.directory': '',\n          'figure.autolayout': False,\n          'figure.dpi': 80,\n          'figure.edgecolor': 'w',\n          'figure.facecolor': '0.75',\n          'figure.figsize': [8.0, 6.0],\n          'figure.frameon': True,\n          'figure.max_open_warning': 20,\n          'figure.subplot.bottom': 0.1,\n          'figure.subplot.hspace': 0.2,\n          'figure.subplot.left': 0.125,\n          'figure.subplot.right': 0.9,\n          'figure.subplot.top': 0.9,\n          'figure.subplot.wspace': 0.2,\n          'font.cursive': ['Apple Chancery',\n                           'Textile',\n                           'Zapf Chancery',\n                           'Sand',\n                           'cursive'],\n          'font.family': 'sans-serif',\n          'font.fantasy': ['Comic Sans MS',\n                           'Chicago',\n                           'Charcoal',\n                           'ImpactWestern',\n                           'fantasy'],\n          'font.monospace': ['Bitstream Vera Sans Mono',\n                             'DejaVu Sans Mono',\n                             'Andale Mono',\n                             'Nimbus Mono L',\n                             'Courier New',\n                             'Courier',\n                             'Fixed',\n                             'Terminal',\n                             'monospace'],\n          'font.sans-serif': ['Bitstream Vera Sans',\n                              'DejaVu Sans',\n                              'Lucida Grande',\n                              'Verdana',\n                              'Geneva',\n                              'Lucid',\n                              'Arial',\n                              'Helvetica',\n                              'Avant Garde',\n                              'sans-serif'],\n          'font.serif': ['Bitstream Vera Serif',\n                         'DejaVu Serif',\n                         'New Century Schoolbook',\n                         'Century Schoolbook L',\n                         'Utopia',\n                         'ITC Bookman',\n                         'Bookman',\n                         'Nimbus Roman No9 L',\n                         'Times New Roman',\n                         'Times',\n                         'Palatino',\n                         'Charter',\n                         'serif'],\n          'font.size': 12,\n          'font.stretch': 'normal',\n          'font.style': 'normal',\n          'font.variant': 'normal',\n          'font.weight': 'normal',\n          'grid.alpha': 1.0,\n          'grid.color': 'k',\n          'grid.linestyle': ':',\n          'grid.linewidth': 0.5,\n          'image.aspect': 'equal',\n          'image.cmap': 'jet',\n          'image.interpolation': 'bilinear',\n          'image.lut': 256,\n          'image.origin': 'upper',\n          'image.resample': False,\n          'interactive': False,\n          'keymap.all_axes': 'a',\n          'keymap.back': ['left', 'c', 'backspace'],\n          'keymap.forward': ['right', 'v'],\n          'keymap.fullscreen': ('f', 'ctrl+f'),\n          'keymap.grid': 'g',\n          'keymap.home': ['h', 'r', 'home'],\n          'keymap.pan': 'p',\n          'keymap.quit': ('ctrl+w', 'cmd+w'),\n          'keymap.save': ('s', 'ctrl+s'),\n          'keymap.xscale': ['k', 'L'],\n          'keymap.yscale': 'l',\n          'keymap.zoom': 'o',\n          'legend.borderaxespad': 0.5,\n          'legend.borderpad': 0.4,\n          'legend.columnspacing': 2.0,\n          'legend.fancybox': False,\n          'legend.fontsize': 'large',\n          'legend.frameon': True,\n          'legend.handleheight': 0.7,\n          'legend.handlelength': 2.0,\n          'legend.handletextpad': 0.8,\n          'legend.isaxes': True,\n          'legend.labelspacing': 0.5,\n          'legend.loc': 'upper right',\n          'legend.markerscale': 1.0,\n          'legend.numpoints': 2,\n          'legend.scatterpoints': 3,\n          'legend.shadow': False,\n          'lines.antialiased': True,\n          'lines.color': 'b',\n          'lines.dash_capstyle': 'butt',\n          'lines.dash_joinstyle': 'round',\n          'lines.linestyle': '-',\n          'lines.linewidth': 1.0,\n          'lines.marker': 'None',\n          'lines.markeredgewidth': 0.5,\n          'lines.markersize': 6,\n          'lines.solid_capstyle': 'projecting',\n          'lines.solid_joinstyle': 'round',\n          'mathtext.bf': 'serif:bold',\n          'mathtext.cal': 'cursive',\n          'mathtext.default': 'it',\n          'mathtext.fallback_to_cm': True,\n          'mathtext.fontset': 'cm',\n          'mathtext.it': 'serif:italic',\n          'mathtext.rm': 'serif',\n          'mathtext.sf': 'sans\\\\-serif',\n          'mathtext.tt': 'monospace',\n          'patch.antialiased': True,\n          'patch.edgecolor': 'k',\n          'patch.facecolor': 'b',\n          'patch.linewidth': 1.0,\n          'path.effects': [],\n          'path.simplify': True,\n          'path.simplify_threshold': 0.1111111111111111,\n          'path.sketch': None,\n          'path.snap': True,\n          'pdf.compression': 6,\n          'pdf.fonttype': 3,\n          'pdf.inheritcolor': False,\n          'pdf.use14corefonts': False,\n          'pgf.debug': False,\n          'pgf.preamble': [''],\n          'pgf.rcfonts': True,\n          'pgf.texsystem': 'xelatex',\n          'plugins.directory': '.matplotlib_plugins',\n          'polaraxes.grid': True,\n          'ps.distiller.res': 6000,\n          'ps.fonttype': 3,\n          'ps.papersize': 'letter',\n          'ps.useafm': False,\n          'ps.usedistiller': False,\n          'savefig.bbox': None,\n          'savefig.directory': '~',\n          'savefig.dpi': 100,\n          'savefig.edgecolor': 'w',\n          'savefig.extension': 'png',\n          'savefig.facecolor': 'w',\n          'savefig.format': 'png',\n          'savefig.frameon': True,\n          'savefig.jpeg_quality': 95,\n          'savefig.orientation': 'portrait',\n          'savefig.pad_inches': 0.1,\n          'svg.embed_char_paths': True,\n          'svg.fonttype': 'path',\n          'svg.image_inline': True,\n          'svg.image_noscale': False,\n          'text.antialiased': True,\n          'text.color': 'k',\n          'text.dvipnghack': None,\n          'text.hinting': True,\n          'text.hinting_factor': 8,\n          'text.latex.preamble': [''],\n          'text.latex.preview': False,\n          'text.latex.unicode': False,\n          'text.usetex': False,\n          'timezone': 'UTC',\n          'tk.pythoninspect': False,\n          'tk.window_focus': False,\n          'toolbar': 'toolbar2',\n          'verbose.fileo': 'sys.stdout',\n          'verbose.level': 'silent',\n          'webagg.open_in_browser': True,\n          'webagg.port': 8988,\n          'webagg.port_retries': 50,\n          'xtick.color': 'k',\n          'xtick.direction': 'in',\n          'xtick.labelsize': 'medium',\n          'xtick.major.pad': 4,\n          'xtick.major.size': 4,\n          'xtick.major.width': 0.5,\n          'xtick.minor.pad': 4,\n          'xtick.minor.size': 2,\n          'xtick.minor.width': 0.5,\n          'ytick.color': 'k',\n          'ytick.direction': 'in',\n          'ytick.labelsize': 'medium',\n          'ytick.major.pad': 4,\n          'ytick.major.size': 4,\n          'ytick.major.width': 0.5,\n          'ytick.minor.pad': 4,\n          'ytick.minor.size': 2,\n          'ytick.minor.width': 0.5}), 'fftsurr': <function fftsurr at 0x2c518c0>, 'SHIFT_UNDERFLOW': 6, 'argmax': <function argmax at 0x21d1b18>, 'minorticks_on': <function minorticks_on at 0x3195de8>, 'prctile': <function prctile at 0x2c51230>, 'deprecate_with_doc': <function <lambda> at 0x2369410>, 'imsave': <function imsave at 0x3196500>, 'polyder': <function polyder at 0x238ce60>, 'LogFormatterMathtext': <class 'matplotlib.ticker.LogFormatterMathtext'>, 'imread': <function imread at 0x3196488>, 'close': <function close at 0x3194b90>, 'DayLocator': <class 'matplotlib.dates.DayLocator'>, 'Formatter': <class 'matplotlib.ticker.Formatter'>, 'is_string_like': <function is_string_like at 0x29927d0>, 'contour': <function contour at 0x3196d70>, 'rad2deg': <ufunc 'rad2deg'>, 'isnan': <ufunc 'isnan'>, 'autoscale': <function autoscale at 0x3198488>, 'firstLine': ['fileId', 'O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8', 'O9', 'O10', 'O11', 'O12', 'O13', 'O14', 'O15', 'O16', 'O17', 'O18', 'O19', 'O20', 'O21', 'O22', 'O23', 'O24', 'O25', 'O26', 'O27', 'O28', 'O29', 'O30', 'O31', 'O32', 'O33', 'O34', 'O35', 'O36', 'O37', 'O38', 'O39', 'O40', 'O41', 'O42', 'O43', 'O44', 'O45', 'O46', 'O47', 'O48', 'O49', 'O50', 'O51', 'O52', 'O53', 'O54', 'O55', 'O56', 'O57', 'O58', 'O59', 'O60', 'O61', 'O62', 'O63', 'O64', 'O65', 'O66', 'O67', 'O68', 'O69', 'O70', 'O71', 'O72', 'O73', 'O74', 'O75', 'O76', 'O77', 'O78', 'O79', 'O80', 'O81', 'O82', 'O83', 'O84', 'O85', 'O86', 'O87', 'O88', 'O89', 'O90', 'O91', 'O92', 'O93', 'O94', 'O95', 'O96', 'O97', 'O98', 'O99', 'O100', 'O101', 'O102', 'O103', 'O104', 'O105', 'O106', 'O107', 'O108', 'O109', 'O110', 'O111', 'O112', 'O113', 'O114', 'O115', 'O116', 'O117', 'O118', 'O119', 'O120', 'O121', 'O122', 'O123', 'O124', 'O125', 'O126', 'O127', 'O128', 'O129', 'O130', 'O131', 'O132', 'O133', 'O134', 'O135', 'O136', 'O137', 'O138', 'O139', 'O140', 'O141', 'O142', 'O143', 'O144', 'O145', 'O146', 'O147', 'O148', 'O149', 'O150', 'O151', 'O152', 'O153', 'O154', 'O155', 'O156', 'O157', 'O158', 'O159', 'O160', 'O161', 'O162', 'O163', 'O164', 'O165', 'O166', 'O167', 'O168', 'O169', 'O170', 'O171', 'O172', 'O173', 'O174', 'O175', 'O176', 'O177', 'O178', 'O179', 'O180', 'O181', 'O182', 'O183', 'O184', 'O185', 'O186', 'O187', 'O188', 'O189', 'O190', 'O191', 'O192', 'O193', 'O194', 'O195', 'O196', 'O197', 'O198'], 'get_xyz_where': <function get_xyz_where at 0x2c51668>, 'irr': <function irr at 0x23fe050>, 'sctypeDict': {0: <type 'numpy.bool_'>, 1: <type 'numpy.int8'>, 2: <type 'numpy.uint8'>, 3: <type 'numpy.int16'>, 4: <type 'numpy.uint16'>, 5: <type 'numpy.int32'>, 6: <type 'numpy.uint32'>, 7: <type 'numpy.int64'>, 8: <type 'numpy.uint64'>, 9: <type 'numpy.int64'>, 10: <type 'numpy.uint64'>, 11: <type 'numpy.float32'>, 12: <type 'numpy.float64'>, 13: <type 'numpy.float128'>, 14: <type 'numpy.complex64'>, 15: <type 'numpy.complex128'>, 16: <type 'numpy.complex256'>, 17: <type 'numpy.object_'>, 18: <type 'numpy.string_'>, 19: <type 'numpy.unicode_'>, 20: <type 'numpy.void'>, 21: <type 'numpy.datetime64'>, 'unicode': <type 'numpy.unicode_'>, 23: <type 'numpy.float16'>, 'cfloat': <type 'numpy.complex128'>, 'longfloat': <type 'numpy.float128'>, 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, 'unicode_': <type 'numpy.unicode_'>, 'complex': <type 'numpy.complex128'>, 'timedelta64': <type 'numpy.timedelta64'>, 'uint16': <type 'numpy.uint16'>, 'c16': <type 'numpy.complex128'>, 'float32': <type 'numpy.float32'>, 'complex256': <type 'numpy.complex256'>, 'D': <type 'numpy.complex128'>, 'H': <type 'numpy.uint16'>, 'void': <type 'numpy.void'>, 'unicode0': <type 'numpy.unicode_'>, 'L': <type 'numpy.uint64'>, 'P': <type 'numpy.uint64'>, 'half': <type 'numpy.float16'>, 'void0': <type 'numpy.void'>, 'd': <type 'numpy.float64'>, 'h': <type 'numpy.int16'>, 'l': <type 'numpy.int64'>, 'p': <type 'numpy.int64'>, 'c32': <type 'numpy.complex256'>, 22: <type 'numpy.timedelta64'>, 'O8': <type 'numpy.object_'>, 'Timedelta64': <type 'numpy.timedelta64'>, 'object0': <type 'numpy.object_'>, 'b1': <type 'numpy.bool_'>, 'float128': <type 'numpy.float128'>, 'M8': <type 'numpy.datetime64'>, 'String0': <type 'numpy.string_'>, 'float16': <type 'numpy.float16'>, 'ulonglong': <type 'numpy.uint64'>, 'i1': <type 'numpy.int8'>, 'uint32': <type 'numpy.uint32'>, '?': <type 'numpy.bool_'>, 'Void0': <type 'numpy.void'>, 'complex64': <type 'numpy.complex64'>, 'G': <type 'numpy.complex256'>, 'O': <type 'numpy.object_'>, 'UInt8': <type 'numpy.uint8'>, 'S': <type 'numpy.string_'>, 'byte': <type 'numpy.int8'>, 'UInt64': <type 'numpy.uint64'>, 'g': <type 'numpy.float128'>, 'float64': <type 'numpy.float64'>, 'ushort': <type 'numpy.uint16'>, 'float_': <type 'numpy.float64'>, 'uint': <type 'numpy.uint64'>, 'object_': <type 'numpy.object_'>, 'Float16': <type 'numpy.float16'>, 'complex_': <type 'numpy.complex128'>, 'Unicode0': <type 'numpy.unicode_'>, 'uintp': <type 'numpy.uint64'>, 'intc': <type 'numpy.int32'>, 'csingle': <type 'numpy.complex64'>, 'datetime64': <type 'numpy.datetime64'>, 'float': <type 'numpy.float64'>, 'bool8': <type 'numpy.bool_'>, 'Bool': <type 'numpy.bool_'>, 'intp': <type 'numpy.int64'>, 'uintc': <type 'numpy.uint32'>, 'bytes_': <type 'numpy.string_'>, 'u8': <type 'numpy.uint64'>, 'u4': <type 'numpy.uint32'>, 'int_': <type 'numpy.int64'>, 'cdouble': <type 'numpy.complex128'>, 'u1': <type 'numpy.uint8'>, 'complex128': <type 'numpy.complex128'>, 'u2': <type 'numpy.uint16'>, 'f8': <type 'numpy.float64'>, 'Datetime64': <type 'numpy.datetime64'>, 'ubyte': <type 'numpy.uint8'>, 'm8': <type 'numpy.timedelta64'>, 'B': <type 'numpy.uint8'>, 'uint0': <type 'numpy.uint64'>, 'F': <type 'numpy.complex64'>, 'bool_': <type 'numpy.bool_'>, 'uint8': <type 'numpy.uint8'>, 'c8': <type 'numpy.complex64'>, 'Int64': <type 'numpy.int64'>, 'Int8': <type 'numpy.int8'>, 'Complex32': <type 'numpy.complex64'>, 'V': <type 'numpy.void'>, 'int8': <type 'numpy.int8'>, 'uint64': <type 'numpy.uint64'>, 'b': <type 'numpy.int8'>, 'f': <type 'numpy.float32'>, 'double': <type 'numpy.float64'>, 'UInt32': <type 'numpy.uint32'>, 'clongdouble': <type 'numpy.complex256'>, 'str': <type 'numpy.string_'>, 'f16': <type 'numpy.float128'>, 'f2': <type 'numpy.float16'>, 'f4': <type 'numpy.float32'>, 'int32': <type 'numpy.int32'>, 'int': <type 'numpy.int64'>, 'longdouble': <type 'numpy.float128'>, 'Complex128': <type 'numpy.complex256'>, 'single': <type 'numpy.float32'>, 'string': <type 'numpy.string_'>, 'q': <type 'numpy.int64'>, 'Int16': <type 'numpy.int16'>, 'Float64': <type 'numpy.float64'>, 'longcomplex': <type 'numpy.complex256'>, 'UInt16': <type 'numpy.uint16'>, 'bool': <type 'numpy.bool_'>, 'Float32': <type 'numpy.float32'>, 'string0': <type 'numpy.string_'>, 'longlong': <type 'numpy.int64'>, 'i8': <type 'numpy.int64'>, 'int16': <type 'numpy.int16'>, 'str_': <type 'numpy.string_'>, 'I': <type 'numpy.uint32'>, 'object': <type 'numpy.object_'>, 'M': <type 'numpy.datetime64'>, 'i4': <type 'numpy.int32'>, 'singlecomplex': <type 'numpy.complex64'>, 'Q': <type 'numpy.uint64'>, 'string_': <type 'numpy.string_'>, 'U': <type 'numpy.unicode_'>, 'a': <type 'numpy.string_'>, 'short': <type 'numpy.int16'>, 'e': <type 'numpy.float16'>, 'i': <type 'numpy.int32'>, 'clongfloat': <type 'numpy.complex256'>, 'm': <type 'numpy.timedelta64'>, 'Object0': <type 'numpy.object_'>, 'int64': <type 'numpy.int64'>, 'Float128': <type 'numpy.float128'>, 'i2': <type 'numpy.int16'>, 'int0': <type 'numpy.int64'>}, 'xticks': <function xticks at 0x3195cf8>, 'hist': <function hist at 0x3197230>, 'bivariate_normal': <function bivariate_normal at 0x2c515f0>, 'NINF': -inf, 'min_scalar_type': <built-in function min_scalar_type>, 'geometric': <built-in method geometric of mtrand.RandomState object at 0x7f399f841690>, 'normTarget': array([[-0.25,  0.26,  0.02, ...,  0.44,  0.51,  0.48],\n       [-0.33,  0.12, -0.02, ...,  0.7 ,  0.52,  0.05],\n       [ 0.14, -0.13,  0.02, ...,  0.43,  0.39,  0.64],\n       ..., \n       [ 1.4 ,  0.26,  0.09, ...,  1.32,  0.72,  0.22],\n       [-0.54,  0.3 , -0.04, ..., -0.37, -0.02, -0.14],\n       [ 0.95,  0.18,  0.17, ...,  0.12,  0.37,  0.05]]), 'sort_complex': <function sort_complex at 0x236c7d0>, 'nested_iters': <built-in function nested_iters>, 'concatenate': <built-in function concatenate>, 'ERR_DEFAULT2': 521, '_i48': u'yoda = normTarget.reshape((200*198,1))', '_i49': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1]+1,0))', 'vdot': <built-in function vdot>, 'bincount': <built-in function bincount>, 'num2epoch': <function num2epoch at 0x307faa0>, '_i46': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-2,0))', 'sctypes': {'int': [<type 'numpy.int8'>, <type 'numpy.int16'>, <type 'numpy.int32'>, <type 'numpy.int64'>], 'float': [<type 'numpy.float16'>, <type 'numpy.float32'>, <type 'numpy.float64'>, <type 'numpy.float128'>], 'uint': [<type 'numpy.uint8'>, <type 'numpy.uint16'>, <type 'numpy.uint32'>, <type 'numpy.uint64'>], 'complex': [<type 'numpy.complex64'>, <type 'numpy.complex128'>, <type 'numpy.complex256'>], 'others': [<type 'bool'>, <type 'object'>, <type 'str'>, <type 'unicode'>, <type 'numpy.void'>]}, 'transpose': <function transpose at 0x21d19b0>, 'add_newdocs': <module 'numpy.add_newdocs' from '/usr/local/lib/python2.7/dist-packages/numpy/add_newdocs.pyc'>, '_i42': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1))', '_i41': u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1)))', 'detrend_linear': <function detrend_linear at 0x2c4f848>, 'corrcoef': <function corrcoef at 0x236d0c8>, 'fromregex': <function fromregex at 0x23fb488>, 'vector_lengths': <function vector_lengths at 0x2c53b90>, 'vectorize': <class 'numpy.lib.function_base.vectorize'>, 'set_printoptions': <function set_printoptions at 0x21dac08>, '_i43': u'yoda.shape', '_i44': u'normTarget.shape', 'trim_zeros': <function trim_zeros at 0x236c848>, 'WEEKLY': 2, 'cos': <ufunc 'cos'>, '_37': (array([   3.,   11.,   42.,  112.,   26.,    4.,    0.,    0.,    0.,    2.]), array([-2.12 , -1.478, -0.836, -0.194,  0.448,  1.09 ,  1.732,  2.374,\n        3.016,  3.658,  4.3  ]), <a list of 10 Patch objects>), 'vlines': <function vlines at 0x3197de8>, 'detrend': <function detrend at 0x2c4f668>, 'arccosh': <ufunc 'arccosh'>, 'DateFormatter': <class 'matplotlib.dates.DateFormatter'>, 'equal': <ufunc 'equal'>, 'display': <function display at 0x1d4c848>, '_i39': u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1))', 'cumprod': <function cumprod at 0x21da758>, 'LinAlgError': <class 'numpy.linalg.linalg.LinAlgError'>, 'float_': <type 'numpy.float64'>, 'deprecate': <function deprecate at 0x23692a8>, 'vander': <function vander at 0x230d938>, '_i31': u'target.shape', 'geterrobj': <built-in function geterrobj>, '_i33': u'normTarget.shape', 'interactive': <function interactive at 0x2a006e0>, '_i35': u'plot(normTarget[:,0])', 'clf': <function clf at 0x3194cf8>, '_i37': u'hist(normTarget[:,197])', 'prepca': <function prepca at 0x2c511b8>, 'wald': <built-in method wald of mtrand.RandomState object at 0x7f399f841690>, 'fromiter': <built-in function fromiter>, 'prctile_rank': <function prctile_rank at 0x2c51488>, '_i29': u'lastObserved = trainOutput(:,-1,:)', 'cm': <module 'matplotlib.cm' from '/usr/local/lib/python2.7/dist-packages/matplotlib/cm.pyc'>, 'tril': <function tril at 0x230d848>, 'poly': <function poly at 0x2377b90>, 'loglog': <function loglog at 0x3197410>, '_i100': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'bitwise_or': <ufunc 'bitwise_or'>, '_i102': u'len(predicted_probs)', '_i103': u'len(predicted_probs[0])', 'figtext': <function figtext at 0x3195050>, 'norm_flat': <function norm_flat at 0x2c51f50>, '_i3': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', '_i107': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', 'tricontourf': <function tricontourf at 0x3197c80>, 'diff': <function diff at 0x236c5f0>, 'cohere': <function cohere at 0x3196c80>, 'normpdf': <function normpdf at 0x2c4fed8>, 'AutoLocator': <class 'matplotlib.ticker.AutoLocator'>, 'iterable': <function iterable at 0x236c1b8>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x2728f10>, 'get_include': <function get_include at 0x2369140>, 'pv': <function pv at 0x23fbe60>, 'tensordot': <function tensordot at 0x21c2b18>, 'piecewise': <function piecewise at 0x236c410>, 'rfftn': <function rfftn at 0x2409410>, 'invert': <ufunc 'invert'>, 'UFUNC_PYVALS_NAME': 'UFUNC_PYVALS', 'fftpack_lite': <module 'numpy.fft.fftpack_lite' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.so'>, 'sinc': <function sinc at 0x236d578>, 'numRows': 55, 'SHIFT_INVALID': 9, 'ubyte': <type 'numpy.uint8'>, 'axis': <function axis at 0x31959b0>, '_i47': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]+1,0))', 'matrix_rank': <function matrix_rank at 0x238caa0>, 'degrees': <ufunc 'degrees'>, 'pi': 3.141592653589793, 'numpy': <module 'numpy' from '/usr/local/lib/python2.7/dist-packages/numpy/__init__.pyc'>, '__doc__': 'Automatically created module for IPython interactive environment', 'empty': <built-in function empty>, 'fig': <matplotlib.figure.Figure object at 0xaa97ad0>, 'find_common_type': <function find_common_type at 0x21bfe60>, 'random_sample': <built-in method random_sample of mtrand.RandomState object at 0x7f399f841690>, 'longest_ones': <function longest_ones at 0x2c51140>, 'irfft2': <function irfft2 at 0x2409578>, 'arcsin': <ufunc 'arcsin'>, 'sctypeNA': {<type 'numpy.float16'>: 'Float16', <type 'numpy.int16'>: 'Int16', 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, <type 'numpy.timedelta64'>: 'Timedelta64', <type 'numpy.uint8'>: 'UInt8', 'c16': 'Complex64', <type 'numpy.datetime64'>: 'Datetime64', 'D': 'Complex64', <type 'numpy.int8'>: 'Int8', 'H': 'UInt16', 'L': 'UInt64', <type 'numpy.void'>: 'Void0', <type 'numpy.bool_'>: 'Bool', 'd': 'Float64', 'h': 'Int16', 'l': 'Int64', <type 'numpy.unicode_'>: 'Unicode0', 'c32': 'Complex128', <type 'numpy.string_'>: 'String0', 'Timedelta64': <type 'numpy.timedelta64'>, 'b1': 'Bool', 'M8': 'Datetime64', 'String0': <type 'numpy.string_'>, <type 'numpy.object_'>: 'Object0', 'I': 'UInt32', '?': 'Bool', 'Void0': <type 'numpy.void'>, <type 'numpy.complex256'>: 'Complex128', 'G': 'Complex128', 'O': 'Object0', 'UInt8': <type 'numpy.uint8'>, 'S': 'String0', <type 'numpy.complex128'>: 'Complex64', 'UInt64': <type 'numpy.uint64'>, 'g': 'Float128', <type 'numpy.complex64'>: 'Complex32', 'Float16': <type 'numpy.float16'>, <type 'numpy.float128'>: 'Float128', 'Bool': <type 'numpy.bool_'>, 'u8': <type 'numpy.uint64'>, <type 'numpy.float64'>: 'Float64', 'u4': <type 'numpy.uint32'>, 'Unicode0': <type 'numpy.unicode_'>, 'u1': <type 'numpy.uint8'>, 'u2': <type 'numpy.uint16'>, 'Datetime64': <type 'numpy.datetime64'>, 'Int8': <type 'numpy.int8'>, <type 'numpy.float32'>: 'Float32', 'B': 'UInt8', 'F': 'Complex32', 'c8': 'Complex32', 'Int64': <type 'numpy.int64'>, 'Complex32': <type 'numpy.complex64'>, 'V': 'Void0', <type 'numpy.uint64'>: 'UInt64', 'b': 'Int8', 'f': 'Float32', 'm8': 'Timedelta64', <type 'numpy.int64'>: 'Int64', 'f16': 'Float128', 'UInt32': <type 'numpy.uint32'>, 'f2': 'Float16', 'f4': 'Float32', 'f8': 'Float64', 'Complex128': <type 'numpy.complex256'>, <type 'numpy.uint64'>: 'UInt64', 'Object0': <type 'numpy.object_'>, 'Int16': <type 'numpy.int16'>, <type 'numpy.int64'>: 'Int64', 'Float64': <type 'numpy.float64'>, 'UInt16': <type 'numpy.uint16'>, 'Float32': <type 'numpy.float32'>, 'i8': <type 'numpy.int64'>, <type 'numpy.uint32'>: 'UInt32', 'i1': <type 'numpy.int8'>, 'i2': <type 'numpy.int16'>, 'M': 'Datetime64', 'i4': <type 'numpy.int32'>, 'Q': 'UInt64', 'U': 'Unicode0', <type 'numpy.int32'>: 'Int32', 'e': 'Float16', 'i': 'Int32', 'm': 'Timedelta64', 'q': 'Int64', <type 'numpy.uint16'>: 'UInt16', 'Float128': <type 'numpy.float128'>}, 'imag': <function imag at 0x23016e0>, 'sctype2char': <function sctype2char at 0x21bf1b8>, 'singlecomplex': <type 'numpy.complex64'>, 'SHIFT_DIVIDEBYZERO': 0, 'sort': <function sort at 0x21d1a28>, 'standard_t': <built-in method standard_t of mtrand.RandomState object at 0x7f399f841690>, '_i40': u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1)))', 'csv2rec': <function csv2rec at 0x2c527d0>, 'MachAr': <class 'numpy.core.machar.MachAr'>, 'apply_along_axis': <function apply_along_axis at 0x2374aa0>, 'new_figure_manager': <function new_figure_manager at 0x3186f50>, 'tight_layout': <function tight_layout at 0x3195848>, 'array_repr': <function array_repr at 0x21db398>, '_i105': u'pred = predicted_probs + lastObserved[200:,stock]', 'reciprocal': <ufunc 'reciprocal'>, 'frompyfunc': <built-in function frompyfunc>, 'rot90': <function rot90 at 0x230d5f0>, 'dstack': <function dstack at 0x2374c80>, 'float64': <type 'numpy.float64'>, 'traincv': array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True, False, False, False, False, False, False,\n       False, False], dtype=bool), 'Annotation': <class 'matplotlib.text.Annotation'>, 'colorbar': <function colorbar at 0x31962a8>, 'cast': {<type 'numpy.float16'>: <function <lambda> at 0x21bf230>, <type 'numpy.string_'>: <function <lambda> at 0x21bf2a8>, <type 'numpy.float128'>: <function <lambda> at 0x21bf320>, <type 'numpy.uint64'>: <function <lambda> at 0x21bf398>, <type 'numpy.int16'>: <function <lambda> at 0x21bf410>, <type 'numpy.timedelta64'>: <function <lambda> at 0x21bf488>, <type 'numpy.object_'>: <function <lambda> at 0x21bf500>, <type 'numpy.float64'>: <function <lambda> at 0x21bf578>, <type 'numpy.int64'>: <function <lambda> at 0x21bf5f0>, <type 'numpy.uint8'>: <function <lambda> at 0x21bf668>, <type 'numpy.datetime64'>: <function <lambda> at 0x21bf6e0>, <type 'numpy.complex256'>: <function <lambda> at 0x21bf758>, <type 'numpy.float32'>: <function <lambda> at 0x21bf7d0>, <type 'numpy.uint32'>: <function <lambda> at 0x21bf848>, <type 'numpy.int8'>: <function <lambda> at 0x21bf8c0>, <type 'numpy.void'>: <function <lambda> at 0x21bf938>, <type 'numpy.complex128'>: <function <lambda> at 0x21bf9b0>, <type 'numpy.uint64'>: <function <lambda> at 0x21bfa28>, <type 'numpy.int32'>: <function <lambda> at 0x21bfaa0>, <type 'numpy.bool_'>: <function <lambda> at 0x21bfb18>, <type 'numpy.unicode_'>: <function <lambda> at 0x21bfb90>, <type 'numpy.complex64'>: <function <lambda> at 0x21bfc08>, <type 'numpy.int64'>: <function <lambda> at 0x21bfc80>, <type 'numpy.uint16'>: <function <lambda> at 0x21bfcf8>}, '_i94': u'yoda = X.reshape((X.shape[0],1))', 'gumbel': <built-in method gumbel of mtrand.RandomState object at 0x7f399f841690>, 'rfft2': <function rfft2 at 0x2409488>, 'eig': <function eig at 0x238c8c0>, 'packbits': <built-in function packbits>, 'issctype': <function issctype at 0x21b8de8>, 'mgrid': <numpy.lib.index_tricks.nd_grid object at 0x236f910>, 'vonmises': <built-in method vonmises of mtrand.RandomState object at 0x7f399f841690>, 'ushort': <type 'numpy.uint16'>, 'normTarget_vector': array([[-0.25],\n       [ 0.26],\n       [ 0.02],\n       ..., \n       [ 0.12],\n       [ 0.37],\n       [ 0.05]]), 'Polygon': <class 'matplotlib.patches.Polygon'>, 'helper': <module 'numpy.fft.helper' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/helper.pyc'>, 'empty_like': <built-in function empty_like>, '_75': (200,), '_74': array([False, False, False, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), '_77': array([[[ 0.      ,  0.      ,  0.      , ...,  0.160672,  0.054283,\n          0.060093],\n        [ 1.61    ,  0.12    ,  0.12    , ...,  0.246306,  0.448241,\n          0.377197],\n        [ 1.12    ,  0.31    ,  0.12    , ...,  0.281271,  0.484713,\n          0.431599],\n        ..., \n        [ 0.9     ,  0.19    ,  0.07    , ...,  0.119027,  0.084617,\n          0.074685],\n        [ 0.87    ,  0.22    ,  0.08    , ...,  0.122028,  0.058538,\n          0.080691],\n        [ 0.83    ,  0.25    ,  0.08    , ...,  0.125018,  0.043205,\n          0.088569]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.405808,  0.188892,\n          0.209284],\n        [ 0.95    , -0.18    ,  0.15    , ...,  0.42738 ,  0.348119,\n          0.34322 ],\n        [ 1.04    , -0.18    ,  0.15    , ...,  0.463135,  0.439758,\n          0.449271],\n        ..., \n        [ 0.87    , -0.01    ,  0.1     , ...,  0.447247,  0.132313,\n          0.208433],\n        [ 0.83    ,  0.      ,  0.05    , ...,  0.445714,  0.153232,\n          0.138243],\n        [ 0.97    , -0.05    ,  0.05    , ...,  0.445714,  0.155649,\n          0.138243]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.934708,  0.084538,\n          0.154596],\n        [ 2.75    ,  0.25    ,  0.      , ...,  0.859673,  0.675959,\n          0.553122],\n        [ 2.22    ,  0.24    ,  0.      , ...,  0.800801,  0.754047,\n          0.652951],\n        ..., \n        [ 6.09    , -0.13    ,  0.      , ...,  0.717239,  0.111535,\n          0.55109 ],\n        [ 6.22    , -0.13    ,  0.      , ...,  0.712795,  0.116218,\n          0.388987],\n        [ 5.75    , -0.17    ,  0.      , ...,  0.715292,  0.152665,\n          0.252609]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.199729,  0.051769,\n          0.117898],\n        [-3.29    ,  0.04    ,  0.24    , ...,  0.349317,  0.77501 ,\n          0.659621],\n        [-3.53    ,  0.06    ,  0.37    , ...,  0.460716,  1.013778,\n          0.894228],\n        ..., \n        [-2.21    ,  1.33    ,  0.5     , ...,  0.221407,  0.051251,\n          0.160312],\n        [-2.25    ,  1.27    ,  0.54    , ...,  0.203557,  0.054283,\n          0.14087 ],\n        [-2.42    ,  1.27    ,  0.53    , ...,  0.185629,  0.059889,\n          0.054874]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.52827 ,  0.128219,\n          0.104881],\n        [ 0.17    , -0.06    ,  0.      , ...,  0.520413,  0.180665,\n          0.150702],\n        [ 0.59    , -0.12    , -0.06    , ...,  0.520859,  0.288167,\n          0.243676],\n        ..., \n        [ 0.97    , -0.24    , -0.08    , ...,  0.296868,  0.023381,\n          0.264344],\n        [ 0.82    , -0.24    , -0.08    , ...,  0.297405,  0.037417,\n          0.211529],\n        [ 0.97    , -0.18    , -0.04    , ...,  0.298542,  0.037238,\n          0.132077]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.31634 ,  0.082624,\n          0.108628],\n        [-0.71    ,  0.26    ,  0.74    , ...,  0.307045,  0.20775 ,\n          0.205129],\n        [-1.06    ,  0.19    ,  0.74    , ...,  0.31471 ,  0.277897,\n          0.274672],\n        ..., \n        [-1.04    , -0.08    ,  0.12    , ...,  0.184709,  0.06532 ,  0.16    ],\n        [-0.95    , -0.19    ,  0.12    , ...,  0.178122,  0.028284,\n          0.152315],\n        [-0.84    , -0.18    ,  0.12    , ...,  0.173413,  0.054283,\n          0.123063]]]), 'einsum': <built-in function einsum>, '_71': sklearn.cross_validation.KFold(n=200, n_folds=63), '_70': 200, 'signbit': <ufunc 'signbit'>, 'cond': <function cond at 0x238ca28>, 'chisquare': <built-in method chisquare of mtrand.RandomState object at 0x7f399f841690>, 'conj': <ufunc 'conjugate'>, 'asmatrix': <function asmatrix at 0x236dc80>, 'floating': <type 'numpy.floating'>, 'flatiter': <type 'numpy.flatiter'>, 'bitwise_xor': <ufunc 'bitwise_xor'>, 'WeekdayLocator': <class 'matplotlib.dates.WeekdayLocator'>, '_34': (200, 198), 'fabs': <ufunc 'fabs'>, 'Locator': <class 'matplotlib.ticker.Locator'>, 'generic': <type 'numpy.generic'>, 'reshape': <function reshape at 0x21d1758>, 'to': 'lanemcintosh@gmail.com', 'NaN': nan, 'cross': <function cross at 0x21c2cf8>, 'sqrt': <ufunc 'sqrt'>, 'show_config': <function show at 0x20f9b18>, 'longcomplex': <type 'numpy.complex256'>, 'poly_between': <function poly_between at 0x2c53938>, 'pad': <function pad at 0x23fec08>, 'split': <function split at 0x2374de8>, 'getp': <function getp at 0x2a9d1b8>, 'floor_divide': <ufunc 'floor_divide'>, '__version__': '1.7.1', 'format_parser': <class numpy.core.records.format_parser at 0x226ebb0>, 'nextafter': <ufunc 'nextafter'>, 'exponential': <built-in method exponential of mtrand.RandomState object at 0x7f399f841690>, 'dedent': <function dedent at 0x2994938>, 'polyval': <function polyval at 0x238cf50>, 'infty': inf, 'flipud': <function flipud at 0x230d578>, 'i0': <function i0 at 0x236d488>, 'permutation': <built-in method permutation of mtrand.RandomState object at 0x7f399f841690>, 'disconnect': <function disconnect at 0x3194c80>, 'iscomplexobj': <function iscomplexobj at 0x2301848>, 'sys': <module 'sys' (built-in)>, 'average': <function average at 0x236c320>, '_exit_code': 0, 'setdiff1d': <function setdiff1d at 0x236c140>, 'psd': <function psd at 0x31976e0>, 'mafromtxt': <function mafromtxt at 0x23fb5f0>, 'bartlett': <function bartlett at 0x236d1b8>, 'polydiv': <function polydiv at 0x238d1b8>, 'numStocks': 198, 'drange': <function drange at 0x307d140>, 'safe_eval': <function safe_eval at 0x2369938>, 'ifft': <function ifft at 0x23fee60>, 'cov': <function cov at 0x236cde8>, 'greater_equal': <ufunc 'greater_equal'>, 'i': 243, 'Tester': <class 'numpy.testing.nosetester.NoseTester'>, 'trapz': <function trapz at 0x236d7d0>, 'PINF': inf, 'rec_drop_fields': <function rec_drop_fields at 0x2c52500>, 'recfromtxt': <function recfromtxt at 0x23fb668>, 'setp': <function setp at 0x31948c0>, 'In': ['', u\"get_ipython().magic(u'cd /home/lane/Kaggle/03\\\\\\\\ Predicting\\\\\\\\ Stock\\\\\\\\ Prices/')\", u\"get_ipython().system(u'ls -F --color ')\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(train), n_folds=63, indices=False)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(trainOutput), n_folds=63, indices=False)', u'len(trainOutput)', u'len(targets)', u'len(target)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'trainInput.shape', u'trainOutput.shape', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:197] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:198] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'trainInput[509,54,243]', u'trainInput[509,54,244]', u'trainInput[509,54,243]', u'fullInput[509,54,244+197]', u'train            = np.zeros((510,55,244+198))\\ntrain[:,:,0:198] = trainOutput\\ntrain[:,:,198:]  = trainInput', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(target[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'trainOutput.shape', u'len(trainOutput[0])', u'target.shape', u'target.shape', u'trainInput.shape', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput(:,-1,:)', u'lastObserved = trainOutput[:,-1,:]\\nlastObserved.shape', u'target.shape', u'normTarget   = target - lastObserved[:target.shape[0],:]', u'normTarget.shape', u'target.shape', u'plot(normTarget[:,0])', u'plot(normTarget[:,197])', u'hist(normTarget[:,197])', u'hist(normTarget)', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1)))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1)))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1))', u'yoda.shape', u'normTarget.shape', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-2,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((200*198,1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True)', u\"yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,4)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,6)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nyaxis('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',norm=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',normed=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\nderiv.shape', u'normTarget.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'len(target)', u'cv', u'for i in cv:\\n    print i', u'for i,j in cv:\\n    print i,j', u'traincv', u'traincv.shape', u'testcv.shape', u'train[traincv]', u'train.shape', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201,:]\\ntest  = X[201:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201]\\ntest  = X[201:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'train.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:200]\\ntest  = X[200:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'y.shape', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'train.shape', u'test.shape', u'yoda = X.reshape((X.shape[0],1))', u'yoda.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock].reshape((deriv.shape[0],1))\\ny     = normTarget[:,stock]\\ntrain = X[:200,:]\\ntest  = X[200:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'predicted_probs.shape', u'len(predicted_probs)', u'len(predicted_probs[0])', u'lastObserved[:,stock].shape', u'pred = predicted_probs + lastObserved[200:,stock]', u'pred = predicted_probs + lastObserved[200:,stock]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape[2]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'numStocks', u'type(predicted_probs)', u'yoda = np.asarray(predicted_probs)\\nyoda.shape', u'yoda = np.asarray(predicted_probs)\\nluke = np.zeros((310,198))\\nluke[:,0] = yoda', u'pred[0]', u'## Fit Random Forest and generate predictions\\nnumStocks   = trainOutput.shape[2]\\nperformance = []\\npred        = np.zeros((310,numStocks))\\nfor stock in xrange(numStocks):\\n    \\n    # get stock-specific features\\n    X     = deriv[:,stock].reshape((deriv.shape[0],1))\\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n\\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n\\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import smtplib', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import pybrain', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random\\nimport smtplib\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=500, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=25, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'sheet.shape', u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection'], 'y': array([-0.25, -0.33,  0.14,  0.64, -0.07, -0.22, -0.67, -0.86,  0.3 ,\n        0.29,  0.04,  0.97,  0.36,  0.51, -0.49, -0.09,  0.53, -1.21,\n        2.27,  2.77, -0.52,  0.  ,  0.88,  0.29,  0.46,  0.9 ,  0.05,\n        0.33, -2.03,  0.43,  0.68,  0.56, -0.69, -1.95,  0.05, -0.7 ,\n       -0.47, -0.29,  0.68,  0.19,  0.87, -0.02,  0.38,  0.21, -0.36,\n        0.  , -0.55,  0.89, -0.14, -0.24, -2.89, -0.2 , -1.47, -1.58,\n       -0.86, -0.56, -0.13, -0.27, -0.07,  0.16, -1.16, -0.25,  0.65,\n        0.34,  0.34,  3.43,  0.41,  0.05,  0.1 ,  0.48,  0.1 , -0.63,\n       -2.05,  0.85,  0.57,  0.23,  0.2 ,  0.13,  0.88, -1.5 , -0.65,\n        0.09,  0.95, -0.72, -2.65, -0.09,  0.04,  0.36,  2.23, -0.33,\n       -0.02, -0.05,  1.37,  0.86,  0.04,  2.78, -0.76, -4.44, -0.15,\n        0.28, -0.99,  0.66,  0.19, -1.3 , -1.45, -0.52, -0.95,  0.27,\n       -3.92,  0.46, -0.5 , -0.17,  1.65,  3.24,  1.18,  0.55,  0.23,\n       -0.03, -0.43, -0.51,  0.08,  0.04, -1.49,  1.15, -0.77,  0.  ,\n       -0.26,  1.78,  0.99, -0.95, -0.76, -0.41, -0.14,  1.34,  0.15,\n       -1.35, -0.18, -0.21,  0.23, -1.52,  1.17, -0.25,  0.33,  0.02,\n        0.29,  0.74, -0.16, -0.06, -2.7 , -0.11,  1.05, -0.31, -0.95,\n       -0.9 ,  2.19,  0.09, -0.76, -0.57, -0.85,  2.14,  1.62,  0.05,\n       -0.4 ,  0.23,  2.3 ,  2.  ,  0.58, -0.37, -0.43,  0.01, -0.62,\n       -0.58, -0.52,  1.23,  0.57,  0.49, -0.02,  0.63, -0.1 ,  0.15,\n        0.96, -0.38,  0.73, -0.93,  0.1 ,  1.15,  0.39,  0.18, -3.55,\n       -0.53,  0.27,  0.05, -0.15, -1.86,  0.25,  0.08,  0.47,  1.4 ,\n       -0.54,  0.95]), 'grid': <function grid at 0x3198050>, 'trainOutput': array([[[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [ 0.97,  0.45,  0.16, ...,  1.37,  1.3 ,  0.29],\n        [ 1.69,  0.51,  0.  , ...,  1.62,  1.81,  0.48],\n        ..., \n        [ 2.79,  0.77,  0.08, ...,  3.17,  3.08,  1.61],\n        [ 2.74,  0.73,  0.12, ...,  3.25,  3.03,  1.59],\n        [ 2.78,  0.77,  0.1 , ...,  3.25,  3.05,  1.55]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-2.14,  0.  , -0.2 , ..., -0.5 ,  0.38,  0.43],\n        [-2.23, -0.07, -0.28, ..., -0.27, -0.02,  0.21],\n        ..., \n        [-4.72,  0.09, -0.2 , ...,  0.61, -0.54,  0.5 ],\n        [-4.51,  0.1 , -0.24, ...,  0.63, -0.52,  0.41],\n        [-4.62,  0.06, -0.22, ...,  0.52, -0.56,  0.33]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [ 0.52,  0.13,  0.12, ...,  0.43,  0.45,  0.16],\n        [ 0.48,  0.13,  0.1 , ...,  0.27,  0.58,  0.25],\n        ..., \n        [ 0.04,  0.12,  0.2 , ..., -0.4 ,  0.96,  1.03],\n        [ 0.1 ,  0.11,  0.2 , ..., -0.45,  0.93,  1.03],\n        [ 0.02,  0.13,  0.18, ..., -0.47,  0.91,  0.97]],\n\n       ..., \n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-0.28, -0.18,  0.08, ..., -0.98, -0.21,  0.07],\n        [-0.13, -0.23,  0.08, ..., -1.66, -0.54,  0.24],\n        ..., \n        [-0.66,  0.12,  0.12, ..., -2.06, -1.19,  0.3 ],\n        [-0.6 ,  0.21,  0.12, ..., -2.06, -1.16,  0.3 ],\n        [-0.33,  0.23,  0.12, ..., -1.81, -1.01,  0.26]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-1.07, -0.07,  0.  , ..., -0.7 , -0.2 , -0.2 ],\n        [-0.99, -0.01,  0.04, ..., -0.6 ,  0.25,  0.1 ],\n        ..., \n        [-0.99,  0.11,  0.  , ..., -0.08,  0.88,  1.29],\n        [-1.13,  0.07,  0.  , ..., -0.18,  0.9 ,  1.17],\n        [-1.13,  0.06,  0.  , ..., -0.23,  0.92,  1.17]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-6.56, -0.36,  0.04, ..., -1.78, -1.83, -1.03],\n        [-5.8 , -0.36,  0.04, ..., -1.23, -1.33, -0.73],\n        ..., \n        [-8.24, -0.79,  0.04, ..., -2.59, -2.34, -1.49],\n        [-8.3 , -0.78,  0.04, ..., -2.61, -2.36, -1.47],\n        [-7.99, -0.78,  0.01, ..., -2.57, -2.34, -1.41]]]), 'standard_normal': <built-in method standard_normal of mtrand.RandomState object at 0x7f399f841690>, 'RankWarning': <class 'numpy.lib.polynomial.RankWarning'>, 'ascontiguousarray': <function ascontiguousarray at 0x21c2668>, '_89': (200,), 'load': <function load at 0x23f9aa0>, '_i4': u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", 'hexbin': <function hexbin at 0x31971b8>, 'Arrow': <class 'matplotlib.patches.Arrow'>, 'less': <ufunc 'less'>, 'putmask': <built-in function putmask>, 'UFUNC_BUFSIZE_DEFAULT': 8192, 'get_state': <built-in method get_state of mtrand.RandomState object at 0x7f399f841690>, 'NAN': nan, 'test_transformed': array([[ -2.90000000e-01,   3.95000000e+01,   5.65000000e+01, ...,\n          8.48180000e-02,   1.46046000e-01,   2.20786000e-01],\n       [  3.80000000e-01,   2.80000000e+01,   3.50000000e+01, ...,\n          6.08164000e-01,   7.14327000e-01,   4.69965000e-01],\n       [  2.00000000e-02,   1.30250000e+02,   4.83750000e+01, ...,\n          9.14371000e-01,   8.75696000e-01,   1.20665000e-01],\n       ..., \n       [  2.70000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          1.78577000e-01,   7.33330000e-02,   8.55570000e-02],\n       [  0.00000000e+00,   4.14500000e+02,   2.80000000e+01, ...,\n          6.20088000e-01,   6.15484000e-01,   7.63330000e-02],\n       [  3.10000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          6.87380000e-02,  -4.30400000e-03,   4.11582000e-01]]), 'typeDict': {0: <type 'numpy.bool_'>, 1: <type 'numpy.int8'>, 2: <type 'numpy.uint8'>, 3: <type 'numpy.int16'>, 4: <type 'numpy.uint16'>, 5: <type 'numpy.int32'>, 6: <type 'numpy.uint32'>, 7: <type 'numpy.int64'>, 8: <type 'numpy.uint64'>, 9: <type 'numpy.int64'>, 10: <type 'numpy.uint64'>, 11: <type 'numpy.float32'>, 12: <type 'numpy.float64'>, 13: <type 'numpy.float128'>, 14: <type 'numpy.complex64'>, 15: <type 'numpy.complex128'>, 16: <type 'numpy.complex256'>, 17: <type 'numpy.object_'>, 18: <type 'numpy.string_'>, 19: <type 'numpy.unicode_'>, 20: <type 'numpy.void'>, 21: <type 'numpy.datetime64'>, 'unicode': <type 'numpy.unicode_'>, 23: <type 'numpy.float16'>, 'cfloat': <type 'numpy.complex128'>, 'longfloat': <type 'numpy.float128'>, 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, 'unicode_': <type 'numpy.unicode_'>, 'complex': <type 'numpy.complex128'>, 'timedelta64': <type 'numpy.timedelta64'>, 'uint16': <type 'numpy.uint16'>, 'c16': <type 'numpy.complex128'>, 'float32': <type 'numpy.float32'>, 'complex256': <type 'numpy.complex256'>, 'D': <type 'numpy.complex128'>, 'H': <type 'numpy.uint16'>, 'void': <type 'numpy.void'>, 'unicode0': <type 'numpy.unicode_'>, 'L': <type 'numpy.uint64'>, 'P': <type 'numpy.uint64'>, 'half': <type 'numpy.float16'>, 'void0': <type 'numpy.void'>, 'd': <type 'numpy.float64'>, 'h': <type 'numpy.int16'>, 'l': <type 'numpy.int64'>, 'p': <type 'numpy.int64'>, 'c32': <type 'numpy.complex256'>, 22: <type 'numpy.timedelta64'>, 'O8': <type 'numpy.object_'>, 'Timedelta64': <type 'numpy.timedelta64'>, 'object0': <type 'numpy.object_'>, 'b1': <type 'numpy.bool_'>, 'float128': <type 'numpy.float128'>, 'M8': <type 'numpy.datetime64'>, 'String0': <type 'numpy.string_'>, 'float16': <type 'numpy.float16'>, 'ulonglong': <type 'numpy.uint64'>, 'i1': <type 'numpy.int8'>, 'uint32': <type 'numpy.uint32'>, '?': <type 'numpy.bool_'>, 'Void0': <type 'numpy.void'>, 'complex64': <type 'numpy.complex64'>, 'G': <type 'numpy.complex256'>, 'O': <type 'numpy.object_'>, 'UInt8': <type 'numpy.uint8'>, 'S': <type 'numpy.string_'>, 'byte': <type 'numpy.int8'>, 'UInt64': <type 'numpy.uint64'>, 'g': <type 'numpy.float128'>, 'float64': <type 'numpy.float64'>, 'ushort': <type 'numpy.uint16'>, 'float_': <type 'numpy.float64'>, 'uint': <type 'numpy.uint64'>, 'object_': <type 'numpy.object_'>, 'Float16': <type 'numpy.float16'>, 'complex_': <type 'numpy.complex128'>, 'Unicode0': <type 'numpy.unicode_'>, 'uintp': <type 'numpy.uint64'>, 'intc': <type 'numpy.int32'>, 'csingle': <type 'numpy.complex64'>, 'datetime64': <type 'numpy.datetime64'>, 'float': <type 'numpy.float64'>, 'bool8': <type 'numpy.bool_'>, 'Bool': <type 'numpy.bool_'>, 'intp': <type 'numpy.int64'>, 'uintc': <type 'numpy.uint32'>, 'bytes_': <type 'numpy.string_'>, 'u8': <type 'numpy.uint64'>, 'u4': <type 'numpy.uint32'>, 'int_': <type 'numpy.int64'>, 'cdouble': <type 'numpy.complex128'>, 'u1': <type 'numpy.uint8'>, 'complex128': <type 'numpy.complex128'>, 'u2': <type 'numpy.uint16'>, 'f8': <type 'numpy.float64'>, 'Datetime64': <type 'numpy.datetime64'>, 'ubyte': <type 'numpy.uint8'>, 'm8': <type 'numpy.timedelta64'>, 'B': <type 'numpy.uint8'>, 'uint0': <type 'numpy.uint64'>, 'F': <type 'numpy.complex64'>, 'bool_': <type 'numpy.bool_'>, 'uint8': <type 'numpy.uint8'>, 'c8': <type 'numpy.complex64'>, 'Int64': <type 'numpy.int64'>, 'Int8': <type 'numpy.int8'>, 'Complex32': <type 'numpy.complex64'>, 'V': <type 'numpy.void'>, 'int8': <type 'numpy.int8'>, 'uint64': <type 'numpy.uint64'>, 'b': <type 'numpy.int8'>, 'f': <type 'numpy.float32'>, 'double': <type 'numpy.float64'>, 'UInt32': <type 'numpy.uint32'>, 'clongdouble': <type 'numpy.complex256'>, 'str': <type 'numpy.string_'>, 'f16': <type 'numpy.float128'>, 'f2': <type 'numpy.float16'>, 'f4': <type 'numpy.float32'>, 'int32': <type 'numpy.int32'>, 'int': <type 'numpy.int64'>, 'longdouble': <type 'numpy.float128'>, 'Complex128': <type 'numpy.complex256'>, 'single': <type 'numpy.float32'>, 'string': <type 'numpy.string_'>, 'q': <type 'numpy.int64'>, 'Int16': <type 'numpy.int16'>, 'Float64': <type 'numpy.float64'>, 'longcomplex': <type 'numpy.complex256'>, 'UInt16': <type 'numpy.uint16'>, 'bool': <type 'numpy.bool_'>, 'Float32': <type 'numpy.float32'>, 'string0': <type 'numpy.string_'>, 'longlong': <type 'numpy.int64'>, 'i8': <type 'numpy.int64'>, 'int16': <type 'numpy.int16'>, 'str_': <type 'numpy.string_'>, 'I': <type 'numpy.uint32'>, 'object': <type 'numpy.object_'>, 'M': <type 'numpy.datetime64'>, 'i4': <type 'numpy.int32'>, 'singlecomplex': <type 'numpy.complex64'>, 'Q': <type 'numpy.uint64'>, 'string_': <type 'numpy.string_'>, 'U': <type 'numpy.unicode_'>, 'a': <type 'numpy.string_'>, 'short': <type 'numpy.int16'>, 'e': <type 'numpy.float16'>, 'i': <type 'numpy.int32'>, 'clongfloat': <type 'numpy.complex256'>, 'm': <type 'numpy.timedelta64'>, 'Object0': <type 'numpy.object_'>, 'int64': <type 'numpy.int64'>, 'Float128': <type 'numpy.float128'>, 'i2': <type 'numpy.int16'>, 'int0': <type 'numpy.int64'>}, 'shape': <function shape at 0x21d1f50>, '_i98': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', 'setbufsize': <function setbufsize at 0x21dd1b8>, '_85': (201,), '_i93': u'test.shape', '_i92': u'train.shape', '_i91': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', '_i90': u'train.shape', '_i97': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'cfloat': <type 'numpy.complex128'>, '_i95': u'yoda.shape', 'RAISE': 2, 'detrend_mean': <function detrend_mean at 0x2c4f758>, '_87': (200,), 'isscalar': <function isscalar at 0x21dbb90>, 'SubplotTool': <class 'matplotlib.widgets.SubplotTool'>, 'get_current_fig_manager': <function get_current_fig_manager at 0x3194b18>, 'character': <type 'numpy.character'>, 'bench': <bound method NoseTester.test of <numpy.testing.nosetester.NoseTester object at 0x2383a90>>, 'fullInput': array([[[ 0.      ,  0.      ,  0.      , ...,  0.299584,  0.038816,\n          0.081309],\n        [ 0.97    ,  0.45    ,  0.16    , ...,  0.314446,  0.251952,\n          0.206263],\n        [ 1.69    ,  0.51    ,  0.      , ...,  0.357783,  0.510176,\n          0.429069],\n        ..., \n        [ 2.79    ,  0.77    ,  0.08    , ...,  0.269088,  0.126912,\n          0.103441],\n        [ 2.74    ,  0.73    ,  0.12    , ...,  0.262727,  0.133116,\n          0.111704],\n        [ 2.78    ,  0.77    ,  0.1     , ...,  0.259782,  0.121326,\n          0.124544]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.320344,  0.071274,\n          0.057831],\n        [-2.14    ,  0.      , -0.2     , ...,  0.410495,  0.634182,\n          0.521483],\n        [-2.23    , -0.07    , -0.28    , ...,  0.478352,  0.79485 ,\n          0.690853],\n        ..., \n        [-4.72    ,  0.09    , -0.2     , ...,  0.231589,  0.067725,\n          0.090799],\n        [-4.51    ,  0.1     , -0.24    , ...,  0.231602,  0.072388,\n          0.100995],\n        [-4.62    ,  0.06    , -0.22    , ...,  0.225328,  0.048442,\n          0.083666]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.19655 ,  0.150555,\n          0.12083 ],\n        [ 0.52    ,  0.13    ,  0.12    , ...,  0.194066,  0.153753,\n          0.128841],\n        [ 0.48    ,  0.13    ,  0.1     , ...,  0.187594,  0.153753,\n          0.132288],\n        ..., \n        [ 0.04    ,  0.12    ,  0.2     , ...,  0.183963,  0.073756,\n          0.08124 ],\n        [ 0.1     ,  0.11    ,  0.2     , ...,  0.177811,  0.060332,\n          0.066165],\n        [ 0.02    ,  0.13    ,  0.18    , ...,  0.174681,  0.06121 ,  0.06    ]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.150991,  0.073394,\n          0.067082],\n        [-0.28    , -0.18    ,  0.08    , ...,  0.150545,  0.066933,\n          0.067082],\n        [-0.13    , -0.23    ,  0.08    , ...,  0.15091 ,  0.068896,\n          0.069121],\n        ..., \n        [-0.66    ,  0.12    ,  0.12    , ...,  0.197203,  0.073121,\n          0.083666],\n        [-0.6     ,  0.21    ,  0.12    , ...,  0.198655,  0.074833,\n          0.069282],\n        [-0.33    ,  0.23    ,  0.12    , ...,  0.198691,  0.099599,  0.08    ]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.150959,  0.089443,\n          0.095102],\n        [-1.07    , -0.07    ,  0.      , ...,  0.191609,  0.267133,\n          0.241753],\n        [-0.99    , -0.01    ,  0.04    , ...,  0.223181,  0.315383,\n          0.298794],\n        ..., \n        [-0.99    ,  0.11    ,  0.      , ...,  0.188956,  0.062823,\n          0.055678],\n        [-1.13    ,  0.07    ,  0.      , ...,  0.191981,  0.066232,\n          0.058119],\n        [-1.13    ,  0.06    ,  0.      , ...,  0.191485,  0.062823,  0.06    ]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  1.10484 ,  0.054283,\n          0.094868],\n        [-6.56    , -0.36    ,  0.04    , ...,  1.356407,  1.782152,\n          1.461476],\n        [-5.8     , -0.36    ,  0.04    , ...,  1.523808,  2.131682,\n          1.812402],\n        ..., \n        [-8.24    , -0.79    ,  0.04    , ...,  0.575108,  0.300311,\n          0.310644],\n        [-8.3     , -0.78    ,  0.04    , ...,  0.569777,  0.276743,\n          0.284429],\n        [-7.99    , -0.78    ,  0.01    , ...,  0.557479,  0.214942,\n          0.323883]]]), 'source': <function source at 0x2369758>, 'add': <ufunc 'add'>, 'uint16': <type 'numpy.uint16'>, 'ndenumerate': <class 'numpy.lib.index_tricks.ndenumerate'>, 'hlines': <function hlines at 0x3197320>, 'ufunc': <type 'numpy.ufunc'>, 'save': <function save at 0x23fb140>, 'multinomial': <built-in method multinomial of mtrand.RandomState object at 0x7f399f841690>, 'ravel': <function ravel at 0x21d1e60>, 'float32': <type 'numpy.float32'>, 'real': <function real at 0x2301668>, 'int32': <type 'numpy.int32'>, 'path_length': <function path_length at 0x2c53c80>, 'tril_indices': <function tril_indices at 0x230daa0>, '_i117': u'## Fit Random Forest and generate predictions\\nnumStocks   = trainOutput.shape[2]\\nperformance = []\\npred        = np.zeros((310,numStocks))\\nfor stock in xrange(numStocks):\\n    \\n    # get stock-specific features\\n    X     = deriv[:,stock].reshape((deriv.shape[0],1))\\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n\\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n\\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'around': <function around at 0x21da938>, 'cbook': <module 'matplotlib.cbook' from '/usr/local/lib/python2.7/dist-packages/matplotlib/cbook.pyc'>, 'lexsort': <built-in function lexsort>, 'get_scale_names': <function get_scale_names at 0x2fc5050>, 'complex_': <type 'numpy.complex128'>, 'ComplexWarning': <class 'numpy.core.numeric.ComplexWarning'>, 'datestr2num': <function datestr2num at 0x307bd70>, 'np': <module 'numpy' from '/usr/local/lib/python2.7/dist-packages/numpy/__init__.pyc'>, 'unicode0': <type 'numpy.unicode_'>, 'ipmt': <function ipmt at 0x23fbcf8>, 'issubclass_': <function issubclass_ at 0x21b8ed8>, 'atleast_3d': <function atleast_3d at 0x22746e0>, 'nper': <function nper at 0x23fbc80>, 'integer': <type 'numpy.integer'>, 'unique': <function unique at 0x2369e60>, 'mod': <ufunc 'remainder'>, '_sh': <module 'IPython.core.shadowns' from '/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/core/shadowns.pyc'>, 'bitwise_not': <ufunc 'invert'>, 'plot_date': <function plot_date at 0x3197668>, '_i101': u'predicted_probs.shape', '_i131': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'laplace': <built-in method laplace of mtrand.RandomState object at 0x7f399f841690>, 'getbufsize': <function getbufsize at 0x21dd230>, 'isfortran': <function isfortran at 0x21c27d0>, '_i134': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'get_printoptions': <function get_printoptions at 0x21dacf8>, 'asarray_chkfinite': <function asarray_chkfinite at 0x236c398>, 'rcParams': RcParams({'agg.path.chunksize': 0,\n          'animation.avconv_args': '',\n          'animation.avconv_path': 'avconv',\n          'animation.bitrate': -1,\n          'animation.codec': 'mpeg4',\n          'animation.convert_args': '',\n          'animation.convert_path': 'convert',\n          'animation.ffmpeg_args': '',\n          'animation.ffmpeg_path': 'ffmpeg',\n          'animation.frame_format': 'png',\n          'animation.mencoder_args': '',\n          'animation.mencoder_path': 'mencoder',\n          'animation.writer': 'ffmpeg',\n          'axes.axisbelow': False,\n          'axes.color_cycle': ['#66c2a5',\n                               '#fc8d62',\n                               '#8da0cb',\n                               '#e78ac3',\n                               '#a6d854',\n                               '#ffd92f',\n                               '#e5c494'],\n          'axes.edgecolor': 'k',\n          'axes.facecolor': 'w',\n          'axes.formatter.limits': [-7, 7],\n          'axes.formatter.use_locale': False,\n          'axes.formatter.use_mathtext': False,\n          'axes.grid': False,\n          'axes.hold': True,\n          'axes.labelcolor': 'k',\n          'axes.labelsize': 'medium',\n          'axes.labelweight': 'normal',\n          'axes.linewidth': 1.0,\n          'axes.titlesize': 'large',\n          'axes.unicode_minus': True,\n          'axes.xmargin': 0,\n          'axes.ymargin': 0,\n          'axes3d.grid': True,\n          'backend': 'module://IPython.kernel.zmq.pylab.backend_inline',\n          'backend.qt4': 'PyQt4',\n          'backend_fallback': True,\n          'contour.negative_linestyle': 'dashed',\n          'datapath': '/usr/local/lib/python2.7/dist-packages/matplotlib/mpl-data',\n          'docstring.hardcopy': False,\n          'examples.directory': '',\n          'figure.autolayout': False,\n          'figure.dpi': 80,\n          'figure.edgecolor': 'white',\n          'figure.facecolor': 'white',\n          'figure.figsize': (6.0, 4.0),\n          'figure.frameon': True,\n          'figure.max_open_warning': 20,\n          'figure.subplot.bottom': 0.125,\n          'figure.subplot.hspace': 0.2,\n          'figure.subplot.left': 0.125,\n          'figure.subplot.right': 0.9,\n          'figure.subplot.top': 0.9,\n          'figure.subplot.wspace': 0.2,\n          'font.cursive': ['Apple Chancery',\n                           'Textile',\n                           'Zapf Chancery',\n                           'Sand',\n                           'cursive'],\n          'font.family': 'sans-serif',\n          'font.fantasy': ['Comic Sans MS',\n                           'Chicago',\n                           'Charcoal',\n                           'ImpactWestern',\n                           'fantasy'],\n          'font.monospace': ['Bitstream Vera Sans Mono',\n                             'DejaVu Sans Mono',\n                             'Andale Mono',\n                             'Nimbus Mono L',\n                             'Courier New',\n                             'Courier',\n                             'Fixed',\n                             'Terminal',\n                             'monospace'],\n          'font.sans-serif': ['Bitstream Vera Sans',\n                              'DejaVu Sans',\n                              'Lucida Grande',\n                              'Verdana',\n                              'Geneva',\n                              'Lucid',\n                              'Arial',\n                              'Helvetica',\n                              'Avant Garde',\n                              'sans-serif'],\n          'font.serif': ['Bitstream Vera Serif',\n                         'DejaVu Serif',\n                         'New Century Schoolbook',\n                         'Century Schoolbook L',\n                         'Utopia',\n                         'ITC Bookman',\n                         'Bookman',\n                         'Nimbus Roman No9 L',\n                         'Times New Roman',\n                         'Times',\n                         'Palatino',\n                         'Charter',\n                         'serif'],\n          'font.size': 10,\n          'font.stretch': 'normal',\n          'font.style': 'normal',\n          'font.variant': 'normal',\n          'font.weight': 'normal',\n          'grid.alpha': 1.0,\n          'grid.color': 'k',\n          'grid.linestyle': ':',\n          'grid.linewidth': 0.5,\n          'image.aspect': 'equal',\n          'image.cmap': 'jet',\n          'image.interpolation': 'bilinear',\n          'image.lut': 256,\n          'image.origin': 'upper',\n          'image.resample': False,\n          'interactive': True,\n          'keymap.all_axes': 'a',\n          'keymap.back': ['left', 'c', 'backspace'],\n          'keymap.forward': ['right', 'v'],\n          'keymap.fullscreen': ('f', 'ctrl+f'),\n          'keymap.grid': 'g',\n          'keymap.home': ['h', 'r', 'home'],\n          'keymap.pan': 'p',\n          'keymap.quit': ('ctrl+w', 'cmd+w'),\n          'keymap.save': ('s', 'ctrl+s'),\n          'keymap.xscale': ['k', 'L'],\n          'keymap.yscale': 'l',\n          'keymap.zoom': 'o',\n          'legend.borderaxespad': 0.5,\n          'legend.borderpad': 0.4,\n          'legend.columnspacing': 2.0,\n          'legend.fancybox': False,\n          'legend.fontsize': 'large',\n          'legend.frameon': True,\n          'legend.handleheight': 0.7,\n          'legend.handlelength': 2.0,\n          'legend.handletextpad': 0.8,\n          'legend.isaxes': True,\n          'legend.labelspacing': 0.5,\n          'legend.loc': 'upper right',\n          'legend.markerscale': 1.0,\n          'legend.numpoints': 2,\n          'legend.scatterpoints': 3,\n          'legend.shadow': False,\n          'lines.antialiased': True,\n          'lines.color': 'b',\n          'lines.dash_capstyle': 'butt',\n          'lines.dash_joinstyle': 'round',\n          'lines.linestyle': '-',\n          'lines.linewidth': 1.0,\n          'lines.marker': 'None',\n          'lines.markeredgewidth': 0.5,\n          'lines.markersize': 6,\n          'lines.solid_capstyle': 'projecting',\n          'lines.solid_joinstyle': 'round',\n          'mathtext.bf': 'serif:bold',\n          'mathtext.cal': 'cursive',\n          'mathtext.default': 'it',\n          'mathtext.fallback_to_cm': True,\n          'mathtext.fontset': 'cm',\n          'mathtext.it': 'serif:italic',\n          'mathtext.rm': 'serif',\n          'mathtext.sf': 'sans\\\\-serif',\n          'mathtext.tt': 'monospace',\n          'patch.antialiased': True,\n          'patch.edgecolor': 'k',\n          'patch.facecolor': 'b',\n          'patch.linewidth': 1.0,\n          'path.effects': [],\n          'path.simplify': True,\n          'path.simplify_threshold': 0.1111111111111111,\n          'path.sketch': None,\n          'path.snap': True,\n          'pdf.compression': 6,\n          'pdf.fonttype': 3,\n          'pdf.inheritcolor': False,\n          'pdf.use14corefonts': False,\n          'pgf.debug': False,\n          'pgf.preamble': [''],\n          'pgf.rcfonts': True,\n          'pgf.texsystem': 'xelatex',\n          'plugins.directory': '.matplotlib_plugins',\n          'polaraxes.grid': True,\n          'ps.distiller.res': 6000,\n          'ps.fonttype': 3,\n          'ps.papersize': 'letter',\n          'ps.useafm': False,\n          'ps.usedistiller': False,\n          'savefig.bbox': None,\n          'savefig.directory': '~',\n          'savefig.dpi': 72,\n          'savefig.edgecolor': 'w',\n          'savefig.extension': 'png',\n          'savefig.facecolor': 'w',\n          'savefig.format': 'png',\n          'savefig.frameon': True,\n          'savefig.jpeg_quality': 95,\n          'savefig.orientation': 'portrait',\n          'savefig.pad_inches': 0.1,\n          'svg.embed_char_paths': True,\n          'svg.fonttype': 'path',\n          'svg.image_inline': True,\n          'svg.image_noscale': False,\n          'text.antialiased': True,\n          'text.color': 'k',\n          'text.dvipnghack': None,\n          'text.hinting': True,\n          'text.hinting_factor': 8,\n          'text.latex.preamble': [''],\n          'text.latex.preview': False,\n          'text.latex.unicode': False,\n          'text.usetex': False,\n          'timezone': 'UTC',\n          'tk.pythoninspect': False,\n          'tk.window_focus': False,\n          'toolbar': 'toolbar2',\n          'verbose.fileo': 'sys.stdout',\n          'verbose.level': 'silent',\n          'webagg.open_in_browser': True,\n          'webagg.port': 8988,\n          'webagg.port_retries': 50,\n          'xtick.color': 'k',\n          'xtick.direction': 'in',\n          'xtick.labelsize': 'medium',\n          'xtick.major.pad': 4,\n          'xtick.major.size': 4,\n          'xtick.major.width': 0.5,\n          'xtick.minor.pad': 4,\n          'xtick.minor.size': 2,\n          'xtick.minor.width': 0.5,\n          'ytick.color': 'k',\n          'ytick.direction': 'in',\n          'ytick.labelsize': 'medium',\n          'ytick.major.pad': 4,\n          'ytick.major.size': 4,\n          'ytick.major.width': 0.5,\n          'ytick.minor.pad': 4,\n          'ytick.minor.size': 2,\n          'ytick.minor.width': 0.5}), 'pcolormesh': <function pcolormesh at 0x3197500>, 'string0': <type 'numpy.string_'>, 'barh': <function barh at 0x3196b18>, '_i130': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', '_i104': u'lastObserved[:,stock].shape', '_i133': u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', '_53': (array([  2.00000000e+00,   0.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         1.00000000e+00,   2.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         2.00000000e+00,   7.00000000e+00,   3.00000000e+00,\n         4.00000000e+00,   7.00000000e+00,   8.00000000e+00,\n         2.20000000e+01,   2.00000000e+01,   1.30000000e+01,\n         2.40000000e+01,   5.30000000e+01,   5.30000000e+01,\n         8.10000000e+01,   1.17000000e+02,   1.68000000e+02,\n         2.91000000e+02,   5.90000000e+02,   1.25600000e+03,\n         2.75800000e+03,   8.53900000e+03,   1.52450000e+04,\n         6.19300000e+03,   1.99500000e+03,   9.18000000e+02,\n         4.14000000e+02,   2.14000000e+02,   1.21000000e+02,\n         1.11000000e+02,   7.50000000e+01,   6.70000000e+01,\n         3.50000000e+01,   3.70000000e+01,   3.00000000e+01,\n         2.50000000e+01,   2.00000000e+01,   6.00000000e+00,\n         7.00000000e+00,   6.00000000e+00,   9.00000000e+00,\n         4.00000000e+00,   3.00000000e+00,   1.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n         3.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         3.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         1.00000000e+00]), array([-15.55  , -15.1994, -14.8488, -14.4982, -14.1476, -13.797 ,\n       -13.4464, -13.0958, -12.7452, -12.3946, -12.044 , -11.6934,\n       -11.3428, -10.9922, -10.6416, -10.291 ,  -9.9404,  -9.5898,\n        -9.2392,  -8.8886,  -8.538 ,  -8.1874,  -7.8368,  -7.4862,\n        -7.1356,  -6.785 ,  -6.4344,  -6.0838,  -5.7332,  -5.3826,\n        -5.032 ,  -4.6814,  -4.3308,  -3.9802,  -3.6296,  -3.279 ,\n        -2.9284,  -2.5778,  -2.2272,  -1.8766,  -1.526 ,  -1.1754,\n        -0.8248,  -0.4742,  -0.1236,   0.227 ,   0.5776,   0.9282,\n         1.2788,   1.6294,   1.98  ,   2.3306,   2.6812,   3.0318,\n         3.3824,   3.733 ,   4.0836,   4.4342,   4.7848,   5.1354,\n         5.486 ,   5.8366,   6.1872,   6.5378,   6.8884,   7.239 ,\n         7.5896,   7.9402,   8.2908,   8.6414,   8.992 ,   9.3426,\n         9.6932,  10.0438,  10.3944,  10.745 ,  11.0956,  11.4462,\n        11.7968,  12.1474,  12.498 ,  12.8486,  13.1992,  13.5498,\n        13.9004,  14.251 ,  14.6016,  14.9522,  15.3028,  15.6534,\n        16.004 ,  16.3546,  16.7052,  17.0558,  17.4064,  17.757 ,\n        18.1076,  18.4582,  18.8088,  19.1594,  19.51  ]), <a list of 100 Patch objects>), 'sign': <ufunc 'sign'>, '_dh': [u'/home/lane/iPython_notebooks', u'/home/lane/Kaggle/03 Predicting Stock Prices'], 'svd': <function svd at 0x238c9b0>, '_i106': u'pred = predicted_probs + lastObserved[200:,stock]', 'findobj': <function findobj at 0x31942a8>, 'spring': <function spring at 0x31989b0>, 'in1d': <function in1d at 0x236c050>, 'interp': <function interp at 0x236c668>, 'draw': <function draw at 0x3194d70>, 'ginput': <function ginput at 0x3194ed8>, 'rcdefaults': <function rcdefaults at 0x3194758>, 'rfft': <function rfft at 0x23feed8>, 'hypot': <ufunc 'hypot'>, 'logical_and': <ufunc 'logical_and'>, 'rrule': <class 'dateutil.rrule.rrule'>, 'table': <function table at 0x3198140>, 'diagflat': <function diagflat at 0x230d758>, 'float128': <type 'numpy.float128'>, 'matshow': <function matshow at 0x3196410>, 'isfinite': <ufunc 'isfinite'>, '_52': (array([  8.00000000e+00,   9.00000000e+00,   3.80000000e+01,\n         8.42000000e+02,   3.81220000e+04,   5.27000000e+02,\n         3.80000000e+01,   8.00000000e+00,   6.00000000e+00,\n         2.00000000e+00]), array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 10 Patch objects>), 'MINUTELY': 5, 'byte_bounds': <function byte_bounds at 0x2369488>, 'iinfo': <class 'numpy.core.getlimits.iinfo'>, 'kaiser': <function kaiser at 0x236d500>, 'ifftshift': <function ifftshift at 0x24096e0>, '_16': 0.32388299999999998, '_113': <type 'list'>, 'inside_poly': <function inside_poly at 0x2c53848>, 'warnings': <module 'warnings' from '/usr/lib/python2.7/warnings.pyc'>, '_116': -3.8199999999999998, 'cv': sklearn.cross_validation.KFold(n=200, n_folds=25), 'is_closed_polygon': <function is_closed_polygon at 0x2c539b0>, 'polysub': <function polysub at 0x238d0c8>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x2728f10>, 'ifftn': <function ifftn at 0x24092a8>, 'fromfile': <built-in function fromfile>, 'prod': <function prod at 0x21da6e0>, 'nanmax': <function nanmax at 0x236cc80>, 'LinearLocator': <class 'matplotlib.ticker.LinearLocator'>, 'tensorinv': <function tensorinv at 0x238c578>, 'plt': <module 'matplotlib.pyplot' from '/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc'>, 'seterrobj': <built-in function seterrobj>, 'power': <ufunc 'power'>, 'array_split': <function array_split at 0x2374d70>, 'zipf': <built-in method zipf of mtrand.RandomState object at 0x7f399f841690>, 'stem': <function stem at 0x3197aa0>, 'ioff': <function ioff at 0x3194488>, 'step': <function step at 0x3197b18>, 'percentile': <function percentile at 0x236d6e0>, 'hsv': <function hsv at 0x31987d0>, 'axhspan': <function axhspan at 0x3196938>, 'FPE_DIVIDEBYZERO': 1, '__name__': '__main__', 'subtract': <ufunc 'subtract'>, 'optimize': <module 'scipy.optimize' from '/usr/local/lib/python2.7/dist-packages/scipy/optimize/__init__.pyc'>, '_': -3.8199999999999998, 'mx2num': <function mx2num at 0x307fb18>, 'fft': <module 'numpy.fft' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/__init__.pyc'>, 'frombuffer': <built-in function frombuffer>, 'iscomplex': <function iscomplex at 0x2301758>, 'fill_betweenx': <function fill_betweenx at 0x3197140>, 'multivariate_normal': <built-in method multivariate_normal of mtrand.RandomState object at 0x7f399f841690>, 'add_docstring': <built-in function add_docstring>, 'argsort': <function argsort at 0x21d1aa0>, '_38': ([array([   0.,    0.,    0.,   11.,  179.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  189.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  189.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  194.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  188.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  191.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   12.,  181.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  193.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   23.,  158.,   11.,    2.,    0.,    2.,    0.]), array([   2.,    0.,    2.,   16.,  159.,   19.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  196.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  187.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  192.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  194.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  184.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  192.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    3.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   1.,    0.,    2.,   28.,  148.,   17.,    3.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  186.,    9.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  184.,    2.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  177.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,    7.,  186.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   20.,  168.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    2.,    0.,   15.,  167.,   16.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    0.,   14.,  167.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,   16.,  165.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   14.,  182.,    2.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    3.,   26.,  153.,   16.,    0.,    0.,    2.,    0.]), array([   3.,    1.,    7.,   46.,  102.,   26.,    8.,    3.,    2.,    2.]), array([   0.,    2.,    0.,   12.,  176.,   10.,    0.,    0.,    0.,    0.]), array([   2.,    0.,    1.,   20.,  155.,   18.,    4.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  181.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  184.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  189.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  182.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   11.,  182.,    6.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  184.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   22.,  166.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  195.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    3.,  193.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  190.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  196.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   29.,  140.,   21.,    4.,    2.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  190.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    3.,   31.,  144.,   17.,    3.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  193.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  188.,    4.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.])], array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 198 Lists of Patches objects>), '_19': 0.32388299999999998, 'fmin': <ufunc 'fmin'>, 'loadtxt': <function loadtxt at 0x23fb398>, '_31': (200, 198), '_30': (510, 198), '_33': (200, 198), '_18': 0.32388299999999998, '_35': [<matplotlib.lines.Line2D object at 0x3c0f110>], 'bytes_': <type 'numpy.string_'>, 'ones_like': <function ones_like at 0x21c2488>, '_36': [<matplotlib.lines.Line2D object at 0x3df1610>], 'ScalarFormatter': <class 'matplotlib.ticker.ScalarFormatter'>, 'is_busday': <built-in function is_busday>, 'arcsinh': <ufunc 'arcsinh'>, 'CLIP': 0, 'exp_safe': <function exp_safe at 0x2c51cf8>, '_i57': u\"fig = gcf()\\nfig.set_size_inches(16,4)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", '_i56': u\"yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", '_i55': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True)', '_i54': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100)', '_i53': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda,100)', '_i52': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda)', '__builtin__': <module '__builtin__' (built-in)>, 'dataset': array([[ 0.      ,  0.      ,  0.      , ...,  1.10484 ,  0.054283,\n         0.094868],\n       [-6.56    , -0.36    ,  0.04    , ...,  1.356407,  1.782152,\n         1.461476],\n       [-5.8     , -0.36    ,  0.04    , ...,  1.523808,  2.131682,\n         1.812402],\n       ..., \n       [-8.24    , -0.79    ,  0.04    , ...,  0.575108,  0.300311,\n         0.310644],\n       [-8.3     , -0.78    ,  0.04    , ...,  0.569777,  0.276743,\n         0.284429],\n       [-7.99    , -0.78    ,  0.01    , ...,  0.557479,  0.214942,\n         0.323883]]), 'annotate': <function annotate at 0x3198230>, '_i80': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201,:]\\ntest  = X[201:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'normalize': <function Normalize at 0x29e6b18>, 'intp': <type 'numpy.int64'>, 'standard_cauchy': <built-in method standard_cauchy of mtrand.RandomState object at 0x7f399f841690>, '_i82': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201]\\ntest  = X[201:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'unpackbits': <built-in function unpackbits>, 'HOURLY': 4, 'arrow': <function arrow at 0x3196848>, 'delete': <function delete at 0x236d938>, 'Infinity': inf, 'log': <ufunc 'log'>, 'numMetrics': 244, 'cdouble': <type 'numpy.complex128'>, 'complex128': <type 'numpy.complex128'>, 'tick_params': <function tick_params at 0x3198398>, 'switch_backend': <function switch_backend at 0x3194320>, 'round_': <function round_ at 0x21da9b0>, 'broadcast_arrays': <function broadcast_arrays at 0x2377410>, 'inner': <built-in function inner>, 'var': <function var at 0x21dab18>, 'c_': <numpy.lib.index_tricks.CClass object at 0x236f9d0>, 'slopes': <function slopes at 0x2c53758>, '_i87': u'train.shape', 'log10': <ufunc 'log10'>, 'thisMetric': array([[ 0.142166],\n       [ 0.272029],\n       [ 0.062272],\n       [ 0.229153],\n       [ 0.042557],\n       [ 0.33731 ],\n       [ 0.310483],\n       [ 0.133083],\n       [ 0.06245 ],\n       [ 0.110805],\n       [ 0.132204],\n       [ 0.169738],\n       [ 0.063246],\n       [ 0.260853],\n       [ 0.136382],\n       [ 0.095102],\n       [ 0.133041],\n       [ 0.175214],\n       [ 0.226495],\n       [ 0.153984],\n       [ 0.188709],\n       [ 0.045583],\n       [ 0.530984],\n       [ 0.060919],\n       [ 0.621289],\n       [ 0.048762],\n       [ 0.106771],\n       [ 0.088944],\n       [ 0.126271],\n       [ 0.07356 ],\n       [ 0.289156],\n       [ 0.109545],\n       [ 0.133791],\n       [ 0.127845],\n       [ 0.042164],\n       [ 0.206586],\n       [ 0.092436],\n       [ 0.125477],\n       [ 0.101871],\n       [ 0.1761  ],\n       [ 0.196723],\n       [ 0.097354],\n       [ 0.2     ],\n       [ 0.061192],\n       [ 0.096839],\n       [ 0.1     ],\n       [ 0.142867],\n       [ 0.21349 ],\n       [ 0.06    ],\n       [ 0.205047],\n       [ 0.251794],\n       [ 0.066332],\n       [ 0.078811],\n       [ 0.32426 ],\n       [ 0.034641],\n       [ 0.056372],\n       [ 0.314925],\n       [ 0.150481],\n       [ 0.109545],\n       [ 0.173429],\n       [ 0.467737],\n       [ 0.200942],\n       [ 0.135565],\n       [ 0.138363],\n       [ 0.166966],\n       [ 0.557494],\n       [ 0.292746],\n       [ 0.188267],\n       [ 0.129615],\n       [ 0.294524],\n       [ 0.057831],\n       [ 0.307571],\n       [ 0.476667],\n       [ 0.04    ],\n       [ 0.318974],\n       [ 0.061734],\n       [ 0.25307 ],\n       [ 0.34    ],\n       [ 0.239397],\n       [ 0.268701],\n       [ 0.291681],\n       [ 0.19    ],\n       [ 0.120324],\n       [ 0.146553],\n       [ 0.421189],\n       [ 0.25399 ],\n       [ 0.05831 ],\n       [ 0.119629],\n       [ 0.336452],\n       [ 0.073106],\n       [ 0.204885],\n       [ 0.11225 ],\n       [ 0.153768],\n       [ 0.181659],\n       [ 0.248149],\n       [ 0.371319],\n       [ 0.79813 ],\n       [ 0.303278],\n       [ 0.289271],\n       [ 0.513561],\n       [ 0.287653],\n       [ 0.106301],\n       [ 0.608997],\n       [ 0.136545],\n       [ 0.209152],\n       [ 0.304485],\n       [ 0.186934],\n       [ 0.319026],\n       [ 0.076449],\n       [ 0.109595],\n       [ 0.11949 ],\n       [ 0.15268 ],\n       [ 0.324157],\n       [ 0.679485],\n       [ 0.158254],\n       [ 0.179846],\n       [ 0.099722],\n       [ 0.034641],\n       [ 0.104297],\n       [ 0.075572],\n       [ 0.067905],\n       [ 0.564427],\n       [ 0.204559],\n       [ 0.153442],\n       [ 0.088192],\n       [ 0.068638],\n       [ 0.108525],\n       [ 0.14345 ],\n       [ 0.19105 ],\n       [ 0.164621],\n       [ 0.141067],\n       [ 0.104297],\n       [ 0.114066],\n       [ 0.172755],\n       [ 0.308887],\n       [ 0.067905],\n       [ 0.100222],\n       [ 0.200776],\n       [ 0.134164],\n       [ 0.122656],\n       [ 0.074833],\n       [ 0.249087],\n       [ 0.074012],\n       [ 0.119164],\n       [ 0.215587],\n       [ 0.424513],\n       [ 0.096437],\n       [ 0.103494],\n       [ 0.232809],\n       [ 0.052705],\n       [ 0.103441],\n       [ 0.189209],\n       [ 0.12    ],\n       [ 0.208113],\n       [ 1.304318],\n       [ 0.034641],\n       [ 0.340506],\n       [ 0.03    ],\n       [ 0.097011],\n       [ 0.216974],\n       [ 0.585928],\n       [ 0.231948],\n       [ 0.141578],\n       [ 0.089691],\n       [ 0.20445 ],\n       [ 0.125344],\n       [ 0.07746 ],\n       [ 0.083533],\n       [ 0.103655],\n       [ 0.052915],\n       [ 0.314713],\n       [ 0.405476],\n       [ 0.11879 ],\n       [ 0.283333],\n       [ 0.471181],\n       [ 0.228789],\n       [ 0.077746],\n       [ 0.074162],\n       [ 0.161245],\n       [ 0.212315],\n       [ 0.202731],\n       [ 0.131149],\n       [ 0.2319  ],\n       [ 0.244154],\n       [ 0.200693],\n       [ 0.453995],\n       [ 0.1206  ],\n       [ 0.220177],\n       [ 0.153623],\n       [ 0.270267],\n       [ 0.121655],\n       [ 0.074907],\n       [ 0.206263],\n       [ 0.157198],\n       [ 0.167929],\n       [ 0.111355],\n       [ 0.275035],\n       [ 0.126095],\n       [ 0.195192],\n       [ 0.113186],\n       [ 0.208753],\n       [ 0.536563],\n       [ 0.110905],\n       [ 0.083732],\n       [ 0.235891],\n       [ 0.131951],\n       [ 0.191949],\n       [ 0.129615],\n       [ 0.139443],\n       [ 0.261874],\n       [ 0.139084],\n       [ 0.321559],\n       [ 0.187113],\n       [ 0.090615],\n       [ 0.066165],\n       [ 0.067165],\n       [ 0.155385],\n       [ 0.119629],\n       [ 0.220454],\n       [ 0.17845 ],\n       [ 0.135195],\n       [ 0.30921 ],\n       [ 0.20955 ],\n       [ 0.086667],\n       [ 0.202731],\n       [ 0.072801],\n       [ 0.086859],\n       [ 0.183697],\n       [ 0.25738 ],\n       [ 0.202731],\n       [ 0.279106],\n       [ 0.114455],\n       [ 0.960422],\n       [ 0.151364],\n       [ 0.175531],\n       [ 0.122066],\n       [ 0.239049],\n       [ 0.150481],\n       [ 0.167332],\n       [ 0.36457 ],\n       [ 0.225389],\n       [ 0.279364],\n       [ 0.142867],\n       [ 0.020276],\n       [ 0.090615],\n       [ 0.426146],\n       [ 0.150591],\n       [ 0.296891],\n       [ 0.04    ],\n       [ 0.203415],\n       [ 0.25399 ],\n       [ 0.122384],\n       [ 0.112151],\n       [ 0.051424],\n       [ 0.08    ],\n       [ 0.380526],\n       [ 0.381838],\n       [ 0.133458],\n       [ 0.041231],\n       [ 0.338083],\n       [ 0.133583],\n       [ 0.215407],\n       [ 0.134454],\n       [ 0.109138],\n       [ 0.351568],\n       [ 0.263333],\n       [ 0.129529],\n       [ 0.098545],\n       [ 0.684471],\n       [ 0.348712],\n       [ 0.047958],\n       [ 0.298068],\n       [ 0.065405],\n       [ 0.364692],\n       [ 0.054263],\n       [ 0.301625],\n       [ 0.147309],\n       [ 0.605402],\n       [ 0.074162],\n       [ 0.129271],\n       [ 0.21    ],\n       [ 0.389102],\n       [ 0.304649],\n       [ 0.199109],\n       [ 0.08775 ],\n       [ 0.074012],\n       [ 0.25865 ],\n       [ 0.155885],\n       [ 0.156667],\n       [ 0.228206],\n       [ 0.099219],\n       [ 0.108679],\n       [ 0.08    ],\n       [ 0.124544],\n       [ 0.138724],\n       [ 0.104403],\n       [ 0.047958],\n       [ 0.264008],\n       [ 0.363517],\n       [ 0.558341],\n       [ 0.119629],\n       [ 0.106301],\n       [ 0.147121],\n       [ 0.124499],\n       [ 0.216795],\n       [ 0.145297],\n       [ 0.11348 ],\n       [ 0.311929],\n       [ 0.332265],\n       [ 0.244495],\n       [ 1.289358],\n       [ 0.079652],\n       [ 0.847526],\n       [ 0.108218],\n       [ 0.208992],\n       [ 0.393206],\n       [ 0.099051],\n       [ 0.050772],\n       [ 0.199444],\n       [ 0.093274],\n       [ 0.06    ],\n       [ 0.117898],\n       [ 0.380716],\n       [ 0.107703],\n       [ 0.080069],\n       [ 0.146287],\n       [ 0.218174],\n       [ 0.194165],\n       [ 0.166567],\n       [ 0.063596],\n       [ 0.184662],\n       [ 0.13784 ],\n       [ 0.618663],\n       [ 0.130384],\n       [ 0.164249],\n       [ 0.652687],\n       [ 0.693253],\n       [ 0.086667],\n       [ 0.317245],\n       [ 0.144837],\n       [ 0.016667],\n       [ 0.400222],\n       [ 0.079652],\n       [ 0.084327],\n       [ 0.156241],\n       [ 0.099051],\n       [ 0.193592],\n       [ 0.15748 ],\n       [ 0.152571],\n       [ 0.105251],\n       [ 0.220025],\n       [ 0.371349],\n       [ 0.053955],\n       [ 0.556996],\n       [ 0.149926],\n       [ 0.071414],\n       [ 0.932011],\n       [ 0.108372],\n       [ 0.36653 ],\n       [ 0.311359],\n       [ 0.199444],\n       [ 0.284917],\n       [ 0.066332],\n       [ 0.138924],\n       [ 0.091165],\n       [ 0.142127],\n       [ 0.219949],\n       [ 0.1294  ],\n       [ 0.30249 ],\n       [ 0.145258],\n       [ 0.06888 ],\n       [ 0.371139],\n       [ 0.251219],\n       [ 0.162207],\n       [ 0.124141],\n       [ 0.291738],\n       [ 0.35201 ],\n       [ 0.08124 ],\n       [ 0.174865],\n       [ 2.412726],\n       [ 0.063857],\n       [ 0.15592 ],\n       [ 0.261236],\n       [ 0.108628],\n       [ 0.138203],\n       [ 0.127671],\n       [ 0.345897],\n       [ 0.162788],\n       [ 0.271477],\n       [ 0.06888 ],\n       [ 0.148324],\n       [ 0.451934],\n       [ 0.036667],\n       [ 0.188532],\n       [ 0.093808],\n       [ 0.137113],\n       [ 0.509117],\n       [ 0.176068],\n       [ 0.319913],\n       [ 0.315718],\n       [ 0.244336],\n       [ 0.10198 ],\n       [ 0.182757],\n       [ 0.037417],\n       [ 0.07356 ],\n       [ 0.412432],\n       [ 0.064893],\n       [ 0.175784],\n       [ 0.194165],\n       [ 0.232904],\n       [ 0.044721],\n       [ 0.065574],\n       [ 0.146287],\n       [ 0.062004],\n       [ 0.176572],\n       [ 0.476527],\n       [ 0.238118],\n       [ 0.065574],\n       [ 0.11893 ],\n       [ 0.247745],\n       [ 0.172337],\n       [ 0.101379],\n       [ 0.059815],\n       [ 0.285326],\n       [ 0.091348],\n       [ 0.257833],\n       [ 0.546626],\n       [ 0.117379],\n       [ 0.26327 ],\n       [ 0.051099],\n       [ 0.102956],\n       [ 0.173141],\n       [ 0.117237],\n       [ 0.185472],\n       [ 0.171205],\n       [ 0.060828],\n       [ 0.094868],\n       [ 0.171205],\n       [ 0.27258 ],\n       [ 0.098995],\n       [ 0.854868],\n       [ 0.08    ],\n       [ 0.08705 ],\n       [ 0.12252 ],\n       [ 0.344384],\n       [ 0.353475],\n       [ 0.178263],\n       [ 0.10198 ],\n       [ 0.102198],\n       [ 0.174356],\n       [ 0.35819 ],\n       [ 0.136382],\n       [ 0.056075],\n       [ 0.127671],\n       [ 0.081854],\n       [ 0.109087],\n       [ 0.223557],\n       [ 0.325645],\n       [ 0.563777],\n       [ 0.140633],\n       [ 0.138564],\n       [ 0.954713],\n       [ 0.061644],\n       [ 0.095917],\n       [ 0.052915],\n       [ 0.495861],\n       [ 0.154416],\n       [ 0.095801],\n       [ 0.250422],\n       [ 0.031798],\n       [ 0.197737],\n       [ 0.317175],\n       [ 0.161898],\n       [ 0.038006],\n       [ 0.321472],\n       [ 0.072648],\n       [ 0.119907],\n       [ 0.118322],\n       [ 0.076012],\n       [ 0.236854],\n       [ 0.143798],\n       [ 0.164857],\n       [ 0.099387],\n       [ 0.021858],\n       [ 0.051424],\n       [ 0.291624],\n       [ 0.190029],\n       [ 0.133832],\n       [ 0.245515],\n       [ 0.273699],\n       [ 0.176289],\n       [ 0.200499],\n       [ 0.535859],\n       [ 0.159931],\n       [ 0.193075],\n       [ 0.285034],\n       [ 0.110454],\n       [ 0.194879],\n       [ 0.150997],\n       [ 0.043333],\n       [ 0.060645],\n       [ 0.150923],\n       [ 0.439634],\n       [ 0.230024],\n       [ 0.120046],\n       [ 0.103494],\n       [ 0.281267],\n       [ 0.083333],\n       [ 0.062539],\n       [ 0.452769]]), 'hypergeometric': <built-in method hypergeometric of mtrand.RandomState object at 0x7f399f841690>, 'uintp': <type 'numpy.uint64'>, 'unwrap': <function unwrap at 0x236c758>, 'NullLocator': <class 'matplotlib.ticker.NullLocator'>, '_i68': u'normTarget.shape', 'triangular': <built-in method triangular of mtrand.RandomState object at 0x7f399f841690>, 'noncentral_chisquare': <built-in method noncentral_chisquare of mtrand.RandomState object at 0x7f399f841690>, 'histogram': <function histogram at 0x236c230>, 'msg': 'To:lanemcintosh@gmail.com\\nFrom: mcintoshlane@gmail.com\\nSubject:Kaggle iPython Notebook \\n\\nYour Python Script has now Completed!', 'issubdtype': <function issubdtype at 0x21bf050>, 'maximum_sctype': <function maximum_sctype at 0x21b8cf8>, 'flexible': <type 'numpy.flexible'>, 'movavg': <function movavg at 0x2c51938>, 'squeeze': <function squeeze at 0x21d1cf8>, 'int8': <type 'numpy.int8'>, 'cholesky': <function cholesky at 0x238c668>, 'info': <function info at 0x23696e0>, 'seterr': <function seterr at 0x21dd0c8>, 'argmin': <function argmin at 0x21d1b90>, 'fignum_exists': <function has_fignum at 0x2cf9938>, 'genfromtxt': <function genfromtxt at 0x23fb500>, 'rec_append_fields': <function rec_append_fields at 0x2c52488>, 'j': 9, 'maximum': <ufunc 'maximum'>, '_23': (510, 55, 198), 'record': <class 'numpy.core.records.record'>, 'obj2sctype': <function obj2sctype at 0x21b8e60>, '_61': <matplotlib.text.Text object at 0x8c45410>, 'clongdouble': <type 'numpy.complex256'>, 'sum': <function sum at 0x21da140>, 'isrealobj': <function isrealobj at 0x23018c0>, 'log1p': <ufunc 'log1p'>, '_oh': {8: 510, 10: 200, 12: (510, 55, 244), 13: (510, 55, 198), 16: 0.32388299999999998, 18: 0.32388299999999998, 19: 0.32388299999999998, 21: (510, 55, 442), 23: (510, 55, 198), 24: 55, 25: (200, 198), 26: (200, 198), 27: (510, 55, 244), 30: (510, 198), 31: (200, 198), 33: (200, 198), 34: (200, 198), 35: [<matplotlib.lines.Line2D object at 0x3c0f110>], 36: [<matplotlib.lines.Line2D object at 0x3df1610>], 37: (array([   3.,   11.,   42.,  112.,   26.,    4.,    0.,    0.,    0.,    2.]), array([-2.12 , -1.478, -0.836, -0.194,  0.448,  1.09 ,  1.732,  2.374,\n        3.016,  3.658,  4.3  ]), <a list of 10 Patch objects>), 38: ([array([   0.,    0.,    0.,   11.,  179.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  189.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  189.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  194.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  188.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  191.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   12.,  181.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  193.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   23.,  158.,   11.,    2.,    0.,    2.,    0.]), array([   2.,    0.,    2.,   16.,  159.,   19.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  196.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  187.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  192.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  194.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  184.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  192.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    3.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   1.,    0.,    2.,   28.,  148.,   17.,    3.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  186.,    9.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  184.,    2.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  177.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,    7.,  186.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   20.,  168.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    2.,    0.,   15.,  167.,   16.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    0.,   14.,  167.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,   16.,  165.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   14.,  182.,    2.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    3.,   26.,  153.,   16.,    0.,    0.,    2.,    0.]), array([   3.,    1.,    7.,   46.,  102.,   26.,    8.,    3.,    2.,    2.]), array([   0.,    2.,    0.,   12.,  176.,   10.,    0.,    0.,    0.,    0.]), array([   2.,    0.,    1.,   20.,  155.,   18.,    4.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  181.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  184.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  189.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  182.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   11.,  182.,    6.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  184.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   22.,  166.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  195.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    3.,  193.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  190.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  196.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   29.,  140.,   21.,    4.,    2.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  190.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    3.,   31.,  144.,   17.,    3.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  193.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  188.,    4.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.])], array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 198 Lists of Patches objects>), 44: (200, 198), 52: (array([  8.00000000e+00,   9.00000000e+00,   3.80000000e+01,\n         8.42000000e+02,   3.81220000e+04,   5.27000000e+02,\n         3.80000000e+01,   8.00000000e+00,   6.00000000e+00,\n         2.00000000e+00]), array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 10 Patch objects>), 53: (array([  2.00000000e+00,   0.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         1.00000000e+00,   2.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         2.00000000e+00,   7.00000000e+00,   3.00000000e+00,\n         4.00000000e+00,   7.00000000e+00,   8.00000000e+00,\n         2.20000000e+01,   2.00000000e+01,   1.30000000e+01,\n         2.40000000e+01,   5.30000000e+01,   5.30000000e+01,\n         8.10000000e+01,   1.17000000e+02,   1.68000000e+02,\n         2.91000000e+02,   5.90000000e+02,   1.25600000e+03,\n         2.75800000e+03,   8.53900000e+03,   1.52450000e+04,\n         6.19300000e+03,   1.99500000e+03,   9.18000000e+02,\n         4.14000000e+02,   2.14000000e+02,   1.21000000e+02,\n         1.11000000e+02,   7.50000000e+01,   6.70000000e+01,\n         3.50000000e+01,   3.70000000e+01,   3.00000000e+01,\n         2.50000000e+01,   2.00000000e+01,   6.00000000e+00,\n         7.00000000e+00,   6.00000000e+00,   9.00000000e+00,\n         4.00000000e+00,   3.00000000e+00,   1.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n         3.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         3.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         1.00000000e+00]), array([-15.55  , -15.1994, -14.8488, -14.4982, -14.1476, -13.797 ,\n       -13.4464, -13.0958, -12.7452, -12.3946, -12.044 , -11.6934,\n       -11.3428, -10.9922, -10.6416, -10.291 ,  -9.9404,  -9.5898,\n        -9.2392,  -8.8886,  -8.538 ,  -8.1874,  -7.8368,  -7.4862,\n        -7.1356,  -6.785 ,  -6.4344,  -6.0838,  -5.7332,  -5.3826,\n        -5.032 ,  -4.6814,  -4.3308,  -3.9802,  -3.6296,  -3.279 ,\n        -2.9284,  -2.5778,  -2.2272,  -1.8766,  -1.526 ,  -1.1754,\n        -0.8248,  -0.4742,  -0.1236,   0.227 ,   0.5776,   0.9282,\n         1.2788,   1.6294,   1.98  ,   2.3306,   2.6812,   3.0318,\n         3.3824,   3.733 ,   4.0836,   4.4342,   4.7848,   5.1354,\n         5.486 ,   5.8366,   6.1872,   6.5378,   6.8884,   7.239 ,\n         7.5896,   7.9402,   8.2908,   8.6414,   8.992 ,   9.3426,\n         9.6932,  10.0438,  10.3944,  10.745 ,  11.0956,  11.4462,\n        11.7968,  12.1474,  12.498 ,  12.8486,  13.1992,  13.5498,\n        13.9004,  14.251 ,  14.6016,  14.9522,  15.3028,  15.6534,\n        16.004 ,  16.3546,  16.7052,  17.0558,  17.4064,  17.757 ,\n        18.1076,  18.4582,  18.8088,  19.1594,  19.51  ]), <a list of 100 Patch objects>), 61: <matplotlib.text.Text object at 0x8c45410>, 63: <matplotlib.text.Text object at 0x8d13e90>, 64: <matplotlib.text.Text object at 0x9b88ad0>, 65: <matplotlib.text.Text object at 0x92e02d0>, 66: (510, 55, 198), 67: (510, 198), 68: (200, 198), 70: 200, 71: sklearn.cross_validation.KFold(n=200, n_folds=63), 74: array([False, False, False, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), 75: (200,), 76: (200,), 77: array([[[ 0.      ,  0.      ,  0.      , ...,  0.160672,  0.054283,\n          0.060093],\n        [ 1.61    ,  0.12    ,  0.12    , ...,  0.246306,  0.448241,\n          0.377197],\n        [ 1.12    ,  0.31    ,  0.12    , ...,  0.281271,  0.484713,\n          0.431599],\n        ..., \n        [ 0.9     ,  0.19    ,  0.07    , ...,  0.119027,  0.084617,\n          0.074685],\n        [ 0.87    ,  0.22    ,  0.08    , ...,  0.122028,  0.058538,\n          0.080691],\n        [ 0.83    ,  0.25    ,  0.08    , ...,  0.125018,  0.043205,\n          0.088569]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.405808,  0.188892,\n          0.209284],\n        [ 0.95    , -0.18    ,  0.15    , ...,  0.42738 ,  0.348119,\n          0.34322 ],\n        [ 1.04    , -0.18    ,  0.15    , ...,  0.463135,  0.439758,\n          0.449271],\n        ..., \n        [ 0.87    , -0.01    ,  0.1     , ...,  0.447247,  0.132313,\n          0.208433],\n        [ 0.83    ,  0.      ,  0.05    , ...,  0.445714,  0.153232,\n          0.138243],\n        [ 0.97    , -0.05    ,  0.05    , ...,  0.445714,  0.155649,\n          0.138243]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.934708,  0.084538,\n          0.154596],\n        [ 2.75    ,  0.25    ,  0.      , ...,  0.859673,  0.675959,\n          0.553122],\n        [ 2.22    ,  0.24    ,  0.      , ...,  0.800801,  0.754047,\n          0.652951],\n        ..., \n        [ 6.09    , -0.13    ,  0.      , ...,  0.717239,  0.111535,\n          0.55109 ],\n        [ 6.22    , -0.13    ,  0.      , ...,  0.712795,  0.116218,\n          0.388987],\n        [ 5.75    , -0.17    ,  0.      , ...,  0.715292,  0.152665,\n          0.252609]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.199729,  0.051769,\n          0.117898],\n        [-3.29    ,  0.04    ,  0.24    , ...,  0.349317,  0.77501 ,\n          0.659621],\n        [-3.53    ,  0.06    ,  0.37    , ...,  0.460716,  1.013778,\n          0.894228],\n        ..., \n        [-2.21    ,  1.33    ,  0.5     , ...,  0.221407,  0.051251,\n          0.160312],\n        [-2.25    ,  1.27    ,  0.54    , ...,  0.203557,  0.054283,\n          0.14087 ],\n        [-2.42    ,  1.27    ,  0.53    , ...,  0.185629,  0.059889,\n          0.054874]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.52827 ,  0.128219,\n          0.104881],\n        [ 0.17    , -0.06    ,  0.      , ...,  0.520413,  0.180665,\n          0.150702],\n        [ 0.59    , -0.12    , -0.06    , ...,  0.520859,  0.288167,\n          0.243676],\n        ..., \n        [ 0.97    , -0.24    , -0.08    , ...,  0.296868,  0.023381,\n          0.264344],\n        [ 0.82    , -0.24    , -0.08    , ...,  0.297405,  0.037417,\n          0.211529],\n        [ 0.97    , -0.18    , -0.04    , ...,  0.298542,  0.037238,\n          0.132077]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.31634 ,  0.082624,\n          0.108628],\n        [-0.71    ,  0.26    ,  0.74    , ...,  0.307045,  0.20775 ,\n          0.205129],\n        [-1.06    ,  0.19    ,  0.74    , ...,  0.31471 ,  0.277897,\n          0.274672],\n        ..., \n        [-1.04    , -0.08    ,  0.12    , ...,  0.184709,  0.06532 ,  0.16    ],\n        [-0.95    , -0.19    ,  0.12    , ...,  0.178122,  0.028284,\n          0.152315],\n        [-0.84    , -0.18    ,  0.12    , ...,  0.173413,  0.054283,\n          0.123063]]]), 78: (510, 55, 442), 81: (510,), 83: (201,), 84: (309,), 85: (201,), 87: (200,), 88: (310,), 89: (200,), 90: (200,), 92: (200,), 93: (310,), 95: (510, 1), 102: 310, 104: (510,), 108: <matplotlib.text.Text object at 0x918f1d0>, 109: 198, 111: <matplotlib.text.Text object at 0x9894b90>, 113: <type 'list'>, 114: (310,), 116: -3.8199999999999998}, 'flatten': <function flatten at 0x2992b90>, 'gmail_pwd': 'hansolo8chewy', 'YEARLY': 0, 'digitize': <built-in function digitize>, 'clongfloat': <type 'numpy.complex256'>, 'ylim': <function ylim at 0x3195b90>, 'yscale': <function yscale at 0x3195c80>, 'inv': <function inv at 0x238c5f0>, 'ediff1d': <function ediff1d at 0x2369050>, 'pie': <function pie at 0x3197578>, '_i45': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,0))', 'char': <module 'numpy.core.defchararray' from '/usr/local/lib/python2.7/dist-packages/numpy/core/defchararray.pyc'>, 'single': <type 'numpy.float32'>, 'isposinf': <function isposinf at 0x2301500>, 'set_cmap': <function set_cmap at 0x3196398>, 'ScalarType': (<type 'int'>, <type 'float'>, <type 'complex'>, <type 'long'>, <type 'bool'>, <type 'str'>, <type 'unicode'>, <type 'buffer'>, <type 'numpy.float16'>, <type 'numpy.string_'>, <type 'numpy.float128'>, <type 'numpy.uint64'>, <type 'numpy.int16'>, <type 'numpy.timedelta64'>, <type 'numpy.object_'>, <type 'numpy.float64'>, <type 'numpy.int64'>, <type 'numpy.uint8'>, <type 'numpy.datetime64'>, <type 'numpy.complex256'>, <type 'numpy.float32'>, <type 'numpy.uint32'>, <type 'numpy.int8'>, <type 'numpy.void'>, <type 'numpy.complex128'>, <type 'numpy.uint64'>, <type 'numpy.int32'>, <type 'numpy.bool_'>, <type 'numpy.unicode_'>, <type 'numpy.complex64'>, <type 'numpy.int64'>, <type 'numpy.uint16'>), 'noncentral_f': <built-in method noncentral_f of mtrand.RandomState object at 0x7f399f841690>, 'triu': <function triu at 0x230d8c0>, 'inf': inf, 'fill': <function fill at 0x3197050>, 'expand_dims': <function expand_dims at 0x2374b90>, 'pareto': <built-in method pareto of mtrand.RandomState object at 0x7f399f841690>, 'logspace': <function logspace at 0x2270de8>, 'floor': <ufunc 'floor'>, 'polyadd': <function polyadd at 0x238d050>, 'TU': TU, 'nan': nan, 'modf': <ufunc 'modf'>, 'emath': <module 'numpy.lib.scimath' from '/usr/local/lib/python2.7/dist-packages/numpy/lib/scimath.pyc'>, 'arctan': <ufunc 'arctan'>, 'bmat': <function bmat at 0x2373cf8>, 'Slider': <class 'matplotlib.widgets.Slider'>, 'prism': <function prism at 0x3198938>, 'isclose': <function isclose at 0x21dbed8>, 'ERR_DEFAULT': 0, 'TH': TH, 'xscale': <function xscale at 0x3195c08>, '_i109': u'trainOutput.shape[2]', 'register_cmap': <function register_cmap at 0x2b80e60>, 'roll': <function roll at 0x21c2b90>, 'figsize': <function figsize at 0x1de18c0>, '_i70': u'len(target)', 'compare_chararrays': <built-in function compare_chararrays>, 'vsplit': <function vsplit at 0x2374ed8>, 'real_if_close': <function real_if_close at 0x2301a28>, 'repeat': <function repeat at 0x21d1848>, 'hamming': <function hamming at 0x236d2a8>, 'ALLOW_THREADS': 1, '_i66': u'trainOutput.shape', 'isInput': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True], '_12': (510, 55, 244), 'errorbar': <function errorbar at 0x3196ed8>, 'ravel_multi_index': <built-in function ravel_multi_index>, '_i67': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\nderiv.shape', 'string_': <type 'numpy.string_'>, 'isinf': <ufunc 'isinf'>, 'spacing': <ufunc 'spacing'>, 'Inf': inf, 'ndarray': <type 'numpy.ndarray'>, 'delaxes': <function delaxes at 0x3195398>, 'pcolor': <function pcolor at 0x3197488>, 'e': 2.718281828459045, 'ERR_CALL': 3, 'datetime_data': <built-in function datetime_data>, '_i79': u'X.shape', 'test': array([[ -2.90000000e-01,   2.85714000e-01,   7.00000000e+00, ...,\n          5.15190000e-01,   2.20786000e-01,   2.08753000e-01],\n       [  3.80000000e-01,   1.60000000e+00,   5.00000000e+00, ...,\n          8.83311000e-01,   4.69965000e-01,   5.36563000e-01],\n       [  2.00000000e-02,   1.11111000e-01,   9.00000000e+00, ...,\n          3.90504000e-01,   1.20665000e-01,   1.10905000e-01],\n       ..., \n       [  2.70000000e-01,   3.23529000e-01,   3.40000000e+01, ...,\n          1.79467000e-01,   8.55570000e-02,   8.33330000e-02],\n       [  0.00000000e+00,   2.94117000e-01,   1.70000000e+01, ...,\n          1.95387000e-01,   7.63330000e-02,   6.25390000e-02],\n       [  3.10000000e-01,   1.60000000e+00,   5.00000000e+00, ...,\n          1.05697000e+00,   4.11582000e-01,   4.52769000e-01]]), 'ERR_IGNORE': 0, 'flag': <function flag at 0x3198668>, 'hsplit': <function hsplit at 0x2374e60>, 'result_type': <built-in function result_type>, 'gradient': <function gradient at 0x236c578>, 'base_repr': <function base_repr at 0x21dbc80>, 'eigh': <function eigh at 0x238c938>, 'argwhere': <function argwhere at 0x21c2848>, 'set_string_function': <function set_string_function at 0x21dba28>, 'swapaxes': <function swapaxes at 0x21d1938>, 'FixedLocator': <class 'matplotlib.ticker.FixedLocator'>, '_111': <matplotlib.text.Text object at 0x9894b90>, 'tensorsolve': <function tensorsolve at 0x238c488>}\n        self.user_ns = {'disp': <function disp at 0x236cd70>, 'union1d': <function union1d at 0x236c0c8>, 'all': <function all at 0x21da398>, '_i132': u'sheet.shape', 'dist': <function dist at 0x2c51758>, 'issubsctype': <function issubsctype at 0x21b8f50>, 'sca': <function sca at 0x3195410>, 'savez': <function savez at 0x23fb1b8>, '_i58': u\"fig = gcf()\\nfig.set_size_inches(16,6)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", 'entropy': <function entropy at 0x2c4fe60>, 'atleast_2d': <function atleast_2d at 0x2274668>, 'restoredot': <built-in function restoredot>, '_95': (510, 1), 'streamplot': <function streamplot at 0x3197b90>, '_93': (310,), '_92': (200,), 'ptp': <function ptp at 0x21da500>, 'Subplot': <class 'matplotlib.axes.AxesSubplot'>, 'frange': <function frange at 0x2c52050>, 'PackageLoader': <class 'numpy._import_tools.PackageLoader'>, 'show': <function show at 0x3194398>, '_83': (201,), 'fft2': <function fft2 at 0x2409320>, '_63': <matplotlib.text.Text object at 0x8d13e90>, 'xkcd': <function xkcd at 0x3194848>, 'rec2csv': <function rec2csv at 0x2c535f0>, 'ix_': <function ix_ at 0x236db18>, 'resize': <function resize at 0x21d1c80>, '_64': <matplotlib.text.Text object at 0x9b88ad0>, 'blackman': <function blackman at 0x236d140>, '_68': (200, 198), 'norm': <function norm at 0x238ccf8>, 'FLOATING_POINT_SUPPORT': 1, '_i85': u'train.shape', 'MultipleLocator': <class 'matplotlib.ticker.MultipleLocator'>, 'mlab': <module 'matplotlib.mlab' from '/usr/local/lib/python2.7/dist-packages/matplotlib/mlab.pyc'>, 'busdaycalendar': <type 'numpy.busdaycalendar'>, 'pkgload': <function pkgload at 0x2107050>, 'mpl': <module 'matplotlib' from '/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc'>, 'rc': <function rc at 0x3194668>, 'thetagrids': <function thetagrids at 0x3195f50>, 'results': [0.40249999999999986, 0.3805, 1.05975, 0.6737500000000001, 0.6269999999999998, 0.41200000000000003, 0.9955, 0.38125000000000003, 0.6900000000000002, 0.8010000000000002, 0.6927500000000002, 0.9587500000000002, 1.095, 1.0350000000000001, 0.975, 0.6989999999999998, 0.7677500000000002, 0.48375, 0.6754999999999998, 1.056, 0.9384999999999999, 0.5549999999999999, 0.48974999999999996, 0.7722500000000001, 0.70925], '_104': (510,), '_i114': u'yoda = np.asarray(predicted_probs)\\nyoda.shape', 'ERR_RAISE': 2, '_i61': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('yoda')\", 'testcv': array([False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), 'cool': <function cool at 0x3198578>, 'tri': <function tri at 0x230d7d0>, 'lapack_lite': <module 'numpy.linalg.lapack_lite' from '/usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so'>, 'diag_indices': <function diag_indices at 0x23748c0>, 'window_hanning': <function window_hanning at 0x2c4f578>, 'array_equal': <function array_equal at 0x21dbf50>, 'FormatStrFormatter': <class 'matplotlib.ticker.FormatStrFormatter'>, '_i25': u'target.shape', '_i22': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(target[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'tanh': <ufunc 'tanh'>, 'longest_contiguous_ones': <function longest_contiguous_ones at 0x2c510c8>, 'get_plot_commands': <function get_plot_commands at 0x31960c8>, 'uint32': <type 'numpy.uint32'>, 'array_equiv': <function array_equiv at 0x21dd050>, '_i12': u'trainInput.shape', 'fftn': <function fftn at 0x2409230>, '_i10': u'len(target)', '_i17': u'trainInput[509,54,244]', '_i16': u'trainInput[509,54,243]', '_i15': u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:198] = trainOutput\\nfullInput[:,:,198:] = trainInput', '_i14': u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:197] = trainOutput\\nfullInput[:,:,198:] = trainInput', 'indices': <function indices at 0x21dbaa0>, 'fftpack': <module 'numpy.fft.fftpack' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack.pyc'>, 'loads': <built-in function loads>, '_i18': u'trainInput[509,54,243]', '_ii': u'sheet.shape', 'set_numeric_ops': <built-in function set_numeric_ops>, '_114': (310,), 'pmt': <function pmt at 0x23fbc08>, 'polar': <function polar at 0x3196578>, 'diag_indices_from': <function diag_indices_from at 0x2374938>, 'object0': <type 'numpy.object_'>, 'ishold': <function ishold at 0x3195230>, 'rate': <function rate at 0x23fbf50>, 'FPE_OVERFLOW': 2, 'Circle': <class 'matplotlib.patches.Circle'>, 'index_exp': <numpy.lib.index_tricks.IndexExpression object at 0x236fa50>, 'append': <function append at 0x236da28>, 'logseries': <built-in method logseries of mtrand.RandomState object at 0x7f399f841690>, '_i128': u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=500, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=25, indices=False)', '_i129': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', 'nanargmax': <function nanargmax at 0x236ccf8>, 'hstack': <function hstack at 0x22747d0>, 'typename': <function typename at 0x2301b18>, 'YearLocator': <class 'matplotlib.dates.YearLocator'>, 'diag': <function diag at 0x230d6e0>, 'pyplot': <module 'matplotlib.pyplot' from '/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc'>, 'axes': <function axes at 0x3195320>, 'ERR_WARN': 1, '_i127': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'unravel_index': <built-in function unravel_index>, 'uniform': <built-in method uniform of mtrand.RandomState object at 0x7f399f841690>, 'polyfit': <function polyfit at 0x238ced8>, 'nanmin': <function nanmin at 0x236cb90>, 'memmap': <class 'numpy.core.memmap.memmap'>, 'axvline': <function axvline at 0x31969b0>, '_90': (200,), 'irfftn': <function irfftn at 0x2409500>, 'nan_to_num': <function nan_to_num at 0x23019b0>, 'twinx': <function twinx at 0x3195668>, 'contourf': <function contourf at 0x3196de8>, 'complex64': <type 'numpy.complex64'>, 'deriv': array([[ 0.04,  0.04, -0.02, ...,  0.  ,  0.02, -0.04],\n       [-0.11, -0.04,  0.02, ..., -0.11, -0.04, -0.08],\n       [-0.08,  0.02, -0.02, ..., -0.02, -0.02, -0.06],\n       ..., \n       [ 0.27,  0.02,  0.  , ...,  0.25,  0.15, -0.04],\n       [ 0.  , -0.01,  0.  , ..., -0.05,  0.02,  0.  ],\n       [ 0.31,  0.  , -0.03, ...,  0.04,  0.02,  0.06]]), '_i34': u'target.shape', 'fmax': <ufunc 'fmax'>, 'copysign': <ufunc 'copysign'>, 'matplotlib': <module 'matplotlib' from '/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc'>, 'l2norm': <function l2norm at 0x2c51ed8>, 'FigureCanvasBase': <class 'matplotlib.backend_bases.FigureCanvasBase'>, 'sinh': <ufunc 'sinh'>, 'unicode_': <type 'numpy.unicode_'>, 'rgrids': <function rgrids at 0x3195ed8>, 'legend': <function legend at 0x31980c8>, 'trunc': <ufunc 'trunc'>, 'box': <function box at 0x31958c0>, 'vstack': <function vstack at 0x2274758>, 'finfo': <class 'numpy.core.getlimits.finfo'>, 'ERR_PRINT': 4, 'levypdf': <function levypdf at 0x2c4ff50>, 'IndexDateFormatter': <class 'matplotlib.dates.IndexDateFormatter'>, 'MO': MO, 'asscalar': <function asscalar at 0x2301aa0>, 'LogLocator': <class 'matplotlib.ticker.LogLocator'>, 'binomial': <built-in method binomial of mtrand.RandomState object at 0x7f399f841690>, 'broken_barh': <function broken_barh at 0x3196b90>, 'poisson': <built-in method poisson of mtrand.RandomState object at 0x7f399f841690>, 'HourLocator': <class 'matplotlib.dates.HourLocator'>, 'less_equal': <ufunc 'less_equal'>, 'l1norm': <function l1norm at 0x2c51e60>, 'BUFSIZE': 8192, 'sci': <function sci at 0x31947d0>, 'object_': <type 'numpy.object_'>, 'FR': FR, 'shuffle': <built-in method shuffle of mtrand.RandomState object at 0x7f399f841690>, 'divide': <ufunc 'divide'>, 'csingle': <type 'numpy.complex64'>, 'dtype': <type 'numpy.dtype'>, 'unsignedinteger': <type 'numpy.unsignedinteger'>, '_i110': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'fftshift': <function fftshift at 0x2409668>, 'fastCopyAndTranspose': <built-in function _fastCopyAndTranspose>, 'num2date': <function num2date at 0x307d0c8>, 'silent_list': <class 'matplotlib.cbook.silent_list'>, 'bitwise_and': <ufunc 'bitwise_and'>, 'uintc': <type 'numpy.uint32'>, '_i30': u'lastObserved = trainOutput[:,-1,:]\\nlastObserved.shape', 'byte': <type 'numpy.int8'>, 'select': <function select at 0x236c488>, 'ticklabel_format': <function ticklabel_format at 0x31982a8>, 'deg2rad': <ufunc 'deg2rad'>, 'plot': <function plot at 0x31975f0>, 'nditer': <type 'numpy.nditer'>, 'eye': <function eye at 0x230d668>, 'triu_indices': <function triu_indices at 0x230db90>, 'kron': <function kron at 0x2377140>, 'newbuffer': <built-in function newbuffer>, '_i86': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:200]\\ntest  = X[200:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'pred': array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       ..., \n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]]), 'negative': <ufunc 'negative'>, 'busday_offset': <built-in function busday_offset>, 'mintypecode': <function mintypecode at 0x2301410>, 'standard_gamma': <built-in method standard_gamma of mtrand.RandomState object at 0x7f399f841690>, 'lstsq': <function lstsq at 0x238cc80>, 'print_function': _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 65536), 'header': 'To:lanemcintosh@gmail.com\\nFrom: mcintoshlane@gmail.com\\nSubject:Kaggle iPython Notebook \\n', '_26': (200, 198), '_27': (510, 55, 244), '_24': 55, '_25': (200, 198), 'MAXDIMS': 32, 'clabel': <function clabel at 0x3196cf8>, 'setxor1d': <function setxor1d at 0x2369f50>, '_21': (510, 55, 442), 'rk4': <function rk4 at 0x2c51578>, 'fftfreq': <function fftfreq at 0x2409758>, 'ifft2': <function ifft2 at 0x2409398>, 'longdouble': <type 'numpy.float128'>, 'uint0': <type 'numpy.uint64'>, 'zeros_like': <function zeros_like at 0x21c2398>, '_i62': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',norm=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_i63': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',normed=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_i60': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nyaxis('yoda')\", 'ylabel': <function ylabel at 0x3195aa0>, 'int_asbuffer': <built-in function int_asbuffer>, 'uint8': <type 'numpy.uint8'>, '_i64': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_i65': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", 'chararray': <class 'numpy.core.defchararray.chararray'>, 'train': array([[  0.04    ,   1.5     ,   2.      , ...,   0.439681,   0.074476,\n          0.142166],\n       [ -0.11    ,   0.789473,  19.      , ...,   0.767666,   0.147196,\n          0.272029],\n       [ -0.08    ,   0.5     ,  12.      , ...,   0.216333,   0.062503,\n          0.062272],\n       ..., \n       [ -0.17    ,   0.222222,   9.      , ...,   0.405073,   0.133066,\n          0.126095],\n       [  0.15    ,  -0.2     ,  10.      , ...,   0.32209 ,   0.127541,\n          0.195192],\n       [  0.11    ,   0.      ,  10.      , ...,   0.232735,   0.130486,\n          0.113186]]), 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'linspace': <function linspace at 0x2270d70>, '_i32': u'normTarget   = target - lastObserved[:target.shape[0],:]', 'hold': <function hold at 0x31951b8>, 'mirr': <function mirr at 0x23fe140>, 'uint64': <type 'numpy.uint64'>, 'sample': <built-in method random_sample of mtrand.RandomState object at 0x7f399f841690>, 'ma': <module 'numpy.ma' from '/usr/local/lib/python2.7/dist-packages/numpy/ma/__init__.pyc'>, 'err': <module 'meanAbsoluteError' from 'meanAbsoluteError.pyc'>, 'f': <built-in method f of mtrand.RandomState object at 0x7f399f841690>, 'hist2d': <function hist2d at 0x31972a8>, 'Text': <class 'matplotlib.text.Text'>, 'isneginf': <function isneginf at 0x2301578>, 'true_divide': <ufunc 'true_divide'>, 'det': <function det at 0x238cc08>, 'SU': SU, 'DateLocator': <class 'matplotlib.dates.DateLocator'>, '_i122': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', '_i8': u'len(trainOutput)', 'thisColumn': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.07301677,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.07301677,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.07301677,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.07301677,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.07301677,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.07301677,  0.07301677,  0.        ,  0.        ]), 'SA': SA, 'rc_context': <function rc_context at 0x31946e0>, 'scatter': <function scatter at 0x3197848>, 'Out': {8: 510, 10: 200, 12: (510, 55, 244), 13: (510, 55, 198), 16: 0.32388299999999998, 18: 0.32388299999999998, 19: 0.32388299999999998, 21: (510, 55, 442), 23: (510, 55, 198), 24: 55, 25: (200, 198), 26: (200, 198), 27: (510, 55, 244), 30: (510, 198), 31: (200, 198), 33: (200, 198), 34: (200, 198), 35: [<matplotlib.lines.Line2D object at 0x3c0f110>], 36: [<matplotlib.lines.Line2D object at 0x3df1610>], 37: (array([   3.,   11.,   42.,  112.,   26.,    4.,    0.,    0.,    0.,    2.]), array([-2.12 , -1.478, -0.836, -0.194,  0.448,  1.09 ,  1.732,  2.374,\n        3.016,  3.658,  4.3  ]), <a list of 10 Patch objects>), 38: ([array([   0.,    0.,    0.,   11.,  179.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  189.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  189.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  194.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  188.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  191.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   12.,  181.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  193.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   23.,  158.,   11.,    2.,    0.,    2.,    0.]), array([   2.,    0.,    2.,   16.,  159.,   19.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  196.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  187.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  192.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  194.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  184.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  192.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    3.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   1.,    0.,    2.,   28.,  148.,   17.,    3.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  186.,    9.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  184.,    2.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  177.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,    7.,  186.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   20.,  168.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    2.,    0.,   15.,  167.,   16.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    0.,   14.,  167.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,   16.,  165.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   14.,  182.,    2.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    3.,   26.,  153.,   16.,    0.,    0.,    2.,    0.]), array([   3.,    1.,    7.,   46.,  102.,   26.,    8.,    3.,    2.,    2.]), array([   0.,    2.,    0.,   12.,  176.,   10.,    0.,    0.,    0.,    0.]), array([   2.,    0.,    1.,   20.,  155.,   18.,    4.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  181.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  184.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  189.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  182.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   11.,  182.,    6.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  184.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   22.,  166.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  195.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    3.,  193.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  190.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  196.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   29.,  140.,   21.,    4.,    2.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  190.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    3.,   31.,  144.,   17.,    3.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  193.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  188.,    4.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.])], array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 198 Lists of Patches objects>), 44: (200, 198), 52: (array([  8.00000000e+00,   9.00000000e+00,   3.80000000e+01,\n         8.42000000e+02,   3.81220000e+04,   5.27000000e+02,\n         3.80000000e+01,   8.00000000e+00,   6.00000000e+00,\n         2.00000000e+00]), array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 10 Patch objects>), 53: (array([  2.00000000e+00,   0.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         1.00000000e+00,   2.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         2.00000000e+00,   7.00000000e+00,   3.00000000e+00,\n         4.00000000e+00,   7.00000000e+00,   8.00000000e+00,\n         2.20000000e+01,   2.00000000e+01,   1.30000000e+01,\n         2.40000000e+01,   5.30000000e+01,   5.30000000e+01,\n         8.10000000e+01,   1.17000000e+02,   1.68000000e+02,\n         2.91000000e+02,   5.90000000e+02,   1.25600000e+03,\n         2.75800000e+03,   8.53900000e+03,   1.52450000e+04,\n         6.19300000e+03,   1.99500000e+03,   9.18000000e+02,\n         4.14000000e+02,   2.14000000e+02,   1.21000000e+02,\n         1.11000000e+02,   7.50000000e+01,   6.70000000e+01,\n         3.50000000e+01,   3.70000000e+01,   3.00000000e+01,\n         2.50000000e+01,   2.00000000e+01,   6.00000000e+00,\n         7.00000000e+00,   6.00000000e+00,   9.00000000e+00,\n         4.00000000e+00,   3.00000000e+00,   1.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n         3.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         3.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         1.00000000e+00]), array([-15.55  , -15.1994, -14.8488, -14.4982, -14.1476, -13.797 ,\n       -13.4464, -13.0958, -12.7452, -12.3946, -12.044 , -11.6934,\n       -11.3428, -10.9922, -10.6416, -10.291 ,  -9.9404,  -9.5898,\n        -9.2392,  -8.8886,  -8.538 ,  -8.1874,  -7.8368,  -7.4862,\n        -7.1356,  -6.785 ,  -6.4344,  -6.0838,  -5.7332,  -5.3826,\n        -5.032 ,  -4.6814,  -4.3308,  -3.9802,  -3.6296,  -3.279 ,\n        -2.9284,  -2.5778,  -2.2272,  -1.8766,  -1.526 ,  -1.1754,\n        -0.8248,  -0.4742,  -0.1236,   0.227 ,   0.5776,   0.9282,\n         1.2788,   1.6294,   1.98  ,   2.3306,   2.6812,   3.0318,\n         3.3824,   3.733 ,   4.0836,   4.4342,   4.7848,   5.1354,\n         5.486 ,   5.8366,   6.1872,   6.5378,   6.8884,   7.239 ,\n         7.5896,   7.9402,   8.2908,   8.6414,   8.992 ,   9.3426,\n         9.6932,  10.0438,  10.3944,  10.745 ,  11.0956,  11.4462,\n        11.7968,  12.1474,  12.498 ,  12.8486,  13.1992,  13.5498,\n        13.9004,  14.251 ,  14.6016,  14.9522,  15.3028,  15.6534,\n        16.004 ,  16.3546,  16.7052,  17.0558,  17.4064,  17.757 ,\n        18.1076,  18.4582,  18.8088,  19.1594,  19.51  ]), <a list of 100 Patch objects>), 61: <matplotlib.text.Text object at 0x8c45410>, 63: <matplotlib.text.Text object at 0x8d13e90>, 64: <matplotlib.text.Text object at 0x9b88ad0>, 65: <matplotlib.text.Text object at 0x92e02d0>, 66: (510, 55, 198), 67: (510, 198), 68: (200, 198), 70: 200, 71: sklearn.cross_validation.KFold(n=200, n_folds=63), 74: array([False, False, False, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), 75: (200,), 76: (200,), 77: array([[[ 0.      ,  0.      ,  0.      , ...,  0.160672,  0.054283,\n          0.060093],\n        [ 1.61    ,  0.12    ,  0.12    , ...,  0.246306,  0.448241,\n          0.377197],\n        [ 1.12    ,  0.31    ,  0.12    , ...,  0.281271,  0.484713,\n          0.431599],\n        ..., \n        [ 0.9     ,  0.19    ,  0.07    , ...,  0.119027,  0.084617,\n          0.074685],\n        [ 0.87    ,  0.22    ,  0.08    , ...,  0.122028,  0.058538,\n          0.080691],\n        [ 0.83    ,  0.25    ,  0.08    , ...,  0.125018,  0.043205,\n          0.088569]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.405808,  0.188892,\n          0.209284],\n        [ 0.95    , -0.18    ,  0.15    , ...,  0.42738 ,  0.348119,\n          0.34322 ],\n        [ 1.04    , -0.18    ,  0.15    , ...,  0.463135,  0.439758,\n          0.449271],\n        ..., \n        [ 0.87    , -0.01    ,  0.1     , ...,  0.447247,  0.132313,\n          0.208433],\n        [ 0.83    ,  0.      ,  0.05    , ...,  0.445714,  0.153232,\n          0.138243],\n        [ 0.97    , -0.05    ,  0.05    , ...,  0.445714,  0.155649,\n          0.138243]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.934708,  0.084538,\n          0.154596],\n        [ 2.75    ,  0.25    ,  0.      , ...,  0.859673,  0.675959,\n          0.553122],\n        [ 2.22    ,  0.24    ,  0.      , ...,  0.800801,  0.754047,\n          0.652951],\n        ..., \n        [ 6.09    , -0.13    ,  0.      , ...,  0.717239,  0.111535,\n          0.55109 ],\n        [ 6.22    , -0.13    ,  0.      , ...,  0.712795,  0.116218,\n          0.388987],\n        [ 5.75    , -0.17    ,  0.      , ...,  0.715292,  0.152665,\n          0.252609]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.199729,  0.051769,\n          0.117898],\n        [-3.29    ,  0.04    ,  0.24    , ...,  0.349317,  0.77501 ,\n          0.659621],\n        [-3.53    ,  0.06    ,  0.37    , ...,  0.460716,  1.013778,\n          0.894228],\n        ..., \n        [-2.21    ,  1.33    ,  0.5     , ...,  0.221407,  0.051251,\n          0.160312],\n        [-2.25    ,  1.27    ,  0.54    , ...,  0.203557,  0.054283,\n          0.14087 ],\n        [-2.42    ,  1.27    ,  0.53    , ...,  0.185629,  0.059889,\n          0.054874]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.52827 ,  0.128219,\n          0.104881],\n        [ 0.17    , -0.06    ,  0.      , ...,  0.520413,  0.180665,\n          0.150702],\n        [ 0.59    , -0.12    , -0.06    , ...,  0.520859,  0.288167,\n          0.243676],\n        ..., \n        [ 0.97    , -0.24    , -0.08    , ...,  0.296868,  0.023381,\n          0.264344],\n        [ 0.82    , -0.24    , -0.08    , ...,  0.297405,  0.037417,\n          0.211529],\n        [ 0.97    , -0.18    , -0.04    , ...,  0.298542,  0.037238,\n          0.132077]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.31634 ,  0.082624,\n          0.108628],\n        [-0.71    ,  0.26    ,  0.74    , ...,  0.307045,  0.20775 ,\n          0.205129],\n        [-1.06    ,  0.19    ,  0.74    , ...,  0.31471 ,  0.277897,\n          0.274672],\n        ..., \n        [-1.04    , -0.08    ,  0.12    , ...,  0.184709,  0.06532 ,  0.16    ],\n        [-0.95    , -0.19    ,  0.12    , ...,  0.178122,  0.028284,\n          0.152315],\n        [-0.84    , -0.18    ,  0.12    , ...,  0.173413,  0.054283,\n          0.123063]]]), 78: (510, 55, 442), 81: (510,), 83: (201,), 84: (309,), 85: (201,), 87: (200,), 88: (310,), 89: (200,), 90: (200,), 92: (200,), 93: (310,), 95: (510, 1), 102: 310, 104: (510,), 108: <matplotlib.text.Text object at 0x918f1d0>, 109: 198, 111: <matplotlib.text.Text object at 0x9894b90>, 113: <type 'list'>, 114: (310,), 116: -3.8199999999999998}, 'Normalize': <class 'matplotlib.colors.Normalize'>, 'spy': <function spy at 0x3196758>, 'train_transformed': array([[  4.00000000e-02,   2.05333333e+02,   3.26666670e+01, ...,\n          6.56650000e-01,   7.30560000e-01,   7.44760000e-02],\n       [ -1.10000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          3.24497000e-01,   2.54928000e-01,   1.47196000e-01],\n       [ -8.00000000e-02,   0.00000000e+00,   0.00000000e+00, ...,\n          9.13311000e-01,   9.19309000e-01,   6.25030000e-02],\n       ..., \n       [ -1.70000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          9.63428000e-01,   9.62613000e-01,   1.33066000e-01],\n       [  1.50000000e-01,   2.19333333e+02,   4.73333330e+01, ...,\n          9.05099000e-01,   6.36617000e-01,   1.27541000e-01],\n       [  1.10000000e-01,   6.95000000e+01,   7.55000000e+01, ...,\n          3.40341000e-01,   2.59492000e-01,   1.30486000e-01]]), 'MinuteLocator': <class 'matplotlib.dates.MinuteLocator'>, 'quiver': <function quiver at 0x3197758>, 'figure': <function figure at 0x3194938>, 'subplot2grid': <function subplot2grid at 0x31955f0>, 'get_sparse_matrix': <function get_sparse_matrix at 0x2c516e0>, 'add_newdoc': <function add_newdoc at 0x236d848>, 'seterrcall': <function seterrcall at 0x21dd2a8>, 'autumn': <function autumn at 0x31966e0>, 'logical_or': <ufunc 'logical_or'>, 'minimum': <ufunc 'minimum'>, 'WRAP': 1, 'tan': <ufunc 'tan'>, 'rms_flat': <function rms_flat at 0x2c51de8>, 'absolute': <ufunc 'absolute'>, 'gca': <function gca at 0x3195488>, 'winter': <function winter at 0x3198aa0>, 'gcf': <function gcf at 0x31949b0>, 'gci': <function gci at 0x31945f0>, 'csd': <function csd at 0x3196e60>, 'RRuleLocator': <class 'matplotlib.dates.RRuleLocator'>, 'get_array_wrap': <function get_array_wrap at 0x23770c8>, 'polymul': <function polymul at 0x238d140>, 'hot': <function hot at 0x3198758>, 'minorticks_off': <function minorticks_off at 0x3195e60>, '_81': (510,), 'get_ipython': <bound method ZMQInteractiveShell.get_ipython of <IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object at 0x2720f90>>, 'get_figlabels': <function get_figlabels at 0x3194aa0>, 'tile': <function tile at 0x23771b8>, 'array_str': <function array_str at 0x21db9b0>, 'eigvalsh': <function eigvalsh at 0x238c7d0>, 'pinv': <function pinv at 0x238cb18>, 'stock': 0, 'longlong': <type 'numpy.int64'>, 'pink': <function pink at 0x31988c0>, 'product': <function product at 0x21da1b8>, 'int16': <type 'numpy.int16'>, 's_': <numpy.lib.index_tricks.IndexExpression object at 0x236fad0>, 'mat': <function asmatrix at 0x236dc80>, 'fv': <function fv at 0x23fbb90>, 'summer': <function summer at 0x3198a28>, '_i123': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random\\nimport smtplib\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', 'yticks': <function yticks at 0x3195d70>, 'docstring': <module 'matplotlib.docstring' from '/usr/local/lib/python2.7/dist-packages/matplotlib/docstring.pyc'>, '_i36': u'plot(normTarget[:,197])', 'asanyarray': <function asanyarray at 0x21c25f0>, 'uint': <type 'numpy.uint64'>, 'negative_binomial': <built-in method negative_binomial of mtrand.RandomState object at 0x7f399f841690>, 'npv': <function npv at 0x23fe0c8>, 'logaddexp': <ufunc 'logaddexp'>, 'flatnonzero': <function flatnonzero at 0x21c28c0>, 'short': <type 'numpy.int16'>, 'correlate': <function correlate at 0x21c29b0>, 'getfigs': <function getfigs at 0x1de1848>, 'fromstring': <built-in function fromstring>, 'pylab_setup': <function pylab_setup at 0x3186cf8>, 'left_shift': <ufunc 'left_shift'>, 'tricontour': <function tricontour at 0x3197c08>, 'subplots': <function subplots at 0x3195578>, 'searchsorted': <function searchsorted at 0x21d1c08>, 'barbs': <function barbs at 0x3197ed8>, 'int64': <type 'numpy.int64'>, 'gamma': <built-in method gamma of mtrand.RandomState object at 0x7f399f841690>, 'may_share_memory': <function may_share_memory at 0x2369500>, '_76': (200,), '__': (310,), 'GridSpec': <class 'matplotlib.gridspec.GridSpec'>, 'help': Type help() for interactive help, or help(object) for help about object., 'xlim': <function xlim at 0x3195b18>, 'copper': <function copper at 0x31985f0>, 'MONTHLY': 1, 'dsplit': <function dsplit at 0x2374f50>, 'intersect1d': <function intersect1d at 0x2369ed8>, 'cosh': <ufunc 'cosh'>, 'window_none': <function window_none at 0x2c4f5f0>, 'can_cast': <built-in function can_cast>, 'performance': [0.73306000000000016], 'ppmt': <function ppmt at 0x23fbde8>, '__package__': None, 'cumsum': <function cumsum at 0x21da410>, 'roots': <function roots at 0x238cd70>, 'Widget': <class 'matplotlib.widgets.Widget'>, 'outer': <function outer at 0x21c2aa0>, 'intc': <type 'numpy.int32'>, 'fix': <function fix at 0x2301488>, 'stineman_interp': <function stineman_interp at 0x2c537d0>, 'busday_count': <built-in function busday_count>, 'cla': <function cla at 0x3197f50>, 'timedelta64': <type 'numpy.timedelta64'>, 'strpdate2num': <class matplotlib.dates.strpdate2num at 0x3025460>, 'Rectangle': <class 'matplotlib.patches.Rectangle'>, 'standard_exponential': <built-in method standard_exponential of mtrand.RandomState object at 0x7f399f841690>, 'subplot_tool': <function subplot_tool at 0x31957d0>, 'choose': <function choose at 0x21d17d0>, '_i': u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', '_i38': u'hist(normTarget)', 'FPE_INVALID': 8, 'recfromcsv': <function recfromcsv at 0x23fb6e0>, 'fill_diagonal': <function fill_diagonal at 0x23742a8>, 'void0': <type 'numpy.void'>, 'get_fignums': <function get_fignums at 0x3194a28>, 'exception_to_str': <function exception_to_str at 0x2994b18>, 'SECONDLY': 6, 'logaddexp2': <ufunc 'logaddexp2'>, 'greater': <ufunc 'greater'>, 'suptitle': <function suptitle at 0x31950c8>, '_109': 198, 'get_backend': <function get_backend at 0x2a00668>, '_i83': u'train.shape', 'matrix_power': <function matrix_power at 0x236dcf8>, 'histogram2d': <function histogram2d at 0x230d9b0>, 'LogFormatter': <class 'matplotlib.ticker.LogFormatter'>, 'polyint': <function polyint at 0x238cde8>, 'nonzero': <function nonzero at 0x21d1ed8>, '_88': (310,), 'rank': <function rank at 0x21da848>, 'quiverkey': <function quiverkey at 0x31977d0>, 'datetime64': <type 'numpy.datetime64'>, '_84': (309,), 'complexfloating': <type 'numpy.complexfloating'>, 'is_numlike': <function is_numlike at 0x29929b0>, '_i50': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],0))', 'ndindex': <class 'numpy.lib.index_tricks.ndindex'>, 'ctypeslib': <module 'numpy.ctypeslib' from '/usr/local/lib/python2.7/dist-packages/numpy/ctypeslib.pyc'>, 'waitforbuttonpress': <function waitforbuttonpress at 0x3194f50>, '_i120': u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'PZERO': 0.0, 'relativedelta': <class 'dateutil.relativedelta.relativedelta'>, 'MonthLocator': <class 'matplotlib.dates.MonthLocator'>, 'asfarray': <function asfarray at 0x23015f0>, 'gmail_user': 'mcintoshlane@gmail.com', 'radians': <ufunc 'radians'>, 'sin': <ufunc 'sin'>, 'fliplr': <function fliplr at 0x230d500>, 'alen': <function alen at 0x21da668>, '_13': (510, 55, 198), 'recarray': <class 'numpy.core.records.recarray'>, 'fmod': <ufunc 'fmod'>, '_10': 200, '_i73': u'for i,j in cv:\\n    print i,j', 'bone': <function bone at 0x3198500>, 'mean': <function mean at 0x21daa28>, 'griddata': <function griddata at 0x2c53668>, 'poly_below': <function poly_below at 0x2c538c0>, 'square': <ufunc 'square'>, 'isvector': <function isvector at 0x2c52320>, 'ogrid': <numpy.lib.index_tricks.nd_grid object at 0x236f950>, 'bytes': <type 'str'>, 'nanargmin': <function nanargmin at 0x236cc08>, 'r_': <numpy.lib.index_tricks.RClass object at 0x236f990>, 'hanning': <function hanning at 0x236d230>, 'trainInput': array([[[ -8.00000000e-01,   5.00000000e+00,   0.00000000e+00, ...,\n           2.99584000e-01,   3.88160000e-02,   8.13090000e-02],\n        [  1.33333300e+00,   3.00000000e+00,   0.00000000e+00, ...,\n           3.14446000e-01,   2.51952000e-01,   2.06263000e-01],\n        [  6.66666000e-01,   3.00000000e+00,   5.00000000e+00, ...,\n           3.57783000e-01,   5.10176000e-01,   4.29069000e-01],\n        ..., \n        [  6.66666000e-01,   3.00000000e+00,   0.00000000e+00, ...,\n           2.69088000e-01,   1.26912000e-01,   1.03441000e-01],\n        [  0.00000000e+00,   2.00000000e+00,   1.00000000e+00, ...,\n           2.62727000e-01,   1.33116000e-01,   1.11704000e-01],\n        [  1.50000000e+00,   2.00000000e+00,   5.00000000e+00, ...,\n           2.59782000e-01,   1.21326000e-01,   1.24544000e-01]],\n\n       [[  2.92682000e-01,   4.10000000e+01,   0.00000000e+00, ...,\n           3.20344000e-01,   7.12740000e-02,   5.78310000e-02],\n        [  3.33333000e-01,   3.00000000e+00,   0.00000000e+00, ...,\n           4.10495000e-01,   6.34182000e-01,   5.21483000e-01],\n        [  2.00000000e+00,   1.00000000e+00,   3.00000000e+00, ...,\n           4.78352000e-01,   7.94850000e-01,   6.90853000e-01],\n        ..., \n        [  0.00000000e+00,   1.10000000e+01,   0.00000000e+00, ...,\n           2.31589000e-01,   6.77250000e-02,   9.07990000e-02],\n        [  3.33333000e-01,   1.50000000e+01,   1.00000000e+00, ...,\n           2.31602000e-01,   7.23880000e-02,   1.00995000e-01],\n        [  7.89473000e-01,   1.90000000e+01,   0.00000000e+00, ...,\n           2.25328000e-01,   4.84420000e-02,   8.36660000e-02]],\n\n       [[  4.41860000e-01,   4.30000000e+01,   0.00000000e+00, ...,\n           1.96550000e-01,   1.50555000e-01,   1.20830000e-01],\n        [  6.66666000e-01,   3.00000000e+00,   5.00000000e+00, ...,\n           1.94066000e-01,   1.53753000e-01,   1.28841000e-01],\n        [  0.00000000e+00,   1.00000000e+00,   5.00000000e+00, ...,\n           1.87594000e-01,   1.53753000e-01,   1.32288000e-01],\n        ..., \n        [ -1.11111000e-01,   9.00000000e+00,   5.00000000e+00, ...,\n           1.83963000e-01,   7.37560000e-02,   8.12400000e-02],\n        [  0.00000000e+00,   6.00000000e+00,   5.00000000e+00, ...,\n           1.77811000e-01,   6.03320000e-02,   6.61650000e-02],\n        [  5.00000000e-01,   1.20000000e+01,   0.00000000e+00, ...,\n           1.74681000e-01,   6.12100000e-02,   6.00000000e-02]],\n\n       ..., \n       [[  4.87500000e-01,   8.00000000e+01,   0.00000000e+00, ...,\n           1.50991000e-01,   7.33940000e-02,   6.70820000e-02],\n        [ -5.00000000e-01,   6.00000000e+00,   0.00000000e+00, ...,\n           1.50545000e-01,   6.69330000e-02,   6.70820000e-02],\n        [  7.77777000e-01,   1.80000000e+01,   0.00000000e+00, ...,\n           1.50910000e-01,   6.88960000e-02,   6.91210000e-02],\n        ..., \n        [  7.30769000e-01,   2.60000000e+01,   0.00000000e+00, ...,\n           1.97203000e-01,   7.31210000e-02,   8.36660000e-02],\n        [  2.85714000e-01,   2.80000000e+01,   5.00000000e+00, ...,\n           1.98655000e-01,   7.48330000e-02,   6.92820000e-02],\n        [  3.23529000e-01,   3.40000000e+01,   0.00000000e+00, ...,\n           1.98691000e-01,   9.95990000e-02,   8.00000000e-02]],\n\n       [[  0.00000000e+00,   2.40000000e+01,   0.00000000e+00, ...,\n           1.50959000e-01,   8.94430000e-02,   9.51020000e-02],\n        [ -2.50000000e-01,   4.00000000e+00,   2.33333300e+00, ...,\n           1.91609000e-01,   2.67133000e-01,   2.41753000e-01],\n        [  0.00000000e+00,   2.00000000e+00,   0.00000000e+00, ...,\n           2.23181000e-01,   3.15383000e-01,   2.98794000e-01],\n        ..., \n        [  1.42857000e-01,   1.40000000e+01,   0.00000000e+00, ...,\n           1.88956000e-01,   6.28230000e-02,   5.56780000e-02],\n        [  6.00000000e-01,   1.00000000e+01,   1.00000000e+00, ...,\n           1.91981000e-01,   6.62320000e-02,   5.81190000e-02],\n        [  2.94117000e-01,   1.70000000e+01,   4.00000000e+00, ...,\n           1.91485000e-01,   6.28230000e-02,   6.00000000e-02]],\n\n       [[  6.00000000e-01,   1.50000000e+01,   0.00000000e+00, ...,\n           1.10484000e+00,   5.42830000e-02,   9.48680000e-02],\n        [  0.00000000e+00,   3.00000000e+00,   3.40000000e+00, ...,\n           1.35640700e+00,   1.78215200e+00,   1.46147600e+00],\n        [  0.00000000e+00,   1.00000000e+00,   3.00000000e+00, ...,\n           1.52380800e+00,   2.13168200e+00,   1.81240200e+00],\n        ..., \n        [ -3.33333000e-01,   3.00000000e+00,   3.40000000e+00, ...,\n           5.75108000e-01,   3.00311000e-01,   3.10644000e-01],\n        [ -7.14285000e-01,   7.00000000e+00,   1.00000000e+00, ...,\n           5.69777000e-01,   2.76743000e-01,   2.84429000e-01],\n        [  1.60000000e+00,   5.00000000e+00,   0.00000000e+00, ...,\n           5.57479000e-01,   2.14942000e-01,   3.23883000e-01]]]), 'connect': <function connect at 0x3194c08>, '_i72': u'for i in cv:\\n    print i', 'str_': <type 'numpy.string_'>, 'margins': <function margins at 0x3198410>, 'allclose': <function allclose at 0x21dbe60>, 'extract': <function extract at 0x236c9b0>, 'isOutput': [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'float16': <type 'numpy.float16'>, '_i13': u'trainOutput.shape', 'ulonglong': <type 'numpy.uint64'>, 'matrix': <class 'numpy.matrixlib.defmatrix.matrix'>, 'probas': array([[ 0.006,  0.002,  0.   , ...,  0.006,  0.   ,  0.   ],\n       [ 0.002,  0.   ,  0.   , ...,  0.008,  0.018,  0.   ],\n       [ 0.002,  0.004,  0.004, ...,  0.002,  0.002,  0.01 ],\n       ..., \n       [ 0.018,  0.   ,  0.006, ...,  0.006,  0.004,  0.006],\n       [ 0.   ,  0.   ,  0.   , ...,  0.002,  0.024,  0.   ],\n       [ 0.004,  0.02 ,  0.004, ...,  0.004,  0.   ,  0.006]]), 'asarray': <function asarray at 0x21c2578>, 'True_': True, 'IndexLocator': <class 'matplotlib.ticker.IndexLocator'>, 'poly1d': <class 'numpy.lib.polynomial.poly1d'>, 'rf': RandomForestClassifier(bootstrap=True, compute_importances=None,\n            criterion='gini', max_depth=None, max_features='auto',\n            min_density=None, min_samples_leaf=1, min_samples_split=2,\n            n_estimators=500, n_jobs=2, oob_score=False, random_state=None,\n            verbose=0), 'void': <type 'numpy.void'>, '_i28': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', 'promote_types': <built-in function promote_types>, '_i26': u'target.shape', 'rec': <module 'numpy.core.records' from '/usr/local/lib/python2.7/dist-packages/numpy/core/records.pyc'>, '_i24': u'len(trainOutput[0])', 'arange': <built-in function arange>, 'datetime_as_string': <built-in function datetime_as_string>, 'plotting': <function plotting at 0x3196050>, 'math': <module 'math' (built-in)>, '_i21': u'train.shape', 'get_cmap': <function get_cmap at 0x2b80ed8>, 'log2': <ufunc 'log2'>, 'specgram': <function specgram at 0x31979b0>, 'date2num': <function date2num at 0x307bed8>, '__builtins__': {'bytearray': <type 'bytearray'>, 'IndexError': <type 'exceptions.IndexError'>, 'all': <built-in function all>, 'help': Type help() for interactive help, or help(object) for help about object., 'vars': <built-in function vars>, 'SyntaxError': <type 'exceptions.SyntaxError'>, '__IPYTHON__active': 'Deprecated, check for __IPYTHON__', 'unicode': <type 'unicode'>, 'UnicodeDecodeError': <type 'exceptions.UnicodeDecodeError'>, 'memoryview': <type 'memoryview'>, 'isinstance': <built-in function isinstance>, 'copyright': Copyright (c) 2001-2012 Python Software Foundation.\nAll Rights Reserved.\n\nCopyright (c) 2000 BeOpen.com.\nAll Rights Reserved.\n\nCopyright (c) 1995-2001 Corporation for National Research Initiatives.\nAll Rights Reserved.\n\nCopyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\nAll Rights Reserved., 'NameError': <type 'exceptions.NameError'>, 'BytesWarning': <type 'exceptions.BytesWarning'>, 'dict': <type 'dict'>, 'input': <function <lambda> at 0x5cf2398>, 'oct': <built-in function oct>, 'bin': <built-in function bin>, 'SystemExit': <type 'exceptions.SystemExit'>, 'StandardError': <type 'exceptions.StandardError'>, 'format': <built-in function format>, 'repr': <built-in function repr>, 'sorted': <built-in function sorted>, 'False': False, 'RuntimeWarning': <type 'exceptions.RuntimeWarning'>, 'list': <type 'list'>, 'iter': <built-in function iter>, 'reload': <built-in function reload>, 'Warning': <type 'exceptions.Warning'>, '__package__': None, 'round': <built-in function round>, 'dir': <built-in function dir>, 'cmp': <built-in function cmp>, 'set': <type 'set'>, 'bytes': <type 'str'>, 'reduce': <built-in function reduce>, 'intern': <built-in function intern>, 'issubclass': <built-in function issubclass>, 'Ellipsis': Ellipsis, 'EOFError': <type 'exceptions.EOFError'>, 'locals': <built-in function locals>, 'BufferError': <type 'exceptions.BufferError'>, 'slice': <type 'slice'>, 'FloatingPointError': <type 'exceptions.FloatingPointError'>, 'sum': <built-in function sum>, 'getattr': <built-in function getattr>, 'abs': <built-in function abs>, 'print': <built-in function print>, 'True': True, 'FutureWarning': <type 'exceptions.FutureWarning'>, 'ImportWarning': <type 'exceptions.ImportWarning'>, 'None': None, 'hash': <built-in function hash>, 'ReferenceError': <type 'exceptions.ReferenceError'>, 'len': <built-in function len>, 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n    for supporting Python development.  See www.python.org for more information., 'frozenset': <type 'frozenset'>, '__name__': '__builtin__', 'ord': <built-in function ord>, 'super': <type 'super'>, 'TypeError': <type 'exceptions.TypeError'>, 'license': Type license() to see the full license text, 'KeyboardInterrupt': <type 'exceptions.KeyboardInterrupt'>, 'UserWarning': <type 'exceptions.UserWarning'>, 'filter': <built-in function filter>, 'range': <built-in function range>, 'staticmethod': <type 'staticmethod'>, 'SystemError': <type 'exceptions.SystemError'>, 'BaseException': <type 'exceptions.BaseException'>, 'pow': <built-in function pow>, 'RuntimeError': <type 'exceptions.RuntimeError'>, 'float': <type 'float'>, 'MemoryError': <type 'exceptions.MemoryError'>, 'StopIteration': <type 'exceptions.StopIteration'>, 'globals': <built-in function globals>, 'divmod': <built-in function divmod>, 'enumerate': <type 'enumerate'>, 'apply': <built-in function apply>, 'LookupError': <type 'exceptions.LookupError'>, 'open': <built-in function open>, 'basestring': <type 'basestring'>, 'UnicodeError': <type 'exceptions.UnicodeError'>, 'zip': <built-in function zip>, 'hex': <built-in function hex>, 'long': <type 'long'>, 'next': <built-in function next>, 'ImportError': <type 'exceptions.ImportError'>, 'chr': <built-in function chr>, 'xrange': <type 'xrange'>, 'type': <type 'type'>, '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\", 'Exception': <type 'exceptions.Exception'>, '__IPYTHON__': True, 'tuple': <type 'tuple'>, 'UnicodeTranslateError': <type 'exceptions.UnicodeTranslateError'>, 'reversed': <type 'reversed'>, 'UnicodeEncodeError': <type 'exceptions.UnicodeEncodeError'>, 'IOError': <type 'exceptions.IOError'>, 'hasattr': <built-in function hasattr>, 'delattr': <built-in function delattr>, 'setattr': <built-in function setattr>, 'raw_input': <function <lambda> at 0x7f39504c2578>, 'SyntaxWarning': <type 'exceptions.SyntaxWarning'>, 'compile': <built-in function compile>, 'ArithmeticError': <type 'exceptions.ArithmeticError'>, 'str': <type 'str'>, 'property': <type 'property'>, 'dreload': <function reload at 0x2725c08>, 'GeneratorExit': <type 'exceptions.GeneratorExit'>, 'int': <type 'int'>, '__import__': <built-in function __import__>, 'KeyError': <type 'exceptions.KeyError'>, 'coerce': <built-in function coerce>, 'PendingDeprecationWarning': <type 'exceptions.PendingDeprecationWarning'>, 'file': <type 'file'>, 'EnvironmentError': <type 'exceptions.EnvironmentError'>, 'unichr': <built-in function unichr>, 'id': <built-in function id>, 'OSError': <type 'exceptions.OSError'>, 'DeprecationWarning': <type 'exceptions.DeprecationWarning'>, 'min': <built-in function min>, 'UnicodeWarning': <type 'exceptions.UnicodeWarning'>, 'execfile': <built-in function execfile>, 'any': <built-in function any>, 'complex': <type 'complex'>, 'bool': <type 'bool'>, 'get_ipython': <bound method ZMQInteractiveShell.get_ipython of <IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object at 0x2720f90>>, 'ValueError': <type 'exceptions.ValueError'>, 'NotImplemented': NotImplemented, 'map': <built-in function map>, 'buffer': <type 'buffer'>, 'max': <built-in function max>, 'object': <type 'object'>, 'TabError': <type 'exceptions.TabError'>, 'callable': <built-in function callable>, 'ZeroDivisionError': <type 'exceptions.ZeroDivisionError'>, 'eval': <built-in function eval>, '__debug__': True, 'IndentationError': <type 'exceptions.IndentationError'>, 'AssertionError': <type 'exceptions.AssertionError'>, 'classmethod': <type 'classmethod'>, 'UnboundLocalError': <type 'exceptions.UnboundLocalError'>, 'NotImplementedError': <type 'exceptions.NotImplementedError'>, 'AttributeError': <type 'exceptions.AttributeError'>, 'OverflowError': <type 'exceptions.OverflowError'>}, 'rec_join': <function rec_join at 0x2c526e0>, 'acorr': <function acorr at 0x31967d0>, 'cumproduct': <function cumproduct at 0x21da488>, 'diagonal': <function diagonal at 0x21d1d70>, 'atleast_1d': <function atleast_1d at 0x22741b8>, '_i116': u'pred[0]', '_i115': u'yoda = np.asarray(predicted_probs)\\nluke = np.zeros((310,198))\\nluke[:,0] = yoda', 'meshgrid': <function meshgrid at 0x236d8c0>, 'eventplot': <function eventplot at 0x3196f50>, '_i112': u'numStocks', '_i111': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", 'column_stack': <function column_stack at 0x2374c08>, 'put': <function put at 0x21d18c0>, '___': <type 'list'>, 'smtpserver': <smtplib.SMTP instance at 0x7f393945a7a0>, 'remainder': <ufunc 'remainder'>, '_i19': u'fullInput[509,54,244+197]', 'get_scale_docs': <function get_scale_docs at 0x2fc7140>, '_i118': u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'row_stack': <function vstack at 0x2274758>, 'expm1': <ufunc 'expm1'>, 'ion': <function ion at 0x3194500>, 'insert': <function insert at 0x236d9b0>, 'semilogx': <function semilogx at 0x31978c0>, 'semilogy': <function semilogy at 0x3197938>, 'ndfromtxt': <function ndfromtxt at 0x23fb578>, 'sometrue': <function sometrue at 0x21da230>, 'place': <function place at 0x236ca28>, 'DataSource': <class 'numpy.lib._datasource.DataSource'>, 'newaxis': None, 'arccos': <ufunc 'arccos'>, 'epoch2num': <function epoch2num at 0x307fa28>, '_i59': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", 'signedinteger': <type 'numpy.signedinteger'>, '_i119': u'import smtplib', 'ndim': <function ndim at 0x21da7d0>, 'rand': <built-in method rand of mtrand.RandomState object at 0x7f399f841690>, 'irfft': <function irfft at 0x23fef50>, 'ranf': <built-in method random_sample of mtrand.RandomState object at 0x7f399f841690>, 'subplots_adjust': <function subplots_adjust at 0x3195758>, 'rint': <ufunc 'rint'>, 'fill_between': <function fill_between at 0x31970c8>, 'Axes': <class 'matplotlib.axes.Axes'>, 'MaxNLocator': <class 'matplotlib.ticker.MaxNLocator'>, 'arctan2': <ufunc 'arctan2'>, 'little_endian': True, 'ldexp': <ufunc 'ldexp'>, 'lognormal': <built-in method lognormal of mtrand.RandomState object at 0x7f399f841690>, 'lookfor': <function lookfor at 0x23697d0>, 'hfft': <function hfft at 0x2409050>, 'array': <built-in function array>, 'common_type': <function common_type at 0x2301b90>, 'size': <function size at 0x21da8c0>, 'logical_xor': <ufunc 'logical_xor'>, '_i51': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))', 'geterrcall': <function geterrcall at 0x21dd320>, 'sheet': [['fileId', 'O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8', 'O9', 'O10', 'O11', 'O12', 'O13', 'O14', 'O15', 'O16', 'O17', 'O18', 'O19', 'O20', 'O21', 'O22', 'O23', 'O24', 'O25', 'O26', 'O27', 'O28', 'O29', 'O30', 'O31', 'O32', 'O33', 'O34', 'O35', 'O36', 'O37', 'O38', 'O39', 'O40', 'O41', 'O42', 'O43', 'O44', 'O45', 'O46', 'O47', 'O48', 'O49', 'O50', 'O51', 'O52', 'O53', 'O54', 'O55', 'O56', 'O57', 'O58', 'O59', 'O60', 'O61', 'O62', 'O63', 'O64', 'O65', 'O66', 'O67', 'O68', 'O69', 'O70', 'O71', 'O72', 'O73', 'O74', 'O75', 'O76', 'O77', 'O78', 'O79', 'O80', 'O81', 'O82', 'O83', 'O84', 'O85', 'O86', 'O87', 'O88', 'O89', 'O90', 'O91', 'O92', 'O93', 'O94', 'O95', 'O96', 'O97', 'O98', 'O99', 'O100', 'O101', 'O102', 'O103', 'O104', 'O105', 'O106', 'O107', 'O108', 'O109', 'O110', 'O111', 'O112', 'O113', 'O114', 'O115', 'O116', 'O117', 'O118', 'O119', 'O120', 'O121', 'O122', 'O123', 'O124', 'O125', 'O126', 'O127', 'O128', 'O129', 'O130', 'O131', 'O132', 'O133', 'O134', 'O135', 'O136', 'O137', 'O138', 'O139', 'O140', 'O141', 'O142', 'O143', 'O144', 'O145', 'O146', 'O147', 'O148', 'O149', 'O150', 'O151', 'O152', 'O153', 'O154', 'O155', 'O156', 'O157', 'O158', 'O159', 'O160', 'O161', 'O162', 'O163', 'O164', 'O165', 'O166', 'O167', 'O168', 'O169', 'O170', 'O171', 'O172', 'O173', 'O174', 'O175', 'O176', 'O177', 'O178', 'O179', 'O180', 'O181', 'O182', 'O183', 'O184', 'O185', 'O186', 'O187', 'O188', 'O189', 'O190', 'O191', 'O192', 'O193', 'O194', 'O195', 'O196', 'O197', 'O198'], ['201', -3.82, -0.88, 0.54, 0.08, -1.65, -2.8, -1.74, -5.108279403464041, -4.58, -5.23, 1.78, -3.49, -1.71, -0.32, 0.35428571428571426, -5.32, -1.46, -3.82, -2.64, -4.65, -6.76, -2.19, -0.9256947683993239, -2.17, -4.67, -2.91, -6.9, -5.18, -3.43, -2.06, -1.41, -6.98, -3.19, -5.5, -4.35, -6.32, -8.4, -3.9, -2.75, -3.88, -4.834514634175348, -8.81, -1.81, 1.84, 3.29, 3.98, -1.89, 2.1, -0.34, 0.88, -1.2, -3.39, 1.35, 2.6471428571428572, 1.37, -3.15, -4.75, -4.42, -5.05, -3.59, 1.42, 2.1, -3.67, 0.25, -2.14, -0.95, -2.99, -5.14, -0.48, 0.71, -0.46, -5.02, -4.93, 0.67, -5.02, -1.15, -3.51, -2.33, -4.35, -6.47, -1.88, -0.7, -1.86, -6.76, -11.6, 11.63, -5.57, -5.65, -1.81, -4.15, -2.98, -4.98, -7.09, -2.53, -1.36, -2.51, -1.3273809523809526, 0.09, 4.07, 1.58, 2.83, 0.71, -1.4673734626473065, 3.31, 4.54, 3.33, -1.34, 0.0, -5.22, -3.09, -3.15, -3.04, -3.83, -2.39, -1.19, -3.23, -5.38, -0.73, 0.45, -0.72, -3.03, -1.47, 1.22, -0.86, -3.06, 1.69, 2.91, 1.71, -4.7, -4.57, -0.18, -3.76, -2.65, -1.5696768707482993, -1.01, 5.73, -5.73, -2.89, -2.1, -7.4, 1.2, 6.14, 3.12, -1.91, -2.13, -9.34, 9.31, 9.23, -3.1, 8.58, -6.09, -3.55, 1.78, -11.41, 25.62, 7.66, 11.19, -1.1, -2.67, -2.06, -4.23, 0.47, 1.67, 0.49, -9.21, -0.61, -2.21, 2.58, 3.81, 2.6, 1.64, 4.91, 6.16, 4.93, -4.6, -5.86, -3.12, 1.2, 0.02, -3.01, -3.17, -5.0, 12.86, -4.81, -12.61, -4.07, -3.55, -4.181362551799029, -1.16, -3.5, -2.83, -2.03, -1.53, -2.5, -3.14, -6.31, -4.71, -3.53], ['202', 7.014285714285714, -1.9, -0.6387782843795413, 0.5821428571428573, -0.08, -1.74, -0.8458847420401708, -1.17, -1.91, -0.5, 3.17, -0.07, 1.07, 1.35, 2.39, -2.31, 3.2, 0.84, 0.74, 1.0, -1.16, 3.18, 2.54, 1.5721746031746033, -2.59, -2.91, -3.55, -3.14, -2.03, -1.77, -0.75, -5.31, 0.03, -2.26, -2.36, -2.1, -4.2, 0.01, -0.61, -1.55, -2.3, -3.1750638007838266, -0.42, 1.15, 1.42, 2.47, -2.24, 3.27, 0.92, 0.81, 1.07, -1.09, 3.26, 2.62, 1.65, -0.82, -2.27, -0.17, -1.49, -1.55, 0.27, 1.3, -3.35, 2.1, -0.23, -0.33, -0.07, -2.21, 2.09, 1.46, 0.49, -1.68, -1.6042857142857143, 1.03, -3.61, 1.82, -0.5, -0.6, -0.35, -2.47, 1.81, 1.18, 0.22, -3.28, -9.13, 9.15, -2.82, -4.59, 0.79, -1.4957142857142858, -1.62, -1.36, -3.47, 0.77, 0.15, -0.8, -0.74, 1.86, 5.64, 3.23, 3.12, 3.39, 1.18, 5.62, 4.97, 3.97, -0.97, 1.77, -4.3342762881169605, -1.94, -2.32, -2.04, -3.58, -2.28, -2.39, -2.13, -4.22, -0.02, -0.63, -1.57, -3.54, -1.33, -0.11, 0.15, -1.98, 2.32, 1.69, 0.72, -3.13, -2.54, -0.28, -3.84, -1.37, -1.66, -0.96, 3.48, -3.41, -1.73, -3.69, -1.07, 2.85, 4.0, 1.93, 3.911438775510204, -1.52, -6.48, 6.48, 5.95, -1.98, 5.25, -3.93, -4.63, 2.01, -10.86, 10.55, 7.371428571428571, 11.015714285714285, -3.14, -1.22, 0.26, -1.88, 2.43, 1.79, 0.83, -6.0, -1.48, -2.14, 2.16, 1.53, 0.57, 0.67, 4.39, 3.9828571428571427, 2.76, -1.93, -2.26, -3.56, -0.62, -1.56, -1.92, -2.27, -1.18, 5.3, -4.25, -5.42, -1.7, -2.77, -2.96, -0.95, -2.09, -1.44, -0.67, -1.779047619047619, -2.33, -2.04, -5.38, -5.58, -2.6], ['203', 2.06, -0.11, 0.37, -0.13, 0.36, 0.82, 0.97, 1.61, 1.14, 2.93, 1.87, 2.06, 1.96, 1.85, 0.97, 2.26, 2.17, 2.29, 0.5, 0.92, 3.2, 2.66, 2.12, 2.55, 1.05, 1.03, 1.0726583949931126, 0.19, 0.09, -0.02, -0.88, 0.39, 0.3, 0.41, -1.34, -0.92, 1.31, 0.78, 0.25, 0.67, 1.63, 0.020062111801242236, 0.85, -0.1, -0.21, -1.07, 0.19, 0.11, 0.22, -1.53, -1.11, 1.12, 0.59, 0.06, 0.47, 1.0700628463056765, 1.55, 0.95, 1.7, 0.95, -0.11, -0.97, 0.29, 0.2, 0.32, -1.43, -1.02, 1.21, 0.69, 0.16, 0.57, 1.8, 1.06, -0.8592857142857143, 0.4, 0.32, 0.43, -1.32, -0.91, 1.33, 0.8, 0.27, 0.69, 0.74, 2.18, -2.2694285714285716, 1.94, 1.27, 1.18, 1.3, -0.47, -0.05, 2.21, 1.67, 1.14, 1.56, 1.95, 0.66, -0.09, 0.03, -1.72, -1.3, 0.92, 0.4, -0.13, 0.28, 0.58, 0.65, 0.03, 0.55, 0.63, 0.45, 0.74, 0.12, -1.63, -1.22, 1.01, 0.48, -0.05, 0.37, 0.26, 0.63, -1.74, -1.33, 0.89, 0.37, 0.0657142857142857, 0.25, 0.87, 0.68, -0.35, 0.4, 6.0, 0.27, 0.16, -1.08, 0.97, 0.52, 0.35, 1.67, -3.9, -1.17, -0.57, 1.04, 0.3, 1.58, -1.69, -1.74, 0.55, -1.66, 1.17, 1.08, -0.54, 2.23, 1.14, -1.55, -2.29, 3.89, 2.41, 0.42, 2.68, 2.15, 1.61, 2.03, 1.65, 1.99, 2.26, 1.72, 1.3340034013605442, 1.61, -0.26, -0.52, -1.05, -0.63, 1.13, 1.31, 0.26, -0.53, -0.12, 0.53, 0.58, 1.52, 0.6, 0.46, -0.88, 1.06, 0.69, 0.79, 0.42, 0.99, 0.47021978021978017, 0.29, -0.05, 0.5, 0.37, 0.88, 0.93, 0.67], ['204', -0.62, -0.06, 0.09122171562045875, 0.26, -0.37, 0.2984196236737595, 7.22, -0.29, 0.79, -1.71, -1.87, -5.55, -1.43, -1.81, -1.65, -1.51, -2.13, -1.83, -1.94, -0.14, -1.65, -2.61, -2.17, -2.08, -0.22, -0.2, 0.16, -3.76, 0.45, 0.05, 0.22, 0.36, -0.26, 0.04, -0.07, 1.76, 0.22, -0.76, -0.31, -0.22, -0.23, 0.7949361992161734, 4.07, 4.37, 3.96, 4.13, 4.28, 3.63, 3.95, 3.83, 5.73, 4.14, 3.11, 3.59, 3.68, 0.3, 0.04, -0.22, -0.17, -0.29, -0.39, -0.23, -0.08, -0.71, -0.41, -0.52, 1.3, -0.22, -1.21, -0.75, -0.66, -2.12, 0.11, 0.16, 0.31, -0.32, -0.01, -0.13, 1.7, 0.17, -0.82, -0.36, -0.27, 0.21, 1.33, -1.35, -0.06, 0.14, -0.48, -0.18, -0.29, 1.54, 0.01, -0.98, -0.52, -0.3759922724755494, 3.21, -0.2, -0.63, -0.32, -0.43, 1.39, -0.14, -1.12, -0.67, -0.58, 0.15, -0.17, 0.09, 0.21, 0.32, 0.13567351865003197, 0.43, 0.31, 0.19, 2.03, 0.49, -0.5, -0.04, 0.05, 0.89, 0.17307674813036728, -0.11, 1.72, 0.18, -0.8, -0.35, -0.26, 0.31, 0.46, 0.53, 0.33, 9.51, -0.07, 0.06, 0.19, -0.17, -0.02118982899237888, 0.36, 0.9, 3.11, -0.38, -0.26, -0.31, 0.58, 0.66, -0.71, -0.6, 0.21, 0.21, 0.42, -1.98, 0.98, 1.3, 1.71, -0.86, -1.2, -3.15, 0.24, 1.83, 0.3, -0.69, -0.23, -0.15, 0.61, -1.57, -1.51, -2.48, -2.03, -1.94, -0.06, -0.99, -0.53, -0.44, 0.75, -0.04154645354645334, 0.93, 0.46, 0.55, 0.21, 0.23, -0.19, 0.69, 0.16, -0.6, 0.71, -0.36, 0.47, 0.09, 0.26, -0.08, 0.45, 0.67, 0.22, 0.38, 0.96, -0.42, 1.06], ['205', -0.6857142857142857, -0.84, -0.38877828437954126, 0.44, -2.77, -1.44, -1.7058847420401708, -2.17, -3.19, -2.51, 1.03, -0.44, -1.05, -0.66, -0.29, -2.35, -0.95, -2.16, -2.09, 1.65, -4.09, -0.64, -0.29, -1.17, -2.81, -2.37, -3.51, -1.46, -2.07, -1.68, -1.31, -3.35, -1.96, -3.16, -3.09, 0.61, -5.07, -1.66, -1.31, -2.136158276802161, -1.89, -4.975063800783826, -2.08, -0.62, -0.23, 0.15, -1.92, -0.52, -1.73, -1.66, 2.1011904761904763, -3.67, -0.21, 0.15, -0.74, -0.88, -2.12, -2.17, -2.85, -1.47, 0.39, 0.77, -1.31, 0.1, -1.12, -1.05, 2.73, -3.07, 0.41, 0.77, -0.12, -2.29, -1.86, 0.38, -1.7, -0.29, -1.51, -1.43, 2.33, -3.45, 0.02, 0.38, -0.51, -4.18, -6.1, 6.13, -2.23, -2.07, -0.66, -1.87, -1.8, 1.94, -3.81, -0.35, 0.0, -0.89, -1.33, -0.16, 1.43, 0.2, 0.27, 4.1, -1.78, 1.75, 2.11, 1.21, -0.35, -0.13, -1.87, -1.73, -1.72, -1.57, -1.57, -1.22, -1.15, 2.62, -3.17, 0.31, 0.67, -0.23, -1.87, -0.36, 0.07, 3.89, -1.97, 1.55, 1.91, 1.01, -1.95, -1.46, 0.47, -1.49, -2.57, -0.26, -0.84, 3.32, -3.31, -1.7, -0.94, -2.48, 7.87, 3.45, 1.73, -0.06856122448979596, -1.67, -4.94, 5.08, 5.1, -1.7, 5.02, -3.43, -2.87, 1.48, -4.66, 14.77, 3.13, 4.68, -8.0, -0.43, 3.82, -2.04, 1.48, 1.84, 0.93, -5.15, -4.09, -5.64, -2.26, -1.8601904761904762, -2.78, 1.65, 3.59, 3.96, 3.04, -3.31, -3.7, -1.88, 0.36, -0.53, -1.69, -1.66, -1.99, 7.36, -1.88, -7.51, -2.23, -2.3589064979199876, -2.23, -0.89, -1.34, -1.77, -1.55, -1.1552380952380952, -1.28, -1.35, -2.4, -2.61, -1.3], ['206', -1.64, -0.62, -0.07984710169072946, 0.09, -1.39, -0.93, -0.89, -1.8, -2.11, -0.67, 2.95, 0.17, 1.61, 1.89, 1.82, -0.97, 1.46, -0.45, -1.4, 1.72, -1.68, 0.84, 1.46, 0.35, -1.09, -2.04, -3.51, -2.7, -1.29, -1.02, -1.09, -3.81, -1.45, -3.3, -4.22, -1.19, -4.49, -2.05, -1.44, -2.52, -1.13, -2.1, -0.84, 1.44, 1.72, 1.65, -1.14, 1.29, -0.29945408163265297, -1.56, 1.55, -1.85, 0.67, 1.29, 0.18, 0.1, -0.53, -1.4, -1.81, -2.25, 0.27, 0.21, -2.55, -0.15, -2.03, -2.96, 0.1, -3.24, -0.76, -0.15, -1.24, -1.96, -2.51, -0.07, -2.81, -0.43, -2.3, -3.23, -0.17, -3.51, -0.9485714285714286, -0.43, -1.51, -3.24, -5.68, 5.61, -2.45, -2.75, -0.36, -2.23, -3.16, -0.1, -3.44, -0.97, -0.36, -1.45, -2.6, 0.31, 2.45, 0.53, -0.43, 2.72, -0.71, 1.83, 2.46, 1.34, -0.22, 0.37, -2.44, -1.3984018193170984, -1.6, -1.37, -2.09, -1.88, -2.81, 0.26, -3.09, -0.61, 0.0, -1.09, -1.49, -0.22, -0.95, 2.18, -1.24, 1.29, 1.92, 0.8, -1.95, -1.86, 0.17, -1.85, -7.74, -0.12, -0.07, 3.7, -3.68, -1.84, -1.87, -2.75, 4.93, 2.88, 1.48, -0.88, -0.9, -4.43, 4.33, 4.33, -1.46, 5.55, -2.89, -1.51, 0.77, -6.35, 17.7, 4.12, 6.24, -4.85, 0.74, 3.16, -0.29, 2.27, 2.9, 1.77, -4.246832100439243, -2.2156457669314813, -3.34, -0.87, -0.25, -1.35, 1.03, 2.56, 3.19, 2.07, -2.1, -2.91, -1.49, 0.62, -0.48, -1.44, -1.56, -1.73, 11.01, -2.12, -10.56, -1.58, -2.34, -2.1, -1.09, -1.75, -1.7354471401614255, -0.72, -0.77, -0.52, -1.01, -3.55, -3.3, -1.69], ['207', -0.27, 0.42, 0.08, 0.02, -0.25, 0.44, 1.96, 0.46, 0.44, 0.2, 0.19, -0.88, -0.8, -0.12, -1.0, 0.35, -0.27, 0.11, 4.04, 0.56, -0.09266451791264106, -0.08, 0.43, -0.23, 0.57, 0.07, 0.01, -1.07, -0.99, -0.31, -1.19, 0.16, -0.46, -0.09, 3.84, 0.37, -0.32, -0.27, 0.24, -0.42, 1.32, 1.8549361992161735, 1.09, 0.07, 0.77, -0.13, 1.24, 0.61, 0.99, 4.96, 1.45, 0.75, 0.8, 1.32, 0.65, 0.73, 1.18, 1.19, 0.11, 1.02, 0.69, -0.2, 1.17, 0.54, 0.92, 4.88, 1.38, 0.68, 0.73, 1.2527347454133169, 0.58, 0.11, 0.32, -0.89, 0.47, -0.15, 0.22, 4.16, 0.68, -0.02, 0.04, 0.55, -0.05644035827487928, 0.08, 0.01, 0.06, 1.22, 1.37, 0.74, 1.12, 5.09, 1.58, 0.88, 0.93, 1.45, 0.78, -0.83, -0.15, -0.62, -0.25, 3.67, 0.21, -0.49, -0.43, 0.08, -0.58, 0.15, -0.12, 1.31, 0.3215981806829015, 0.2, 0.48567351865003194, 0.5418094764861292, 0.37, 4.32, 0.83, 0.13, 0.19, 0.7, 0.04, 0.35, 0.1, 3.93, 0.46, -0.24, -0.19, 0.33, -0.33, -0.41, -0.21, 0.04, 0.5, -2.57, 0.29, 0.18, -0.78, 0.77, 0.39, 0.14, -0.03, 0.72, -0.5, -0.27, -0.11, 0.18, 0.78, -0.76, -0.74, 0.25, -1.16, 0.49, -0.02, 0.02, 1.45, -0.52, -0.88, -1.47, -0.69, -3.69, -3.34, -4.01, -3.96, -3.46, -4.1, 0.69, -0.36, -0.69, -0.64, -0.13, -0.79, 0.34, 0.05, 0.57, -0.1, 0.46, 0.22, 0.28, 0.52, -0.15, 0.29, 0.32, 0.5825760496238783, 0.22, 1.4901996269574993, -0.21, 0.62, -0.41, -0.23, -0.66, 0.96, 0.22, 0.18, -0.35, 0.88, 0.515957527023814, 0.15, -1.11, 0.33], ['208', -2.38, 0.11, -0.028778284379541254, 0.06, -0.82, 0.54, -0.21, 0.23, 0.57, 0.0, -0.62, 0.16, -0.42, -0.19, 0.41, 1.5, -0.38, -0.15, 2.98, 1.14, 0.14, 0.3, -0.06, -0.81, 0.69, 0.06, 0.63, 0.79, 0.21, 0.43, 1.04, 2.14, 0.24, 0.48, 3.62, 1.78, 0.77, 0.93, 0.56, -0.18, 0.42, 0.68, -0.16, -0.58, -0.36, 0.25, 1.34, -0.54, -0.31, 2.81, 0.98, -0.03, 0.14, -0.23, -0.97, 0.7400628463056765, 1.07, 0.68, 0.57, 0.42, 0.23, 0.83, 1.93, 0.04, 0.27, 3.41, 1.57, 0.56, 0.72, 0.36, -0.39, 0.54, 0.19, 0.6, 1.7, -0.19, 0.05, 3.18, 1.34, 0.33, 0.49, 0.13, -0.61, 0.74, 0.14, -0.17, -0.41, 1.09, -0.79, -0.55, 2.56, 0.73, -0.27, -0.11, -0.47, -1.21, -0.4, -1.48, -1.86, -1.63, 1.45, -0.36, -1.35, -1.19, -1.54, -2.28, 0.11, -1.49, -0.39, 0.38, 0.37, 0.37, 0.38, 0.23, 3.3701587301587304, 1.53, 0.52, 0.68, 0.32, -0.42, -0.19, 0.15, 3.13, 1.29, 0.29, 0.45, 0.08, -0.66, -0.22, -0.33, 0.1, 0.37, -1.2, 0.12, -0.03, -1.02, 0.94, 0.48, 0.21, -0.47, 2.23, -0.74, -0.38, -1.18, 0.33, 1.18, -1.29, -1.28, 0.37, -1.53, 0.76, -0.45, 0.19, 1.11, -3.54, -0.81, -1.18, -2.18, -2.89, -1.78, -2.76, -2.6, -2.95, -3.67, 1.23, -1.13, -0.99, -0.83, -1.19, -1.93, -0.14, 0.16, -0.2, -0.94, 0.6, 0.73, -0.3, -0.36, -1.0277512446849837, 0.4, 0.36, 0.17, -1.09, -0.11980037304250064, 1.17, 0.01, 0.37, 0.06, -0.74, 0.6, 0.23, 0.76, 0.1, 0.43, 0.895957527023814, 0.24, 0.11, 1.17], ['209', -2.49, -0.54, -0.16877828437954126, 0.17, -1.32, -1.11, -1.2, -2.51, -2.01, -1.55, 1.25, -0.12, 0.47, 1.35, 1.77, -0.91, -0.16, -1.06, -1.55, -0.36, -2.22, -0.52, -0.2, -0.71, -2.68, -1.72, -2.77, -1.36, -0.77, 0.1, 0.51, -2.13, -1.39, -2.28, -2.77, -1.59, -3.43, -1.75, -1.43, -1.94, -1.38, -3.0550638007838264, -1.43, 0.59, 1.47, 1.89, -0.78, -0.04, -0.94, -1.43, -0.24, -2.1, -0.4, -0.08, -0.59, -1.57, -2.3142857142857145, -2.26, -1.6, -2.01, 0.88, 1.3, -1.37, -0.63, -1.52, -2.01, -0.82, -2.68, -0.98, -0.66, -1.18, -3.04, -2.86, 0.8402278911564625, -2.22, -1.49, -2.37, -2.86, -1.68, -3.52, -1.84, -1.52, -2.03, -2.66, -3.37, 3.416, -3.27, -2.63, -1.9, -2.78, -3.27, -2.09, -3.92, -2.25, -1.93, -2.44, -2.19, -0.65, 0.75, -0.15, -0.65, 0.55, -1.33, 0.39, 0.71, 0.19, -0.73, -0.71, -1.6, -1.02, -1.02, -0.95, -1.4, -0.9, -1.3998412698412697, -0.2, -2.07, -0.36, -0.04, -0.55, -0.93, -0.5, -0.5, 0.7, -1.18, 0.54, 1.0957142857142856, 0.35, -1.4, -1.63, 0.0, -1.15, -6.82, -0.30774866403437834, -0.22, 1.61, -1.7, -0.86, -0.15, -2.73, 2.39, 2.04, 1.04, -1.25, -0.73, -3.05, 3.0, 2.97, -1.0, 2.49, -2.02, -3.06, 1.55, -4.12, 14.86, 2.84, 4.16, -2.27, 0.0, 1.21, -0.68, 1.05, 1.38, 0.85, -3.03, -1.2, -1.87, -0.16, 0.16, -0.36, 0.68, 1.74, 2.07, 1.54, -1.99, -2.12, -1.04, 0.33, -0.19, -0.99, -1.07, -2.46, 7.4, -1.53, -7.58, -2.2, -1.44, -1.36, -0.52, -1.18, -0.86, -0.66, -0.43, -0.47, -0.85, -3.67, -0.88, -0.75], ['210', 2.72, -0.11, 0.08122171562045875, 0.19, 0.17, -0.31, -0.45, 0.5217205965359587, -0.77, 0.05, 1.62, 0.15, 0.843913265120849, 0.43, -0.76, -0.51, 0.47, 0.35, 1.49, -0.77, -0.32, 0.7, 0.47, -0.5, 0.43, -0.93, -1.54, -1.44, -0.4123253968253967, -1.17, -2.33, -2.09, -1.13, -1.24, -0.12, -2.34, -1.9, -0.9, -1.13, -2.09, 0.75, -1.74, -0.1, 0.62, 0.28, -0.91, -0.66, 0.31, 0.2, 1.34, -0.92, -0.47, 0.54, 0.32, -0.66, 0.34, -0.24, 0.78, -0.82, -0.72, -0.34, -1.52, -1.28, -0.31, -0.42, 0.71, -1.53, -1.09, -0.08, -0.3, -1.27, 0.78, -0.38, -1.18, -0.94, 0.04, -0.08, 1.06, -1.19, -0.75, 0.27, 0.04, -0.93, -1.52, -1.08, 1.03, 0.81, 0.3380874332127649, 1.23, 1.12, 2.26, -0.01, 0.6052352330209474, 1.46, 1.24, 0.25, -1.33, 0.57, 0.99, 0.87, 2.01, -0.26, 0.19, 1.22, 0.99, 0.01, -0.28, 0.56, -1.25, -0.21, -0.52, 0.08, -0.42, -0.11, 1.02, -1.23, -0.78, 0.23, 0.0, -0.97, -0.66, -0.3, 1.13, -1.12, -0.67, 0.34, 0.12, -0.86, -0.7610416300368755, -0.78, 0.19, -0.43, -4.41, 0.1, -0.1, -0.95, 0.91, 0.48, -0.46, -0.07, -1.5894817511227284, 0.41, 0.22, 1.42, -0.41, -0.64, 0.63, 0.65, -0.21, -1.29, -0.4, -1.29, 0.64, -1.21, 4.18, 0.89, 1.21, 1.69, -1.42, -2.22, -1.78, -0.78, -1.01, -1.97, -0.6, 0.82, 0.45, 1.47, 1.25, 0.26, 0.37, 1.02, 0.79, -0.19, -0.82, -1.21, -0.5527253150925656, -0.23, -1.19, -0.27, -0.17560369872470916, 0.4, 2.35, 0.1, -2.21, -0.55, -0.61, -0.42, -0.97, -0.43, 0.15, -0.41, -0.99, -0.16, 0.56, -0.95, -1.07, -0.15], ['211', 0.75, -1.4, 0.07122171562045874, 0.11, -1.33, -0.49, -1.84, -1.6, -1.79, -2.88, -0.78, -1.42, -1.73, -1.4429761904761904, -1.11, -3.65, -1.77, -2.83, -2.3, -0.82, -3.32, -2.05, -1.91, -1.93, -1.82, -0.76, -2.0873416050068876, -0.64, -0.96, -0.68, -0.34, -2.89, -1.0, -2.07, -1.53, -0.04, -2.56, -1.28, -1.14, -1.16, -1.6, -3.58, -1.49, -0.32, -0.03, 0.31, -2.26, -0.36, -1.44, -0.89, 0.6, -1.93, -0.64, -0.5, -0.52, -0.7, -0.97, -1.39, -1.11, -1.17, 0.29, 0.7348467679404526, -1.95, -0.04, -1.12, -0.57, 0.93, -1.62, -0.32, -0.18, -0.2, -0.63, -1.45, 0.35, -2.23, -0.32, -1.4, -0.86, 0.64, -1.9, -0.61, -0.47, -0.48, -2.48, -2.52, 2.45, -1.789129077338006, -2.481912566787235, -0.66, -1.74, -1.2, 0.29, -2.23, -0.95, -0.81, -0.83, 1.95, 0.8, 1.95, 0.85, 1.4005714285714286, 2.94, 0.34, 1.66, 1.8, 1.79, -0.08, 0.83, -0.78, -0.71, -0.78, -0.84, -1.14, -0.9534006093113236, -0.54, 0.96, -1.58, -0.29, -0.15, -0.16, -0.9, -0.05, 0.55, 2.07, -0.5, 0.81, 0.95, 0.93, -1.21, -1.05, 0.21, -1.06, 5.74, -0.14, 0.0, 2.39, -2.42, -1.19, -1.47, -1.32, 4.290518248877271, 1.4, 0.7, 0.33, -0.25, -2.3285238095238094, 2.08, 2.08, -0.7, 3.64, -1.42, -1.45, 0.71, -3.48, 9.03, 2.37, 3.4, -4.09, -0.6, 1.51, -1.05, 0.25, 0.39, 0.38, -2.1, -2.08, -2.52, -1.24, -1.1, -1.12, 0.45, 1.31, 1.46, 1.44, -1.73, -1.8, -0.85, 0.14, 0.12, -0.71, -0.84, -1.45, 4.6, -1.08, -4.80347619047619, -1.34, -1.09, -0.99, -0.02, -0.85, -0.9, 0.38, -0.32, -0.58, -0.97, -1.36, -0.89, -0.46], ['212', 8.94, -0.21, -0.8687782843795413, 0.35, 0.51, -0.83, -1.305884742040171, -1.16, -0.81, 0.42, 0.520608843537415, 1.46, 1.09, 1.95, 1.02, -2.39, 1.89, 2.07, -0.84, -1.7974455782312924, 0.41, 1.2, 2.08, 1.74, -1.72, -0.79, -0.09, 0.95, 0.58, 1.43, 0.5, -2.88, 1.37, 1.55, -1.34, -2.63, -0.09, 0.69, 1.56, 1.23, -0.87, -0.85, -1.03, -0.37, 0.48, -0.44, -3.8, 0.42, 0.59, -2.27, -3.54, -1.03, -0.26, 0.61, 0.28, -0.89, -0.58, -0.93, -0.36, -0.5907547529341225, 0.9531047225355607, -0.07, -3.44, 0.79, 0.96, -1.91, -3.19, -0.67, 0.11, 0.98, 0.64, -1.44, -1.5, -0.91, -4.25, -0.06, 0.12, -2.73, -4.0, -1.5, -0.73, 0.13, -0.2, -0.68, -4.34, 4.4, -0.6, -3.37, 0.86, 1.04, -1.84, -3.12, -0.6, 0.18, 1.05, 0.72, 2.71, 2.87, 4.38, 4.56, 1.59, 0.26, 2.87, 3.68, 4.721108978323264, 4.23, -1.2, 2.94, -2.03, -1.04, -1.06, -1.04, -1.44, 0.18, -2.6698412698412697, -3.95, -1.44, -0.67, 0.19, -0.14, -0.59, -1.62, -2.84, -4.11, -1.62, -0.85, 0.01, -0.32, -1.8410416300368755, -1.88, 0.43, -1.2, 5.57, -0.2696768707482993, 0.29, 2.53, -2.358279874187437, -1.23, 0.54, -2.17, -4.91, 2.06, 1.09, 4.5, -0.48, -3.13, 3.19, 3.09, -1.04, 3.64, -2.02, -3.26, 1.62, -4.34, 7.93, 2.93, 4.24, 4.9, 1.26, -1.31, 1.26, 2.06, 2.94, 2.765761712843646, -3.17, 2.6, 2.6, 3.41, 4.3, 3.96, 0.0, 0.78, 1.66, 1.32, -0.75, -0.65, -0.78, 0.87, 0.53, -1.11, -0.9456036987247092, -1.13, 4.02, -1.9698003730425007, -3.9, -1.03, -1.0688174603174603, -1.63, -0.33, -1.14, -1.04, -0.51, -0.62, -1.01, -1.3, -2.14, -2.66, -1.2669832262926028], ['213', -2.57, 0.12, -0.08, -0.3, 0.6929790809910596, 0.24, -1.095884742040171, -0.7, -0.24, -0.81, -1.04, 0.07, 0.37, -0.5, -0.42, 0.08, -1.58, -0.83, -1.3, -2.33, -0.58, -1.86, -0.79, -1.29, -0.18, -0.19, 0.23, 1.12, 1.43, 0.54, 0.62, 1.13, -0.54, 0.21, -0.27, -1.31, 0.46, -0.83, 0.25, -0.25, -0.42, -0.9250638007838266, -0.88, 0.3, -0.58, -0.49, 0.01, -1.65, -0.91, -1.38, -2.4, -0.66, -1.93, -0.86, -1.36, -0.15, -0.63, -0.59, 0.06, -1.18, -0.87, -0.79, -0.29, -1.94, -1.21, -1.67, -2.7, -0.95, -2.22, -1.16, -1.66, -2.52, -0.31, 0.08, 0.59, -1.08, -0.33, -0.8, -1.84, -0.08, -1.36, -0.29, -0.79, 0.07, 0.08, -0.08, -0.39, 0.5, -1.16, -0.42, -0.89, -1.92, -0.16, -1.44, -0.37, -0.87, -1.36, -0.89, -1.65, -0.91, -1.38, -2.41, -0.66, -1.93, -0.87, -1.37, -0.48, -0.7906317967746538, 0.18572371188304004, 0.27, 0.22, 0.38, 0.8518094764861293, 0.75, 0.28, -0.77, 1.01, -0.28, 0.8, 0.29, 0.91, 0.03, -0.47, -1.51, 0.25, -1.03, 0.05, -0.46, 0.1, 0.53, 0.05603717887804044, 0.7, -3.75, -1.14, -0.29, -1.12, 1.1, 0.56, 0.39, -0.44, -3.12, -0.63, -0.3, -1.29, 0.41, 0.92, -0.93, -0.85, 0.27, -1.74, 0.55, 0.26, -0.4, 2.38, -2.66, -1.66, -2.29, 3.07, 0.8203786848072563, -1.04, 0.73, -0.56, 0.52, 0.17576171284364575, 0.8, 1.56, 1.79, 0.49, 1.58, 1.07, -0.23, -1.28, -0.21, -0.71, -0.13, 0.0, 1.07, 1.09, 0.58, 0.26, 0.32, -0.54, -1.3, -0.09, 1.49, 0.41189489941485546, 0.4, -0.02, -0.51, 0.12, 0.55, 0.12, 0.73, 0.23, 0.48, -0.45, 1.08, 0.24], ['214', 0.94, 0.16, 0.21122171562045874, 0.19, 0.47, 0.46, 0.7141152579598291, 0.88, 0.86, 0.77, -0.25, -0.72, 0.36, -0.86, -0.32, 0.21, -0.34, 0.62, 1.09, 0.09, 0.94, 0.69, 0.23, 0.29, 0.26, 0.83, 1.0526583949931125, -0.48, 0.6, -0.62, -0.022180028704908802, 0.46, -0.09, 0.87, 1.34, 0.34, 1.19, 0.94, 0.47, 0.54, 0.85, 1.8549361992161735, 1.5, 1.08, -0.14, 0.4, 0.94, 0.39, 1.35, 1.82, 0.82, 1.67, 1.42, 0.95, 1.02, 0.2, -0.15, 0.28, 0.36, 0.41, -1.21, -0.67, -0.15, -0.69, 0.26, 0.73, -0.26, 0.58, 0.34, -0.13, -0.06, 1.01, 1.64, 0.55, 1.08, 0.53, 1.5, 1.97, 0.96, 1.82, 1.57, 1.1, 1.17, 1.54, 1.01, -1.07, 1.09, 0.53, -0.01, 0.94, 1.42, 0.41, 1.27, 1.02, 0.55, 0.62, 2.81, 0.56, -0.54, 0.41, 0.88, -0.12, 0.73, 0.48, 0.02, 0.08, 0.17, 0.53, 0.12017700342548367, 0.5315981806829014, 0.5551790696343399, 0.565673518650032, 1.11, 0.96, 1.43, 0.43, 1.28, 1.03, 0.56, 0.63, -0.15, 0.15, 0.47, -0.52, 0.32, 0.07, -0.39, -0.33, 0.48, 0.33, 0.19, 0.73, 8.71, 0.09, 0.14, -2.03, 2.07, 1.01, -1.42, 1.81, -1.49, -1.03, -0.48, 0.5, 0.07, 1.42, -1.54, -1.4, 0.47, -3.0, 0.9898783572413152, -1.13, 0.54, 3.33, -5.69, -2.27, -3.28, 1.48, -0.32, -0.99, -0.15, -0.4, -0.86, -0.79, 1.42, 0.68, 0.85, 0.6, 0.14, 0.2, -0.17, -0.25, -0.71, -0.64, 0.89, 0.86, 0.07, -0.46, -0.4, 0.5, 0.53, 0.88, -2.63, 0.52, 2.54, 1.3872638105244333, 0.5, 0.54, 0.07, 0.38, 1.0, 0.22, -0.2, 0.03, 0.47, 3.34, 1.61, 0.83], ['215', 0.8, 0.12, 0.05122171562045875, 0.13, 1.12, -0.34, -0.62, -0.27, -0.03, -0.76, -0.96, -0.59, -1.23, -0.48, -0.25, -1.04, -0.56, -0.67, 1.79, -1.54, -0.49, -0.99, -0.3556947683993239, -0.25, 0.18, 0.21937141458889198, 0.2, 0.37, -0.28, 0.48, 0.7678199712950912, -0.08, 0.41, 0.29, 2.77, -0.59, 0.47, -0.04, 0.51, 0.71, -0.42, -0.37506380078382656, -0.16, -0.64, 0.11, 0.34, -0.45, 0.04, -0.08, 2.39, -0.5203333333333333, 0.1, -0.4, 0.14, 0.34, 0.28, -0.16, -1.09, 0.13, 0.5592452470658775, 0.76, 1.0, 0.2, 0.69, 0.57, 3.06, -0.31, 0.75, 0.24, 0.79, 0.99, -0.38, -0.27, 0.23, -0.56, -0.07, -0.18, 2.28, -1.06, -0.01, -0.51, 0.03, 0.23, 0.04, -0.48, 0.45, -0.51, -0.79, -0.31, -0.42, 2.04, -1.29, -0.2261298384155527, -0.74, -0.2, 0.0, 0.04, 0.28, 0.49, 0.37, 2.885904761904762, -0.51, 0.55, 0.04, 0.59, 0.79, -0.19, 0.27, 0.0, -0.13, -0.18, -0.14, -0.1990429599640126, -0.11, 2.36, -0.99, 0.06, -0.44, 0.11, 0.31, 0.26, -0.09, 2.47, -0.88, 0.17, -0.33, 0.22, 0.42, -0.27, -0.25, 0.32, -0.38, 0.0, 0.28, 0.2, 0.18, -0.21, -0.11, 0.76, 0.46, -1.58, 0.26, 0.1, 0.42, -0.39, -0.44, 0.47, 0.46, -0.15, 0.06, -0.26, -1.83, 0.9647652642842468, -0.59, -5.25, 0.36, 0.61, 1.69, -2.5, -3.27, -2.24, -2.73, -2.2, -2.0, -0.45, 0.8, 1.06, 0.55, 1.1, 1.31, -0.26, -0.5, 0.04, 0.24, 0.03, 0.12, 0.24, 0.55, 0.75, -0.16, -0.16, -0.19, -1.71, -0.69, 1.75, -0.12273618947556672, 0.7310935020800124, -0.31, 0.2, -0.56, 0.04, -0.3047020479520478, -0.35, 0.08, -0.5, -0.94, 1.1730376647162362, -0.54], ['216', -5.56, 0.22, -0.36877828437954124, 0.07, -0.38, 0.26, 1.25, -0.32, 0.27, 1.76, 2.15, 1.0, 2.03, 1.88, 2.03, 3.81, 1.46, 1.84, 0.56, 1.85, 1.51, 1.22, 1.12, 1.3921746031746032, -1.1, -0.96, -0.38, -1.13, -0.12, -0.27, -0.12, 1.63, -0.68, -0.31, -1.56, -0.29, -0.63, -0.91, -1.01, -0.74, 0.49, 0.52, 0.75, 1.02, 0.86, 1.02, 2.78, 0.46, 0.83, -0.44, 0.84, 0.5, 0.22, 0.12, 0.39, -1.1, -0.61, -0.43, 0.21, -0.26, -0.15, 0.0, 1.75, -0.56, -0.19, -1.44, -0.17, -0.51, -0.79, -0.89, -0.63, -0.66, -0.11, 0.15, 1.9, -0.41, -0.04, -1.29, -0.02, -0.36, -0.64, -0.74, -0.47, 0.0, 1.7, -1.3344319727891159, -0.26, 1.75, -0.56, -0.19, -1.44, -0.17, -0.51, -0.79, -0.89, -0.63, -3.34, -1.97, -2.26, -1.9, -3.13, -1.89, -2.22, -2.5, -2.59, -2.33, 0.02, -1.99, 0.31, 0.28, 0.42, 0.22, 0.3, 0.37, -0.89, 0.3905357142857143, 0.04, -0.24, -0.34, -0.07, 0.39, -0.07, -1.25, 0.02, -0.32, -0.6, -0.7, -0.44, 0.57, 0.46, 0.27, 0.34, -10.1, -0.1, -0.68, 0.38, -0.3, -0.19, -0.4, -1.28, 0.1, -0.57, -0.28, -2.86, 0.4, 0.84, -0.87, -0.95, 0.28, 0.62, 0.57, -1.14, 0.59, 0.92, 1.7127091836734694, -0.67, -0.97, -0.14, 1.19, 1.29, 0.94, 0.66, 0.55, 0.83, 0.85, -0.09, -0.34, -0.62, -0.72, -0.45, 0.25, -0.27711507143650005, -0.38, -0.12, 0.19, 0.23, 0.53, -0.1, 0.17, 0.3, 0.3, -0.37, 1.16, 0.44, -1.22, 0.37, -0.49, 0.64, 0.34278685149693167, 0.23, -0.13, 0.77, 0.91, 0.53, 0.37, -1.12, -0.28, 0.75], ['217', 5.23, 0.0, 0.05122171562045875, 0.17, 1.0, 0.28, -0.08, 0.68, 0.51, 1.11, 0.07, 1.31, 0.84, 0.69, 1.16, -0.21, 0.86, 1.37, -0.01, -0.32, 1.61, 0.44, 0.37, 1.19, 1.27, 0.78, 1.04, 1.24, 0.78, 0.63, 1.1, -0.28, 0.79, 1.3, -0.08, -0.39, 1.55, 0.37, 0.3, 1.12, -0.3125315746467892, 0.22, -0.2, -0.46, -0.61, -0.15, -1.5, -0.45, 0.05, -1.31, -1.61, 0.3, -0.87, -0.93, -0.12, 0.91, 1.27, 0.987827972809784, 0.52, 0.33924524706587755, -0.15, 0.32, -1.04, 0.01, 0.52, -0.85, -1.15, 0.76, -0.4, -0.47, 0.34, 0.58, 0.41, 0.47, -0.9, 0.16, 0.67, -0.7, -1.01, 0.91, -0.26, -0.32, 0.49, 0.54, 1.83, -1.86, -0.05, -1.36, -0.3, 0.2, -1.16, -1.47, 0.44, -0.72, -0.79, 0.0740077275244506, 2.32, 1.32, 1.07, 1.58, 0.2, -0.11, 1.83, 0.65, 0.58, 1.4, -0.12, 1.37, -1.75, 0.24, -0.13, -0.2, 0.25, 0.5, -0.86, -1.17, 0.75, -0.42, -0.48, 0.33, 0.54, -0.25, -1.36, -1.66, 0.25, -0.92, -0.98, -0.17, -0.25, -0.46, 0.3, 0.32, 6.91, 0.18, 0.07, 0.39, -0.32, -0.18, 0.29, 1.51, -2.75, -0.49, -0.23, 2.55, 0.03, 0.75, -0.81, -0.64, 0.26, 0.54, 0.52, -1.88, 0.95, 1.64, -25.189348639455783, -1.12, -1.69, 2.72, 1.12, -0.31, 1.63, 0.45, 0.38, 1.2, 0.74, 1.43, 1.94, 0.76, 0.69, 1.51, -0.5, -1.1571150714365, -1.23, -0.42, 0.5, 0.72, 0.67, -0.07, 0.75, 0.3, 0.25, 0.66, -5.82, -1.29, 5.91, 0.89, 1.2, 0.74, 0.82, 0.13, -0.17, 0.12, 0.0, 0.16, -0.08, 1.83, 1.96, -0.25], ['218', -0.88, 0.11, -0.21, 0.25, 0.44, 0.24, 1.2441152579598291, 0.05, 0.36, 2.45, 2.6, 1.85, 1.49, 1.83, 2.73, 2.22, 1.63, 2.2, 4.2, 1.97, 1.99, 1.55, 0.25, 1.25, 1.61, -0.44, -0.15, -0.73, -1.09, -0.76, 0.13, -0.38, -0.95, -0.2727410958555916, 1.56, -0.61, -0.6, -1.02, -2.29, -1.32, -0.62, 0.71, 0.58, -0.36, -0.03, 0.86, 0.35, -0.22, 0.34, 2.3, 0.11, 0.13, -0.3, -1.58, -0.6, -0.22, -0.34, -0.94, 0.12, 0.95, 0.44310472253556066, 1.3348467679404525, 0.72, 0.14, 0.8026050661400617, 2.68, 0.48, 0.49, 0.38746485260770963, -1.22, -0.23, 0.05, 0.61, 0.89, 0.38, -0.19, 0.37, 2.33, 0.14, 0.16, -0.04285714285714287, -1.55, -0.57, 0.17, 5.63, -5.62, -0.27, -0.4119125667872351, -1.07, -0.52, 1.43, -0.74, -0.72, -1.15, -2.3890238095238097, -1.44, -2.62, 0.23, -0.57, -0.01, 1.94, -0.24, -0.22, -0.65, -1.93, -0.95, 0.781141873999017, 0.2, 0.77, 0.44, 0.75, 0.19, 0.81, 0.56, 2.53, 0.34, 0.35, -0.08, -1.36, -0.38, 1.0165360710717855, 0.24, 1.96, -0.22, -0.21, -0.64, -1.91, -0.93, 2.1789583699631248, 1.59, 0.62, 0.83, -8.17, 0.43, 0.29, -0.34, 0.36, 0.17, 0.78, -0.96, -0.93, -0.87, -0.44, -0.35, -0.44, 1.38, -1.61, -1.37, 0.42, -0.47, 0.88, -2.23, 1.12, 2.39, -3.4, -1.63, -2.41, 0.83, -1.3596213151927437, -2.14, -2.13, -2.54, -3.8, -2.83, 1.32, 0.47, 0.02, -0.41, -1.69, -0.71, 0.45, -0.43, -1.71, -0.72, 0.7601351386708531, 0.11, 0.89, -1.28, -0.3, 0.43, 0.47, 0.05, -1.62, 1.57, 1.88, -0.35, 0.4, 2.2, 1.0, 0.21, 0.32, -0.11, -0.8, -0.64, 1.19, 0.24, 1.24, 1.48], ['219', -5.8, -0.09, -0.07, 0.02, -1.32, -0.37, -0.5258847420401709, -1.6082794034640413, -1.17, -1.37, -0.03, -0.54, -1.096086734879151, 0.2, 0.58, -0.47, -0.5, -1.14, -1.08, 0.77, -1.55, -1.22, -1.99, -1.53, -2.02, -0.770628585411108, -1.3173416050068876, -0.51, -1.14, 0.23, 0.61, -0.44, -0.47, -1.11, -1.05, 0.8, -1.53, -1.19, -1.97, -1.5, -1.77, -1.36, -0.84, -0.63, 0.74, 1.13, 0.07, 0.04, -0.6, -0.54, 1.32, -0.9919345319135571, -0.68, -1.4257142857142857, -0.99, -1.24, -1.32, -1.62, -1.3, -0.21, 1.4831047225355605, 1.77, 0.7, 0.67, 0.02, 0.08, 1.96, -0.39, -0.06, -0.84, -0.37, -1.5063939988582844, -1.57, 0.39, -0.67, -0.7, -1.34, -1.276904761904762, 0.57, -1.75, -1.42, -2.19, -1.73, -1.05, 1.13, -1.1, -1.95, -1.05, -1.08, -1.72, -1.66, 0.19, -2.13, -1.79, -2.56, -2.1, 0.73, -0.91, -0.03, -0.68, -0.61, 1.25, -1.09, -0.75, -1.53, -1.07, -0.04, -0.97, -1.19, -0.32, -0.17, -0.44432648134996805, -0.88, -0.64, -0.58, 1.28, -1.06, -0.72, -1.5, -1.03, -0.26, -0.24, 0.06, 1.94, -0.42, -0.08, -0.86, -0.39, 0.04, -0.45, -0.28, -0.73, 1.83, -0.07, -0.02, 0.25, -0.19, -0.1, 0.14, -2.44, 4.25, 0.66, 0.3, -2.94, 0.13307978986877905, -1.04, 1.09, 0.89, -0.32, 0.36, -0.65, 0.14, -0.1, -2.64, 0.32, 1.74, 2.57, -4.29, -0.3, 1.87, -0.48, -0.14, -0.92, -0.45, -0.94, -2.13, -2.31, -1.98, -2.75, -2.28, 0.18, 0.34, -0.45, 0.02, -1.16, -1.14, -0.16, -0.78, -0.31, -0.28, -0.4, -1.54, -1.19, -0.93, 1.14, -0.62, -1.73, 0.63, 0.47, -1.13, -0.33, -0.03, 0.2, -0.35, 0.16, -1.85, -2.62, 0.64], ['220', -3.78, -0.47, 0.2, -0.1, -0.18, 0.21, 2.49, -0.54, 0.29, -1.87, -2.44, -2.88, -1.83, -1.27, -1.85, -0.82, -1.9, -1.87, 0.64, -2.1, -1.9, -1.79, -2.16, -2.38, -0.36, -0.27, 0.58, -0.44, 0.62, 1.21, 0.61, 1.67, 0.56, 0.58, 3.16, 0.35, 0.56, 0.67, 0.29, 0.10384172319783916, 0.74, -0.14, 1.03, 1.07, 1.66, 1.06, 2.12, 1.01, 1.03, 3.62, 0.8, 1.01, 1.12, 0.74, 0.51, -0.07, 0.37, -1.0, 0.0, -0.04, 0.58, -0.02, 1.04, -0.06, -0.04, 2.52, -0.27, -0.06, 0.05, -0.33, -0.56, -1.18, -0.62, -0.59, 0.45, -0.64, -0.62, 1.93, -0.85, -0.64, -0.53, -0.9, -1.13, 0.38, 0.66, -0.63, -0.02, 1.05, -0.05, -0.02, 2.54, -0.25, -0.05, 0.06, -0.31, -0.54, -2.75, -1.07, -1.09, -1.07, 1.47, -1.29, -1.09, -0.98, -1.35, -1.58, 0.07, -1.04, 0.13, -0.16, 0.27, -0.48, 0.02, 0.02, 2.59, -0.21, 0.0, 0.11, -0.27, -0.49, -0.03, 0.0, 2.56, -0.23, -0.02, 0.09, -0.29, -0.52, 0.12, -0.2, -0.01, 0.17, -8.24, -0.15, -0.13, 2.81, -2.93, -1.44, -0.47, 0.24616353211204947, -0.49, 0.31, 0.16, -1.89, 0.14, -0.48, 0.35, 0.49, -0.09670919513614704, 4.31, -0.27, 0.37, -0.19, 0.04, 9.6, -0.09, -0.11, 0.6, -2.5, -2.72, -2.52, -2.41, -2.78, -3.0, -0.44, 0.23, 0.21, 0.32, -0.06, -0.29, 0.02, 0.11, -0.27, -0.49, 0.35, 0.25, -0.09, -0.38, -0.6, -0.15, -0.09, -0.49, 5.3, 0.49, -5.46, 0.07, 0.13, 0.29, -0.15721314850306833, 0.35, -1.75, 0.11, 0.27, 0.49, 0.605957527023814, -2.17, -0.59, 0.69], ['221', -2.36, 0.45, 0.16, 0.02, -0.79, 0.2384196236737595, -1.19, -0.26, 0.34, 0.45, -0.13, 0.91, 0.43, 0.39, 1.81, 1.15, 0.31, 0.33, 1.82, -0.33, 0.8, 0.25, 0.5, 0.33, -0.3, 0.28, 0.58, 1.04, 0.56, 0.52, 1.94, 1.28, 0.44, 0.45, 1.95, -0.2, 0.9307606837606838, 0.38, 0.63, 0.46, 0.35, 0.6, -0.46, -0.48, -0.52, 0.89, 0.24, -0.6, -0.58, 0.9, -1.23, -0.11, -0.66, -0.41, -0.57, 0.47, 0.17, -0.22, 0.66, 0.01, -0.04, 1.37, 0.71, -0.12, -0.11, 1.38, -0.76, 0.37, -0.18, 0.07, -0.1, -0.54, 0.06, 1.41, 0.76, -0.08, -0.07, 1.42, -0.72, 0.41, -0.14, 0.11, -0.06, 0.77, 0.01, 0.0, -1.339129077338006, -0.65, -1.47, -1.46, 0.01, -2.1, -0.99, -1.53, -1.28, -1.45, -0.74, -0.7, -0.83, -0.82, 0.66, -1.47, -0.34, -0.89, -0.64, -0.81, 0.05, -0.64, -0.8398953488372093, 0.19, 0.22, 0.27, 0.14, 0.02, 1.51, -0.64, 0.49, -0.06, 0.19, 0.02, 0.21, 0.17307674813036728, 1.49, -0.65, 0.48956235827664396, -0.07, 0.18, 0.01, -0.32, -0.16, -0.11, 0.38, -2.29, 0.31, 0.2, -0.08, 0.1, 0.04, 0.24, 0.47, -1.67, -0.39, -0.2, -1.23, 0.48, 0.62, -0.64, -0.57, 0.2, -0.12, 0.4, 0.48, -0.24, 0.44, 0.57, -0.25, -0.43, 1.64, -1.35, -2.11, -1.0, -1.54, -1.29, -1.46, 0.64, 0.78, 1.14, 0.59, 0.84, 0.67, -0.35, -0.55, -0.3, -0.47, 0.5901351386708531, 0.86, 0.19, 0.25, 0.08, 0.22, 0.2, -0.23, 0.25, -0.5088836208193301, -0.3, 0.28, 0.29, -0.06, -0.17, 0.31, 0.07, 0.2, 0.69, 0.59, 0.11, -0.93, -0.02, 0.13], ['222', 2.92, 0.01, -0.07877828437954125, 0.07, -0.1170209190089404, 0.5, 0.36411525795982913, -0.82, -0.63, -0.84, -0.15939115646258506, -1.4, -0.68, 0.12, 0.97, -1.78, -1.34, -0.72, 1.72, -0.66, -1.39, -1.61, -0.29, -0.404883372579801, -0.58, -0.19, -0.67, -1.23, -0.51, 0.3, 1.14, -1.61, -1.17, -0.54, 1.89, -0.48, -1.22, -1.44, -0.12, -0.38, -0.8, -3.02, 0.769303232481804, 0.73, 1.54, 2.4, -0.38, 0.06, 0.69, 3.16, 0.76, 0.01, -0.21, 1.12, 0.86, -0.2, -0.87, -0.13, 0.14291666666666658, -0.16, 0.81, 1.66, -1.1, -0.67, -0.03, 2.41, 0.03, -0.72, -0.93, 0.39, 0.13, 0.53, -0.96, 0.85, -1.9, -1.46, -0.84, 1.59, -0.78, -1.52, -1.73, -0.41, -0.67, -1.24, -0.95, 0.9, -1.79, -2.72, -2.29, -1.67, 0.74, -1.416255228898086, -2.34, -2.55, -1.25, -1.51, 1.66, 0.96, 0.44, 1.08, 3.56, 1.14, 0.39, 0.18, 1.6511089783232642, 1.25, 0.05, 0.98, -0.23, 0.12, -0.16, 0.47, 0.51, 0.64, 3.1, 0.7, -0.05, -0.19969498055271245, 1.07, 0.81, 0.68, -0.12, 2.45, 0.06, -0.68, -0.9, 0.43, 0.17, -0.54, 0.47, 0.06, 0.69, 3.31, -0.13, -0.15, -0.6, 0.6, 0.32, 0.82, -0.82, 0.36, -0.25, -0.12, 1.53, 0.37, 0.58, -0.51, -0.4, 0.13, -1.07, 0.26, -0.84, 0.38, 1.49, 2.87, -1.02, -1.43, -0.37, -2.51, -2.33, -3.06, -3.27, -1.97, -2.23, 0.32, -0.045645766931481174, -0.74, -0.96, 0.37, 0.11, 0.56, -0.21, 1.12, 0.86, -0.55, -0.95, 0.78, 1.33, 1.07, 0.14, 0.17, -0.57, 1.33, -0.05, -0.7707193877551022, 0.48, -0.3688174603174603, -0.55, -0.26, 0.61, 0.38, 0.64, 0.09, 0.33, -0.29, -0.09, -0.46, 0.33], ['223', 4.64, -0.4, -0.18877828437954128, -0.12, -0.66, -0.97, -1.2558847420401709, -1.24, -1.68, -0.68, 1.24, 0.55, 0.2, 0.45, -0.22, -1.23, 0.74, -0.31, -0.6, 0.91, -1.09, 0.1, 0.95, 0.54, -1.13, -1.38, -1.9, -0.69, -1.03, -0.78, -1.44, -2.44, -0.49, -1.53, -1.82, -0.33, -2.235546329921431, -1.12, -0.29, -0.6461582768021608, -0.5, -3.18, -1.22, -0.35, -0.09, -0.76, -1.77, 0.2, -0.85, -1.14, 0.3607142857142857, -1.601934531913557, -0.44, 0.4, 0.0, -2.69, -1.17, -1.39, -1.37, -0.88, 0.26, -0.42, -1.43, 0.55, -0.5, -0.79, 0.71, -1.29, -0.09, 0.75, 0.34, -1.8863939988582845, -1.13, -0.67, -1.68, 0.29, -0.76, -1.05, 0.45, -1.54, -0.35, 0.49, 0.1435596417251207, -2.18, -4.47, 4.58, -0.46, -1.01, 0.97, -0.09, -0.38, 1.13, -0.88, 0.32, 1.17, 0.77, 1.48, 0.56, 2.0, 0.94, 0.64, 2.17, 0.14, 1.35, 2.21, 1.8, -0.35, 0.55, -1.6042762881169599, -1.04, -1.19, -0.96, -1.41, -1.04, -1.33, 0.16, -1.83, -0.64, 0.2, -0.2, -0.9, -0.37, -0.29, 1.22, -0.79, 0.41, 1.26, 0.85, -1.74, -1.32, -0.46, -1.29, 2.95, -0.53, -0.35, 1.76, -1.77, -0.9, -1.29, -2.04, 3.1, 2.03, 1.03, 2.41, -0.56, -3.2, 3.18, 3.02, -1.03, 2.63, -2.03, 1.86, -0.97, -4.21, 5.55, 2.88, 4.23, -3.06, -0.08, 1.51, -0.5, 0.7, 1.56, 1.15, -3.05, -1.57, -1.99, -0.8, 0.04, -0.36, 0.42, 1.21, 2.07, 1.66, -1.76, -2.25, -0.78, 0.85, 0.44, -1.0, -1.0456036987247093, -1.3, 2.94, -1.49, -2.98, -1.34, -0.44, -1.62, -0.4, -1.23, -0.69, -0.8, -0.93, -1.14, -1.22, 0.29, -0.76, -0.98], ['224', 2.98, 0.06, 0.011221715620458745, -0.29, 0.6, 1.0684196236737595, 0.97, 0.93, 0.93, 0.25, -1.36, 0.1, -1.17, -0.7, -0.94, -0.06, -0.9, 0.48, 1.15, 0.02, 0.43, -0.51, -1.31, -0.39, 1.0, 0.66, 1.63, 1.48, 0.2, 0.68, 0.4878199712950912, 1.32, 0.47, 1.87, 2.55, 1.4, 1.82, 0.87, 0.05, 0.99, 0.35, 0.7849361992161734, 0.34930323248180406, -1.26, -0.79, -1.03, -0.16, -1.0, 0.39, 1.06, -0.08, 0.34, -0.61, -1.41, -0.48, 0.21, 0.65, 0.67, 0.27, 1.43, 0.48, 0.23, 1.12, 0.27, 1.67, 2.35, 1.2, 1.62, 0.7296581632653062, 0.015338978481835797, 0.8141848072562359, 0.3736060011417156, 0.95, -0.24, 0.64, -0.21, 1.19, 1.86, 0.72, 1.14, 0.19, -0.62, 0.31, 1.7, 4.05, -3.99, 1.2, 0.89, 0.04, 1.43, 2.11, 0.97, 1.38, 0.43, -0.38, 0.56, 1.45, 0.31, -0.84, 0.54, 1.21, 0.08, 0.49, -0.45, -1.26, -0.33, -0.1, 0.31, 0.04, 1.05, 0.99, 1.09, 1.16, 1.4, 2.08, 0.93, 1.35, 0.4, -0.41, 0.52, 0.73, -0.23, 0.67, -0.36775528629437304, -0.05, -0.99, -1.79, -0.87, 1.33, 1.24, -0.25, 0.87, 4.38, -0.2, 0.07, -2.51, 2.51, 1.28, 0.37, 1.1, -0.45, -2.07, -1.05, 1.53, 0.72, 3.17, -3.12, -3.13, 1.03, -3.88, 2.07, 1.33, -0.91, 3.47, -9.74, -2.29, -3.5, 0.43, -0.5796213151927438, -1.12, -0.5127867132867132, -1.64, -2.44, -1.52, 3.15, 0.23, 0.41, -0.53, -1.33, -0.41, -0.19, -0.8511214088935782, -1.74, -0.82, 0.98, 1.3184535464535465, 0.76, -0.81, 0.12, 1.05, 1.04, 0.92, -6.14, 0.6603332627840632, 6.15, 1.2, 0.96, 1.58, 1.0127868514969316, 1.0, 1.36, 0.7, 0.33, 0.91, 0.64, 1.58, 1.13, 0.22], ['225', 5.29, 0.13, -0.05, -0.22, 1.34, 0.28, -3.59, 1.08, 0.3, 0.68, -0.09, 3.1, 2.07, 0.07, -0.49, -1.25, 0.84, 1.72, 0.77, -1.05, 1.62, 0.34, 1.52, 0.97, 2.17, 0.72, 0.77, 3.2001785714285718, 2.16, 0.16, -0.4, -1.16, 0.94, 1.81, 0.87, -0.96, 1.71, 0.43, 1.62, 1.06, 0.61, 1.45, -2.35, -1.0, -2.94, -3.4191849704247237, -4.22, -2.19, -1.34, -2.26, -4.03, -1.44, -2.68, -1.53, -2.07, 1.44, 1.4, 1.25, 0.93, -1.36, -1.96, -2.51, -3.25, -1.2, -0.34, -1.27, -3.0497619047619047, -0.44, -1.69, -0.53, -1.08, 1.77, 0.61, -0.56, -1.32, 0.77, 1.65, 0.7, -1.12, 1.55, 0.27, 1.45, 0.9, 0.86, -2.4, 2.36, 1.18, -0.76, 1.35, 2.23, 1.28, -0.56, 2.12, 0.84, 2.03, 1.47, 2.44, 1.96, 2.12, 3.01, 2.05, 0.21, 2.91, 1.61, 2.81, 2.25, -0.79, 2.04, -2.01, -0.06, -0.09, -0.18432648134996804, -0.16, 0.87, -0.07, -1.88, 0.77, -0.5, 0.67, 0.12, 0.06, -1.02, -0.6763144197072768, -2.72, -0.1, -1.36, -0.19, -0.74, -1.23, -0.79, -0.49, -0.86, 7.8, -1.34, -1.09, 1.09, -1.13, -0.56, -1.49, 1.7, -3.53, 0.07, 0.0, 2.67, 0.38307978986877905, -0.18, 0.19, 0.17, -0.05, 1.55, -0.15, -0.73, 0.13, -0.45, 5.91, 0.28, 0.41, 3.47, -0.09, -1.81, 0.84, -0.38270294784580494, 0.74, 0.19, -0.17, 1.75, 2.69, 1.4, 2.6, 2.04, -0.8555102040816327, -1.26, -0.09, -0.64, 0.43, 0.86, 0.34, 1.3732337781266353, 0.63, -0.05, -0.22, 0.92, 3.28, -1.94, -3.16, -0.27, 0.31, -0.83, -0.4772131485030684, -0.21, -0.13, 0.52, 0.75, 0.2, -0.29, 0.07, 0.22, -0.49], ['226', -0.34, 0.33, 0.25, 0.03, 0.47, 0.46, 0.73, 0.88, 1.04, 0.11, -1.37, 0.0019344980416409752, -1.11, -1.19, -1.0, 0.11, -0.7, -0.12, -0.8, -0.78, 0.7, -1.38, 0.47, -0.33, 0.68, 0.46, 1.5326583949931125, 1.19, 0.26, 0.18, 0.38, 1.51, 0.68, 1.27, 0.58, 0.6, 2.1, 0.0, 1.87, 1.06, 0.51, 1.7549361992161734, 0.31, -0.91, -0.99, -0.79, 0.32, -0.19134863945578234, 0.08, -0.6, -0.58, 0.9, -1.18, 0.7042857142857143, -0.13, 0.55, 0.62, -0.7, 0.87, 1.23, -0.08, 0.12, 1.24, 0.41, 1.0, 0.32, 0.33, 1.83, -0.27, 1.6, 0.79, -0.38, 1.32, 0.2, 1.32, 0.5, 1.08, 0.4, 0.41, 1.92, -0.19, 1.68, 0.87, 1.45, -0.35, 0.19, 1.11, 1.12, 0.29, 0.88, 0.2, 0.21, 1.71, -0.38, 1.48, 0.67, -0.56, -0.01, -0.81, -0.24, -0.9084761904761905, -0.9, 0.59, -1.49, 0.36, -0.44, 0.2, 0.0, 2.12, 0.37, 0.34, 0.38, 0.82, 0.58, -0.1, -0.08, 1.41, -0.68, 1.18, 0.38, 1.33, 0.23, -0.68, -0.66, 0.82, -1.25, 0.59, -0.21, 0.26, 1.06, 0.03, 0.58, -1.82, 0.2980695494981211, 0.05, -0.22, 0.23, 0.11, 0.37, 1.47, -1.83, -0.77, -0.36, -0.16, 0.86, 1.0, -1.04, -1.04, 0.38, -0.35, 0.72, 0.09, -0.08, 2.41, -4.61, -1.63, -2.41, 1.7, 0.91, 0.01, 1.51, -0.58, 1.28, 0.47, 1.2, 0.9, 1.5, -0.6, 1.26, 0.46, -0.59, -2.06, -0.23, -1.02, 0.98, 1.25, 1.5, 1.87, 1.06, 0.4, 0.42, 0.91, -2.89, 0.19, 3.04, 0.27, 0.07, -0.36, -0.7172131485030684, 0.96, 0.14, 0.99, 1.07, 0.59, 0.525957527023814, -0.93, -0.49, 0.2], ['227', -1.11, 0.46, 0.41, -0.14, 0.46, 0.98, 1.48, 1.4, 1.63, 1.19, -0.97, -0.15, 0.31, 0.61, -0.15, 1.21, -0.08, 0.5, 2.4, -0.59, 1.28, 0.06, -0.73, -0.43, 1.55, 1.29, 2.18, 0.8301785714285714, 1.29, 1.59, 0.83, 2.2, 0.9, 1.48, 3.41, 0.39, 2.28, 1.04, 0.24, 0.5838417231978392, 0.71, 2.96, 1.5493032324818041, 0.46, 0.76, 0.0, 1.37, 0.08, 0.65, 2.56, -0.44, 1.44, 0.21, -0.58, -0.28, 1.26, 0.8, 2.02, 1.96, 0.88, 0.3, -0.45, 0.9, -0.38, 0.19, 2.09, -0.89, 0.97, -0.25, -1.04, -0.74, 1.44, 0.58, -0.7353571428571428, 0.6, -0.68, -0.11, 1.78, -1.19, 0.67, -0.55, -1.33, -1.03, 1.94, 5.12, -5.07, 1.34, 1.36, 0.07, 0.65, 2.55, -0.44, 1.43, 0.2, -0.58, -0.29, -0.91, -0.02, -1.27, -0.71, 1.18, -1.78, 0.07, -1.14, -1.92, -1.62, 0.64, -0.05, 3.98572371188304, 1.08, 1.19, 1.065673518650032, 1.27, 0.57, 2.48, -0.51, 1.36, 0.13, -0.65, -0.36, 1.17, 0.69, 1.9, -1.08, 0.78, -0.44, -1.22, -0.92, 2.13, 1.89, -0.2, 1.23, -2.63, 0.29, 0.42, -1.43, 1.4224623233908948, 0.7688101710076211, 0.79, 2.12, -3.58, -2.08, -1.05, -0.54, 0.5, 3.3, -3.25, -3.19, 1.123290804863853, -2.27, 2.15, 1.82, -0.91, 3.69, -5.48, -2.58, -3.76, 3.62, -1.18, -2.92, -1.09, -2.29, -3.023374458874459, -2.77, 3.13, 1.79, 1.88, 0.65, -0.14, 0.16, -0.09, -1.21, -1.99, -1.7, 1.59, 2.05, 1.14, -0.79, -0.49, 1.08, 1.11, 1.4, -4.19, 3.1711163791806696, 4.37, 1.4618948994148555, 0.54, 1.94, 0.3, 1.54, 0.85, 0.48, 0.2, 0.6, 1.63, 1.56, -0.06, 1.68], ['228', 2.85, -1.09, -0.10877828437954125, 0.03, -0.23, 0.54, -0.46, 0.31, 0.62, 0.08, -1.36, 0.4, -0.18, -0.26, -0.46, -1.37, -0.6, -0.14, 3.72, -0.07, 0.84, 0.46, -1.33, -0.27, 0.64, 0.6, 1.4926583949931125, 1.78, 1.19, 1.11, 0.91, -0.02, 0.77, 1.24, 5.14, 1.31, 2.23, 1.84, 0.03, 1.1, -0.57, 1.4949361992161734, -0.31, -0.58, -0.66, -0.86, -1.76, -0.99, -0.53, 3.31, -0.46, 0.44, 0.06, -1.72, -0.66, 0.09, 0.29, -0.14, 0.84, 0.27, -0.08, -0.28, -1.19, -0.41, 0.05, 3.91, 0.12, 1.02, 0.64, -1.091735383663955, -0.08, 1.16, 0.34, -0.2, -1.12, -0.34, 0.12, 3.99, 0.19, 1.1, 0.72, -1.07, -0.01, 1.3, 3.62, -3.66, 0.55, -0.92, 0.2999013605442177, 0.33, 4.2, 0.4016746031746032, 1.31, 0.92, -0.8390238095238095, 0.19, 4.84, 1.48, 0.79, 1.25, 5.16, 1.32, 2.24, 1.86, 0.04, 1.12, 0.33, 1.44, 0.49, 0.69, 0.83517906963434, 0.61, 0.68, 0.46, 4.34, 0.53, 1.44, 1.1203050194472877, -0.74, 0.33, -0.37, 0.22, 3.86, 0.16224471370562701, 0.97, 0.59, -1.19, -0.13, 1.56, 1.19, 0.11, 0.76, 14.887738095238095, 0.25, 0.07, -1.86, 1.79, 0.91, 0.36, 0.72, -0.36, -1.35, -0.72, 1.41, 0.57, 2.06, -2.14, -2.03, 0.69, -2.69, 1.4198783572413154, 0.26, -0.14, 1.94, -0.75, -1.35, -1.97, 0.32, -3.5, -3.65, -2.78, -3.14, -4.86, -3.84, 1.99, 0.15, 0.91, 0.53, -1.26, -0.2, -0.75, -0.38, -2.15, -1.1, 0.66, 1.04, -0.37, -1.78, -0.72, 0.71, 0.71, 0.14, -0.49, 0.58, 0.52, 0.5172638105244333, -0.07, 1.43, 1.07, 0.85, 0.99, 0.02, 0.79, 0.81, 0.35, 1.23, -0.48, 0.43], ['229', 1.62, -1.01, -0.25, 0.37, -1.72, -1.0215803763262405, -1.81, -1.6, -1.99, -2.59, 0.3, -1.4792857142857143, -0.7, -0.07, -0.95, -3.43, -1.05, -2.13, -0.35, 0.55, -3.17, -0.72, -0.78, -1.29, -2.22, -1.62, -2.8473416050068874, -1.78, -0.99, -0.36, -1.25, -3.71, -1.34, -2.42, -0.65, 0.26, -3.46, -1.01, -1.07, -1.58, -1.42, -2.98, -1.12, 0.8, 1.44, 0.54, -1.948956349206349, 0.44, -0.66, 1.15, 2.07, -1.71, 0.78, 0.8071428571428572, 0.2, 0.14, -1.81, -2.28, -2.26, -1.91, 0.63, -0.15515323205954745, -2.75, -0.35, -1.45, 0.34, 1.2602380952380952, -2.49, -0.02, -0.08, -0.59, -1.3, -2.52, -0.88, -3.36, -0.98, -2.07, -0.29, 0.62, -3.11, -0.65, -0.71, -1.22, -2.78, -5.04, 5.07, -1.65, -2.5, -0.1, -1.19, 0.6, 1.52, -2.24, 0.24, 0.18, -0.34, 0.93, 0.87, 2.46, 1.34, 3.18, 4.12, 0.26, 2.8124285714285713, 2.74, 2.22, -0.57, 0.86, -3.8542762881169597, -1.19, -1.28, -1.19, -1.4881905235138708, -1.1, 0.7, 1.62, -2.15, 0.34, 0.27, -0.24, -1.85, -0.46, 1.82, 2.75, -1.06, 1.5757995496566926, 1.39, 0.87, -2.04, -1.77, 0.21, -1.68, 2.76, -0.42, -0.35, 1.31, -1.29, -0.62, -0.74, -2.37, 6.48, 2.42, 1.21, 0.89, -0.56, -3.88, 3.56, 3.49, -1.17, 1.91, -2.35, -4.57, 2.35, -4.66, 5.57, 3.1, 4.51, -6.3, -2.24, 0.91, -2.83, -0.36, -0.42, -0.93, -3.52, -3.13, -3.7, -1.26, -1.32, -1.83, 0.6, 2.54, 2.47, 1.95, -1.99, -2.44, -1.89, -0.06, -0.57, -1.21, -1.27, -1.66, 4.11, -3.07, -4.28, -1.1627361894755668, -2.75, -1.83, -0.43721314850306836, -1.41, -0.53, -0.62, -0.5, -0.55, -1.234042472976186, -2.74, -3.96, -1.75], ['230', 0.47, 0.94, -0.07877828437954125, -0.08, -0.47, 0.92, 0.09, 1.24, 0.85, 1.2770884353741496, 0.12, 0.52, -1.04, -0.52, -2.15, -0.14, -0.35, 0.68, 2.93, 2.44, 0.83, 0.13, -0.32, 1.62, 0.91, 1.43, 0.72, 0.4, -1.16, -0.64, -2.27, -0.25, -0.47, 0.56, 2.81, 2.32, 0.794453670078569, 0.01, -0.43, 1.5, 1.26, 0.6049361992161734, 0.5093032324818041, -1.55, -1.03, -2.66, -0.65, -0.87, 0.16, 2.4, 1.91, 0.31, -0.39, -0.83, 1.09, -0.1476426685347185, 0.25, 0.78, 1.21, 1.89, 0.52, -1.12, 0.91, 0.69, 1.74, 4.01, 3.51, 1.89, 1.1959625850340136, 0.7882646163360448, 2.68, -0.09, 1.36, -1.64, 0.39, 0.17, 1.21, 3.47, 2.97, 1.36, 0.66, 0.21, 2.15, 0.98, 3.22, -3.23, 3.05, 2.06, 1.84, 2.895714285714286, 5.2, 4.69, 3.05, 2.33, 1.9109761904761904, 3.85, 0.91, 0.97, -0.22, 0.833095238095238, 3.07, 2.58, 0.97, 0.27, -0.18, 1.75, 0.37, 1.08, 1.33, 0.58, 0.94, 0.26, 1.19, 1.03, 3.3, 2.8, 1.19, 0.49, 0.04, 1.98, 0.64, 0.15, 2.24, 1.75, 0.15956235827664397, -0.54, -0.99, 0.93, 1.41, 2.279561224489796, 0.0, 0.8, 1.51, 0.38, 0.24, 0.67, -0.64, -0.33, 0.62, 3.16, 2.84, -1.09, -0.57, 0.2, 0.4, 1.71, -1.82, -1.88, 0.59, 1.11, 1.19, 1.69, -0.83, 3.49, -2.54, -2.26, -3.63, -2.93, -2.04, -0.48, -2.04, -2.72, -3.16, -1.28, 1.73, -1.56, -1.56, -2.25, -2.69, -0.8, 0.0, -0.7, -1.14, 0.78, 0.85, 1.1, 0.7, -0.45, 1.48, 0.57, 0.59, 1.27, -1.28, 2.0, 0.96, 1.02, 1.34, 1.15, 1.94, 0.4, 0.12, 0.55, 0.61, 1.37, -0.77, 1.23, 2.321595238095238, -0.52], ['231', 0.5, -0.51, 0.08, 0.32, -0.19702091900894042, -0.91, -1.48, -1.49, -1.76, -4.04, -1.36, -2.97, -2.72, -2.92, -3.2, -5.088928571428571, -2.22, -3.596530612244898, -1.58, -2.62, -4.13, -3.28, -1.96, -3.44, -2.77, -1.36, -2.72, -1.6294545454545453, -1.38, -1.58, -1.87, -3.78, -0.87, -2.28, -0.23, -1.28, -2.81, -1.94, -0.61, -2.1, -1.16, -2.92, -1.11, 0.25, 0.05, -0.24, -2.18, 0.77, -0.339454081632653, 1.43, 0.36, -1.2, -0.32, 1.04, -0.48, -0.38, -2.35, -2.44, -1.09, -1.36, -0.2, -0.49, -2.43, 0.52, -0.91, 1.17, 0.11, -1.45, -0.5103418367346938, 0.78, -0.73, -0.31, -1.16, -0.29, -2.2285714285714286, 0.72, -0.71, 1.6274764481550195, 0.31, -1.25, -0.37, 0.99, -0.53, -2.51, -5.48, 5.42, -0.87, -1.95, 1.02, -0.42, 1.67, 0.6, -0.96, -0.08, 1.28, -0.24, -0.97, 1.1, 3.02, 1.56, 3.69, 2.6, 1.0, 1.91, 3.29, 1.74, -0.52, 1.04, 0.17, -1.16, -1.26, -1.19, -1.87, -1.42, 0.65, -0.41, -1.96, -1.08, 0.26, -1.25, -0.88, -0.39692325186963273, 2.1, 1.03, -0.54, 0.35, 1.71, 0.18, -2.25, -1.71, 0.46, -1.58, -1.76, -0.32, 0.0, 2.5, -2.37, -1.2, -0.64, -2.47, 2.67, 2.34, 1.11, 0.26, -0.51, -3.68, 3.61, 3.47, -1.17, 3.6, -2.35, -3.12, 1.58, -5.6, 5.75, 3.74, 5.61, -2.73, -2.5, -1.05, -2.59, -1.72, -0.38, -1.88, -3.47, -1.46, -1.55, -0.67, 0.68, -0.84, 0.1, 0.89, 2.27, 0.73, -1.84, -2.01, -0.79, 1.36, -0.16, -1.05, -1.23, -1.47, 3.08, -0.95, -3.07, -1.46, -2.01, -2.12, -1.51, -1.63, -1.3, 0.1, -0.43, -0.43, -0.63, -2.58, -3.76, -1.65], ['232', 0.18, 0.44, -0.09877828437954125, -0.01, 0.21, 0.92, 1.4, 0.83, 1.18, 1.24, -0.17, 0.37, 0.72, -0.39, 0.19, 1.4, -0.56, 0.82, -1.44, 1.19, 1.47, 0.13, -0.11, 0.81, 0.54, 1.21, 1.41, 0.55, 0.89, -0.22, 0.36, 1.57, -0.39, 0.99, -1.27, 1.36, 1.64, 0.3, 0.06, 0.98, 0.68, 1.06, 0.86, 0.34, -0.76, -0.18, 1.02, -0.93, 0.44, -1.81, 0.81, 1.09, -0.25, -0.48, 0.44, 0.33006284630567656, 0.24, -0.15, 1.33, 0.52, -1.1, -0.52, 0.67, -1.27, 0.1, -2.14, 0.47, 0.75, -0.59, -0.82, 0.09, 0.26, 1.63, 0.58, 1.79, -0.18, 1.21, -1.05, 1.58, 1.86, 0.52, 0.28, 1.2, 1.28, 3.44, -3.48, 1.05, 1.2, -0.75, 0.62, -1.63, 1.193744771101914, 1.28, -0.06, -0.3, 0.62, 2.48, -0.15, -1.93, -0.57, -2.8, -0.21, 0.07, -1.25, -1.48, -0.58, 0.32, -0.12, -0.56, 1.04, 1.11, 1.07, 1.81, 1.39, -0.88, 1.76, 2.04, 0.69, 0.46, 1.38, 0.96, 0.47307674813036726, -2.24, 0.37, 0.8286030199958774, -0.68, -0.92, 0.0, 2.06, 2.55, -0.14, 1.53, 7.728670068027211, 0.07, -0.07, -2.82, 2.79, 1.428810171007621, 0.59, 0.96, -0.19, -2.13, -1.02, 0.12, 0.67, 3.27, -3.24, -3.08, 1.03, -4.2, 2.05, 1.59, -0.78, 5.38, -5.440028911564625, -3.53, -5.3, 0.26, 2.72, 2.66, 2.95, 1.59, 1.35, 2.28, 3.18, 0.05, 0.28, -1.05, -1.28, -0.37, -0.23, -1.32, -1.55, -0.65, 1.13, 1.29, 1.11, -0.23, 0.68, 0.99, 1.13, 0.8, -2.64, 0.55, 2.41, 1.66, 1.19, 1.35, 0.92, 0.79, 1.41, 0.75, 1.27, 0.62, 0.505957527023814, 2.67, 1.86, 1.03], ['233', -0.8, 0.0, 0.011221715620458745, -0.24, -1.23, 0.04, 1.63, -0.23, 0.82, -0.42, -1.45, -1.4, -0.9, -0.42, 2.6, -0.06, -0.63, -0.78, 0.37, 2.55, -0.38, -0.6, -1.11, -0.49, -0.04, 0.04, 1.04, 0.05, 0.56, 1.04, 4.11, 1.41, 0.83, 0.68, 1.85, 4.06, 1.08, 0.86, 0.35, 0.97, 0.06, 2.39, 0.990204081632653, 0.5, 0.99, 4.05, 1.36, 0.78, 0.62, 1.8871355564861205, 4.0, 1.03, 0.81, 0.29, 0.92, -0.07, 0.29, 0.16, 0.84, 0.48, 0.48, 3.53, 0.85, 0.28, 0.12, 1.28, 3.48, 0.52, 0.3, -0.21, 0.41, -0.11, 0.0, 3.04, 0.37, -0.2, -0.36, 0.8, 2.99, 0.04, -0.18, -0.68, -0.07, 1.24, 1.85, -1.9, -2.95, -2.59, -3.15, -3.3, -2.17, -0.05, -2.91, -3.12, -3.61, -3.01, -0.21, -0.37, -0.57, -0.73, 0.43, 2.61, -0.32, -0.55, -1.05, -0.44, 0.31, -0.33, -0.26, 0.0, 0.06, -0.09, 0.2, -0.16, 1.0, 3.2, 0.25, 0.09030501944728757, -0.48, 0.14, 0.03, 0.36, 1.16, 3.36, 0.409562358276644, 0.18, -0.33, 0.29, 0.51, 0.3, -0.01, 0.13, -0.74, 0.23, 0.22, -0.52, 0.49, 0.26, -0.53, -1.72, 5.59, 0.0, 0.03, -0.4, -0.58, 0.09, 0.0, 0.04, -0.01, -0.82, -0.17, 0.63, -0.26, 0.56, -3.08, -0.35, -0.62, -5.57, -0.4696213151927438, 2.17, -0.75, -0.97, -1.47, -0.86, -0.04, -2.9, -2.86, -3.07, -3.57, -2.97, -0.04, -0.22, -0.73, -0.11, 0.87, 1.0, 0.18, -0.51, 0.11, -0.09, -0.03, -0.08, -1.9728571428571429, -0.43, 1.77, -0.11, -0.23, 0.69, 0.62, -0.23, 0.24, -0.67, -0.9, -0.21, 0.07, 1.02, -0.5, 0.39], ['234', -2.21, -1.53, -0.18877828437954128, 0.07, -0.42, -0.34, -0.62, -0.8482794034640413, -0.9, -1.31, -0.59, -1.16, 0.19, -0.8, 0.75, -1.01, -0.94, -1.1, 2.45, -0.34, -1.92, -1.14, -1.07, -0.93, -0.46, -0.53, -0.72, -0.57, 0.79, -0.2, 1.35, -0.42, -0.34, -0.51, 3.06, 0.25, -1.33, -0.54, -0.48, -0.34, -0.76, -2.56, -0.15, 1.37, 0.5378753944468231, 1.94, 0.15, 0.23, 0.06, 3.65, 0.83, -0.76, 0.03, 0.09, 0.23, 0.0, -0.69, -0.22, -0.71, -1.5, -0.99, 0.56, -1.2, -1.13, -1.29, 2.25, -0.53, -2.11, -1.33, -1.26, -1.13, -0.43, -0.52, 1.56, -0.22, -0.14, -0.31, 3.27, 0.46, -1.13, -0.34, -0.28, -0.14, -1.48, -0.98, 1.0, -2.05, -1.7494795918367347, -1.68, -1.84, 1.68, -1.09, -2.65, -1.87, -1.8014761904761905, -1.68, -0.12, -0.3, 0.07, -0.09, 3.49, 0.67, -0.92, -0.13, -0.06, 0.08, -0.27, -0.35, -0.83, -0.28, -0.32, -0.23, -0.38, -0.17, 3.42, 0.6, -0.99, -0.2, -0.13, 0.0, -0.24, -0.21, 3.59, 0.77, -0.82, -0.04, 0.03, 0.17, 0.12, 0.16, 0.17, -0.22, -0.46, 0.0, 0.02, 0.69, -0.67, -0.34, -1.33, -1.3, 2.01, 0.54, 0.22, -1.1, 0.0, -0.87, 0.93, 0.83, -0.28, 0.97, -0.56, -0.37160934502005916, 0.24, -1.14, 1.59, 0.78, 1.01, -2.04, -3.67, -2.72, -4.26, -3.5, -3.43, -3.3, -0.81, -0.97, -1.58, -0.8, -0.73, -0.6, 0.62, 0.8, 0.86, 1.0, -0.88, -1.19, -0.17, 0.07, 0.2, -0.3, -0.23560369872470915, -0.86, 1.17, -0.84, -1.2, -0.71, -0.10890649791998751, -0.24, 0.14, -0.24399479488765202, -0.42, 0.38, 0.25, -0.55, -0.38, -0.76, -0.4, -0.28], ['235', -1.17, -0.6, -0.14, 0.14, -0.78, -1.19, -1.33, -0.67, -1.45, -0.37, 1.61, 0.83, 0.93, 0.63, 0.34, -0.36, 1.04, -0.01, -2.8, -0.55, -0.85, 0.05, 0.45, 0.35, -1.05, -1.05, -1.95, -0.77, -0.67, -0.96, -1.25, -1.94, -0.56, -1.6, -4.34, -2.12, -2.42, -1.54, -1.14, -1.24, -0.55, -4.04, -1.19, 0.1811974674961171, -0.2, -0.49, -1.18, 0.2, -0.84, -3.6, -1.37, -1.67, -0.78, -0.38, -0.48, -0.49, 0.55, -1.07, -1.56, -1.29, -0.3, -0.5792006802721088, -1.28, 0.11, -0.94, -3.69, -1.4697619047619048, -1.76, -0.88, -0.48, -0.58, -0.25, -0.99, -0.29, -0.99, 0.4, -0.64, -3.41, -1.17, -1.47, -0.58, -0.18, -0.29, -2.37, -2.49, 2.46, -0.6733017616146798, -0.7, 0.69, -0.35, -3.13, -0.89, -1.19, -0.3, 0.11, 0.0, -0.1, 0.0, 1.41, 0.35, -2.44, -0.18, -0.49, 0.41, 0.82, 0.71, -0.118858126000983, -0.07, -1.98, -1.17, -1.33, -1.06, -1.39, -1.04, -3.8, -1.57, -1.87, -0.98, -0.58, -0.69, -0.45, -0.35, -2.78, -0.53, -0.84, 0.06, 0.46, 0.36, -0.28, -0.56, 0.2, -1.5, -0.25, -0.36, -0.07, 1.61, -1.69, -0.82, 0.13, -1.68, -0.31, 2.34, 1.15, -0.57, -1.0, -3.46, 3.48, 3.52, -1.17, 2.49, -2.35, -1.69, 0.83, -4.14, 7.46, 2.8, 4.35, 0.39, 2.5, 2.31, 2.0, 2.92, 3.34, 3.23, -3.5, 0.18, -0.3, 0.6, 1.0, 0.9, 0.49, 0.9, 1.31, 1.2, -1.49, -1.79, -0.41, 0.4, 0.3, -1.067919965685943, -1.22, -0.68, 4.84, -2.2, -5.06, -1.59, -2.27, -0.81, -0.1, -1.45, -1.16, -0.54, -0.85, -1.44, -0.71, -3.24, -2.71, -1.01], ['236', -3.53, 0.4, 0.17122171562045874, -0.24, -0.04, 0.13, 0.17411525795982916, 0.69, 0.78, 0.66, 0.66, 0.33, 0.47, 0.07, 0.05, 1.27, 1.37, 0.91, 3.48, -0.8690034013605442, 0.57, 0.6, 0.39, 0.875116627420199, 0.69, 0.19, 0.0, -0.33, -0.19, -0.59, -0.61, 0.6, 0.71, 0.25, 2.8, -1.54, -0.09, -0.06, -0.27, 0.07, 0.42, 0.95, 0.33, 0.14, -0.26, -0.28, 0.94, 1.04, 0.58, 3.14, -1.21, 0.25, 0.27, 0.06, 0.4, 0.26006284630567655, 0.76, 0.82, 1.19, 0.19, -0.4, -0.42, 0.8, 0.9, 0.44, 3.0, -1.35, 0.1, 0.13, -0.08, 0.26, 0.88, 0.59, -0.02, 1.3555085034013605, 1.3, 0.84, 3.41, -0.95, 0.5, 0.53, 0.32, 0.66, 0.74, 0.35, -0.35857142857142854, 0.61, 1.22, 1.3417857142857144, 0.86, 3.43, -0.93, 0.53, 0.55, 0.34, 0.68, -1.14, -0.5226334687834371, 0.1, -0.36, 2.18, -2.13, -0.69, -0.6575714285714286, -0.87, -0.53, -0.25, -0.64, -0.93, 0.14, 0.25, -0.09, -0.7, -0.46, 2.08, -2.0302873118944547, -0.79, -0.76, -0.97, -0.63, 0.09, -0.25, 2.55, -1.78, -0.33, -0.31, -0.52, -0.18, 0.28, 0.15, -0.35, -0.4, -3.64, -0.43, -0.14, 0.22, -0.22, -0.09, 0.27, 0.6, -3.09, -0.26, -0.14, -1.73, -0.14, 0.47, -0.5, -0.47, 0.14, 0.27, 0.29, 0.82, -0.65, -2.13, -1.12, 1.35, 2.14, 3.29, -2.72, -4.22, -2.81, -2.78, -2.99, -2.66, 0.43, 1.56, 1.47, 1.5, 1.28, 1.63, 0.09, 0.03, -0.18, 0.16, 0.73, 0.84, 0.06, -0.21, 0.13, 0.14, 0.01, 0.75, -1.47, -0.38, 1.5, 0.43, 0.76, 0.27, 0.34, -0.13, -0.07, -0.31, -0.24, 0.36, -0.07, 0.7, 0.47, -0.58], ['237', 2.1, -0.24, 0.06122171562045875, -0.08, 0.69, 0.5384196236737595, 1.7000361663652803, 1.61, 1.9, 1.55, -1.48, 0.281934498041641, 0.01, 0.65, -0.26, 0.72, 0.41, 0.88, 3.07, 1.18, 2.17, 2.2, 0.96, 0.64, 1.29, 1.63, 3.08, 1.59, 1.51, 2.17, 1.24, 2.24, 1.93, 2.4, 4.63, 2.700714285714286, 3.71, 3.74, 2.48, 2.16, 1.02, 2.42, 1.47, 0.01119746749611708, 0.57, -0.34, 0.64, 0.33, 0.8, 2.99, 1.09, 2.09, 2.12, 0.88, 0.56, 0.68, 2.33, 0.94, 1.17, 1.54, 0.7431047225355607, -0.27, 0.71, 0.41, 0.88, 3.07, 1.17, 2.16, 2.19, 0.96, 0.64, 2.12, 0.89, -0.91, 0.07, -0.24, 0.23, 2.41, 0.52, 1.51, 1.54, 0.31, -0.01, 2.78, 1.61, -1.62, 1.82, 0.98, 0.68, 1.15, 3.35, 1.44, 2.44, 2.47, 1.23, 0.91, 1.01, 0.82, -0.3, 0.16, 2.34, 0.45, 1.44, 1.47, 0.24, -0.08, 0.44, 0.79, 3.12, 0.8915981806829014, 0.75, 0.99, 1.13, 0.47, 2.65, 0.76, 1.75, 1.78, 0.55, 0.23, -0.3134639289282145, 0.66, 2.17, 0.29, 1.28, 1.31, 0.08, -0.24, 0.82, 0.8, 0.14, 1.09, 3.11, 0.54, 0.28, -2.04, 2.062462323390895, 1.04, -1.0, 2.13, -0.75, -1.65, -0.91, 1.14, 0.53, 2.63, -2.63, -2.52, 0.84, -3.06, 1.72, 1.48, -0.77, 3.45, -6.12, -2.33, -3.37, 0.84, -1.48, -1.84, -0.87, -0.85, -2.033374149659864, -2.36, 2.53, 0.37, 0.99, 1.01, -0.21, -0.53, -0.61, 0.03, -1.18, -1.5, 1.92, 2.24, -0.64, -1.21, -1.52, 0.85, 0.93, 1.78, -3.84, 2.310199626957499, 3.78, 1.33, 0.68, 0.58, -0.32, 1.29, 0.97, 0.6, 0.26, 1.2, 0.9, 0.96, 1.7, 0.88], ['238', -1.93, -0.36, -0.028778284379541254, 0.08, -0.46, -0.44, -0.16588474204017084, -1.01, -0.52, -0.76, -0.38, -0.6, 0.52, -0.15, -0.02, -0.15, -0.26, -0.73, 0.18, -0.33, -0.67, -0.53, -0.53, -0.57, -1.26, -0.77, -0.38, -0.22, 0.9108333333333334, 0.23, 0.36, 0.23, 0.12, -0.36, 0.56, 0.05, -0.3, -0.16, -0.15, -0.19, -0.19, -0.5350638007838266, -0.16, 1.12, 0.45, 0.58, 0.45, 0.34, -0.14, 0.79, 0.27, -0.041934531913557026, 0.07, 0.07, 0.03, -0.36, 0.11, -0.55, -0.41, -1.27, -0.5568952774644393, -0.53, -0.66, -0.77, -1.24, -0.33, -0.84, -1.18, -1.04, -1.04, -1.08, -1.1863939988582846, -0.61, 0.13, 0.0, -0.11, -0.59, 0.33, -0.18, -0.52, -0.39, -0.38, -0.42, -0.42, -0.51, 0.52, -0.7033017616146798, -0.13, -0.24, -0.71, 0.2, -0.31, -0.65, -0.51, -0.51, -0.55, -1.11, -0.61, -0.11, -0.59, 0.33, -0.18, -0.52, -0.38, -0.38, -0.42, -0.04, -0.63, -0.23, -0.3, -0.38482093036566006, -0.2, -0.5, -0.48, 0.44, -0.07, -0.41, -0.27, -0.27, -0.25141531611693435, -0.06, -0.03, 1.1736855802927233, 0.41, 0.06, 0.2, 0.21, 0.17, -0.32, -0.44, 0.01, -0.48, -3.09, -0.1, -0.07, 0.1, -0.14, -0.06, 0.67, -0.5238364678879506, 0.83, 0.49, 0.28, -0.95, -0.29, -0.9, 0.95, 0.9, -0.31, 0.17, -0.6, -0.92, 0.47, -1.48, -3.85, 1.04, 1.55, -0.76, -0.94, -0.51, -0.85, -0.71, -0.71, -0.75, -0.96, -0.43, -0.34, -0.2, -0.2, -0.24, -0.09, 0.14, 0.15, 0.1, -0.52, -0.47, -0.23, 0.01, -0.04, -0.29, -0.31, -0.94, -1.84, -0.16, 1.84, -0.97, -0.7, -0.15136255179902908, -0.04, -0.57, 0.17455285983857427, -0.22, -0.37, -0.52, -0.19, -2.59, -1.31, -0.5], ['239', -1.72, 0.49, 0.18, -0.09, -0.72, 0.17, 0.49411525795982914, -0.11, 0.2, -0.45, -0.85, 0.05, -1.03, -0.03, -0.38, 0.34, -1.09, -0.55, -3.41, -0.66, -0.59, -0.44, -1.14, -0.63, 0.2, 0.26, 0.4, 0.91, -0.18, 0.82, 0.47, 1.21, -0.24, 0.4172589041444084, -2.58, 0.19, 0.26, 0.42, -0.29, 0.23, 0.68, 0.9049361992161734, -0.51, -1.09, -0.09, -0.43, 0.29, -1.14, -0.6, -3.46, -0.71, -0.64, -0.49, -1.19, -0.68, 0.25, -0.22, -0.51, 0.5, 0.59, 1.01, 0.66, 1.39, -0.06, 0.49, -2.4, 0.38, 0.45, 0.6, -0.11, 0.41, -0.53, -0.42, -0.35, 0.38, -1.06, -0.52, -3.38, -0.62, -0.55, -0.4, -1.11, -0.59, 0.6, 2.08, -2.09, -0.03330176161467985, 0.73, -0.71, -0.17, -3.04, -0.28, -0.21, -0.06, -0.76, -0.1859922724755494, -1.06, -0.8, -1.43, -0.89, -3.74, -1.0, -0.93, -0.78, -1.48, -0.97, 0.06, -0.86, 0.88, 0.31, 0.55, 0.11, 0.65, 0.55, -2.35, 0.44, 0.51, 0.66, -0.05, 0.5285846838830657, 0.17, 0.1, -2.88, -0.11, -0.04, 0.11, -0.59, -0.07, 1.05, 0.96, -0.11, 0.57, -3.26, 0.2, 0.27, 0.54, -0.57, -0.3, 1.34, -0.1, -0.43, -0.67, -0.33, -0.65, 0.48307978986877903, 0.82, -0.93, -0.94, 0.29, 0.75, 0.59, 0.21, -0.07, 1.93, -3.81, -1.29, -1.92, 0.46, 3.06, 2.85, 2.92, 3.08, 2.35, 2.89, 0.91, 0.21, 0.07, 0.22, -0.49, 0.03, 0.14, 0.15, -0.56, -0.04, 0.16, 0.48, -0.02, -0.71, -0.19, 0.31, 0.43439630127529083, -0.11, -1.81, 0.69, 1.62, 0.81, 1.1410935020800126, 0.7, 0.52, 0.7100774025227806, -0.4, 0.25, 0.51, 0.39, 0.17, 0.48, 0.99, 0.66], ['240', 3.13, 0.12, 0.2912217156204588, 0.19, -0.29, -0.09, 0.18, 0.44, 0.32, 0.55, 0.06060884353741497, 0.14, -0.05, -0.08, -0.78, -0.13, -0.02, 0.55, -5.2, 2.03, 0.54, 0.59, -0.08, 0.71, 0.04, 0.11, 0.5, 0.09, -0.1, 0.013189937047079991, -0.83, -0.18, -0.07, 0.5, -5.24, 1.98, 0.49, 0.54, -0.13, 0.66, 0.08746842535321082, 0.0, 0.42, -0.19, -0.22, -0.92, -0.27, -0.15, 0.42, -5.32, 1.89, 0.409654729237061, 0.45, -0.21, 0.57, 0.97, 0.3, 0.73, 0.12, 0.61, -0.03, -0.73, -0.08, 0.04, 0.61, -5.14, 2.09, 0.59, 0.64, -0.02, 0.76, 0.55, 0.64, -0.7, -0.05, 0.07, 0.64, -5.11, 2.12, 0.62, 0.67, 0.01, 0.79, 0.56, 2.01, -2.03, 1.3766982383853201, 0.65, 0.77, 1.34, -4.45, 2.83, 1.33, 1.38, 0.71, 1.5, 1.38, 0.69, 0.12, 0.69, -5.07, 2.17, 0.68, 0.72, 0.06, 0.84, 0.08, 0.68, 0.3, 0.14, 0.12, 0.18567351865003195, 0.57, 0.57, -5.18, 2.05, 0.56, 0.6, -0.06, 0.72, 0.05, 0.0, -5.72, 1.47, -0.01, 0.15579954965669268, -0.63, 0.15, 0.56, 0.84, 0.24, 0.07, 4.26, 0.21, 0.18, -0.38, 0.38, 0.18, 0.51, -0.45, 3.03, -0.29, -0.15, 1.59, 0.0, 0.6305968614718616, -0.53, -0.39, 0.14, -0.67, 0.29, -0.08, 0.03, 1.65, -4.49, -1.19, -1.65, -3.0, 6.06, 7.62, 6.05, 6.1, 5.4, 6.22, 0.44, -1.45, -1.46, -1.42, -2.06, -1.3, 0.01, 0.05, -0.61, 0.17, 0.23, 0.22, -0.03, -0.66, 0.19224875531501634, 0.14, 0.18439630127529083, 0.56, -2.33, 1.13, 2.29, -0.002736189475566718, 0.48, 0.63, 0.78, 0.05, 0.29, 0.35, -0.06, -0.53, -0.15, 1.69, 0.29, 0.05], ['241', -3.36, 0.38, 0.18122171562045875, 0.08, 0.07, 0.02, -0.49588474204017086, -0.84, -0.36, -1.03, -0.59, -0.28, -0.59, -1.19, 1.2242857142857142, -0.7, -1.5071428571428571, -0.85, 0.77, -3.49, -0.9526645179126411, -1.17, -0.58, -0.65, -0.3, 0.98, -0.45, 0.31, 0.0, -0.61, 1.82, -0.11, -0.93, -0.26, 1.37, -2.92, -0.4, -0.59, 0.02, -0.06, -1.74, 0.23, -0.75, -0.31, -0.92, 1.5, -0.42, -1.23, -0.57, 1.05, -3.22, -0.681934531913557, -0.89, -0.29, -0.37, -0.15, -0.59, -1.4580521152823784, -0.36, -0.45, -0.61, 1.82, -0.11, -0.93, -0.26, 1.36, -2.92, -0.4, -0.59, 0.01, -0.07, -0.97, 0.16, 2.44, 0.5, -0.32, 0.35, 1.99, -2.33, 0.21, 0.02, 0.63, 0.55, -0.03, -1.13, 1.1305714285714286, -2.22, -1.9, -2.7, -2.04, -0.44, -4.66, -2.18, -2.36, -1.77, -1.85, -0.02, -0.33, -0.82, -0.15, 1.48, -2.81, -0.29, -0.23718300350443208, 0.13, 0.05, -0.28, -0.4, 2.51, -0.06, -0.05, 0.03, 0.48, 0.67, 2.31, -2.01, 0.53, 0.34, 0.95, 0.87, 0.23, -0.18, 1.63, -2.67, -0.14, -0.32, 0.28, 0.44217743764172346, 1.04, 1.46, -0.33, 0.37, 0.03, -0.07, -0.14, 0.42, -0.41, -0.22, 0.62, -0.03, -5.1, 0.1, 0.05, -1.74, 0.04, -0.06, 0.06, 0.21, -0.06, 0.54, -0.15, -0.07, 0.06, 1.43, 0.13, -0.92, -1.38, 5.14, -1.4696213151927437, -4.23, -1.5427867132867132, -1.93, -1.33, -1.41, -0.08, 2.55, 2.6, 2.41, 3.03, 2.94, -0.05, -0.10112140889357832, 0.42, 0.34, -0.24, -0.23, 0.14, 0.6, 0.52, -0.09, -0.03, -0.78, 0.09, 1.4, 0.0, -0.66, 0.73, -0.46, -0.08, 0.06, -0.04, 0.27, -0.11, -0.41, -0.38, -0.25, 1.79, -0.24], ['242', -3.4, 0.11, 0.09122171562045875, 0.07, -0.6570209190089404, -0.26, -0.82, -0.49, -0.26, 1.05, 1.07, 1.92, 0.52, 2.15, 2.57, 1.71, 1.86, 1.01, 5.22, 1.77, 0.78, 1.84, 1.57, 1.34, -0.8, -0.73, -0.02, 0.8401785714285714, -0.54, 1.07, 1.48, 0.64, 0.78, -0.06, 4.1, 0.7, -0.29, 0.76, 0.5, 0.27, -0.67, -0.66, -0.86, -1.37, 0.22, 0.63, -0.21, -0.06, -0.9, 3.23, -0.15, -1.0919345319135572, -0.08, -0.34, -0.57, -0.14, 0.56, -1.31, 0.06, 0.52, 1.62, 2.03, 1.19, 1.33, 0.48, 4.67, 1.25, 0.26, 1.32, 1.05, 0.82, -0.3, -1.08, 0.41, -0.43, -0.29, -1.12, 3.0, -0.37, -1.34, -0.3, -0.57, -0.79, -0.23, -1.61, 1.57, -1.48, -0.83, -0.69, -1.52, 2.59, -0.7683253968253968, -1.74, -0.7, -0.97, -1.19, -1.49, -0.66, 0.14, -0.69, 3.45, 0.06, -0.92, 0.13, -0.14, -0.36, -0.15, -0.65, -1.98, -0.46, -0.49, -0.44, -0.8, -0.84, 3.3, -0.08, -1.06, -0.01, -0.28, -0.51, -0.83, 0.04, 4.17, 0.76, -0.22, 0.83, 0.56, 0.33, -0.46, -0.44, 0.07, -0.69, -4.57, -0.08, -0.24, 1.14, -1.13, -0.56, -0.08, -0.22383646788795053, 1.29, 1.01, 0.44, -1.7, 0.13, -1.38, 1.34, 1.41, -0.47, 1.5, -0.93, -0.29, 0.14, -2.42, 0.2721071428571429, 1.57, 2.22, -1.18, -3.97, -3.27, -4.22, -3.21, -3.46, -3.68, -1.4, -0.72, -0.97, 0.07, -0.2, -0.42, 0.26, 1.05, 0.78, 0.56, -0.29, 0.07, -0.78, -0.27, -0.49, -0.47, -0.5, -0.37, 0.84, -1.45, -0.83, -1.0, -1.03, -0.52, -0.23, -0.94, -0.64, 0.26, 0.38, -0.38, -0.29, -1.97, -2.36, -0.05], ['243', 1.92, -0.07, 0.08015289830927054, 0.15, -0.53, -0.07, -0.44588474204017087, -0.74, 0.33, -1.34, -2.31, -1.02, -1.06, -0.5, -0.11, -1.48, -1.55, -1.44, 0.97, -0.7, -1.28, -1.57, -1.57, -1.39, -0.44, 0.14, 0.99, 1.32, 1.28, 1.86, 2.25, 0.85, 0.78, 0.89, 3.35, 1.65, 1.06, 0.76, 0.76, 0.95, -0.03253157464678917, 0.95, -0.32, -0.03, 0.53, 0.92, -0.46, -0.53, -0.42, 2.01, 0.32, -0.26, -0.56, -0.55, -0.37, -0.61, -0.76, -0.47, 0.53, -0.29, 0.56, 0.95, -0.43, -0.5, -0.39, 2.04, 0.36, -0.22, -0.52, -0.52, -0.33, -0.96, -0.85, 0.39, -0.99, -1.06, -0.95, 1.47, -0.2, -0.78, -1.08, -1.08, -0.89, 1.04, 0.72, -0.7, -1.23, -1.37, -1.44, -1.33, 1.08, -0.59, -1.17, -1.46, -1.46, -1.27, -0.42, 0.14, -0.07, 0.04, 2.48, 0.79, 0.21, -0.09, -0.09, 0.1, 0.06, 0.09, -0.97427628811696, 0.17, 0.17517906963433993, 0.2, 0.21, 0.11, 2.55, 0.86, 0.28, -0.02, -0.02, 0.2285846838830657, 0.2, 0.1, 2.44, 0.75, 0.17, -0.13, -0.13, 0.06, 0.83, 0.29, 0.29, 0.14, -1.11, 0.13, 0.2, -0.54, 0.56, 0.25, 0.34, -0.6638364678879505, 1.22, -0.37, -0.19, 0.94, 0.17, 0.57, -0.54, -0.49, 0.22329080486385297, -0.87, 0.33, -1.44, 0.69, 0.72, -1.59, -0.41, -0.65, -1.26, -2.29, -1.65, -2.22, -2.51, -2.51, -2.33, 0.5, -0.64, -0.4358074110763185, -0.88, -0.87, -0.69, -0.07, -0.3, -0.3, -0.11, 0.33, 0.8084535464535467, 0.23, 0.0, 0.26224875531501635, 0.17, 0.11, -0.76, -1.32, -0.38, 1.27, -0.39, 0.22, 0.23, 0.19, -0.08, 0.29, 0.29, 0.33, 0.18, 0.04, -1.31, 0.68, 0.07], ['244', -0.53, 0.15, 0.13122171562045873, 0.03, 0.0, 0.31, 0.51, -0.58, 0.1, -0.6, -0.71, -0.96, -0.58, 0.41, -0.16, -0.69, -0.52, -0.68, -0.7, -0.22, -0.42, -0.47, -1.3, -0.86, 0.36, 0.4, 0.12, -0.25, 0.14011904761904762, 1.14, 0.56, 0.02, 0.2, 0.04, 0.02, 0.5, 0.3, 0.24, -0.59, -0.15, 0.2, -0.24, 0.37, 0.38, 1.39, 0.8, 0.27, 0.45, 0.28, 0.27, 0.75, 0.54, 0.49, -0.34, 0.1, 0.03, -0.44, -0.07, 0.22, -0.01, 1.0, 0.42, -0.11, 0.07, -0.1, -0.11, 0.37, 0.16, 0.11, -0.72, -0.28, -0.5263939988582844, -1.01, -0.57, -1.1, -0.92, -1.09, -1.1, -0.63, -0.83, -0.88, -1.5769045181009465, -1.2164403582748793, 0.0, 1.73, -1.77, -0.43, -0.53, -0.35, -0.52, -0.53, -0.06, -0.26, -0.31, -1.14, -0.7, -0.4, 0.1, 0.18, 0.02, 0.0, 0.48, 0.28, 0.22, -0.61, -0.17, 0.02, 0.11, 0.04, 0.26, 0.41, 0.13567351865003197, -0.08, -0.16, -0.18, 0.3, 0.1, 0.04, -0.79, -0.35, 0.03, 0.08, -0.02, 0.46, 0.26, 0.21, -0.62, -0.18, 0.74, 0.63, 0.08, -0.04, -1.12, 0.01, -0.07, 0.0, 0.05, 0.0, 0.52, -0.85, 0.79, -0.45, -0.26, -0.3, 0.19, 0.76, -0.78, -0.74, 0.26, -0.09, 0.5, -0.27, 0.12, -0.21, -5.32, 0.2, 0.23, -0.73, 0.1, 0.48, 0.28, 0.22, -0.61, -0.17, 0.79, -0.38, -0.2, -0.26, -1.08, -0.64, -0.18, -0.05, -0.88, -0.44, 0.16, 0.11, -0.12, -0.83, -0.39, 0.26, 0.21, -0.45, -3.66, 0.52, 3.66, 0.3718948994148555, 0.08, 0.7104317111459968, 0.44, 0.29, -0.07, 0.16, 0.21, 0.38, 0.27, -0.29, 0.07, -0.03], ['245', -2.01, 0.34, -0.028778284379541254, -0.28, -0.1, 0.06, 0.044115257959829166, 0.09, 0.31, 0.28, -0.6, 0.23, 0.35, 0.02, 0.46, 0.6, 0.23, 0.28, -3.83, -0.6, 0.21, 0.31, -0.19, -0.4, -0.86, -0.28, 0.89, 0.84, 0.96, 0.63, 1.07, 1.21, 0.84, 0.89, -3.25, 0.0, 0.82, 0.92, 0.41, 0.21, 0.36, 0.75, 0.05, 0.20119746749611708, -0.21, 0.22, 0.37, 0.0, 0.05, -4.05, -0.83, -0.02, 0.08, -0.42, -0.63, 0.35, 0.54, -0.19, 0.34, -0.07, -0.33, 0.11, 0.25, -0.11, -0.07, -4.16, -0.95, -0.13, -0.03, -0.54, -0.74, 0.76, 0.26, 0.44, 0.58, 0.21, 0.26, -3.85, -0.62, 0.19, 0.29, -0.21, -0.35644035827487924, 0.89, 1.3, -1.39, -0.17, 0.14, -0.22, -0.17, -4.27, -1.06, -0.24, -0.14, -0.65, -0.85, -1.49, -0.2426334687834371, -0.36, -0.32, -4.4, -1.2, -0.38, -0.28, -0.79, -0.99, -0.02, -0.26, 0.23572371188304003, 0.18, 0.38, -0.024326481349968038, 0.12180947648612922, 0.05, -4.05, -0.84, -0.02, 0.08, -0.43, -0.5714153161169343, 0.08, 0.0, -4.1, -0.88, -0.07, 0.03, -0.47, -0.68, 0.54, 0.59, -0.26, 0.01, -4.48, 0.26, 0.21, 0.72, -0.71, -0.35, 0.65, -0.19, -1.76, -0.43, -0.18, -0.98, 0.3, 0.37, -0.4, -0.58, 0.18, 1.07, 0.39, 0.73, -0.39, 0.14, -2.67, -0.07, -0.07, 1.78, 4.28, 3.3548095238095237, 4.206609977324264, 4.31, 3.78, 3.57, 0.56, 0.89, 0.82, 0.92, 0.41, 0.21, 0.07, 0.1, -0.41, -0.61, 0.32, 0.26, -0.03, -0.51, -0.71, 0.18, 0.11, 0.13, -1.37, 0.73, 1.21, 0.047263810524433285, 0.37, 0.48, -0.2, 0.32, 0.0, -0.03, 0.0, -0.24, 0.68, -1.31, 0.58, 0.77], ['246', -8.0, -1.26, -0.28, -0.18, -0.51, -1.11, -0.5258847420401709, -2.018279403464041, -2.3, -2.19, 0.4, -1.92, 0.4, 1.59, -0.2, 0.61, -1.33, -1.68, -1.55, -2.94, -2.69, -0.88, -1.14, -1.55, -3.32, -2.36, -2.5473416050068876, -2.3, 0.0, 1.18, -0.59, 0.21, -1.72, -2.07, -1.9392857142857143, -3.32, -3.07, -1.27, -1.53, -1.8961582768021608, -1.8025315746467891, -4.55, -0.28, 2.36, 3.57, 1.75, 2.57, 0.6, 0.24, 0.38, -1.04, -0.79, 1.06, 0.79, 0.37, -1.3199371536943236, -2.44, -1.37, -1.94, -2.510754752934122, 1.18, -0.6, 0.2, -1.73, -2.07, -1.8313219954648525, -3.33, -3.08, -1.28, -1.54, -1.95, -1.99, -3.72, -1.76, -0.97, -2.87, -3.21, -3.08, -4.46, -4.21, -2.43, -2.69, -3.09, -3.64, -3.87, 3.21, -2.0, 0.8, -1.14, -1.48, -1.35, -2.75, -2.5, -0.68, -0.95, -1.36, -4.1, -2.78, -1.93, -2.27, -2.14, -3.52, -3.27, -1.48, -1.74, -2.15, -1.08, -2.81, -1.36427628811696, -1.06, -1.09, -1.09, -0.87, -0.35, -0.22, -1.63, -1.37, 0.46, 0.19, -0.23, -1.43, -0.53, 0.13, -1.29, -1.03, 0.81, 0.54, 0.12, -0.61, -0.5, -0.13, -1.31, -8.21, -2.0219304505018787, -1.86, 1.28, -1.24, -0.62, -0.47, -1.32, -1.33, 2.13, 1.05, -4.1, -0.98, -3.34, 3.37, 3.32, -1.06, 2.04, -2.19, -0.63, 0.26, -2.65, 11.22, 1.73, 2.69, 1.63, -0.66, -1.42, -1.16, 0.68, 0.41, -0.01, -3.14, 0.77, 0.26, 2.12, 1.85, 1.43, 0.51, 1.86, 1.59, 1.16, -2.46, -2.88, -1.33, -0.27, -0.68, -1.11, -1.0, -1.94, 5.58, -0.9098003730425006, -5.46, -2.05, -1.66, -1.06, -0.42, -1.743994794887652, -0.68, -1.03, -0.46, -1.03, -0.65, -2.84, -1.97, -0.44], ['247', -2.09, 0.12, 0.09122171562045875, 0.08, 0.15, -0.63, -1.0058847420401709, -0.77, -1.12, -1.73, 1.05, -1.42, -1.61, -1.77, -0.32273809523809527, -1.36, -1.012857142857143, -1.66, -1.39, -1.7233571428571428, -2.01, -0.62, -0.29, -1.33, -0.42, -1.2, -2.76, -2.44, -2.2123253968253964, -2.79, -1.37, -2.38, -2.08, -2.68, -2.42, -2.76, -3.02, -1.66, -1.33, -2.36, -1.79, -3.1750638007838266, -0.32, -0.19, -0.35, 1.1, 0.06, 0.38, -0.24, 0.03, -0.32, -0.6, 0.81, 1.14, 0.09, -1.02, -0.65, -0.08, -0.35, -0.13, -0.16, 1.3, 0.26, 0.57, -0.05, 0.22, -0.13, -0.4, 1.0, 1.34, 0.28, 1.25, 0.03, 1.46, 0.42, 0.73, 0.11, 0.38, 0.03, -0.24, 1.16, 1.5, 0.44, -2.62, -3.39, 3.63, -1.4, -1.02, -0.72, -1.33, -1.06, -1.41, -1.68, -0.27428571428571424, 0.04, -1.0, -0.7473809523809524, -0.38, 0.31, -0.31, -0.04, -0.38, -0.66, 0.74, 1.08, 0.03, -0.19, -0.41, -0.17989534883720928, -0.62, -0.7, -0.36, -0.69, -0.62, -0.35, -0.69, -0.97, 0.43, 0.76, -0.29, -1.02, -0.08, 0.27, -0.08, -0.35, 1.05, 1.39, 0.33, -1.11, -1.05, 0.13, 0.11, -1.59, 0.3580695494981211, 0.22, 0.46, -0.47, -0.26, -0.37, 0.36, -0.32, 1.25, 0.61, -0.98, -0.56, -1.6, 1.54, 1.93, -0.63, 0.69, -1.28, 0.3, -0.18, -2.12, 2.45, 1.43, 2.04, 0.19, -0.34, -0.34, -0.62, 0.78, 1.12, 0.06, -1.85, 0.0, -0.28, 1.13, 1.47, 0.41, 0.28, 1.4128849285635, 1.75, 0.69, -1.18, -1.54, -1.12, 0.33, -0.71, -0.69, -0.52, -0.78, 1.3, 0.0, -1.16, -0.03, -0.27, -1.45, -1.04, -0.77, -0.46, -0.42, -0.68, -0.64, -0.41, 1.13, 0.5, -0.64], ['248', -0.53, 0.12, -0.43877828437954125, 0.06, 0.07, -0.41, 1.5, 0.69, 0.45, 2.23, 2.33, 0.32, 2.17, 2.46, 0.9, 1.75, 2.68, 2.47, 6.64, 1.71, 2.05, 2.8010442176870747, 2.37, 2.19, 0.13, 0.28, -0.09, -1.96, -0.16, 0.13, -1.39, -0.57, 0.35, 0.14, 4.22, -0.6, -0.27, 0.43, 0.05, -0.13, 1.95, -0.15, 1.91, 1.84, 2.13, 0.58, 1.42, 2.35, 2.14, 6.3, 1.38, 1.72, 2.43, 2.05, 1.86, -0.28, 0.39, 1.28, 0.12, 0.07, 0.29, -1.24, -0.41, 0.51, 0.3, 4.38, -0.45, -0.11, 0.59, 0.2, 0.02, 1.1, -0.22, -1.52, -0.7, 0.22, 0.01, 4.08, -0.73, -0.4, 0.3, 0.05309548189905343, -0.27, -0.2, -0.24, 0.19, 1.32, 0.84, 1.77, 1.55, 5.69, 0.8, 1.14, 1.85, 1.46, 1.27, 0.36, 0.48, 0.92, 0.71, 4.8459047619047615, -0.04, 0.3, 1.0, 0.62, 0.43, 0.18114187399901702, 0.54, 0.56, -0.1, -0.06, -0.03, -0.44, -0.21, 3.86, -0.95, -0.4442217465074606, 0.08, -0.3, -0.48, -0.48, -0.23, 4.08, -0.74, -0.41, 0.29, -0.09, -0.27, 0.37, 0.45, 0.06, 0.05, 0.92, 0.18, -0.28, -0.17, 0.18, 0.11, 0.21406627346681525, 1.05, -0.9, 0.12, 0.1, -0.25, -0.39, -0.14, 0.14, 0.26, -0.08, -0.22, -0.2, -0.5, 0.25, -1.23, 8.05, 0.87, 1.21, 1.3056150793650794, -4.14, -4.63, -4.31, -3.64, -4.0, -4.18, -0.25, 0.6543542330685188, 0.33, 1.04, 0.65, 0.47, 0.18, 0.7, 0.32, 0.14, 0.41, 0.09, -0.52, -0.38, -0.56, -0.07, -0.09, 0.64, 4.812857142857143, -0.3, -4.13, 0.3, 0.05, -0.14, -0.18, -0.88, 0.18, 0.03, -0.29, -0.03, 0.04, -0.21, 1.5030376647162362, -0.43], ['249', -0.59, 0.63, 0.04, -0.06, 0.41, 0.27, 1.17, 0.65, 0.51, -0.62, -1.48, -1.17, -1.63, -0.09, -2.94, -0.25, -1.19, -0.79, -0.52, -1.2033571428571428, -0.35, -0.77, -1.16, -1.47, 0.45, 0.63, 0.9126583949931124, 0.32, -0.14535714285714285, 1.42, -1.4221800287049087, 1.26, 0.29, 0.8272589041444084, 0.97, 0.28, 1.15, 0.72, 0.33, 0.053841723197839156, 0.88, 1.64, 0.56, -0.46, 1.1, -1.79, 0.94, -0.02, 0.39, 0.7571355564861204, -0.04, 0.83, 0.41, 0.01, -0.3, 1.05, -0.44, 0.3, -0.11, 1.03, 1.56, -1.33, 1.4, 0.44, 0.85, 1.1371802721088435, 0.42, 1.3, 1.1974648526077096, 0.48273474541331685, 0.18418480725623584, 0.14, -0.53, -2.849285714285714, -0.16, -1.11, -0.7, -0.4269047619047619, -1.12, -0.26, -0.68, -1.07, -1.38, 1.05, 1.721742947528662, -1.58, 2.4266982383853204, 2.78, 1.8, 2.22, 2.49, 1.78, 2.67, 2.23, 1.83, 1.51, -0.13, -0.37, -0.95, -0.54, -0.28, -0.97, -0.11, -0.53, -0.92, -1.23, 0.25, -0.45, 2.3157237118830403, 0.49, 0.53, 0.585673518650032, 0.6618094764861292, 0.41, 0.68, -0.02, 0.85, 0.43, 0.04, -0.22141531611693435, 0.25, 0.17, 0.27, -0.43, 0.44, 0.02, -0.38, -0.69, 0.5, 0.43, -0.16, 0.55, -0.37, 0.1, 0.1, -0.9, 0.7, 0.45, -0.26, 0.95, -1.33, -0.98, -0.52, -0.21, 0.5, 1.46, -1.49, -1.47, 0.47, -1.4, 0.9, 1.36, -0.7, 1.74, -6.02, -1.1, -1.59, 1.22, -0.09, -0.69, 0.17, -0.25, -0.64, -0.95, 1.4708051948051948, 0.6, 0.87, 0.45, 0.05, -0.26, 0.176501700680272, -0.42, -0.81, -1.12, 0.55, 0.64, 0.16, -0.39, -0.7, 0.49, 0.53, 0.6, -4.07, 2.05, 4.14, 0.51, 0.37, 0.55, -0.32, -0.14, 0.36, 0.83, 0.57, 0.67, 0.87, 0.39, 0.4, 1.23], ['250', 2.04, -0.18, 0.12, 0.05, 0.18, -0.42, -2.1758847420401706, -0.99, -0.7, -0.15, 0.5, 1.35, 0.28, 0.89, 2.03, -1.09, 0.05, -0.12, 1.18, -0.09, -0.29, 0.19, 0.26, 0.19, -0.8, -0.17, -0.65, 0.85, -0.22, 0.38, 1.52, -1.58, -0.45, -0.5027410958555916, 0.68, -0.59, -0.705546329921431, -0.31, -0.24, -0.31, -0.56, 0.07, -1.48, -0.9788025325038829, -0.46, 0.67, -2.41, -1.28, -1.46, -0.17, -1.43, -1.62, -1.14, -1.08, -1.15, -0.68, -0.59, -1.28, -0.66, -0.43, 0.61, 1.74, -1.36, -0.23, -0.4, 0.9, -0.37, -0.57, -0.09, -0.02, -0.09, -0.75, -1.03, 1.13, -1.96, -0.83, -1.0, 0.29, -0.97, -1.16, -0.69, -0.62, -0.69, -0.36, -1.09, 1.11, -2.13, -3.05, -1.94, -2.11, -0.83, -2.08, -2.1047647669790526, -1.8, -1.73, -1.8, 0.18, 0.95, 1.15, 0.98, 2.29, 1.01, 0.81, 1.29, 1.36, 1.29, -0.07, 0.87, -0.11, -0.4, -0.41, -0.3, -0.2, -0.17, 1.13, -0.14, -0.34, 0.14, 0.21, 0.14, -0.12346392892821456, -0.03, 1.31, 0.03, -0.16, 0.32, 0.39, 0.31, -0.6, -0.51, 0.07, -0.3, 0.4, 0.07, 0.24, 0.53, -0.49, -0.29, 0.14, -0.98, 0.0, 0.8, 0.39, 1.04, -0.45, -1.15, 1.09, 1.17, -0.39, 0.82, -0.77, -0.95, 0.48, -0.57, -1.7, 0.42, 0.49, -0.07, -1.32, -1.26, -1.45, -0.98, -0.91, -0.98, -1.12, -0.06, -0.2, 0.29, 0.35, 0.28, 0.14, 0.48, 0.55, 0.48, -0.6772046485260771, -0.41, -0.34, 0.07, 0.0, -0.36, -0.36, -0.93, -0.87, -0.11, 0.85, 0.08, -0.59, -0.41, -0.07, -0.7999225974772194, -0.53, -0.2, -0.34, 0.07, -0.34, -1.41, 0.07, -0.28], ['251', -7.91, -0.4, -0.3487782843795412, 0.18, -2.26, -1.24, -0.32588474204017087, -1.05, -1.7, 0.8470884353741497, 2.84, 0.86, 1.59, 2.27, 0.97, 2.54, 0.71, 0.1, 3.72, 3.7, -0.57, 2.63, 2.04, 0.74, -2.16, -1.95, -2.37, -1.93, -1.22, -0.56, -1.82, -0.29, -2.07, -2.67, 0.85, 0.84, -3.319239316239316, -0.2, -0.78, -2.04, -0.28, -2.85, -0.250696767518196, 0.73, 1.4, 0.11, 1.67, -0.14, -0.75, 2.84, 2.82, -1.41, 1.76, 1.17, -0.11, -0.97, -0.75, -1.41, -1.62, -1.17, 0.66, -0.61, 0.94, -0.87, -1.47, 2.09, 2.08, -2.13, 1.02, 0.44, -0.84, -1.57, -1.82, -1.27, 0.27, -1.52, -2.12, 1.42, 1.4, -2.78, 0.36, -0.22, -1.49, -2.64, -4.67, 4.63, -0.56, 1.56, -0.25, -0.86, 2.72, 2.71, -1.53, 1.65, 1.06, -0.22, -3.37, -2.09, -1.79, -2.377880952380952, 1.14, 1.13, -3.04, 0.09, -0.49, -1.76, 0.13, -2.11, 0.73572371188304, -1.53, -1.32, -0.76, -0.31, -0.61, 2.98, 2.97, -1.28, 1.91, 1.32, 0.03, -1.99, 0.3, 3.61, 3.6, -0.67, 2.53, 1.94, 0.64, -1.59, -1.72, 0.19, -0.55, -6.78, -0.18, -0.01, 0.24, -0.23, -0.1, -3.25, -2.36, 6.18, 2.16, 1.1, -4.03, -1.4, -2.94, 3.07, 3.14, -1.07, 0.36, -2.14, -1.37, 0.68, -0.93, 6.33, 0.6, 0.9, -6.38, -3.19, -0.01, -4.13, -1.04, -1.62, -2.87, -3.31, -3.18, -4.1164625850340135, -1.03, -1.61, -2.85, 0.98, 3.22, 2.62, 1.32, -1.79, -2.03, -2.17, -0.58, -1.84, -1.03, -0.97, -1.28, 3.23, 0.5, -3.19, -1.4, -2.15, -1.6, -1.27, -1.03, -0.2, -1.51, -0.9897755102040815, -0.64, -0.34, -1.28, -1.68, 0.35], ['252', 5.65, 0.68, 0.26122171562045876, -0.15, 2.2929790809910595, 2.69, 1.7841152579598292, 2.9117205965359587, 2.09, 2.0, -2.82, 0.65, 0.04, -1.12, -1.77, 0.54, -1.52, 0.94, 2.6, -1.66, 2.947335482087359, -0.79, -1.45, -0.6, 0.23, 1.079371414588892, 4.96, 3.56, 2.94, 1.75, 1.08, 3.46, 1.33, 3.87, 5.57, 1.18, 5.89, 2.08, 1.41, 2.28, 1.96, 3.3549361992161733, 1.35, -0.6, -1.5921246055531768, -2.4, -0.1, -2.16, 0.29, 1.94, -2.3, 2.25, -1.43, -2.08, -1.24, -0.83, 0.46, -1.14, 1.47, 1.96, -1.16, -1.81, 0.5, -1.56, 0.9, 2.56, -1.7097619047619048, 2.87, -0.84, -1.49, -0.64, 4.3, 3.16, -0.65, 1.68, -0.41, 2.09, 3.76, -0.55, 4.08, 0.33, -0.33, 0.53, 3.26, 9.54, -9.47, 3.84, 2.35, 0.25, 2.76, 4.45, 0.1, 4.76, 0.99, 0.32, 1.19, 3.18, 1.527366531216563, -2.05, 0.4, 2.05, -2.2, 2.36, -1.33, -1.98, -1.13, 1.08, 1.48, 5.43, 2.76, 2.79, 2.78, 3.58, 2.5, 4.19, -0.15, 4.5, 0.74, 0.07, 0.94, 2.88, 1.05, 1.64, -2.58, 1.95, -1.5942004503433074, -2.37, -1.53, 3.6418280382942037, 3.59, 0.0, 3.26, 9.477952380952381, 0.32225133596562167, 0.09, -5.66, 5.67, 2.8688101710076213, 1.8, 4.3, -7.34, -5.59, -2.77, 2.88, 1.82, 8.460596861471862, -8.34, -8.28, 2.79, -8.56, 5.54, 5.0, -2.49, 10.64, -10.42, -7.14, -10.58, 7.36, -0.58, -4.16, 0.3, -3.31, -3.95, -3.12, 8.37, 3.73, 4.65, 0.89, 0.22, 1.09, -0.88, -3.6, -4.24, -3.41, 3.33, 3.55, 2.82, -0.66, 0.27224875531501636, 2.8, 2.874396301275291, 3.74, -5.39, 4.9, 5.41, 3.66, 3.85, 3.5, 0.86, 3.22, 2.82, 1.82, 1.91, 1.96, 2.61, 4.87, 4.73, 2.56], ['253', -0.16, 0.15, 0.05122171562045875, -0.24, 0.28, 0.91, 0.82, 1.65, 0.8, 2.54, 1.83, 1.92, 1.76, 1.08, -0.33, 2.92, 1.91, 2.78, 3.06, 1.33, 2.387335482087359, 2.0, 1.52, 1.59, -0.2, 0.6, 0.7, 0.09, -0.07, -0.74, -2.12, 1.07, 0.08, 0.93, 1.21, -0.49, 0.51, 0.17, -0.31, -0.23, 1.73, 1.68, 0.61, -0.15, -0.82, -2.21, 0.97, -0.01, 0.84, 1.12, -0.58, 0.448065468086443, 0.08, -0.4, -0.32, 1.4, -0.08, 1.43, 1.03, 0.76, -0.67, -2.06, 1.13, 0.15, 1.0, 1.28, -0.43, 0.58, 0.24, -0.24, -0.17, 0.8, 1.44, -1.4, 1.81, 0.83, 1.68, 1.96, 0.24, 1.26, 0.91, 0.43, 0.51, 0.94, 3.3, -3.29, 2.88, 3.26, 2.26, 3.13, 3.41, 1.67, 2.7, 2.35, 1.86, 1.93, -1.51, -0.2826334687834371, -0.97, -0.13, 0.14, -1.54, -0.55, -0.88, -1.36, -1.29, -0.13, -0.34, 2.46, 0.92, 0.82, 1.17, 0.61, 0.85, 1.13, -0.58, 0.43, 0.09, -0.39, -0.26141531611693436, 0.36, -0.24, 0.5236855802927234, -1.41, -0.42, -0.76, -1.23, -1.16, 0.97, 1.279561224489796, -0.41, 2.34, -4.36, -0.4, 0.07, -2.71, 2.63, 1.37, -0.2, 0.61, -2.2, -1.82, -0.89, -0.13, 0.07, 2.76, -2.77, -2.79, 0.93, -4.22, 1.82, 1.09, -0.8, 1.84, -8.55, -1.25, -1.9, 2.3, -0.51, -1.68, -0.69, -1.03, -1.5, -1.43, 2.76, 1.2, 1.01, 0.67, 0.19, 0.26, 0.18, -0.34, -0.82, -0.74, 0.78, 0.89, 0.52, -0.48, -0.4, 0.91, 1.0, 1.45, -5.81, 2.72, 5.46, 1.75, 0.29, 1.01, 0.07, 1.59, 1.56, 0.01, -0.79, 0.64, 0.93, 3.26, 0.28, 1.41], ['254', -1.08, 0.0, 0.13122171562045873, -0.11, -0.04, 0.9484196236737595, 2.82, 0.25, 0.8, -0.95, -1.66, -2.95, -0.9, -0.04, -1.01, 0.3, -2.31, -0.95, -0.5341378641200069, -1.37, -0.9, -2.01, -1.5, -1.97, -0.24, 0.54, 0.72, -1.31, 0.7714285714285715, 1.64, 0.66, 1.99, -0.66, 0.72, 0.96, 0.29, 0.77, -0.35, 0.16, -0.32, 0.81, 0.8649361992161734, 2.06, 2.11, 3.167875394446823, 2.0, 3.35, 0.66, 2.06, 2.31, 1.62, 2.11, 0.97, 1.5, 1.01, -0.19, 1.05, 0.15, 0.37, -0.05, 0.87, -0.1, 1.21, -1.42, -0.05, 0.3086780045351474, -0.48, 0.0, -1.11, -0.5972652545866831, -1.08, 0.64, -0.91, -0.96, 0.34, -2.27, -0.91, -0.67, -1.33, -0.86, -1.97, -1.46, -1.93, 0.79, 2.12, -2.18, 0.06, 1.31, -1.32, 0.06, 0.3, -0.37, 0.1, -1.01, -0.5, -0.97, -2.73, -1.24, -2.6, -1.24, -1.0, -1.67, -1.2, -2.3, -1.79, -2.26, 0.02, -1.25, 0.39, 0.8115981806829015, 0.74, 0.8656735186500321, 1.39, 1.39, 1.64, 0.96, 1.6157782534925393, 0.31, 0.83, 0.35, 0.97, 0.0, 0.24, -0.43, 0.05, -1.07, -0.55, -1.03, 0.98, 1.14, -0.12, 0.93, -8.11, 0.2, 0.03, -1.71, 1.74, 0.89, 1.25, 0.78, -0.77, -1.52, -0.76, -0.52, 0.51, 2.23, -2.42, -2.28, 0.77, -2.57, 1.56, -0.56, 0.26, 4.13, -0.68, -2.66, -4.09, 0.86, -0.24, -0.67, -0.2, -1.31, -0.79, -1.27, 2.3, 0.43, 0.48, -0.64, -0.12, -0.6, -0.05, -1.11, -0.6, -1.08, 0.77, 0.5, 1.08, 0.52, 0.04, 0.76, 0.81, 0.06257604962387836, -0.59, 0.7, 0.72, 0.42, 0.69, 0.56, -0.48, 1.18, 0.85, 0.34, 0.66, 0.66, 1.04, 0.42, 0.9, 0.73], ['255', -1.19, -0.12, 0.06, 0.26, 0.17, 0.63, -0.1, 1.07, 0.92, 0.61, 0.41, -1.07, -0.6160867348791511, -0.74, 0.08, 1.41, -0.4, 0.2, -0.29, 0.22, 0.88, -0.84, -0.09, -0.44, 2.45, 1.26, 0.19, -1.48, -1.09, -1.15, -0.33, 0.99, -0.81, -0.21, -0.7, -0.19, 0.46, -1.24, -0.5, -0.85, 1.17, 0.8749361992161734, 1.69, 0.3936589811608609, 0.49787539444682316, 1.16, 2.5, 0.67, 1.28, 0.79, 1.3, 1.97, 0.23, 0.99, 0.9508287981859411, 0.4, 1.46, -0.11, 0.75, 1.29, -0.06, 0.77, 2.1, 0.28, 0.89, 0.4, 0.91, 1.57, -0.16, 0.6, 0.25, -0.2, 1.35, 0.83, 2.16, 0.34, 0.95, 0.45, 0.97, 1.63, -0.1, 0.65, 0.3, 0.37, 2.35, -2.36, 0.52, 1.32, -0.49, 0.12, -0.37, 0.14, 0.8, -0.92, -0.17, -0.4659922724755494, -0.88, -0.79, -1.78, -1.19, -1.67, -1.17, -0.52, -2.21, -1.47, -1.82, 0.58, -0.81, 2.84, 0.73, 0.8, 0.7, 1.0109570400359875, 0.61, 0.12, 0.63, 1.29, -0.43, 0.32, 0.028584683883065676, 1.73, 0.4, -0.49, 0.02, 0.68, -1.04, -0.29, -0.64, 0.58, 0.71, 0.49, 1.19, -2.65, 0.88, 1.06, -1.27, 1.29, 0.64, 3.67, 1.3561635321120495, -0.7, -1.43, -0.74, -0.6, 0.81, 2.13, -2.2, -2.16, 0.72, -1.89, 1.43, -1.94, 1.0, 2.96, -4.49, -1.97, -2.98, 0.6738095238095239, 0.89, 0.51, 1.17, -0.55, 0.2, -0.15, 2.16, 0.38, 0.66, -1.06, -0.31, -0.66, -0.27, -1.6111214088935784, -0.96, -1.3, 0.87, 0.45, 1.45, 0.75, 0.4, 0.72, 0.79, 1.24, -2.97, 2.49111637918067, 2.9, 0.83, 0.71, 0.69, -0.27721314850306833, 0.84, 0.62, 0.59, 0.88, 0.77, 1.04, 0.73, 0.79, 1.06], ['256', -7.27, -1.02, -0.37, 0.21, -1.48, -1.52, -1.91, -3.6, -3.27, -4.18, 0.45, -3.2, -1.27, -0.59, -0.28, -2.25, -2.18, -3.35, -4.17, -2.46, -4.67, -3.09, -1.72, -2.63, -3.61, -2.76, -4.61, -3.63, -1.71, -1.04, -0.73, -2.69, -2.62, -3.78, -4.61, -2.9, -5.1, -3.53, -2.16, -3.07, -3.5, -4.755063800783826, -1.01, 1.99, 2.69, 3.01, 0.98, 1.05, -0.15, -1.01, 0.76, -1.491934531913557, 0.11, 1.53, 0.59, -2.03, -3.57, -2.68, -3.36, -2.95, 0.69, 1.0, -0.99, -0.92, -2.11, -2.95, -1.21, -3.45, -1.85, -0.46, -1.38, -3.32, -3.61, 0.31, -1.67, -1.6, -2.77, -3.61, -1.88, -4.11, -2.52, -1.14, -2.05, -4.56, -6.54, 6.47, -3.9, -1.97, -1.9, -3.07, -3.9, -1.996255228898086, -4.4, -2.82, -1.44, -2.35, -2.85, -1.97, 0.07, -1.0246649659863944, -1.97, -0.22, -2.48, -0.87, 0.54, -0.39, -1.11, -2.04, -2.78, -1.56, -1.72, -1.49, -2.04, -1.19, -2.04, -0.29, -2.55, -0.94, 0.47, -0.46, -1.2, -0.8069232518696328, -0.86, 0.92, -1.37, 0.26, 1.68, 0.74, -2.54, -2.5, -0.21, -1.88, -8.44, -0.98, -0.63, 2.16, -2.24, -1.12, -1.07, -5.74, 3.35, 3.03, 1.53, -3.64, -0.8, -4.78, 4.65, 4.67, -1.56, 3.32, -3.12, -2.53, 1.25, -6.04, 5.28, 4.1, 6.07, -3.2, 0.0, 1.79, -0.52, 1.13, 2.56, 1.61, -4.67, -1.76, -2.27, -0.65, 0.76, -0.17, 0.52, 1.65, 3.1, 2.14, -3.17, -3.81, -1.12, 1.42, 0.48, -1.4379199656859432, -1.62, -3.63, 6.82, -2.82, -6.95, -2.02, -1.92, -2.5, -0.93, -2.24, -0.9954471401614257, -0.78, -0.51, -1.42, -1.59, -2.66, -2.21, -1.32], ['257', -5.73, -0.83, -0.45, 0.1, -1.32, -1.69, -1.2458847420401709, -2.91, -2.54, -2.4, 0.27, -0.36, 0.55, 1.45, -0.22, -1.9, 0.33, -1.39, -3.76, -0.94, -3.5, -0.19, -0.09, -0.86, -3.15, -2.61, -2.66, -0.63, 0.28, 1.18, -0.48, -2.16, 0.07, -1.5327410958555914, -4.01, -1.2, -3.75, -0.46, -0.35, -1.12, -1.51, -3.8350638007838267, -2.05, 0.91, 1.82, 0.15, -1.54, 0.7, -1.03, -3.41, -0.57, -3.14, 0.17, 0.28, -0.5, -1.0, -2.7557142857142853, -3.76, -2.4, -2.93, 0.9, -0.76, -2.43, -0.21, -1.93, -3.990306689342404, -1.47, -4.02, -0.73, -0.63, -1.4, -3.9, -3.8, -1.65, -2.8633418367346937, -1.1, -2.8, -5.13, -2.35, -4.88, -1.62, -1.52, -2.28, -3.31, -6.68, 6.73, -2.19, -1.68, 0.55, -1.17, -3.55, -0.72, -3.28, 0.03, 0.13, -0.5859922724755494, -2.19, -0.51, 2.28, 0.52, -1.89, 0.98, -1.63, 1.74, 1.84, 1.06, -1.25, -0.53, -3.5198953488372093, -1.78, -1.83, -1.79, -2.73, -1.72, -4.08, -1.27, -3.82, -0.52, -0.42, -1.19, -2.13, -1.03, -2.4, 0.46, -2.14, 1.21, 1.32, 0.54, -2.89, -3.06, -0.54, -2.41, -4.28, -1.3, -1.1, 3.72, -3.59, -1.82, -1.84, -1.53, 2.93, 3.54, 1.8645476190476191, -2.89, -1.28, -5.52, 5.42, 5.34, -1.75, 5.49, -3.52, -1.78, 0.87, -8.16, 5.32, 5.52, 8.18, -3.0, 1.41, 2.93, 0.27, 3.7, 4.129638579674294, 3.01, -5.39, -1.48, -2.59, 0.75, 0.85, 0.08, 1.13, 3.42, 3.53, 2.8014285714285716, -2.57, -2.75, -2.21, 0.1, -0.67, -1.8, -1.94, -2.82, 2.69, -2.89, -2.68, -2.13, -2.56, -2.32, -0.77, -2.07, -2.02, -0.87, -1.39, -1.05, -1.56, -4.3, -3.9, -2.05], ['258', 1.72, 0.12, 0.73, 0.4, 0.21, 1.69, -0.18, 0.39, 1.69, -0.98, -3.69, -0.62, -1.3, -2.3, -1.0, 0.06856009070294794, -1.85, -0.92, -0.1, -2.12, -0.8426645179126411, -1.66, -1.05, -2.67, 0.84, 0.28, 2.8526583949931124, 3.18, 2.48, 1.44, 2.79, 3.5733503401360545, 1.91, 2.87, 3.72, 1.63, 2.9844536700785693, 2.11, 2.74, 1.06, 1.07, 3.2349361992161736, -0.35, -0.68, -1.68, -0.38, 0.46052947845804987, -1.23, -0.3, 0.52, -1.51, -0.23193453191355703, -1.04, -0.43, -2.06, 0.42, 1.66, -0.98, 2.4, 0.33, -1.01, 0.3, 1.27, -0.56, 0.38, 1.21, -0.83, 0.42, -0.36, 0.25, -1.39, -1.42, 1.35, 1.33, 2.1, 0.46, 1.41, 2.25, 0.18, 1.45, 0.66, 1.28, -0.38, 3.42, 0.21, -0.27, 0.03, 0.76, -0.85, 0.08, 0.91, -1.13, 0.12, -0.66, -0.05, -1.69, -1.04, -0.73, -1.6, -0.67, 0.15, -1.88, -0.63, -1.41, -0.8, -2.43, -0.21, -0.81, 0.95, 1.27, 0.93, 1.59, 0.89, 0.94, 1.8869325674325674, -0.28, 1.1557782534925394, 0.19, 0.81, -0.84, 0.53, -0.05, 0.83, -1.21, 0.04, -0.74, -0.13, -1.76, -0.78, -1.71, 0.77, 0.79, -2.44, 1.44, 0.73, -2.78, 2.67, 1.34, 0.51, 1.11, -2.3222410208838777, -2.61, -1.3, 0.82, 0.92, 3.67, -3.78, -3.77, 1.24, -4.32, 2.46, -3.33, 1.8, 2.46, -4.47, -1.82, -2.84, 2.45, -0.87, -2.0151904761904764, -0.78, -1.56, -0.95, -2.57, 3.7, 1.17, 1.27, 0.47, 1.09, -0.56, -0.09, -0.78, -0.17, -1.8, 1.85, 2.32, 0.69, 0.62, -1.03, 1.29, 1.2, 0.26, -2.25, 1.85, 2.27, 1.2, 1.49, 0.08, -1.5672131485030683, 2.27, 1.06, 1.48, 0.18, 1.444626243824729, 1.74, 1.48, 1.22, 0.7], ['259', -0.46, 0.26, 0.16, 0.06, 0.48, 0.61, 0.6941152579598292, 1.23, 0.29, 0.11, -0.13, -0.54, -1.35, -0.69, -1.08, 0.58, 0.09, 0.06, -1.97, -1.29, 0.15, -0.64, -0.38, -0.17, 0.11, 0.43, 0.27265839499311245, -0.41, -1.23, -0.56, -0.95, 0.72, 0.22, 0.30725890414440843, -1.84, -1.16, 0.28, -0.51, -0.25, -0.04, 1.47, -1.25, 0.66, -0.82, -0.15, -0.55, 1.13, 0.63, 0.61, -1.44, -0.75, 0.69, -0.1, 0.16, 0.37, 1.23, 1.06, 1.03, 0.17, 1.49, 0.68, 0.28, 1.96, 1.47, 1.44, -0.62, 0.07, 1.52, 0.72, 0.99, 1.2, 1.39, 0.8, -0.3853571428571429, 1.28, 0.78, 0.76, -1.29, -0.61, 0.84, 0.04, 0.31, 0.52, -0.14, 1.5, -1.5, 1.2466982383853202, 1.68, 1.19, 1.16, -0.89, -0.21, 1.24, 0.44, 0.71, 0.92, -1.22, -0.47, -0.49, -0.52, -2.54, -1.86, -0.43, -1.22, -0.96, -0.75, 0.12, -0.45, -0.33, 0.58, 0.58517906963434, 0.59, 0.02, -0.03, -2.06, -1.3794642857142856, 0.06, -0.74, -0.47, -0.20141531611693433, 0.69, 0.05, -2.03, -1.35, 0.08, -0.71, -0.45, -0.24, 0.3, 0.11, 0.02, 0.33, -3.64, 0.05, 0.04, -0.87, 0.9, 0.48, 0.72, -0.33, -2.8, -1.16, -0.61, -0.22, 0.68, 1.79, -1.85, -1.79, 0.58, -1.46, 1.16, -0.27, 0.14, 0.12, -3.6, -0.09, -0.1, 2.84, 2.12, 0.69, 2.166609977324263, 1.35, 1.62, 1.83, 1.913167899560757, 1.42, 1.45, 0.65, 0.92, 1.13, -0.04, -0.79, -0.53, -0.32, 0.29, 0.19, 0.76, 0.26, 0.48, 0.59, 0.57, 1.07, -1.98, 0.0, 2.15, 0.41, 0.8, 0.5, 0.21, 0.41, 0.58, 0.76, 0.68, 1.05, 0.29, -0.35, 0.85, -0.33], ['260', -3.6, -0.96, 0.04, 0.04, -1.18, -0.75, -0.63, -1.7382794034640414, -0.99, -2.15, -0.63, -2.0, -0.9860867348791511, -0.04, -0.4, -0.86, -1.06, -1.67, -2.43, -0.36, -2.21, -1.29, -1.87, -1.17, -0.56, -1.29, -1.4973416050068875, -1.38, -0.42, 0.6, 0.24, -0.22, -0.43, -1.04, -1.81, 0.27, -1.58, -0.66, -1.25, -0.54, -1.2525315746467893, -0.74, -0.15, 0.97, 2.0, 1.64, 1.17, 0.96, 0.34, -0.438347866419295, 1.67, -0.20034527076293904, 0.73, 0.14, 0.85, -1.08, -0.4, -0.36, -1.74, -1.11, 1.02, 0.66, 0.2, -0.01, -0.62, -1.39, 0.7, -1.17, -0.24, -0.83, -0.12, -1.14, -2.11, -0.36, -0.81, -1.02, -1.63, -2.39, -0.32, -2.17, -1.25, -1.83, -1.13, -1.4, -1.02, 1.03, -1.759129077338006, -0.46, -0.67, -1.27, -2.04, 0.03, -1.82, -0.9, -1.48, -0.77, -2.02, -1.31, -0.21, -0.82, -1.59, 0.5, -1.36, -0.44, -1.02, -0.31, -0.37, -1.4, 0.13, -0.82, -0.81, -0.9, -1.1, -0.61, -1.38, 0.9097126881055455, -0.9842217465074605, -0.23, -0.82, -0.051415316116934326, -0.85, -0.49, -0.78, 1.33, -0.55, 0.38, -0.21, 0.51, 0.4418280382942037, 0.35, -0.21, -1.04, -6.03, -0.01, -0.01, 1.54, -1.51, -0.74, -0.09, -3.42, 3.42, 1.73, 0.79, -1.77, -0.686920210131221, -2.57, 2.56, 2.38, -0.83, 2.39, -1.65, 0.15, -0.025234735715753215, -3.22, 16.43, 2.14, 3.26, -3.49, 0.29, 2.12, 0.23, 1.17, 0.58, 1.3, -2.51, -1.79, -1.85, -0.93, -1.51, -0.81, 0.06, 0.94, 0.34, 1.06, -0.98, -1.27, -0.87, -0.59, 0.12, -0.84, -0.8856036987247091, -1.71, 7.56, -0.51, -7.100719387755102, -1.82, -1.68, -0.28, 0.72, -1.54, -0.62, -0.35, -1.03, -0.56, -0.99, -2.3, -2.67, -1.41], ['261', -0.15, 0.18, 0.15122171562045875, -0.08, 0.06297908099105959, 0.47, -1.1458847420401708, 0.46, 0.58, 1.09, 0.2, 1.54, 1.1, 0.65, 0.6, 1.15, 0.59, 0.69, 2.03, 0.48, 1.497335482087359, 0.46, 0.24, 0.69, 0.25, 0.57, 0.88, 1.3305454545454547, 0.89, 0.45, 0.4578199712950912, 0.95, 0.38, 0.48, 1.82, 0.28, 1.25, 0.25, 0.03, 0.48, 0.25, 1.5, -0.44, -0.43, -0.87, -0.92, -0.38, -0.93, -0.83, 0.48, -1.04, -0.08, -1.06, -1.28, -0.84, 0.48, 0.43, 0.44, 0.93, -0.01, -0.44, -0.3751532320595474, 0.06, -0.5, -0.4, 0.92, -0.6, 0.36, -0.63, -0.85, -0.4, 0.24, 0.43, -0.05, 0.5, -0.07, 0.04, 1.36, -0.17, 0.8, -0.19, -0.42, 0.08355964172512072, 1.49, 2.18, -2.1, 0.48, 0.55, -0.02, 0.08, 1.41, -0.12, 0.85, -0.15, -0.37, 0.08, 0.55, -0.07, -0.56, -0.46, 0.86, -0.66, 0.3, -0.69, -0.91, -0.46, 0.25, -0.14, 4.1, 0.26, 0.56517906963434, 0.04567351865003196, 0.5, 0.1, 1.43, 0.09971268810554554, 0.86, -0.06969498055271243, -0.35, 0.1, 0.51, 0.39, 1.5836855802927234, -0.2, 0.76, -0.23, -0.45, 0.0, 0.74, 0.56, -0.18, 0.38, 1.56, 0.09, 0.06, 0.44, -0.47, -0.24, 0.53, 0.16, -1.19, -0.52, -0.27, -0.07, 0.19, 0.74, -0.72, -0.77, 0.30329080486385296, 0.7, 0.5, 0.62, -0.32, 1.44, -2.37, -1.02, -1.31, 1.16, -0.92, -1.51, -0.56, -1.54, -1.76, -1.31, 0.7508051948051948, 0.6, 0.97, -0.03, -0.25, 0.2, -0.36, -0.98, -1.2, -0.76, 0.61, 1.12, 0.62, -0.22, 0.23, 0.27, 0.26, 0.34, -0.91, 3.06, 0.88, 0.15, 0.36, 0.85, 0.45, 0.49, -0.07, -0.01, 0.34, 0.15462624382472906, 0.4, 0.7, -0.47, 0.0], ['262', -0.8, -0.03, -0.05, -0.01, -0.45, -0.42, -0.44, -0.1, 0.3, 0.0, -0.66, 0.5593248299319729, 0.29, 0.28, 0.28, 0.17, 0.13, 0.01, -1.24, 0.06, 0.17, -0.42, -0.13, 0.34, -0.46, -0.1, 0.66, 1.21, 0.9708333333333333, 0.94, 0.95, 0.84, 0.79, 0.67, -0.59, 0.72, 0.83, 0.24, 0.53, 1.01, -0.16, 1.04, -0.55, -0.2563410188391391, -0.27, -0.26, -0.37, -0.42, -0.53, -1.78, -0.49, -0.37, -0.96, -0.67, -0.20495238095238094, 0.54, -0.07, 0.04, 0.06, -0.29, -0.01, 0.0, -0.11, -0.16, -0.27, -1.52, -0.23, -0.11, -0.7, -0.41, 0.05, -0.67, -0.27, 0.01, -0.1, -0.14, -0.26, -1.51, -0.22, -0.1, -0.69, -0.4, 0.07, 0.82, 0.33174294752866196, -0.17, -0.28, -0.11, -0.15, -0.27, -1.52, -0.23, -0.11, -0.7, -0.41, 0.06, -0.98, -0.17, -0.04, -0.16, -1.41, -0.12, 0.06262653735269351, -0.59, -0.3, 0.17, 0.1, -0.17, 0.41, -0.14, 0.0, -0.21, -0.13, -0.12, -1.37, -0.07, 0.04, -0.55, -0.26, 0.26858468388306567, 0.5, -0.01, -1.25, 0.05, 0.16, -0.43, -0.14, 0.33, 0.13, 0.14, 0.02, 0.22, -2.79, 0.05, -0.01, 0.36, -0.4, -0.19, 0.66, 0.07, 0.17, 0.35, 0.2, -0.39, 0.02, -0.45, 0.53, 0.49, -0.15, 0.57, -0.39, 0.05, -0.02, -0.39, 1.3, 0.11, 0.34, -0.14, 1.25, 1.31, 1.43, 0.83, 1.12, 1.6, -0.56, -0.06, 0.11, -0.48, -0.19, 0.28, -0.17, -0.59, -0.3, 0.17, 0.18, 0.5, 0.42, 0.29, 0.76, -0.16, -0.14, -0.19, 0.68, 0.0, -0.77, -0.87, -0.2, 0.13, 0.47, -0.26, -0.26, -0.21, 0.17, 0.2, -0.34, -1.08, 0.14, -0.64], ['263', -0.06, 0.04, 0.00015289830927053559, -0.09, 0.0, 0.22, 0.57, -0.38, -0.1, -0.84, -0.79, -1.32, -0.4, 1.14, -0.54, -0.47, -1.49, -1.01, -2.51, 0.06, -1.02, -1.0, -1.2, -1.42, 0.02, -0.05, -0.017341605006887542, -0.53, 0.39, 2.09318993704708, 0.25, 0.32, -0.71, -0.22, -1.73, 0.85, -0.23, -0.21, -0.41, -0.63, 0.2, -0.09, 0.49, 0.93, 2.5, 0.79, 0.86, -0.17, 0.31, -1.2, 1.4, 0.31, 0.32, 0.12, -0.1, -0.27, 0.69, 0.16, -0.12, -0.43, 1.6531047225355606, -0.14, -0.07, -1.09, -0.61, -2.11, 0.46, -0.62, -0.6, -0.8, -1.02, 0.76, -1.96, -1.67, -1.6, -2.6, -2.13, -3.61, -1.07, -2.14, -2.12, -2.31, -2.53, -0.46, 1.02, -0.96, -0.3, 0.07, -0.96, -0.47, -1.98, 0.6, -0.48, -0.46, -0.66, -0.88, -0.55, -0.36, -1.02, -0.54, -2.04, 0.53, -0.55, -0.53, -0.73, -0.95, 0.11, -0.31, 0.84, 0.28, 0.3, 0.24, 0.66, 0.4913469387755102, -1.03, 1.57, 0.48, 0.5, 0.3, 0.07, 0.2, 0.18, -1.51, 1.08, -0.01, 0.01, -0.19, -0.41, 0.89, 0.97, -0.25, 0.23, -1.4, 0.19, 0.06, -0.5, 0.48, 0.26, 0.6, -0.94, 1.57, -0.5, -0.24, -0.05, 0.25, 0.7914761904761906, -0.86, -0.84, 0.29, -0.71, 0.56, 1.0, -0.49, 1.96, -2.68, -1.18, -2.0, -1.66, 1.71, 2.63, 1.53, 1.55, 1.35, 1.12, 0.84, -0.89, -1.08, -1.06, -1.25, -1.48, 0.18, 0.02, -0.18, -0.41, -0.07, -0.22, 0.16, -0.2, -0.42, 0.3620800343140569, 0.33, -0.32, -1.81, 0.86, 1.81, 0.51, -0.44, 0.36, -0.23, 0.22, 0.42, 0.06, 0.01, 0.65, 0.675957527023814, -0.46, -0.52, 0.62], ['264', -3.75, -0.57, -0.22877828437954126, -0.34, -0.34, -0.03, -2.21, -1.33, -1.58, -2.004642857142857, -0.939391156462585, -0.15, -2.23, 0.58, -0.40285714285714286, -0.64, -2.02, -1.53, -1.47, -1.47, -2.54, -1.5, -1.635694768399324, -2.2, -1.64, -0.93, -1.0973416050068874, 0.81, -1.29, 1.55, 0.54, 0.31, -1.08, -0.59, -0.53, -0.53, -1.61, -0.56, -0.79, -1.27, -0.6, -1.9, -1.92, -2.08, 0.73, -0.27, -0.49, -1.87, -1.38, -1.2228644435138796, -1.33, -2.39, -1.36, -1.58, -2.06, -0.74, -2.03, -0.29, -1.31, 0.16, 2.88, 1.85, 1.62, 0.21, 0.72, 0.770952380952381, 0.77, -0.32, 0.74, 0.51, 0.02, -0.58, -2.64, -0.99, -1.22, -2.59, -2.1, -2.04, -2.05, -3.1, -2.08, -2.3, -2.77, -1.71, -1.01, 0.98, -1.66, -0.23, -1.61, -1.12, -1.06, -1.06, -2.13, -1.09, -1.31, -1.8, -2.23, -1.43, -1.38, -0.89, -0.83, -0.84, -1.91, -0.87, -1.09, -1.57, -0.58, -1.38, -0.04, -0.16, -0.27, 0.055673518650031964, -0.05, 0.5, 0.56, 0.55, -0.53, 0.52, 0.3, -0.19, -0.5, -0.55, 0.06, 0.05, -1.03, 0.02, -0.2, -0.69, -0.38, -0.36, -0.6, 0.08, -6.66, -0.52, -0.47, -0.13, 0.16246232339089484, 0.11881017100762112, -1.5, -1.85, 1.16, 0.37, 0.19, -1.87, -0.036920210131220946, -0.48, 0.58, 0.52, -0.16, -0.19, -0.34, 2.13, -1.02, -0.14, 0.38, 0.11, 0.18, -1.19, -0.6, 0.0, -1.08, -0.03, -0.26, -0.74, -0.55, -0.6, -1.08, -0.03, -0.25, -0.74, 0.48, 1.06, 0.83, 0.34, -1.57, -1.55, -0.57, -0.22, -0.71, -0.18, -0.15, -1.2874239503761218, 0.27, 0.42, -0.26, -0.35, -0.4989064979199875, -0.35, -0.49, 0.3, 0.19, -0.83, 0.55, -0.445373756175271, 0.14, -1.09, -0.57, 0.69], ['265', 4.4, -1.33, -0.08, 0.23, 0.78, -1.25, -3.27, -1.87, -2.29, -0.86, 1.95, 0.47, -0.43, 1.74, 1.46, -1.64, 0.63, -0.66, -2.73, 0.51, -1.08, 0.6, 1.29, 0.58, -2.13, -1.38, -2.76, -1.45, -2.33, -0.2, -0.48, -3.52, -1.29, -2.56, -4.59, -1.41, -2.895546329921431, -1.33, -0.64, -1.34, -1.56, -4.855063800783826, -1.33, -0.9, 1.27, 0.99, -2.1, 0.16, -1.12, -3.19, 0.04071428571428572, -1.511934531913557, 0.12, 0.82, 0.11, -0.89, -1.69, -2.05, -1.69, -0.43, 2.18, 1.9, -1.21, 1.06, -0.23, -2.31, 0.94, -0.65, 1.03, 1.73, 1.01, -3.28, -2.56, -0.28, -3.32, -1.09, -1.9206972789115644, -4.4, -1.21, -2.78, -1.13, -0.44, -1.15, -3.33, -5.71, 5.69, -2.29, -3.05, -0.82, -2.09, -4.13, -0.94, -2.5, -0.85, -0.17, -0.87, 1.52, 0.79, 2.31, 1.0, -1.11, 2.18, 0.57, 2.27, 3.121108978323264, 2.25, -0.27, 0.78, -1.05, -1.6, -1.66, -1.55, -1.48, -1.28, -3.34, -0.12, -1.7, -0.03, 0.66, 0.008584683883065672, -0.66, -0.2, -2.09, 1.17, -0.42, 1.26, 1.96, 1.24, -2.36, -1.81, 0.2, -1.89, 4.69, 0.03, -0.14, 3.75, -3.71, -1.86, -0.37, -1.57, 2.96, 3.19, 1.61, 2.18, -0.74, -4.9, 4.99, 4.81, -1.6, 5.51, -3.2, -2.7, 1.32, -4.4, 7.27, 2.88, 4.38, -2.85, 1.92, 3.33, 1.7, 3.42, 4.14, 3.4, -4.78, -1.36, -1.58, 0.09, 0.78, 0.07, 0.22, 1.69, 2.4, 1.68, -2.21, -2.72, -1.45, 0.69, -0.02, -2.17, -2.12, -1.79, 7.19, -1.36, -6.3186904761904765, -1.26, -2.57, -2.13, -0.71, -1.73, -1.9, -0.63, -0.32, -1.16, -1.43, -2.44, -2.91, -1.61], ['266', 3.93, 0.24, 0.13122171562045873, 0.04, 0.36, 0.03, 0.76, 0.1, -0.09, 1.68, 1.4, 1.07, 1.61, 1.53, 1.01, 1.39, 1.8, 1.78, -0.45, 1.8, 1.807335482087359, 1.54, 2.2843052316006762, 1.54, -0.07, 0.07, 0.3126583949931125, -0.33, 0.21, 0.13, -0.3321800287049088, -0.01, 0.39, 0.4872589041444084, -1.82, 0.4, 0.37, 0.14, 0.78, 0.14, -0.2, -0.98, 0.61, 0.54, 0.46, -0.06, 0.32, 0.72, 0.7, -1.5, 0.73, 0.7280654680864429, 0.47, 1.11, 0.47, -0.33, -0.88, -0.51, -0.54, 0.07, -0.08, -0.6, -0.22, 0.18, 0.16, -2.03, 0.19, 0.16, -0.07, 0.57, -0.07, -0.27, 0.15, -0.52, -0.14, 0.26, 0.24, -1.95, 0.26, 0.24, 0.01, 0.65, 0.0, -0.18, -0.99, 1.14, 0.7066982383853202, 0.38, 0.78, 0.76, -1.44, 0.79, 0.76, 0.53, 1.17, 0.53, 0.48, 0.29, 0.4, 0.38, -1.81, 0.4, 0.38, 0.15, 0.79, 0.14, -0.11, 0.25, -0.68, -0.2184018193170985, -0.08, -0.36, -0.11, -0.02, -2.2, 0.0, -0.02, -0.25, 0.38, -0.26, 0.02, -0.09, -2.18, 0.11224471370562701, 0.0, -0.23, 0.41, -0.23, 0.04, 0.28, -0.06, -0.01, 1.67, -0.1, -0.07, 1.44, -1.47, -0.6911898289923789, -0.34, 0.74, 0.18, 0.53, 0.27, 1.92, 0.12, -0.84, 0.72, 0.82, -0.27, 2.18, -0.55, 0.12, -0.07, -0.31, -1.3, 0.24, 0.33, -0.2, 2.14, 2.26, 2.23, 2.0, 2.65, 1.99, -0.7168321004392431, -0.12, -0.03, -0.25, 0.38, -0.26, -0.09, -0.23, 0.41, -0.23, -0.06, -0.28, 0.13, 0.63, 0.06224875531501633, -0.25, -0.23, 0.19, -0.57, -0.36, 0.65, -0.03, -0.33, -0.5, -0.64, 0.09, -1.0, 0.33, -0.01, 0.22, 0.14, -0.6, -0.16, -0.05], ['267', -2.43, -0.79, 0.15, 0.26, -0.7, -1.27, -1.1758847420401708, -1.75, -1.94, -1.62, 1.62, -0.68, -1.3, 0.19, -0.16, -0.77, -0.77, -1.32, 5.65, 0.07, -1.92, -0.99, 0.03, -1.3178253968253968, -0.7214063389924734, -0.99, -3.18, -2.26, -2.87, -1.41, -1.75, -2.35, -2.35, -2.89, 3.97, -1.52, -3.48, -2.57, -1.57, -2.89, -0.8125315746467892, -5.31, -0.95, -0.63, 0.87, 0.52, -0.09, -0.09, -0.65, 6.37, 0.75, -1.25, -0.32, 0.71, -0.65, -0.8499371536943234, -0.99, -1.07, -1.49, -0.32, 1.51, 1.15, 0.54, 0.54, -0.02, 7.040952380952381, 1.39, -0.63, 0.31, 1.34, -0.02, -2.6, -1.8, -0.35, -0.95, -0.96, -1.51, 5.45, -0.12, -2.1, -1.18, -0.16, -1.51, -3.79, -4.41, 4.422833333333334, -1.46, -0.61, -0.61, -1.16, 5.83, 0.23, -1.76, -0.83, 0.19, -1.16, 0.54, -0.86, 0.0, -0.56, 6.47, 0.84, -1.16, -0.23, 0.8, -0.56, -0.53, -0.84, 1.19, -1.29, -1.53, -1.04, -0.85, -0.55, 6.47, 0.85, -1.16, -0.22, 0.8, -0.56, -0.64, -0.3, 7.07, 1.41, -0.61, 0.33, 1.36, 0.0, -1.9, -1.68, 0.13, -1.21, 2.12, -0.01, 0.0, 1.74, -1.75, -0.88, -0.61, -1.98, 3.2, 2.58, 1.34, -1.21, -1.18, -3.92, 3.9, 4.0, -1.28, 2.61, -2.61, -1.9, 0.94, -2.62, 5.18, 1.74, 2.6, -3.2, -6.88, -5.29, -7.17, -6.29, -5.33, -6.6, -3.98, -1.69, -1.99, -1.06, -0.04, -1.39, 0.756501700680272, 0.94, 1.98, 0.61, -1.83, -2.46, -0.63, 1.03, -0.33, -1.29, -1.23, -1.72, 2.55, -0.04, -2.45, -1.92, -2.39, -1.64, -1.2772131485030684, -1.26, -1.1297802197802196, -1.02, -1.23, -1.35, -0.3, -2.74, -4.03, -1.3], ['268', 0.39, -0.19, 0.04, 0.19, -0.19702091900894042, -0.27, -0.41, -0.17, -0.48, 0.12, 0.32, 0.71, -0.12, -0.4, 0.39, -0.37, -0.06, 0.11, 5.8, 0.83, -0.41, -0.34, -0.56, 0.06, 0.45, -0.51, -0.2, 0.39, -0.44, -0.72, 0.07, -0.68, -0.38, -0.21, 5.46, 0.51, -0.72, -0.66, -0.88, -0.26, -0.32, -0.05506380078382657, -0.59, -0.82, -1.1, -0.31, -1.07, -0.76, -0.6, 5.06, 0.13, -1.11, -1.04, -1.26, -0.65, -0.71, 0.0, -0.07, -1.25, 0.24, -0.28, 0.51, -0.25, 0.06, 0.23, 5.93, 0.96, -0.29, -0.22, -0.44, 0.18, -1.11, 0.52, 0.79, 0.03, 0.34, 0.51, 6.22, 1.24, -0.01, 0.06, -0.16, 0.46, -0.46, 1.59, -1.58, -0.27, -0.76, -0.45, -0.28, 5.39, 0.44, -0.8, -0.73, -0.95, -0.33, -0.43738095238095237, 0.49, 0.31, 0.48, 6.19, 1.21, -0.04, 0.03, -0.19, 0.43, -0.07, 0.44, 3.82, -0.11, 0.08, -0.2, 0.18, 0.17, 5.86, 0.89, -0.35, -0.28, -0.5, 0.12, 0.63, 0.01, 5.69, 0.73, -0.51, -0.45, -0.67, -0.05, 0.07, -0.29, 0.09, 0.06, -0.87, 0.08, -0.27, -0.14, 0.19, 0.07, 0.09, -0.14, 1.33, 0.22, 0.1, 0.15, -0.31, -0.26, 0.27, 0.33, -0.1, -0.17, -0.22, -2.43, 1.19, 0.51, 2.46, -0.31, -0.55, -1.28, -5.37, -4.69, -5.87, -5.8, -6.01, -5.43, -0.38, -0.71, -1.23, -1.16, -1.38, -0.77, 0.53, 0.07, -0.15, 0.47, -0.54, -0.7815464535464534, 0.46, -0.22, 0.4, -0.1, -0.03, -0.14, 1.24, 1.8, -1.33, 0.96, -1.49, 0.68, 0.6927868514969316, 0.12, 0.12, -0.61, -0.47, -0.05537375617527095, 0.06, 0.32, -1.73, -0.34], ['269', -13.632857142857144, -0.43, -0.41877828437954123, -0.1, -1.96, -0.76, 0.21, -2.13, -0.77, -2.3, -1.21, -3.03, 0.08, -0.2, 0.87, 0.26071428571428573, 0.17, -1.4294285714285713, -0.89, 0.08, -2.52, -1.18, -0.88, -1.47, -1.93, -2.3, -1.1, -1.84, 1.3, 1.02, 2.11, 1.48, 1.4014285714285712, -0.22, 0.33, 1.31, -1.33, 0.03, 0.33, -0.26, -4.05, -0.5, 0.76, 3.2, 2.92, 4.02, 3.39, 3.3, 1.65, 2.21, 3.21, 0.53, 1.9, 2.22, 1.61, -1.68, -3.1657142857142855, -1.62, -1.49, -2.37, -0.27, 0.79, 0.43142857142857144, 0.09, -1.5, -0.96, 0.01, -2.59, -1.26, -0.96, -1.54, -2.66, -2.1, 1.07, 0.45, 0.37, -1.23, -0.69, 0.28, -2.33, -0.99, -0.69, -1.27, -0.73, -4.21, 4.14, -3.14, -0.61, -0.69, -2.28, -1.74, -0.78, -3.36, -2.04, -1.74, -2.32, -3.29, -2.55, 0.5385714285714286, -1.68, -1.14, -0.17, -2.77, -1.44, -1.14, -1.72, -0.82, -2.54, -2.46, -1.19, -1.3, -1.34, -2.46, -1.6, -1.06, -0.09, -2.68, -1.35, -1.05, -1.64, -1.09, -0.88, 0.55, 1.53, -1.11, 0.25, 0.6328571428571429, -0.04, -1.64, -2.43, -0.24396282112195955, -2.45, -6.49, -0.33967687074829933, -0.22428571428571428, 1.49, -1.43, -0.74, -0.63, -3.76, 4.55, 2.49, 1.19, -6.488561224489796, -0.38, -3.95, 3.97, 3.58, -1.23, 2.18, -2.41, 0.29, -0.08, -7.29, 6.623125850340137, 4.87, 7.23, -4.75, -1.42, 0.98, -1.64, -0.3, 0.01, -0.59, -3.45, -2.38, -2.6, -1.27, -0.96, -1.55, 0.23, 1.37, 1.68, 1.08, -0.74, -1.04, -1.13, 0.31, -0.29, -1.19, -1.41, -2.04, 3.25, -2.56, -3.1, -3.84, -2.09, -1.43, -0.5172131485030683, -1.71, -0.69, -1.06, -0.27, -1.02, -0.84, -5.84, -3.81, -1.9], ['270', -8.31, 0.04, -0.08, 0.0, -1.74, -0.5, -0.22, -0.45, -0.7, 0.22, 1.0, 0.8293248299319728, -0.4, 0.81, 0.4, 2.38, 1.27, 0.14, 3.97, 2.39, -0.47, -0.89, 0.37, -0.38, -1.02, -0.56, -0.78, -0.18, -1.39, -0.19, -0.59, 1.3633503401360545, 0.27, -0.85, 2.94, 1.37, -1.45, -1.87, -0.62, -1.37, 0.0, -1.57, -0.6, -1.21, -0.01, -0.42, 1.7842665945165948, 0.45, -0.68, 3.12, 1.55, -1.28, -1.7, -0.4157142857142857, -1.19, -1.28, -0.75, -1.06, -0.73, 0.62, 1.22, 0.81, 2.79, 1.68, 0.54, 4.39, 2.8, -0.06, -0.49, 0.78, 0.02, 0.03, -0.59, -0.4, 1.56, 0.46, -0.67, 3.14, 1.56, -1.26, -1.68, -0.43, -1.18, -0.71, -0.28, 0.19, -0.19, 1.97, 1.2999013605442178, -0.26, 3.55, 1.98, -0.86, -1.28, -0.03, -0.78, -3.48, -2.11, -1.08, -2.19, 1.55, 0.01, -2.78, -3.19, -1.96, -2.7, 0.03, -2.11, -1.17, -0.36, -0.38482093036566006, -0.34, -1.04, -1.12, 2.66, 1.1, -1.72, -2.13, -0.89, -1.63, 0.9, 0.08, 3.83, 2.24, -0.6, -0.8942004503433073, 0.23, -0.52, -0.42, -0.74, -0.07, -0.99, -10.48, -0.05, 0.04, 0.67, -0.71, -0.33, -0.56, -0.64, 4.02, 0.76, 0.32, -4.15, -0.11, -1.08, 0.97, 1.1, -0.37, 1.08, -0.76, 0.44, -0.21, -3.12, -2.93, 1.98, 3.09, -4.02, -3.61, -1.52, -4.27, -4.67, -3.46, -4.19, -0.9268321004392431, -2.12, -2.79, -3.2, -1.97, -2.7, 0.7444897959183674, -0.42, 0.84, 0.08, -0.62, -0.67, 1.11, 1.27, 0.51, -0.34, -0.48, -0.44, -0.03, -0.85, 0.06, -1.44, -1.44, -0.16, -0.75, -0.4, -0.55, 0.0, -0.47, -0.05, 0.6, -3.1, -1.47, -0.5], ['271', 3.11, 0.05, -0.028778284379541254, 0.28, -0.41, -0.64, 1.0641152579598292, -0.86, -0.75, 0.0, 1.56, -0.46, -0.22, -0.63, 2.0, -1.62, 0.63, -0.01, -4.37, 0.75, 0.3473354820873589, -0.06, 0.87, 0.97, -1.72, -1.05, -1.54, -1.99, -1.75, -2.16, 0.43, -3.13, -0.91, -1.54, -5.84, -0.8, -1.23, -1.59, -0.68, -0.58, -2.92, 0.68, 0.46, 0.24, -0.18, 2.47, -1.148956349206349, 1.1, 0.45, -3.93, 1.6496666666666666, 0.77, 0.4, 1.33, 1.7508287981859412, 0.95, -0.52, -0.9, -0.74, 0.22, -0.42, 2.22, -1.4, 0.85, 0.21, -4.16, 0.97, 0.53, 0.16, 1.09, 1.19, -2.51, 0.64, 2.65, -0.9892857142857143, 1.28, 0.63, -3.75, 1.4, 0.95, 0.58, 1.51, 1.62, -1.06, -2.52, 2.51, -1.96, -3.55, -1.34, -1.97, -6.24, -1.22, -1.65, -2.01, -1.11, -1.0, -0.17, 1.64, 2.29, 1.64, -2.79, 2.41, 1.96, 1.59, 2.53, 2.63, -0.09, 1.68, -0.26, -0.82, -0.71, -0.9, -0.63, -0.64, -4.97, 0.12, -0.32, -0.69, 0.23, 0.34, -0.14, 0.01, -4.36, 0.76, 0.32, -0.05, 0.88, 0.98, -0.75, -0.46, 0.46, -0.59, -0.5090476190476191, 0.0, -0.07, 2.58, -2.57, -1.26, 0.11, -0.9138364678879505, 1.52, 1.66, 0.83, 1.58, -0.31692021013122096, -2.46, 2.41, 2.47, -0.82, 3.95, -1.64, -5.03, 2.5, -1.82, 4.687380952380952, 1.25, 1.8, -1.6161904761904764, 4.56, 5.35, 4.89, 4.51, 5.47, 5.58, -2.52, -0.75, -0.44, -0.8, 0.12, 0.22, -0.31, -0.37, 0.56, 0.66, -0.71, -0.89, 0.06, 0.93, 1.03, -0.8, -0.77, -0.77, 3.24, -0.49, -3.23, -0.73, -0.16, -0.86, 0.1, -0.71, -1.18, -0.78, 0.1, -0.77, -0.97, -0.23, 0.94, -0.7], ['272', -1.72, 0.53, 0.09122171562045875, -0.24, -0.94, 0.3, 0.7, -0.22, 0.17, -1.84, -2.08, -1.95, -1.75, -0.79, -1.54, -0.86, -1.64, -1.9597942176870748, -4.39, -0.63, -2.53, -2.1440578231292515, -3.1, -2.59, -0.28, -0.04, 0.27265839499311245, 0.13, 0.33, 1.32, 0.56, 1.25, 0.45, 0.09, -2.36, 1.49, -0.46, -0.18, -1.04, -0.52, -0.62, 1.2349361992161734, 0.11, 0.2, 1.19, 0.42, 1.12, 0.32, -0.04, -2.48, 1.35, -0.59, -0.32, -1.17, -0.66, 0.22, 0.55, 0.08, 0.19, -0.09, 0.99, 0.22, 0.92, 0.12, -0.24, -2.571321995464853, 1.15, -0.79, -0.52, -1.37, -0.85, 0.4736060011417156, -1.06, -0.76, -0.07, -0.86, -1.22, -3.63, 0.16, -1.76, -1.49, -2.33, -1.82, 0.25, 3.59, -3.59, -0.31, 0.6905204081632652, -0.1, -0.47, -2.9, 0.92, -1.01, -0.74, -1.58, -1.07, -0.16, -1.0, -0.79, -1.15, -3.56, 0.23, -1.69, -1.42, -2.1188910216767356, -1.75, 0.26, -1.03, 2.02, 0.42, 0.58, 0.31, -0.21, -0.36, -2.8, 1.03, -0.91, -0.64, -1.4040121365844473, -0.97, 0.46, 0.16, -2.44, 1.4, -0.55, -0.27, -1.12, -0.61, 1.6689583699631245, 0.87, -0.21, 0.43, -0.3, 1.06, 0.65, -0.4, 0.38, 0.18, 0.29, -0.91, 2.7405182488772715, -0.88, -0.45, -0.83, 0.57, 1.2, -1.37, -1.3, 0.44, -0.53, 0.88, 2.55, -1.29, -0.52, -2.93, 0.36, 0.52, -2.5161904761904763, 2.66, 3.93, 1.94, 2.22, 1.366625850340136, 1.88, 1.24, -1.22, -1.91, -1.65, -2.49, -1.98, 0.7, 0.27, -0.58, -0.07, 0.2, 0.02, 0.43, -0.85, -0.34, 0.42, 0.38, -0.21, -1.3, 1.79, 0.97, 0.0, -0.08, 1.29, 0.5927868514969317, 0.54, 0.07, 0.3, 0.73, 0.27, 0.855957527023814, -2.65, -1.0784047619047619, 0.58], ['273', -8.33, 0.98, 0.0, -0.27, 0.15, 1.03, 3.55, -0.65, 1.06, -1.41, -2.31, -5.0, -1.87, 0.05, -0.75, 0.67, -1.97, -1.47, -0.64, -2.75, -1.55, -0.58, -2.46, -2.6, -0.86, 0.07, 0.92, -2.75, 0.45, 2.42, 1.59, 3.365035714285714, 0.34, 0.86, 1.71, -0.45, 0.78, 1.77, -0.15, -0.3, -0.83, 0.46493619921617346, 3.77, 3.29, 5.32, 4.47, 5.97, 3.19, 3.72, 4.59, 2.37, 3.63, 4.65, 2.68, 2.52, 0.28, -0.15, 0.27, 0.7, 0.47, 1.96, 1.14, 2.5942857142857143, -0.1, 0.41, 1.25, -0.89, 0.33, 1.31, -0.6, -0.74, -1.91, -1.47, -0.8, 0.62, -2.02, -1.52, -0.69, -2.8, -1.6, -0.63, -2.51, -2.5964403582748794, 0.63, 2.56, -2.6, -0.67, 1.43, -1.23, -0.72, 0.11, -2.01, -0.8, 0.17, -1.72, -1.86, -4.03, -2.07, -2.63, -2.12, -1.31, -3.39, -2.21, -1.007183003504432, -3.11, -3.25, 0.21, -2.1, -0.05, 0.89, 0.77, 1.02, 0.57, 0.52, 1.36, -0.79, 0.43, 1.42, -0.49, -0.64, -0.82, 0.05, 0.84, -1.3, -0.08, 0.9, -1.01, -1.15, 0.9, 0.8, -0.38, 0.6, -11.69, 0.42, 0.39, -2.07, 2.13, 1.06, -1.6, -0.2, -2.77, -1.71, -0.92, -4.22, 0.45, 2.67, -2.71, -2.61, 0.88, -3.29, 1.75, 2.69, -1.36, 1.65, -6.99, -1.16, -1.65, 2.77, -0.78, -2.12, -0.91, 0.06, -1.83, -1.97, 2.72, 1.37, 1.23, 2.22, 0.3, 0.15, 0.14, 0.98, -0.92, -1.07, 0.93, 0.49, -0.84, -1.89, -2.03, 0.94, 0.87, -0.46, -3.61, 0.23, 3.64, 0.58, 0.85, 1.07, -0.15, 1.46, 0.64, 0.87, -0.05, 0.69, 1.22, -1.64, 1.34, 1.14], ['274', -5.39, 0.06, 0.17122171562045874, 0.0, 0.11, -0.1, 0.11, 0.06, 0.13, 1.24, 0.79, 1.57, 1.89, 1.89, 0.29, 2.08, 1.67, 0.97, 3.53, 0.09, 1.33, 0.99, 1.52, 1.47, 0.34, -0.16, 0.45, 0.78, 1.09, 1.09, -0.5, 1.28, 0.88, 0.19, 2.72, -0.69, 0.54, 0.2, 0.73, 0.7238417231978392, -0.26, 0.0, -0.33, 0.31, 0.47787539444682314, -1.27, 0.5, 0.09, -0.59, 1.92, -1.46, -0.24, -0.58, -0.05, -0.1, 0.0, 0.59, 0.74, 0.17, -0.64, 0.0, -1.57, 0.19, -0.21, -0.9, 1.61, -1.77, -0.55, -0.89, -0.36, -0.41, 0.05, -0.64, -1.57, 0.19, -0.21, -0.9, 1.61, -1.77, -0.55, -0.88, -0.36, -0.41, 0.25, -0.42, 0.5, 0.95, 1.79, 1.38, 0.69, 3.23, -0.2, 1.04, 0.7, 1.23, 1.18, -1.62, -0.83, -0.4, -1.08, 1.42, -1.95, -0.74, -1.07, -0.54, -0.6, 0.18, -0.89, -0.88, -0.13, -0.08, -0.05432648134996804, -0.4290429599640126, -0.69, 1.83, -1.56, -0.34, -0.67, -0.14, -0.13141531611693433, 0.33, 0.26, 2.53, -0.88, 0.35, 0.01, 0.55, 0.49, -0.3, -0.48, 0.12603717887804045, -0.18681321637643203, -4.73, 0.01, 0.1, 0.31, -0.3175376766091052, -0.15, 0.08, 1.09, -2.29, 0.25, 0.15, -2.64, 0.22, -0.42, 0.35, 0.33, -0.12, 0.45, -0.24, 0.4, -0.22, -1.26, 4.71, 0.92, 1.2, 2.3, -2.21, -3.32, -2.12, -2.45, -1.93, -1.98, -0.4, 1.15, 1.24, 0.9, 1.44, 1.39, -0.09, -0.34, 0.19, 0.14, 0.15, 0.09, 0.25, 0.53, 0.48, -0.09, -0.14, 0.06257604962387836, 1.96, -0.62, -2.13, 0.11, -0.14, -0.20136255179902912, 0.02278685149693166, -0.23, -0.24, 0.14, 0.29, 0.1, -0.144042472976186, 0.0, -0.58, -0.32], ['275', 2.73, 0.24, 0.17122171562045874, 0.14, 2.02, -0.34, -0.85, -0.46, -0.4, -0.58, -0.48, 0.11, -1.06, 0.36, 0.89, -1.06, -0.26, -0.71, -3.61, -2.68, -0.37, -0.51, -0.17, -0.08, -0.59, -0.44062858541110805, -0.1, 0.6, -0.58, 0.84, 1.38, -0.58, 0.23, -0.23, -3.14, -2.21, 0.11, -0.03, 0.31, 0.4, -0.78, 0.7749361992161734, -0.7, -1.17, 0.24, 0.78, -1.17, -0.37, -0.82, -3.71, -2.79, -0.48, -0.62, -0.28, -0.2, 0.71, -0.88, -0.08, -0.43, 0.48, 1.43, 1.97, 0.0, 0.81, 0.35, -2.5628197278911564, -1.64, 0.7, 0.55, 0.9, 0.98, -0.71, -0.94, 0.53, -1.41, -0.61, -1.07, -3.95, -3.03, -0.72, -0.86, -0.53, -0.44, -0.04, -1.45, 1.44, -1.4233017616146797, -1.93, -1.14, -1.59, -4.46, -3.54, -1.25, -1.39, -1.05, -0.97, -0.25, 0.48, 0.81, 0.35, -2.58, -1.64, 0.69, 0.55, 0.89, 0.98, -0.02, 0.52, -0.58, -0.23, -0.4, -0.11, -0.3290429599640126, -0.46, -3.36, -2.43, -0.11, -0.25, 0.09, 0.17, -0.03, 0.13, -2.91, -1.98, 0.35, 0.2, 0.55, 0.64, -1.23, -1.24, 0.11, -0.4, -0.76, -0.18, 0.27, 0.25, -0.26, -0.14, 0.21, -0.42, -4.25, 0.5, 0.19, 1.33, -0.22, -0.67, 0.66, 0.67, -0.22, 0.32, -0.43, -1.63, 0.83, -0.95, -4.09, 0.67, 0.97, 4.48, 3.13, 0.96, 3.36, 3.21, 3.56, 3.66, -0.68, 2.15015873015873, 2.37, 2.23, 2.58, 2.67, -0.22, -0.14, 0.2, 0.29, -0.48, -0.19, -0.08, 0.34, 0.43, -0.18, -0.27, -0.52, -1.68, -0.46, 2.129280612244898, -0.57, -0.36, -0.33136255179902907, 0.09, 0.010077402522780693, -0.21, -0.2, -0.32, 0.45, -0.5, -0.67, -0.16, -0.45], ['276', -7.06, -0.93, -0.58, 0.23, -1.54, -1.91, -1.14, -2.06, -2.52, -2.35, 2.6903184712113286, -1.51, 0.84, 0.6, -0.95, -2.11, 0.5071428571428571, -0.6, 0.95, -0.23, -3.12, -0.14, 1.25, -0.41, -3.12, -3.43, -4.72, -3.9, -1.5898809523809525, -1.84, -3.35, -4.48, -1.96, -3.0, -1.5, -2.65, -5.46, -2.55, -1.2, -2.82, 1.51, -6.38, -0.85, 2.39, 2.15, 0.6408150295752765, -0.61, 2.02, 0.93, 2.5, 1.3, -1.63, 1.4, 2.8, 1.12, -3.03, -3.6957142857142857, -1.16, -1.8, -3.17, -0.24, -1.78, -2.93, 0.3114285714285714, -1.42, 0.11, -1.06, -3.92, -0.9540374149659864, 0.4, -1.24, -1.54, -2.93, -1.54, -2.7, -0.13, -1.19, 0.34, -0.83, -3.69, -0.73, 0.64, -1.01, -4.65, -10.15, 10.23, -1.42, -1.17, 1.44, 0.36, 1.91, 0.73, -2.19, 0.82, 2.22, 0.54, -0.97, -0.25, 2.64, 1.55, 3.12, 1.92, -1.03, 2.02, 3.43, 1.74, -1.9, -0.24, -2.99, -2.21, -2.59, -2.04, -2.81, -1.06, 0.47, -0.7, -3.57, -0.61, 0.77, -0.88, -2.15, -1.77, 1.55, 0.37, -2.54, 0.46, 2.0485714285714285, 0.18, -3.69, -3.16, 0.03, -2.97, -1.94, -2.02, -1.07, 4.44, -4.37, -2.21, -1.79, -3.85, 4.17, 4.651428571428572, 2.264547619047619, -3.51, -1.72, -6.99, 7.607142857142857, 6.924285714285714, -2.2, 6.68, -4.39, -4.27, 1.78, -8.43, 28.87, 5.58, 8.48, -4.28, -3.27, -1.17, -4.02, -1.07, 0.3, -1.35, -6.7, -2.13, -2.89, 0.1, 1.48, -0.18, 0.79, 3.08, 4.5, 3.0285714285714285, -2.72, -3.33, -2.22, 1.39, -0.28, -2.25, -2.41, -2.1, 14.37, -3.9, -14.29, -2.12, -2.89, -3.56, -1.64, -2.42, -2.26, -1.34, -1.72, -1.3, -1.95, -3.22, -3.9, -0.7], ['277', -1.68, 0.22, -0.15, -0.01, -0.36, -0.39158037632624054, 0.0, 0.43, 0.25, 1.75, 1.99, 1.54, 2.43, 1.41, 1.32, 1.33, 1.88, 1.72, 8.06, 2.64, 1.52, 1.5, 1.35, 2.1, -0.2, -0.04, -0.23, -0.44, 0.43, -0.57, -0.66, -0.65, -0.11, -0.26, 5.95, 0.64, -0.46, -0.48, -0.63, 0.11, 0.12, 0.40493619921617346, 0.409303232481804, 0.88, -0.13, -0.22, -0.21, 0.34, 0.18, 6.43, 1.09, -0.02, -0.03, -0.18, 0.55, 0.5, 0.41, 1.32, 0.39, -0.67, -1.0, -1.09, -1.08, -0.54, -0.69, 5.5, 0.2, -0.89, -0.91, -1.06, -0.33, -0.04, 0.34, -0.09, -0.08, 0.46, 0.31, 6.56, 1.21, 0.11, 0.09, -0.06, 0.68, 0.24, 0.93, -0.89, 0.43, 0.01, 0.56, 0.4, 6.66, 1.31, 0.2, 0.18, 0.04, 0.77, -0.14, 0.42, 0.54, 0.39, 6.65, 1.3, 0.2526265373526935, 0.17, 0.02, 0.76, 0.17, 0.42, -2.14, -0.3, -0.26, -0.33, -0.13, -0.15, 6.07, 0.75, -0.35, -0.37, -0.52, 0.22, 0.15, 0.03, 6.23, 0.9, -0.2, -0.22, -0.37, 0.37, 0.0, 0.08, 0.28, -0.22, -0.84, 0.19, 0.2, 0.23, -0.24, -0.14, 0.67, 0.23, 1.8005182488772715, 0.59, 0.31, -0.95, -0.23, -0.9, 0.83, 0.87, -0.3, 0.45, -0.55, -1.92, 0.91, -0.33, 0.28, 0.21, 0.33, -1.75, -5.84, -5.02, -6.05, -6.07, -6.21, -5.52, -0.87, -0.87, -1.09, -1.11, -1.26, -0.53, 0.23, -0.02, -0.17, 0.57, 0.5701351386708531, 0.37, 0.3272746849074344, -0.15, 0.6622487553150163, -0.25, -0.18560369872470917, 0.5625760496238783, 0.19, -1.74, -0.23, -0.3, -0.73, 0.39, 0.74, -0.55, -0.11, -0.59, -0.1, -0.17, -0.25404247297618604, -1.22, -0.69, -1.42], ['278', -12.888571428571428, 0.021428571428571422, -0.26877828437954127, 0.01, -2.11, -1.44, 0.06, -1.98, -0.92, -2.51, -1.66, -2.51, -0.98, -0.79, -0.42, 0.06, -1.13, -1.86, -4.05, 0.51, -2.6, -0.76, -0.68, -0.88, -2.11, -2.46, -0.86, -0.86, 0.7208333333333333, 0.89, 1.26, 1.76, 0.54, -0.2, -2.43, 2.210714285714286, -0.95, 0.92, 1.0, 0.8438417231978392, -1.66, -0.96, 0.0, 1.57, 1.77, 2.14, 2.64, 1.42, 0.67, -1.58, 3.09, -0.09, 1.8, 1.88, 1.67, -1.49, -1.55, -1.75, -1.54, -1.55, 0.19, 0.5607993197278912, 1.05, -0.15, -0.89, -3.1, 1.5, -1.64, 0.22, 0.3, 0.1, -1.01, -1.5242857142857142, 0.37, 0.86, -0.35, -1.08, -3.29, 1.3, -1.83, 0.03, 0.11, -0.1, -1.0010901360544218, -4.99, 4.93, -2.1, 0.49, -0.2800986394557823, -1.41, -3.65, 0.93, -2.19, -0.34, -0.26, -0.46, -3.65, -2.57, -1.19, -1.92, -4.11, 0.44, -2.66, -0.82, -0.74, -0.94, -0.8, -2.62, -1.34, -1.77, -1.53, -1.93, -1.4, -0.74, -2.95, 1.65, -1.49, 0.38, 0.45, 0.25, -1.72, -0.66, -2.24, 2.41, -0.75, 1.12, 1.2, 0.99, -0.79, -0.3, -0.65, -1.68, -7.35, -0.33, -0.36, 4.87, -4.87, -2.43, -0.78, -2.68, 5.72, 3.57, 1.76, -6.314778911564626, -1.01, -5.25, 5.37, 5.38, -1.77, 7.16, -3.42, -2.15, 1.02, -4.16, 9.65, 2.797142857142857, 4.435714285714286, -5.99, 1.61, 4.75, 1.51, 3.43, 3.51, 3.3, -5.35, -3.0, -3.09, -1.26, -1.18, -1.38, 0.09, 1.89, 2.202857142857143, 1.76, -0.99, -1.12, -1.77, 0.08, -0.13, -1.66, -1.71, -1.83, 4.89, -1.47, -4.93, -2.58, -2.32, -1.84, -0.2, -1.91, -2.22, -0.64, -0.949047619047619, -1.59, -1.64, -3.01, -3.38, -1.05], ['279', -1.09, -0.23, 0.011221715620458745, 0.15, -1.61, 0.29, -0.12, -0.17, 0.42, -0.22, -0.7, -0.43, -0.31, 0.37, -1.5, -0.19, -0.12, -0.17, -0.06, 3.93, 0.01, 0.06, -0.38, -1.16, 0.7, -0.14, 0.49, 0.27, 0.4, 1.08, -0.81, 0.52, 0.59, 0.53, 0.65, 4.67, 0.72, 0.77, 0.33, -0.46, 0.43, 0.40493619921617346, 0.21, 0.12, 0.8, -1.08, 0.24, 0.32, 0.26, 0.37, 4.809666666666667, 0.44, 0.5, 0.06, -0.73, 0.48, 0.29, 0.3, 0.28, 0.09, 0.68, -1.2, 0.12, 0.2, 0.14, 0.25, 4.26, 0.32, 0.37, -0.06, -0.85, 0.23, -0.58, -1.86, -0.56, -0.48, -0.54, -0.18252355184498031, 3.55, -0.36, -0.3, -0.74, -1.52, 0.47, 0.42, -0.41, 1.3, 1.33, 1.41, 1.35, 1.46, 5.52, 1.54, 1.59, 1.15, 0.35, 0.61, -0.03, 0.08, 0.02, 0.13, 4.13, 0.2, 0.25, -0.18, -0.97, -0.06, 0.0, 2.55, 0.2, 0.22, 0.29, -0.1, -0.06, 0.05, 4.05, 0.13, 0.18, -0.26, -1.05, -0.28, -0.05, 0.11, 4.11, 0.18, 0.24, -0.2, -0.99, 0.31, 0.17, 0.2860371788780405, 0.24, 1.89, 0.07, 0.0, -0.49, 0.41, 0.23, 0.06, -1.92, 8.13, -0.44, -0.21, -0.56, 0.5, 0.49, -0.6, -0.6, 0.21, -0.78, 0.4, -0.8116093450200591, 0.47, -0.24, -1.35, 0.16, 0.36, -8.09, -0.16, 4.0, 0.07, 0.12, -0.31, -1.1, 0.57, -3.99, -3.77, -3.72, -4.14, -4.9, -0.23, 0.05, -0.39, -1.17, 0.34, 0.56, -0.28, -0.44, -1.22, 0.19, 0.2, -0.14, -0.79, 1.78, 0.91, 0.58, -0.85, 0.16, -0.79, 0.29, 0.16, 0.5, 0.21, 0.42, 0.95, -0.56, -0.99, 0.95], ['280', 4.518571428571429, -1.87, 0.27, 0.6521428571428572, 0.88, -0.16, 0.25, 0.44, -0.06, 0.47, 1.25, 0.15, -0.36, -0.56, -0.19, -1.48, 1.56, 1.09, 2.71, -0.19, 0.42, 0.87, 0.96, 0.62, 0.13, 0.46, -0.77, -1.09, -1.59, -1.78, -1.42, -2.7, 0.31, -0.15, 1.45, -1.42, -0.82, -0.37, -0.28, -0.62, 1.09, 1.23, 0.32, -0.51, -0.7, -0.34, -1.63, 1.7186513605442175, 0.94, 2.56, -0.34, 0.27, 0.72, 0.8442857142857143, 0.48, -0.15, -0.16, -0.38, -0.48, 0.83, -0.2, 0.17, -1.13, 1.92, 1.46, 3.08, 0.17, 0.78, 1.2314285714285713, 1.33, 0.99, -0.55, 1.6757142857142857, 0.37, -0.93, 2.13, 1.66, 3.29, 0.37, 0.99, 1.44, 1.53, 1.19, -0.24109013605442178, -1.07, 1.14, 0.66, -1.29, 1.75, 1.32, 2.91, 0.0, 0.62, 1.07, 1.16, 0.82, 2.76, 1.98, 3.08, 2.61, 4.26, 1.31, 1.93, 2.39, 2.48, 2.15, -0.45, 1.98, 0.74, -0.18, -0.13, -0.34, -1.07, -0.46, 1.14, -1.72, -1.12, -0.68, -0.59, -0.92, -0.41, -0.62, 1.6, -1.27, -0.66, -0.22, -0.13, -0.47, -0.05, -0.21, -0.2, -0.87, 5.531102040816326, -0.42, -0.62, 0.46, -0.44, -0.22, -0.39, 0.81, -1.43, 0.35, 0.22, 2.23, -0.04, -0.63, 0.73, 0.42, -0.17, 0.74, -0.35, -2.37, 1.18, -3.16, 1.52, 2.2342857142857144, 3.275714285714286, 1.45, -2.18, -2.82, -2.23, -1.79, -1.7, -2.03, -0.46, 0.66, 0.61, 1.06, 1.15, 0.81, 0.05, 0.45, 0.7728571428571429, 0.2, -0.08, -0.38, -0.4, 0.09, -0.25, -0.19, -0.34, 0.33, 0.9157142857142857, -0.31, -0.67, -0.09, -0.38, -0.49, -0.34, -0.64, -0.31, 0.06, 0.06095238095238095, 0.54, -0.15, -0.35, -0.77, -0.49], ['281', 0.68, -0.07, 0.17122171562045874, 0.15, 0.3, -0.08, -1.72, -1.64, -1.14, -1.8, -1.13, -0.37, -0.53, -0.92, 0.22, -1.27, -1.01, -1.48, -3.54, -1.53, -2.1, -2.2, -0.98, -1.51, -1.61, -1.09, -0.67, 0.77, 0.61, 0.22, 1.37, -0.14, 0.12, -0.35, -2.43, -0.4, -0.98, -1.08, 0.2588796134390452, -0.3461582768021609, -1.3525315746467892, -1.89, -1.43, -0.15, -0.55, 0.6, -0.9, -0.64, -1.11, -3.18, -1.16, -1.73, -1.83, -0.61, -1.15, -0.5099371536943235, -0.3957142857142858, -1.91, -1.22, -1.28, -0.39, 0.75, -0.75, -0.49, -0.95, -3.03, -1.0, -1.58, -1.68, -0.45, -0.99, -2.55, -0.89, 1.15, -0.36, 0.04948941254823622, -0.56, -2.65, -0.61, -1.19, -1.29, -0.06, -0.6, -1.1, -1.82, 1.8, -2.02, -1.49, -1.23, -1.69, -3.75, -1.74, -2.32, -2.42, -1.2, -1.6759922724755494, -1.84, -0.54, 0.26, -0.21, -2.3, -0.26, -0.84, -0.94, 0.3, -0.25, -0.23, -0.65, 1.7, -0.4, -0.42, -0.43, -0.8, -0.47, -2.55, -0.52, -1.1, -1.2, 0.03, -0.51, 0.45, -0.33, -2.1, -0.05, -0.63, -0.73, 0.51, 0.2021774376417234, -1.01, -0.74, 0.29, -0.46, -5.7, 0.05, 0.14, 1.91, -1.91, -0.95, 0.14, -0.4938364678879505, 0.4, 0.75, 0.46, 0.46, 0.11, -1.28, 1.45, 1.22, -0.42, 2.9, -0.87, -1.27, 0.67, -2.36, 0.76, 1.62, 2.39, -0.5661904761904761, 1.8, 2.09, 1.49, 1.39, 2.66, 2.1, -1.28, -0.2798412698412699, -0.58, -0.68, 0.9794625850340136, 0.01, 0.3, -0.1, 1.14, 0.6, -1.19, -1.07, 0.41, 1.25, 0.7, -0.42, -0.51, -1.63, 0.5, 1.19, -0.63, -0.82, -0.55, -0.83, -0.54, -0.23, -0.92, 0.06, 0.11, 0.27, -0.29, -1.65, -1.4, -1.25], ['282', -4.332857142857143, 0.31, 0.09015289830927053, -0.1, 0.05, 0.29, -0.47, -1.27, -0.5, -0.9229115646258504, -1.42, -0.49, -0.61, -0.59, 0.49, -0.94, -1.23, -1.17, -5.26, -0.92, -1.46, -0.64, -1.03, -1.6, -1.59, -0.58, 0.05, 0.94, 0.82, 0.85, 1.94, 0.49, 0.19, 0.25, -3.9, 0.5, -0.04, 0.79, 0.4, -0.18, -1.16, -0.34, -0.88, -0.12, -0.1, 0.99, -0.42895634920634923, -0.7371428571428571, -0.68, -4.79, -0.43, -0.941934531913557, -0.15, -0.5242857142857144, -1.11, -1.56, -1.55, -1.86, -0.36, -0.76, 0.03, 1.12, -0.32, -0.62, -0.56, -4.68, -0.31, -0.85, -0.03, -0.42, -0.99, -3.35, -0.79, 1.09, -0.35, -0.65, -0.59, -4.7, -0.34, -0.88, -0.05, -0.44, -1.02, -0.27, -0.83, 0.95, -1.86, -1.42, -1.72, -1.66, -5.73, -1.41, -1.95, -1.13, -1.52, -2.08, -0.18, -0.44, -0.3, -0.24, -4.37, 0.01, -0.53, 0.3, -0.09, -0.67, -0.27, -0.45, 0.18, 0.05, 0.09, -0.08, -0.14, 0.06, -4.08, 0.31, -0.23, 0.6, 0.21, -0.37, -0.67, -0.2, -4.14, 0.25, -0.29, 0.54, 0.14, -0.43, 0.07, 0.22, 0.04, -0.21, -1.4022619047619047, 0.16, -0.24, 1.03, -1.04, -0.53, 0.07, -0.66, 0.94, -0.12, -0.07, -2.0707142857142857, 0.41, 0.01, 0.0, -0.13, 0.04, 1.53, 0.08, 0.64, -0.32, -0.36, 5.63, 0.21, 0.44, -1.02, 4.1, 4.58, 4.01, 4.88, 4.47, 3.87, 0.1, -0.45, -0.54, 0.29, -0.11, -0.68, 0.09, 0.83, 0.44857142857142857, -0.14, -0.49, -0.1, -0.74, -0.39, -0.97, -0.02, -0.02, -1.34, 2.84, 0.28, -2.89, -0.56, 0.12, -0.35, -0.4972131485030683, 0.4, -0.42, 0.5, 0.25, 0.3, 0.23, -1.76, -0.41, -0.08], ['283', -9.94, -0.26, 0.13, 0.29, -0.96, -0.89, -0.8058847420401708, -1.3382794034640413, -1.46, -1.32, 1.09, -0.21, -0.45, 1.03, 0.39, 0.72, -0.24, 0.09, -0.62, 0.45, -2.202664517912641, -0.54, -0.41, -0.46, -2.53, -1.33, -2.38, -1.28, -1.52, -0.05, -0.69, -0.36, -1.31, -0.98, -1.69, -0.63, -3.29, -1.61, -1.48, -1.53, -0.4, -1.81, -1.11, -0.24, 1.25, 0.6708150295752765, 0.94, -0.03, 0.3, -0.41, 0.66, -2.011934531913557, -0.33, -0.2, -0.25, -0.08, -1.1, -1.86, -1.24, -0.88, 1.49, 0.84, 1.18, 0.21, 0.54, -0.17, 0.91, -1.8, -0.09, 0.04, -0.01, -0.94, -2.33, -0.64, -0.31, -1.26, -0.93, -1.64, -0.58, -3.24, -1.56, -1.43, -1.47, -1.87, -2.64, 2.69, -1.71, 0.33, -0.63, -0.3, -1.01, 0.061674603174603174, -2.62, -0.93, -0.8, -0.84, -3.18, -2.03, -0.96, -0.63, -1.33, -0.27, -2.94, -1.25, -1.13, -1.17, -0.23, -2.0, -1.19, -0.9, -0.94, -0.94, -1.0081905235138708, 0.33, -0.38, 0.7, -2.0, -0.3, -0.17, -0.22, -0.79, -1.41, -0.71, 0.36, -2.33, -0.63, -0.5, -0.55, -1.05, -1.05, 0.28, -1.09, -9.82, -0.09, -0.12, 1.62, -1.61, -0.82, -1.92, -1.82, 3.37, 1.78, 0.9, -5.06, -0.4069202101312209, -2.83, 2.82, 2.71, -0.93, 2.43, -1.89, -3.37, 1.64, -3.17, 5.88, 2.07, 3.01, -3.42, -0.71, 1.08, -1.63, 0.08, 0.21, 0.16, -2.59, -1.77, -2.68, -0.99, -0.86, -0.91, 0.94, 1.8288785911064216, 1.87, 1.83, -1.51, -1.36, -0.79, 0.13, 0.08, -0.92, -0.8856036987247091, -1.46, 3.05, -1.29, -2.8085714285714287, -1.98, -1.63, -0.92, -0.05, -1.12, -0.67, -0.34, -0.26, -0.95, -0.87, -3.12, -2.04, -0.62], ['284', -2.1, 0.13, -0.23877828437954127, -0.01, 0.96, 0.32, 0.26, -0.37, 0.31, -1.98, -2.55, -2.09, -3.56, -1.14, -1.05, -2.06, -1.35, -2.24, -3.64, -3.6, -1.76, -1.43, -1.45, -1.8648833725798009, 1.06, 0.93, 0.6126583949931124, 0.47, -1.04, 1.45, 1.54, 0.5, 1.23, 0.4272589041444084, -1.12, -1.08, 0.81, 1.15, 1.12, 0.56, -0.5145146341753485, -0.17, 0.11, -1.51, 0.97, 1.06, 0.03, 0.75, -0.16, -1.59, -1.55, 0.33965472923706097, 0.67, 0.65, 0.08, -0.6, 0.04, -0.42, 0.51, 1.64, 2.52, 2.61, 1.56, 2.3, 1.37, -0.08, -0.04, 1.87, 2.22, 2.19, 1.62, 2.25, -0.85, 0.09, -0.93, -0.21, -1.12, -2.53, -2.49, -0.63, -0.29, -0.32, -0.88, 0.22, -1.79, 1.88, -0.94, -1.02, -0.3, -1.2, -2.62, -2.58, -0.72, -0.38, -0.41, -0.97, 0.32, 0.08, 0.73, -0.18, -1.61, -1.57, 0.31, 0.65, 0.62, 0.06, 0.35, 0.07, 1.12, 0.21159818068290148, 0.22, 0.09567351865003196, -0.64, -0.9, -2.3198412698412696, -2.28, -0.41, -0.08, -0.1, -0.66, -0.59, 0.27, -1.43, -1.39, 0.49, 0.83, 0.81, 0.24, -0.75, -0.59, -0.07, -0.13, 0.75, -0.39, -0.43, 1.56, -1.59, -0.8, -0.24, 0.09, -3.16, -0.32, -0.14, -1.06, 0.58, 0.4514761904761905, -0.48, -0.55, 0.18, 2.4, 0.36, -0.11, 0.01, -1.83, -1.89, 1.31, 1.82, 3.32, 1.73, 0.04, 1.95, 2.3, 2.27, 1.7, 0.42, 1.68, 1.91, 2.26, 2.23, 1.66, -0.22, 0.34, 0.31, -0.25, 0.26, 0.31, -0.56, -0.02, -0.59, 0.18, 0.16, -0.36, -0.92, 0.58, 1.17, 0.12, 1.52, -0.46136255179902913, -0.56, 0.0, -0.68, 1.07, 0.89, 0.28, 0.03, -0.12, 1.07, -0.89], ['285', -9.07, 1.5, 0.29, 0.3, -0.43, 0.93, -0.59, 1.34, 0.33, -1.4558571428571427, -2.08, -1.09, -3.08, -3.11, -3.23, 2.2, -2.0, -1.81, -2.06, -1.22, -1.93, -2.75, -2.58, -2.55, 1.04, 0.49, 0.6726583949931124, 1.01, -1.02, -1.05, -1.17, 4.38, 0.09, 0.28, 0.03, 0.88, 0.15, -0.68, -0.5, -0.43615827680216085, 1.41, 0.5149361992161734, -0.37, -2.01, -2.04, -2.16, 3.33, -0.91, -0.72, -0.97, -0.13, -0.85, -1.68, -1.5, -1.48, 1.17, 0.27, 0.7878279728097839, 0.11, 1.68, -0.03, -0.15, 5.45, 1.12, 1.31, 1.06, 1.92, 1.18, 0.34, 0.52, 0.54, -0.29, 1.71, -0.12, 5.49, 1.15, 1.35, 1.09, 1.95, 1.22, 0.37, 0.56, 0.58, 0.94, 3.4, -3.47, 1.83, 5.61, 1.27, 1.47, 1.21, 2.07, 1.3638701615844473, 0.49, 0.6785238095238095, 0.7, -4.53, -3.58, -4.11, -3.92, -4.17, -3.35, -4.05, -4.85, -4.68, -4.65, 0.73, -3.55, 0.27, 0.42, 0.9151790696343399, 1.065673518650032, 0.6218094764861293, 0.2, -0.06, 0.79, 0.07, -0.77, -0.59, -0.5114153161169342, 0.37, 0.36, -0.25, 0.6, -0.13, -0.96, -0.78, -0.76, 0.81, 0.74, 0.88, 0.913186783623568, -13.35, 1.27, 1.07, -1.76, 1.7, 0.888810171007621, -2.68, 0.16, 0.35, -1.82, -0.94, -4.46, 1.12, 2.76, -2.67, -2.76, 0.973290804863853, -2.59, 1.76, -1.59, 0.75, 1.55, -4.18, -1.07, -1.62, -0.31, 0.61, 0.85, 0.13660997732426305, -0.71, -0.53, -0.51, 2.68, -0.24, -0.72, -1.55, -1.37, -1.35, 0.49, -0.83, -0.66, -0.63, 0.34, 0.57, 1.33, 0.18, 0.2, 0.94, 0.91, 1.67, -1.99, 0.73, 2.03, 0.36, 0.5, 1.15, 0.02, 0.99, 0.48, 1.02, 1.23, 1.46, 1.13, -1.95, 0.26, 0.54], ['286', -0.64, 0.55, 0.16, -0.04, -0.04, -0.54, -1.4499638336347196, -0.9182794034640412, -0.57, -1.07, -0.55, -0.21, -1.15, -0.06, -0.16, -0.45, -0.51, -1.1, -0.8, -1.13, -0.8, -1.19, -0.46, -0.46, -0.61, -0.42, -0.49734160500688757, 0.34, -0.6, 0.49, 0.39, 0.1, 0.04, -0.55, -0.26, -0.58, -0.25, -0.64, 0.09, 0.09, -0.05, -1.04, -0.86, -0.94, 0.15, 0.12081502957527657, -0.24, -0.3, -0.89, -0.59, -0.92, -0.59, -0.8861344435209981, -0.25, -0.25, -0.37, -0.94, -1.68, -0.33, 0.08, 1.1, 1.000799319727891, 0.71, 0.64, 0.05, 0.35, 0.02, 0.35, -0.04, 0.7, 0.7, -0.91, -1.01, -0.1, -0.39, -0.45, -1.04, -0.75, -1.07, -0.74, -1.13, -0.4, -0.4, -0.57, -1.44, 1.49, -0.91, -0.29, -0.35, -0.94, -0.64, -0.97, -0.64, -1.03, -0.3, -0.3, -1.32, -0.63, -0.06, -0.65, -0.36, -0.68, -0.35, -0.74, -0.01, -0.01, -0.05, -0.62, 0.01, -0.5184018193170985, -0.69, -0.33432648134996806, -0.56, -0.59, -0.29, -0.6194642857142857, -0.29, -0.68, 0.05, 0.05, 0.03, 0.03, 0.3, -0.03, 0.3, -0.09, 0.65, 0.65, -0.76, -0.92, 0.12, -0.43, -4.12, -0.15, 0.07, 0.6, -0.63, -0.2811898289923789, -0.33, -1.49, -0.28, 1.07, 0.54, -0.34, -0.66, -1.68, 1.61, 1.61, -0.4867091951361471, 0.98, -1.1, -0.36, 0.17, -1.67, 1.99, 1.15, 1.58, 0.23, -0.27, -0.33, 0.0, -0.39, 0.35, 0.35, -1.67, 0.06, 0.33353741496598643, -0.06, 0.68, 0.68, -0.27, -0.39, 0.34, 0.35, -0.52, -0.3415464535464533, 0.12, 0.74, 0.74, -0.54, -0.5, -0.99, 0.94, -1.09, -0.85, -0.4, -1.07, -0.62, 0.0, -0.59, -0.41, -0.86, -1.17, 0.12, -0.62, 0.04, -0.84, -1.27], ['287', -8.23, -0.97, -0.4998471016907295, 0.07, -1.54, -2.78, -1.89, -4.0, -2.98, -4.92, -1.64, -2.74, -1.14, -1.75, -1.1157142857142859, -1.85, -1.2885714285714285, -3.82, -6.35, -2.5574455782312926, -5.17, -1.87, -2.06, -2.63, -3.82, -2.97, -3.33, -1.1194545454545455, 0.5146428571428572, -0.12, 0.52, -0.22, -0.3, -2.22, -4.8, -1.27, -3.59, -0.24, -0.43, -1.01, -3.23, -3.79, -2.24, 1.64, 1.01, 1.66, 0.92, 0.83, -1.11, -3.72, -0.15, -2.5, 0.89, 0.7, 0.11, -2.93, -2.7457142857142856, -4.49, -3.44, -3.82, -0.62, 0.02, -0.72, -0.8, -2.71, -5.28, -1.77, -4.08, -0.74, -0.93, -1.5, -4.44, -3.22, 0.64, -0.1, -0.18, -2.1, -4.68, -1.15, -3.48, -0.12, -0.31, -0.89, -3.28, -8.36, 8.4, -3.84, -0.73, -0.82, -2.72, -5.29, -1.78, -4.09, -0.6742857142857143, -0.94, -1.52, -3.22, -3.13, -0.09, -2.007880952380952, -4.59, -1.06, -3.38, -0.02, -0.21, -0.79, -1.2, -3.16, -2.28, -2.52, -2.51, -2.45, -3.04, -1.92, -4.51, -0.97, -3.3, 0.06, -0.13, -0.71, -2.96, -1.14, -2.64, 0.97, -1.41, 2.02, 1.83, 1.24, -3.45, -3.75, -0.38, -2.78, -6.32, -1.1796768707482992, -0.7942857142857144, 5.09, -5.1, -2.56, -1.88, -6.04, 4.24, 5.06, 2.9582806122448977, -4.14, -1.62, -7.5, 7.44, 7.55, -2.5, 7.64, -5.05, -2.14, 1.1, -9.07, 8.073125850340135, 6.07, 9.16, -4.18, 1.54, 3.7048095238095238, 1.27, 4.79, 4.59, 3.98, -7.5, -2.09, -2.35, 1.05, 0.86, 0.27, 0.7165017006802721, 3.48, 3.28, 3.331428571428572, -2.95, -3.32, -3.1, -0.19, -0.77, -2.46, -2.51, -3.93, 3.99, -3.19, -4.06, -2.66, -3.05, -2.92, -0.58, -3.07, -2.42, -1.79, -1.7, -2.13, -2.35, -4.94, -4.24, -2.12], ['288', -2.41, -0.01, -0.01, -0.05, -0.65, -0.07, 1.26, -0.99, 0.2, -1.01, -1.64, -1.11, -0.77, 0.51, 0.42, -0.25, -0.7, -1.11, -4.77, -0.37, -0.62, -0.73, -0.37, -0.92, -0.98, -0.21, 0.64, 0.54, 0.89, 2.19, 2.09, 1.42, 0.95, 0.54, -3.18, 1.29, 1.04, 0.93, 1.29, 0.7738417231978392, -0.82, 0.6449361992161734, 0.1, 0.35, 1.64, 1.6108150295752766, 0.87, 0.41, 0.0, -3.71, 0.75, 0.49, 0.48386555647900187, 0.75, 0.19, -0.39, -0.72, -0.88, -0.05, -0.17075475293412243, 1.28, 1.19, 0.52, 0.06, -0.35, -4.04, 0.4, 0.15, 0.04, 0.4, -0.16, -0.82, -1.51, -0.09, -0.75, -1.2, -1.61, -5.01252355184498, -0.87, -1.12, -1.23, -0.7369045181009466, -1.3764403582748792, 0.77, -1.64, 1.68, -1.42, -0.66, -1.12, -1.52, -5.17, -0.78, -1.03, -1.14, -0.78, -1.34, -0.09, -0.77, -0.46, -0.87, -4.54, -0.12, -0.3173734626473065, -0.48, -0.13, -0.68, 0.09, -0.83, -0.29427628811696, -0.2, -0.3, -0.09, -0.31, -0.41, -4.1, 0.34, 0.08, -0.03, 0.33, -0.22, -0.23, 0.11, -3.7, 0.75, 0.5, 0.5157995496566927, 0.75, 0.19, -1.22, -1.33, 0.08, -0.29, -0.39, 0.14, 0.07, -0.04, 0.0, -0.01, 0.07, -0.83, 1.27, 0.41, 0.21, -1.16, -0.21, -0.66, 0.59, 0.64, -0.15670919513614703, 0.03, -0.44, -0.85, 0.45, -0.88, -0.17, 0.6, 0.92, -1.3, 3.95, 4.63, 4.36, 4.25, 4.62, 4.04, -0.6391948051948052, -0.64, -0.26, -0.36, 0.0, -0.56, -0.39, -0.11, 0.25, -0.3, 0.18, 0.35, -0.28, 0.36, -0.2, -0.22, -0.2, -0.9, 0.3, -0.25, -0.31, -0.3781051005851445, -0.16, -0.64, -0.56, -0.48, 0.05, 0.17, -0.19, -0.26, -0.09, -1.61, -0.2, -0.14698322629260274], ['289', 0.91, -0.53, -0.12, 0.08, -0.01, 0.57, -1.0299638336347197, -0.5482794034640412, -0.05062194561298938, -0.93, -1.03, -0.11, -1.05, -1.1, -0.41, -0.71, -0.84, -0.91, -0.43, 0.1, -0.95, -0.96, -0.93, -0.87, -0.04, -0.82, 0.1, 0.93, -0.02, -0.08, 0.6878199712950912, 0.33, 0.19, 0.12, 0.6, 1.14, 0.08, 0.07, 0.1, 0.16, -0.15, -1.11, -0.82, -0.94, -0.99, -0.29, -0.59, -0.73, -0.79, -0.32, 0.21, -0.84, -0.84, -0.82, -0.76, -0.2, 0.0, -0.52, 0.16, 0.12, -0.05, 0.65, 0.35, 0.21, 0.15, 0.63, 1.16, 0.1, 0.1, 0.12, 0.18, -1.33, 0.18, 0.71, 0.4, 0.27, 0.2, 0.68, 1.22, 0.15, 0.15, 0.18, 0.24, -0.41, -0.12, 0.08, -0.53, -0.2119125667872351, -0.43, -0.5, -0.03, 0.51, -0.3847647669790526, -0.55, -0.53, -0.47, -1.85, -0.23, -0.13, -0.2, 0.28, 0.81, -0.25, -0.25, -0.23, -0.17, -0.12, -0.24, 1.3, 0.13, -0.13, 0.40567351865003193, -0.09, -0.07, 0.41, 0.94, -0.12, -0.12, -0.01401213658444736, -0.03, 0.05, -0.02, 0.48, 1.01, -0.05, -0.05, -0.02, 0.04, -0.39, -0.64, 0.19603717887804045, 0.08, -5.17, -0.05, 0.0, -1.23, 1.25, 0.6588101710076211, -0.03, 0.29, 1.88, -0.27, -0.11, 0.48, -0.2, 0.5505968614718616, -0.47, -0.4, 0.14, -1.88, 0.3, 0.22, -0.12, -0.25, -5.18, 0.22, 0.35, -1.9428690476190476, -0.5, 0.53, -0.513390022675737, -0.53, -0.5, -0.44, 0.42, -1.03, -1.05, -1.05, -1.03, -0.97, 0.02, 0.0, 0.02, 0.08, -0.19, 0.04, 0.03, 0.03, 0.09, 0.15, 0.12, -0.71, -1.98, 0.67, 1.94, -0.33, -0.42, 0.0, 0.06, 0.11, 1.15, -0.07, -0.28, -0.12, -0.06, -0.68, -0.76, 0.02], ['290', 5.23, -1.59, -1.08, 0.09, -1.9570209190089405, -2.0315803763262403, -2.55, -2.23, -2.3, -1.2592857142857143, 2.04, 1.42, 0.17, 0.65, 0.77, -5.16, 1.57, 0.2, 1.58, 2.93, -1.11, 1.0, 2.35, 1.81, -1.73, -1.74, -3.23, -0.61, -1.83, -1.36, -1.24, -7.05, -0.46, -1.8, -0.45, 0.88, -3.09, -1.02, 0.31, -0.22, -1.6, -1.3650638007838265, -2.64, -1.23, -0.75, -0.64, -6.48, 0.15, -1.2, 0.16, 1.5, -2.49, -0.41, 0.92, 0.39, -1.66, -2.49, -3.81, -1.96, -1.43, 0.48, 0.6, -5.32, 1.39, 0.13260506614006173, 1.4271802721088434, 2.76, -1.28, 0.83, 2.18, 1.64, -2.09, -1.9, 0.12, -5.77, 0.91, -0.45, 0.92, 2.5891309523809523, -1.75, 0.34, 1.69, 1.15, -2.58, -9.65, 9.62, -1.9833017616146797, -5.88, 0.79, -0.57, 0.8, 2.15, -1.87, 0.23, 1.57, 1.03, 6.74, 4.11, 7.09, 5.65, 7.11, 8.53, 4.27, 6.49, 7.92, 7.35, -1.41, 4.13, -6.78, -2.27, -2.26, -2.46, -2.7790429599640123, -1.35, 0.01, 1.35, -2.64, -0.56, 0.77, 0.24, -2.21, -1.46, 1.38, 2.73, -1.31, 0.8, 2.15, 1.61, -4.571041630036876, -4.24, 0.12, -2.876813216376432, 20.08, -1.0, -0.56, 4.77, -4.81, -2.39, -1.17, -2.47, 8.14, 4.62, 2.31, 2.71, -1.39, -6.94, 6.89, 6.87, -2.27, 7.25, -4.54, -4.08, 1.83, -8.37, 13.81, 5.51, 8.28, -8.11, -2.8, 1.33, -2.65, -0.57, 0.76, 0.23, -6.88, -4.08, -3.93, -1.88, -0.56, -1.09, -0.15, 2.13, 3.5, 2.95, -2.2, -2.25, -2.24, 1.34, 0.8, -2.31, -2.39, -2.06, 7.3, -5.75, -7.19, -1.75, -2.03, -3.4513625517990287, -0.53, -2.54, -2.29, -1.81, -0.31, -1.65, -3.02, 0.66, -4.34, -3.48], ['291', -2.27, 0.11, 0.11122171562045875, 0.1, -1.48, -0.08, -0.17588474204017085, -0.27, -0.04, -1.27, -1.27, -1.05, -1.21, -0.88, -2.22, -0.51, -0.47, -1.44, 0.15, -0.22, -1.13, -1.04, 0.26, -1.19, -0.41, -0.63, 0.03265839499311246, 0.22, 0.07011904761904762, 0.39, -0.96, 0.76, 0.8, -0.18, 1.43, 1.06, 0.14, 0.23, 1.55, 0.08, -0.44, -0.22506380078382657, -0.22, -0.16, 0.16, -1.18, 0.54, 0.58, -0.4, 1.3071355564861205, 0.84, -0.08034527076293904, 0.01, 1.32, -0.15, -0.24, 0.15, -0.62, -0.17, -0.06, 0.33, -1.02, 0.7, 0.74, -0.24, 1.3871802721088435, 1.0, 0.08, 0.17, 1.49, 0.02, -0.85, -0.39, -1.34, 0.37, 0.41, -0.56, 1.04, 0.67, -0.25, -0.16, 1.16, -0.31, -0.03, -3.76, 3.82, 0.97, 1.74, 1.78, 0.79, 2.42, 2.04, 1.1338701615844473, 1.2, 2.54, 1.05, -1.58, -0.76, 0.04, -0.93, 0.66, 0.29, -0.62, -0.53, 0.78, -0.68, 0.22, -0.78, -1.1298229965745161, -0.35, -0.69, -0.05, -0.8, -0.97, 0.62, 0.26, -0.66, -0.57, 0.74, -0.72, -0.28, 0.23307674813036727, 1.61, 1.24, 0.31, 0.41, 1.73, 0.25, -2.76, -2.97, 0.22, -0.78, -4.588897959183674, -0.08, -0.07, -0.14, 0.14, 0.08, -1.11, -0.93, 2.07, 0.71, 0.32, -1.16, -0.25, -1.03, 1.08, 1.03, -0.35, -0.08, -0.71, -1.07, 0.53, -2.45, 0.11, 1.58, 2.37, -2.08, -1.41, -0.37, -1.28, -1.19, 0.12, -1.34, -1.01, -1.05, -0.91, -0.82, 0.49, -0.98, -0.14, 0.09, 1.41, -0.06, 0.12013513867085306, -0.11, -0.23, 1.32, -0.16, -0.35, -0.42, -0.26, 0.77, -1.12, -0.63, -0.57, -0.73, -1.53, -1.45, 0.07, -0.01, 0.11, -0.44, -0.11, -0.08, -2.37, -1.02, -0.61], ['292', 3.82, 0.58, 0.12, 0.3821428571428573, 0.76, 0.33, 1.6, 0.72, 1.28, 0.56, -0.98, -0.05806550195835902, -0.39, -0.15, -0.61, -0.68, 0.66, 0.41, -1.56, -0.47, 1.67, 0.74, -0.47, 0.31, 0.94, 0.84, 1.55, 0.72, 0.6, 0.83, 0.37, 0.3, 1.65, 1.4, -0.59, 0.51, 2.67, 1.73, 0.51, 1.3, 0.55, 2.75, 0.82, -0.13, 0.11, -0.35, -0.42, 0.92, 0.67, -1.3, -0.21, 1.93, 1.0938655564790019, 0.4214285714285715, 0.57, 0.59, 1.02, 1.78, 1.160952380952381, 0.95, 0.24, -0.22, -0.29, 1.05, 0.8, -1.17, -0.08, 2.06, 1.13, -0.08, 0.7, 1.12, 0.71, -0.46, -0.53, 0.81, 0.56, -1.41, -0.32, 1.82, 0.89, -0.32, 0.46, 1.77, 2.35, -2.29, 1.17, -0.0694795918367347, 1.27, 1.02, -0.96, 0.14, 2.29, 1.35, 0.14, 0.92, 2.23, 1.25, 1.35, 1.1, -0.88, 0.21, 2.36, 1.43, 0.21, 1.0, 0.12, 1.3, -0.81, 0.41, 0.59, 0.12, -0.1, -0.25, -2.2, -1.12, 1.0, 0.14030501944728757, -1.12, -0.35, -0.09, 0.15, -1.96, -0.88, 1.25, 0.33, -0.88, -0.1, 0.8689583699631245, 0.45, -0.02, -0.06, 6.59, 0.1, 0.11, -0.21, 0.24, 0.1, 0.28, 0.5, -2.04, -0.8, -0.42, 1.86, 0.35, 1.23, -1.28, -1.26, 0.4, -0.4, 0.81, 0.53, -0.3, -0.25, -2.04, 0.13, 0.25, 2.09, 2.15, 1.1, 3.27, 2.33, 1.1, 1.9, 1.22, 1.0301587301587303, 2.15, 1.21, 0.0, 0.78, -1.09, -0.91, -2.1, -1.33, 1.24, 1.51, -0.18, -1.2, -0.42, 0.42, 0.33, 0.65, -1.58, -0.43, 1.57, 0.15, 0.7810935020800125, 1.03, 0.78, 0.15, 0.03, 0.37, 0.14, 0.68, 0.335957527023814, -0.26, 1.3830376647162361, -0.29], ['293', 5.93, 0.75, 0.05, -0.18, 1.9, 0.59, 1.36, 0.96, 1.68, 0.34, -1.48, -1.12, -1.53, -0.34, 0.72, -0.32, 0.017142857142857144, -0.16, 1.35, -2.32, 0.9, -0.57, -1.24, -0.39, 1.71, 2.22, 1.85, 0.37, -0.05, 1.16, 2.23, 1.18, 1.4914285714285713, 1.34, 2.87, -0.85, 2.42, 0.93, 0.24, 1.11, 0.6374684253532109, 2.1449361992161733, 1.47, -0.42, 0.79, 1.86, 0.81, 1.11, 0.96, 2.5, -1.21, 2.068065468086443, 0.56, -0.13, 0.74, 0.13, 1.16, 1.12, 1.56, 1.9, 1.21, 2.28, 1.23, 1.54, 1.39, 2.93, -0.8, 2.6334211542425834, 0.98, 0.4553389784818358, 1.16, 1.07, 0.68, 1.06, 0.02, 0.32, 0.17, 1.69, -1.99, 1.25, -0.23, -0.91, -0.05, 1.98, 4.42, -4.46, -0.38, -1.02, -0.73, -0.88, 0.63, -3.01, 0.19, -1.27, -1.95, -1.1, 3.06, 0.66, 0.3, 0.15, 1.67, -2.01, 1.22, -0.25, -0.93, -0.07, 0.86, 0.68, -1.63, 0.79, 0.94, 0.7, 0.35, -0.15, 1.37, -2.3, 0.92, -0.55, -1.23, -0.37, 0.97, 0.5, 1.52, -2.15, 1.07, -0.4, -1.08, -0.22, 1.76, 0.48, -0.3, 0.943186783623568, 6.05, 0.18, -0.06, -0.84, 0.81, 0.43, 0.96, 0.71, -5.31, -1.53, -0.81, 2.94, 0.41, 2.43, -2.47, -2.37, 0.78, -1.23, 1.57, 0.88, -0.44, 1.07, -9.29, -0.75, -1.14, 5.293809523809524, -1.0, -3.62, -0.44, -1.89, -2.56, -1.72, 2.37, 2.7201587301587304, 3.3, 1.79, 1.1, 1.97, -0.56, -1.46, -2.13, -1.28, 1.74, 1.88, 0.91, -0.68, 0.18, 0.81, 0.76, 0.9225760496238784, -4.66, -0.61, 4.6, 1.75, 1.47, 1.6, 0.86, 0.58, 0.36, 0.54, 0.39, 0.06, 0.73, 2.46, 2.92, 0.3730167737073973], ['294', 3.64, 0.18, 0.4012217156204588, 0.05, 0.8129790809910595, 0.46, 1.2441152579598291, 0.93, 0.94, 3.73, 3.08, 2.558992063492063, 3.1, 2.4, 3.45, 3.21, 2.6599999999999997, 3.37, 7.7, 1.9966428571428572, 3.9, 3.33, 3.17, 3.36, 0.77, 0.64, 0.63, -0.52, 0.02, -0.66, 0.36, 0.13, -0.43, 0.28, 4.48, -1.06, 0.79, 0.24, 0.09, 0.27, 0.26, 2.08, 1.16, 0.54, -0.14, 0.88, 0.65, 0.09, 0.81, 5.03, -0.55, 1.32, 0.76, 0.61, 0.8, 0.14, 1.13, 1.43, 0.97, 0.61, -0.68, 0.34, 0.11, -0.45, 0.27, 4.46, -1.08, 0.77, 0.22, 0.2353389784818358, 0.25, 0.88, 1.3, 1.03, 0.79, 0.23, 0.95, 5.17, -0.4, 1.46, 0.9, 0.76, 0.94, 1.08, 1.55, -1.5, 0.27, -0.23, -0.79, -0.08, 4.11, -1.42, 0.43, -0.12, -0.27, -0.09, 0.19, 0.5, -0.56, 0.16, 4.35, -1.19, 0.67, 0.11, -0.04, 0.15, 0.43, 0.51, 0.15, 0.58, 0.49, 0.61, 1.07, 0.72, 4.94, -0.63, 1.23, 0.68, 0.53, 0.71, 0.39, 0.35, 4.18, -1.34, 0.51, -0.05, -0.18428571428571427, -0.01, 0.47, 0.55, 0.05, 0.59, 0.47, 0.1, 0.02, -1.44, 1.41, 0.72, 0.53, 0.5561635321120495, -3.3, -1.14, -0.6, 1.84, 0.4, 1.63, -1.74, -1.76, 0.57, -2.1, 1.14, -0.22, 0.12, 3.21, -3.08, -2.12, -3.24, 3.25, -3.68, -5.3, -3.53, -4.06, -4.2, -4.03, 1.71, 1.71, 1.87, 1.31, 1.16, 1.35, -0.16, -0.55, -0.7, -0.52, 0.98, 1.01, 0.39, -0.15, 0.03, 0.52, 0.61, 0.94, -1.26, -0.1, 1.24, 0.91, 0.31, 0.54, 0.18, 0.61, 0.65, 0.59, 0.58, 0.8, 0.36, 0.81, 0.81, -0.58], ['295', -0.38, -0.23, 0.011221715620458745, -0.12, -1.09, 0.29, 1.78, -0.02, -0.17, -0.77, -0.2, -1.45, -0.19, -0.58, 0.38, -0.34, -1.09, -0.64, 0.07, 1.01, -1.12, -0.87, -1.16, -1.2, 0.0, 0.18, -0.5373416050068875, -1.25, 0.01, -0.39, 0.58, -0.14, -0.9, -0.45, 0.27, 1.21, -0.92, -0.67, -0.96, -1.0, -0.29, -1.77, 0.7, 1.28, 0.88, 1.86, 1.13, 0.3992789115646258, 0.82, 1.54, 2.490714285714286, 0.34, 0.59, 0.39714285714285713, 0.26, 0.0, 0.07, 0.0, -0.61, -0.57, -0.39, 0.57, -0.14, -0.9, -0.45, 0.26, 1.2, -0.93, -0.68, -0.97, -1.01, 0.06, -0.18, 0.97, 0.25, -0.51, -0.06, 0.66, 1.6, -0.54, -0.28, -0.58, -0.62, -0.61, 1.01, -1.05, -1.14, -0.71, -1.47, -1.02, -0.31, 0.62, -1.49, -1.24, -1.53, -1.57, -0.62, -0.43, -0.76, -0.31, 0.41, 1.35, -0.79, -0.53, -0.83, -0.87, -0.28, -0.46, 0.62, 0.31, 0.25, 0.22, 0.33, 0.5865993906886765, 1.18, 2.12, -0.03, 0.23, -0.07, -0.051415316116934326, 0.0, -0.12, 0.72, 1.66, -0.48, -0.22, -0.52, -0.56, 0.04, 0.1, -0.013962821121959568, -0.45, -2.36, -0.22, -0.13, -0.65, 0.71, 0.34, -0.2859337265331848, -0.28, 3.32, -0.61, -0.28, -0.15, 0.26307978986877906, 0.63, -0.87, -0.94, 0.3, -1.1, 0.63, -1.01, 0.26, 0.92, 3.46, -0.51, -0.94, -3.28, -0.5096213151927438, 0.94, -1.19, -0.93, -1.23, -1.27, 0.91, -1.75, -2.1, -1.85, -2.14, -2.18, 0.36, 0.26, -0.04, -0.08, -0.18, -0.45, 0.1, -0.3, -0.34, 0.29, 0.23, 0.02, 1.63, 0.39, -1.84, 0.08, -0.34, 0.4, -0.04, -0.22, 0.19, 0.31, 0.05, 0.6, 0.44, -2.29, -0.36, 0.03], ['296', -1.04, -1.24, 0.03, -0.01, -0.26, 0.5, 0.21, 0.84, 0.2, 0.95, 0.18, 0.61, -0.16, -0.7, -0.31, 2.3, 0.41, 0.87, 3.32, 1.4, 1.04, 0.42, 0.19, 0.3, -1.08, 0.49937141458889195, 0.77, 0.43, -0.34, -0.87, -0.49, 2.12, 0.24, 0.69, 3.14, 1.22, 0.86, 0.24, 0.01, 0.17384172319783917, 0.92, 1.1549361992161733, 0.34, -0.76, -1.3, -0.91, 1.68, -0.19, 0.26, 2.7, 0.78, 0.458065468086443, -0.18, -0.42, -0.3, 0.96, 0.21, 0.32, 0.1, 1.11, -0.54, -0.15, 2.46, 0.58, 1.03, 3.49, 1.56, 1.2, 0.58, 0.35, 0.46, 0.46, 1.66, 0.39, 3.02, 1.1816609275411798, 1.58, 4.05, 2.11, 1.75, 1.13, 0.89, 1.01, 0.51, 2.3, -2.31, 1.3066982383853203, 2.62, 0.73, 1.18, 3.65, 1.71, 1.36, 0.74, 0.5, 0.62, -2.96, -1.31, -1.84, -1.4, 1.0, -0.88, -1.23, -1.83, -2.06, -1.95, -0.04, -1.1606317967746538, 0.0, 0.5315981806829014, 0.69517906963434, 0.39, 0.53, 0.45, 2.9, 0.98, 0.62, 0.01, -0.22, -0.11, 0.49, 0.08, 2.44, 0.53, 0.17, -0.44, -0.67, -0.56, 1.15, 1.17, -0.06, 0.69, -8.78, 0.19, 0.0, -0.13, 0.09246232339089482, 0.04, 0.49, 1.69, 0.76, -0.98, -0.47, -0.45, 0.68, 1.52, -1.55, -1.49, 0.48, -0.21, 0.99, 0.8, -0.32523473571575323, 1.63, -3.4, -1.11, -1.62, -0.89, -2.3, -1.87, -2.21, -2.81, -3.03, -2.92, 1.48, -0.44, -0.35, -0.96, -1.19, -1.08, -0.09, -0.61, -0.84, -0.73, 0.21, 0.5184535464535467, 0.53, -0.23, -0.047751244684983665, 0.51, 0.51, 0.98, -1.36, 0.05, 1.27, 0.83, 0.8, 0.7604317111459968, 0.11, 0.87, -0.03, 0.64, 0.79, 0.14, 0.65, -0.72, 1.23, 0.52], ['297', 0.29, 0.17, 0.04, 0.04, 0.97, -0.1, 1.0641152579598292, 0.59, 0.97, 0.49, -0.82, -0.51, 1.63, -0.38, -0.45, -0.4, 0.25, 0.32, 1.23, -1.63, 0.58, 0.25, -0.06, 0.52, 1.49, 1.19, 1.31, 0.3, 2.46, 0.44, 0.37, 0.4233503401360544, 1.07, 1.14, 2.07, -0.82, 1.4, 1.07, 0.8688796134390452, 1.35, 0.55, 0.27, 1.01, 2.1536589811608606, 0.13, 0.13081502957527658, 0.1264030612244898, 0.77, 0.83, 1.8571355564861205, -1.12, 1.128065468086443, 0.76, 0.46, 1.04, 0.39, 0.65, 0.37, 0.49, -1.12, -1.98, -2.04, -1.99, -1.36, -1.29, -0.39, -3.2, -1.03, -1.36, -1.65, -1.08, 0.76, 0.87, -0.07, -0.02, 0.63, 0.7, 1.62, -1.25, 0.96, 0.63, 0.33, 0.91, 1.09, 1.62, -1.66, 0.94, 0.05, 0.7, 0.77, 1.69, -1.18, 1.03, 0.7, 0.4, 0.98, 4.66, 0.89, 0.65, 0.72, 1.64, -1.23, 0.98, 0.65, 0.35, 0.93, 0.17, 0.95, 0.47, 0.1, 0.2751790696343399, -0.04, 0.24, 0.07, 1.0869325674325676, -1.87, 0.33, 0.0, -0.3, 0.28, 0.24, 0.17, 0.91, -1.94, 0.26, -0.07, -0.37, 0.21, 0.73, 0.39, 0.1, 0.23, 14.207619047619048, 0.01, 0.0, 0.0, -0.02, 0.0, 0.12, 2.7361635321120494, -4.22, -0.21, -0.13, 0.18, 0.09, 0.26, -0.42, -0.34, 0.1, 0.06, 0.19, -0.48, 0.3147652642842468, 0.78, -2.11, -0.59, -0.78, 4.23, -0.74, -2.83, -0.65, -0.98, -1.27, -0.7, 0.3, 2.15, 2.24, 1.9, 1.6, 2.19, -0.09, -0.33, -0.63, -0.05, 0.89, 0.86, 0.24, -0.3, 0.28, 0.11, 0.16, 0.63, -0.63, 0.54, 0.61, 1.27, 1.44, 0.54, 0.58, 0.98, 0.11455285983857427, -1.05, 0.63, -1.26, -0.04, 3.08, 2.4330376647162364, 0.25], ['298', 1.37, -0.28, 0.0, -0.17, -0.4, -0.41, -0.6658847420401709, 0.02, -0.38, 1.05, 0.81, 1.42, 1.34, 0.43, 1.5, 0.42, 1.59, 1.17, 1.6, 1.6, 1.21, 1.53, 1.61, 1.44, -1.04, 0.08, 0.23, 0.6, 0.53, -0.38, 0.68, -0.39, 0.77, 0.36, 0.78, 0.78, 0.39, 0.71, 0.79, 0.63, 0.22, -2.0150638007838264, -0.37, -0.08, -0.98, 0.08, -0.99, 0.17, -0.24, 0.18, 0.17, -0.21, 0.11, 0.19, 0.02, -0.07, -0.07, -0.52, -0.28, -0.29, -0.9, 0.16, -0.91, 0.24, -0.17, 0.25, 0.25, -0.14, 0.18, 0.26, 0.1, -0.73, 0.62, 1.07, -0.01, 1.16, 0.74, 1.17, 1.16, 0.78, 1.1, 1.18, 1.01, -0.55, -1.72, 1.69, -0.41330176161467985, -1.07, 0.09, -0.32, 0.1, 0.09, -0.29, 0.03, 0.11, -0.06, -0.74, 0.63, 1.17, 0.75, 1.18, 1.17, 0.78, 1.1124285714285715, 1.19, 1.02, -0.19, 0.63, -0.21427628811695995, -0.26, -0.39, -0.16, -0.54, -0.41, 0.01, 0.0, -0.38, -0.06, 0.02, -0.15, -0.64, -0.12, 0.42, 0.42, 0.03, 0.35, 0.43, 0.27, -0.32, -0.23, -0.2, -0.25, -1.34, -0.36, -0.35, -0.17, 0.2, 0.08, -1.29, 0.1, 1.0, 0.51, 0.27, 0.69, -0.24, -0.89, 0.87, 0.83, -0.26, -0.23, -0.53, 1.44, -0.71, -1.63, 4.72, 1.1, 1.65, -1.11, -0.54, 0.0, -0.39, -0.07, 0.01, -0.15, -0.8, -0.54, -0.38, -0.06, 0.02, -0.15, -0.16, 0.32, 0.4, 0.23, -0.42, -0.39, -0.47, 0.08, -0.09, -0.27, -0.28, 0.10257604962387837, 2.31, -0.47980037304250067, -2.36, -0.03, 0.14, -0.55, -0.17, 0.22, -0.07, -0.69, 0.55, -0.73, -0.39, -0.54, 0.32, -0.49], ['299', 2.98, 0.43, -0.32877828437954126, 0.38, 1.04, -0.011580376326240524, -0.44588474204017087, -0.1, -0.96, -0.25, 1.31, 0.06, 0.65, -1.2, 0.1, -2.46, 0.11, -0.12, -1.48, -1.52, -0.77, 0.43, 0.79, -0.17, -0.79, 0.68, -1.4973416050068875, -1.23, -0.64, -2.47, -1.1321800287049086, -3.71, -1.18, -1.4, -2.75, -2.79, -2.05, -0.87, -0.51, -1.4061582768021608, 0.12, -1.29, -0.31, 0.59, -1.0921246055531768, 0.03, -2.52, 0.05, -0.18, -1.538347866419295, -1.58, -0.83, 0.36, 0.72, -0.23, -0.5, -0.35, -0.22, -0.62, -0.89, -1.84, -0.55, -3.09, -0.54, -0.77, -2.12, -2.16, -1.41, -0.23, 0.13, -0.81, -0.6, 0.96, 1.31, -1.27, 1.33, 1.1, -0.28, -0.33, 0.44, 1.64, 2.01, 1.0935596417251208, -1.28, -2.54, 2.47, -0.30330176161467987, -2.55, 0.02, -0.21, -1.57, -1.62, -0.86, 0.33, 0.69, -0.26, 1.24, 2.27, 2.63, 2.4, 1.0, 0.96, 1.73, 2.95, 3.32, 2.35, 0.05, 2.29, 0.89, -0.2, -0.38, -0.02, -0.3590429599640126, -0.23, -1.59, -1.63, -0.88, 0.31, 0.67, -0.28, -0.64, -0.13, -1.36, -1.41, -0.65, 0.54, 0.9, -0.05, -1.16, -1.49, 0.6360371788780403, -0.19681321637643204, 2.43, 0.11, 0.4, -0.56, 0.621720125812563, 0.2788101710076211, -0.07, 0.52, -2.58, 0.44, 0.18, 1.52, 0.08, -0.56, 0.66, 0.62, -0.22, -0.77, -0.39, -3.21, 1.61, -1.19, 2.93, 0.66, 1.02, 2.62, 1.25, 0.2871787775716348, 0.72, 1.93, 2.3, 1.33, -0.65, 1.3, 0.77, 1.98, 2.34, 1.38, 0.53, 1.2, 1.57, 0.61, -0.92, -1.33, -0.67, 0.36, -0.59, -0.18, -0.19, -0.05, 1.45, 0.07, -1.36, 0.17, -0.52, -1.02, -0.94, 0.05, 0.08, 0.2, -0.06, -0.09, -0.08, 0.0, -0.43, -0.33], ['300', -6.47, 0.31, -0.13877828437954126, 0.43, -2.0070209190089403, -1.78, -1.6358847420401708, -3.58, -3.0406219456129895, -3.25, 1.3803184712113286, -1.42, -1.12, 0.16, 0.4642857142857143, -1.42, -1.1328571428571428, -3.02, -2.95, -0.09, -4.0, -1.4, -0.15, -2.18, -3.75, -2.34, -4.37, -2.56, -2.26, -1.0, -0.7, -2.56, -2.32, -4.14, -4.07, -1.24, -5.11, -2.54, -1.31, -3.32, -2.98, -4.065063800783826, -1.650696767518196, 0.31, 1.6, 1.91, 0.01, 0.25, -1.62, -1.54, 1.36, -2.61, 0.02, 1.29, -0.77, -4.09, -3.98, -3.68, -3.18, -2.15, 1.29, 1.6, -0.3, -0.05, -1.92, -1.85, 1.05, -2.91, -0.29, 0.98, -1.08, -4.45, -3.4, 0.3, -1.57, -1.33, -3.17, -3.1, -0.24, -4.15, -1.56, -0.31, -2.34, -4.12, -8.17, 8.28, -3.6533017616146797, -1.86, -1.62, -3.46, -3.39, -0.54, -4.406129838415552, -1.85, -0.61, -2.63, -0.84, -1.86, 0.24, -1.63, -1.55, 1.35, -2.62, 0.01, 1.4211089783232642, -0.78, -0.07885812600098302, -1.79, -1.52427628811696, -1.7, -2.05, -1.33, -2.1, -1.87, -1.79, 1.2997126881055456, -2.86, -0.23, 1.03, -1.02, -1.71, -0.24, 0.07, 3.02, -1.01, 1.7857995496566925, 2.96, 0.86, -3.23, -3.6, 0.66, -1.84, -1.66, -0.82, -0.43, 1.21, -1.2, -0.63, -0.73, -3.45, 6.35, 3.32, 1.72, -3.28, -1.22, -5.09, 5.04, 5.08, -1.69, 1.83, -3.38, -5.16, 2.51, -6.26, 11.05, 4.21, 6.28, -6.34, -0.31, 2.95, -1.08, 1.59, 2.88, 0.78, -5.07, -3.16, -3.91, -1.32, -0.06, -2.1, 0.78, 2.7, 4.01, 1.89, -3.09, -3.61, -1.87, 1.27, -0.79, -1.63, -1.72, -3.37, 5.54, -1.99, -5.66, -2.46, -2.27, -3.1, -2.04, -1.99, -0.88, -1.28, -0.82, -1.52, -1.09, -3.48, -2.76, -1.66], ['301', -3.58, 0.25, 0.011221715620458745, 0.02, 0.0, 0.38, 1.26, 0.09, 0.39, -3.2192857142857143, -3.61, -3.79, -4.1, -3.94, -4.840234693877551, -2.04, -3.8342857142857145, -3.15, -5.368518140589569, -2.7192857142857143, -3.62, -3.58, -3.63, -3.85, 0.67, -0.12, 0.4326583949931125, -0.18, -0.4891666666666667, -0.34, -1.44, 1.63, -0.25, 0.48, -1.84, 0.92, -0.01, 0.04, -0.02, -0.25, 0.9, 0.35, 0.59, -0.32, -0.15, -1.26, 1.82, -0.07, 0.66, -1.66, 1.1, 0.18, 0.22, 0.16, -0.06, 0.69, -0.15, 0.3, 0.53, 0.92, 0.17, -0.94, 2.15, 0.25, 0.99, -1.34, 1.43, 0.5, 0.8674648526077097, 0.49, 0.26943877551020406, -0.21, 0.75, -1.11, 1.98, 0.09, 0.82, -1.5, 1.26, 0.33, 0.37, 0.32, 0.1435596417251207, 0.42, 1.25, -1.27, 1.87, 3.12, 1.2, 1.95, -0.4, 2.583744771101914, 1.45, 1.5, 1.44, 1.21, -2.12, -1.1326334687834372, -1.86, -1.14, -3.41, -0.7, -1.62, -1.57, -1.63, -1.85, -0.07, -1.22, 0.0, 0.5815981806829015, 0.5351790696343399, 0.54, 0.66, 0.73, -1.59, 1.17, 0.24, 0.29, 0.23, 0.01, 0.41, -0.07, -2.3, 0.44, -0.3013969800041226, -0.44, -0.5, -0.72, 0.77, 0.73, -0.11, 0.48, -5.94, 0.09, -0.0642857142857143, -1.24, 1.27, 0.61, 0.53, -0.68, 1.03, -1.04, -0.52, -1.8, 0.46, 1.52, -1.59, -1.53, 0.573290804863853, -1.94, 1.04, 0.27, -0.14, 1.84, -1.28, -1.29, -2.02, -0.99, 2.28, 2.81, 1.86, 1.91, 1.85, 1.62, 1.57, -0.51, -0.9164625850340137, -0.87, -0.93, -1.15, 0.41, 0.04, -0.01, -0.24, 0.43, 0.32, 0.37, -0.06, -0.28, 0.52, 0.52, 0.11257604962387836, -0.91, 0.38, 1.01, 0.68, 0.7, 0.43, -0.22, 0.44, 0.47, 0.47, 0.63, 0.57, 0.65, -0.46, 1.23, 0.49301677370739727], ['302', 0.94, 0.48, 0.02, -0.18, 1.22, 0.5, 0.6141152579598291, 0.8017205965359587, 0.79, 2.72, 1.66, 2.62, 1.87, 3.06, 1.7, 2.18, 2.55, 2.72, 2.79, 2.0, 2.94, 1.66, 2.33, 2.05, 0.64, 0.16, 1.0726583949931126, 0.94, 0.2, 1.37, 0.04, 0.51, 0.87, 1.04, 1.11, 0.33, 1.25, 0.0, 0.66, 0.38, 0.26, 0.75, 0.1, -0.73, 0.42, -0.9, -0.43, -0.07, 0.1, 0.17, -0.61, 0.3, -0.94, -0.28, -0.56, 1.53, 0.7, 0.8078279728097839, 0.58, 0.9192452470658775, 1.17, -0.16, 0.3, 0.67, 0.84, 0.91, 0.13, 1.213421154242583, -0.2, 0.46, 0.18, 0.54, -0.32, -1.32, -0.85, -0.49, -0.32, -0.01252355184498033, -1.03, -0.12, -1.35, -0.7, -0.98, 1.15, 1.18, -1.16, 1.01, 0.47, 0.84, 1.01, 1.07, 0.29, 1.21, -0.04, 0.62, 0.34, 0.59, 0.53, 0.36, 0.53, 0.6015238095238095, -0.18, 0.74, -0.51, 0.15, -0.13, 0.03, 0.44, -1.08, 0.49, 0.52, 0.41, 0.17, 0.17, 0.24, -0.54, 0.37, -0.87, -0.21, -0.49, 1.0, 0.0, 0.07, -0.71, 0.21, -1.03, -0.38, -0.66, -0.19, -0.38, -0.1, 0.37, 1.82, 0.28, 0.2, -0.1, 0.07, 0.03, 0.22, 0.69, -1.3194817511227284, -1.0, -0.47, 0.54, 0.52, 1.43, -1.43, -1.54, 0.48, -0.09, 0.95, 1.81, -0.92, 0.46, -0.27, -0.36, -0.46, 1.4, -0.07, -0.7751904761904762, 0.14, -1.1, -0.45, -0.73, 1.45, 0.71, 0.92, -0.33, 0.33, 0.05, -0.21, -1.24, -0.58, -0.86, 0.68, 1.1684535464535466, 1.04, 0.66, 0.38, 0.47, 0.5443963012752908, 0.88, -3.24, -0.48, 3.7892806122448977, 0.49, 0.83, 0.38, -0.28, 0.59, 0.0, 0.7, 0.34, 0.83, 0.66, 0.0, 0.74, -0.21], ['303', -3.2, 0.32, 0.05122171562045875, 0.01, 0.26, 0.2, 0.45, 0.72, 0.63, 0.68, 0.47, -0.27, -1.02, 0.52, -0.54, 1.38, 0.95, 0.71, -1.66, 1.19, 0.77, 0.08, 0.04, -0.47, 1.3, 0.32937141458889196, 0.21, -0.73, -1.48, 0.05, -1.0, 0.9, 0.48, 0.24, -2.12, 0.72, 0.3, -0.39, -0.42, -0.94, 0.7, 0.0, 0.95, -0.76, 0.79, -0.27, 1.65, 1.22, 0.98, -1.4, 1.46, 1.04, 0.34, 0.31, -0.21, -0.04, 0.44, 0.51, 1.02, 1.72, 1.6631047225355606, 0.49, 2.42, 1.99, 1.75, -0.64, 2.23, 1.81, 1.11, 1.08, 0.56, 0.79, 0.16, -1.05, 0.85, 0.43, 0.19, -2.17, 0.67, 0.25, -0.44, -0.48, -0.99, 0.01, 1.69, -1.79, 1.23, 1.9205204081632652, 1.5017857142857143, 1.25, -1.13, 1.73, 1.31, 0.62, 0.58, 0.06, -1.99, -0.68, -0.42, -0.66, -3.0, -0.18, -0.6, -1.28, -1.32, -1.82, -0.06, -0.48063179677465384, 3.25, 0.46, 0.0, -0.02, -0.18819052351387078, -0.24, -2.58, 0.24, -0.17, -0.86, -0.9, -1.3514153161169342, 0.62, -0.02, -2.35, 0.48, 0.06, -0.5042004503433073, -0.66, -1.17, 0.76, 0.84, 0.16, 0.55, -5.57, 0.13, 0.14, -0.98, 1.1117201258125629, 0.5188101710076211, 0.0, 1.9661635321120494, 0.89, -0.95, -0.46, -1.65, 0.44, 1.42, -1.43, -1.32, 0.46, -1.29, 0.9498783572413152, 0.32, -0.16, 0.6607142857142857, -1.85, -0.45, -0.65, -0.9, 2.38, 2.9, 2.47, 1.8172970521541951, 1.73, 1.21, 1.37, -0.5, -0.41, -1.1, -1.13, -1.64, -0.09, -0.69, -0.72, -1.23, 0.57, 0.43, 0.61, -0.03, -0.55, 0.43, 0.45, 0.74, -1.95, 2.25, 2.01, 0.24, 0.9, 0.64, -0.51, 0.0, 0.1, 0.3, 0.42, 0.31, 1.16, -0.57, 0.94, 0.74], ['304', -2.26, 0.35, 0.11, 0.13, -0.39, -0.1, -1.0158847420401709, -0.14, -0.73, -1.34, 0.16, -0.54, -1.05, -0.83, -1.73, -0.87, -1.67, -1.51, 2.59, -1.51, -1.74, -0.96, -1.62, -1.48, 0.6, -0.38, -1.4673416050068875, -0.7, -1.21, -0.99, -1.8321800287049088, -1.03, -1.83, -1.67, 2.42, -1.67, -1.9, -1.12, -1.78, -1.64, -0.2, -1.94, -0.81, -0.52, -0.29, -1.2, -0.33, -1.14, -0.98, 3.14, -0.98, -1.21, -0.32613444352099813, -1.09, -0.94, -0.14, -0.07, 0.59, -0.73, -0.29, 0.22, -0.69, 0.19, -0.63, -0.46, 3.68, -0.46, -0.7, 0.1, -0.57, -0.43, 0.48, -0.51, -0.91, -0.04, -0.85, -0.69, 3.45, -0.68, -0.92, -0.13, -0.79, -0.65, -1.23, 0.66, -0.6, 0.4366982383853202, 0.88, 0.06, 0.23, 4.4, 0.23, -0.01, 0.79, 0.12, 0.26, 0.52, -0.48, -0.82, -0.65, 3.48, -0.65, -0.89, -0.09, -0.76, -0.62, -0.06, -0.56, -0.04, 0.07, 0.07517906963433994, 0.1, 0.34, 0.17, 4.33, 0.17, -0.07, 0.73, 0.06, 0.2, -0.37, 0.17, 4.16, 0.0, -0.24, 0.56, -0.11, 0.03, -0.04, -0.02, 0.29, 0.19, 1.57, -0.01, 0.0, 0.04, 0.0, -0.03, -0.34, -1.13, -0.25, -0.15, -0.07, -1.18, -0.21, 0.17, -0.29, -0.19, 0.05, 0.03, 0.1, -1.69, 0.89, 1.01, -2.18, -0.71, -0.96, 0.31, -3.83, -3.99, -4.22, -3.45, -4.1, -3.96, 0.17, 0.17, -0.24, 0.56, -0.11, 0.03, 0.41, 0.8, 0.13, 0.27, -0.77, -0.97, -0.39, -0.67, -0.53, 0.07, 0.09, -0.13, -1.16, -0.38, 1.16, -0.39, 0.8, 0.28, 0.14, 0.05, -0.27, 0.29, -0.93, 0.15, 0.14, 1.52, 0.29, 0.18], ['305', -1.99, -0.33, 0.05122171562045875, 0.0, -0.04, -0.11158037632624052, 0.44, -0.59, -0.31, -0.95, -0.91, -1.6, -0.29, -0.34, -1.01, -0.61, -0.52, -0.83, -3.2, -1.16, -1.23, -1.57, -1.11, -0.66, -0.28, -0.52, -0.00734160500688754, -0.69, 0.63, 0.58, -0.1, 0.3, 0.4, 0.08, -2.31, -0.25, -0.32, -0.66, -0.2, 0.25, -0.49, -1.0050638007838266, 0.65, 1.33, 1.28, 0.6, 1.0, 1.1, 0.78, -1.63, 0.45, 0.37, 0.03, 0.5, 0.95, -0.54, -0.59, -0.98, -0.54, -0.67, -0.05, -0.7192006802721088, -0.33, -0.23, -0.55, -2.92, -0.87, -0.94, -1.29, -0.82, -0.38, -0.1, -0.62, -0.67, -0.27, -0.18, -0.49, -2.87, -0.82, -0.89, -1.23, -0.77, -0.32, -0.38, 0.21, -0.25, 0.05, 0.4, 0.5, 0.18, -2.21, -0.15, -0.22, -0.57, -0.1, 0.35, -2.26, -0.26263346878343713, 0.1, -0.22, -2.6, -0.55, -0.62, -0.96, -0.49, -0.05, -0.08, -0.38, 0.61, -0.4, 0.08, -0.88, -0.44, -0.32, -2.7, -0.64, -0.72, -1.06, -0.59, -0.15, 0.66, -0.06692325186963273, -2.39, -0.33, -0.4, -0.74, -0.28, 0.17, 0.13, 0.0, -0.06, -0.26, -6.67, 0.1, 0.0, 2.9, -2.84, -1.44, 0.75, -0.17, -0.32, 0.8, 0.42, -1.0, -0.07, -1.21, 1.16, 1.19, -0.356709195136147, 4.22, -0.78, 0.49, -0.23, -1.25, 0.1527091836734694, 0.83, 1.37, 0.39, 2.32, 2.11, 2.04, 1.68, 2.16, 2.62, -1.24, 0.21, -0.07, -0.42, 0.05, 0.5, 0.28, -0.35, 0.12, 0.57, -0.29, -0.38, 0.63, 0.47, 0.92, -0.39, -0.39, -0.53, 0.27, 0.46, -0.33, -0.05, -0.2, 0.15, 0.5227868514969317, 0.2, -1.35, -0.62, 0.21, -0.13, -0.3, 0.62, -0.44, -0.24], ['306', 4.25, 0.14, 0.02, -0.07, 0.61, -0.05, 0.07, 0.07, 0.4, -0.10291156462585038, -0.81, -1.16, 1.05, -1.31, -1.4757142857142858, -2.6, -0.61, -0.56, -2.03, -0.9974455782312925, -0.03, -0.48, -0.75, -0.2, 1.0, 1.099371414588892, 0.3026583949931125, -0.35, 1.88, -0.5, -0.68, -1.8, 0.18, 0.25, -1.22, -0.52, 0.79, 0.33, 0.07, 0.62, 0.84, 0.7549361992161734, 0.62, 2.24, -0.15, -0.33, -1.46, 0.53, 0.61, -0.88, -0.17, 1.15, 0.68, 0.42, 0.97, 0.64, 0.42, -0.21, 0.39, -1.58, -2.34, -2.51, -3.61, -1.67, -1.59, -3.04, -2.35, -1.06, -1.52, -1.78, -1.24, 0.12, 0.77, -0.18, -1.31, 0.68, 0.76, -0.73, -0.02, 1.3, 0.84, 0.57, 1.12, 0.28, 0.43, -0.44, 0.95, -1.13, 0.86, 0.94, -0.55, 0.16, 1.48, 1.01, 0.75, 1.3, 4.59, 2.11, 2.01, 2.09, 0.6255850340136054, 1.31, 2.64, 2.17, 1.9, 2.46, 0.01, 2.11, -1.12, -0.04, 0.02, -0.14, 0.09, 0.08, -1.4, -0.69, 0.62, 0.16, -0.11, 0.44, -0.21, 0.01, -1.47, -0.77, 0.54, 0.20579954965669267, -0.19, 0.36, 0.49, 0.55, -0.07, -0.04, 13.52, 0.04, 0.05, 0.77, -0.75, -0.38, -1.19, 1.26, -1.58, 0.12, 0.03, 2.31, -0.3, -0.11, 0.0, 0.13, -0.02, 1.27, -0.07, -0.24, 0.1547652642842468, 0.26, 1.2006513605442177, -0.17, -0.29, 1.61, 1.51, 0.71, 2.04, 1.57, 1.31, 1.86, -0.08, 0.79, 1.32, 0.85, 0.59, 1.14, -0.52, -0.46, -0.72, -0.18, 0.44, 0.25, -0.06, -0.26, 0.28, 0.07208003431405688, -0.05, 0.14, 0.67, -0.89, -0.59, 0.07, 1.19, 0.2, 0.55, 0.34, -0.16, -0.86, -0.29, -0.57, -0.35, 3.1202406343656346, 1.93, 0.62], ['307', 5.131428571428571, -6.06, -2.47, 0.34, -2.15, -3.84, -4.15, -7.21, -5.86, -4.56, 4.350608843537414, -1.3, 2.46, 4.17, 1.3371428571428572, -7.799285714285714, 1.19, -0.37942857142857145, -4.49, -0.45, -4.69, 1.9, 3.57, 0.67, -6.37, -4.4, -8.52, -5.4, -1.8, -0.16, -2.89, -11.63, -3.02, -4.52, -8.46, -4.59, -8.65, -2.34, -0.73, -3.52, -4.22, -7.35, -3.3, 3.8, 5.54, 2.65, -6.568956349206349, 2.52, 0.93, -3.24, 0.8607142857142857, -3.44, 3.24, 4.93, 1.99, -5.57, -5.6499999999999995, -5.78, -5.81, -6.85, 1.67, -1.11, -9.799999999999999, -1.24, -2.77, -6.78, -2.84, -6.98, -0.4903418367346939, 1.09, -1.75, -8.72, -8.38, -2.73, -11.426705782312926, -2.86, -4.36, -8.32, -4.44, -8.51, -2.18, -0.57, -3.3064403582748794, -7.98, -22.21, 22.31, -5.8, -9.0, -0.13, -1.67, -5.74, -1.75, -5.93, 0.57, 2.22, -0.64, 2.51, 3.52, 10.378571428571428, 8.05, 3.59, 7.97, 3.37, 10.52, 12.33, 9.18, -4.35, 3.5, -7.25, -4.92, -5.58, -4.78, -5.68, -1.55, -5.62, -1.62, -5.81, 0.7, 2.36, -0.52, -6.05, -4.2, -4.13, -0.08, -4.33, 2.28, 4.042857142857143, 1.05, -8.66, -5.98, -0.75, -6.16, 5.1, -8.9796768707483, -7.28, 9.334285714285715, -8.66, -4.31, -5.08, -12.13, 8.36, 10.021428571428572, 4.954547619047619, 2.635221088435374, -3.6, -15.56, 16.117142857142856, 14.994285714285715, -4.92, 13.507142857142858, -9.85, -5.21, 2.63, -17.13, 28.92, 11.37, 17.15, -8.37, -0.07, 4.23, -0.21, 6.69, 8.45, 5.4, -14.83, -4.12, -4.26, 2.36, 4.040857142857143, 1.7685714285714287, 0.14, 6.91, 8.67, 5.8585714285714285, -6.05, -6.97, -6.33, 1.64, -1.21, -4.95, -5.32, -7.24, 14.53, -7.55, -14.36, -5.76, -6.64, -7.85, -2.81, -5.21, -4.11, -2.4, -3.82, -3.93, -5.19, -6.76, -9.7, -6.94], ['308', 1.31, 0.68, -0.038778284379541256, 0.08, 0.25, 1.05, 0.8741152579598291, 0.41, 1.15, 1.37, -0.28, 0.58, 2.37, 1.74, 0.8, -0.09, 0.91, 1.21, 2.21, 0.4, 1.497335482087359, 0.35, 0.41, 0.25, 1.0, 0.739371414588892, 1.65, 0.86, 2.65, 2.02, 1.08, 0.19, 1.19, 1.49, 2.5, 0.68, 1.74, 0.63, 0.69, 0.53, 0.3374684253532108, 1.0249361992161734, 0.78, 1.78, 1.15, 0.22, -0.67, 0.33, 0.62, 1.62, -0.1788095238095238, 0.87, -0.13613444352099813, -0.17, -0.33, -0.12, 0.92, 0.46, 1.66, -0.98, -0.62, -1.53, -2.4, -1.43, -1.13, -0.15, -1.92, -0.726578845757417, -1.97, -1.92, -2.07, 1.75, -0.37, -0.92, -1.8, -0.82, -0.52, 0.47, -1.31, -0.27, -1.36, -1.31, -1.46, 1.15, 3.06, -3.02, 0.56, -0.88, 0.11, 0.41, 1.4, -0.39, 0.66, -0.44, -0.39, -0.54, 4.41, 1.46, 1.0, 1.3, 2.31, 0.49, 1.55, 0.44, 0.5, 0.34, 0.29, 1.55, 1.52, 1.08, 1.03, 0.97, 0.46, 0.3, 1.29, -0.5, 0.55, -0.55, -0.42401213658444736, -0.5914153161169343, 0.94, 0.16, 0.99, -0.8, 0.25, -0.85, -0.79, -0.95, 0.94, 0.51, 0.11, 0.48, 8.924476190476192, -0.05, 0.14, -1.53, 1.54, 0.8, 0.16406627346681524, 0.96, -1.86, -2.06, -1.05, 0.7, 1.61, 2.95, -2.85, -3.16, 1.02, -2.23, 2.08, -0.27, 0.13, 1.4, -4.23, -0.93, -1.45, 1.81, -0.83, -1.77, -0.74, -1.82, -1.77, -1.92, 3.2, 0.96, 1.05, -0.05, 0.01, -0.15, -0.09, -1.09, -1.04, -1.19, 1.09, 1.43, 1.01, 0.06, -0.1, 1.05, 0.89, 0.64, -2.14, 0.9, 2.05, 0.26, 0.57, 0.96, -0.16, 0.41, 1.0, 1.11, 2.46, 1.8, 1.195957527023814, -1.35, 0.46, 0.26], ['309', -5.53, 1.06, -0.31877828437954125, -0.4078571428571427, 1.53, 3.39, 3.33, 4.95, 4.03, 3.810714285714286, -0.99, 0.7, -0.46, -0.3, -0.14, 7.0, -0.05, 2.95, 0.44, 1.05, 3.87, -0.6069251700680272, -1.14, -0.28, 4.75, 2.75, 4.882658394993112, 1.8284685082657772, 0.53, 0.69, 0.86, 8.07, 0.95, 3.98, 1.44, 2.06, 4.91, 0.46, -0.15, 0.71, 3.01, 5.28, 3.090204081632653, -1.15, -1.0, -0.83, 6.26, -0.75, 2.24, -0.26, 0.35, 3.15, -1.31, -1.8142857142857143, -0.6691712018140588, 3.26, 2.6, 4.81, 5.2, 4.29, 0.16, 0.33, 7.5, 0.42, 3.43, 0.91, 1.52, 4.35, -0.15, -0.68, 0.18, 6.37, 4.13, 0.17, 7.33, 0.26, 3.27, 0.75, 1.36, 4.19, -0.31, -0.84, 0.02, 4.5650595238095235, 12.41, -13.77, 3.95, 7.15, 0.09, 3.09, 0.58, 1.19, 4.01, -0.39428571428571424, -1.0, -0.15, -0.64, -2.98, -6.59, -3.777880952380952, -6.13, -5.56, -2.93, -7.12, -7.61, -6.158571428571428, 0.62, -2.96, 3.54, 3.91, 4.11, 3.69, 3.86, 3.0, 0.49, 1.1105357142857144, 3.92, -0.57, -0.4614285714285715, -0.23, 4.19, 0.83, -2.44, -1.84, 0.899562358276644, -3.46, -3.98, -3.14, 4.43, 3.12, -2.16, 4.05, -1.49, 2.12, 1.03, -8.34, 8.35, 4.17, 3.05, 4.38, -4.961283898641042, -7.75, -3.85, -2.7, 2.93, 11.89, -11.69, -11.55, 3.93, -12.34, 7.81, 1.92, -1.19, 11.31, 20.58, 1.91, 1.86, 5.47, 3.36, 0.61, 3.42, -1.05, -1.5687142857142857, -0.72, 11.36, 2.73, 2.79, -1.65, -2.17, -1.33, -0.06, -4.32, -4.587142857142857, -4.0, 4.06, 4.39, 4.45, -0.53, 0.33, 3.84, 3.81, 5.13, -3.24, 3.88, 3.5, 4.02, 4.42, 5.01, 0.87, 3.6, 3.82, 2.5, 3.2409523809523813, 3.7, 4.11, 3.75, 6.34, 4.26], ['310', 11.188571428571429, 0.19, 0.13122171562045873, 0.05, 1.67, 0.84, 1.8641152579598292, 2.28, 2.08, 1.7370884353741496, -1.34, -0.89, -0.33, -0.7, -0.73, 0.23, 0.13, 0.71, -0.73, -0.43, 2.42, 1.76, 0.38, 0.07, 2.53, 1.98, 2.66, 0.46, 1.03, 0.65, 0.62, 1.59, 1.49, 2.08, 0.6377619047619048, 0.92, 3.81, 3.15, 1.75, 1.43, 1.11, 3.34, 2.19, 0.5736589811608608, 0.19, 0.16, 1.13, 1.02, 1.61, 0.16, 0.46, 3.34, 2.68, 1.28, 0.97, 1.53, 1.47, 1.36, 1.85, 1.62, -0.38, -0.4, 0.55, 0.45, 1.04, -0.3990476190476191, -0.10976190476190477, 2.75, 2.1, 0.7127347454133168, 0.4, 2.45, 2.0, -0.03, 0.94, 0.83, 1.4232142857142855, -0.02, 0.27, 3.14, 2.5614285714285714, 1.09, 0.78, 2.37, 2.69, -2.72, 2.03, 0.96, 0.86, 1.44, 0.0, 0.3, 3.17, 2.51, 1.572517006802721, 0.81, 4.31, 1.06, -0.1, 0.48, -0.95, -0.66, 2.19, 1.5563946608946608, 0.15, -0.15, 0.7, 1.09, 0.8, 0.91, 0.86, 0.995673518650032, 1.16, 0.5813469387755101, -0.85, -0.56, 2.29, 1.63, 0.25, -0.05, -0.24, 0.58, -1.1663144197072766, -1.13, 1.709562358276644, 1.05, -0.32, -0.63, 1.16, 1.14, 0.31603717887804045, 0.91, 8.52, 0.4, 0.35, -1.88, 1.961720125812563, 0.94, 0.81, 1.7, -3.49, -1.84, -0.9, 5.59, 0.36, 2.73, -2.76, -2.69, 0.9, -2.83, 1.79, 0.25, -0.13, 3.5, -4.68, -2.35, -3.46, 3.46, 2.03, 0.3, 3.17, 2.51, 1.12, 0.8, 2.7631678995607567, 1.8643542330685188, 2.86, 2.21, 0.82, 0.51, -1.11, -0.64, -1.99, -2.29, 2.340135138670853, 2.09, -0.47, -1.36, -1.66, 1.03, 0.91, 2.18, -2.31, 0.87, 2.31, 1.52, 1.4211825396825397, 0.9, -0.31, 1.03, 0.81, 0.27, 0.22, 0.84, 1.21, 3.31, 2.37, 1.25], ['311', 8.06, 0.48, 0.19, 0.02, 0.38, 1.08, 1.02, 2.33, 1.3, 1.8, 0.74, 0.38, -0.15, -0.4, -0.69, -0.2792857142857143, 0.44, 1.5505714285714287, 3.76, 0.9, 2.31, 0.7230748299319728, 0.15, 0.81, 1.46, 1.58, 1.05, -0.24153149173422278, -0.89, -1.13, -1.42, -1.02, -0.3, 0.8, 3.0, 0.16, 1.56, -0.02, -0.59, 0.07, 1.53, 1.4749361992161734, 1.41, -0.53, -0.78, -1.06, -0.66, 0.06, 1.16, 3.37, 0.52, 1.92, 0.34, -0.23, 0.43, 1.8, 1.42, 1.44, 1.76, 1.95, -0.25, -0.53, -0.13, 0.6, 1.7, 3.92, 1.06, 2.47, 0.88, 0.3, 0.96, 2.36, 2.21, -0.27535714285714286, 0.12, 0.85, 1.95, 4.18, 1.31, 2.72, 1.13, 0.55, 1.21, 1.19, 4.56, -4.474, 2.5008709226619943, 0.41, 1.14, 2.25, 4.48, 1.6016746031746032, 3.02, 1.42, 0.84, 1.5, 4.2, 2.08, 0.73, 1.83, 4.06, 1.19, 2.6, 1.01, 0.43, 1.09, 0.4, 2.02, 1.81, 1.17, 1.21, 1.14, 1.35, 1.1, 3.31, 0.46, 1.86, 0.28, -0.29, 0.36, 1.08, 0.25, 2.18, -0.64, 0.75, -0.6842004503433073, -1.38, -0.73, 1.52, 1.1, 0.29, 0.88, 12.64, 0.13, 0.15, -2.44, 2.43, 1.22, 0.39, 2.35, -1.82, -2.41, -1.17, 4.1, 0.813079789868779, 3.57, -3.78, -3.6, 1.18, -3.78, 2.38, 1.98, -0.98, 4.09, -10.73, -2.76, -4.18, 1.8, -1.9, -2.76, -1.4, -2.93, -3.49, -2.85, 3.57, 0.89, 1.5441925889236814, -0.18, -0.75, -0.09, -0.5, -1.55, -2.11, -1.47, 1.29, 1.25, 1.07, -0.57, 0.08, 1.22, 1.16, 2.13, -5.02, 1.61, 5.13, 2.2, 1.24, 1.65, 0.66, 0.79, 1.21, 1.34, 0.76, 0.81, 0.98, 4.1, 1.78, 1.14], ['312', -3.94, -0.24, -0.08877828437954126, 0.16, -1.47, -1.59, -2.3, -1.91, -2.11, -1.28, 1.28, 0.78, -0.21, 1.17, 0.29, -0.15, -0.49, -0.97, -3.37, 2.03, -1.78, -0.34, 0.4, -0.53, -1.42, -1.58, -2.53, -0.49, -1.47, -0.11, -0.98, -1.41, -1.75, -2.22, -4.6, 0.74, -3.02, -1.6, -0.87, -1.79, -0.81, -2.935063800783827, -2.0497959183673466, -0.98, 0.39, -0.49, -0.92, -1.26, -1.73, -4.12, 1.24, -2.54, -1.11, -0.38, -1.31, -0.6, -0.89, -2.4, -1.95, -1.08, 1.38, 0.49, 0.06, -0.28, -0.76, -3.17, 2.24, -1.58, -0.13, 0.61, -0.33, -2.42, -2.43, -0.88, -1.31, -1.65, -2.12, -4.5, 0.85, -2.92, -1.49, -0.77, -1.69, -2.57, -4.44, 4.44, -1.57, -0.4294795918367347, -0.77, -1.25, -3.65, 1.74, -2.06, -0.62, 0.11, -0.82, -2.25, -1.062633468783437, -0.34, -0.82, -3.23, 2.18, -1.64, -0.19, 0.6911089783232642, -0.39, -0.33, -1.13, -1.01, -1.22, -1.48, -0.88, -0.8, -0.48, -2.9, 2.54, -1.3, 0.15, 0.89, -0.04, -0.94, -0.32, -2.43, 3.03, -0.82, 0.64, 1.38, 0.44, -1.47, -1.35, 0.08, -0.8, -6.76, -0.25, -0.34, 0.98, -0.96, -0.47, -0.69, -2.77, 6.59, 2.45, 1.23, -1.93, -0.82, -3.63, 3.7, 3.67, -1.22, 1.5, -2.44, -2.18, 1.1, -2.44, 11.59, 1.62, 2.43, -6.33, 2.16, 5.6, 1.8472132867132867, 3.14, 3.9, 3.1057617128436457, -3.65, -3.25, -3.5958074110763185, -2.32, -1.6, -2.52, 0.5, 1.47, 2.22, 1.27, -1.8998648613291471, -2.41, -0.95, 0.74, -0.2, -1.23, -1.14, -1.87, 6.4, -0.53, -6.63, -2.63, -2.38, -1.68, -0.93, -0.8599225974772193, -0.58, -1.2, -0.84, -1.14, -0.75, -2.85, -2.9, -0.5], ['313', 7.854285714285714, 0.59, 0.22122171562045873, 0.48, 0.78, 0.53, 0.5641152579598292, 1.04, 0.89, 1.69, 0.78, 0.46, 0.68, 0.26, 0.44, -0.38, 0.51, 0.94, -2.96, 0.87, 2.01, 0.49104421768707485, 1.26, 1.0, 2.37, 1.29, 0.9, -0.32, -0.1, -0.52, -0.34, -1.15, -0.27, 0.16, -3.7, 0.09, 1.22, -0.33, 0.48, 0.26384172319783916, 0.7674684253532109, 0.55, 1.22, 0.22, -0.2, -0.02, -0.83, 0.05, 0.48, -3.4, 0.41, 1.54, -0.01, 0.8971428571428572, 0.54, 0.86, 2.33, 0.88, 0.48, 1.0, -0.42, -0.24, -1.05, -0.17, 0.26, -3.61, 0.19, 1.32, -0.23, 0.57, 0.32, 0.64, 1.43, 0.18, -0.63, 0.25, 0.68, -3.2, 0.61, 1.75, 0.19, 1.0, 0.74, 0.88, 1.49, -1.46, 1.24, -0.81, 0.07, 0.5, -3.38, 0.43, 1.56, 0.01, 0.82, 0.56, 4.91, 2.07, 0.89, 1.32, -2.59, 1.25, 2.4, 0.83, 1.64, 1.39, 0.7, 2.09, 2.26, 0.75, 0.53, 1.2, 1.17, 0.43, -3.45, 0.35, 1.49, -0.06, 1.3685714285714285, 0.49, 1.21, 0.74, -3.86, -0.07, 1.06, -0.49, 0.32, 0.06, 0.88, 0.8, 0.71, 0.97, 14.397619047619049, 0.34, 0.14, -2.72, 2.72, 1.36, 0.86, 1.84, -1.62, -1.52, -0.78, 3.829285714285714, 0.69, 2.5, -2.4, -2.27, 0.76, -4.18, 1.52, -1.74, 0.79, 3.48, -6.48, -2.48, -3.45, 1.66, 4.78, 3.94, 5.11, 3.5, 4.34, 4.08, 2.3, 0.81, 1.13, -0.42, 0.39, 0.13, -0.31, -1.53, -0.73, -0.99, 1.010135138670853, 0.6, 1.24, 0.81, 0.55, 0.82, 0.83, 1.02, -3.31, 2.33, 3.4, 1.18, 0.7, 0.42, -0.25, 1.1, 0.97, 0.78, 0.930952380952381, 0.64, 0.68, 3.04, 2.171595238095238, 0.98], ['314', -0.31, -0.08, 0.0, 0.02, -1.44, 0.08, -0.16, -0.41, -0.3, 0.31, 0.41, 0.64, 0.42, 1.31, 0.19, 0.22, 0.41, 0.14, 4.89, 4.01, -0.01, -0.23, -0.55, -0.5, -0.46, -0.49, -0.1, 0.23, 0.01, 0.9, -0.22, -0.19, -0.01, -0.27, 4.46, 3.58, -0.42, -0.63, -0.95, -0.91, 0.52, 0.014936199216173434, -0.33, -0.22, 0.67, -0.44, -0.42, -0.23, -0.5, 4.22, 3.35, -0.65, -0.86, -1.18, -1.14, -0.27, -0.3, -0.22, -0.15, -0.11, 0.89, -0.22, -0.2, -0.01, -0.28, 4.46, 3.58, -0.256578845757417, -0.64, -0.96, -0.91, 0.2, -0.99, -1.1, -1.08, -0.9, -1.16, 3.533095238095238, 2.66, -1.31, -1.52, -1.83, -1.79, -0.29, 2.34, -2.29, 0.11, 0.02, 0.6399013605442176, -0.06, 4.69, 3.81, -0.2, -0.42, -0.74, -0.69, -1.4, 0.09, 0.19, -0.08, 4.66, 3.79, -0.23, -0.44, -0.76, -0.72, 0.27, 0.06, 3.96, 0.32, 0.26, 0.36, -0.1, -0.27, 4.47, 3.59, -0.41, -0.63, -0.95, -0.9, 0.49, 0.17, 4.75, 3.87, -0.15, -0.36, -0.68, -0.64, 1.31, 0.59, -0.07, 0.08, -4.04, 0.05, 0.0, -0.69, 0.69, 0.39, -0.32, -0.99, 6.95, -0.53, -0.29, -0.15, 0.49, 1.0, -0.95, -0.95, 0.32, -1.09, 0.62, 0.19, -0.1, -0.34, 0.68, 0.15, 0.33, -7.06, -4.37, -0.84, -4.67, -4.88, -5.18, -5.14, 0.94, -3.56, -3.87, -4.07, -4.38, -4.34, 0.32, -0.22, -0.54, -0.49, -0.39, -0.39, 0.54, -0.32, -0.28, 0.31, 0.27, -0.31, 0.01, 2.34, -0.06, -0.49, -1.29, 0.86, 0.05, 0.22, 0.34, 0.47, 0.48, 0.62, 0.895957527023814, -1.11, -2.21, 0.43], ['315', 0.43, -0.45, 0.17, -0.17, 0.25, 0.49, -1.325884742040171, 0.63, 0.92, -0.05, -1.52, 0.64, -1.2, -0.59, -1.39, 0.14, -0.6, -0.21, -0.34, -0.34633673469387755, 0.37, -0.33, -1.09, -0.28, 0.84, 0.32, 1.49, 2.2, 0.33, 0.94, 0.13, 1.69, 0.94, 1.34, 1.2, 1.17, 1.92, 1.21, 0.43, 1.26, 0.3874684253532108, 1.66, -0.4906967675181959, -1.83, -1.23, -2.02, -0.5, -1.23, -0.84, -0.98, -1.01, -0.27, -0.96, -1.73, -0.92, 1.1, 0.24, 0.69, 1.66, 1.16, 0.61, -0.2, 1.35, 0.61, 1.0, 0.86, 0.84, 1.58, 0.88, 0.1, 0.93, -0.35, 0.54, -0.81, 0.73, -0.01, 0.39, 0.25, 0.22, 0.96, 0.27, -0.51, 0.31, 1.7289098639455782, 3.03, -2.88, 1.36, 1.55, 0.81, 1.2, 1.06, 1.04, 1.78, 1.08, 0.3, 1.1840077275244505, 0.05, -0.19, -0.74, -0.3269047619047619, -0.48, -0.51, 0.23, -0.46, -1.23, -0.42, 0.19, -0.17, 2.56, 0.67, 0.71, 0.705673518650032, 0.55, 0.39134693877551024, 0.26, 0.23, 0.97, 0.27, -0.5, 0.32, 0.35, 0.16, -0.14, -0.17, 0.57, -0.12, -0.89, -0.07, 1.31, 1.14, -0.36, 0.38, 0.13, 0.04, 0.14, -1.7, 1.69, 0.84, 1.12, 1.38, -0.7, -1.31, -0.66, 0.23, 0.32, 2.12, -1.96, -2.08, 0.67, -2.47, 1.35, 0.95, -0.53, 1.63, -4.33, -1.04, -1.56, 0.74, 0.29, -0.03, 0.71, 0.02, -0.75, 0.06, 2.11, 0.32, 0.74, 0.05, -0.73, 0.09, -0.42, -0.69, -1.46, -0.64, 0.94, 1.51, 0.28, -0.77, 0.05, 0.78, 0.63, 0.64, -2.15, 1.48, 2.35, 0.54, 0.7, 1.06, 0.82, 0.53, 0.77, 0.67, 0.26, 0.62, 0.23, 0.23, 0.14, -0.08], ['316', 0.58, 1.27, -0.20877828437954127, 0.12, 0.99, 1.48, 1.2741152579598292, 1.58, 1.73, -0.51, -2.07, -2.68, -1.32, -1.97, -1.1, -2.041439909297052, -2.97, -1.49, -1.21, -0.93, 0.14733548208735894, -1.92, -1.9, -3.03, 2.75, 0.63, 1.6326583949931126, -0.62, 0.77, 0.11, 0.99, -0.29, -0.91, 0.59, 0.88, 1.17, 2.23, 0.16, 0.2688796134390452, -0.98, 0.77, 1.3349361992161735, 2.23, 1.4, 0.74, 1.62, 0.3464030612244898, -0.29, 1.22, 1.51, 1.8, 2.8980654680864433, 0.79, 0.8, -0.36, -0.14, 1.54, 1.7, 1.48, 0.82, -0.66, 0.22, -1.05, -1.67, -0.18, 0.11, 0.5239757335335068, 1.45, -0.61, -0.59, -1.73, 3.39, 1.49, 0.88, -0.4, -1.02, 0.48, 0.77, 1.06, 2.12, 0.05, 0.06, -1.09, 1.4, 4.66, -4.69, 0.6, -1.27, -1.88, -0.4, -0.11, 0.18, 1.22, -0.82, -0.81, -1.95, 1.02, 1.9, -0.62, 0.89, 1.18, 1.47, 2.53, 0.45, 0.47, -0.69, 0.87, 1.91, 3.13, 1.78, 1.52, 2.24, 2.53, 1.52, 1.81, 2.1, 3.17, 1.08, 1.09, -0.07, 1.6, 1.0, 0.29, 0.57, 1.63, -0.43, -0.42, -1.56, 1.7618280382942038, 2.13, 0.05, 2.82, 2.01, 0.75, 0.48, -5.45, 5.45, 2.7, 1.52, 2.63, -0.6, -3.56, -1.78, 0.35, 1.0330797898687791, 5.76, -5.71, -5.31, 1.75, -8.17, 3.51, -1.38, 0.7, 7.61, -4.46, -4.99, -7.56, 0.8738095238095238, 0.71, 0.6171787775716348, 1.34, -0.72, -0.7, -1.84, 5.36, 0.42, 1.05, -1.0, -0.98, -2.12, -0.62, -2.02, -2.01, -3.14, 1.7, 1.55, 1.44, 0.01, -1.13, 1.64, 2.0, 1.46, -2.2, 3.4101996269574992, 1.89, 2.2, 2.11, 1.42, -1.15, 2.28, 2.19, 1.07, 0.06, 1.46, 2.6, 3.25, 2.74, 3.41], ['317', -2.88, -0.85, 0.011221715620458745, 0.14, -0.55, 0.1, -1.73, -0.96, 0.0, -1.75, -2.06, -1.28, -0.3960867348791511, -0.23, -1.29, -1.4, -1.25, -1.75, -1.09, -1.75, -1.31, -1.52, -1.27, -1.28, -0.33, -0.29, 0.32, 0.8, 1.64, 1.87, 0.79, 0.68, 0.83, 0.32, 0.9907142857142857, 0.32, 0.77, 0.55, 0.81, 0.8, -0.25, 0.45, -0.48, 0.83, 1.06, -0.02, -0.12, 0.03, -0.48, 0.19, -0.48, -0.03, -0.25, 0.01, 0.0, 0.0, 0.42, -0.44, 0.52, -1.3, 0.23, -0.84, -0.95, -0.8, -1.3, -0.64, -1.3, -0.86, -1.07, -0.82, -0.82, -0.77, -1.52, -1.07, -1.17, -1.02, -1.52, -0.86, -1.52, -1.08, -1.3, -1.04, -1.05, 0.14, -1.12, 1.1, -0.46, -0.11, 0.04, -0.46, 0.21, -0.46, -0.02, -0.23, 0.02, 0.02, -3.04, -0.35, 0.15, -0.35, 0.31, -0.35, 0.09, -0.12, 0.13, 0.12, -0.02, -0.46, 1.24, -0.1384018193170985, -0.10482093036566006, -0.21, -0.5, -0.5, 0.16, -0.5, -0.06, -0.27, -0.02, -0.03, -0.33, 0.0, 0.67, 0.0, 0.45, 0.23, 0.49, 0.48, -0.79, -0.82, 0.3, -0.48, -9.03, 0.06, -0.06, 0.54, -0.56, -0.28, 0.08, -0.34, 0.08, 0.37, 0.13, -1.43, -0.06, -0.52, 0.43, 0.53, -0.14670919513614705, 0.86, -0.37, -1.72, 0.87, -1.46, 1.05, 0.95, 1.5, -0.14, -0.66, -0.66, -0.22, -0.43, -0.18, -0.19, -0.55, 0.0, 0.45, 0.23, 0.48, 0.48, -0.44, -0.22, 0.04, 0.03, 0.0, 0.28, -0.23, 0.25, 0.25, -0.18, -0.22, -0.88, 0.13, 0.0, -0.18, -1.042736189475567, -0.23, -0.48, 0.06278685149693167, -0.17, 0.03, 0.1, 0.19, -0.11, -0.48, -1.5, -1.07, -0.5], ['318', -3.31, 0.45, -0.02, -0.18, 0.65, 0.10841962367375949, 1.64, 0.1, 0.34, 0.03, -0.17, -1.21, 0.17, 0.25, -0.71, 1.64, -0.72, -0.05, -2.71, -1.17, -0.43266451791264104, -0.06, -0.83, -0.5, -0.41, 0.0, 0.2, -1.04, 0.34, 0.42, -0.54, 1.81, -0.55, 0.13, -2.55, -1.0, -0.3, 0.11, -0.66, -0.33, 0.4, 0.07, 1.26, 1.4, 1.48, 0.51, 2.89, 0.5, 1.18, -1.52, 0.04, 0.75, 1.16, 0.39, 0.73, -0.18, -0.21, 0.40782797280978395, 0.03, -0.14, 0.08, -0.88, 1.47, -0.89, -0.21, -2.88, -1.2160242664664933, -0.64, -0.23, -1.0, -0.66, -0.14, -0.22, -0.96, 1.39, -0.97, -0.29, -2.95, -1.41, -0.72, -0.31, -1.07, -0.74, 0.27, 2.55, -2.6, 0.7866982383853202, 2.37, -0.01, 0.67, -2.01, -0.46, 0.24, 0.65, -0.12, 0.27400772752445063, -2.69, -1.58, -2.32, -1.66, -4.28, -2.76, -2.08, -1.67, -2.43, -2.1, -0.06, -1.63, 1.15572371188304, 0.49, 0.54, 0.535673518650032, 0.76, 0.68, -2.0, -0.45, 0.25, 0.66, -0.11, 0.23, 0.12, 0.07, -2.67, -1.12, -0.43, -0.02, -0.78, -0.45, 0.97, 0.89, -0.38, 0.713186783623568, -7.99, 0.29, 0.07, -0.89, 0.971720125812563, 0.39, -0.08, 1.19, -2.48, -0.99, -0.52, -1.73, 0.15, 1.46, -1.46, -1.51, 0.5, -1.27, 0.99, 2.04, -1.03, 2.27, -4.02, -1.5, -2.23, 2.52, 2.82, 1.59, 2.3, 2.72, 1.94, 2.28, 1.48, 1.21, 0.7, 1.12, 0.34, 0.68, 0.5, 0.41, -0.36, -0.02, 0.36, 0.17, 0.09, -0.77, -0.43, 0.52, 0.56, 0.02, -2.07, 1.1, 2.1, 0.66, 1.26, 0.86, 0.34, 0.99, 0.47, -0.38, 0.23, 0.06, 0.615957527023814, 0.78, 1.84, 1.03], ['319', 0.1, 0.3, 0.13122171562045873, -0.14, 0.05, 0.23, 0.9241152579598292, 0.73, 1.12, 1.61, 0.63, 0.73, 0.53, 1.48, 0.74, 2.15, 1.09, 1.01, 8.25, 2.016979591836735, 2.02, 1.11, 0.67, 0.94, -0.28, 0.37, 0.97, 0.1, -0.1, 0.84, 0.1, 1.51, 0.45, 0.37, 7.57, 1.785112244897959, 1.38, 0.47, 0.03, 0.3, 2.4, 3.0049361992161736, 0.86, -0.2, 0.74, 0.0, 1.4, 0.35, 0.27, 7.46, 1.23, 1.308065468086443, 0.37, -0.07, 0.2, 0.07, 0.38, 1.54, 0.79, 1.07, 0.94, 0.21, 1.61, 0.55, 0.47, 7.68, 1.43, 1.48, 0.58, 0.13, 0.4, 1.52, 0.12, -0.73, 0.66, -0.39, -0.47, 6.67, 0.49, 0.53, -0.36, -0.8, -0.54, 1.73, 2.48, -2.4640000000000004, 0.86, 1.4, 0.34, 0.27, 7.45, 1.423744771101914, 1.27, 0.37, -0.07, 0.2, -2.217904761904762, -0.53, -1.04, -1.12, 5.97, -0.17, -0.13, -1.02, -1.45, -1.19, 0.36, -0.39063179677465387, -0.37, 0.46, 0.35, 0.68, 0.51, -0.08, 7.09, 0.88, 0.92, 0.03, -0.41, -0.15, 0.65, 0.59, 7.17, 0.96, 1.0, 0.1, -0.34, -0.07, -0.28, -0.53, -0.13, 0.9, -6.93, 0.65, 0.36, -1.29, 1.28, 0.63, 0.76, 0.14, 0.76, -0.96, -0.49, 0.07, -0.12, 1.57, -1.58, -1.4, 0.45, -2.04, 0.94, 2.97, -1.46, 1.56, -4.13, -1.1, -1.6, -0.8, -6.14, -5.8, -5.75, -6.59, -7.0, -6.76, 1.4, -0.36, 0.04, -0.85, -1.28, -1.02, -0.4, -0.89, -1.33, -1.06, 1.04, 1.22, 0.49, -0.44, -0.17, 0.5, 0.57, 0.85, -1.96, 0.13, 2.15, -0.03, 0.37, 0.93, 0.27, 0.95, 0.6, 0.32, -0.86, -0.03, 0.66, 0.6, -0.61, 1.05], ['320', 3.3242857142857143, 0.11, 0.08, 0.04, -0.2270209190089404, 0.75, 1.74, 0.44, 0.6, -0.29, -0.25, -1.65, 0.42, -0.66, -0.27, -1.67, -0.77, -0.59, -0.14, -0.43, -0.36, -0.7, -0.51, -0.9848833725798009, -0.11, 0.21, -0.04, -1.4, 0.67, -0.41, -0.01, -1.1049642857142856, -0.52, -0.33, 0.12, -0.18, -0.11, -0.45, -0.26, -0.88, -0.15, 0.58, 1.38, 2.11, 1.01, 1.41, -0.02, 0.9, 1.08, 1.54, 1.24, 1.31, 1.0538655564790018, 1.16, 0.53, 0.63, 0.29, 0.45, 0.51, -0.71, -1.08, -0.68, -2.08, -1.19, -1.0, -0.55, -0.85, -0.6165788457574171, -1.12, -0.93, -1.55, 1.17, 0.37, 0.4, -1.02, -0.11, 0.07, 0.7774764481550197, 0.23, 0.3, -0.04, 0.15, -0.48, 0.34, 0.78, -0.8, -0.03, -1.41, -0.5, -0.32, 0.3657885487528346, -0.16, -0.09, -0.44, -0.25, -0.87, 1.48, 1.4, 0.91, 1.1, 1.56, 1.26, 1.33, 0.98, 1.18, 0.54, 0.19, 1.42, 3.56, 0.49, 0.47, 0.47, 0.48, 0.19, 0.64, 0.34, 0.41, 0.07, 0.26, -0.37, 0.48, 0.29, 0.45, 0.16, 0.23, -0.12, 0.07, -0.55, 0.28, 0.37, -0.11, 0.39, 4.29, 0.12, 0.2, -0.6, 0.58, 0.3, 0.47, 0.69, -0.52, -0.98, -0.46, 1.3, 0.32, 1.36, -1.45, -1.44, 0.48, -0.98, 0.94, 0.51, -0.23, 1.37, -0.18, -0.85, -1.34, 0.14, -0.16, -0.29, -0.22, -0.57, -0.38, -1.0, 1.45, 0.14, 0.07, -0.27, -0.09, -0.71, 0.07, -0.34, -0.15, -0.78, 0.56, 0.58, 0.41, 0.19, -0.44, 0.45, 0.44, 0.52, 0.16, 2.92, -1.15, 0.94, 0.82, 0.22, -0.62, 0.6, 0.58, 0.09, 0.27, 0.11, 0.85, 0.49, 0.39, 0.17], ['321', 0.81, -0.23, -0.009847101690729465, 0.02, -0.45, 0.39, 1.74, 0.0, 0.87, 0.23, -0.45, -1.4, 0.27, 1.46, 0.5, -0.07, 0.08, 0.24, -0.93, 1.33, 0.61, -0.29, -0.07, -0.81, 0.83, -0.14, 0.68, -0.95, 0.73, 1.93, 0.96, 0.38, 0.54, 0.69, -0.48, 1.8, 1.07, 0.16, 0.38, -0.36, 0.04, 0.65, 1.65, 1.7, 2.91, 1.93, 1.35, 1.51, 1.66, 0.5771355564861204, 2.78, 2.04, 1.13, 1.35, 0.6, 0.5600628463056766, 0.14, 1.14, 0.54, -0.05, 1.19, 0.23, -0.34, -0.19, -0.04, -1.2, 1.06, 0.34, -0.56, -0.34, -1.08, -0.22, -1.22, -0.95, -1.52, -1.36, -1.21, -2.36, -0.13, -0.84, -1.73, -1.51, -2.24, 0.69, 1.06, -1.07, -0.27, -0.57, -0.42, -0.26, -1.43, 0.83, 0.11, -0.79, -0.57, -1.3, -0.92, 0.3, 0.15, 0.31, -0.86, 1.41, 0.68, -0.22, 0.0, -0.74, 0.04, 0.33, 0.22, 0.36, 0.43, 0.35, 0.14, 0.15, -1.01, 1.25, 0.53, -0.37, -0.15, -0.89, 0.45, -0.01, -0.9063144197072766, 1.1, 0.37, -0.4042004503433073, -0.31, -1.04, -0.22, -0.51, 0.12, 0.3, -3.27, 0.12, 0.03, 0.32, -0.21, -0.13, 0.0, -1.3, 2.16, -0.75, -0.36, 0.37, 0.38, 1.12, -1.02, -1.06, 0.35, 0.38, 0.73, -0.43, 0.23, 0.53, -1.72, -0.3, -0.49, -2.14, 1.17, 2.29, 1.55, 0.64, 0.87, 0.12, 1.12, -1.09, -0.72, -1.61, -1.39, -2.12, -0.38, -0.9, -0.68, -1.41, 0.82, 0.68, 0.52, 0.22, -0.52, 0.4720800343140569, 0.38, -0.05, -0.21, 0.4401996269574993, 0.12, 0.54, 0.33, 0.3, -0.74, 0.26, -0.46, 0.57, 0.12, 1.03, 1.04, -0.79, 0.05, 2.48], ['322', -0.37, -0.77, 0.0, 0.1, -1.75, -0.42158037632624057, -0.7158847420401708, -1.1382794034640413, -1.19, -0.8, 1.2, -0.21, 0.07, 0.31, 1.07, -0.3, 0.23, -0.78, 5.03, 2.15, -0.91, -0.26, 0.79, -0.13, -0.81, -1.24, -1.9373416050068875, -1.39, -1.11, -0.87, -0.12, -1.48, -0.95, -1.95, 3.79, 0.94, -2.08, -1.44, -0.4, -1.31, -3.05, -2.92, -0.59, 0.29, 0.52, 1.29, -0.09, 0.45, -0.57, 5.25, 2.36, -0.7, -0.05, 1.0, 0.08, -0.45, -1.32, -2.6, -0.76, -0.87, 0.3431047225355606, 1.0, -0.37, 0.16, -0.85, 4.95, 2.07, -0.99, -0.34, 0.71, -0.21, -1.15, -1.11, 0.76, -0.61, -0.08, -1.08, 4.7, 1.83, -1.22, -0.57, 0.47, -0.44, -1.93, -4.43, 4.38, -1.85, -1.36, -0.83, -1.83, 3.91, 1.07, -1.96, -1.32, -0.28, -1.1359922724755493, -1.08, -0.5, 0.54, -0.48, 5.34, 2.46, -0.61, 0.04, 1.09, 0.17, -0.2, -0.49, -2.38, -0.77, -0.84, -0.67, -1.03, -1.01, 4.78, 1.91, -1.14, -0.5, 0.55, -0.3114153161169343, -0.57, -0.03, 5.85, 2.95, -0.14, 0.52, 1.57, 0.65, -1.57, -1.51, 0.27603717887804047, -0.81, -3.11, -0.28, -0.28, 1.74, -1.74, -0.88, -0.32, -1.5, 5.77, 1.52, 0.78, -0.22, -0.23692021013122094, -2.21, 2.22, 2.28, -0.76, 2.8, -1.53, -1.34, 0.64, -3.07, 7.08, 1.98, 3.11, -5.69, -5.55, -2.74, -5.66, -5.04, -4.04, -4.91, -2.34, -2.89, -3.0, -2.36, -1.33, -2.23, 0.11, 0.66, 1.72, 0.79, -1.24, -1.31, -0.54, 1.05, 0.13, -0.78, -0.6956036987247092, -1.22, 3.58, -1.66, -3.61, -0.9, -1.01, -1.58, -0.91, -0.56, -0.77, -0.42, -0.01, -0.11, -0.67, -1.02, -2.05, -0.9], ['323', 7.08, 0.06, -0.23877828437954127, 0.05, 0.65, -0.17, 0.71, 0.4, -0.12, 0.77, 1.52, -0.17, -0.07, 1.39, 0.69, -0.3792857142857143, 1.06, 1.3205714285714287, 1.48, 0.27, 0.87, 0.8730748299319728, 1.15, 0.75, 0.23, 0.27, -0.73, -1.67, -1.57, -0.13, -0.82, -1.87, -0.44857142857142857, -0.2, -0.03, -1.23, -0.64, -0.64, -0.37, -0.76, 0.73, -0.74, 0.95, 0.1, 1.56, 0.86, -0.1889563492063492, 1.23, 1.49, 1.66, 0.44476190476190475, 1.04, 1.05, 1.32, 0.9250476190476191, 0.6700628463056766, 1.0842857142857143, 0.38, -0.32, 0.84, 1.46, 0.76, 0.3385714285714286, 1.13, 1.39, 1.56, 0.34, 0.94, 0.94, 1.22, 0.82, 1.31, -0.61, -0.69, -1.3133418367346938, -0.32, -0.07, 0.1, -1.1, -0.52, -0.51, -0.24, -0.63, -0.66, -0.85, 0.87, 0.09, -1.06, 0.37, 0.63, 0.79, -0.42, 0.18, 0.2757142857142857, 0.46, 0.06, 1.932095238095238, 1.16, 1.4528571428571428, 1.71, 1.88, 0.65, 1.25, 1.502816996495568, 1.54, 1.13, -0.66, 1.21, 0.65, -0.12, -0.37, 0.05, -0.28, 0.25, 0.42, -0.79, -0.19, -0.19, 0.08, -0.31, -0.02, -0.54, 0.17, -1.04, -0.45, -0.44, 0.41999999999999993, -0.56, -0.49, -0.13, -0.26, -0.29, 4.0, -0.1319304505018789, -0.47, -0.63, 0.55, 0.33, 0.0, 1.12, -1.1, 0.27, 0.14142857142857143, 3.51, -0.25, -0.38, 0.36, 0.38, -0.11, -0.8, -0.24, -0.7516093450200592, 0.48, -0.84, -2.95, 0.56, 0.97, 1.07, -0.7, -1.2, -0.61, -0.6, -0.33, -0.73, -0.31, 0.5, 0.6, 0.6, 0.9298095238095239, 0.48, -0.09, 0.01, 0.28, -0.12, -0.11, -0.51, -0.1, 0.27, -0.12, -0.11, -0.15, 0.52, -1.5, 0.38, 1.18, -0.31, -0.7, -0.37, -0.4, -0.53, 0.0, 0.43, -0.79, 0.43, 0.03, -0.38, -0.44, -0.57], ['324', -1.5, -0.19, 0.1, -0.06, -0.4, 0.19841962367375948, 1.17, -0.69, 0.05, -1.31, -1.08, -2.25, -0.39, -0.74, 0.3, -1.07, -1.82, -1.4, -2.68, -1.34, -1.66, -1.48, -1.61, -1.83, -0.54, -1.05, -0.24, -1.19, 0.7, 0.34, 1.39, 0.01, -0.75, -0.32, -1.62, -0.27, -0.5155463299214309, -0.41, -0.53, -0.76, -0.9, -0.9450638007838266, 0.96, 1.91, 1.55, 2.61, 1.21, 0.44, 0.87, -0.43, 0.93, 0.6, 0.79, 0.66, 0.44, -0.41, -0.29, 0.37, 0.55, -0.93, -0.35, 0.69, -0.69, -1.43, -1.01, -2.3, -0.96, -1.28, -1.1, -1.22, -1.44, -0.3, -0.58, 1.04, 0.09665816326530619, -1.09, -0.66, -1.95, -0.61, -0.93, -0.75, -0.87, -1.1, -0.18, 0.97, -1.03, -1.61, -1.37, -2.11, -1.69, -2.97, -1.64, -1.96, -1.78, -1.9, -2.12, -2.51, -0.24, -0.75, -0.33, -1.62, -0.27, -0.6, -0.42, -0.54, -0.76, 0.06, -0.25, 0.83, 0.24, 0.30517906963433994, 0.38567351865003197, 0.51, 0.43, -0.88, 0.48, 0.16, 0.34, 0.22, -0.01, 0.09, 0.09, -1.3, 0.06, -0.27, 0.035799549656692686, -0.21, -0.43, 0.48, 0.57, -0.07, 0.41, -7.41, 0.11, 0.13, -0.38, 0.39, 0.23881017100762114, 0.16, -0.8, -0.07, -0.45, -0.24, -0.74, 0.32, 0.69, -0.79, -0.67, 0.22, -0.59, 0.5298783572413152, 0.25, -0.15, 1.53, -1.25, -1.04, -1.56, 0.07380952380952381, 1.4, 1.37, 1.04, 1.23, 1.1, 0.87, 0.6808051948051949, 0.03, -0.32, -0.14, -0.27, -0.49, 0.36, 0.18, 0.06, -0.17, 0.05, -0.08, 0.17, -0.13, -0.35, 0.24, 0.28, -0.69, -0.86, 0.5, 0.98, 0.0, -0.11, 0.3, -0.22, 0.43, 0.25, 0.27, 0.37, 0.11, 0.52, -1.53, -0.12, 1.3130167737073972], ['325', -2.51, -0.06, 0.02, -0.24, 0.18, -0.05, -4.53, -0.97, -1.18, -0.36, 0.05, 3.4, 0.26, 0.26, 0.98, -0.6, 1.02, 0.02, -0.45, -0.07, -0.01, -0.18, -0.03, 0.19, -0.24, -0.33, -0.41, 3.35, 0.21, 0.22, 0.93, -0.65, 0.97, -0.03, -0.48223809523809524, -0.12, -0.06, -0.23, -0.08, 0.14, -1.0745146341753484, -0.8350638007838266, -3.64, -3.04, -3.03, -2.34, -3.87, -2.3, -3.27, -3.72, -3.36, -3.3, -3.46, -3.32, -3.11, -1.0, -0.8, -0.15, -0.49, -0.62, 0.11310472253556063, 0.72, -0.85, 0.76, -0.24, -0.709047619047619, -0.33, -0.27, -0.43, -0.29, -0.07, -0.78, -0.62, 0.71, -0.86, 0.75, -0.25, -0.71, -0.34, -0.27, -0.44, -0.3, -0.08, -0.61, -1.29, 1.25, -1.33, -1.5594795918367348, 0.04, -0.95, -1.42, -1.04, -0.98, -1.15, -1.0, -0.78, -1.27, 0.3173665312165629, 1.63, 0.62, 0.15, 0.53, 0.59, 0.42, 0.57, 0.79, -0.46, 0.24, -1.51, -0.31, -0.31, -0.53, -1.37, -0.99, -1.46, -1.08, -1.02, -1.19, -1.04, -0.7614153161169342, -0.2, -0.38, -0.47, -0.09, -0.03, -0.19, -0.05, 0.41217743764172343, -0.91, -1.29, -0.11, -0.98, -3.74, -0.4264527417027417, -0.04, 1.12, -1.06, -0.55, -0.64, -1.0, 0.46, 0.61, 0.34, -1.28, -0.26, -0.91, 0.81, 1.02, -0.31, 1.6, -0.74, -1.26, 0.4547652642842468, -4.03, 0.28, 2.69, 3.99, -0.47286904761904763, 0.09, 0.38, 0.44, 0.28, 0.42, 0.64, -1.03, -0.29, 0.06, -0.1, 0.04, 0.26, -0.35, -0.17, -0.02, 0.2, -1.23, -0.41, -0.18, 0.15, 0.37, -0.33, -0.49, -0.7274239503761217, 0.5, -1.45, -0.55, -0.88, -0.1, -0.33, 0.22, -1.08, -0.46, -0.1, -0.2, -0.07, -0.55, -2.01, -0.98, -0.88], ['326', 2.43, 0.7, -0.15877828437954128, -0.24, 0.4529790809910596, 1.01, 1.5541152579598292, 0.83, 1.01, 0.81, -0.66, -0.04, -0.56, 0.34, 0.86, 0.54, -0.11, 0.56, 4.47, 0.23071428571428573, 0.43, 1.7, -0.6, -0.13, 1.49, 0.88, 1.47, 0.62, 0.09, 1.0, 1.52, 1.2, 0.54, 1.22, 5.16, 0.8907142857142857, 1.09, 2.38, 0.05, 0.53, 0.93, 0.94, 0.85, -0.53, 0.38, 0.89, 0.58, -0.08, 0.6, 4.51, 0.27, 0.47, 1.74, -0.57, -0.09, 0.8500628463056766, 0.72, 0.94, 1.16, 1.4592452470658774, 1.0131047225355607, 1.43, 1.11, 0.45, 1.13, 5.06, 0.8, 1.0, 2.28, -0.04, 0.44, 0.5, 0.47, 0.51, 0.2, -0.46, 0.22, 4.11, -0.11, 0.09, 1.36, -0.94, -0.47, 1.35, 3.43, -3.2971666666666666, -0.05, -0.31, -0.96, -0.29, 3.58, -0.62, -0.42, 0.84, -0.9974829931972791, -0.9259922724755494, 1.89, 0.27, -0.65, 0.02, 3.91, -0.31, -0.11, 1.16, -1.14, -0.67, 0.16, 0.33, 1.07, 1.01, 1.06, 0.87, 0.93, 0.68, 4.59, 0.35, 0.55, 1.82, -0.49, -0.02, -0.79, 0.3030767481303673, 3.89, -0.33, -0.13, 1.14, -1.1542857142857141, -0.69, 1.65, 0.49, -0.37, 0.64, 3.71, -0.1, -0.02, -0.79, 0.8, 0.4, 0.34, 2.52, -1.17, -1.99, -1.0, 1.19, 0.66, 2.87, -2.89, -2.9, 1.0, -1.26, 2.05, 1.31, -0.68, 2.76, -6.94, -1.92, -2.77, 1.15, -3.5, -4.06, -3.87, -2.65, -4.86, -4.4, 3.03, 0.58, 0.2, 1.47, -0.83, -0.36, 0.38, 1.27, -1.03, -0.56, 1.05, 1.4184535464535466, -0.88, -2.27, -1.8, 1.07, 0.97, 0.73, -3.43, 1.45, 3.45, 1.89, 1.5, 1.42, 0.48, 0.92, 0.4845528598385743, 0.92, 0.14, 1.48, 0.94, 1.61, 1.77, 1.67], ['327', 0.17, 0.06, 0.22, -0.15, -0.09, 0.39, 0.03, 0.05172059653595872, -0.05, -0.84, -0.1, -1.1, -1.01, -0.72, -1.09, -1.11, -0.71, -0.81, 0.54, -0.52, -0.98, -1.17, -1.3, -1.04, 0.72, 0.21, -0.73, -1.0, -0.91, -0.62, -0.99, -1.01, -0.61, -0.71, 0.65, -0.42, -0.88, -1.06, -1.2, -0.94, 0.0, -1.49, 0.27, 0.09, 0.38, 0.01, -0.01, 0.39, 0.29, 1.66, 0.59, 0.12, -0.07, -0.2, 0.06, -0.54, 1.11, 0.0, -0.11, 0.18, 0.29, -0.09, -0.1, 0.3, 0.2, 1.57, 0.49, 0.03, -0.16, -0.3, -0.04, 0.35, -0.11, -0.37, -0.39, 0.01, -0.09, 1.28, 0.2, -0.26, -0.45, -0.58, -0.32, -0.62, 1.07, -1.07, 0.26, -0.02, 0.38, 0.29, 1.66, 0.58, 0.12, -0.07, 0.24251700680272095, 0.05, 0.68, 0.3573665312165629, 0.4, 0.3, 1.68, 0.6, 0.13, -0.05, -0.19, 0.07, 0.01, 0.27, 0.4, 0.11, 0.29, -0.11, -0.12, -0.1, 1.27, 0.19, -0.27, -0.45, -0.59, -0.27141531611693437, 0.37, -0.02, 1.37, 0.38224471370562696, -0.17, -0.36, -0.49, -0.24, 0.34, -0.15, -0.16, 0.03, 1.86, 0.05, -0.07, 1.63, -1.44, -0.7, 0.18, 0.37, 0.6, -0.23, -0.15, 0.07, 0.05, 0.2, -0.34, -0.36, 0.11, 2.15, 0.21, 1.71, -0.88, -0.01360430839002269, -2.67, 0.26, 0.45, -0.6, -1.37, -0.7328212224283652, -1.52, -1.7, -1.84, -1.58, 0.39, -0.32, -0.46, -0.65, -0.78, -0.53, 0.15, -0.19, -0.32, -0.07, -0.03, -0.44, 0.33, -0.14, 0.12, 0.09, 0.08, 0.02, -1.21, 0.21, 1.24, 0.7172638105244333, 0.3, 0.47, 0.26, 0.3, -0.69, 0.54, -0.21, 0.05, 0.295957527023814, 0.13, 0.58, -0.18], ['328', 6.37, 1.05, 0.92, -0.32, 2.17, 2.41, 2.1941152579598295, 4.28, 3.65, 3.38, -2.19, 1.09, -0.24, -0.84, -1.41, 1.07, -0.46, 1.123469387755102, 2.19, -0.02, 5.13, -0.45, -0.49, 0.21, 4.43, 3.88, 5.7, 3.35, 2.0, 1.38, 0.8, 3.33, 1.77, 3.38, 4.48, 2.22, 7.490760683760684, 1.78, 1.74, 2.45, 3.56, 6.48, 2.27, -1.31, -1.91, -2.47, -0.02, -1.42071768707483, 0.03, 1.09, -1.09, 4.0, -1.52, -1.56, -0.87, 2.36, 4.44, 3.53, 3.23, 3.63, -0.61, -1.17, 1.31, -0.22, 1.35, 2.43, 0.22, 5.38, -0.22, -0.25, 0.45, 4.6, 4.26, -0.57, 1.93, 0.39, 1.97, 3.06, 1.1491309523809523, 6.03, 0.39, 0.36, 1.06, 5.02, 10.76, -10.89, 4.86, 2.51, 0.97, 2.56, 3.65, 1.41, 6.64, 1.597142857142857, 0.93, 1.64, 3.02, 2.29, -1.51, 0.04, 1.1, -1.08, 4.02, -1.51, -1.54, -0.85, 1.96, 2.29, 3.17, 2.86, 2.91, 2.97, 3.85, 1.57, 2.65, 0.44, 5.61, 0.0, -0.03, 0.67, 3.69, 2.24, 1.06, -1.12, 3.98, -1.55, -1.58, -0.89, 3.96, 4.67, 0.13, 3.36, 6.17, 1.13, 0.88, -6.18, 6.17, 3.09, 2.48, 5.41, -6.64, -5.77, -2.89, 3.11, 2.06, 8.83, -8.7, -8.5, 2.84, -9.27, 5.76, 2.99, -1.51, 11.77, -10.43, -7.7, -11.45, 6.81, 1.17, -1.8328212224283653, 2.88, -2.58, -2.62, -1.94, 8.64, 3.4, 5.15, -0.43, -0.47, 0.23, -1.67, -5.31, -5.35, -4.69, 3.68, 4.34, 3.85, -0.03, 0.66, 2.95, 3.004396301275291, 4.31, -5.31, 4.19, 5.42, 3.67, 4.3210935020800125, 3.968637448200971, 0.7, 3.01, 2.68, 1.36, 1.89, 2.39, 3.17, 4.91, 7.18, 3.13], ['329', 0.62, 0.04, -0.49, 0.2, -0.2, 0.38, 0.64, 1.15, 1.15, 1.8, 0.07, 0.57, 0.7, 1.29, 0.04, 1.69, 0.97, 1.59, 3.55, 1.86, 2.15, 1.51, 1.3, 1.73, 1.08, 0.51, 1.73, 0.49, 0.63, 1.22, -0.03, 1.61, 0.9, 1.52, 3.47, 1.79, 2.08, 1.43, 1.23, 1.66, 1.05, 2.45, 1.23, 0.13, 0.72, -0.45918497042472345, 1.11, 0.4, 1.02, 2.961652133580705, 1.29, 1.58, 0.93, 0.8271428571428572, 1.16, 1.15, 1.69, 1.44, 0.87, 1.1792452470658776, 0.59, -0.66, 0.98, 0.27, 0.89, 2.83, 1.15, 1.44, 0.8, 0.6, 1.03, 0.14, 0.5, -1.2253571428571428, 0.39, -0.32, 0.29, 2.22, 0.56, 0.85, 0.21, 0.01, 0.43, 1.6, 2.12, -2.15, 1.76, 1.65, 0.93, 1.55, 3.51, 1.82, 2.12, 1.47, 1.26, 1.7440077275244505, -0.51, 0.11, -0.71, -0.09, 1.83, 0.17, 0.46, -0.18, -0.38, 0.04, 0.13, 0.13244557823129252, 0.88, 0.63, 0.56, 0.76, 0.83, 0.62, 2.55, 0.88, 1.17, 0.53, 0.33, 0.8185846838830657, 0.24, 0.21, 2.173685580292723, 0.26, 0.7286030199958774, -0.09, -0.28, 0.14, 0.2189583699631245, 0.34, 0.44, 0.53, -1.71, 0.01, -0.66, -1.62, 1.73, 0.61, 0.06, 2.85, -0.09, -1.22, -0.61, 0.25, 0.11, 1.85, -1.93, -1.81, 0.11, -2.53, 1.26, -1.14, 0.58, 2.5, -3.34, -1.68, -2.47, 0.04, -1.68, -1.63, -1.34, -1.97, -2.17, -1.75, 1.84, -0.06, 0.29, -0.35, -0.55, -0.13, -0.34, -0.64, -0.83, -0.41, 1.2, 1.22, 0.29, -0.2, 0.22, 0.6, 0.66, 1.12, -1.55, 0.4, 1.42, 0.5172638105244333, 0.46, 0.49, 0.42, 0.03, 0.5, -0.59, -0.5, -0.03, 0.07, 0.58, 1.46, 0.33], ['330', 0.41, 0.0, 0.24122171562045874, 0.19, -0.3, 0.14, -1.2158847420401708, -0.9482794034640413, -0.55, -3.51, -2.75, -2.98, -3.07, -2.81, -2.29, -3.53, -3.38, -3.44, -0.71, -2.53, -3.762664517912641, -3.46, -4.1, -3.82, 0.29, -0.21, -0.78, -0.23, -0.33, -0.06, 0.47, -0.79, -0.64, -0.7, 2.1, 0.23, -1.07, -0.72, -1.2811203865609546, -1.1, -0.38, -1.5950638007838267, -0.55, -0.09, 0.17, 0.71, -0.56, -0.41, -0.47, 2.34, 0.46, -0.811934531913557, -0.49, -1.15, -0.87, -0.14, -0.59, -0.9, -0.79, -0.45, 0.27, 0.8, -0.47, -0.32, -0.2773949338599383, 2.43, 0.55, -0.75, -0.4, -1.06, -0.78, -1.67, -0.72, 0.53, -0.74, -0.59, -0.65, 2.16, 0.28, -1.01, -0.67, -1.33, -0.9864403582748793, -0.85, 1.33, -1.4, -1.24, -1.26, -1.11, -1.17, 1.62, -0.24832539682539684, -1.54, -1.19, -1.85, -1.57, -0.44, 0.02, 0.15, 0.09, 2.92, 1.03, -0.28, 0.07, -0.59, -0.31, -0.06, -0.03, 1.34572371188304, 0.17, 0.26, 0.02, -0.13, -0.06, 2.76, 0.88, -0.43, -0.08, -0.74, -0.46, -0.07, -0.08, 2.82, 0.94, -0.37, -0.02, -0.68, -0.4, 1.04, 0.67, 0.3460371788780404, 0.02, -1.41, 0.13, -0.03, -0.15, 0.1, 0.06, 0.14, 0.39, 1.89, -0.39, -0.19, 0.2, 0.05, 0.48, -0.49, -0.45, 0.18, -0.31, 0.33, -2.021609345020059, 1.084765264284247, -0.45, 0.06, 0.24, 0.43, -1.98, -2.82, -1.84, -3.11, -2.7283894557823127, -3.403248299319728, -3.13, 0.48, -1.0, -1.29, -0.95, -1.6, -1.32, 0.3, 0.35, -0.31, -0.03, -0.58, -0.82, -0.05, -0.66, -0.38, 0.16, 0.11, -0.97, -0.48, 1.48, 0.57, 0.15726381052443328, -0.17, 0.61, 0.29, 0.3100774025227807, 0.1, 0.09, -0.2, 0.17462624382472908, 0.33, -1.57, 0.07, 0.46], ['331', 3.79, 2.18, 0.25122171562045875, -0.19, 0.52, 1.7, 2.63, 1.69, 1.12, 2.48, 1.82, 0.52, 0.79, 1.41, -0.95, 1.65, -0.21, 1.73, 6.53148185941043, 1.12, 2.36, 1.69, 0.31, 0.91, 0.83, 1.259371414588892, 0.65, -1.28, -1.01, -0.4, -2.72, -0.17, -1.99, -0.09, 4.61, -0.69, 0.53, -0.13, -1.48, -0.8561582768021608, 1.93, 0.79, 2.149303232481804, 0.27, 1.057875394446823, -1.46, 1.12, -0.73, 1.2, 5.97, 0.6, 1.83, 1.16, -0.21, 0.38, 0.4, 1.06, 1.18, 1.12, 1.67, 0.62, -1.73, 0.85, -0.99, 0.93, 5.68, 0.33, 1.56, 0.89, -0.48, 0.11, 2.13, 1.05, -2.33, 0.23, -1.6, 0.31, 5.03, -0.29, 0.94, 0.28, -1.09, -0.5, 0.33, 6.15, -6.06, 3.46, 2.62, 0.75, 2.7, 7.54, 2.09, 3.34, 2.66, 1.27, 1.9240077275244507, 1.49, 0.8973665312165628, -1.83, 0.08, 4.79, -0.52, 0.7, 0.04, -1.1788910216767359, -0.73, 0.85, 0.86, 1.99, 1.71, 1.65, 1.79, 2.69, 1.94, 6.74, 1.33, 2.58, 1.9603050194472875, 0.52, 1.12, 0.99, 0.74, 4.71, -0.6, 0.62, -0.04, -1.4, -0.81, 2.18, 2.72, 0.24603717887804044, 1.85, 4.83, 0.36, 0.21, -4.53, 4.57, 2.3, 2.53, 1.37, -2.72, -3.44, -1.74, 1.91, 1.34, 5.07, -5.1, -4.89, 1.72, -6.83, 3.42, 2.6, -1.31, 8.12, -15.54, -5.38, -8.02, 2.63, -3.79, -5.07, -3.9, -4.53, -5.83, -5.27, 5.17, 1.34, 1.23, 0.56, -0.8, -0.21, 0.11, -0.66, -2.01, -1.42, 1.192795351473923, 0.57, 0.78, -1.36, -0.77, 1.69, 1.79, 1.72, -8.15, 2.48, 8.28802380952381, 1.92, 0.99, 2.16, 0.6627868514969316, 1.85, 2.16, 1.81, 1.12, 1.2, 1.56, 2.19, 1.13, 0.37], ['332', 1.42, -0.11, 0.17122171562045874, 0.0, 0.97, 0.84, 1.11, 0.72, 0.43, 0.99, 0.47, 0.47899206349206347, -0.02, 0.41, 0.39, 0.37, -0.69, 0.57, 7.87, -1.49, 0.35, 0.01, 0.12, 0.05, 0.24, 0.54, 0.52, 0.0, -0.49, -0.06, -0.08, -0.09, -1.15, 0.21725890414440846, 7.36, -1.95, -0.04554632992143094, -0.46, -0.35, -0.42, -0.05, 0.40493619921617346, 0.52, -0.49, -0.06, -0.07, -0.09, -1.15, 0.11, 7.37, -1.95, -0.11, -0.46, -0.34, -0.42, -0.38, 1.54, 0.97, 0.52, 1.01, 0.5331047225355606, 0.42, 0.4, -0.67, 0.6, 7.89, -1.47, 0.38, 0.03, 0.14, 0.07, 0.38, 0.57, -0.02, -0.04, -1.1, 0.16, 7.43, -1.89, -0.06, -0.4, -0.29, -0.36, 0.61, 2.7, -2.76, 0.59, -0.02, -1.08, 0.18, 7.45, -1.6862552288980859, -0.04, -0.39, -0.27, -0.34, 0.37, 0.6873665312165629, -1.06, 0.2, 7.46, -1.86, -0.02, -0.37, -0.25, -0.33, 0.53, 0.63, 3.14, 0.96, 0.89, 1.1, 1.6909570400359875, 1.27, 8.62, -0.81, 1.05, 0.7, 0.8959878634155526, 0.74, 0.7, 0.41, 7.25, -2.05, -0.22, -0.56, -0.45, -0.52, 1.0, 1.25, 0.08603717887804044, 1.04, 1.15, 0.35, 0.25, -2.8, 2.81, 1.41, 0.45, 1.3761635321120496, -5.022241020883878, -1.92, -0.96, 0.79, 0.53, 2.970596861471862, -2.83, -2.84, 0.98, -4.24, 1.95, 0.5883906549799409, -0.23, 4.96, -4.7, -3.32, -5.03, 5.13, -6.38, -8.67, -6.97, -7.29, -7.18, -7.25, 2.89, 2.51, 1.87, 1.52, 1.64, 1.56, 0.63, -0.35, -0.23, -0.3, 0.47, 0.45, 0.98, 0.11, 0.04, 0.99, 1.1143963012752909, 0.82, -3.28, 2.28, 3.57, 0.87, 1.41, 0.86, -0.07, 1.22, 1.28, 0.44, -0.2566666666666667, 1.14, 1.025957527023814, 0.37, 1.71, 1.06], ['333', -16.58, -2.44, -0.77, 0.51, -3.42, -4.18, -2.705884742040171, -7.14, -4.23, -7.18, -2.04, -4.81, 0.05, -0.41, -0.8957142857142857, -4.311439909297052, -3.4771428571428573, -5.462517573696145, -6.28, -1.27, -8.22, -4.56, -3.32, -3.35, -6.12, -6.28, -5.25, -2.83, 2.13, 1.67, 1.16, -2.64, -1.47, -3.82, -4.33, 0.79, -6.31, -2.5, -1.31, -1.34, -4.82, -4.36, -2.49, 5.11, 4.63, 4.11, 0.21104365079365078, 1.4, -1.02, -1.54, 3.72, -3.58, 0.26, 1.57, 1.53, -4.69, -3.7799999999999994, -6.91, -4.88, -7.22, -0.45, -0.95, -4.47, -3.53, -5.83, -6.32, -1.32, -8.27, -4.61, -3.37, -3.4, -9.46, -6.8, -0.5, -4.176705782312926, -3.09, -5.4, -5.9, -0.87, -7.85, -4.18, -2.93, -2.96, -5.13, -13.79, 11.37, -6.34, -3.76, -2.6, -4.93, -5.43, -0.37, -7.39, -3.6842857142857146, -2.44, -2.47, -7.72, -2.67, 1.8285714285714285, -1.21, -1.73, 3.52, -3.76, 0.07, 1.37, 1.34, -1.44, -2.69, -5.48, -4.01, -3.87, -4.32, -3.83, -2.38, -2.9, 2.29, -4.91, -1.12, 0.17, 0.13, -2.71, -1.48, -0.53, 4.79, -2.59, 1.29, 2.6928571428571426, 2.58, -4.1, -2.4, 0.4, -4.34, -15.19, -2.0396768707482993, -1.24, 9.164285714285715, -8.57, -4.28, -0.92, -11.12, 11.68, 8.251428571428571, 4.064547619047619, -8.41, -2.84, -12.3, 12.967142857142857, 12.344285714285714, -4.03, 13.357142857142858, -8.03, -8.53, 4.15, -11.68, 22.44, 7.75, 11.54, -12.15, -0.96, 5.34, -2.07, 1.83, 3.15, 3.12, -12.14, -5.99, -7.04, -3.34, -2.08, -2.0185714285714282, 1.13, 3.98, 5.34, 5.538571428571428, -4.41, -4.74, -2.74, 1.3, 1.27, -3.96, -4.03, -7.3, 11.03, -5.29, -11.18, -6.05, -6.66, -3.99, -0.03, -4.34, -4.0, -2.81, -2.49, -3.08, -3.96, -7.61, -8.94, -3.38], ['334', 1.18, -0.12, -0.1, 0.25, 0.04, -0.24, -0.31, -0.07, -0.07, -0.8629115646258504, -1.87, -0.6406751700680272, 0.23, -0.64, -1.0, -1.73, -1.11, -1.38, -1.13, -1.37, -1.13, -1.45, -1.675694768399324, -1.21, 0.29, 0.78, 0.57, 1.24, 2.14, 1.25, 0.88, 0.14, 0.77, 0.5, 0.75, 0.51, 0.75, 0.43, 0.09, 0.67, -0.99, -0.24, -0.66, 0.89, 0.01, -0.35, -1.08, -0.46, -0.73, -0.48, -0.72, -0.48, -0.8, -1.13, -0.56, -0.2, -1.2, -0.4, -0.29, -1.53, -0.87, -1.23, -1.95, -1.34, -1.61, -1.35, -1.6, -1.35, -1.68, -2.0, -1.231743720565149, 0.6436060011417155, -0.67, -0.36, -1.09, -0.47, -0.74, -0.49, -0.73, -0.49, -0.81, -1.14, -0.57, 0.13, 0.75, -0.74, -0.30912907733800593, -0.74, -0.11, -0.39, -0.13, -0.37, -0.13, -0.45, -0.78, -0.21, 2.99, 0.5073665312165629, 0.63, 0.35, 0.61, 0.36, 0.61, 0.28, -0.05, 0.53, 0.09, 0.46, 1.24, -0.16, -0.01, -0.2, -0.12819052351387078, -0.27, -0.01, -0.26, -0.01, -0.34, -0.67, -0.1, 0.27, 0.07, 0.26, 0.01, 0.26, -0.07, -0.4, 0.17, -0.09, -0.47, 0.21, -0.05, 8.29, 0.25, 0.14, 1.56, -1.54, -0.81, 1.66, -0.64, -0.07, 0.35, 0.17, 0.61, 0.0, -0.61, 0.61, 0.57, -0.21, 2.43, -0.36, -1.25, 0.59, -0.54, 3.34, 0.35, 0.44, 0.06, -0.18, -0.25, 0.0, -0.28838945578231295, -0.66, -0.08, -0.55, 0.06, 0.25, -0.08, -0.41, 0.16, -0.18, -0.33, -0.65, -0.08, -0.12, 0.04, 0.14, -0.33, 0.31224875531501634, -0.19, -0.11, -0.12, 2.73, 1.64, -2.55, -0.36, -0.5088174603174603, 0.48, 0.57, 0.48, -0.41, 0.08, 0.59, -0.87, -0.1, -0.19, -0.93, 0.37], ['335', 4.68, -0.48, -0.04, 0.12, -0.49, -0.87, -0.38588474204017087, -1.06, -0.7, -1.1, -0.07, -0.99, 0.17, 0.72, -0.98, -2.04, -0.26, -0.92, 1.851481859410431, -0.02, -0.85, -0.74, -0.28, -0.41, -1.29, -0.88, -1.03, -0.92, 0.24, 0.79, -0.91, -1.97, -0.19, -0.85, 1.91, 0.05, -0.78, -0.67, -0.21, -0.2961582768021609, -0.06, -1.7650638007838266, -0.11, 1.18, 1.72, 0.01, -1.06, 0.74, 0.07, 2.861652133580705, 0.98, 0.168065468086443, 0.26, 0.72, 0.58, -0.42, -0.61, -0.98, -0.52, -1.27, 0.54, -1.15, -2.21, -0.43, -1.09, 1.66, -0.19, -1.03, -0.91, -0.45, -0.59, -0.7, -1.8, -1.68, -2.74, -0.97, -1.62, 1.12, -0.73, -1.56, -1.44, -0.99, -1.12, -1.23, -2.18, 2.13, -0.08330176161467984, -1.07, 0.73, 0.06, 2.85, 0.97, 0.13, 0.25, 0.71, 0.57, 0.4912233560090703, 1.047366531216563, 1.82, 1.15, 3.96, 2.07, 1.21, 1.33, 1.8, 1.66, -0.15, 0.93, -0.5, -0.8, -0.79, -0.73, -0.84, -0.66, 2.11015873015873, 0.24, -0.59, -0.48, -0.02, -0.15, -0.15346392892821453, -0.18, 2.78, 0.91, 0.07, 0.18, 0.65, 0.51, -1.11, -1.22, 0.20603717887804043, -0.7, 0.61, 0.03, 0.0, 1.49, -1.51, -0.75, 0.07406627346681526, -1.1938364678879505, 2.04, 1.62, 0.81, 2.35, -0.64, -2.43, 2.44, 2.35, -0.8, 2.3, -1.59, -1.1, 0.5747652642842468, -2.46, 5.36, 1.63, 2.46, -2.13, -2.88, -1.82, -2.64, -2.53, -2.08, -2.21, -2.42, -1.08, -0.83, -0.72, -0.26, -0.4, -0.25, 0.12, 0.58, 0.44, -0.65, -0.79, -0.36, 0.6532337781266354, 0.32, -0.79, -0.79, -1.01, 2.5, -0.5, -2.53, -1.56, -1.09, -0.82, -0.14, -0.81, -0.77, -0.75, -1.09, -0.28, -0.68, -1.8497593656343654, -2.01, -1.42], ['336', 4.03, -0.4, -0.36, 0.08, 0.62, -1.08, -0.71, -1.55, -2.05, -2.23, 0.68, -1.1392857142857142, -0.86, -1.62, -1.89, -2.06, -0.83, -1.75, -2.38, -2.08, -2.6, -1.0, -2.42, -1.1, -1.2, -0.35, -2.9, -1.81, -1.53, -2.29, -2.55, -2.73, -1.5, -2.42, -3.05, -2.728642857142857, -3.27, -1.67, -3.08, -1.78, -0.88, -1.7350638007838266, -1.1, 0.29, -0.49, -0.75, -0.93, 0.32285714285714284, -0.61, -1.26, -0.95, -1.48, 0.14, -1.2742857142857142, 0.04, -2.25, -1.04, -2.73, -2.86, -1.39, -0.77, -1.04, -1.21, 0.03, -0.9, -1.5228197278911566, -1.24, -1.76, -0.14, -1.57, -0.25, -1.67, 0.02571428571428569, -0.27, -0.44, 0.81, -0.13, -0.77, -0.47, -1.0, 0.6642857142857143, -0.81, 0.53, -2.51, -0.44, 0.53, -0.35, -0.18, 1.08, 0.17, -0.51, -0.2, -0.73, 0.91, -0.54, 0.8, 1.54, -0.18, 1.26, 0.32, -0.33, -0.03, -0.56, 1.08, -0.37, 0.97, -0.57, -0.16764311878597596, 0.86, -1.03, -0.96, -1.15, -1.42, -0.93, -1.57, -1.27, -1.79, -0.17, -1.6, -0.28, -1.4, -0.49, -0.3963144197072767, -0.34, -0.87, 0.76, -0.68, 0.65, 0.7, -0.85, 0.42, -1.47, 3.02, 1.17, 0.97, 2.33, -2.26, -1.12, -2.25, -1.91, 0.43, 2.06, 1.03, 2.21, -1.39, -3.14, 3.15, 3.01, -1.0, 3.47, -2.01, -1.5, 0.73, -4.27, 3.28, 3.0328571428571425, 4.1814285714285715, -0.28, 0.15, 0.3, -0.23, 1.461610544217687, -0.04, 1.31, -2.93, -0.15, -0.53, 1.11, -0.34, 1.0, 0.38, 1.65, 0.27, 1.54, -2.03, -2.55, -1.25, -1.43, -0.11, -0.99, -1.07, -1.58, 1.66, 0.29, -1.72, -0.42, -1.18, 0.19, 1.35, -1.3, -1.08, -1.09, -1.34, -1.48, -1.14, -0.4, -1.06, -1.2], ['337', 10.69, 2.9, -1.0587782843795412, 0.53, 0.68, -2.19, -2.39, -2.76, -3.83, -1.4529115646258504, 2.980608843537415, 1.08, 1.35, -0.8339200680272107, 2.07, -4.34, 0.46, -1.07, -1.61, -3.31, -2.62, -2.9769251700680273, 1.43, 0.26, -2.5214063389924735, -0.39, -4.697341605006888, -1.84, -1.5491666666666668, -3.99, -0.87, -7.1, -2.43, -3.92, -4.45, -6.1, -5.43, -5.7, -1.49, -2.63, -2.87, -6.33, -2.95, 0.27, -2.2, 0.99, -5.36, -0.30134863945578233, -2.12, -2.66, -4.34, -3.66, -4.01, 0.35, -0.81, -1.9, -3.7, -1.85, -3.69, -3.21, -2.46, 0.71, -5.62, -0.87, -2.38, -2.92, -4.6, -3.92, -4.27, 0.08, -1.08, -4.66, -0.7685714285714286, 3.25, -3.24, 1.6816609275411798, 0.08, -0.48, -2.19, -1.5, -1.86, 2.6, 1.42, -5.41, -8.31, 7.91, -3.9, -6.29, -1.58, -3.065714285714286, -3.61, -5.28, -4.6, -4.864285714285715, -0.63, -1.78, 3.88, 2.55, 5.03, 3.43, 2.8505714285714285, 1.7028571428571428, 1.8, 1.43, 6.04, 4.81, -1.04, 2.54, -5.36, -1.9, -1.88, -1.58, -2.36, -1.52, -2.07, -3.76, -3.07, -3.43, 0.96, -0.2, 0.81, -0.85, -0.55, -2.27, -1.57, -1.93, 2.52, 1.34, -4.32, -4.640438775510204, 0.61, -0.95, 7.72, -0.93, -0.8, 3.19, -3.19, -1.62, -1.55, -5.65, -2.98, 3.86, 1.92, 5.26, -1.16, -5.74, 5.87, 5.84, -1.92, 4.81, -3.78, 0.28, 0.02, -7.19, -4.93, -0.27, -0.06, 2.53, -0.3, -1.73, -1.02, -1.39, 3.09, 1.9, -5.69, 1.45, 0.71, 0.34, 4.900857142857143, 4.338571428571429, 0.74, -0.37, 4.16, 2.96, -3.73, -5.11, 1.11, 4.54, 3.34, -1.94, -1.89, -2.86, 6.04, -3.04, -7.28, -0.62, -1.07, -3.29, -1.15, -2.29, -1.46, -1.73, -0.03, -2.11, -2.16, -0.84, 0.48, -2.07], ['338', 3.83, -0.3, 0.12, -0.03, 0.45, 0.92, 0.6641152579598292, 1.25, 1.06, -1.02, -2.77, -1.47, -2.73, -2.38, -1.7, -2.35, -2.83, -1.47, 0.66, -1.04, -0.57, -0.8, -2.08, -2.18, 1.25, 1.45, 1.8, 1.34, 0.05, 0.4, 1.1, 0.44, -0.06, 1.34, 3.53, 1.78, 2.27, 2.03, 0.71, 0.61, 1.68, 1.8149361992161734, 0.46, -1.28, -0.93, -0.24, -0.89, -1.38, 0.0, 2.16, 0.43, 0.91, 0.7738655564790019, -0.62, -0.72, 0.83, 0.86, -0.74, 1.09, 1.76, 0.35, 1.05, 0.39, -0.1, 1.29, 3.507180272108844, 1.7302380952380951, 2.22, 1.98, 0.67, 0.56, 0.93, 1.4, 0.7, 0.04, -0.46, 0.94, 3.12, 1.37, 1.86, 1.62, 0.31, 0.21, 1.35, 3.351742947528662, -3.19, 0.7366982383853201, -0.66, -1.14, 0.24, 2.41, 0.67, 1.16, 0.92, -0.38, -0.49, 1.29, 1.36, -0.49, 0.9, 3.08, 1.34, 1.82, 1.59, 0.28, 0.17, 0.48, 1.35, -0.07, 0.5615981806829015, 0.98517906963434, 1.08, 1.86, 1.4, 3.59, 2.0397126881055456, 2.5057782534925392, 2.09, 0.77, 0.67, -0.24346392892821456, 0.46, 2.16, 0.43, 0.91, 0.68, -0.62, -0.72, 0.84, 1.09, 0.24, 1.2, 3.81, 0.12, -0.06, -2.53, 2.54, 1.3088101710076212, -2.44, 1.9961635321120494, -0.06, -1.96, -1.0, 1.92, 0.57, 2.91, -2.91, -2.91, 0.97, -3.87, 1.9698783572413152, 1.13, -0.56, 5.47, -10.92, -3.75, -5.55, 0.1, -1.67, -1.7, -1.22, -1.45, -2.72, -2.83, 2.88, 0.02, 0.48, 0.25, -1.04, -1.15, -0.45, -0.23, -1.52, -1.62, 1.1, 1.4, -0.22, -1.29, -1.39, 0.51, 0.61, 1.15, -6.42, 1.1, 6.27, 0.89, 0.29, 1.08, -0.11, 1.29, 1.04, 0.46, 0.26, 1.39, 1.19, 0.14, 0.2, 1.69], ['339', 3.3, 0.32, 0.47, -0.07, 0.5, 1.38, 1.91, 3.83, 2.21, 4.06, 0.52, 3.04, 1.01, 0.13, -0.56, 3.21, 2.26, 1.94, 7.21, 3.53, 4.88, 1.55, 0.93, 2.14, 3.0, 3.05, 3.5626583949931123, 2.51, 0.49, -0.23681006295292, -1.07, 2.68, 1.74, 1.42, 6.66, 3.0, 4.34, 1.03, 0.42, 1.62, 4.01, 2.76, 0.99, -1.97, -2.82, -3.49, 0.17, -0.75, -1.06, 4.05, 0.48, 1.79, -1.45, -2.04, -0.87, 2.53, 2.87, 1.5, 2.08, 3.02, -0.87, -1.55, 2.18, 1.24, 0.93, 6.15, 2.5, 3.83, 0.54, -0.07, 1.12, 3.99, 3.93, -0.68, 3.08, 2.13, 1.81, 7.08, 3.4, 4.74, 1.42, 0.8, 2.01, 3.88, 8.45, -8.35, 4.64, 3.79, 2.83, 2.51, 7.81, 4.11, 5.46, 2.12, 1.5, 2.71, 1.28, 0.83, -0.92, -1.23, 3.88, 0.31, 1.62, -1.61, -2.21, -1.04, 2.04, 0.81, 2.5257237118830402, 1.58, 1.73, 1.45, 1.76, -0.31, 4.84, 1.24, 2.56, -0.7, -1.3, -0.12, 2.25, 2.08, 5.17, 1.55, 2.88, -0.39, -0.99, 0.19, 3.89, 3.06, -0.1, 1.98, 2.5, 1.11, 0.73, -2.54, 2.5, 1.28, 0.4, 4.04, -0.99, -3.15, -1.59, 1.69, 0.66, 4.980596861471861, -4.84, -4.71, 1.59, -3.91, 3.17, 3.76, -1.88, 5.25, -14.99, -3.5, -5.19, 1.02, -2.94, -3.44, -2.18, -5.29, -5.86, -4.73, 4.82, 0.52, 1.3, -1.91, -2.51, -1.34, -0.78, -3.17, -3.76, -2.61, 2.41, 2.88, 2.48, -0.61, 0.58, 1.61, 1.65, 3.66, -7.49, 2.41, 7.41, 1.76, 1.54, 3.1, 1.19, 1.97, 1.29, 1.12, 0.14, 0.76, 1.88, 3.15, 2.9, 1.24], ['340', 1.88, -0.14, -0.03, 0.23, 0.06, 0.05, -1.23, 0.01, -0.32, 0.42, 0.5903184712113286, 1.49, 1.24, 0.11, 0.75, 0.82, 0.33, 0.25, 4.16, -0.41, 0.68, 0.69, 0.62, 1.16, -0.85, 0.5, 0.04, 1.1001785714285715, 1.2676746031746031, -0.27, 0.37, 0.44, -0.05, -0.13, 3.76, -0.79, 0.29, 0.31, 0.24, 0.77, -0.13, 0.15, -1.05, -0.25, -1.36, -0.72, -0.65, -1.14, -1.22, 2.63, -1.87, -0.8, -0.78, -0.85, -0.32, -0.78, -0.46, 0.61, 0.23, -0.7307547529341225, -1.11, -0.48, -0.41, -0.9, -0.97, 2.89, -1.62, -0.55, -0.54, -0.61, -0.08, 1.13, 0.31, 0.64, 0.72, 0.22, 0.5793027210884354, 4.05, -0.52, 0.57, 0.5814285714285714, 0.52, 1.05, -0.2, -0.52, 0.46, -0.32912907733800595, 0.07, -0.4082142857142857, -0.5, 3.38, -1.15, -0.07, -0.06, -0.13, 0.4, 0.992095238095238, -0.4, -0.49, -0.57, 3.31, -1.22, -0.15, -0.13, -0.2, 0.33, 0.36, -0.37, -1.74427628811696, -0.08, 0.02, -0.21, 0.09, -0.08, 3.82, -0.74, 0.35, 0.36, 0.29, 0.83, -0.19, 0.17, 3.9, -0.66, 0.42, 0.44, 0.37, 1.1421774376417235, 0.14, 0.14, 0.55, -0.09, 2.77, 0.2, 0.01, -0.53, 0.53, 0.26, 1.39, -1.55, -1.79, 0.21, 0.1, 1.03, -0.27, -0.28, 0.3, 0.26, -0.08, -0.79, -0.18, -2.52, 1.23, 0.2, -0.08, -0.17, -0.23, 1.74, -3.59, -4.39, -3.34, -3.33, -3.39, -2.88, -0.26, 0.83, 1.09, 1.11, 1.04, 1.57, -0.25, 0.022884928563499992, -0.05, 0.48, -0.36, -0.04, -0.27, -0.07, 0.46, 0.022080034314056876, -0.07, -0.07, -0.05, -1.42, 0.04, -0.16, -0.14, -0.2, 0.53, -0.11, 0.88, -0.33, -0.37, -0.61, -0.73, 0.63, -0.32, -0.64], ['341', 1.03, 0.12, 0.07122171562045874, 0.08, 0.07, -0.13, -1.18, -0.23, -0.12, -0.92, -1.31, 0.05, -0.95, -0.38, -0.9, -1.05, -1.27, -0.89, -0.28, -1.42, -0.45, -1.15, -0.98, -1.24, 0.42, 0.18, 0.4, 1.38, 0.37, 0.94, 0.41, 0.27, 0.04, 0.42, 1.05, -0.11, 0.8707606837606837, 0.17, 0.33, 0.07, -0.06, 0.95, -0.97, -1.0, -0.43, -0.95, -1.1, -1.32, -0.95, -0.33, -1.47, -0.5, -1.2, -1.04, -0.9891712018140588, -0.07, 0.08, -0.87, -0.09, 0.03, 0.57, 0.05, -0.1, -0.32, 0.06, 0.68, -0.47, 0.5, -0.2, -0.03, -0.3, 0.3, -0.54, -0.52, -0.67, -0.89, -0.51, 0.1, -1.04, -0.07, -0.77, -0.61, -0.87, 0.38, 0.23, -0.16, -0.02, -0.14, -0.37, 0.01, 0.63, -0.52, 0.46, -0.25, -0.08, -0.34, 0.11, 0.13, -0.23, 0.16, 0.77, -0.37, 0.6, -0.1, 0.06, -0.2, 0.161141873999017, 0.17, 0.11, -0.04, -0.01, 0.03, 0.36, 0.38, 1.0, -0.15, 0.83, 0.13, 0.29, 0.03, 0.19, -0.03, 0.62, -0.53, 0.44, -0.26, -0.09, -0.36, 0.31, 0.58, 0.18, 0.35, 0.4, -0.03, 0.07, 0.0, 0.07, 0.01, 0.34, -0.25, -0.92, 0.01, 0.03, 0.57, 0.07, -0.11, 0.05, 0.1, -0.05, -0.13, -0.09, -1.14, 0.59, 0.88, 1.55, -0.72, -0.97, 0.91, -0.64, -1.14, -0.17, -0.87, -0.71, -0.97, -0.13, 0.51, 0.98, 0.27, 0.44, 0.17, -0.47, -0.7, -0.53, -0.8, -0.15, 0.02, 0.23, 0.17, -0.1, -0.03, 0.06, -0.26, 1.03, 0.09, -0.99, -0.2627361894755667, -0.12, 0.07, -0.26, -0.22, -0.13, 0.22, -0.22, -0.06, 0.33, -0.17, 0.24, 0.53], ['342', -3.32, -2.45, -0.26, -0.61, 0.14, 1.14, 1.22, 0.16, 2.25, 0.74, -1.99, -0.57, -0.94, 0.11, 1.64, 0.61, 0.83, 0.51, 1.015862135879993, 0.26, 1.54, 1.44, 1.0, -0.2, 0.09, -0.66, 2.78, 1.45, 1.07, 2.14, 3.71, 2.65, 2.88, 2.55, 2.88, 2.29, 3.6, 3.5, 3.05, 1.83, -2.58, 6.59, 1.31, -0.37, 0.69, 2.23, 1.19, 1.41, 1.09, 1.42, 0.8984761904761904, 2.13, 2.02, 1.58, 0.38, -0.21, -0.28, -2.69, 1.68, 1.69, 1.06, 2.6, 1.56, 1.79, 1.46, 1.79, 1.21, 2.5, 2.4159625850340136, 2.115338978481836, 0.75, 0.09, 0.62, 1.53, 0.5, 0.72, 0.4, 0.73, 0.15, 1.43, 1.33, 0.89, -0.31, 4.27, -1.97, 0.91, -0.89, -1.02, -0.8, -1.11, -0.79, -1.36, -0.1, -0.2, -0.63, -1.81, 0.05, 0.12, 0.22, -0.1, 0.22, -0.35, 0.93, 0.82, 0.38, -0.8, 0.24, 0.12, -0.19, 0.92, 0.67, 0.81, -0.1, -0.32, 0.0, -0.57, 0.7, 0.6, 0.16, -1.02, -0.42, 0.22, 0.32, -0.25, 1.02, 0.92, 0.48, -0.71, -0.82, -0.43, -1.34, -0.38, 0.06, -1.38, -0.9, -0.88, 0.93, 0.46, 0.07, -0.25, -0.83, -1.2114285714285715, -0.865452380952381, -1.75, 1.39, 1.97, -2.2600000000000002, -2.1057142857142854, 0.94, -1.29, 1.86, 4.36, -2.17, -0.39, 3.39, 0.02, 0.06, 0.82, -0.1, -0.57, 0.7, 0.6, 0.16, -1.02, 2.78, 0.47, 1.28, 1.18, 0.7408571428571429, -0.46, -0.79, -0.1, -0.54, -1.71, 2.57, 3.37, -0.69, -0.43, -1.61, 0.93, 0.69, -0.03, 1.77, 0.74, -3.05, 1.34, 0.72, -0.26, -1.18, 1.18, 0.45, 2.0, 1.14, 1.87, 0.93, -0.94, -1.3, 1.11], ['343', 0.23, 0.4, 0.09122171562045875, -0.04, 0.18, 0.2784196236737595, 0.51, -0.31, -0.46, -0.91, -0.72, -0.53, -0.91, -1.02, -0.03, -0.66, -0.86, -0.84, -1.37, -0.62, -1.36, -0.64, -0.81, -1.47, -0.26, -0.17, -0.19, 0.19, -0.19, -0.3, 0.7, 0.06, -0.14, -0.12, -0.65, 0.1, -0.64, 0.09, -0.08, -0.75, -0.33, -1.3150638007838267, -0.38, -0.38, -0.49, 0.51, -0.13, -0.33, -0.31, -0.84, -0.09, -0.83, -0.11, -0.27, -0.94, -1.25, 0.27, -0.31, -0.2, 0.0, -0.11, 0.89, 0.25, 0.05, 0.07, -0.46, 0.29, -0.45, 0.28, 0.11, -0.57, 0.83, 0.11, 1.0, 0.36, 0.16, 0.18, -0.36, 0.4, -0.34, 0.38, 0.22, -0.46, -0.53, -0.36, 0.31, -0.88, -0.5419125667872351, -0.83, -0.81, -1.34, -0.59, -1.33, -0.61, -0.77, -1.44, 1.05, -0.25, -0.2, -0.18, -0.71, 0.04, -0.7, 0.02, -0.14, -0.82, -0.06, -0.35, 0.79, 0.18, 0.04, 0.28, -0.05, 0.02, -0.51, 0.24, -0.5, 0.22, 0.06, -0.62, -0.043463928928214546, -0.07, -0.53, 0.22, -0.52, 0.2, 0.04, -0.64, 0.04, -0.12, 0.11, 0.06, 3.03, 0.02, -0.13, -0.91, 0.94, 0.48, -0.28, 0.4061635321120495, 0.47, -0.37, -0.2, 0.04, -0.47, 0.63, -0.55, -0.5, 0.17, -1.44, 0.34, -1.07, 0.52, -0.09, 1.92, 0.05, 0.09, -0.5461904761904762, 0.47, 0.76, 0.02, 0.74, 0.57, -0.1, 0.51, -0.29, -0.74, -0.02, -0.18, -0.86, 0.45, 0.73, 0.56, -0.12, -0.44, -0.44, -0.28, -0.17, -0.84, 0.19, 0.13, -0.25, 0.94, 0.8, -0.93, 0.25, 0.3, -0.11, -0.67, 0.46, 0.35, -0.46, -1.15, 0.42, 0.57, 0.28, 0.38, 0.3], ['344', 3.92, 0.49, 0.17122171562045874, -0.09, 1.07, 0.66, 1.2541152579598291, 1.75, 1.4293780543870107, 1.89, 0.74, 0.53, 0.35, 1.45, -0.6, 0.44, 0.68, 1.28, -1.19, -0.23, 2.26, 0.92, 0.62, 0.57, 2.03, 1.48, 1.14, -0.21, -0.38857142857142857, 0.7, -1.33, -0.3, -0.06, 0.54, -1.91, -0.96, 1.52, 0.18, -0.11, -0.16, 2.1574684253532106, 1.67, 1.35, -0.18, 0.91, -1.13, -0.09, 0.15, 0.75, -1.71, -0.76, 1.72, 0.39, 0.09, 0.04, 1.6, 1.88, 1.4, 1.09, 1.54, 1.09, -0.95, 0.09, 0.33, 0.93, -1.53, -0.58, 1.91, 0.5859625850340136, 0.2727347454133169, 0.22, 2.36, 0.44, -2.02, -0.99, -0.75, -0.16, -2.6, -1.65, 0.81, -0.51, -0.81, -0.86, 1.28, 3.51, -3.5, 2.51, 1.05, 1.29, 1.9, -0.59, 0.37, 2.89, 1.54, 1.24, 1.18, 2.27, 1.44, 0.24, 0.84, -1.62, -0.67, 1.82, 0.48, 0.18, 0.13, 0.88, 1.46, 2.200104651162791, 1.01, 1.0, 1.1, 1.2, 0.6, -1.86, -0.91, 1.7457782534925395, 0.24, -0.06, -0.11, 0.84, 0.6, -2.44, -1.5, 0.97, -0.35, -0.65, -0.7, 1.33, 1.12, 0.01, 1.16, 6.71, 0.15, 0.17, -2.76, 2.68, 1.33, 0.11, 2.64, -4.06, -2.11, -1.0, 2.04, 0.28, 3.03, -3.04, -3.03, 1.0, -4.03, 2.0, 1.56, -0.82, 3.54, -13.39, -2.37, -3.57, 4.13, 3.12, 0.97, 3.5, 2.14, 1.84, 1.78, 2.99, 2.13, 2.5, 1.16, 0.86, 0.81, -0.37, -1.31, -1.6, -1.65, 1.39, 1.38, 0.96, -0.3, -0.35, 1.04, 1.1143963012752909, 1.77, -7.83, 2.100199626957499, 8.01, 1.197263810524433, 1.4611825396825397, 1.26, -0.05, 0.77, 1.27, 0.43, -0.11, 0.77, 1.31, 1.64, 2.38, 1.12], ['345', 2.54, -0.47, -0.05, 0.2, 0.26, -0.37, -0.8758847420401709, -0.94, -0.52, 0.49, 1.21, 0.8, 1.79, 2.08, 2.41, -0.15, 1.39, 0.42, 0.06, 0.11, 0.49, 1.06, 0.49, 1.32, 0.04, -0.5, -0.71, -0.4, 0.58, 0.86, 1.19, -1.34, 0.18, -0.78, -1.13, -1.09, -0.71, -0.15, -0.71, 0.11, -1.14, -1.72, -0.31, 0.98, 1.27, 1.6, -0.94, 0.58, -0.37, -0.73, -0.69, -0.31, 0.26, -0.31, 0.52, -0.03, -0.68, 0.08, -0.57, -1.28, 0.28, 0.61, -1.91, -0.4, -1.34, -1.7, -1.66, -1.28, -0.72, -1.28, -0.46, -0.98, -1.55, 0.33, -2.18, -0.68, -1.62, -1.97, -1.93, -1.55, -1.0, -1.55, -0.74, -0.73, -0.25, 0.22, -1.88, -2.5, -1.0, -1.94, -2.3, -2.25, -1.88, -1.32, -1.88, -1.07, 0.96, 0.64, 1.54, 0.58, 0.21, 0.26, 0.64, 1.21, 0.7811089783232642, 1.47, -0.04, 0.66, -1.05, -0.48, -0.37, -0.67, -0.88, -0.95, -1.31, -1.26, -0.88, -0.32, -0.88, -0.06, -0.2534639289282145, 0.07, -0.36, -0.32, 0.07, 0.63, 0.07, 0.89, -0.35, -0.62, -0.09, -0.84, 2.85, -0.07, -0.14, 1.44, -1.41, -0.71, 0.54, -0.98, -0.81, 0.94, 0.46, 1.3, -0.11, -1.4, 1.48, 1.44, -0.47, 2.11, -0.96, -2.11, 1.03, -2.62, -0.69, 1.78, 2.63, 0.7, 0.43, 0.04, 0.43, 1.0, 0.7496385796742939, 1.26, -1.46, 0.38, 0.38, 0.95, 0.38, 1.21, 0.0, 0.56, 0.0, 0.83, -0.61, -0.55, -0.56, -0.56, 0.26, -0.49, -0.57, -0.86, -0.62, -1.25, 0.32, -0.97, -0.93, 0.0, 0.83, -0.55, -0.52, -0.38, 1.1402244897959184, -0.76, -0.82, -1.3, -1.08, -1.5], ['346', 0.49, -0.69, 0.04, 0.06, -0.95, 0.94, -0.18588474204017086, -0.08, 1.04, 0.8321428571428571, -0.95, 0.27, 0.92, 1.0670238095238096, 1.49, 1.11, 0.15, 0.51, -0.53, 0.83, 1.25, -1.1, -0.48, 0.95, 0.82, 0.11, 1.8, 1.23, 1.89, 2.03, 2.46, 2.08, 1.12, 1.47, 0.43, 1.8, 2.22, -0.15, 0.48, 1.92, 0.26, 0.95, 0.57, 0.65, 0.79, 1.21, 0.84, -0.07072108843537415, 0.24, -0.79, 0.57, 0.98, -1.37, -0.75, 0.68, -0.07, 0.31, -0.08, 1.25, -0.08, 0.14, 0.56, 0.19, -0.76, -0.41, -1.44, -0.08, 0.32, -2.01, -1.39, 0.03, 0.2736060011417156, -0.22, 0.42, 0.05, -0.9, -0.38017346938775515, -1.57, -0.22, 0.18, -2.14, -1.53, -0.11, 1.45, 3.28, -3.3, -0.64, -0.37, -1.31, -0.9642857142857143, -1.99, -0.64, -0.24, -2.55, -1.94, -0.53, -1.56, -0.27, -0.95, -0.6, -1.62, -0.27, 0.13, -2.19, -1.4388910216767359, -0.16, 0.13, -0.26, 1.12, 0.33, 0.71, -0.08, 0.68, 0.35, -0.68, 0.68, 1.09, -1.26, -0.64, 0.79, 1.71, 0.3830767481303673, -1.03, 0.33, 0.74, -1.6, -0.98, 0.44, 1.5, 1.55, 0.09, 0.67, -4.63, 0.23, 0.07, 1.56, -1.57, -0.79, 0.44, -1.43, 0.06, -0.68, -0.36, 0.16, 0.62, 0.99, -0.89, -1.12, 0.32, 2.46, 0.61, -0.64, 0.32, 2.04, -3.28, -1.407142857142857, -2.08, 0.2656150793650793, 1.37, 1.37, 1.78, -0.58, 0.05, 1.48, 0.91, 0.0, 0.41, -1.92, -1.31, 0.11, -0.41, -2.32, -1.71, -0.29, 1.05, 1.25, 1.96, 0.63, 2.07, 0.26, 0.28, -0.07, -3.01, 0.92, 2.99, 0.8, 0.0, 1.32, 1.44, 0.81, -0.54, 0.7, 1.22, 0.26462624382472905, -0.11, 0.64, -0.96, 0.42], ['347', 1.71, 0.83, 0.02, -0.42, 1.38, 1.04, 2.6341152579598295, 1.14, 1.13, 0.18, -1.9, -1.44, -2.34, -0.54, -1.16, 0.33071428571428574, -1.64, 0.47748242630385496, 0.53, -1.69, 0.27, -0.23, -0.83, -1.1, 1.08, 0.76, 2.1626583949931124, 0.48, -0.45, 1.39, 0.8178199712950912, 2.28, 0.27, 2.11, 2.48, 0.22, 2.22, 1.71, 1.1, 0.82, 1.08, 0.9349361992161734, 1.65, -0.92, 0.91, 0.28, 1.8, -0.21, 1.62, 1.99, -0.26, 1.749654729237061, 1.23, 0.62, 0.34, -0.14, -0.62, 0.78, 1.18, 2.59, 1.84, 1.21, 2.74, 0.72, 2.56, 2.94, 0.66, 2.68, 2.17, 1.55, 1.27, 1.01, 0.73, -0.62, 0.8807142857142857, -1.1, 0.71, 1.08, -1.16, 0.82, 0.32, -0.28, -0.56, 1.6, 2.68, -2.7, 1.3966982383853201, 1.51, -0.48, 1.34, 1.71, -0.54, 1.45, 0.95, 0.34, 0.06, 0.06, -0.15, -1.97, -0.17, 0.19, -2.02, -0.06, -0.3171830035044322, -1.16, -1.43, 0.14, -0.07, 0.9, 1.1815981806829015, 1.03, 1.2456735186500318, 1.85, 1.83, 2.2, -0.05, 1.95, 1.44, 0.83, 0.54, 0.14, 0.02, 0.37, -1.85, 0.11, -0.39, -0.98, -1.26, 0.84, 1.17, -0.78, 1.42, 0.08, 0.12, 0.07, -2.49, 2.51, 1.3188101710076212, -2.37, 1.94, -4.1, -2.18, -1.16, 0.87, 0.53, 3.35, -3.25, -3.35, 1.1832908048638529, -3.77, 2.24, 4.57, -2.32, 5.56, -4.21, -3.69, -5.51, 4.09, -0.34, -2.21, -0.25, -0.75, -1.35, -1.62, 3.4131678995607566, 1.91, 2.0, 1.49, 0.88, 0.6, -0.09, -0.5, -1.1, -1.38, 1.15, 1.23, 0.41, -0.6, -0.8077512446849837, 1.182080034314057, 1.11, 1.05, -2.25, 1.28, 2.3, 1.89, 1.91, 1.02, -0.28, 1.94, 1.07, 0.58, 0.22, 0.58, 1.3, 2.83, 2.66, 1.65], ['348', 1.63, 0.49, 0.3412217156204588, -0.04, 0.61, 1.51, 1.34, 1.24, 1.76, 3.22, 0.74, 2.5819344980416408, 1.633913265120849, 2.66, 1.93, 3.31, 1.01, 2.62, 5.97, 1.92, 3.357335482087359, 2.06, 1.62, 2.01, 1.42, 2.33, 2.4926583949931125, 1.63, 0.82, 1.9, 1.18, 2.55, 0.27, 1.86, 5.635702380952381, 1.17, 2.56, 1.31, 0.87, 1.25, 1.01, 3.76, 0.82, -0.8, 0.27, -0.44, 0.9, -1.24071768707483, 0.23, 3.5971355564861205, -0.45, 0.91, -0.32, -0.10857142857142854, -0.37, 0.69, 1.33, 0.15, 2.04, 1.63, 1.08, 0.36, 1.71, -0.55, 1.04, 4.34, 0.35, 1.72, 0.49, 0.06, 0.43, 0.96, 0.55, -0.71, 0.63, -1.61, -0.04, 3.22, -0.72, 0.64, -0.59, -1.01, -0.64, 2.22, 4.62, -4.62, 1.27, 1.35, -0.9, 0.68, 3.96, -0.01, 1.36, 0.13, -0.3, 0.07, 1.74, -0.08, -2.22, -0.66, 2.58, -1.34, 0.01, -1.21, -1.63, -1.26, 0.65, -0.06, 1.81, 1.6, 1.39, 1.8, 2.19, 1.59, 4.91, 0.9, 2.28, 1.04, 0.61, 0.99, 1.13, 0.59, 3.26, -0.68, 0.68, -0.55, -0.97, -0.6, 2.31, 2.74, 0.07, 2.02, 5.47, 0.1, -0.07, -4.12, 4.122462323390895, 2.07, 0.66, 0.7, -2.43, -3.22, -1.64, 0.78, 0.88, 4.85, -4.67, -4.7, 1.643290804863853, -6.21, 3.22, 0.48, -0.24, 6.46, -7.74, -4.39, -6.51, 2.42, -2.59, -3.82, -2.5, -3.69, -4.1, -3.74, 4.83, 1.28, 1.37, 0.13, -0.29, 0.08, -0.09, -1.22, -1.64, -1.27, 1.81, 2.15, 1.14, -0.43, -0.05, 1.6, 1.68, 1.13, -5.79, 1.6711163791806698, 5.78, 1.85, 1.84, 1.57, 0.38, 1.7, 2.1, 1.15, 0.46, 1.2, 1.19, 3.1202406343656346, 2.25, 2.23], ['349', -0.03, -0.12, -0.3098471016907295, 0.07, 0.84, -0.08, -0.04588474204017083, -0.71, -0.24, -0.55, 0.0, -1.35, 0.013913265120848936, -0.71, 0.27, -0.98, -0.47, -0.48, -1.5, -2.23, -0.41, -1.32, -0.91, -0.63, -1.03, 0.55, -0.5173416050068875, -1.35, -0.05, -0.71, 0.27, -0.98, -0.47, -0.48, -1.4992857142857143, -2.23, -0.41, -1.32, -0.91, -0.5761582768021608, -0.44, 1.43, 0.81, 1.32, 0.66, 1.65, 0.38, 0.89, 0.89, -0.15, -0.89, 0.95, 0.03, 0.45, 0.74, -0.07, -0.58, -1.49, -0.72, -0.42075475293412246, -0.66, 0.33, -0.93, -0.42, -0.43, -1.3413219954648525, -2.18, -0.36, -1.27, -0.86, -0.57, -1.26, 0.16, 0.99, -0.28, 0.24, 0.23, -0.8, -1.53, 0.3, -0.62, -0.07690451810094656, 0.08, -0.45, 1.03, -1.06, -0.82, -1.25, -0.75, -0.75, -1.77, -2.306255228898086, -0.69, -1.59, -1.19, -0.8459922724755494, 2.19, 0.44, 0.51, 0.51, -0.52, -1.26, 0.57, -0.34, 0.07, 0.36, -0.03, 0.48, 0.42572371188304003, -0.04, 0.18517906963433994, -0.22432648134996808, -0.08, 0.0, -1.03, -1.76, 0.06, -0.85, -0.44, -0.15, 0.6, -0.08, -1.03, -1.76, 0.06, -0.85, -0.44, -0.15, 0.47, 1.43, 0.12, -0.15, 4.46, -0.2419304505018789, -0.42, 0.77, -0.76, -0.41, -0.32593372653318475, 0.08025974025974027, -3.53, 0.1, 0.05, 0.03, 0.28, -0.24, 0.23, 0.19, -0.05, 1.21, -0.13, -0.25, 0.09, -0.12, 1.2, 0.15, 0.09, 3.46, 0.96, -0.74, 1.1, 0.18, 0.59, 0.89, -0.22, 1.72, 1.86, 0.93, 1.35, 1.64, -0.14, -0.91, -0.5, -0.21, -0.19, -0.53, 0.78, 0.41, 0.7, -0.04, -0.07, -0.6074239503761216, 0.6, -0.2498003730425007, -0.75, -0.18, 0.01, 0.37, 0.29, -0.77, -0.44, 0.01, 0.57, 0.37, 0.07, 0.4, 0.6, 0.07], ['350', -1.99, -0.44, -0.17877828437954127, 0.17, -0.31, 0.19, -0.74, -0.95, -0.72, -0.83, -0.21, -0.38, -0.06, 0.48, -0.19, -0.67, -0.55, 0.13, 2.59, -0.19, -1.0, -0.19, -0.3956947683993239, -0.49, -1.26, -1.21, -0.62, -0.17, 0.15, 0.69, 0.02, -0.46, -0.34, 0.35, 2.81, 0.02, -0.79, 0.02, -0.28, -0.28, -0.76, -0.47, -0.45, 0.32, 0.86, 0.19, -0.29, -0.17, 0.52, 2.99, 0.19, -0.62, 0.19, -0.11, -0.11, -0.14993715369432348, -1.34, -1.5021720271902161, -1.2, -0.77, 0.54, -0.12920068027210885, -0.61, -0.49, 0.19, 2.65, -0.12976190476190477, -0.95, -0.14, -0.43, -0.43, -1.25, -1.3, -0.2497721088435375, -1.14, -1.02, -0.34, 2.11, -0.67, -1.47, -0.67, -0.97, -0.96, -0.48, -0.97, 1.0, -0.64, -0.48, -0.36, 0.33, 2.79, 0.0, -0.81, 0.0, -0.3, -0.3, -2.64, -0.16, 0.12, 0.81, 3.3159047619047617, 0.48, -0.34, 0.7228169964955679, 0.18, 0.18, -0.82, -0.14, 1.33, -0.13, -0.14, -0.24, -0.28, 0.69, 3.16, 0.36, -0.46, 0.36, 0.06, 0.06, -0.7, -0.96, 2.46, -0.32, -1.13, -0.33, -0.62, -0.62, -0.43, 0.33, -0.08, -0.38, -5.12, -0.4796768707482993, -0.3, 0.82, -0.88, -0.41, -0.2, -0.66, 1.38, 0.35, 0.14, -0.95, 0.37, -0.58, 0.56, 0.34, -0.13, 1.16, -0.27, -0.98, 0.45, -0.83, 9.49, 0.53, 0.81, -1.39, -3.34, -2.71, -3.51, -2.72, -3.01, -3.0, -0.36, -0.64, -0.81, 0.0, -0.3, -0.3, 0.18, 0.82, 0.52, 0.52, -0.66, -0.79, -0.64, -0.3, -0.29, 0.09208003431405688, -0.18, -1.02, 4.75, 0.17, -4.86, -1.3, -0.06, -0.34, 0.0, 0.06, -0.34, 0.61, 0.58, -0.17, -0.34, -2.2, -0.42, -0.14], ['351', 0.88, 0.0, 0.17122171562045874, -0.04, 0.18, 0.39, 0.9841152579598291, -0.1, 0.28, 0.23, -0.2, 0.17, -0.07, 1.5, -1.22, 0.15, -0.13, 0.23, -1.22, -0.02, 0.21733548208735892, 0.53, 0.29, -0.12, 0.04, 0.51, 0.42, 0.37, 0.13, 1.7, -0.9721800287049088, 0.35, 0.07, 0.42, -1.03, 0.17, 0.37, 0.72, 0.49, 0.08, 0.8, 0.6749361992161734, 0.05, -0.24, 1.32, -1.39, -0.02, -0.3, 0.05, -1.39, -0.2, 0.0, 0.35, 0.12, -0.29, -0.41, 0.19, -0.86, 0.26, 0.3, 1.57, -1.15, 0.22, -0.06, 0.3, -1.15, 0.05, 0.25, 0.6, 0.36, -0.05, -0.15, -1.25, -2.68, -1.33, -1.6, -1.25, -2.68, -1.5, -1.3, -0.96, -1.19, -1.59, 0.33, -0.06, 0.05, 1.460870922661994, 1.39, 1.11, 1.46, 0.23578854875283461, 1.21, 1.41, 1.77, 1.53, 1.12, 1.12, 0.08, -0.27, 0.08, -1.37, -0.17, 0.03, 0.38, 0.14, -0.27, 0.0, 0.05, -0.25, 0.2515981806829015, 0.18, 0.31, 0.35, 0.35, -1.1, 0.1, 0.3, 0.65, 0.42, 0.01, -0.25, 0.053076748130367266, -1.45, -0.25, -0.05, 0.3, 0.06, -0.34, -0.39, -0.48, 0.04, 0.29, 3.19, -0.03, 0.07, -0.51, 0.54, 0.25, 0.29, 1.04, -0.47, -0.4, -0.21, 0.44, -0.11, 0.54, -0.55, -0.58, 0.19, -0.76, 0.44, 0.31, -0.12, 1.05, -3.15, -0.72, -1.12, 0.52, 1.47, 1.21, 1.42, 1.77, 1.53, 1.12, 0.58, 0.25, 0.2, 0.55, 0.31, -0.09, 0.05, 0.35, 0.11, -0.29, 0.24, 0.37, -0.3, -0.23, -0.64, 0.22, 0.26, -0.07, 0.29, 0.06, -0.33, 0.15, 0.51, -0.06, -0.41, 0.35, 0.42, 0.14, -0.82, 0.06, 0.34, 0.84, 0.66, 0.7730167737073972], ['352', 11.16, 0.74, 0.8112217156204587, -0.45, 3.17, 2.9184196236737594, 3.05, 6.77, 5.59, 6.21, -1.89, 2.401934498041641, 0.94, -0.99, -0.49, 4.52, 0.57, 4.5, 5.19, 2.49, 8.27, 1.67, 0.23, 3.23, 7.5, 3.98, 8.26, 4.18, 2.88, 0.92, 1.43, 6.54, 2.51, 6.52, 7.230714285714286, 4.47, 10.36, 3.64, 2.17, 5.22, 4.53, 8.1, 3.92, -1.24, -3.12, -2.63, 2.27, -1.6, 2.25, 2.93, 0.7096666666666667, 5.93, -0.52, -1.93, 1.01, 5.21, 6.43, 4.94, 3.98, 5.22, -1.91, -1.41, 3.55, -0.37, 3.53, 4.22, 1.54, 7.26, 0.73, -0.7, 2.27, 6.79, 7.27, 0.51, 5.57, 1.57, 5.54, 6.25, 3.52, 9.35, 2.69, 1.23, 4.26, 8.048909863945578, 16.38, -16.33, 6.73, 5.03, 1.06, 5.01, 5.71, 3.0, 8.8, 2.17, 0.72, 3.74, 1.93, 1.61, -3.78, -0.02, 0.64, -1.94, 3.6426265373526934, -2.73, -4.1, -1.23, 1.5911418739990169, 1.66, 5.57, 3.44, 3.76, 3.31, 5.61, 3.91, 4.6, 1.92, 7.66, 1.1, -0.33, 2.65, 4.1, 1.64, 0.67, -1.92, 3.61, -2.7, -4.08, -1.21, 5.59, 5.78, 0.17, 4.75, 3.82, 1.97, 1.15, -6.1, 6.05, 3.04, 1.83, 7.19, -7.2, -6.85, -3.46, 5.57, 2.13, 10.55, -10.5, -10.32, 3.43, -9.09, 6.87, 6.64, -3.28, 16.77, -26.49, -11.15, -16.6, 7.02, 0.96, -2.57, 2.92, -3.35, -4.72, -1.87, 10.27, 3.62, 5.63, -0.8, -2.21, 0.72, -1.9, -6.09, -7.42, -4.65, 5.61, 6.11, 4.46, -1.42, 1.53, 3.4, 3.6, 6.78, -13.22, 4.91, 13.33, 5.44, 4.23, 5.96, 2.99, 4.780077402522781, 3.35, 0.87, 2.46, 1.98, 2.965957527023814, 9.05, 6.743037664716236, 4.46], ['353', -3.39, 1.04, -0.008778284379541255, 0.07, 0.06, 0.52, -0.5, 0.31, 0.72, 0.56, 0.09031847121132863, 0.42, -0.49, 0.71, 0.29, 1.06, 0.33, 0.49, 0.36, -0.25, 1.12, 1.04, 0.3543052316006761, -0.49, 1.33, 0.28, 0.68, 0.5401785714285715, -0.37, 0.83, 0.41, 1.19, 0.45, 0.61, 0.48, -0.13, 1.25, 1.16, 0.38, -0.37, 0.6174684253532109, 2.0, 0.14, -0.91, 0.29, -0.13, 0.64, -0.09, 0.07, -0.07, -0.67, 0.7, 0.62, -0.16, -0.91, 0.55, 0.45, 0.15, 0.75, 1.06, 1.21, 0.78, 1.56, 0.82, 0.98, 0.85, 0.24, 1.62, 1.54, 0.75, 0.0, 0.93, -0.15, -0.42, 0.35, -0.38, -0.22, -0.3469047619047619, -0.96, 0.41, 0.33, -0.45, -1.19, 1.05, 1.02, -1.02, 0.27, 0.77, 0.04, 0.2, 0.07, -0.54, 0.83, 0.75, -0.03, -0.78, -0.71, -0.5, -0.73, -0.57, -0.7, -1.3, 0.06, -0.02, -0.79, -1.54, -0.05, -0.49, -0.16, 0.61, 0.47, 0.7, 0.23, 0.16, 0.03, -0.58, 0.8, 0.71, -0.07, -0.7514153161169344, 0.39, 0.12307674813036727, -0.13, -0.74, 0.63, 0.55, -0.23, -0.97, 0.13, 0.32, 0.04, 0.25, -1.87, 0.07, 0.17, -1.76, 1.78, 0.91, 0.89, -0.5, -1.4494817511227285, -1.23, -0.64, -1.67, 0.49, 1.85, -1.79, -1.8, 0.62, -2.68, 1.24, -0.27, 0.13, 0.71, -1.7, -0.5, -0.74, 1.5738095238095238, 0.21, -0.61, 0.77, 0.68, -0.1, -0.84, 1.87, 0.82, 1.38, 1.3, 0.51, -0.24, -0.56, -0.08, -0.86, -1.6, 0.27, 0.36, -0.47, -0.77, -1.52, 0.17, 0.06, 0.12, -0.33, 0.43019962695749936, 0.39, -0.03, 0.64, 0.3, -0.75, 0.58, 0.63, 0.78, 0.08, 0.61, 1.06, -0.39, 0.35, 0.67], ['354', -7.13, -0.22, -0.19877828437954126, -0.17, -0.05, 1.22, -0.41, -0.6982794034640413, 0.32, -1.13, -2.29, -0.92, -1.76, -0.58, 0.59, 1.65, -0.57, -1.21, -3.38, -1.51, -1.402664517912641, -0.67, -2.47, -1.57, 0.6, -0.27, 1.18, 1.4, 0.54, 1.75, 2.94, 4.03, 1.76, 1.1, -1.12, 0.79, 0.87, 1.66, -0.18, 0.73, -1.8345146341753484, 1.33, -0.20979591836734693, -0.7588025325038829, 0.35, 1.52, 2.6, 0.36, -0.29, -2.478347866419295, -0.6, -0.53, 0.25, -1.56, -0.66, -2.0476426685347184, -1.76, -2.77, 0.48, 0.64, 1.2, 2.38, 3.47, 1.8814285714285712, 0.55, -1.65, 0.25, 0.32, 1.1114285714285714, -0.72, 0.19, -1.11, -0.56, 1.17, 2.24, 0.01, -0.4701734693877551, -2.82, -0.94, -0.87, -0.08857142857142856, -1.9, -1.0, 0.98, 2.82, -2.95, -1.71, 1.06, -1.15, -1.79, -3.94, -2.09, -2.02, -1.25, -3.04, -2.15, -0.94, -2.74, -2.18, -2.82, -4.95, -3.11, -3.04, -2.2775714285714286, -4.05, -3.17, -0.19, -2.78, -0.08427628811695997, 0.08, 0.73, 0.24567351865003195, -0.57, -0.65, -2.83, -0.95, -0.88, -0.1, -1.91, -1.01, -0.43, 0.08, -2.2, -0.3, -0.23, 0.55, -1.27, -0.37, 1.44, -0.26, -0.26, -0.18, -1.9, -0.5196768707482994, -0.75, 1.52, -1.57, -0.78, -3.31, -0.59, -0.66, -1.29, -0.67, -2.27, 1.02, 1.4905968614718617, -1.49, -1.9, 0.68, 2.49, 1.31, 2.98, -1.52, -1.64, -0.59, 1.25, 1.76, 0.64, 2.650378684807256, 1.93, 2.01, 2.81, 0.94, 1.87, 1.78, 0.39, 0.07, 0.86, -0.97, -0.06, 0.32, 0.78, -1.04, -0.13, 0.37, 0.9, -0.47, -1.81, -0.91, 0.62, 0.43, -1.03, -0.32, 0.37, 0.17, 0.79, 0.4411825396825397, 1.37, 0.92, 0.85, -0.47, 1.3952979520479523, 0.51, 0.82, 0.45, -0.69, -0.7184047619047619, 1.52], ['355', 0.88, 0.4, 0.16015289830927054, 0.11, 0.53, -0.1, 0.41, 0.02, -0.17, 1.14, 1.42, 0.93, 1.59, 1.48, 0.31, 1.16, 1.01, 1.06, -1.09, 0.85, 0.67, 1.2, 1.37, 1.3, -0.12, 0.03, -0.28, -0.48, 0.17, 0.06, -1.09, -0.26, -0.4, -0.35, -2.47, -0.56, -0.73, -0.21, -0.04, -0.12, 0.15, -0.28, 0.2, 0.65, 0.54, -0.61, 0.22, 0.08, 0.13, -2.0, -0.08, -0.26, 0.27, 0.44, 0.36, -0.65, -0.37, 0.26, -0.17, -0.45, -0.11, -1.26, -0.43, -0.57, -0.52, -2.531321995464853, -0.73, -0.9, -0.38, -0.21, -0.29, -0.73, -0.33, -1.15, -0.32, -0.46, -0.41, -2.53, -0.62, -0.79, -0.27, -0.1, -0.17, -0.2, -0.69, 0.69, 0.8566982383853201, 0.84, 0.7, 0.75, -1.39, 0.53, 0.36, 0.89, 1.06, 0.98, 0.18, 0.05736653121656289, -0.14, -0.09, -2.22, -0.31, -0.48, 0.05, 0.22, 0.14, 0.02, 0.0, 0.13, 0.0, 0.05, -0.06, 0.12, 0.05, -2.08, -0.16, -0.33, 0.19, 0.36, 0.29, -0.04, 0.07, -2.13, -0.22, -0.39, 0.14, 0.31, 0.23, -0.67, -0.71, 0.11, 0.08, 0.3, 0.1, 0.13, 0.76, -0.7475376766091052, -0.3511898289923789, 0.14, 0.93, -0.51, -0.02, 0.03, 0.45, 0.16, 0.0, -0.07, -0.06, 0.03, 1.15, 0.08, -1.31, 0.67, 0.33, -7.56, -0.21, -0.26, 0.6, 2.25, 1.95, 1.78, 2.32, 2.49, 2.41, 0.04, 0.29, -0.17, 0.36, 0.52, 0.45, 0.46, 0.53, 0.69, 0.62, -0.12, -0.08154645354645335, -0.07, 0.17, 0.09, 0.03, 0.03, 0.06257604962387836, -4.66, 0.0, 4.65, 0.23, 0.52, -0.23, -0.07, 0.54, -0.46, 0.03, 0.42, 0.09, -0.16, 0.35, -0.02, 0.26], ['356', 0.23, -0.37, -0.2, 0.05, -0.21, -0.42, -0.54, 0.14, -0.48, -0.22, 0.04, -0.28, 0.21, -0.17, 0.39, -0.02, -0.08, 0.25, 4.4, 0.43, -0.3426645179126411, -0.08, 0.47, 0.35, -0.57, -0.71, -0.22734160500688755, -0.31, 0.17, -0.2, 0.36, -0.05, -0.12, 0.21, 4.37, 0.39, -0.42, -0.12, 0.44, 0.32, -2.0, -0.6850638007838266, 0.05, 0.49, 0.11, 0.67, 0.26, 0.2, 0.53, 4.69, 0.71, -0.11, 0.2, 0.75, 0.63, -0.75, 0.31, 0.13, -0.63, -0.43, -0.38, 0.18, -0.23, -0.29, 0.04, 4.19, 0.22, -0.59, -0.29, 0.26, 0.14, -0.61, -0.06, 0.5607142857142857, 0.15, 0.09, 0.42, 4.58, 0.59, -0.22, 0.08, 0.64, 0.52, -0.45, -1.53, 1.75, -0.61, -0.41, -0.47, -0.14, 4.0, 0.04, -0.77, -0.47, 0.08, -0.04, -1.15, -0.21, -0.06, 0.27, 4.42, 0.45, -0.37, 0.1728169964955679, 0.49, 0.37, -0.22, 0.17, -0.82, -0.41, -0.42482093036566004, -0.34, -0.14, 0.33, 4.49, 0.51, -0.3, 0.0, 0.56, 0.43, -0.28, -0.47, 4.15, 0.18, -0.63, -0.33, 0.23, 0.1, -2.3, -0.93, 0.05, -0.13, -4.29, 0.03, -0.08, -0.36, 0.37, 0.23, -0.4, -0.75, -0.16, 0.61, 0.39, -0.11, -0.15, -1.0885238095238097, 0.89, 0.75, -0.35, -0.95, -0.84, -1.0, 0.47, -0.31, -6.17, 0.35, 0.0, -1.37, -4.43, -3.81, -4.59, -4.3, -3.76, -3.88, -0.92, -0.65, -0.81, -0.51, 0.05, -0.08, 0.16, 0.3, 0.86, 0.74, -0.49, -0.51, -0.14, 0.56, 0.44, -0.43, -0.43, -0.07742395037612165, -1.41, -0.84, 1.11, 0.11, -1.09, -0.69, -0.12, -0.27, 0.21, -0.9, 1.05, -0.67, -0.57, -1.06, -1.56, -1.61], ['357', -2.92, -0.52, 0.22122171562045873, 0.14, -1.51, -2.8, -1.8758847420401707, -3.3, -3.33, -3.84, 1.1, -1.76, -0.23, 0.12, -1.27, -3.49, -0.67, -3.29, -2.29, -1.53, -4.85, -0.78, -0.9256947683993239, -1.09, -3.26, -2.560628585411108, -4.89, -2.83, -1.32, -0.97, -2.35, -4.54, -1.76, -4.35, -3.35, -2.6, -5.89, -1.86, -2.1, -2.17, -2.602531574646789, -6.22, -1.920696767518196, 1.55, 1.91, 0.49, -1.76, 1.11, -1.56, -0.54, 0.24, -3.15, 1.0, 0.75, 0.68, -1.63, -3.38, -1.88, -2.46, -3.62, 0.35, -1.039200680272109, -3.27, -0.44, -3.06, -2.06, -1.3, -4.63, -0.55, -0.79, -0.86, -4.47, -3.96, -1.39, -3.61, -0.79, -3.41, -2.4, -1.64, -4.97, -0.9, -1.14, -1.21, -5.16, -8.09, 8.17, -2.6, -2.24, 0.61, -2.04, -0.7842114512471654, -0.25, -3.62, 0.5, 0.26, 0.18, -0.9, -0.36, 2.92, 0.21, 1.25, 2.04, -1.41, 2.81, 2.56, 2.48, -0.47, -0.38, -3.28427628811696, -2.68, -2.57, -2.6443264813499683, -3.19, -2.64, -1.63, -0.86, -4.21, -0.11, -0.35, -0.43, -2.76, -0.57, 1.04, 1.82, -1.61, 2.6, 2.35, 2.27, -2.8281719617057965, -3.05, 0.21, -2.81, -1.76, -0.5677486640343783, -0.61, 4.68, -4.72, -2.371189828992379, -0.19, -4.19, 4.56, 5.33, 2.66, -1.39, -2.5, -7.96, 7.96, 8.01, -2.63, 7.06, -5.25, -1.4, 0.73, -9.5, 17.62, 6.39, 9.49, -4.59, -1.59, 0.78, -2.62, 1.54, 1.3, 1.3857617128436457, -7.886832100439243, -2.35, -3.38, 0.76, 0.51, 0.44, 1.06, 4.28, 4.03, 3.95, -3.079864861329147, -3.88, -3.09, -0.24, -0.32, -2.71, -2.64, -3.48, 8.84, -3.22, -8.53, -2.95, -3.32, -2.771362551799029, -0.08, -2.5599225974772195, -2.17, -2.38, -2.43, -2.85, -2.78, -2.88, -3.54, -2.06], ['358', 3.93, -0.9, 0.13, -0.02, -0.52, 0.2, 0.8141152579598292, -0.05, -0.39, 0.3970884353741497, 0.36, -0.77, 0.28, -0.05, -0.28, -1.04, 0.53, 0.03, 1.66, 1.83, -0.44, 0.13, 0.89, -0.26, 0.49, -0.45, -0.41, -1.13, -0.08, -0.41, -0.64, -1.4, 0.17, -0.33, 1.3, 1.47, -0.8, -0.23, 0.53, -0.5761582768021608, -0.55, -1.98, 0.730204081632653, 1.06, 0.73, 0.49, -0.27, 1.31, 0.81, 2.45, 2.63, 0.33, 0.91, 1.67, 0.51, 0.04, 0.08, 1.07, -0.25, -0.33, -0.33, -0.56, -1.32, 0.25, -0.25, 1.38, 1.55, -0.72, -0.15, 0.61, -0.54, 1.37, 0.0, -0.23, -0.99, 0.58, 0.08, 1.71, 1.88, -0.39, 0.18, 0.94, -0.22, -1.0, -1.86, 1.77, 0.23, -0.6719125667872351, 0.81, 0.31, 1.95, 2.12, -0.16, 0.41, 1.17, 0.02, 1.66, 1.0773665312165628, 1.59, 1.08, 2.73, 2.91, 0.61, 1.18, 1.95, 0.79, -0.01, 1.02, -0.67, 0.2, 0.02, 0.16, -0.57, -0.5, 1.13, 1.3, -0.9593197278911564, -0.4, 0.36, -0.79, -0.18, -0.08, 1.63, 1.8, -0.47, 0.1, 0.86, -0.29, -1.86, -2.03, 0.17, -0.63, 3.28, -0.21, 0.07, -1.04, 1.05, 0.32, -0.51, -1.18, 3.62, -0.31, -0.16, 1.91, 0.65, 0.31, -0.29, -0.7, -0.32, -1.57, 0.39, -0.91, 0.48, -1.64, -2.93, 1.11, 1.58, -3.69, -1.68, 0.17, -2.07, -1.51, -0.76, -1.9, 0.53, -1.85, -2.23, -1.68, -0.93, -2.06, 0.39, 0.57, 1.33, 0.18, -0.43, -0.73, -0.18, 0.76, -0.39, 0.14, 0.04, 0.05, -1.44, -0.5898003730425007, 1.4165238095238095, -0.75, -1.11, -0.93, -1.14, -0.3, 0.1, -0.06, -0.06, -0.18, 0.22, -1.26, -1.3, -0.06], ['359', -0.46, 0.33, 0.13122171562045873, -0.3, 0.28, 0.85, -0.13588474204017084, 1.22, 0.65, 0.55, -0.61, 1.38, -0.96, -0.43, -0.89, 0.85, -0.76, 0.85, -2.02, -0.78, 0.43, -1.15, -1.19, -0.5, 0.59, 0.85, 1.16, 2.0, -0.36, 0.18, -0.29, 1.47, -0.15, 1.46, -1.42, -0.17, 1.04, -0.55, -0.59, 0.1, 1.17, 0.83, -0.6206967675181959, -2.31, -1.78, -2.24, -0.52, -2.11, -0.52, -3.35, -2.13, -0.94, -2.49, -2.53, -1.85, 0.35, 0.55, 0.86, 1.08, 1.52, 0.54, 0.07, 1.83, 0.21, 1.83, -1.07, 0.18, 1.4, -0.19, -0.23, 0.46, 1.2, 0.98, -0.46, 1.29, -0.33, 1.28, -1.6, -0.35, 0.86, -0.73, -0.76, -0.07, 1.17, 4.95, -4.91, 1.48669823838532, 1.76, 0.14, 1.76, -1.14, 0.11, 1.33, -0.26, -0.3, 0.39, 0.39, -0.3, -1.6, 0.0, -2.85, -1.62, -0.42, -1.99, -2.02, -1.34, -0.029020408163265305, -0.31, 2.4157237118830404, 1.08, 1.3, 0.79, 1.31, 1.62, -1.27, -0.02, 1.2, -0.4, -0.35401213658444736, 0.26, 1.42, -0.3, -2.85, -1.62, -0.42, -1.8542004503433074, -2.02, -1.34, 1.57, 1.39, -0.23, 1.18, 1.22, -0.26, 0.07, -1.34, 1.32, 0.67, 0.43, 0.77, -2.52, -2.11, -1.09, -0.2, 0.56, 3.320596861471862, -3.16, -3.26, 1.08, -1.92, 2.16, 1.45, -0.95, 3.9, -6.0, -2.65, -3.86, 2.57, 2.62, 1.27, 2.5, 0.89, 0.85, 1.55, 3.26, 1.34, 1.22, -0.37, -0.41, 0.28, 0.12, -1.5671150714365, -1.61, -0.93, 0.72, 1.01, 1.72, -0.04, 0.66, 1.09, 1.1, 1.27, -3.2, 2.2311163791806696, 3.26, 1.0572638105244332, 2.13, 1.76, 0.7, 0.68, 0.77, 0.5, 0.67, 0.53, 1.05, 1.71, 2.09, 0.83], ['360', -4.66, -0.29, 0.19122171562045873, 0.23, -1.18, -0.19, -0.45, -0.47, -1.09, -1.02, 0.38, -0.08, -0.87, -1.16, -0.63, -0.85, 0.37, -0.86, -1.92, 1.51, -1.73, -0.88, -0.76, -0.84, -0.88, -0.95, -1.4, -0.46, -1.25, -1.54, -1.01, -1.23, -0.01, -1.24, -2.3, 1.12, -2.1, -1.25, -1.13, -1.22, -0.6, -1.1450638007838265, -0.95, -0.7188025325038829, -1.09, -0.55, -0.77, 0.45, -0.79, -1.85, 1.59, -1.65, -0.7061344435209982, -0.68, -0.76, -0.08, -0.39, -1.23, -1.31, -0.15, -0.29, 0.25, 0.03, 1.26, 0.01, -1.06, 2.4, -0.86, 0.0, 0.12, 0.03, -0.2763939988582844, 0.14, 0.54, 0.32, 1.55, 0.3, -0.77, 2.7, -0.57, 0.29, 0.41, 0.33, -1.47, -1.04, 0.97, -0.4, -0.22, 1.0, -0.24, -1.31, 2.15, -1.11, -0.25, -0.13, -0.21, -2.03, -0.17, 1.23, -0.02, -1.08, 2.38, -0.88, -0.03, 0.09, 0.01, -0.26, -0.15, -1.3, -0.32, -0.39, -0.37, -1.3890429599640124, -1.23, -2.29, 1.13, -2.09, -1.24, -1.12, -1.21, 0.12653607107178547, -0.10692325186963274, -1.07, 2.482244713705627, -0.87, -0.01, 0.11, 0.03, -0.76, -1.12, 0.12, -0.75, -6.13, 0.13, 0.06, 0.21, -0.25, -0.12, 0.45, 0.3, 5.01, 0.63, 0.38, -2.38, -0.09, -1.12, 1.05, 1.01, -0.33, 0.49, -0.65, -1.79, 0.88, -4.13, -0.18, 2.76, 4.13, -4.87, 0.92, 3.5, 0.2, 1.07, 1.19, 1.11, -0.98, -2.49, -3.19, -2.35, -2.23, -2.31, 0.72, 0.87, 0.99, 0.9, -1.08, -1.24, -0.15, 0.12, 0.11224875531501632, -0.33, -0.45, -0.42, 0.47, -1.21, -0.66, -0.43, -1.32, -0.27, -0.08, -0.67, -0.08, 0.01, -0.03, -0.3, -0.18, -1.72, -1.81, -0.02], ['361', 4.91, 0.01, -0.12, 0.47, -0.23, -1.47, -0.6, -2.42, -2.12, -2.05, 1.65, -1.68, 0.42, 0.5170238095238096, -0.16, -3.559285714285714, 0.25, -1.1294285714285712, -0.83, -0.01, -2.28, 0.35, -0.15, 0.68, -2.85, -1.68, -3.65, -3.28, -1.22, -1.12, -1.78, -5.13, -1.38, -2.74, -2.45, -1.64, -3.87, -1.29, -1.78, -0.96, -1.11, -3.42, -0.38, 2.13, 2.23, 1.55, -1.91, 1.96, 0.56, 0.86, 1.7, -0.61, 2.06, 1.55, 2.4, -0.89, -1.41, -1.8980521152823784, -2.16, -2.46, 0.1, -0.57, -3.96, -0.17, -1.54, -1.24, -0.42, -2.69, -0.07, -0.57, 0.26, -2.64, -2.55, -0.67, -4.05, -0.11051058745176379, -1.63, -1.34, -0.52, -2.78, -0.17, -0.67, 0.17, -3.46, -5.95, 5.861428571428572, -1.9, -3.41, 0.41, -0.97, -0.68, 0.15, -2.13, 0.51, 0.0, 0.84, 2.75, 1.57, 3.95, 2.52, 2.83, 3.68, 1.33, 4.05, 3.53, 4.4, -1.07, 1.61, -2.83, -1.82, -1.96, -1.84, -2.29, -1.37, -1.08, -0.26, -2.53, 0.1, -0.4, 0.43, -2.2, -0.93, 0.3, 1.13, -1.17, 1.49, 0.99, 2.0721774376417237, -2.37, -1.17, 0.86, -2.27, 5.47, -0.13, 0.0, 3.88, -3.94, -1.94, -0.71, -2.75, 4.07, 3.72, 1.82, 2.38, -1.11, -5.66, 5.66, 5.57, -1.83, 5.83, -3.66, -5.46, 2.73, -6.88, 9.96, 4.59, 6.92, -3.9228690476190478, -1.23, 0.83, -1.46, 1.19, 0.69, 1.53, -5.5, -2.04, -2.27, 0.36, -0.15, 0.69, 0.24, 2.69, 2.18, 3.03, -2.18, -2.63, -2.39, -0.5, 0.33, -1.86, -1.91, -2.32, 4.82, -3.23, -4.58, -2.03, -1.99, -1.9, 0.84, -2.55, -1.55, -0.83, -1.02, -1.91, -2.71, -1.81, -2.68, -3.39], ['362', 0.92, 0.37, 0.26122171562045876, 0.36, -0.65, 0.02, -0.13588474204017084, -0.7, -0.99, 0.05, 1.6, 0.35, -1.11, -1.74, 1.05, -0.01, 0.32, 0.23, -3.45, 0.46, -0.04, 0.63, 0.44, 1.06, -1.15, 0.21, -1.53, -1.23, -2.67, -3.29, -0.54, -1.58, -1.26, -1.35, -4.97, -1.12, -1.61, -0.95, -1.14, -0.53, 0.54, -2.76, -0.3, -1.46, -2.08, 0.7, -0.3590816326530612, 0.009278911564625847, -0.12, -3.79, 0.11476190476190476, -0.39, 0.28, 0.7214285714285714, 0.71, -0.14, 0.47, -1.52, -1.199047619047619, 1.17, -0.64, 2.19, 1.12, 1.45, 1.36, -2.37, 1.59, 1.09, 1.76, 1.57, 2.2, -0.98, 1.82, 2.84, 1.76, 2.1, 2.01, -1.74, 2.25, 1.74, 2.41, 2.22, 2.85, -1.81, -1.22, 1.2, -0.99, -1.0494795918367348, -0.72, -0.81, -4.46, -0.58, -1.08, -0.42, -0.61, 0.01, 2.55, 0.06, 0.33, 0.24, -3.45, 0.47, -0.03, 0.64, 0.45, 1.07, -0.008858126000982985, 0.02, -1.68, -0.13, -0.18, 0.0, -0.27, 0.04659939068867647, -3.77, 0.14, -0.35931972789115646, 0.31, 0.12, 0.74, -0.31, -0.18, -3.68, 0.23, -0.27, 0.4, 0.21, 0.83, -0.73, -1.03, 0.51, -0.52, 5.08, 0.05, 0.29, 0.19, -0.25, -0.1, 0.38, -1.36, 0.78, 0.21, 0.07, 0.44, -0.39, -0.36, 0.3, 0.27, -0.11, 0.27, -0.18, -2.24, 1.164765264284247, -0.93, -1.01, 0.61, 0.82, -0.7, 3.950378684807256, 4.06, 3.54, 4.23, 4.04, 4.68, -0.32, -0.41, -0.5, 0.17, -0.02, 0.6, 0.09, 0.67, 0.48, 1.1, -1.02, -1.46, -0.58, -0.19, 0.43, -0.1, -0.09, -0.6, -0.41, -2.0, 0.27, 0.73, 0.5510935020800125, -0.39, 0.62, -0.15, 0.11, -0.33, -0.47523809523809524, 0.38, -1.0, 2.66, 0.013037664716236297, -2.24], ['363', -0.29, -0.21, -0.12984710169072947, 0.18, -0.3, -0.17, 0.69, -0.59, -0.51, -0.25, 1.47, -1.05, 0.27, 0.27, 0.57, -0.45, 0.04, 0.03, -0.95, -0.05, -0.57, -0.25, 0.07, -0.35, -0.44, 0.01, -1.7, -2.48, -1.18, -1.19, -0.89, -1.89, -1.41, -1.42, -2.38, -1.5, -2.01, -1.7, -1.38, -1.7461582768021608, -0.13, -1.14, 0.81, 1.34, 1.4978753944468233, 1.63, 0.61, 1.1, 1.09, 0.1, 1.01, 0.48, 0.81, 1.13, 0.71, -1.52, -0.29, 0.22, 0.0, -0.52, -0.01, 0.29, -0.72, -0.24, -0.24, -1.22, -0.32, -0.676578845757417, -0.52, -0.21, -0.62, -0.98, -0.52, 0.3, -0.71, -0.23, -0.23, -1.21, -0.32, -0.84, -0.52, -0.2, -0.62, -1.37, -0.48, 0.41, -0.81, -1.01, -0.53, -0.53, -1.51, -0.61, -1.13, -0.81, -0.5, -0.91, 0.35, 0.2, 0.49, 0.48, -0.5, 0.4, -0.12, 0.2, 0.52, 0.1, -0.17, 0.22, -0.56, -0.26, -0.17, -0.26, -0.29, -0.01, -0.99, -0.09, -0.61, -0.29, 0.03, -0.3314153161169343, -0.09, -0.28, -0.98, 0.012244713705627006, -0.6, -0.28, 0.04, -0.38, -0.12, -0.1, 0.27, 0.23318678362356798, 0.98, -0.02, 0.0, 0.99, -1.02, -0.49, 0.2, -0.8497402597402597, 0.3, 0.46, 0.27, -0.12, 0.003079789868779062, -0.77, 0.71, 0.79, -0.26, 1.42, -0.53, -1.24, 0.61, -0.88, 2.76, 0.5, 0.75, -0.3, 0.7, 0.91, 0.38, 0.7, 1.03, 0.6, -0.72, -0.2, -0.52, -0.2, 0.12, -0.3, 0.32, 0.32, 0.64, 0.22, -0.45, -0.83, 0.0, 0.32, -0.1, -0.26, -0.21, -0.65, 1.6, -0.59, -1.44, -0.23, -0.79, -0.32, -0.42, -0.25, -0.24, -0.05, -0.12, -0.23, 0.1, 1.64, -0.41, -0.18], ['364', -0.69, -0.32, 0.05122171562045875, 0.07, -0.1170209190089404, 0.85, 1.0041152579598291, 1.41, 0.48, 0.85, 0.47, 0.42, 0.46, -0.51, -2.7, 1.14, 0.87, 0.67, -3.77, 1.47, 0.71, 1.27, -0.42, 1.08, 0.48, 0.54, 0.38, -0.05, 0.0, -0.97, -3.15, 0.67, 0.4, 0.21, -4.22, 1.0, 0.24, 0.8, -0.89, 0.61, 2.01, -0.5250638007838266, 0.43, 0.05, -0.92, -3.1, 0.72, 0.46, 0.26, -4.17, 1.05, 0.29, 0.9438655564790018, -0.84, 0.67, 0.68, 0.74, 0.66, 0.73, 0.38, -0.96, -3.15, 0.67, 0.41, 0.21, -4.21, 1.01, 0.25, 0.81, -0.88, 0.62, 0.94, 1.36, -2.21, 1.65, 1.39, 1.19, -3.28, 1.99, 1.22, 1.79, 0.08, 1.6, 0.37, 2.9, -2.92, 3.65, 3.95, 3.67, 3.47, -1.1, 4.29, 3.51, 4.08, 2.34, 3.89, -2.4, -0.29, -0.26, -0.46, -4.85, 0.33, -0.42, 0.13, -1.54, -0.05, 0.03, -0.36, -2.09, 0.36, 0.78, -0.14, -0.02, -0.2, -4.6, 0.6, -0.16, 0.4, -1.29, 0.21, -0.41, 0.17, -4.41, 0.8, 0.04, 0.59, -1.09, 0.6521774376417234, 0.74, 0.45, 0.23, 0.32, -7.08, 0.0, -0.14, 1.55, -1.54, -0.76, -0.45, 2.18, 1.37, -0.73, -0.35, -0.31, 0.71, 1.02, -1.01, -1.11, 0.36, 2.3, 0.77, -0.33, 0.14, -0.12, -3.4, 0.0, 0.13, -1.27, 4.8, 5.45, 4.65, 5.24, 3.47, 5.04, 1.08, -0.62, -0.75, -0.2, -1.87, -0.38, 0.14, 0.56, -1.13, 0.37, 0.58, 0.53, -0.42, -1.67, -0.19, 0.36, 0.3, 1.44, -0.98, -1.86, 1.03, -1.0, 0.77, 1.28, 1.52, 1.2, -0.69, 0.32, 1.78, 0.55, -0.23, 0.46024063436563456, 2.9, -0.33], ['365', -5.08, 0.04, -0.028778284379541254, 0.09, -1.06, -0.11, 0.6700361663652803, -0.41, -0.2, -0.15, 0.28, -1.14, 0.66, 1.25, 0.46, 1.46, 0.45, -0.23, -0.56, 2.33, -0.55, -0.35, 0.41, 0.42, -1.14, -0.87, -0.43, -1.4098214285714286, 0.3846428571428572, 1.10318993704708, 0.18, 1.18, 0.17, -0.51, -0.84, 2.05, -0.83, -0.63, 0.13, 0.13, -0.42, -1.19, 1.189303232481804, 1.82, 2.41, 1.61, 2.63, 1.61, 0.92, 0.58, 3.51, 0.59, 0.79, 1.56, 1.57, -0.42, 0.04, 0.15, -0.6, -0.81, 0.58, -0.2, 0.8, -0.21, -0.88, -1.21, 1.66, -1.21, -1.01, -0.25, -0.21581519274376415, 1.45, -1.38, -0.78, 0.21, -0.78, -1.46, -1.79, 1.07, -1.78, -1.58, -0.83, -0.82, -0.64, -1.5, 1.49, -0.61, 1.0, 0.0, -0.68, -1.01, 1.87, -1.01, -0.81, -0.05, -0.04, -3.2679047619047616, -1.512633468783437, -0.99, -1.67, -1.99, 0.86, -1.99, -1.79, -1.04, -1.03, 0.07, -1.61, -3.589822996574516, -0.47, -0.52482093036566, -0.39, -0.5381905235138708, -0.68, -1.01, 1.87, -1.0, -0.8, -0.05, -0.04, -0.09, 0.07, -0.33, 2.57, -0.33, -0.13, 0.64, 0.64, -0.49, -0.04, 0.15603717887804044, -0.65, -9.63, -0.03, -0.09, 1.5, -1.52, -0.73, -0.43, -1.8297402597402599, 4.84, 0.94, 0.45, -2.51, 0.3, -1.47, 1.49, 1.36, -0.46, 2.22, -0.93, -0.42, 0.18, -1.84, 5.97, 1.29, 1.79, -4.88, 0.41, 2.91, 0.01, 0.21, 0.97, 0.98, -1.46, -2.43, -2.82, -2.63, -1.8712346938775508, -1.8785714285714286, 0.4, 0.2, 0.97, 0.97, -0.22, -0.42, 0.2, 0.76, 0.77, -0.47, -0.51, -0.38, 3.65, -2.45, -3.65, -1.84, -1.16, -0.56, 0.01, -0.48, -0.63, 0.24, 0.53, -0.15, -0.57, -3.48, -2.07, -0.61], ['366', -2.89, -0.35, 0.011221715620458745, 0.23, -1.19, -0.31158037632624047, -0.6858847420401708, -1.45, -1.16, -1.92, -0.36, -1.72, -1.35, -0.8, 0.91, -1.46, -1.31, -1.97, -0.89, -1.04, -2.37, -0.93, -0.6356947683993238, -1.73, -1.1, -0.540628585411108, -1.5373416050068875, -1.36, -0.99, -0.29681006295292, 1.3278199712950913, -1.11, -0.96, -1.62, -0.54, -0.68, -2.02, -0.57, -0.37, -1.38, -1.4, -1.41, -0.21, 0.38, 0.94, 2.67, 0.26, 0.41, -0.26, 0.84, 0.69, -0.67, 0.8938655564790019, 1.0, -0.02, -1.45, -1.13, -0.75, -1.25, -0.58, 0.56, 2.28, -0.12, 0.03, -0.63, 0.46, 0.31, -1.04, 0.42, 0.62, -0.39, -1.6763939988582846, -1.14, 1.72, -0.67, -0.3705105874517638, -1.19, 0.14747644815501967, -0.24, -1.59, -0.13, 0.06, -0.94, -1.71, -3.26, 3.22, -2.7633017616146796, -2.35, -2.2, -2.85, -1.78, -1.93, -3.25, -1.82, -1.62, -2.61, -0.77, -0.3926334687834371, 0.15, -0.52, 0.8866683673469387, 0.43, -0.93, 0.54, 0.74, -0.27, -0.12, -0.41, -1.69, -0.42, -0.62, -0.23, -0.61, -0.66, 0.43, 0.28, -1.07, 0.39, 0.59, -0.42, -0.8334639289282145, 0.05, 1.1, 0.95, -0.41, 1.06, 1.26, 0.24, -0.68, -0.54, 0.06, -0.37, -2.16, -0.24, -0.21, -0.26, 0.24, 0.13, -0.29, -1.43, 1.8, 0.8, 0.38, -1.4, -0.38692021013122097, -1.29, 1.27, 1.23, -0.44, -0.39, -0.86, -3.33, 1.68, -1.76, 4.31, 1.19, 1.77, -1.7, -1.04, -0.15, -1.49, -0.04, 0.16, -0.85, -1.25, -0.89, -1.35, 0.11, 0.31, -0.7, 0.46, 1.48, 1.68, 0.66, -1.14, -1.56, -1.0, 0.3932337781266354, -0.81, -0.42, -0.44, -1.41, 2.03, -1.35, -2.05, -0.11, -0.7989064979199876, -1.2, -1.01, -0.58, 0.3, -0.47, -0.56, -0.29, -0.19, -1.13, -1.15, -0.27], ['367', 5.21, 0.56, 0.07122171562045874, 0.03, 0.99, 1.25, 0.6, 2.16, 1.69, 2.39, 0.7303184712113286, 1.82, 1.26, 0.13, -0.9, 1.28, 0.86, 1.85, 2.46, 1.87, 3.04, 1.21, 0.95, 1.33, 2.49, 2.27, 1.87, 1.3, 0.74, -0.39, -1.4, 0.76, 0.34, 1.32, 1.94, 1.35, 2.51, 0.69, 0.44, 0.81, 2.21, 1.95, 0.56, -0.56, -1.66, -2.67, -0.54, -0.95, 0.02, 0.63, 0.05, 1.19, -0.6, -0.85, -0.49, 1.9800628463056764, 1.93, 1.16, 2.03, 1.12, -1.11, -2.12, 0.02, -0.39, 0.58, 1.19, 0.61, 1.76, 0.09295748299319728, -0.3, 0.07, 1.13, 2.26, -1.02, 1.15, 0.73, 1.71, 2.33, 1.74, 2.91, 1.08, 0.82, 1.2, 1.7, 4.0, -3.96, 3.32, 2.19, 1.77, 2.77, 3.39, 2.79, 3.97, 2.13, 1.87, 2.24, 3.57, 1.11, -0.41, 0.56, 1.17, 0.59, 1.74, -0.06, -0.32, 0.05, 0.6, 1.18, 2.48, 1.14, 1.22, 1.24, 1.52, 0.98, 1.59, 1.01, 2.16, 0.35, 0.09, 0.46, 1.17, 0.54, 0.61, 0.03, 1.17, -0.62, -0.88, -0.51, 1.35, 1.13, 0.23, 1.76, 10.77, 0.6, 0.9428571428571428, -1.79, 1.71, 0.87, 0.52, 1.41, -1.05, -2.33, -1.17, 2.58, 0.49, 3.69, -3.58, -3.37, 1.14, -2.66, 2.3, 0.25, -0.1, 4.48, -8.49, -3.0, -4.53, 0.97, -0.07, -0.58, 0.56, -1.22, -1.47, -1.11, 3.46, 0.51, 1.14, -0.65, -0.9, -0.54, -0.62, -1.77, -2.02, -1.66, 1.76, 1.88, 1.17, -0.26, 0.11, 1.12, 1.29, 2.04, -4.9, 2.44, 5.0, 2.73, 2.23, 1.43, 0.37, 1.97, 0.99, 0.26529795204795226, 0.29, 0.49, 1.05, 4.74, 3.3, 1.05], ['368', -0.08, 0.42, -0.07984710169072946, -0.01, -0.29, 0.08, 0.5, 0.71, 0.37, 0.43, 0.52, -0.06, 0.11, -0.03, -0.61, 0.87, 0.6, 0.31, 1.55, 1.55, 0.39, 0.36, 0.06, 0.41, 0.8, 0.23937141458889197, -0.09, -0.58, -0.42, -0.55, -1.0721800287049086, 0.34, 0.07, -0.21, 1.03, 1.02, -0.13, -0.17, -0.46, -0.11, 2.24, 0.4808975626058773, 0.5, 0.17, 0.03, -0.55, 0.93, 0.66, 0.37, 1.62, 1.61, 0.45, 0.42, 0.12, 0.47, 0.9900628463056765, 0.22, 0.87, 0.52, 0.33, -0.14, -0.72, 0.76, 0.49, 0.21, 1.4671802721088434, 1.44, 0.28, 0.25, -0.05, 0.31, 0.75, 0.47, -0.58, 0.9, 0.63, 0.34, 1.59, 1.58, 0.42, 0.39, 0.09, 0.45, -0.1, 1.0, -1.03, 1.05, 1.49, 1.22, 0.93, 2.18, 2.17, 1.01, 0.98, 0.67, 1.03, -0.81, -0.43, -0.27, -0.55, 0.68, 0.68, -0.47, -0.5, -0.8, -0.45, 0.19, -0.42, 1.31, 0.1, 0.19517906963433995, 0.10567351865003197, -0.16, -0.28, 0.95, 0.95, -0.21, -0.24, -0.54, -0.12141531611693432, 0.17, 0.17307674813036728, 1.24, 1.23, 0.08, 0.05, -0.25, 0.1, 0.51, 0.57, -0.1, 0.0, -2.58, -0.08, -0.14, 0.03, -0.04, 0.0, 0.98, -0.09383646788795053, 1.92, -0.18, -0.12, -0.07, -0.04, 0.28, -0.39, -0.25, 0.11, 0.02, 0.19, 1.06, -0.55, -0.56, 0.83, 0.36, 0.57, -1.94, -1.1, -0.01, -1.15, -1.18, -1.48, -1.12, 0.28, -1.09, -1.14, -1.17, -1.47, -1.12, 0.05, -0.03, -0.33, 0.02, 0.36, 0.22, 0.08, -0.3, 0.06, 0.11, 0.04, 0.77, -0.19, 0.5, -0.19, 0.6872638105244333, -0.13, 0.38, 0.36, -0.25, -0.21978021978021978, 0.16, -0.14, 0.694626243824729, 0.02, -0.6697593656343656, -0.51, -0.18], ['369', 2.85, 0.3, -0.29, 0.26, 0.35, -0.49, -0.35, 0.62, -0.62, -0.56, 0.46, 0.1, -0.34, -1.16, -1.75, -2.319285714285714, -1.17, -0.5594285714285715, -0.35, -0.4, -0.56, -1.3738418367346938, -0.17, -0.22, -0.18, 0.67, -1.02, -0.36, -0.79, -1.61, -2.19, -2.76, -1.62, -1.02, -0.8, -0.85, -1.02, -1.84, -0.62, -0.68, 1.06, -0.68, -0.66, -0.43, -1.26, -1.84, -2.3989563492063493, -1.27, -0.66, -0.44, -0.5, -0.66, -1.49, -0.26, -0.32, 0.68, 0.9157142857142857, 0.0, -0.94, -0.23, -0.82, -1.41, -1.9857142857142858, -0.84, -0.23, -0.01, -0.06, -0.23, -1.06, 0.17273474541331685, 0.11, 0.47, 0.6, -0.59, -1.18, -0.01, 0.6, 0.82, 0.77, 0.6, -0.24, 1.0, 0.95, -0.97, 1.01, -1.1, 1.2, -0.58, 0.59, 1.2, 1.42, 1.37, 1.2, 0.44571428571428573, 1.61, 1.55, 1.82, 1.8, 1.18, 1.8, 2.02, 1.97, 1.8, 0.95, 2.2, 2.15, -0.11, 1.83, 1.44, 0.12, 0.23, 0.21, 0.61, 0.61, 0.83, 0.78, 0.61, -0.23, 1.02, 0.96, 0.69, 0.0, 0.22, 0.17, 0.0, -0.83, 0.5985714285714285, 0.34, 0.11, 0.73, 0.5, 0.54, 5.34, -0.2496768707482993, -0.22, -1.18, 1.2, 0.28, 0.39, -0.56, 0.35, -0.28857142857142853, 0.3082806122448981, 1.48, -0.24, 0.56, -0.3771428571428571, -0.3042857142857143, -0.49, -1.69, 0.21, -2.56, 1.31, 1.81, -0.8172908163265306, -1.18, -1.84, -0.51, -0.22, -0.05, -0.22, -1.05, 0.18, 0.12, 0.46, -0.17, -0.17, -1.0, 0.23, 0.18, 0.0, -0.83, 0.4, 0.34142857142857147, -0.63, -0.96, 0.84, 1.24, 1.19, 0.07, 0.32, 0.62, -0.41, 0.97, 0.33, -0.22, 0.05, -0.4, -0.06, -0.38, -0.28, -1.07, -1.48, -0.71, -0.34, 1.11, 1.38, 0.23], ['370', -1.62, 1.26, 0.25, -0.18, 1.01, 1.12, 0.9641152579598291, 2.12, 2.23, 1.35, -1.74, 0.35, -1.3, -2.26, -0.21, 1.6711360544217686, -0.8, 0.47020578231292515, 6.41, 0.01, 2.39, 0.51, -0.67, 0.0, 2.12, 2.33, 3.14, 2.13, 0.45, -0.53, 1.56, 3.44, 0.96, 2.22, 8.29, 1.78, 4.2, 2.29, 1.09, 1.8138417231978392, 1.46, 4.274936199216174, 0.990204081632653, -1.65, -2.6, -0.56, 1.28, -1.14, 0.08, 6.03, -0.34, 2.03, 0.15, -1.02, -0.35, 1.6900628463056764, 1.94, 1.7, 2.51, 2.69, -0.97, 1.11, 2.97, 0.51, 1.76, 7.81, 1.33, 3.74, 1.83, 0.64, 1.32, 2.23, 3.6914285714285713, 2.1, 3.98, 1.5, 2.76, 8.87, 2.32, 4.76, 2.8314285714285714, 1.62, 2.31, 3.18, 5.47, -5.48, 1.56, 1.85, -0.59, 0.65, 6.63, 0.4137447711019141, 2.61, 0.72, -0.46, 0.21, -0.21, -0.28, -2.39, -1.18, 4.7, -1.6, 0.74, -1.11, -2.27, -1.61, 0.74, -0.28, 1.81, 0.79, 1.23, 1.31, 2.16, 1.24, 7.26, 0.81, 3.21, 1.31, 0.12, 0.8, 0.17653607107178546, 0.91, 5.94, -0.43, 1.94, 0.07, -1.1, -0.44, 2.18, 1.98, -0.08, 1.4, -0.44, 0.31, 0.21, -2.71, 2.75, 1.38, -2.37, 1.47, -2.68, -2.5, -1.27, -0.82, 0.58, 3.97, -3.9, -3.83, 1.26, -4.15, 2.57, 2.73, -1.38, 6.42, -3.73, -4.25, -6.46, 2.6171309523809523, -4.75, -6.01, -3.77, -5.55, -6.65, -6.02, 3.81, 1.34, 2.38, 0.5, -0.68, -0.01, -1.02, -1.84, -2.99, -2.34, 2.13, 2.84, 0.84, -1.17, -0.5, 1.31, 1.36, 2.03, -2.35, 1.89, 2.18, 2.16, 1.62, 2.03, 0.68, 1.74, 1.12, 0.12, 0.51, 1.15, 1.35, 3.4, 2.51, 1.62], ['371', -0.38, 0.0, 0.09122171562045875, 0.05, -0.89, -0.11, -0.4558847420401708, 0.07, -0.19, -0.23, -0.09939115646258503, -0.18, -0.52, -0.85, 0.28, -0.4, 0.13, -0.08, 4.49, 1.19, -0.09, -0.13, 0.14, 0.08, -0.47, -0.11, -0.12, -0.07, 0.007674603174603278, -0.73, 0.39, -0.2897142857142857, 0.24, 0.04, 4.61, 1.3, 0.03, -0.01, 0.25, 0.19, -1.04, -0.25506380078382657, -0.05, -0.25880253250388296, -0.67, 0.46, -0.22, 0.31, 0.1, 4.68, 1.37, 0.09, 0.05, 0.32, 0.26, -0.17, -0.38, 0.48, 0.29, 0.29, -0.33, 0.8, 0.11, 0.65, 0.44, 5.04, 1.8339757335335067, 0.44, 0.39, 0.66, 0.6, 0.55, 0.62, 1.13, 0.45, 0.98, 0.77, 5.39, 2.05, 0.77, 0.73, 0.99, 0.93, -0.18, -0.91, 0.95, -0.51, -0.68, -0.15, -0.35, 4.21, 0.9, -0.36, -0.4, -0.14, -0.2, 0.38, 0.17, 0.54, 0.33, 4.92, 1.6, 0.32, 0.28, 0.54, 0.49, -0.23, 0.12, -1.38, -0.07840181931709851, -0.14, -0.09, -0.36, -0.21, 4.36, 1.05, -0.21, -0.26, 0.01, -0.05, -0.08, -0.16, 4.58, 1.26, -0.01, -0.05, 0.21, 0.16, -0.45, -0.48, 0.27, -0.14, 1.27, -0.09, -0.15, 0.37, -0.23827987418743707, -0.18, 0.14, -0.68, 2.71, 0.27, 0.11, -0.2, 0.16307978986877908, -0.35, 0.37, 0.33, -0.07670919513614705, 0.49, -0.24, -1.14, 0.56, -1.07, -1.12, 0.71, 1.04, -2.344384920634921, -4.52, -3.17, -4.38, -4.42, -4.17, -4.22, -0.34, -1.4, -1.26, -1.3, -1.04, -1.09, -0.15, -0.04, 0.22, 0.17, -0.15, -0.02, -0.11, 0.26, 0.21, -0.11, -0.11, 0.14, -0.52, -1.16, 0.58, -0.17, -0.29, -0.37, -0.05, 0.14, -0.07, -0.2, 0.05, 0.25, -0.31, -0.38, -0.8584047619047619, -0.79], ['372', 9.71, 0.0, 0.04, -0.03, 1.29, 0.58, 0.75, 1.18, 0.87, 0.4453571428571429, -0.6, -0.5606751700680271, -1.19, -0.1, -1.64, -2.05, -0.75, 0.11, -0.5, -1.55, 0.64, 0.31, -0.83, -0.75, 0.95, 1.32, 0.98, 0.03, -0.6, 0.5, -1.05, -1.45, -0.15, 0.71, 0.1, -0.96, 1.25, 0.91, -0.23, -0.15, 1.5, 0.55, 0.96, -0.5388025325038829, 0.47, -1.08, -1.48, -0.17, 0.69, 0.08, -0.98, 1.22, 0.89, -0.26, -0.18, 0.77, 1.91, 0.88, 1.36, 1.59, 1.11, -0.45920068027210886, -0.86, 0.45, 1.32, 0.7, -0.23602426646649322, 1.86, 1.52, 0.37, 0.45, 1.69, 0.48, -1.54, -1.95, -0.65, 0.21, -0.4, -1.45, 0.75, 0.41, -0.73, -0.65, 0.59, 2.89, -2.93, 2.0966982383853203, -0.41, 0.91, 1.79, 1.17, 0.09, 2.33, 1.99, 0.83, 0.91, 3.24, 2.47, 1.33, 2.3053350340136056, 1.58, 0.5, 2.75, 2.4, 1.24, 1.32, 0.28, 2.44, 2.53, 0.82, 0.82, 0.87, 1.13, 0.86, 0.25, -0.81, 1.4, 1.06, -0.08, -0.01, 0.26, 0.27, -0.61, -1.66, 0.53, 0.2, -0.94, -0.86, 0.68, 0.68, 0.02, 0.99, 9.72, 0.05, -0.03, -1.51, 1.47, 0.72, 0.25406627346681526, 0.8, -3.8094817511227284, -1.65, -0.89, 4.77, 0.34, 2.45, -2.61, -2.51, 0.82, -2.25, 1.67, 0.97, -0.51, 3.42, -2.17, -2.33, -3.37, 4.04, 0.88, -1.06, 1.15, 0.81, -0.33, -0.26, 2.51, 1.9601587301587302, 2.23, 1.89, 0.74, 0.81, -0.27, -0.33, -1.46, -1.39, 0.89, 0.89, 0.07, -1.13, -0.9877512446849838, 0.84, 0.86, 1.13, -1.16, 1.72, 1.28, 1.78, 1.18, 1.21, 0.08, 0.95, 0.7, 0.42, 0.24, 0.68, 1.14, 2.55, 1.88, 2.1], ['373', 1.5, -0.25, -0.31877828437954125, -0.01, 0.83, 0.54, 0.07411525795982916, 0.72, 0.07, -1.34, -1.24, -1.5, -1.66, -2.46, -2.96, -1.28, -2.6, -1.06, 0.11, -3.08, -1.75, -2.69, -2.13, -1.73, 0.48, -0.36, -0.1, -0.26, -0.42, -1.23, -1.73, -0.04, -1.37, 0.19, 1.37, -1.86, -0.51, -1.47, -0.9, -0.49, 1.1574684253532108, 0.0, 0.16, -0.16, -0.97, -1.48, 0.22, -1.12, 0.45, 1.64, -1.6, -0.25, -1.21, -0.64, -0.23, 0.52, 0.25, 0.78, 0.73, 0.32, -0.82, -1.32, 0.38, -0.96, 0.7126050661400617, 1.8, -1.45, -0.09, -1.05, -0.48, -0.07, 0.33, 1.15, -0.51, 1.21, -0.15, 1.44, 2.64, -0.64, 0.73, -0.24, 0.34, 0.75, -0.48, 2.53, -2.6, 1.69669823838532, 1.72, 0.36, 1.96, 3.16, -0.13, 1.25, 0.27, 0.85, 1.27, 0.0, 0.017366531216562897, -1.33, 0.23, 1.41, -1.82, -0.47, -1.43, -0.86, -0.45, -0.39, -0.06, 0.72, 0.68, 0.6, 0.86, 1.29, 1.59, 2.79, -0.49, 0.88, -0.09, 0.48, 0.9, 1.3, -0.29, 1.18, -2.05, -0.7, -1.65, -1.09, -0.68, 0.89, 1.34, -0.13, 1.21, 0.03, 0.13225133596562166, -0.62, -2.19, 2.23, 1.1, 1.01, 0.69, -3.55, -1.35, -0.67, 0.72, 0.04, 2.04, -2.13, -1.93, 0.69, -3.25, 1.39, 0.45, -0.31, 3.88, -1.96, -2.51, -3.83, 3.55, -1.45, -3.19, -1.86, -2.8, -2.24, -1.84, 2.01, 1.8, 1.38, 0.4, 0.98, 1.4, 0.41, -0.96, -0.39, 0.02, 0.0927953514739229, 0.14, 1.39, 0.57, 0.99, 0.63, 0.69, 0.69, -0.96, 1.0101996269574993, 1.1, 0.31, 0.4611825396825397, 0.81, 0.42, 0.68, 1.23, 0.38, 0.01, 0.3846262438247291, 0.39, 1.37, 1.14, 0.56], ['374', 0.79, -0.99, 0.12, -0.11, -0.81, 0.33841962367375944, 1.39, 0.44, 0.1, 0.65, 0.01, -0.26, 0.29, -1.74, 0.06, 0.5, 0.52, 0.64, 2.135862135879993, 1.66, 0.23733548208735894, 0.98, -0.08, 0.62, 0.37, 0.14, 0.6726583949931124, -0.27, 0.28, -1.75, 0.05, 0.5, 0.51, 0.63, 1.96, 1.65, 0.19, 0.97, -0.08, 0.61, 0.3, -0.06506380078382656, 0.91, 0.55, -1.48, 0.32, 0.77, 0.78, 0.91, 2.23, 1.93, 0.46, 1.24, 0.19, 0.88, 0.07, 0.44, -0.07, -0.61, 0.43924524706587753, -2.02, -0.22, 0.22, 0.23, 0.36, 1.67, 1.37, -0.08, 0.69, -0.36, 0.33, -0.82, 2.43, 1.83, 2.29, 2.3, 2.43, 3.77, 3.46, 1.98, 2.77, 1.7, 2.4, 0.0, 1.6, -1.61, 0.59, 0.44, 0.46, 0.58, 1.9, 1.6, 0.14, 0.92, -0.14, 0.56, 2.84, 0.14, 0.01, 0.14, 1.45, 1.15, -0.3, 0.47, -0.58, 0.12, -0.02, 0.16, 0.38, 0.15, 0.33, -0.03, 0.13, 0.12, 1.44, 1.14, -0.32, 0.46, -0.59, 0.1, -0.45, 0.01, 1.31, 1.01, -0.44, 0.34, -0.71, -0.02, 0.34, 0.17, -0.26, 0.13, 8.22, 0.0, -0.07, 0.46, -0.4, -0.21, -0.66, 0.54, 1.92, -0.26, -0.13, 0.4, -0.32, 0.38, -0.39, -0.41, 0.13, 0.62, 0.29, 1.63, -0.81, 0.44, 0.93, -0.24, -0.4, -1.85, -1.29, -0.3, -1.73, -0.97, -2.0, -1.32, 0.35, -0.99, -1.43, -0.67, -1.71, -1.02, 0.45, 0.78, -0.28, 0.42, 0.11, -0.34, -0.33, -1.04, -0.36, 0.16, 0.22439630127529087, 0.5, 0.27, 0.24, -0.23, 0.88, -0.08, 0.72, 0.7, 0.12, -0.15, -0.17, -0.31, 0.25, 0.03, 2.9, 0.43, -0.35], ['375', -2.67, -0.06, 0.21, 0.15, 0.19, 0.51, 0.32, 1.23, 0.68, 1.51, 0.82, 1.21, 0.68, 0.33, 0.4742210884353741, 2.29, 1.1271428571428572, 1.43, 2.24, 0.87, 1.48, -0.08, -0.55, 1.3, 1.1685936610075265, 1.47, 0.68, 0.39, -0.14, -0.49, -0.78, 1.45, 0.26, 0.6, 1.41, 0.05, 0.65, -0.9, -1.36, 0.47, 0.92, 1.09, 0.29020408163265304, -0.53, -0.87, -1.16, 1.06, -0.13, 0.21, 1.02, -0.34, 0.26, -1.28, -1.75, 0.08, 1.6023573314652815, 0.82, 0.78, 0.88, 0.82, -0.35, -0.64, 1.6, 0.4, 0.74, 1.55, 0.19, 0.79, -0.76, -1.219795918367347, 0.61, 0.9, 1.17, -0.29, 1.95, 0.75, 1.1, 1.91, 0.54, 1.14, -0.41, -0.88, 0.97, 1.13, 5.05, -5.2, 1.47, 2.25, 1.04, 1.39, 2.2, 0.83, 1.44, -0.12, -0.59, 1.26, -1.06, -0.76, -1.18, -0.84, -0.05, -1.38, -0.79, -2.32, -2.78, -0.97, 0.36, -0.76, -0.08, 0.19, 0.4, 0.19, 0.42, 0.34, 1.14, -0.21, 0.39, -1.16, -1.62, 0.21, 0.46, 0.08, 0.8, -0.55, 0.05, -1.49, -1.917142857142857, -0.13, 3.04, 3.07, 0.39, 1.07, -3.29, 1.468069549498121, 0.9628571428571429, -1.49, 1.45, 0.73, -2.11, 0.0, -1.31, -1.67, -0.81, -1.33, 0.11, 2.61, -2.58, -2.49, 0.81, -2.19, 1.61, -0.74, 0.37, 2.77, -2.34, -1.79, -2.84, 1.2, -0.72, -1.34, -0.75, -2.27, -2.73, -0.92, 2.4, 0.63, 0.6, -0.95, -1.41, 0.42, 0.03, -1.54, -2.0, -0.18, 0.61, 0.89, 1.59, -0.47, 1.38, 0.75, 0.85, 0.97, -1.01, 0.65, 0.59, 0.95, 1.18, 2.07, 1.86, 0.96, 0.96, -0.34, 0.17, 0.47, 0.21, 2.2, 1.16, -0.23], ['376', 2.87, 0.0, -0.08, -0.03, 0.64, 0.53, 1.144115257959829, 1.34, 1.45, 1.62, -0.26, 0.36, 0.73, 0.75, 0.36, 1.69, 0.71, 1.31, 1.71, 2.02, 2.29, -0.1, 0.95, 0.63, 1.28, 0.76, 1.89, 0.63, 0.99, 1.02, 0.63, 1.96, 0.98, 1.58, 1.98, 2.29, 2.644453670078569, 0.17, 1.21, 0.9, 0.53, 2.0800621118012423, 1.25, 0.36, 0.39, -0.01, 1.32, 0.35, 0.94, 1.34, 1.64, 1.9480654680864429, -0.46, 0.58, 0.27, 0.8, 1.01, 1.4, 1.38, 0.89, 0.03, -0.25515323205954743, 0.96, -0.01, 0.58, 0.98, 1.28, 1.56, -0.82, 0.22, -0.09, 0.86, 0.86, -0.39, 0.93, -0.04, 0.55, 0.95, 1.25, 1.53, -0.85, 0.19, -0.12, 1.94, 2.1, -2.07, 1.26, 1.33, 0.35, 0.95, 1.35, 1.65, 1.93, -0.46, 0.58, 0.27, 0.15, -0.07, -0.96, -0.37, 0.02, 0.32, 0.59, -1.76, -0.73, -1.04, 0.12, -0.01, 0.16, 0.56, 0.62, 0.51, 0.91, 0.59, 1.0, 1.29, 1.57, -0.8, 0.23, -0.08, 1.82, 0.31, 0.4, 0.7, 0.97, -1.39, -0.36, -0.67, 0.77, 0.86, 0.15603717887804044, 0.88, 0.3, 0.03, 0.0, -0.64, 0.61, 0.3, 0.13, 3.1102597402597403, 0.72, -1.13, -0.57, 1.4, 0.53, 1.77, -1.73, -1.7, 0.55, -1.0, 1.07, 0.3, -0.14, 2.77, -5.3, -1.82, -2.79, -0.88, -0.09, 0.3, 0.57, -1.78, -0.76, -1.06, 1.69, -0.38, 0.27, -2.07, -1.05, -1.36, -0.66, -2.34, -1.32, -1.62, 1.37, 1.49, 1.72, 1.05, 0.73, 0.58, 0.63, 1.42, -2.56, 0.51, 2.58, 1.11, 0.9, 0.67, -0.31, 0.55, 0.22, 0.3, 0.67, 0.66, 0.98, 1.03, 0.96, 0.89], ['377', 2.53, 0.69, -0.08, -0.13, 1.95, 0.99, 0.024115257959829165, 1.62, 0.91, 1.46, 0.39, 1.94, -0.39, -0.28, 0.87, 0.55, 0.11, 1.22, -2.58, -1.56, 1.93, -0.42, 0.89, 0.41, 1.62, 2.04, 1.07, 1.54, -0.7598809523809524, -0.67, 0.48, 0.16, -0.27, 0.83, -2.96, -1.94, 1.53, -0.8, 0.5, 0.02, 1.01, 2.6849361992161733, -0.47, -2.28, -2.18, -1.05, -1.36, -1.79, -0.71, -4.428347866419295, -3.44, -0.01, -2.31, -1.03, -1.5, 1.13, 1.54, 0.63, 1.3, 1.86, 0.11, 1.27, 0.94, 0.5, 1.7126050661400618, -2.2, -1.18, 2.33, -0.03, 1.282734745413317, 0.8, 2.43, 1.75, 1.16, 0.83, 0.39, 1.5, -2.31, -1.29, 2.21, -0.14, 1.17, 0.69, 1.12, 1.83, -1.94, 0.58, -0.32, -0.75, 0.34, -3.42, -2.42, 1.2152352330209475, -1.28, 0.01, -0.46, 2.49, 0.91, -0.44, 0.67, -3.11, -2.1, 1.37, -0.96, 0.33, -0.14, 0.48, 0.92, 0.41, 1.22, 1.02, 1.44, 1.35, 1.11, -2.69, -1.67, 1.81, -0.53, 0.77, 0.29, 1.87, 0.24, -3.75, -2.75, 0.7, -1.62, -0.33, -0.8, 0.11, 0.28, -0.26, 1.43, 5.21, -0.03, -0.37, -2.68, 2.7, 1.37, 0.57, 3.79, -5.6794817511227285, -2.43, -1.27, 1.23, 0.41, 3.64, -3.68, -3.61, 1.2, -4.14, 2.4, 2.43, -1.19, 3.99, -8.62, -2.77, -3.97, 5.883809523809524, 4.15, 1.04, 4.63, 2.532096371882086, 3.56, 3.06, 3.57, 3.07, 3.55, 1.17, 2.49, 2.0, -0.46, -2.3, -1.02, -1.49, 0.89, 1.39, 1.88, 1.31, 0.82, 1.2, 1.28, 1.52, -4.24, 1.56, 4.35, 1.96, 2.95, 0.57, -0.48, 1.46, 1.53, 0.39, 0.83, 0.49, 1.05, 2.15, 4.5130376647162365, 1.06], ['378', 1.35, -0.12, 0.09122171562045875, -0.05, 0.1, 0.65, 0.19, 1.26, 1.27, 1.42, -0.81, 0.81, 0.63, 0.02, 0.26, 0.94, 1.01, 0.84, -4.22, 0.85, 2.16, 1.12, 0.64, 1.18, 1.66, 0.46, 2.2826583949931125, 1.63, 1.45, 0.84, 1.08, 1.77, 1.83, 1.66, -3.439285714285714, 1.68, 3.0644536700785694, 1.94, 1.46, 2.0, 0.95, 2.45, 0.61, -0.17, -0.78, -0.54, 0.14, 0.2, 0.03, -4.99, 0.05, 1.34, 0.31, -0.16, 0.37, 0.87, 1.21, 1.32, 0.75, 0.78, -0.61, -0.37, 0.31, 0.37, 0.21, -4.82, 0.22, 1.52, 0.48, 0.01, 0.54, 1.23, 1.4, 0.24, 0.92, 0.99, 0.82, -4.24, 0.83, 2.14, 1.09, 0.62, 1.16, 2.01, 2.12, -2.09, 1.15, 0.68, 0.74, 0.57, -4.47, 0.7837447711019141, 1.89, 0.85, 0.37, 0.91, 0.68, 0.47, 0.06, -0.1, -5.12, -0.09, 1.2, 0.17, -0.3, 0.23, 0.58, 0.48, 0.8, 0.44, 0.54, 0.33, 0.41, -0.17, -5.18, -0.15, 1.14, 0.11, -0.36, 0.17, 0.3, 0.57, -5.02, 0.01, 1.31, 0.27, -0.2, 0.5821774376417235, 0.51, 0.31, 0.08, 0.21, 1.91, 0.05, -0.2, -0.36, 0.3, 0.15, 0.39, 1.37, -1.1, -0.9, -0.48, 0.66, 0.09, 1.38, -1.41, -1.31, 0.44, -0.59, 0.9, 0.9183906549799409, -0.42, 1.16, -4.77, -0.84, -1.21, 1.19, 5.89, 5.3, 6.66, 5.57, 5.08, 5.64, 1.34, 0.56, 1.29, 0.26, -0.21, 0.32, -0.72, -1.02, -1.48, -0.96, 1.24, 1.53, 0.3, -0.47, 0.06, 0.47, 0.41, 1.18, -0.75, 0.66, 0.63, 0.52, 1.09, 0.848637448200971, 0.53, 0.72, 0.55, 0.0, -0.09, 0.2, 0.24, 1.34, 1.81, -0.02], ['379', 5.8, 0.52, 0.04015289830927054, -0.2, 1.86, 1.2, 0.5741152579598292, 1.0, 0.99, 0.73, -0.35, 0.51, 0.4, -0.6, 0.22, -1.11, -0.1, 0.6454705215419502, 0.21, -2.68, 0.93, 0.6370289115646258, -0.42, 0.13, 1.4, 0.71, 1.09, 0.87, 0.76, -0.25, 0.57, -0.76, 0.26, 0.89, 0.56, -2.34, 1.29, 0.7, -0.06, 0.49, 1.37, 1.7249361992161734, 0.22, -0.028802532503882913, -1.11, -0.29, -1.61, -0.61, 0.02, -0.3, -3.18, 0.41, -0.17, -0.93, -0.38, 0.07, 0.38, 1.25, 1.09, 0.33, -1.0, -0.18, -1.5, -0.49, 0.13, -0.19, -3.07, 0.683421154242583, -0.06, -0.82, -0.25056122448979595, 1.5, 1.34, 0.82, -0.51, 0.51, 1.14, 0.81, -2.1, 1.53, 0.94, 0.18, 0.74, 1.21, 3.09, -3.11, 0.52, -1.32, -0.31, 0.32, -0.01, -2.89, 0.71, 0.12, -0.64, -0.08, 1.82, 1.86, 1.02, 1.66, 1.3315238095238096, -1.59, 2.06, 1.46, 0.7, 1.26, 0.21, 1.83, 0.33, 0.95, 1.08, 0.77, 0.83, 0.63, 0.3, -2.59, 1.02, 0.43, -0.32, 0.23, 0.17, 0.2, -0.32, -3.2, 0.39, -0.2, -0.95, -0.4, 1.27, 1.54, -0.25, 1.01, 5.27, 0.1, 0.07, -0.93, 0.94, 0.47, -1.71, 1.17, -6.98, -1.91, -1.0, 2.91, 0.75, 2.84, -2.81, -2.84, 0.95, -1.49, 1.89, 0.89, -0.46, 2.5, -7.059348639455782, -1.73, -2.57, 6.9, 0.53, -2.88, 0.72, 0.13, -0.63, -0.07, 2.82, 3.51, 3.71, 3.3471428571428574, 2.33, 2.89, -0.19, -0.58, -1.33, -0.78, 0.96, 1.07, 0.4, -0.75, -0.2, 0.95, 0.92, 0.89, -4.08, 0.43, 3.86, 1.24, 1.82, 1.16, 0.56, 1.47, 0.8645528598385742, 0.74, 0.39, 0.47, 0.6, 1.78, 1.61, 1.36], ['380', -28.17857142857143, -0.37, 0.15122171562045875, -0.15, -1.35, 0.61, 0.6441152579598292, 2.23, 1.11, 1.81, 1.06, 1.05, -0.55, 0.02, -0.18, 7.230714285714286, 0.92, 1.52, 2.2, 1.45, 1.99, 2.1270289115646257, 0.45, -0.12, 1.45, -0.62, 0.74, -0.01, -1.5798809523809525, -1.03, -1.23, 6.1, -0.14, 0.45, 1.137761904761905, 0.39, 0.92, 0.76, -0.61, -1.17, 2.88, 1.44, 0.75, -1.5763410188391391, -1.02, -1.21, 6.354266594516595, 0.17865136054421765, 0.47, 1.13, 0.4, 0.93, 0.77, -0.59, -1.16, 0.99, 3.16, 2.29, 0.75, 2.37, 0.57, 0.37, 7.82, 1.48, 2.08, 2.76, 2.01, 2.56, 2.39, 1.0, 0.43, 1.97, 1.8, -0.19, 7.21, 0.91, 1.51, 2.18, 1.44, 1.98, 1.81, 0.43, -0.07644035827487929, 1.11, 3.61, -3.52, 1.99, 7.42, 1.1, 1.7, 2.38, 1.63, 2.17, 2.01, 0.6385238095238095, 0.06, -5.8, -5.05, -5.88, -5.32, -4.69, -5.39, -4.88, -4.797183003504432, -6.32, -6.85, 0.65, -5.07, 1.93572371188304, 0.93, 0.5, 0.47, 0.88, 0.59, 1.26, 0.53, 1.06, 0.9, -0.47, -1.03, -0.04, 0.29, 0.9136855802927233, -0.07, 0.47, 0.3, -1.06, -1.62, 1.64, 0.84, -0.36, 1.25, -11.682380952380951, 0.28, 0.15, -2.61, 2.64, 1.33, 0.23, 0.77, -0.38224102088387807, -1.75, -0.91, -14.094778911564626, 0.69, 2.87, -2.7, -2.64, 0.93, -3.95, 1.85, 2.77, -1.33, 3.69, 0.65, -2.3885714285714283, -3.7542857142857144, 0.66, -0.38, -0.73, -0.2, -0.3543095238095238, -1.71, -2.26, 2.61, 0.35, 0.53, 0.37, -0.99, -1.55, -0.18, -0.16, -1.51, -2.07, 1.19, 0.94, -0.02, -1.35, -1.91, 0.37, 0.43, 2.0, 0.2, 2.34, -0.32, 0.53, 0.08, 1.35, -0.57, 1.24, 1.18, 0.2, 1.25, 0.35, 1.93, 0.45, -0.46, 1.89], ['381', -1.09, -0.17, -0.3, -0.01, -0.29, -0.07, -3.4, -1.2, -1.06, -0.55, 0.21, 1.63, 0.99, 0.16, 1.38, -0.23, -0.43, -0.26, -0.038518140589569164, -0.28, -0.51, 0.03, -0.38, -0.11, -3.7, -0.36, -0.76, 1.42, 0.78, -0.05, 1.17, -0.44, -0.64, -0.47, -0.26, -0.49, -0.72, -0.18, -0.59, -0.32, -0.83, -0.9, -2.15, -0.63, -1.2821246055531768, -0.25, -1.83, -2.03, -1.86, -1.66, -1.89, -2.11, -1.58, -1.98, -1.72, -0.91, -0.99, -0.87, -0.52, -1.53, -0.82, 0.39, -1.2, -1.41, -1.24, -1.03, -1.26, -1.48, -0.95, -1.35, -1.09, -0.66, -0.71, 1.22, -0.39, -0.59, -0.42, -0.21, -0.45, -0.67, -0.13, -0.54, -0.2264403582748793, -0.59, -0.49, 0.45, -1.8733017616146799, -1.59, -1.79, -1.62, -1.41, -1.64, -1.87, -1.34, -1.73, -1.48, -1.19, -0.33, -0.2, -0.03, 0.18, -0.06, -0.28, 0.26, -0.15, 0.11, -0.18, -0.26, -0.6, -0.23, -0.26, -0.19, -0.12, 0.17, 0.38, 0.15, -0.08, 0.46, 0.05, 0.32, -0.66, -0.29, 0.21, -0.03, -0.25, 0.29, -0.12, 0.14, 0.09, 0.22276190476190477, 0.02, -0.49, -3.2922619047619044, 0.21, 0.27, 0.4, -0.43, -0.2, -0.97, -1.22, 0.58, 0.43, 0.21, -0.55, -0.34, -0.72, 0.78, 0.69, -0.22, 0.6, -0.49, -0.64, 0.34, -0.34, 0.3, 0.12, 0.28, -0.48, -0.5, -0.23, -0.46, 0.08, -0.32, -0.06, -0.69, -0.27, -0.22, 0.31, -0.09, 0.17, -0.04, 0.54, 0.13, 0.4, -0.99, -0.33, -0.58, -0.4, -0.14, -0.22, -0.25, -1.25, 0.37, -0.57, -0.44, -0.32, -0.66, -0.18, 0.26, -0.293994794887652, -0.28, 0.8, -1.13, -0.27, -0.44, -0.73, -0.91, -0.93], ['382', -3.52, -0.57, 0.04, 0.12, -1.01, -0.46, -1.1, -1.68, -1.26, -1.7, -0.15, -0.9, -0.09, 1.31, -0.46, -0.56, -1.08, -1.2, 1.28, -0.33, -2.07, -1.3, -0.49, -1.1, -0.26140633899247345, -1.2, -1.5273416050068875, -0.75, 0.06, 1.46, -0.32, -0.42, -0.93, -1.06, 1.875702380952381, -0.18, -1.93, -1.15, -0.35, -0.95, -1.55, -2.2, -0.81, 0.82, 2.23, 0.44, 0.34, -0.18, -0.31, 2.2, 0.58, -1.18, -0.4, 0.41, -0.2, -0.9, -1.48, -1.4, -1.07, -1.62, 1.4, -0.38, -0.48, -0.99, -1.12, 1.37, -0.24, -1.99, -1.21, -0.4072652545866831, -1.01, -1.01, -2.97, -1.75, -1.85, -2.35, -2.48, -0.03, -1.62, -3.34, -2.57, -1.78, -2.38, -1.87, -3.17, 3.23, -1.25, -0.1, -0.61, -0.74, 1.75, 0.13, -1.62, -0.84, -0.03, -0.64, -2.15, -1.15, -0.52, -0.64, 1.85, 0.24, -1.52, -0.74, 0.07, -0.54, -0.66, -1.127643118785976, -0.35, -0.49, -0.56, -0.47, -0.63, -0.13, 2.38, 0.75, -1.01, -0.22, 0.59, -0.02, -0.47, -0.51, 2.51, 0.88, -0.88, -0.09, 0.72, 0.1, -1.23, -0.9, 0.14, -0.58, -6.67, -0.63, -0.47, 0.48, -0.49, -0.29, -0.26, -2.5838364678879504, 2.79, 0.99, 0.51, -1.73, -0.15, -1.57, 1.49, 1.48, -0.49, 0.75, -1.02, -2.2, 1.09, -1.96, 6.0, 1.31, 2.01, -2.7, -2.94, -1.59, -3.31, -2.54, -1.75, -2.35, -1.41, -1.38, -1.75, -0.97, -0.16, -0.77, 0.38, 0.79, 1.61, 0.99, -1.2, -1.54, -0.41, 0.81, 0.2, -0.47, -0.56, -1.6174239503761216, 3.78, -0.79, -3.76, -0.63, -1.22, -1.22, -0.61, -0.48, -0.28, -0.07, 0.17, 0.0, -0.61, -0.64, -1.8, -0.35], ['383', 2.97, 0.5, -0.30877828437954125, -0.3, 2.11, 0.81, 0.9141152579598292, 1.4, 0.78, 3.04, 2.13, 2.56, 2.02, 2.69, 1.84, 2.87, 1.36, 2.71, 5.01, 1.28, 3.19, 1.71, 1.43, 1.53, 1.79, 1.1, 0.9, 0.42, -0.11, 0.55, -0.28, 0.73, -0.75, 0.57, 2.82, -0.83, 1.04, -0.4, -0.68, -0.58, 0.7, 0.77, 0.47, -0.53, 0.13, -0.7, 0.3, -1.17, 0.15, 2.39, -1.25, 0.61, -0.82, -1.1, -1.0, 0.91, 1.35, 0.72, 0.56, 1.0, 0.66, -0.17, 0.84, -0.64, 0.68, 2.94, -0.72, 1.15, -0.3, -0.58, -0.47, 1.66, 0.34, -0.83, 0.17, -1.3, 0.02, 2.26, -1.38, 0.48, -0.95, -1.23, -1.13, 0.89, 4.4, -4.38, 1.21669823838532, 1.01, -0.47, 0.85, 3.11, -0.55, 1.32, -0.12, -0.4, -0.3, 1.18, 0.17, -1.47, -0.16, 2.08, -1.55, 0.31, -1.12, -1.4, -1.3, 0.2, 0.2, 2.18, 1.04, 1.01, 1.11, 1.66, 1.33, 3.6, -0.08, 1.8, 0.35, 0.14598786341555264, 0.17, 1.26, 0.32, 2.24, -1.39, 0.46, -0.8442004503433073, -1.25, -0.8978225623582765, 1.75, 1.63, 0.0, 1.07, 2.23, 0.2, 0.14, -2.66, 2.66, 1.35, 0.6, 2.33, -3.399481751122728, -2.2, -1.09, 1.54, 0.39, 3.25, -3.22, -3.24, 1.06, -4.07, 2.09, 0.62, -0.31, 4.99, -6.6, -3.33, -4.95, 3.44, -1.88, -3.56, -1.74, -3.14, -3.41, -3.31, 3.19, 1.74, 2.0241925889236816, 0.43, 0.15, 0.25, -0.14, -1.3411214088935783, -1.7, -1.6, 0.82, 1.0084535464535467, 1.3, -0.28, -0.18, 1.192080034314057, 1.09, 1.27, -3.24, 1.11, 3.22, 1.63, 1.3, 1.59, 0.17278685149693168, 1.13, 1.2845528598385743, 0.7, 0.15, -0.06, 1.49, 2.15, 2.05, 2.82], ['384', 0.86, -0.19, -0.14877828437954127, 0.14, -0.8570209190089404, -0.24, -0.88, -0.49, -1.09, -0.05, 1.27, 0.92, 0.32, 0.63, 0.47, 0.65, 0.68, 0.27, -2.87, 1.63, -0.37, 0.01, 0.43, 0.48, -0.25, -0.52, -1.3, -0.34, -0.93, -0.63, -0.7221800287049088, -0.6, -0.58, -0.98, -4.08, 0.36, -1.62, -1.24, -0.7311203865609548, -0.77, -0.11, -2.3, -0.96, -0.59, -0.29, -0.44, -0.26, -0.24, -0.64, -3.75, 0.71, -1.28, -0.9, -0.49, -0.43, -0.29993715369432344, -0.11571428571428577, -0.45, -0.92, -0.37, 0.3, 0.15, 0.33, 0.36, -0.05, -3.18, 1.4339757335335068, -0.69, -0.31, 0.11, 0.16, -0.1, -0.68, -0.15, 0.03, 0.05, -0.35, -3.47, 1.0, -0.99, -0.61, -0.2, -0.14, -1.48, -1.43, 1.37, -0.53, 0.18, 0.2117857142857143, -0.2, -3.33, 1.15, -0.84, -0.47, -0.05, 0.01, -0.23, -0.7, 0.03, -0.38, -3.5, 0.97, -1.02, -0.64, -0.22, -0.17, -0.36, -0.58, -3.01, -0.5, -0.42, -0.5, -0.73, -0.41, -3.53, 0.95, -1.05, -0.67, -0.25, -0.2, -0.14, -0.32, -3.13, 1.36, -0.64, -0.26, 0.16, 0.21, -0.64, -0.66, 0.21, -0.7, -0.55, -0.13, -0.2, 1.67, -1.7, -0.84, -0.42, -1.2638364678879506, 3.26, 1.03, 0.49, 0.44, 0.03, -1.48, 1.4, 1.43, -0.49, 2.56, -0.98, -2.1, 1.03, -2.15, 5.05, 1.42, 2.24, -3.34, 2.9, 4.63, 2.57, 2.96, 3.4, 3.45, -1.51, -1.66, -1.97, -1.6, -1.18, -1.13, 0.38448979591836735, 0.38, 0.81, 0.86, -1.11, -1.25, -0.06, 0.42, 0.47, -0.48, -0.53, -0.52, 1.95, -2.07, -2.08, -0.46, -1.03, -0.48, 0.05, -0.3, -0.68, 0.2, 0.3, -0.35, -0.53, 0.79, -1.87, -0.36], ['385', -1.8, 0.18, 0.4112217156204588, -0.23, 0.67, -0.33, -1.7558847420401709, -0.42, -0.8, 0.13, 1.44, 1.02, 0.22, 0.88, 1.96, 0.19, 0.52, 0.15, -0.49, -1.35, 0.19, 0.4, 0.28, 0.15, -0.28, 0.43, -1.3, -0.41, -1.2, -0.55, 0.51, -1.23, -0.91, -1.27, -1.8992857142857142, -2.75, -1.23, -1.02, -1.14, -1.27, -1.05, -1.5650638007838267, -0.89, -0.79, -0.14, 0.93, -0.82, -0.5, -0.86, -1.49, -2.34, -0.82, -0.61, -0.73, -0.86, -0.5, 0.46, 3.03, -0.57, -0.09, 0.66, 1.74, -0.03, 0.3, -0.07, -0.7, -1.56, -0.03, 0.18, 0.06, -0.07, 0.48, -0.75, 1.07, -0.68, -0.36, -0.72, -1.35, -2.21, -0.2381462585034016, -0.47, -0.59, -0.72, -1.16, -0.57, 0.58, -1.8, -1.6519125667872352, -1.41, -1.77, -2.4, -3.24, -1.73, -1.53, -1.65, -1.77, -0.55, -0.06, 0.33, -0.04, -0.67, -1.53, 0.0, 0.21, 0.09, -0.04, 0.0, -0.06, 0.83, -0.28, 0.26, -0.81, -0.39, -0.37, -1.0, -1.86, -0.33, -0.12, -0.16401213658444735, -0.37, -0.05, -0.03, -0.64, -1.5, 0.04956235827664399, 0.25, 0.13, 0.0, 0.52, 0.72, -0.26396282112195957, -0.41, -1.27, 0.2480695494981211, 0.22, 4.17, -4.2, -2.11, 0.61, -1.28, -3.04, 0.55, 0.27, -0.83, 0.65, -0.86, 0.91, 0.8, -0.28, 6.2, -0.53, 2.29, -1.1, -1.22, -5.56, 0.72, 1.11, 2.94, 0.61, -0.86, 0.68, 0.89, 0.77, 0.64, -0.83, 1.49, 1.56, 1.77, 1.65, 1.52, -0.07, 0.21, 0.09, -0.04, -4.11, -5.19, -0.28, -0.12, -0.25, -0.25, -0.85, -2.56, -2.65, 0.54, 2.47, -0.27, 0.68, -0.08136255179902908, -0.13, -0.3599225974772193, -2.34, 0.93, 1.21, 0.38, -0.03, -0.72, 0.7030376647162363, -0.42], ['386', 2.39, -0.22, -0.30877828437954125, -0.07, 0.55, -0.45, 0.54, -0.63, -0.13, -0.17, -0.39, 0.29, 0.43, 0.57, -0.33, -0.42, 0.82, -0.22, -0.84, -1.48, -0.03, 0.9, 0.4, 0.31, -0.78, -1.08, 0.23, 0.68, 0.82, 0.96, 0.06, -0.02, 1.22, 0.18, -0.45, -1.1, 0.36, 1.29, 0.8, 0.7, 0.0, 0.67, -0.44979591836734695, 0.14, 0.28, -0.62, -0.7, 0.53, -0.5, -1.13, -1.76, -0.32, 0.61, 0.11, 0.02, -0.91, -0.77, -0.39, -0.35007142857142853, -0.59, 0.14, -0.76, -0.84, 0.39, -0.64, -1.26, -1.9, -0.46, 0.47, -0.03, -0.12, 0.05, -0.73, -0.9, -0.98, 0.25, -0.78, -1.4, -2.04, -0.4469183673469388, 0.33, -0.17, -0.20644035827487928, 0.47, -1.94, 1.89, 0.17, -0.08, 1.5899013605442176, 0.12, -0.51, -1.15, 0.3, 1.23, 0.74, 0.64, -2.8, 0.25, 1.24, 0.30533503401360546, -0.43, -1.07, 0.39, 1.32, 0.82, 0.73, -0.08, 0.3, -1.28, -0.37, -0.37, -0.47, -0.98, -1.03, -1.65, -2.28, -0.84, 0.08, -0.42, -0.51, -1.15, 0.05, -0.63, -1.27, 0.19, 1.12, 0.62, 0.52, -0.66, -0.49, 0.21603717887804044, -0.74, -8.4, -0.43, -0.47, 0.37, -0.41, -0.19, -2.62, -0.23, -2.62, 0.71, 0.39, 1.19, -0.37, -1.05, 1.15, 1.15, -0.38, 0.58, -0.63, 0.76, -0.4, -2.88, -3.76, 1.98, 2.94, 2.5771309523809522, 0.68, -0.65, 0.82, 1.75, 1.25, 1.16, -1.09, 1.34, 1.47, 2.42, 1.91, 1.82, -0.14, 0.93, 0.43, 0.34, -0.08, -0.04, -1.05, -0.49, -0.59, -0.35, -0.44, -0.56, -1.01, -1.07, 1.1314285714285712, -0.4327361894755667, -0.04, -0.56, -0.09, -0.97, 0.01, -0.23, -0.38, -0.61, -0.47, -1.1, 0.43, -0.17], ['387', -5.61, 0.62, -0.05877828437954126, -0.19, 0.49, 1.29, 1.0641152579598292, 0.8, 1.97, 1.2, -2.28, 0.2, -0.09, 0.47, 0.7, 3.42, 0.45, 1.18, 4.831481859410431, 0.3, 1.86, 0.13, -0.45, -0.2, 1.63, 1.52, 3.6026583949931124, 2.55, 2.25, 2.82, 3.05, 5.83, 2.8, 3.55, 7.27, 2.64, 4.24, 2.47, 1.87, 2.13, 1.03, 3.84, 1.0, -0.29, 0.27, 0.49, 3.21, 0.24, 0.97, 4.6, 0.09, 1.65, -0.08, -0.66, -0.41, -0.97, 0.99, 1.63, 1.66, 1.29, 0.56, 0.79, 3.51, 0.6185714285714285, 1.27, 4.91, 0.39, 1.95, 0.22, -0.37, -0.11, 0.9, 0.73, 0.23, 2.93, -0.02, 0.7, 4.32, -0.17, 1.8218537414965983, -0.34, -0.92, -0.67, 3.17, 4.35, -4.24, 0.5, 2.7, -0.25, 0.48, 4.09, -0.4, 1.15, -0.57, -1.1414761904761903, -0.9, -1.27, -2.14, -2.87, -2.16, 1.35, -3.01, -1.51, -3.18, -3.74, -3.5, 0.471141873999017, -2.14, 0.73, 1.31, 1.34, 1.18, 0.75, 0.73, 4.35, -0.15, 1.4, -0.32, -0.9, -0.65, 1.07, 0.07307674813036727, 3.59, -0.87, 0.67, -1.04, -1.62, -1.37, 1.19, 0.71, -0.27, 0.88, -2.63, 0.87, -0.11, -2.66, 2.63, 1.34, 0.37, 0.48, -1.59, -2.67, -1.31, -2.84, 0.71, 3.84, -3.87, -3.96, 1.31, -4.03, 2.62, 2.13, -1.06, 2.37, -6.39, -1.5, -2.23, 1.85, -3.44, -4.31, -2.82, -4.47, -5.03, -4.624238287156354, 3.99, 0.9, 1.56, -0.17, -0.75, -0.5, -0.64, -1.7, -2.27, -2.02, 1.94, 2.28, 1.08, -0.58, -0.33, 1.3, 1.27, 0.83, -3.27, 0.34, 3.2421428571428574, 1.15, 1.56, 1.67, 0.25, 1.6200774025227807, 1.36, 0.82, 1.49, 0.67, 1.41, 0.6502406343656345, 2.12, 0.83], ['388', -2.27, -0.98, -0.04, -0.23, -0.32, -0.86, -1.1658847420401708, -1.29, -1.96, -1.17, 1.37, 0.12, -1.41, 0.64, 0.05, -0.9, 1.07, -0.95, -0.63, 0.07, -1.932664517912641, 0.53, 0.25, -0.14, -0.69, -2.23, -2.4673416050068875, -1.2294545454545454, -2.74, -0.72, -1.242180028704909, -2.23, -0.29, -2.29, -1.97, -1.28, -3.29, -0.83, -1.1, -1.49, -0.43, -4.075063800783826, -1.29, -1.53, 0.52, -0.07, -1.02, 0.95, -1.07, -0.75, -0.05, -2.09, 0.41, 0.14, -0.26, -0.53, -0.07, -0.55, -1.82, 0.24, 2.08, 1.48, 0.52, 2.52, 0.47, 0.8, 1.5, -0.57, 1.97, 1.69, 1.29, -1.07, -1.8, -0.59, -1.53, 0.43, -1.58, -1.26, -0.57, -2.59, -0.11, -0.38, -0.78, -2.67, -4.46, 4.47, -1.18330176161468, -0.95, 1.02, -1.0, -0.68, 0.02, -2.02, 0.48, 0.21, -0.19, -2.62, -0.28, 1.99, -0.05, 0.27, 0.97, -1.08, 1.44, 1.16, 0.76, -0.42, -0.1506317967746538, -1.86427628811696, -1.35, -1.26, -1.53, -2.22, -1.9986530612244897, -1.68, -1.0, -3.01, -0.54, -0.81, -1.2, -1.75, -0.22, 0.33, 1.03, -1.03, 1.49, 1.22, 0.82, -1.48, -1.54, -0.39, -2.09, -5.09, -0.48, -0.39, 3.58, -3.59, -1.81, -1.48, -1.22, 2.45, 2.69, 1.37, -1.15, -0.56, -4.28, 4.24, 4.02, -1.34, 5.37, -2.69, 1.1183906549799407, -0.48, -6.64, 7.48, 4.43, 6.57, -2.44, -0.55, 0.7, -1.35, 1.16, 0.89, 0.49, -3.9891948051948054, -1.24, -2.04, 0.46, 0.19, -0.21, 0.82, 2.55, 2.27, 1.87, -1.97, -2.35, -1.69, -0.27, -0.67, -1.32, -1.46, -1.21, 3.91, -1.48, -3.8, -1.67, -1.26, -1.42, -0.4, -1.94, -1.79, -0.64, -0.22, -1.14, -1.03, -2.62, -1.94, -2.0569832262926027], ['389', 1.84, 0.44, 0.44, -0.14, 1.09, 1.52, 1.19, 1.0, 2.52, 1.21, -2.95, 0.24, -0.72, 0.88, -0.42, -0.32, -0.89, 0.45, 0.62, -0.77, 1.77, 0.02, -0.11, 0.27, 1.99, 2.28, 4.29, 3.408468508265777, 2.3, 3.95, 2.61, 2.7133503401360546, 2.12, 3.51, 3.69, 2.25, 4.86, 3.07, 2.92, 3.32, 0.12, 5.16, 0.97, -0.96, 0.64, -0.65, -0.56, -1.13, 0.21, 0.39, -1.0, 1.53, -0.21, -0.35, 0.03, 0.66, 0.74, -0.31, 2.24, 1.94, 1.61, 0.31, 0.4, -0.17, 1.18, 1.36, -0.05, 2.51, 0.75, 0.61, 1.0, 0.13, 0.32, -0.8697721088435375, -1.2, -1.76, -0.43, -0.25, -1.64, 0.88, -0.85, -0.99, -0.6, 4.6, 4.01, -4.2, 1.63, 0.09, -0.48, 0.87, 1.04, -0.36, 2.19, 0.44, 0.3, 0.69, 2.4, 1.54, -0.57, 0.78, 0.95, -0.44, 2.1, 0.35, 0.21, 0.6, 0.95, 1.53, 1.04, 1.52, 1.51, 1.61, 2.12, 1.35, 1.53, 0.12, 2.68, 0.92, 0.78, 1.17, 1.19, 0.75, 0.17, -1.21, 1.31, -0.43, -0.56, -0.18, 1.8, 2.11, -0.02, 2.17, 4.89, 0.3580695494981211, -0.14, -3.28, 3.19, 1.63, 1.09, 1.56, -3.71, -3.05, -1.5385714285714287, 0.93, 1.53, 4.61, -4.680000000000001, -4.65, 1.5, -4.78, 3.03, 2.99, -1.47, 6.22, -5.952619047619048, -4.19, -6.19, 3.59, 0.58, -1.39, 1.14, -0.6, -0.73, -0.35, 4.52, 1.99, 2.56, 0.8, 0.66, 1.05, -0.10349829931972804, -1.72, -1.85, -1.4685714285714286, 2.49, 2.96, 1.18, -0.14, 0.25, 1.5, 1.62, 1.18, -2.94, 1.57, 3.11, 1.81, 2.09, 1.32, 0.39, 2.26, 1.87, 1.07, 1.47, 1.03, 0.93, 2.53, 2.46, -0.23], ['390', 3.11, 0.53, 0.06, -0.28, 0.22, 1.0, 1.14, 2.33, 1.86, 3.54, 0.84, 2.68, 1.6, 0.84, 1.47, 3.42, 1.44, 3.48, 5.61, 4.17, 4.08, 2.72, 1.51, 3.06, 1.5485936610075264, 1.03, 2.67, 1.822860544217687, 0.75, 0.0, 0.62, 2.56, 0.6, 2.62, 4.73, 3.3, 3.21, 1.86, 0.66, 2.2, 1.3, 2.4849361992161736, 0.840204081632653, -1.05, -1.78, -1.17, 0.72, -1.2, 0.79, 2.86, 1.46, 1.37, 0.04, -1.13, 0.38, 1.35, 1.36, 1.88, 2.07, 1.91, -0.74, -0.12, 1.79, -0.15, 1.86, 3.95, 2.53, 2.44, 1.1, -0.08, 1.44, 1.88, 2.67, 0.62, 2.55, 0.59, 2.62, 4.72, 3.3, 3.2, 1.86, 0.66, 2.2535596417251207, 2.61, 5.49, -5.48, 2.04, 1.92, -0.03, 1.98, 4.08, 2.66, 2.57, 1.23, 0.04, 1.57, 0.76, 0.11, -1.91, 0.06, 2.12, 0.72, 0.64, -0.68, -1.84, -0.35, -0.1, 0.12235688121402405, 2.22, 1.21, 1.43, 1.13, 2.06, 2.01, 4.11, 2.69, 2.59, 1.26, 0.07, 1.59, 0.55, 0.10307674813036727, 2.05, 0.66, 0.57, -0.74, -1.9, -0.16782256235827656, 1.99, 2.13, -0.03, 1.87, 2.11, 0.08, 0.31, -2.04, 2.03, 1.01, 0.22, 3.2202597402597406, 1.24, -2.5, -1.22, 1.58, 0.85, 3.88, -3.81, -3.66, 1.22, -3.07, 2.45, 1.94, -1.25, 6.23, -6.44, -4.17, -6.13, -1.27, -1.96, -1.36, -1.45, -2.74, -3.88, -2.41, 3.61, -0.61, -0.09, -1.39, -2.55, -1.06, -0.52, -1.3, -2.46, -0.98, 1.86, 2.36, 0.79, -1.18, 0.40224875531501636, 1.25, 1.37, 2.5, -3.32, 3.05, 3.17, 1.53, 0.88, 1.99, 1.53, 1.49, 1.22, 1.2652979520479524, 0.5, 1.29, 0.46, 2.4, 0.31, 1.09], ['391', -1.84, 0.92, -0.028778284379541254, -0.06, -0.5, 0.13, -0.21, 0.04, -0.4, -0.15, 1.0503184712113285, 0.1, -0.88, -1.38, -0.42, 0.52, -0.63, -0.08, 0.85, -0.39, -0.61, -0.61, -0.3, -0.96, 0.21, -0.19, -0.98, -0.73, -1.7, -2.2, -1.25, -0.32, -1.45, -0.91, 0.01, -1.21, -1.43, -1.44, -1.12, -1.78, -0.81, -0.20506380078382658, -0.25, -0.98, -1.48, -0.44918497042472344, 0.41, -0.73, -0.18, 0.74, -0.49, -0.71, -0.71, -0.4, -1.06, 0.33, 0.14, -0.36, -0.55, 0.74, -0.5, 0.46, 1.41, 0.25, 0.81, 1.74, 0.5, 0.28, 0.27, 0.59, -0.08, -1.15, 1.25, 0.97, 1.92, 0.76, 1.32, 2.26, 1.01, 0.78, 0.78, 1.1, 0.43, -0.65, 0.65, -0.72, 0.27, 0.94, -0.21, 0.35, 1.28, 0.04, -0.18, -0.19, 0.13, -0.54, -1.53, -0.66, -1.14, -0.59, 0.33, -0.9, -1.12, -1.12, -0.81, -1.46, 0.02, -0.67, 1.13572371188304, 0.15, 0.26517906963433996, 0.26, 0.5518094764861292, 0.56, 1.49, 0.25, 0.03, 0.02, 0.34, -0.33, 0.35, -0.07, 0.92, -0.31, -0.53, -0.54, -0.22, -0.88, 0.08, -0.03, -0.29, 0.67, -4.6, 0.28, 0.17, -0.14, 0.08, 0.06, 1.06, 0.23, -0.51, -0.3, -0.21, -0.87, 0.31, 0.53, -0.51, -0.6, 0.14, -0.16, 0.52, 1.08, -0.54, 1.52, -3.48, -1.09, -1.38, 0.5, -0.99, -1.22, -1.44, -1.45, -1.13, -1.79, 0.52, 0.24, -0.22, -0.23, 0.09, -0.57, 0.906501700680272, -0.01, 0.31, -0.35, -0.45, -0.57, 0.47, 0.32, -0.35, 0.19, 0.26, 0.14, -1.18, 1.3301996269574994, 0.97, 0.0, 0.6, 0.15, -0.66, 0.72, 0.06, -0.17, 0.23, 0.05, 0.81, 0.93, 1.38, 1.62], ['392', 5.9, 0.48, -0.05, 0.0, 1.3129790809910595, 0.6, 1.67, 1.21, 1.39, 0.9253571428571429, -1.41, -0.55, -0.61, 0.75, -0.79, 0.23, 1.15, 0.91, 0.85, -1.66, 0.91, -0.13, -0.64, 2.76, -0.44, 0.35, 2.3, 0.87, 0.81, 2.19, 0.63, 1.66, 2.6, 2.36, 2.29, -0.25, 2.35, 1.3, 0.78, 4.273841723197839, 1.14, 3.1, 1.619303232481804, -0.06, 1.3, -0.24, 0.78, 1.71, 1.47, 1.4, -1.12, 1.47, 0.42, -0.1, 3.33, 0.98, 0.18, 0.91, 0.6, 1.5592452470658775, 1.37, -0.18, 0.85, 1.78, 1.53, 1.47, -1.05, 1.53, 0.48, -0.03, 3.39, 2.7, 0.11, -1.53, -0.51, 0.4, 0.17, 0.1, -2.39, 0.16, -0.87, -1.38, 2.0, 2.6189098639455786, 3.29, -3.37, 1.66, 1.03, 1.96, 1.72, 1.65, -0.87, 1.71, 0.67, 0.15, 3.58, 0.86, 0.63, 0.92, 0.68, 0.62, -1.88, 0.68, -0.36, -0.87, 2.52, -0.02, 0.64, 1.21, 0.03, 0.65, -0.69, -0.29, -0.24, -0.3, -2.78, -0.24, -1.27, -1.78, 1.59, 0.84, -0.05, -0.06, -2.55, 0.0, -1.04, -1.54, 1.83, 1.81, 2.35, 0.17, -0.38, 1.4, 0.56, 0.07, 3.24, -3.37, -1.65, 0.45, 3.6, -5.08, -0.12, -0.04, 2.88, 0.63, -0.16, 0.18, -0.2, 0.05, 4.96, 0.15, -2.041609345020059, 1.08, -0.95, 0.82, 0.49, 0.76, 5.11, 0.01, -2.49, 0.06, -0.97, -1.48, 1.9, 0.12, 2.56, 2.61, 1.55, 1.03, 4.49, -0.05, -1.03, -1.54, 1.83, 1.44, 2.08, 0.99, -0.51, 2.89, 0.0, -0.12, 1.12, 0.32, 0.0, -0.17, -0.36, 0.35, 1.51, 3.43, 0.54, -0.82, 0.34, 1.14, 0.28, -1.85, 0.17, -1.74, -2.2], ['393', 1.45, 0.34, 0.09122171562045875, -0.22, 0.0, -0.15, 0.45411525795982915, 0.67, 0.77, -0.05, -0.61, -0.7, -0.39, -0.47, -1.36, -0.21, -0.36, -0.2, -0.86, 0.06, 0.48733548208735894, 0.53, -0.85, -0.47, 1.51, 0.94, 0.56, -0.1, 0.22, 0.14, -0.7021800287049088, 0.4, 0.24, 0.41, -0.25, 0.67, 1.07, 1.14, -0.25, 0.18384172319783917, 0.27, 1.7949361992161734, 0.66, 0.32, 0.24, -0.66, 0.5, 0.34, 0.51, -0.15, 0.77, 1.17, 1.24, -0.15, 0.24, 0.8, 0.3, 0.15, 0.73, 0.34, -0.08, -0.98, 0.18, 0.02, 0.19, -0.47, 0.45, 0.85, 0.92, -0.47, -0.08, 0.5, 0.42, -0.9, 0.26, 0.11, 0.27, -0.39, 0.54, 0.93, 1.0, -0.39, 0.01, 0.98, 2.05, -2.04, 1.33, 1.17, 1.01, 1.18, 0.51, 1.45, 1.84, 1.92, 0.52, 0.91, 0.34, 0.16, -0.15, 0.01, -0.6484761904761905, 0.28, 0.67, 0.74, -0.64, -0.25, 0.23, 0.18, 2.45, 0.21, 0.61, -0.22, 0.31, 0.16, -0.49, 0.43, 0.82, 0.9, -0.49, -0.1, -0.29, 0.15, -0.66, 0.27, 0.66, 0.73, -0.65, -0.26, 1.01, 0.9, -0.04, 0.4, 0.97, 0.03, 0.0, 0.53, -0.5275376766091052, -0.26, 1.4240662734668152, 1.3561635321120495, 0.22, -0.45, -0.18, 0.78, 0.553079789868779, 0.7, -0.66, -0.63, 0.2, 0.78, 0.46, 1.79, -0.89, 0.92, 0.0, -0.67, -0.87, -0.26, 0.81, 0.93, 1.32, 1.4, 0.0, 0.4, 0.64, -0.12, 0.39, 0.46, -0.92, -0.53, -0.51, 0.07, -1.3, -0.92, 0.77, 0.76, -0.58, -1.37, -0.99, 0.23, 0.28439630127529086, 0.66, -0.66, 1.5, 0.77, 0.5272638105244333, 0.83, 0.81, 0.46278685149693166, 0.36, -0.75, 0.37, 1.35, -0.07, 0.49595752702381396, 1.12, 0.87, 0.0], ['394', -7.48, -0.71, -0.2787782843795412, 0.21, -1.78, -1.37, 0.07411525795982916, -3.92, -4.12, -1.09, 3.94, 0.71, 1.85, 3.53, 2.6342857142857143, 1.25, 1.13, -0.8, -2.76, 2.02, -1.92, 0.32, 0.5, 0.875116627420199, -4.96, -3.770628585411108, -4.84, -3.11, -2.01, -0.39, -1.26, -2.59, -2.7, -4.56, -6.45, -1.8286428571428572, -5.64, -3.48, -3.31, -3.09, -4.55, -3.89, -1.789795918367347, 1.13, 2.81, 1.9, 0.54, 0.42, -1.5, -3.45, 1.3, -2.62, -0.39, -0.21, 0.02, -2.46, -4.15, -2.54, -4.42, -2.89, 1.66, 0.77, -0.59, -0.7, -2.6, -4.53, 0.17, -3.7, -1.5, -1.33, -1.09, -2.3, -4.47, -0.88, -2.21, -2.32, -4.19, -6.08, -1.46, -5.27, -3.1, -2.94, -2.71, -4.71, -4.66, 4.67, -3.63, -1.34, -1.45, -3.34, -5.25, -0.59, -4.43, -2.25, -2.08, -1.85, -4.06, -2.32, -0.12, -2.03, -3.97, 0.76, -3.14, -0.92, -0.75, -0.51, -0.38, -2.35, -2.65, -1.5684018193170985, -1.51, -1.86, -2.2, -1.92, -3.85, 0.88, -3.02, -0.8, -0.63, -0.4, -1.41, -0.29, -1.98, 2.84, -1.13, 1.13, 1.31, 1.55, -1.63, -1.91, 0.35, -2.25, -11.87, -0.16, 0.06, 3.55, -3.6, -1.8, -0.44, -3.36, 6.23, 3.17, 1.62, -3.89, -0.67, -4.98, 5.03, 4.89, -1.64, 5.4, -3.29, -1.47, 0.68, -6.52, 4.45, 4.23, 6.41, -6.4, 1.72, 4.92, 0.86, 3.17, 3.35, 3.6, -4.91, -3.05, -3.87, -1.67, -1.49, -1.26, 0.85, 2.29, 2.47, 2.71, -1.91, -1.98, -1.41, 0.18, 0.41, -1.59, -1.65, -2.73, 6.5, -3.99, -7.12, -2.7, -3.3, -1.58, 0.24, -1.53, -1.63, -0.73, -0.55, -0.99, -1.81, -4.28, -4.46, -2.19], ['395', 0.18, -0.23, -0.10877828437954125, 0.17, -0.48, -0.31, 0.05, -1.23, -0.73, -3.26, -2.35, -3.58, -2.19, -2.58, -1.25, -3.68, -2.37, -3.17, -5.53, -1.98, -3.56, -2.3, -2.33, -2.14, -2.29, -0.5706285854111081, -0.93, -1.26, 0.16, -0.23, 1.13, -1.37, -0.02, -0.84, -3.25, 0.38, -1.24, 0.05, 0.02, 0.22, -0.44, -1.7891024373941227, 0.33, 1.44, 1.04, 2.42, -0.11, 1.26, 0.43, -2.02, 1.66, 0.02, 1.33, 1.3, 1.5, -0.14, -0.21, -1.06, 0.06, -1.09, -0.39, 0.97, -1.52, -0.18, -1.0, -3.41, 0.22, -1.4, -0.11, -0.14, 0.06, -0.96, -0.7, 1.36, -1.14, 0.21, -0.61, -3.03, 0.61, -1.01, 0.28, 0.26, 0.45, -0.9373265306122449, -2.6, 2.55, -2.04, -2.47, -1.13, -1.95, -4.33, -0.74, -2.34, -1.06, -1.09, -0.9, 0.27, 0.44, 1.36, 0.53, -1.91, 1.77, 0.13, 1.44, 1.41, 1.61, -0.16, 0.49, 0.13, -0.65, -0.68, -0.67, -0.91, -0.82, -3.23, 0.4, -1.22, 0.07, 0.04, 0.2985846838830657, -1.0, -0.1, -2.43, 1.23, -0.4, 0.9, 0.87, 1.07, -0.3, 0.0, 0.23, -0.7, 1.1, -0.03, 0.0, 1.59, -1.57, -0.78, -1.27, -1.79, 2.63, 1.3, 0.68, 0.07, -0.07, -1.86, 1.89, 1.93, -0.65, 2.32, -1.31, -2.04, 0.98, -2.68, 2.65, 1.71, 2.45, -2.56, 2.4, 3.75, 2.08, 3.42, 3.39, 3.59, -2.01, -1.31, -1.61, -0.33, -0.35, -0.16, 0.31, 1.31, 1.28, 1.48, -0.65, -0.76, -0.98, -0.03, 0.17, -0.65, -0.7, -1.26, 3.75, -0.45, -3.77, -1.01, -1.67, -0.96, 0.19, -0.58, -0.63, 0.44, -0.05, -0.27, -1.15, -2.24, -2.27, -1.46], ['396', 2.42, 0.18, 0.2, 0.13, -0.42, 0.55, 0.89, 1.6, 1.3, 0.59, -1.22, -0.23, -1.22, -1.29, -0.31, 0.23, -0.67, 0.28, 0.95, 1.01, 1.297335482087359, 0.01, -0.64, -0.59, 1.16, 0.869371414588892, 1.83, 1.01, 0.0, -0.07, 0.92, 1.47, 0.55, 1.51, 2.2, 2.25, 2.51, 1.25, 0.59, 0.64, 1.13, 1.4449361992161733, 0.82, -1.0, -1.06, -0.08, 0.46, -0.45, 0.5, 1.18, 1.24, 1.49, 0.24, -0.42, -0.36, 1.42, 1.33, 0.82, 1.17, 1.83, -0.07, 0.92, 1.47, 0.55, 1.6126050661400617, 2.4896933106575965, 2.25, 2.6734211542425825, 1.25, 0.58, 0.64, 1.07, 1.9, 0.99, 1.54, 0.62, 1.58, 2.27, 2.33, 2.58, 1.32, 0.66, 0.71, 1.76, 3.22, -3.22, 0.9, 0.54, -0.37, 0.59, 1.26, 1.32, 1.57, 0.32, -0.33, -0.28, 0.17, 0.36, -0.9, 0.04, 0.72, 0.77, 1.02, -0.22, -0.87, -0.82, 0.18, 0.31, 3.62, 0.72, 0.78, 0.82, 1.3418094764861292, 0.95, 1.64, 1.69, 1.95, 0.69, 0.03, 0.08, 0.55, 0.31, 0.68, 0.73, 0.98, -0.26, -0.91, -0.86, 0.66, 0.61, 0.0, 1.19, 0.56, 0.43, 0.21, -2.16, 2.17, 1.09, 0.31, 1.86, 0.81, -1.43, -0.73, 1.27, -0.01, 2.38, -2.27, -2.16, 0.73, -3.26, 1.47, 1.2583906549799408, -0.57, 3.79, -5.86, -2.51, -3.69, -0.83, -0.36, 0.05, 0.3, -0.93, -1.58, -1.53, 2.2108051948051948, -0.41, 0.3941925889236815, -0.98, -1.63, -1.58, -0.66, -1.23, -1.88, -1.83, 1.45, 1.43, 0.58, -0.65, -0.6, 0.71, 0.8, 1.61, -2.97, 2.98, 2.99, 0.61, 0.94, 1.24, 0.05, 0.56, 1.11, -0.06, -0.41, 0.14, 1.265957527023814, 1.43, 1.26, 1.58], ['397', 2.67, -0.12, 0.1, 0.21214285714285727, -0.72, -0.09, -0.25, -0.79, -0.34, -0.21, 0.06, 0.26, 0.22, 0.99, 0.51, -0.68, 0.88, -0.24, -0.36, 2.21, 0.07, 0.5130748299319728, -0.01, 0.16, -0.78, -0.5, -0.27, 0.2, 0.16, 0.93, 0.45, -0.74, 0.82, -0.3, -0.42, 2.15, 0.01, 0.45, -0.07, 0.1, -0.22, -0.57, -0.47, -0.03, 0.73, 0.26, -0.94, 0.63, -0.49, -0.61, 1.9507142857142856, -0.19, 0.25, -0.27, -0.1, 0.0, 0.06, -0.47, -0.23, -0.43, 0.76, 0.29, -0.9, 0.66, -0.46, -0.58, 1.98, -0.16, 0.29, -0.24, -0.07, -0.46, -1.1885714285714286, -0.47, -1.66, -0.1, -1.2067857142857144, -1.33, 1.21, -0.91, -0.47, -0.99, -0.82, -0.36, -0.87, 0.86, -0.72, -1.19, 0.37, -0.75, -0.87, 1.69, -0.44, 0.0, -0.52, -0.35, -0.54, 0.47, 1.58, 0.45, 0.33, 2.92, 0.76, 1.2, 0.68, 0.85, -0.09, 0.45, -0.64, -0.28, -0.28, -0.54, -1.09, -1.11, -1.23, 1.32, -0.81, -0.37, -0.89, -0.72, -0.82, 0.02, -0.12, 2.46, 0.31, 0.75, 0.23, 0.4, -0.68, -1.56, -0.45, -0.86, -1.18, -0.18, -0.19, 1.61, -1.65, -0.81, -1.28, -0.75, 4.6, 0.54, 0.39, 1.5, 0.16, -1.01, 1.05, 0.77, -0.27, 2.4, -0.55, 2.32, -1.13, -3.07, 6.27, 2.2142857142857144, 3.2314285714285713, -4.82, 0.15, 2.58, 0.43, 0.87, 0.35128571428571426, 0.52, -0.74, -2.37, -2.1, -1.67, -2.18, -2.01, -0.28, 0.44, 0.15285714285714286, 0.09, -0.35, -0.41, -0.72, -0.32676622187336457, -0.35, -0.47, -0.41, -0.75, 3.197142857142857, -0.56, -3.25, -0.73, 0.03, -0.2, 0.17, -0.79, -0.61, -0.16, 0.04, 0.12, -0.37, -2.03, -1.05, -1.02], ['398', 1.09, 0.19, 0.09122171562045875, -0.45, 1.59, 1.04, 1.03, 1.09, 0.87, 1.07, -0.17, 0.18, -0.36, -0.77, 0.69, 0.92, -0.22, 0.72, -0.49, -0.21, 1.42, 0.49, 0.74, -0.51, 1.59, 1.41, 1.2826583949931125, 0.35, -0.19, -0.6, 0.87, 1.1, -0.05, 0.89, -0.32, -0.04, 1.5907606837606838, 0.67, 0.91, -0.2961582768021609, 0.5, 1.21, 0.89, -0.54, -0.95, 0.51, 0.74, -0.4, 0.54, -0.67, -0.39, 1.24, 0.31, 0.56, -0.69, 1.28, 0.45, 0.14, 0.88, 1.44, -0.41, 1.06, 1.29, 0.14, 1.08, -0.14, 0.15, 1.78, 0.86, 1.1, -0.15, 0.6, 1.86, 1.48, 1.71, 0.56, 1.5, 0.28, 0.56, 2.21, 1.27, 1.52, 0.26, 1.23, 1.16, -1.16, 0.38, 0.23, -0.91, 0.02, -1.18, -0.9, 0.72, -0.2, 0.04, -1.19, 0.93, 0.15, -1.13, -0.2, -1.4, -1.13, 0.49, -0.42, -0.18, -1.42, 0.32, 0.21, 1.26, 1.08, 0.86517906963434, 1.5356735186500319, 1.3, 0.94, -0.28, 0.01, 1.64, 0.72, 0.96, -0.29, 0.61, 0.35, -1.2, -0.92, 0.8786030199958773, -0.22, 0.02, -1.22, 0.17, 0.42, -0.66, 1.45, 2.0, 0.54, 0.27, -2.58, 2.5324623233908947, 1.28, 0.13, 1.6902597402597401, -2.74, -2.16, -1.09, 0.49, 0.49, 3.41, -3.4, -3.28, 1.133290804863853, -3.91, 2.2398783572413152, 1.49, -0.74, 3.93, -6.22, -2.63, -3.89, 2.61, 1.58, 0.28480952380952385, 1.92, 0.99, 1.24, -0.01, 3.32, 1.29, 1.64, 0.71, 0.95, -0.3, -0.34, -0.91, -0.67, -1.9, 1.1101351386708531, 0.98, 0.58, 0.24, -1.0, 1.12, 1.18, 1.0825760496238783, -3.15, 1.04, 3.1, 1.32, 2.34, 0.34, -1.24, 1.31, 1.0, 0.1, 0.48, 1.49, 1.59, 2.13, 2.67, 1.51], ['399', -4.36, 1.46, 0.04, -0.16, 0.33, 0.82, 1.44, 0.02, -0.07, 0.5, -0.56, 0.23, -0.62, 0.16, 0.13, 2.28, -0.82, 0.43, -0.88, 0.06, 0.86, -0.1, -0.54, -0.65, -3.11, -1.0, 1.07, 0.8005454545454546, -0.05, 0.73, 0.7, 2.86, -0.25, 1.0, 0.12570238095238095, 0.63, 1.43, 0.46, 0.03, -0.08, -0.88, 0.69, 0.26, -0.85, -0.07, -0.1, 2.04, -1.05, 0.2, -1.11, -0.17, 0.62, -0.34, -0.77, -0.88, -0.03, -2.23, -2.04, -0.53, 1.12, 0.78, 0.75, 2.91, -0.2, 1.1526050661400618, -0.27, 0.68, 1.48, 0.51, 0.08, -0.03, -0.26, 0.33, -0.04, 2.11, -0.98, 0.27, -1.04, -0.1, 0.69, -0.27, -0.7, -0.81, 0.82, 2.82, -2.9, 0.37, 2.15, -0.94, 0.3, -1.01, -0.06832539682539683, 0.73, -0.23, -0.66, -0.78, -2.15, -1.74, -3.03, -1.8, -3.09, -2.17, -1.39, -2.33, -2.75, -2.86, 0.09, -1.76, 1.95, 0.96, 0.89, 1.08, 1.32, 1.26, -0.07, 0.88, 1.69, 0.72, 0.28, 0.17, 0.53, 0.06, -1.31, -0.37, 0.42, -0.54, -0.97, -1.08, 1.3, 1.14, -0.25, 1.27, -6.37, 0.11, 0.04, -2.76, 2.81, 1.428810171007621, 0.28, 1.29, -1.04, -1.93, -0.97, -2.21, 0.46, 2.75, -2.79, -2.89, 0.97, -4.26, 1.94, 2.37, -1.18, 3.96, -6.51, -2.62, -3.96, 1.0, 1.39, 0.95, 1.75, 0.78, 0.6696385796742939, 0.23, 2.89, 0.44, 0.8, -0.16, -0.6, -0.71, -0.36, -0.96, -1.38, -1.49, 1.032795351473923, 1.01, 0.6, -0.43, -0.54, 0.93, 1.02, 0.49, -3.11, 1.84, 3.11, 1.0, 1.56, 1.04, -0.11, 1.11, 1.2, 0.08, 0.7316666666666667, 0.8, 1.15, 1.38, 2.29, 1.24], ['400', -4.13, 1.15, 0.32122171562045876, -0.34, 0.3, 1.82, 1.414115257959829, 2.64, 1.88, 3.32, 0.89, 2.31, 1.67, 0.46, 0.85, 5.34, -0.42, 2.25, 5.46, 1.07, 3.28, 1.08, 0.11, 1.06, 2.34, 1.6993714145888918, 2.41, 1.41, 0.77, -0.43, -0.04, 4.41, -1.3, 1.34, 4.53, 0.18, 2.434453670078569, 0.19, -0.77, 0.16, 1.77, 2.1649361992161733, 0.99, -0.63, -1.81, -1.42, 2.96, -2.67, -0.06, 3.08, -1.21, 0.94, -1.2, -2.15, -1.23, 0.5, 1.6, 2.05, 2.16, 1.63, -1.19, -0.8, 3.62, -2.05, 0.57, 3.74, -0.59, 1.58, -0.57, -1.53, -0.6, 3.6, 2.85, 0.39, 4.86, -0.88, 1.78, 4.98, 0.61, 2.8, 0.62, -0.34, 0.6, 2.28, 9.31, -9.26, 2.4508709226619945, 4.45, -1.27, 1.38, 4.57, 0.21, 2.4, 0.23, -0.74, 0.2, -0.7, -1.92, -5.47, -2.94, 0.12, -4.06, -1.96, -4.04, -4.97, -4.07, 0.95, -1.93, 3.47, 2.3, 2.62, 2.255673518650032, 3.831809476486129, 2.68, 5.91, 1.5, 3.71, 1.51, 0.54, 1.49, 2.09, 1.06, 3.15, -1.15, 1.01, -1.14, -2.09, -1.16, 3.21, 3.67, 0.22, 3.15, -1.55, 1.18, 0.87, -4.63, 4.67, 2.37, 1.96, 3.13, -4.41, -4.61, -2.34, -2.15, 1.86, 7.12, -7.23, -6.76, 2.3, -7.0, 4.59, 2.74, -1.33, 11.35, -10.33, -7.49, -11.18, 4.46, -2.03, -4.17, -2.08, -4.16, -5.08, -4.18, 6.81, 2.23, 2.18, 0.01, -0.95, -0.01, 0.05, -2.12, -3.06, -2.15, 2.0601351386708533, 2.48, 2.22, -0.96, -0.03, 2.26, 2.47, 2.74, -5.19, 3.7, 5.19, 2.3, 2.08, 3.21, 0.94, 2.55, 2.14, 1.56, 1.72, 2.29, 2.325957527023814, 2.74, 3.47, 2.97], ['401', -1.88, 0.0, -0.07877828437954125, 0.12, -0.9, 0.19, 0.69, -0.06, 0.31, -0.17, 0.37, -1.02, 0.19, 0.27, -0.41, -0.85, 0.28, 0.19, 1.59, -0.07, -0.03, -0.81, -0.24, -0.31, 0.17, 0.16937141458889196, -0.54, -1.39, -0.18, -0.1, -0.78, -1.22, -0.1, -0.18, 1.21, -0.44, -0.4, -1.18, -0.61, -0.68, -0.13, -1.07, 0.860204081632653, 1.22, 1.31, 0.61, 0.17, 1.31, 1.23, 2.64, 0.96, 1.0, 0.22, 0.78, 0.72, -0.4376426685347185, -0.25, 0.08, 0.42, -0.36, 0.08, -0.6, -1.04, 0.09, 0.0, 1.4, -0.25, -0.22, -1.0, -0.43, -0.5, -0.41, -0.44, -0.68, -1.12, 0.0, -0.08, 1.32, -0.34, -0.3, -1.08, -0.52, -0.58, -0.3, 0.65, -0.65, 0.25, -0.44, 0.69, 0.61, 2.01, 0.35, 0.38, -0.4, 0.17, 0.11, -0.02, 0.69, 1.14, 1.05, 2.47, 0.79, 0.83, 0.04, 0.61, 0.55, -0.25, 0.71, 0.19572371188304005, -0.14, 0.0, -0.41, -0.44, -0.08, 1.31, -0.34, -0.31, -1.0196949805527125, -0.52, -0.58, 0.53, -0.36, 1.4, -0.26, -0.22, -1.0, -0.44, -0.5, -0.08, -0.13, 0.38, -0.57, 0.03, -0.19, -0.35, 0.52, -0.59, -0.2411898289923789, -0.08, 0.28, 0.4205182488772715, 0.31, 0.19, -0.94, -0.15, -0.6, 0.67, 0.49, -0.15, 0.94, -0.32, -0.2, 0.08, -1.37, 7.1, 0.9, 1.41, -0.35, -1.73, -1.63, -1.6, -2.36, -1.81, -1.87, -0.49, -0.1, 0.03, -0.74, -0.18, -0.24, -0.14, -0.78, -0.21, -0.28, 0.19, 0.07, 0.64, 0.57, 0.5, -0.21, -0.21, 0.12, 3.45, 0.09019962695749935, -3.36, -0.46, -1.1488174603174601, 0.08, -0.06, -0.68, -0.23, -0.09, -0.28, 0.27, 0.14, -1.15, -1.9884047619047618, 0.15], ['402', 2.15, 0.84, 0.69, -0.07, 0.87, 1.29, 0.76, 1.9917205965359586, 1.8893780543870107, 0.99, -0.94, 0.471934498041641, -0.6860867348791511, -2.04, -1.77, 0.08, -0.72, -0.36, 1.14, -1.27, 2.087335482087359, -1.96, -1.48, 0.24, 3.76, 1.89, 1.9826583949931125, 1.23, 0.19, -1.11, -0.7721800287049088, 1.03, 0.23, 0.59, 2.1, -0.33, 3.02, -1.03, -0.54, 1.2338417231978391, 1.42, 1.6, 0.71, -1.02, -2.31, -2.04, -0.2, -0.99, -0.63, 0.86, -1.54, 1.77, -2.23, -1.75, 0.2808287981859412, 1.31, 1.71, 1.46, 1.48, 1.75, -1.3, -1.03, 0.83, 0.03, 0.39, 1.9, -0.52, 2.82, -1.22, -0.73, 1.0, 1.85, 3.1, 0.28, 2.16, 1.35, 1.72, 3.25, 0.79, 4.18, 0.08, 0.58, 2.33, 2.33, 7.17, -7.08, 2.8466982383853203, 1.88, 1.07, 1.43, 2.96, 0.7037447711019141, 3.88, -0.2, 0.3, 2.04, 2.5, 0.91, -0.79, -0.44, 1.06, -1.34, 1.97, -2.04, -1.55, 0.16, 1.23, 0.94, 2.41, 1.55, 2.1, 1.08, 1.72, 0.36, 1.87, -0.3602873118944545, 2.79, -1.25, -0.6940121365844474, 0.96, 3.0265360710717855, 1.35, 1.5, -0.91, 2.598603019995877, -1.4842004503433075, -1.12, 0.6, 3.35, 2.54, -0.06, 1.75, 4.94, 1.4, 0.8, -1.45, 1.49, 0.71, 2.58, 3.2, -4.55, -3.1, -1.6, 1.05, 1.27, 4.83, -4.76, -4.67, 1.55, -2.38, 3.12, 1.74, -0.85, 5.18, -7.23, -3.51, -5.05, 4.47, -0.15, -2.38, 0.9, -3.07, -2.59, -0.89, 4.72, 2.29, 3.3635374149659865, -0.7, -0.21, 1.53, -1.04, -3.93, -3.45, -1.77, 1.79, 1.88, 3.01, 0.5, 2.3222487553150164, 1.57, 1.58, 2.01, -3.7, 2.03, 3.77, 0.9172638105244333, 3.03, 2.5, 1.74, 1.05, 1.2, 1.07, 2.93, 1.16, 0.75, 2.72, 3.75, 0.3], ['403', -4.38, 0.95, 0.04015289830927054, 0.1, -0.3, 0.44, 1.52, 0.02, 0.19, -1.29, -1.7, -1.77, -0.07, -2.02, -0.85, 0.29, -1.5, -1.5, -3.9, -0.71, -1.33, -1.94, -1.71, -1.94, -0.78, 0.64, 0.42, -0.07, 1.6808333333333332, -0.33, 0.86, 2.03, 0.2, 0.2, -2.24, 1.0, 0.37, -0.24, -0.01, -0.24, 0.05, -0.12993788819875776, 0.49, 1.811197467496117, -0.25, 1.0108150295752765, 2.1, 0.28, 0.27, -2.17, 1.08, 0.478065468086443, -0.17, 0.07, -0.17, 0.42, -0.55, 0.6, 0.15, -1.22, -1.95, -0.78, 0.36, -1.43, -1.43, -3.83, -0.64, -1.26, -1.87, -1.64, -1.87, 0.02, 0.75, 1.2, 2.36, 0.53, 0.53, -1.92, 1.34, 0.7, 0.08, 0.32, 0.08, 0.37, 0.95, -0.98, -0.44, 1.15, -0.65, -0.66, -3.08, 0.14, -0.49, -1.1, -0.86, -1.1, -1.92, -1.58, -1.78, -1.776904761904762, -4.17847619047619, -1.0, -1.62, -2.22, -1.99, -2.22, 0.08, -1.47, -0.54, 0.36, 0.37, 0.38567351865003197, 0.2109570400359874, 0.0, -2.4398412698412697, 0.8, 0.17, -0.45, -0.21, -0.45, 0.52, 0.22, -2.44, 0.8, 0.17, -0.44, -0.21, -0.44, -0.03, -0.05, 0.28, 0.35, -5.92, 0.06, 0.07, -0.72, 0.67, 0.34, -1.09, 1.40025974025974, 1.16, -0.7, -0.35, -2.34, 0.22, 1.09, -1.09, -1.07, 0.35, -1.11, 0.69, -1.17, 0.56, 0.6707142857142857, 0.0, -0.46, -0.74, -1.17, 2.72, 3.32, 2.67, 2.04, 2.28, 2.2057617128436457, 1.02, -0.5798412698412698, -0.62, -1.24, -1.0, -1.24, 0.04, -0.62, -0.38, -0.61, 0.23, 0.27, 0.66, 0.24, 0.0, 0.35, 0.34, 0.07, -0.1, 0.07, 0.08, 0.12, 0.5410935020800125, 0.43, -0.24, 0.41, -0.06, 0.12, 0.11, 0.88, 0.745957527023814, 1.6, 0.7030376647162363, 0.93], ['404', -0.16, 0.18, 0.18122171562045875, -0.02, 1.28, 0.04, 0.16, 0.67, 0.76, 0.24, -0.55, -0.41, 1.55, -0.94, -1.9, 0.17, 0.56, 0.19, -0.65, -2.45, 0.24, 1.7960714285714285, 1.2, -0.21, 1.39, 0.85, 0.8, 0.14, 2.11, -0.39, -1.35, 0.72, 1.11, 0.75, -0.09, -1.91, 0.8, 2.36, 1.77, 0.34, 0.66, -0.1, 0.66, 1.97, -0.53, -1.49, 0.58, 0.97, 0.61, -0.23, -2.04, 0.66, 2.21, 1.62, 0.2, 0.12006284630567655, 0.43, 1.01, 0.85, -1.28, -2.45, -3.39, -1.36, -0.97, -1.33, -2.16, -3.93, -1.116578845757417, 0.24, -0.34, -1.73, 1.19, 1.19, -0.97, 1.11, 1.51, 1.14, 0.3, -1.52, 1.19, 2.76, 2.16, 0.74, 0.63, -2.72, 2.69, 2.18, 2.1, 2.5, 2.13, 1.28, -0.56, 2.18, 3.76, 3.16, 1.72, 0.872095238095238, 0.08, 0.39, 0.03, -0.81, -2.61, 0.08, 1.62, 1.04, -0.37, 0.16, 0.04, -2.49, 0.06, -0.31, 0.45, -0.31, -0.36, -1.2, -2.99, -0.31, 1.23, 0.64, -0.76, -1.22, 0.05, -0.84, -2.64, 0.05, 1.59, 1.01, -0.4, -1.36, -1.41, 0.15, -0.08, 2.87, 0.1, 0.08, -1.81, 1.81, 0.9, -0.28, 1.23, -5.67, -0.19, -0.11, -0.11, -0.32, 0.22, -0.19, -0.28, 0.09, -2.71, 0.25987835724131525, 0.61, -0.3, -0.94, 1.28, 0.77, 0.91, 5.66, 0.9, -1.81, 0.9, 2.45, 2.179638579674294, 0.44, 0.26, 2.76, 2.76, 4.35, 3.74, 2.29, 0.0, 1.54, 0.96, -0.45, 0.7, 0.73, -1.52, -0.58, -1.97, 0.08, 0.03, 0.68, -0.14, 0.0, 0.14, 0.71, 0.12, -0.95, -1.4, 0.3, 0.78, -0.45, -0.06666666666666667, -0.21, 0.45, 0.34, 0.55, 0.34], ['405', 2.59, 0.66, 0.0, -0.28538095238095235, -0.1, 0.21, 0.4741152579598292, -0.09, 0.67, -0.93, -1.55, -1.17, -1.41, -1.4, 0.73, -1.18, -2.47, -1.2, -1.99, -1.41, -0.39, -2.02, -2.3, -1.49, 0.63, 0.52, 0.6626583949931124, 0.39, 0.14, 0.16, 2.32, 0.38, -0.93, 0.36, -0.44, 0.15, 1.18, -0.47, -0.76, 0.07, -0.38, 1.3949361992161733, 0.25, -0.24, -0.22, 1.93, -0.01, -1.31, -0.03, -0.82, -0.24, 0.7996547292370609, -0.85, -1.14, -0.31, 0.69, -0.31, -0.14805211528237844, 0.45, 0.49, 0.12310472253556064, 2.18, 0.24, -1.07, 0.22, -0.58, 0.0, 1.04, -0.61, -0.9, -0.07, 0.54, 0.47, 2.16, 0.22, -1.09, 0.2, -0.6, -0.01, 1.02, -0.63, -0.91, -0.09, 0.99, 3.58, -3.66, -1.65, -1.9, -3.18, -1.92, -2.7, -2.13, -1.12, -2.73, -3.01, -2.2, 0.5012233560090703, 0.25, -1.3, -0.02, -0.81, -0.23, 0.8, -0.84, -1.13, -0.31, 0.28, 0.26, -0.33, 0.65, 0.62, 0.67, 1.58, 1.3, 0.5, 1.09, 2.13, 0.47, 0.18, 1.0685846838830657, 0.88, 0.27, -0.79, -0.21, 0.82, -0.82, -1.11, -0.29, 1.36, 1.6, -0.31, 0.77, 0.71, 0.12, 0.28, -1.72, 1.78, 0.9, 0.55, -0.31, -0.93, -1.32, -0.66, 1.3, 0.19, 1.95, -1.95, -1.96, 0.64, -2.56, 1.28, 2.78, -1.37, 4.77, 0.34, -3.25, -4.7, 0.87, 1.08, 0.59, 1.63, -0.03, -0.32, 0.51, 1.97, 0.49, 1.03, -0.61, -0.9, -0.08, -0.54, -1.5411214088935783, -1.91, -1.1, 0.64, 0.72, 1.11, -0.29, 0.54, 0.65, 0.7, -0.22, -6.23, 0.65, 6.25, 0.97, 0.74, 1.4, 0.83, 0.34, 0.8002197802197802, 0.09, -0.12, 0.14, 0.56, 2.9, 1.53, 0.52], ['406', -11.77, 0.0, -0.08, -0.08, -0.74, -0.02, -0.67, 0.52, -0.65, 0.1, 1.03, 1.44, -0.34, 0.89, -0.3, 4.37, 0.5, 0.02, -2.24, 0.64, -0.5, 0.0, -0.17, -0.18, 0.4, -0.03, -0.93, 0.41, -1.35, -0.14, -1.32, 3.31, -0.53, -1.0, -3.229285714285714, -0.39, -1.51, -1.02, -1.19, -1.2, 0.33, -0.48, -1.33, -1.75, -0.55, -1.72, 2.89, -0.93, -1.4, -3.63, -0.79, -1.91, -1.42, -1.4928571428571429, -1.6, 1.24, 1.09, 1.71, -0.11, 0.44, 1.23, 0.04, 4.73, 0.84, 0.4626050661400617, -1.8013219954648525, 0.98, -0.16, 0.34, 0.16, 0.16, 2.02, -0.78, -1.18, 3.45, -0.39, -0.86, -3.1, -0.25, -1.2169183673469388, -0.88, -1.05, -1.0064403582748793, -0.72, 0.81, -0.83, 0.4, 4.69, 0.8, 0.32, -1.94, 0.94, -0.2, 0.3, 0.13, 0.12, -3.58, -4.1, -3.71, -4.17, -6.33, -3.58, -4.67, -4.19, -4.36, -4.36, 0.09, -4.17, 3.29, 0.0, 0.03, 0.0, -0.4, -0.48, -2.72, 0.14, -0.99, -0.5, -0.67, -0.68, 0.18, 0.07, -2.26, 0.62, -0.34139698000412266, -0.02, -0.19, -0.2, 0.58, 0.53, 0.03, 0.08, -10.58204761904762, 0.2, 0.17, -0.03, -0.01, 0.0, -0.3, -0.15, 1.06, 0.0, -0.02, -5.73, 0.27, 0.05, -0.05, -0.02, -0.01, 0.0, 0.02, 1.28, -0.65, -1.2, -2.0, 0.85, 1.22, -1.16, 2.39, 2.94, 1.78, 2.29, 2.4296385796742936, 2.1, 0.0, -0.54, -1.13, -0.64, -0.81, -0.81, 0.6, 0.5, 0.33, 0.32, -0.63, -0.47, 0.1, -0.17, -0.18, 0.0, -0.01, 0.51, -3.27, 2.01, 3.18, -1.57, -0.59, 0.27, -0.01, -0.08, 0.0, 0.56, 0.7702244897959184, -0.11, 0.28, -1.7, -1.26, -0.72], ['407', -2.11, -0.3, 0.08015289830927054, -0.12, -0.44, 0.81, 0.36, 0.56, 0.68, -0.57, -1.76, -0.52, -1.05, -1.24, -1.11, -0.36, -1.64, -0.85, 0.42, -0.16, -0.23, -0.79, -1.28, -0.91, 0.91, 0.63, 1.2, 1.26, 0.71, 0.53, 0.66, 1.42, 0.11, 0.92, 2.22, 1.63, 1.55, 0.99, 0.5788796134390451, 0.86, 0.8574684253532109, 1.7949361992161734, -0.05, -0.54, -0.72, -0.59, 0.16, -1.13, -0.33, 0.95, 0.36, 0.29, -0.27, -0.77, -0.39, 0.5900628463056766, 0.28, 0.29, 0.25, 0.49, -0.18, -0.05, 0.71, -0.6, 0.21, 1.49, 0.91, 0.83, 0.27, -0.23, 0.15, 0.98, 0.67, 0.13, 0.89, -0.41, 0.39, 1.68, 1.09, 1.02, 0.46, -0.05, 0.33, 1.33, 1.72, -1.75, 0.5766982383853202, 0.76, -0.54, 0.26, 1.55, 0.96, 0.88, 0.32, -0.18, 0.2, 0.02, -0.22, -1.29, -0.5, 0.78, 0.2, 0.12, -0.43, -0.93, -0.55, 0.28, -0.24, 0.68, 0.87, 0.65, 1.075673518650032, 1.09, 0.81, 2.1, 1.51, 1.44, 0.87, 0.44598786341555263, 0.8085846838830657, 0.2, 0.28, 1.28, 0.7, 0.62, 0.1957995496566927, -0.44, -0.06, 0.47, 0.69, -0.27, 0.55, 0.24, 0.1, 0.03, -3.28, 3.26, 1.64, -0.12, 0.52, 0.8277589791161221, -1.77, -0.87, -1.01, 0.42, 2.68, -2.71, -2.68, 0.87, -4.94, 1.76, 1.72, -0.86, 3.22, -5.13, -2.22, -3.16, -0.77, -0.99, -0.58, -0.4527867132867132, -1.2, -1.7, -1.33, 2.7, -0.41, -0.07, -0.63, -1.13, -0.75, -0.34, -0.56, -1.05, -0.68, 0.67, 0.8, 0.21, -0.5, -0.12, 0.89, 0.86, 0.57, -3.15, 0.02, 3.14, 0.94, 0.76, 0.72, 0.38, 0.58, 1.7, 0.39, 0.29, 1.16, 0.34, 1.75, 0.74, 0.53], ['408', 3.41, -0.08, -0.14877828437954127, 0.16, -1.45, -0.05, -0.49, -0.61, 0.0, -0.13, -0.33, 0.15, 0.93, 1.77, 1.0, -0.29, -0.33, 0.17, 1.27, 1.37, 0.48, 0.91, -0.13, -0.34, -1.55, -0.3, 0.19, 0.48, 1.26, 2.1, 1.33, 0.04, 0.0, 0.5, 1.6, 1.7, 0.81, 1.24, 0.19, -0.01, -0.75, 0.9749361992161734, -0.28, 0.77, 1.61, 0.84, -0.44, -0.48, 0.02, 1.11, 1.22, 0.33, 0.75, -0.28, -0.49, 0.25006284630567654, -0.71, -0.93, -0.01, -1.05, 0.83, 0.07, -1.2, -1.24, -0.75, 0.34, 0.44, -0.44, -0.02, -1.05, -1.25, -2.1, -1.87, -0.75, -2.02, -2.06, -1.57, -0.49, -0.39, -1.26, -0.84, -1.87, -2.07, 0.42, 0.67, -0.62, -1.12, -1.27, -1.31, -0.82, 0.5057885487528346, 0.37, -0.51, -0.09, -1.12, -1.32, 1.31, 0.2273665312165629, -0.04, 0.46, 1.56, 1.66, 0.77, 1.2, 0.15, -0.05, -0.22, 0.2, -0.09, 0.05, -0.16, 0.24, 0.2, 0.5, 1.6, 1.7, 0.81, 1.24, 0.2, -0.01, -0.9, -0.3, 1.1, 1.2, 0.31, 0.74, -0.3, -0.51, -0.09, 0.91, 0.09, -0.14, 2.64, -0.03, -0.02, -1.11, 1.08, 0.55, 0.86, -1.1797402597402598, 2.8787161013589584, -0.13, -0.05, 1.73, -0.16, 0.11, -0.08, -0.17, 0.1, -1.58, 0.1, -0.28, 0.13, 0.49, 0.8686904761904761, -0.46, -0.57, -2.85, -1.38, 0.1, -0.78, -0.36, -1.38, -1.58, 0.25, -1.48, -0.88, -0.46, -1.48, -1.68, -0.61, 0.43, -0.61, -0.81, 0.0, 0.21, -1.03, -1.03, -1.23, 0.02, 0.09, -0.79, 0.46, 0.16, -0.96, -0.27, -1.36, 0.0, -0.2, 0.3, 0.75, 0.23, -0.49, -0.23, 0.2, -0.78, -1.55, 1.0930167737073972], ['409', 5.44, 0.21, 0.29, -0.17, 1.32, 3.36, 2.4941152579598294, 5.13, 4.14, 3.63, -2.33, 1.0393248299319728, 0.34, -1.04, -1.56, 1.9, -0.8, 2.58, 4.85, 3.07, 4.52, 0.26, -0.81, 1.49, 5.29, 3.6, 6.132658394993112, 3.44, 2.73, 1.32, 0.8, 4.33, 1.56, 5.03, 7.35, 5.53, 7.02, 2.66, 1.55, 3.963841723197839, 3.39, 5.0, 2.57, -0.68, -2.05, -2.56, 0.86, -1.81, 1.54, 3.78, 2.02, 3.46, -0.76, -1.82, 0.46, 5.25, 4.55, 3.29, 3.89, 3.28, -1.37, -1.88, 1.56, -1.14, 2.24, 4.49, 2.72, 4.17, -0.07, -1.15, 1.15, 5.0, 4.72, -0.52, 2.97, 0.24, 3.66, 5.95, 4.15, 5.62, 1.32, 0.23, 2.6135596417251206, 5.36, 12.29, -12.37, 5.260870922661994, 3.51, 0.76, 4.2, 6.5, 4.69, 6.17, 1.85, 0.75, 3.1, 4.98122335600907, 1.7, -2.65, 0.67, 2.89, 1.14, 2.632626537352693, -1.61, -2.66, -0.4, 1.26, 1.9493682032253463, 4.6, 3.21, 3.38517906963434, 3.09, 4.47, 3.41, 5.7, 3.9, 5.37, 1.08, -0.01, 2.32, 3.3, 1.02, 2.21, 0.47, 1.89, -2.26, -3.31, -1.06, 4.33, 5.05, 0.37, 3.84, 9.37, 0.5803231292517006, 0.81, -5.78, 5.78, 2.91, 1.61, 5.15, -1.0094817511227283, -6.49, -3.21, 2.84, 2.0, 9.880596861471862, -9.66, -9.61, 3.19, -8.77, 6.37, 2.45, -1.19, 13.35, -14.71, -8.9, -13.33, 1.14, -1.16, -1.7, -0.31, -4.37, -5.4, -3.2, 9.6, 0.54, 1.41, -2.72, -3.76, -1.53, -0.85, -4.07, -5.1, -2.9, 4.32, 4.63, 3.35, -1.07, 1.23, 3.22, 3.29, 5.1, -7.43, 4.26, 7.65, 4.41, 4.27, 4.5586374482009715, 2.33, 4.3, 2.96, 1.93, 1.74, 2.54, 2.1, 7.83, 4.61, 2.12], ['410', 2.09, 0.62, 0.09122171562045875, -0.17, 0.28, 0.93, 0.22, 1.39, 1.3093780543870106, 2.22, 0.92, 2.16, 0.94, 0.8, 1.04, 1.86, 1.91, 2.52, -1.79, 1.74, 2.45, 3.7130748299319727, 1.41, 1.94, 1.39, 1.07, 1.28, 1.23, 0.02, -0.12, 0.11, 0.93, 0.98, 1.7072589041444086, -2.69, 0.81, 1.594453670078569, 2.76, 0.48, 1.0, 1.1, 2.41, 0.05, -1.2, -1.33, -1.1, -0.3, -0.24, 0.35, -3.87, -0.41, 0.28, 1.52, -0.74, -0.22, 1.65, 0.75, 1.12, 1.09, 1.27, -0.13, 0.1, 0.91, 0.97, 1.57, -2.7, 0.8, 1.5, 2.75, 0.46, 0.99, 1.56, 1.41, 0.6502278911564625, 1.05, 1.1, 1.71, -2.57, 0.93, 1.64, 2.89, 0.6, 1.12, 1.57, 1.71, -1.59, 1.17, 0.81, 0.87, 1.47, -2.8, 0.7, 1.4, 2.65, 0.37, 0.89, 0.71, 0.35, 0.05, 0.66, -3.58, -0.11, 0.58, 1.82, -0.44, 0.08, -0.39, 0.46, -0.34, 0.66, 0.58, 0.45, 0.3, 0.6, -3.63, -0.17, 0.53, 1.76, -0.5, 0.02, -1.2, -0.3, -4.21, -0.76, -0.07, 1.16, -1.09, -0.57, 0.11, -0.31, -0.17, -0.64, 2.04, -0.36, 0.23, -0.4, 0.41, 0.22, 0.13, 2.44, -0.96, -1.25, -0.64, 1.02, 0.3430797898687791, 1.9, -1.96, -1.95, 0.65, -0.63, 1.36, -0.07160934502005914, -0.16, 0.88, -3.37, -0.6, -0.94, 0.97, 4.08, 3.6, 4.32, 5.6, 3.25, 3.79, 2.0, 0.47, 0.7, 1.94, -0.33, 0.19, -0.23, 1.23, -1.02, -0.5, 1.19, 1.32, -1.44, -2.22, -1.71, 0.62, 0.5, 1.39, -1.76, -0.32, 1.7021428571428572, 0.82, 1.2010935020800126, 0.8, 0.52, 0.71, 0.28, 0.8, 0.1, 0.84, 0.28, 1.03, 1.31, -0.05], ['411', -1.3, -0.59, -0.10877828437954125, -0.03, -1.18, -0.71, -4.9, -1.97, -1.33, -2.82, -1.75, -0.77, -1.68, -0.29, -0.94, -2.111439909297052, -1.76, -2.19, -1.21, -1.55, -2.16, -1.57, -1.34, -1.92, -1.67, -0.87, -1.09, 0.99, 0.08, 1.49, 0.82, -0.69, 0.6328571428571429, -0.45, 0.55, 0.21, -0.41, 0.18, 0.42, -0.17, -1.68, -1.74, -2.06, -0.91, 0.49, -0.17, -1.67, -0.99, -1.43, -0.44, -0.78, -1.4, -0.8, -0.57, -1.16, -1.0, -0.76, -0.862172027190216, -1.01, -1.16, 1.41, 0.75, -0.76, -0.08, -0.52, 0.47, 0.13, -0.49, 0.11, 0.34, -0.25, -1.38, -2.54, -0.6592857142857144, -2.1485714285714286, -1.48, -1.91, -0.93, -1.26, -1.88, -1.29, -1.06, -1.64, -1.36, -4.07, 4.06, -1.9, -1.5, -0.82, -1.26, -0.27, -0.61, -1.23, -0.64, 0.05251700680272092, -0.99, -1.34, -0.4, 0.69, 0.24, 1.2415238095238095, 0.9, 0.28, 0.88, 1.11, 0.52, -0.61, -0.45, -2.01, -0.93, -1.03, -0.8, -1.08, -0.44, 0.55, 0.21, -0.41, 0.19, 0.42, -0.17, -1.28, -0.65, 1.0, 0.66, 0.03, 0.63, 0.87, 0.27, -1.09, -1.18, -0.22, -1.11, -3.8578571428571427, -0.96, -1.09, 1.59, -1.64, -0.85, -1.4, -2.49, 2.57, 1.83, 0.9745476190476191, -0.66, -0.67, -2.75, 2.8, 2.74, -0.92, 2.5, -1.83, -1.69, 0.83, -3.26, 10.0, 2.16, 3.25, -2.54, -1.63, -0.34, -0.96, -0.36, -0.13, -0.72, -2.74, -1.29, -0.62, -0.03, 0.21, -0.38, -0.68, 0.6, 0.84, 0.24, -1.34, -1.12, -1.27, 0.24, -0.35, -0.9, -0.96, -2.08, 5.86, -1.72, -5.67, -1.11, -1.53, -1.5, -0.59, -0.89, -0.79, -0.3, -0.47, -0.6, -0.92, -1.77, -2.05, -0.89], ['412', -1.51, 0.35, 0.08, -0.18, 0.48, 0.25, 0.21, 0.26, 0.33, 1.66, 0.58, 2.69, 1.96, -0.04, 1.5, 2.04, 1.4, 1.57, -1.17, 0.61, 2.21, 1.93, 1.16, 1.6, 0.37, 0.31937141458889196, 1.08, 2.1, 1.38, -0.61, 0.92, 1.46, 0.82, 0.98, -1.73, 0.04, 1.62, 1.35, 0.58, 1.02, 0.62, 1.12, -1.0, -0.71, -2.65, -1.15, -0.63, -1.25, -1.09, -3.75, -2.02, -0.47, -0.74, -1.49, -1.05, 0.39, 0.51, 0.14, 0.08, -0.29, -1.96, -0.45, 0.08, -0.55, -0.39, -3.052819727891156, -1.32, 0.24, -0.03, -0.79, -0.35, -0.75, 1.7, 1.5407142857142857, 2.08, 1.44, 1.6, -1.13, 0.65, 2.25, 1.97, 1.2, 1.64, 1.16, 1.05, -1.09, 0.16, 0.53, -0.1, 0.06, -2.63, -0.88, 0.69, 0.42, -0.34, 0.1540077275244506, -0.69, -0.37, -0.63, -0.47, -3.15, -1.4, 0.16, -0.11, -0.87, -0.43, 0.09, -0.44, 0.21, 0.17, 0.27, 0.09, 0.26, 0.16, -2.53, -0.78, 0.8, 0.52, -0.24, 0.2, -0.22, 0.15307674813036726, -2.69, -0.94, 0.8086030199958774, 0.36, -0.4, 0.04, 0.91, 0.78, -0.27, 0.22, -2.37, 0.05, -0.03, -0.26, 0.31, 0.15, 0.2, -0.11, -2.17, -0.37, -0.16, -0.75, -0.07, 0.48, -0.58, -0.51, 0.17, -0.44, 0.35, 1.61, -0.77, 0.75, -2.97, -0.48, -0.8, 2.09, 2.86, 1.8, 3.42, 3.14, 2.35, 2.81, 0.5, 1.04, 1.59, 1.31, 0.54, 0.99, -0.53, -0.27, -1.03, -0.59, 0.3, 0.84, -0.26, -0.76, -0.32, 0.16, 0.19, 0.31, -1.56, -0.23, 1.64, 0.5372638105244333, 0.6610935020800125, 0.5, 0.44, 0.1, 0.15, -0.08, -0.35, 0.04, 0.06, 0.86, 2.27, 0.42], ['413', 3.007142857142857, -0.58, 0.13122171562045873, 0.26, 0.88, -0.52, 0.28, 0.57, 0.7, -0.83, -1.72, -1.29, -0.9, -1.26, -1.96, -0.98, -0.33, -1.2, -0.46, -1.75, -0.02, -1.18, -0.84, -0.54, 1.09, -0.46, 0.9, 0.44, 0.83, 0.47, -0.24, 0.76, 1.41, 0.53, 1.28, -0.03, 1.73, 0.55, 0.9, 1.2, 0.38, 1.22, 0.4602040816326531, 0.39, 0.03, -0.68, 0.32, 0.97, 0.09, 0.9371355564861203, -0.47, 1.28, 0.11, 0.45, 0.76, 0.2, 0.91, 1.44, 1.0, 0.07, -0.36, -1.07, -0.08, 0.57, -0.3, 0.45, -0.85, 0.89, -0.28, 0.06, 0.36, 0.56, 0.43, -0.71, 0.29, 0.94, 0.06, 0.81, -0.49, 1.25, 0.08, 0.43, 0.73, 0.62, 0.52, -0.51, 1.15, 1.0, 1.66, 0.78, 1.53, 0.22, 1.98, 0.8, 1.14, 1.45, 0.35, 0.15, 0.65, -0.22, 0.52, -0.78, 0.96, -0.2, 0.14, 0.44, 0.26, 0.16, -1.54, -0.21, -0.16, -0.21432648134996807, -0.5, -0.87, -0.13, -1.42, 0.3106802721088435, -0.85, -0.51, -0.21, 0.1, 0.37, 0.75, -0.56, 1.19, 0.02, 0.36, 0.67, -0.21, -0.98, 0.5, -0.46, 0.61, 0.15, 0.42, -0.59, 0.63, 0.31, -0.1, 1.41, -1.83, 0.41, 0.22, 1.871438775510204, -0.28, -0.63, 0.64, 0.75, -0.22, -0.8, -0.44, -1.41, 0.74, -1.51, 3.5, 1.0, 1.43, 1.86, -0.3516360544217687, -1.29, 0.44, -0.72, -0.38, -0.08, -0.5468321004392431, 0.93, 1.76, 0.58, 1.3394625850340136, 1.23, -0.81, -1.16, -0.82, -0.52, 0.74, 0.86, 0.35, 0.35, 0.65, -0.23, -0.27, 0.61, 1.68, -1.31, -1.88, -0.73, 0.11, 0.01, 0.3, -1.77, 0.54, 0.015297952047952229, -0.27, -0.62, -0.29, -1.67, 0.31, 0.77], ['414', -1.9, -0.17, -0.04877828437954125, -0.14, -0.24, 0.55, 1.15, 0.51, 0.06, 0.94, 0.63, 0.3, 0.9, 1.02, 0.7, 1.33, 0.0, 1.04, -0.93, 1.27, 0.55, 0.65, -0.42, 0.06, -0.11, -0.18, 0.34265839499311246, -0.33, 0.26, 0.38, 0.07, 0.69, -0.63, 0.4, -1.55, 0.63, -0.09, 0.02, -1.05, -0.57, -0.15, 0.4249361992161734, 0.64, 0.6, 0.72, 0.4, 1.03, -0.3, 0.74, -1.22, 0.97, 0.25, 0.35, -0.72, -0.24, 0.24, 0.14, 0.43, 0.3, 0.04, 0.11, -0.2, 0.43, -0.89, 0.14, -1.81, 0.37, -0.35, -0.25, -1.31, -0.83, 1.57, -0.07, -0.31, 0.31, -1.0, 0.02, -1.92, 0.25, -0.46, -0.36, -1.43, -0.95, 0.03, 3.8, -3.83, 0.24, 0.62, -0.7, 0.34, -1.62, 0.56, -0.15, -0.05, -1.12, -0.64, -0.86, -0.38, -1.31, -0.29, -2.23, -0.06, -0.77, -0.67, -1.73, -1.25, 0.09, -0.26063179677465376, 1.4, 0.8715981806829014, 0.89, 0.825673518650032, 0.94, 1.04, -0.93, 1.27, 0.55, 0.65, -0.43, 0.06, 0.38, -0.1, -1.95, 0.23, -0.49, -0.38, -1.45, -0.97, 1.2, 0.91, -0.13, 0.93, -2.6, -0.26, -0.26, -0.7, 0.67, 0.37, -0.4, -0.07, 0.67, -1.6, -0.82, -0.88, 0.72, 2.38, -2.35, -2.38, 0.81, -1.02, 1.61, 1.04, -0.51, 2.82, -0.38, -1.83, -2.81, -0.61, 1.89, 2.22, 1.49, 1.59, 0.51, 1.0, 2.42, -0.32, -0.72, -0.61, -1.67, -1.19, 0.39, 0.11288492856349999, -0.97, -0.48, 0.19, 0.24845354645354667, 0.29, -1.07, -0.59, 0.8, 0.83, 0.44257604962387836, -0.19, 1.16, 0.13, 1.02, 0.98, 1.37, 0.49, 0.92, 0.3345528598385743, 0.9, 0.45, 0.82, 0.965957527023814, -0.49, 1.59, 1.08], ['415', -2.6, -0.29, 0.13122171562045873, -0.13, 0.78, 0.9, 0.49411525795982914, 0.26, 0.37, -0.61, -0.7993911564625851, -1.28, -1.22, -0.65, -0.84, -0.6, -1.5, -0.97, -11.0, -1.93, -0.43, -1.85, -1.44, -1.72, 0.09, 0.12, 0.21, -0.47, -0.41, 0.17, -0.03, 0.22, -0.69, -0.16, -10.27, -1.13, 0.38, -1.04, -0.64, -0.91, -0.05, 1.9608975626058773, 0.68, 0.06, 0.64, 0.44, 0.69, -0.22, 0.31, -9.85, -0.67, 0.85, -0.58, -0.07285714285714287, -0.45, -0.01993715369432346, 0.0, 0.26, 0.47, 0.62, 0.6831047225355606, 0.38, 0.63, -0.28, 0.25, -9.9, -0.72, 0.8, -0.64, -0.23, -0.5, 0.61, 0.04, -0.2, 0.05, -0.86, -0.33, -10.42, -1.29, 0.22, -1.21, -0.8, -1.08, 0.88, 2.57, -2.63, 0.24, 0.25, -0.66, -0.13, -10.25, -1.1, 0.41, -1.01, -0.6, -0.88, -0.38, -0.01, -0.91, -0.38, -10.47, -1.35, 0.16, -1.26, -0.85, -1.13, 0.62, 0.06, 2.79, 0.78, 0.93, 0.59, 0.9009570400359874, 0.53, -9.65, -0.44, 1.08, -0.36, 0.05, -0.22, 1.19, 0.36, -10.13, -0.97, 0.54, -0.89, -0.48, -0.75, 0.95, 0.85, -0.15, 0.72, -1.17, 0.14, 0.13, -0.74, 0.74, 0.4088101710076211, 0.63, 1.09, -2.6, -1.57, -0.81, -1.29, 0.78, 2.45, -2.3, -2.31, 0.833290804863853, -1.08, 1.57, 0.45, -0.26, 2.7, -2.59, -1.91, -2.64, 2.6, 11.68, 10.517178777571635, 11.88, 10.29, 10.74, 10.43, 2.4208051948051947, 1.35, 1.53, 0.09, 0.5, 0.22, -0.18, -1.42, -1.02, -1.29, 0.37, 0.56, 1.26, 0.41, 0.14, 0.84, 0.8, 0.29, -2.14, 1.84, 2.29, 0.35, 1.26, 0.85, -0.28, 0.55, 0.29, 1.1, 0.64, 1.15, 1.13, 0.44, 2.04, 1.49], ['416', 4.501428571428571, -0.63, -0.08, -0.13, 0.49, 0.48, 1.45, 0.75, 0.79, -0.05, -1.16, -0.74, -0.75, -0.48, -1.2, -0.33, -0.23, -0.35, 0.78, -1.15, 0.27, -0.02, -1.16, -0.74, 0.84, 0.969371414588892, 1.12, 0.42, 0.42, 0.69, -0.04, 0.84, 0.94, 0.83, 1.96, 0.01, 1.524453670078569, 1.15, 0.0, 0.42, 0.26, 1.99, 0.7, 0.0, 0.4378753944468231, -0.46, 0.42, 0.52, 0.4, 1.53, -0.41, 1.02, 0.73, -0.42, 0.0, 0.37, 0.76, 0.95, 0.78, 0.7, 0.27, -0.45, 0.42, 0.52, 0.4, 1.54, -0.41, 1.02, 0.73, -0.42, 0.0, 0.45, 0.43, -0.72, 0.15, 0.25, 0.13, 1.26, -0.68, 0.75, 0.46, -0.69, -0.21644035827487929, 1.24, 2.66, -2.7, 1.19669823838532, 0.88, 0.98, 0.86, 2.0, 0.05, 1.48, 1.19, 0.04, 0.46, 2.83, 0.28, 0.1, -0.02, 1.11, -0.82, 0.6, 0.5528169964955679, -0.83, -0.42, 0.43, 0.24, 3.05, 0.65, 0.82, 0.43567351865003195, 0.18, -0.11, 1.01, -0.92, 0.5, 0.21, -0.93, -0.51, 0.14, 0.29, 1.13, -0.81, 0.62, 0.33, -0.82, -0.4, 1.0189583699631244, 0.65, -0.08, 0.26, 8.541102040816327, 0.15, 0.02, -0.51, 0.52, 0.30881017100762115, -0.63, 1.96, -2.23, -1.25, -0.65, 2.6014387755102044, 0.25, 1.95, -1.88, -1.88, 0.63, -0.77, 1.27, 1.56, -0.76, 0.58, -3.25, -0.44, -0.62, 2.21, -0.82, -1.91, -0.5, -0.79, -1.92, -1.51, 1.9, 1.1101587301587303, 1.44, 1.14, -0.01, 0.41, -0.32, -0.29, -1.42, -1.01, 0.83, 0.92, -0.03, -1.14, -0.72, 0.64, 0.53, 0.76, -0.66, 2.08, 0.66, 0.52, 1.06, 1.12, 0.42, 0.82, 0.31, 0.11, 0.5, 0.37, 0.7, 1.2, 0.87, -0.05], ['417', -4.34, -1.12, -0.09, 0.08, -0.96, -1.03, -1.825884742040171, -2.03, -1.95, -3.62, -1.57, -2.28, -0.12, -1.65, -0.99, -1.56, -2.68, -3.3, -3.85, -2.41, -3.78, -3.18, -2.4, -1.98, -2.32, -2.61, -2.08, -0.72, 1.48, -0.08, 0.6, 0.02, -1.12, -1.76, -2.31, -0.85, -2.24, -1.63, -0.84, -0.42, -1.27, -2.59, -1.37, 2.21, 0.65, 1.32, 0.75, -0.4, -1.05, -1.61, -0.13, -1.53, -0.92, -0.12, 0.3, -0.41, -0.86, -1.86, -2.369047619047619, -3.51, -1.53, -0.87, -1.44, -2.56, -3.087394933859938, -3.74, -2.29, -3.66, -3.06, -2.28, -1.87, -1.65, -2.0, 0.67, 0.1, -1.04, -1.68, -2.24, -0.77, -2.006918367346939, -1.56, -0.76, -0.34, -1.96, -3.42, 3.39, -2.66, -0.57, -1.71, -2.34, -2.89, -1.44, -2.82, -2.21, -1.43, -1.01, -4.05, -2.1, -1.14, -1.78, -2.33, -0.87, -2.26, -1.65, -0.86, -0.44, -0.35, -2.12, -1.78, -1.09, -1.01, -1.23, -0.97, -0.64, -1.21, 0.27, -1.13, -0.52, 0.28, 0.7685846838830657, -0.48, -0.27692325186963274, -0.57, 0.92, -0.480437641723356, 0.13, 0.94, 1.36, -1.08, -0.5, 0.19, -1.09, -12.24, -0.08, -0.07, 2.2, -2.2, -1.08, 0.2, -1.17, 2.53, 2.09, 1.09, -2.19, -0.41, -3.29, 3.26, 3.21, -1.06, 3.27, -2.19, -1.38, 0.68, -2.9, 6.6, 2.08, 2.8, -2.55, 0.24, 1.5, 0.08, 0.7, 1.51, 1.94, -3.29, -1.24, -1.4, -0.79, 0.01, 0.44, 0.16, 0.62, 1.43, 1.86, -1.94, -2.09, -0.46, 0.8, 1.23, -1.12, -1.12, -1.88, 3.91, -1.82, -3.97, -1.65, -2.0, -1.25, 0.43, -1.01, -1.02, -0.32, -0.06, -0.54, -1.67, -2.87, -2.86, -1.18], ['418', -0.13, 0.07, -0.2, -0.11, -0.96, -0.3315803763262405, -0.51, -0.66, -0.24, -1.3029115646258504, -2.16, -1.11, -1.75, -1.62, -0.14, -1.34, -1.59, -1.75, -3.69, 0.84, -1.84, -1.84, -1.88, -1.98, -0.78, -0.29, 0.42, 1.08, 0.42, 0.55, 2.06, 0.84, 0.58, 0.42, -1.56, 3.07, 0.32, 0.33, 0.29, 0.19, -0.75, -0.8850638007838266, -0.65, -0.65, -0.52, 0.98, -0.23, -0.49, -0.65, -2.61, 1.97, -0.74, -0.73, -0.78, -0.88, -0.21, -0.54, -0.7, 0.06, 0.0, 0.13, 1.640799319727891, 0.42, 0.16, 0.0, -1.97, 2.64, -0.09, -0.08, -0.13, -0.23, -0.25, -0.13, 1.5, 0.29, 0.03, -0.13, -2.1, 2.5, -0.23, -0.22, -0.26, -0.36, 0.13, 0.18, -0.28, -1.61, -1.2, -1.45, -1.61, -3.55, 1.173744771101914, -1.7, -1.69, -1.74, -1.84, -1.29, -0.3426334687834371, -0.26, -0.42, -2.38, 2.2, -0.4473734626473065, -0.51, -0.55, -0.65, -0.11, -0.39, 2.39, -0.34, -0.28, -0.3, -0.16, -0.16, -2.13, 2.47, -0.0742217465074606, -0.25, -0.29, -0.39, 0.08, 0.053076748130367266, -1.97, 2.64, -0.09, -0.08, -0.13, -0.23, 0.61, 0.78, -0.11, 0.05, -4.02, 0.04, 0.16, 0.86, -0.84, -0.42, -0.79, -0.66, 5.07, 0.69, 0.4, -0.03, -0.31, -1.07, 1.12, 1.11, -0.35, 1.26, -0.7, 1.12, -0.56, -0.29, -0.94, 0.24, 0.46, -5.12, 2.0, 4.7, 1.91, 1.92, 1.87, 1.77, -0.95, -2.57, -2.66, -2.65, -2.7, -2.79, 0.09, 0.01, -0.04, -0.14, -0.33, 0.0, 0.08, -0.05, -0.14, -0.35, -0.32, -0.64, -0.28, 1.85, 0.22, -0.28, -0.91, 0.13, -0.1, -0.36, -0.91, -0.06, -0.6, 0.2, 0.23, -1.4, -0.81, -0.26], ['419', -1.77, -0.36, -0.2, 0.07, -1.96, -1.04, -1.61, -2.46, -2.12, -2.82, 0.51, -1.44, -1.5060867348791511, -0.16, -0.83, -2.33, -1.32, -2.53, -2.35, -0.25, -3.07, -1.96, -1.79, -1.44, -2.18, -1.5106285854111081, -3.31, -1.94, -2.07, -0.66, -1.33, -2.82, -1.82, -3.03, -2.85, -0.75, -3.56, -2.45, -2.29, -1.94, -1.86, -2.72, -1.4, -0.13, 1.3, 0.62, -0.9, 0.12, -1.11, -0.93, 1.21, -1.65, -0.52, -0.36, 0.0, -0.76, -1.36, -2.88, -2.32, -1.27, 1.44, 0.7507993197278912, -0.77, 0.26, -0.8773949338599383, -0.8, 1.4639757335335069, -1.52, -0.39, -0.23, 0.13, -2.83, -2.67, -0.68, -2.18, -1.16, -2.38, -2.2, -0.1, -2.92, -1.8, -1.64, -1.29, -2.75, -3.11, 3.07, -2.0, -1.51, -0.49, -1.71, -1.53, 0.59, -2.26, -1.13, -0.97, -0.61, -2.24, -0.4226334687834371, 1.03, -0.21, -0.03, 2.13, -0.76, 0.38, 0.55, 0.91, -0.33, -0.42, 0.89, -1.15, -1.15, -1.15, -1.52, -1.0934006093113235, -1.05, 1.08, -1.78, -0.65, -0.48, -0.13, -0.76, -0.29, 0.19, 2.34, -0.55, 0.59, 0.76, 1.12, -1.45, -1.44, -0.2839628211219596, -1.34, -6.58, -0.46, -0.65, 2.65, -2.72, -1.35, 0.27, -4.3, 5.08, 2.21, 1.13, -0.91, -1.01, -3.45, 3.39, 3.45, -1.13, 4.01, -2.28, -1.06, 0.47, -4.48, 13.09, 3.02, 4.42, -5.15, -0.47, 2.15, -0.73, 0.41, 0.58, 0.93, -3.42, -2.57, -2.83, -1.71, -1.55, -1.2, 0.26, 1.15, 1.32, 1.68, -2.19, -2.5, -0.88, 0.17, 0.52, -1.12, -1.17, -2.31, 6.74, 0.09, -6.72, -1.55, -1.48, -1.04, 0.36, -0.4, -1.04, -1.03, -0.82, -1.36, -1.39, -1.87, -2.99, -1.27], ['420', 2.73, 0.42, 0.26, 0.01, 0.3429790809910596, 0.58, 1.214115257959829, 0.95, 1.02, 0.94, -0.02, 0.13, 0.12, 0.67, 0.41, 0.4, 0.2, 0.66, 2.6, 0.09, 0.99, 0.81, -0.23, 0.1, 0.35, 0.14, 0.9926583949931125, 0.2684685082657772, 0.14, 0.69, 0.43, 0.42, 0.23, 0.68, 2.62, 0.12, 1.01, 0.83, -0.21, 0.16384172319783916, 0.92, 1.69, 0.820204081632653, -0.01, 0.54, 0.28, 0.27, 0.08, 0.53, 2.47, -0.03, 0.86, 0.68, -0.36, -0.02, 0.41, 0.49, 0.91, 1.01, 0.82, 0.55, 0.29, 0.28, 0.08, 0.54, 2.48, -0.03, 0.87, 0.69, -0.35, -0.02, 1.06, 0.27, -0.26, -0.27, -0.46, -0.01, 1.92, -0.57, 0.32, 0.14, -0.9, -0.57, 1.33, 3.13, -3.2, 0.53, -0.01, -0.21, 0.25, 2.18, -0.32, 0.57, 0.4, -0.64, -0.31, 0.21, 0.54, -0.19, 0.26, 2.19, -0.3, 0.59, 0.41, -0.63, -0.3, 0.25, 0.55, 3.01, 0.64, 0.73, 0.62, 0.8118094764861292, 0.45, 2.39, -0.11, 0.78, 0.6, -0.43, -0.04141531611693433, 0.13, 0.28, 1.93, -0.56, 0.33, 0.15, -0.89, -0.56, 1.81, 1.77, 0.03, 0.81, 0.3, 0.28, 0.34, -1.45, 1.43, 0.7888101710076211, 0.78, 2.11, -1.71, -1.35, -0.65, 1.31, 0.06, 2.02, -2.05, -2.09, 0.65, -2.36, 1.28, 0.59, -0.34, 2.15, -3.68, -1.53, -2.28, 1.7, -1.6016360544217687, -2.44, -1.3727867132867133, -1.75, -2.76, -2.44, 1.91, 0.85, 0.89, 0.72, -0.33, 0.01, -0.05, -0.18, -1.21, -0.88, 1.02, 1.18, 0.13, -1.03, -0.7, 0.63, 0.72, 1.01, -3.19, 2.25, 3.11, 0.19, 0.81, 1.2586374482009708, 0.33, 0.94, 0.73, -0.02, -0.23, 0.31, 0.84, 0.14, 1.75, 0.25], ['421', 0.48, 0.05, -0.06877828437954125, 0.2, -0.07, -1.09, -2.72, -1.58, -2.28, -1.52, 1.34, 0.85, -0.98, 0.31, 0.03, -1.67, -0.35, -1.12, -2.77, -0.47, -2.16, -0.87, -0.15, -0.48, -1.06, -0.890628585411108, -2.82, -0.48, -2.29, -1.01, -1.29, -2.97, -1.66, -2.42, -4.05, -1.78, -3.45, -2.18, -1.47, -1.8, -1.13, -5.315063800783826, -2.34, -1.81, -0.53, -0.81, -2.5, -1.18, -1.95, -3.59, -1.3, -2.98, -1.71, -0.99, -1.32, -1.2, -1.11, -0.83, -1.79, -0.54, 1.3, 1.02, -0.7, 0.64, -0.14, -1.81, 0.52, -1.19, 0.11, 0.84, 0.5, -1.4, -1.82, -0.28, -1.98, -0.65, -1.43, -3.07, -0.78, -2.46, -1.18, -0.32690451810094656, -0.79, -3.36, -3.46, 3.38, -1.54, -1.7, -0.37, -1.15, -2.8, -0.49, -2.19, -0.9, -0.18, -0.51, 0.41, 0.16, 1.35, 0.56, -1.12, 1.23, -0.49, 0.81, 1.55, 1.21, -0.41, 0.19, 1.51, -0.88, -0.74, -0.97, -1.18, -0.78, -2.43, -0.12, -1.82, -0.53, 0.2, -0.14, -0.46, -0.4, -1.67, 0.66, -1.05, 0.25, 0.98, 0.64, -1.78, -1.28, 0.17, -0.83, 1.13, -0.09, 0.27, 1.98, -1.97, -1.0, 0.55, -1.58, 2.1, 1.64, 0.89, 0.3, -0.63, -2.62, 2.65, 2.58, -0.84, 2.94, -1.7, -2.54, 1.24, -3.49, 9.12, 2.33, 3.49, -1.9828690476190476, 1.3083639455782314, 2.37, 0.8272132867132869, 1.95, 2.7, 2.35, -2.53, -1.05, -1.7, -0.41, 0.32, -0.02, 0.66, 1.31, 2.06, 1.71, -2.197204648526077, -2.48, -0.65, 0.73, 0.39, -0.83, -0.88, -1.53, 5.1, -0.12, -5.23, -0.62, -0.15, -1.37, -0.34, -0.96, -0.86, -0.69, 0.21, -1.37, -1.04, -1.1, -0.46, -1.3], ['422', -0.06, 0.0, -0.008778284379541255, -0.05, 0.01, -0.04, 0.014115257959829165, 0.0, -0.01, 0.05, -0.03, 0.05, 0.02, -0.07, 0.08, 0.05, -0.04, 0.03, 0.0, 0.05, 0.11733548208735894, 0.07, 0.24, 0.01, 0.16, -0.04, 0.12265839499311246, 0.09, 0.06, -0.04, 0.16781997129509119, 0.09, -0.01, 0.06, 0.03, 0.09, 0.11, 0.1, 0.28, 0.08384172319783915, 0.0, 0.014936199216173434, 0.0, -0.03, -0.13, 0.03, 0.0, -0.1, -0.02, -0.05, 0.0, 0.04806546808644298, 0.02, 0.19, -0.04, 0.03, 0.07, 0.08, 0.06, 0.03, -0.1, 0.06, 0.03, -0.07, 0.0, -0.02, 0.03, 0.05, 0.05, 0.22, -0.01, -0.03, 0.13, 0.16, 0.13, 0.03, 0.1, 0.07, 0.13, 0.15, 0.14, 0.32, 0.13355964172512072, 0.0, -0.42, 0.34, 0.00669823838532016, -0.03, -0.13, -0.05, -0.08, -0.03, 0.0, -0.01, 0.16, -0.07, -0.18, 0.0, -0.1, -0.03, -0.05, 0.0, 0.02, 0.02, 0.19, -0.04, 0.11, 0.0, 0.07572371188304003, 0.01, -0.06, 0.13567351865003197, 0.1718094764861292, 0.07, 0.14693256743256752, 0.1, 0.12, 0.11, 0.29, 0.10858468388306568, 0.06, 0.02, -0.03, 0.03, 0.05, 0.04, 0.22, -0.02, 0.0, 0.04, 0.07, 0.11, 0.0, 0.02, 0.0, -0.1, 0.15, 0.14881017100762112, 0.0, 0.0, 0.07, 0.0, 0.0, 0.0, 0.11, 0.12, -0.11, -0.04, 0.02, -0.26, -0.01, 0.16, -0.11, 0.23, 0.01, -0.15, -0.31, -0.04, 0.05, 0.06, 0.08, 0.07, 0.25, 0.01, 0.04, 0.0, 0.02, 0.02, 0.19, -0.04, -0.02, -0.01, 0.17, -0.07, 0.04, 0.02, -0.02, 0.17, -0.06, 0.02, -0.01, 0.0, -0.09, 0.15019962695749933, 0.06, 0.06, -0.14, -0.19, -0.23, -0.08, -0.03, 0.0, 0.0, 0.04, 0.04, 0.02, 0.06, 0.03], ['423', -1.52, 2.0214285714285714, 0.07, 0.01, 0.44, -0.01, 1.82, 0.07, -0.17, -0.95, -0.18, -2.6, -1.78, -0.37, -1.26, -1.01, -1.34, -1.13, -3.4, -2.53, -1.15, -1.57, -1.28, -1.54, -0.25, 0.48, -0.78, -2.43, -1.61, -0.19, -1.08, -0.84, -1.16, -0.95, -3.23, -2.36, -0.98, -1.4, -1.1, -1.37, 0.08, -1.42, 1.69, 0.84, 2.29, 1.38, 1.63, 1.29, 1.51, -0.8183478664192949, 0.07119047619047619, 1.48, 1.05, 1.35, 1.08, -0.14, -0.08, -0.47, -0.53, 0.84, 1.44, 0.53, 0.78, 0.45, 0.67, -1.65, -0.76, 0.64, 0.21, 0.51, 0.24, -0.25, -0.59, -0.8753571428571428, -0.65, -0.97, -0.76, -3.04, -2.17, -0.79, -1.21, -0.91, -1.18, -0.8395238095238095, 1.54, -1.55, 0.31, 0.25, -0.06821428571428571, 0.13, -2.17, -1.29, 0.11, -0.32, 0.010976190476190473, -0.29, 0.74, 0.06, -0.33, -0.12, -2.41, -1.53, -0.0773734626473065, -0.56, -0.27, -0.54, 0.2, -0.05, 2.85, 0.43, 0.35, 0.58, 0.39, 0.21, -2.09, -1.21, 0.19, -0.17969498055271244, 0.06, -0.21, 1.1, 0.18, -2.3, -1.42, -0.03, -0.45, -0.15, -0.42, 0.58, 0.61, 0.11, 0.52, 2.09, 0.82, 0.83, -0.99, 1.05, 0.5, 4.1, 0.87, -3.2, -0.84, -0.42, -0.73, 0.67, 1.27, -1.19, -1.21, 0.41, -1.5, 0.86, -0.12, 0.1447652642842468, 1.18, -5.07, -0.86, -1.18, 3.2, 2.53, 0.9, 2.33, 1.89, 2.2, 1.92, 1.24, 1.62, 1.41, 0.98, 1.290857142857143, 1.0114285714285713, 0.2, -0.42, -0.13, -0.4, 0.010135138670853056, -0.7, 0.63, 0.3, 0.03, 0.42, 0.48, 0.07, -3.14, 2.1, 3.32, 0.17, -0.06, 0.33, -0.27, 0.28, 0.25, 0.61, 0.77, 0.83, 0.6, 0.3, 0.12, 0.2], ['424', 6.1, 1.26, 0.16, -0.08, 0.94, 0.87, 1.894115257959829, 2.08, 1.28, 4.11, 2.230608843537415, 3.47, 2.39, 2.54, 2.35, 1.91, 2.71, 3.77, 4.39, 3.32, 5.0, 2.58, 2.83, 2.96, 2.47, 1.759371414588892, 1.85, 1.22, 0.16, 0.31, 0.13, -0.31, 0.48, 1.51, 2.12, 1.08, 2.72, 0.35, 0.6, 0.72, 0.78, 2.44, 0.62, -1.04, -0.9, -1.08, -1.51, -0.73, 0.29, 0.89, -0.14, 1.48, -0.86, -0.62, -0.48495238095238097, 1.44, 1.09, 2.02, 1.17, 1.68, 0.15, -0.03, -0.47, 0.31, 1.35, 1.96, 0.92, 2.55, 0.18, 0.43, 0.56, 2.84, 1.53, -0.18, -0.62, 0.16, 1.2, 1.8, 0.76, 2.4, 0.03, 0.28, 0.4, 1.68, 3.58, -3.6, 1.72, -0.44, 0.35, 1.38, 1.99, 0.95, 2.613870161584447, 0.22, 0.9225170068027209, 0.59, 0.86, 2.16, 0.79, 1.83, 2.44, 1.39, 3.04, 0.66, 0.91, 1.03, 0.41, 2.1923568812140237, 1.06572371188304, 1.23, 1.11, 1.36, 1.36, 1.03, 1.64, 0.6, 2.23, -0.13, 0.12, 0.24, 1.46, 0.33, 0.6, -0.43, 1.19, -1.0242004503433073, -0.9, -0.78, 0.93, 1.04, -0.14, 1.26, 2.12, 0.21, 0.17, -2.56, 2.51, 1.27, 1.78, 0.85, -1.38, -2.46, -1.23, 3.44, 1.22, 3.64, -3.74, -3.7, 1.24, -3.77, 2.47, 1.37, -0.6652347357157532, 3.86, -10.36, -2.75, -4.05, 1.39, -0.27, -1.02, 0.59, -1.74, -1.49, -1.37, 3.53, 0.76, 1.62, -0.72, -0.48, -0.36, -0.85, -2.31, -2.07, -1.95, 1.37, 1.49, 1.5, 0.25, 0.37, 1.24, 1.26, 2.06, -5.55, 1.2001996269574993, 2.54, 1.82, 1.1, 1.25, 0.12, 1.17, 1.12, 1.67, 1.01, 1.23, 1.12, 0.98, 1.68, 0.85], ['425', 2.41, 0.29, 0.08, 0.14, 0.59, -0.18, -0.6858847420401708, -0.44, -0.02, 0.9, 1.6, 1.5293248299319728, 1.26, 1.22, 1.02, 1.03, 1.53, 1.0, -4.42, 1.63, 0.77, 0.45, 1.32, 1.475116627420199, 0.13, 0.11, -0.6573416050068874, -0.08, -0.34, -0.37, -0.57, -0.57, -0.07, -0.47274109585559154, -5.93, 0.02, -0.82, -1.13, -0.28, -0.27, 0.51, 0.4808975626058773, -0.61, -0.26, -0.29, -0.49, -0.49, 0.01, -0.51, -5.85, 0.11, -0.74, -1.05, -0.2, -0.19, -0.35, 0.27, -0.74, 0.42, -0.35, -0.03, -0.23, -0.23, 0.27, -0.25, -5.6, 0.37, -0.48, -0.79, 0.06, 0.07, -0.55, -0.32, -0.2, -0.2, 0.3, -0.22, -5.5669047619047625, 0.7191309523809524, -0.45, -0.76, 0.09, 0.1, -0.44, -0.67, 0.65, -0.12, 0.0, 0.5, -0.02, -5.38, 0.7937447711019141, -0.25, -0.57, 0.29, 0.3, 1.09, -0.12, 0.5, -0.02, -5.39, 0.6, -0.25, -0.57, 0.29, 0.3, -0.23, 0.029368203225346196, -1.46427628811696, -0.11840181931709852, -0.16482093036566006, -0.16, -0.62, -0.52, -5.86, 0.1, -0.75, -1.06, -0.21, -0.2, 0.29, -0.1, -5.37, 0.62, -0.23, -0.55, 0.31, 0.32, -0.11, -0.55, 0.31603717887804045, -0.39, 3.45, 0.1, 0.26, 0.48, -0.46, -0.24, 0.02, -0.95, 1.36, 0.33, 0.15, 1.17, 0.07, -0.27940313852813836, 0.5, 0.5, -0.11670919513614705, 0.65, -0.35, -1.04, 0.49, -1.86, 2.4, 1.16, 1.77, -1.41, 5.57, 6.33, 5.43, 5.09, 6.0, 6.01, -0.46, -0.71, -0.84, -1.16, -0.31, -0.3, 0.13, -0.32, 0.54, 0.55, -0.06, 0.0, 0.45, 0.86, 0.87, -0.12, -0.2, -0.52, 2.22, -1.78, -2.14, -0.28, -0.07, -0.41, 0.01, -0.46, 0.0, 0.34, 0.32, -0.59, -0.42, 0.18, 0.23, -0.07], ['426', -52.74, 0.11, 0.04, 0.12, 0.18, -0.4, -0.5958847420401708, -1.2, -0.49, -1.9, -1.13, -1.9, -1.35, -0.57, -0.52, -1.16, -1.36, -1.21, -2.58, -1.57, -2.03, -0.6240578231292517, 0.67, -1.72, -0.08140633899247347, -1.58, -0.77, -0.77, -0.23, 0.57, 0.62, -0.03, -0.23, -0.08, -1.46, -0.44, -0.91, 0.4, 1.82, -0.59, -0.8525315746467891, -2.5950638007838265, 0.0, 0.55, 1.35, 1.4, 0.75, 0.55, 0.7, -0.7, 0.34, -0.14, 1.18, 2.6557142857142857, 0.18, -0.09993715369432345, -1.19, -1.18, -0.06, -0.55, 0.8, 0.85, 0.2, 0.0, 0.15, -1.24, -0.22, -0.69, 0.63, 2.05, -0.37, -1.1, -1.34, 0.05, -0.5885714285714285, -0.8, -0.65, -2.02, -1.01, -1.47, -0.17, 1.25, -1.16, -0.95, -6.34, 6.55, -1.38, -0.64, -0.8282142857142857, -0.69, -2.07, -1.05, -1.52, -0.22, 1.2, -1.2, -1.97, -0.6726334687834371, -0.2, -0.05, -1.44, -0.41, -0.88, 0.43, 1.85, -0.56, -0.66, -0.73, -1.39427628811696, -0.5, -0.85, -0.13, -0.54, 0.15, -1.24, -0.21, -0.68, 0.63, 2.6885714285714286, -0.36, -1.14, -0.69, -1.38, -0.36, -0.83, 0.48, 1.91, -0.51, -3.1, -2.52, 0.11, -0.28, -3.59, -0.61, -0.22, -0.8, 0.8, 0.41, -0.95, -0.9, 0.64, 0.95, 0.49, -2.74, -0.16, -1.45, 1.45, 1.5, -0.47, -1.06, -0.95, -2.39, 1.2, -1.69, 2.83, 1.06, 1.53, -0.77, 0.7, 1.04, 0.56, 1.89, 3.34, 0.89, -1.45, -0.33, -0.47, 0.84, 2.27, -0.15, 0.14, 1.32, 2.76, 0.32, -0.42, -0.76, -1.17, 1.42, -0.99, -0.56, -0.43, -1.25, 1.35, -0.95, -1.21, -1.08, -0.59, -2.55, -2.37, -1.22, 0.55, -0.13, -0.01, -0.09, -0.18, -1.04, -0.5, -0.93], ['427', 0.57, 0.0, 0.4712217156204588, 0.07, 0.19, -0.21158037632624052, 0.22411525795982914, 0.47, 0.47, -1.01, -1.73, -1.59, -1.23, -2.09, -1.21, -2.32, -1.34, -1.13, 0.52, -0.99, -0.67, -1.5, -0.84, -0.91, 0.33, 1.549371414588892, 0.73, 0.14, 0.51, -0.37, 0.53, -0.6, 0.39, 0.62, 2.29, 0.75, 1.08, 0.23, 0.9, 0.84, 0.45, -0.14506380078382658, 0.59, 0.36, -0.3421246055531769, 0.38, -0.74, 0.25, 0.47, 2.14, 0.6, 0.94, 0.09, 0.76, 0.69, 0.83, -0.73, -0.68, 0.27, 0.22, -0.7668952774644393, 0.02, -1.1, -0.11, 0.11, 1.77, 0.24, 0.57, -0.27, 0.39, 0.33, 0.29, 1.11, 0.9, -0.23, 0.77, 0.99, 2.67, 1.12, 1.46, 0.61, 1.28, 1.21, 0.5, -0.64, 0.55, 0.2, -1.12, -0.13, 0.09, 1.75, 0.22, 0.55, -0.29, 0.37, 0.3, 0.37, 1.34, 1.0, 1.22, 2.9, 1.35, 1.69, 0.84, 1.51, 1.44, 0.12, 1.28, -0.17, -0.09, -0.11, 0.07567351865003197, 0.34, 0.22, 1.88, 0.35, 0.68, -0.16, 0.51, 0.44, 0.37, 0.12, 1.66, 0.13, 0.46, -0.38, 0.29, 0.22, -0.33, -0.32, 0.38, 0.11, 1.31, 0.05354725829725827, 0.07, -0.16, 0.2, 0.09, -0.08, 1.3461635321120495, -0.01, 0.06, 0.08, 0.37, -0.27, -0.19, 0.21, 0.29, -0.1, -0.35, -0.2, -0.5, 0.26, 0.99, 1.94, -0.66, -1.07, -0.022869047619047622, -1.52, -1.5, -1.18, -2.01, -1.35, -1.42, -0.28, -0.02, 0.33, -0.51, 0.15, 0.09, -0.35, -0.84, -0.18, -0.24, 0.49, 0.36, 0.5872746849074344, 0.67, 0.6722487553150163, -0.05, -0.06, 0.37, 1.06, -0.35, -1.05, 0.26726381052443327, 0.36, -0.17, -0.07, -0.27, 0.04, -0.55, -0.4, 0.06, -0.1, 1.13, 0.6, -0.06], ['428', 3.12, 0.36, -0.04, -0.21, 0.64, 0.55, 1.6, 0.75, 1.24, 0.47, -0.96, -1.05, 0.1, -0.52, 1.14, -0.31, -0.41, 0.27, 0.68, -0.7763367346938775, 0.87, 0.13, -0.23, -0.34, 1.41, 1.36, 1.45, -0.08, 1.08, 0.45, 2.13, 0.66, 0.56, 1.24, 1.66, 0.17, 1.85, 1.1, 0.74, 0.63, -0.06, 2.58, 1.53, 1.16, 0.54, 2.21, 0.74, 0.64, 1.33, 1.75, 0.25, 1.968065468086443, 1.19, 0.82, 0.71, 0.27, 0.45, 0.71, 0.41, 0.37, -0.62, 1.04, -0.42, -0.51, 0.16, 0.58, -0.9, 0.76, 0.02, -0.33, -0.44, 0.94, 0.99, 1.67, 0.2, 0.1, 0.79, 1.2, -0.29, 1.39, 0.65, 0.29, 0.18, 2.05, 1.65, -1.63, -0.6233017616146799, -1.44, -1.54, -0.86, -0.45, -1.92, -0.27, -1.0, -1.36, -1.47, 3.15, 0.78, -0.1, 0.58, 1.0, -0.49, 1.18, 0.44, 0.08, -0.03, 0.21, 0.77, 2.890104651162791, 0.65, 0.70517906963434, 0.685673518650032, 0.88, 0.68, 1.1, -0.39, 1.29, 0.54, 0.18, 0.07, 0.29, 0.2, 0.41, -1.06, 0.6, -0.14, -0.5, -0.61, 0.58, 0.58, -0.4, 0.84, 9.54, 0.12, -0.09, -2.16, 2.18, 1.09, -0.52, 0.58, -2.54, -1.36, -0.66, 1.59, -0.04, 2.0905968614718615, -1.86, -1.97, 0.683290804863853, -3.21, 1.3, 2.02, -1.01, 2.62, -1.11, -1.79, -2.62, 2.54, -0.21, -1.47, 0.19, -0.55, -0.91, -1.02, 1.96, 1.28, 1.68, 0.93, 0.57, 0.46, -0.4, -0.74, -1.09, -1.2, 1.16, 1.16, 0.34, -0.36, -0.47, 0.62, 0.64, 0.8, -0.51, 2.82, 0.31, 1.447263810524433, 0.92, 0.7, -0.11, 0.9, 1.19, -0.03, -0.11, -0.3, 0.81, 2.29, 1.47, 0.6830167737073972], ['429', 1.04, 0.31, -0.48877828437954124, -0.1, 0.06, 0.64, 0.014115257959829165, 0.7, 0.64, 1.39, 0.58, 1.62, 0.99, 1.07, 1.9, 1.61, 0.32, 0.81, 1.61, 2.23, 1.53, -0.22, 0.75, 0.81, 0.27, -0.12, 0.81, 1.1484685082657773, 0.41, 0.49, 1.31, 1.02, -0.26, 0.22, 1.03, 1.64, 0.95, -0.8, 0.17, 0.23, -0.5025315746467891, 0.9649361992161734, -0.22, -0.62, -0.54, 0.28, -0.01, -1.28, -0.8, 0.0, 0.6, -0.08, -1.81, -0.85, -0.79, 1.3, 0.0, -0.68, 0.67, 0.4, 0.08, 0.9, 0.62, -0.66, -0.18, 0.62, 1.23, 0.54, -1.2, -0.24, -0.18, 0.37, 0.32, 0.82, 0.53, -0.74, -0.26, 0.54, 1.15, 0.46, -1.28, -0.32, -0.26, 0.97, 1.88, -1.88, -0.5, -0.28, -1.55, -1.07, -0.28, 0.33, -0.36, -2.08, -1.12, -1.07, -0.97, -0.21, -1.27, -0.79, 0.0, 0.61, -0.08, -1.8, -0.85, -0.79, 0.54, -0.19, 2.4957237118830404, 0.55, 0.67, 0.46, 1.07, 0.49, 1.29, 1.9, 1.21, -0.54, 0.43, 0.49, 1.49, 0.58, 0.8, 1.41, 0.72, -1.02, -0.05, 0.0, 1.23, 1.88, -0.04, 1.03, -3.26, 0.22, -0.8, 0.08, -0.1, -0.04, 0.62, 3.57, 1.54, -1.1, -0.57, 0.57, 0.6, 1.76, -1.67, -1.55, 0.54, 0.09, 1.09, 1.31, -0.73, 3.23, -7.53, -2.21, -3.24, -1.45, -0.22, 0.9371787775716347, -0.08, -1.8, -0.85, -0.79, 1.66, -0.82, -0.68, -2.4, -1.45, -1.39, -0.14, -1.7271150714365, -0.77, -0.71, 0.59, 0.87, 1.62, 0.97, 1.03, 0.57, 0.51, 0.74, -3.73, 2.02, 4.16, 0.65, -0.27, 0.64, 0.13278685149693165, 0.86, 0.0, 1.05, 1.23, 1.11, 0.58, -0.09, -0.35, 1.18], ['430', 1.24, -0.31, -0.1, -0.13, 0.62, 0.02, 0.45, 0.55, 0.0, -0.87, -0.2, -0.9, -0.75, -0.42, -1.01, -0.75, -1.27, -0.92, 2.02, -2.09, -1.05, -0.9, -1.35, -0.66, 0.57, 0.29, -0.67, -0.69, -0.55, -0.22, -0.81, -0.55, -1.07, -0.72, 2.22, -1.89, -0.85, -0.7, -1.15, -0.45, 0.16, 0.18493619921617344, 0.02, 0.15, 0.48, -0.11, 0.15, -0.38, -0.03, 2.94, -1.21, -0.16, -0.01, -0.46, 0.24, 0.2, 0.31, 1.77, -0.23, -0.12, 0.33, -0.26, 0.0, -0.53, -0.17, 2.79, -1.35, -0.3, -0.16, -0.61, 0.09, 0.49, -0.45, -0.16977210884353744, -0.33, -0.85, -0.5, 2.45, -1.68, -0.63, -0.48, -0.93, -0.23, -0.03, 1.19, -1.15, 0.14, 0.26, -0.27, 0.09, 3.06, -1.09, -0.04, 0.11, -0.35, 0.36, -0.91, -0.12, -0.53, -0.17, 2.79, -1.35, -0.24737346264730647, -0.16, -0.61, 0.09, -0.16, -0.06, -1.12, 0.38, 0.31, 0.44, 0.4, 0.35, 3.33, -0.83, 0.39577825349253937, 0.37, -0.004012136584447365, 0.62, 0.05, 0.05, 2.97, -1.18, -0.13, 0.02, -0.43, 0.27, 0.37, 0.48, -0.34, 0.4, -2.56, 0.21806954949812107, 0.0, -1.4, 1.46, 0.73, 0.31406627346681526, 0.89, -2.49, -0.78, -0.37, 0.62, 0.07, 1.1, -1.1, -1.11, 0.37, -2.23, 0.76, 0.68, -0.35, 1.14, -0.68, -0.77, -1.17, 2.34, -2.83, -3.7028212224283656, -3.01, -2.86, -3.3, -2.62, 1.1, 1.25, 1.06, 1.21, 0.76, 1.47, 0.18, 0.15, -0.3, 0.4, 0.09, 0.11, 0.03, -0.45, 0.25, 0.35, 0.41, 0.58, -0.22, -0.66, 0.36, 0.14, 0.46, 0.48, 0.7, 0.5, 0.74, 0.22, -0.33, 0.45, -0.22, 0.81, 0.83, -0.24], ['431', 0.09, 0.53, 0.13122171562045873, 0.0, 0.36, 0.34, 1.0841152579598292, 0.74, 0.7, 1.28, 0.52, 0.9, 1.03, 0.15, 1.36, 0.97, 0.82, 1.2377619047619046, 0.31, 0.51, 1.23, 0.97, 0.47, 0.6, 1.6, 0.64, 0.76, 0.38, 0.51, -0.36, 0.84, 0.45, 0.3, 0.68, -0.21, -0.01, 0.71, 0.45, -0.04, 0.08, -0.65, 1.56, 0.37, 0.12, -0.74, 0.46, 0.07, -0.08, 0.3, -0.59, -0.39, 0.33, 0.07, -0.43, -0.3, 0.83, 0.72, 0.63, 0.53, 0.25, -0.87, 0.34, -0.05, -0.2, 0.18, -0.71, -0.51, 0.21, -0.05, -0.55, -0.42, 0.19, 1.13, 1.2246428571428571, 0.82, 0.67, 1.05, 0.16, 0.36, 1.08, 0.82, 0.32, 0.45, 1.1, 2.33, -2.33, -0.08, -0.39, -0.54, -0.16, -1.04, -0.84, -0.13, -0.39, -0.88, -0.76, 0.4226190476190476, 0.3, -0.15, 0.23, -0.66, -0.46, 0.26, 0.0, -0.5, -0.37, -0.07, 0.3024455782312925, -0.73427628811696, 0.46, 0.7, 0.23, 0.46, 0.38, -0.5, -0.31, 0.41, 0.15, -0.34, -0.16141531611693433, 0.34, 0.08, -0.88, -0.69, 0.03, -0.23, -0.72, -0.6, 1.06, 1.2, -0.15, 0.33, 1.26, 0.2, 0.14, 0.39, -0.46, -0.2, 1.14, 2.36, -1.48, -0.93, -0.49, 0.05, 0.79, 1.38, -1.4, -1.41, 0.46, 0.48, 0.89, 0.62, -0.29, 1.4, -4.61, -0.9, -1.45, 1.57, 0.97, 0.2, 0.92, 0.66, 0.16, 0.29, 1.29, 0.77, 0.72, 0.46, -0.04, 0.12571428571428572, 0.05, -0.26, -0.75, -0.63, 0.66, 0.77, 0.31, -0.49, -0.37, 0.46, 0.47, 0.66, -3.21, -0.09, 3.35, 0.03, 1.05, 0.8, 0.12, 0.43, -0.54, 0.83, 1.2, 0.76, 0.68, 0.26, 0.57, 0.63], ['432', 2.96, -0.03, 0.05122171562045875, 0.19, -0.69, -0.08, -0.12588474204017086, -0.26, -0.55, -0.66, 0.41, -0.66, -0.18, -0.53, 0.04, -1.21, -0.09, -0.63, 0.4, 0.21, -0.86, 0.35, 0.02, -0.07, -0.45, -0.41, -1.0373416050068875, -1.07, -0.59, -0.94, -0.37, -1.61, -0.5, -1.04, -0.01, -0.2, -1.27, -0.06, -0.39, -0.48, 0.17548536582465155, -3.2, 0.0, 0.48, 0.12, 0.7, -0.55, 0.57, 0.02, 1.06, 0.87, -0.18193453191355702, 1.02, 0.69, 0.59, -0.27, 0.11, 0.07, -0.22, -0.47, -0.35, 0.23, -1.03, 0.1, -0.45, 0.59, 0.4, -0.5165788457574171, 0.54, 0.21, 0.12, -0.12, -0.12, 0.58, -0.68, 0.45, -0.1, 0.94, 0.75, -0.33, 0.89, 0.56, 0.47, -1.5, -1.75, 1.78, -0.7, -1.25, -0.13, -0.67, 0.36, 0.17, -0.9, 0.31, -0.02, -0.11, -0.15, 0.637366531216563, 1.13, 0.58, 1.63, 1.44, 0.4126265373526935, 1.58, 1.25, 1.15, 0.05, 0.58, -1.43427628811696, -0.3, -0.43, -0.2, -0.57, -0.55, 0.49, 0.3, -0.78, 0.44, 0.11, 0.02, -0.95, -0.02, 1.04, 0.85, -0.23, 0.99, 0.66, 0.57, -0.33, 0.2, 0.2, -0.706813216376432, -0.39, 0.08, 0.24, 0.19, -0.06827987418743707, -0.05118982899237888, -0.32, -0.46, 1.74, 0.53, 0.24, 1.49, 0.11, -0.68, 0.85, 0.81, -0.29, 0.23, -0.57, -0.8, 0.38, -1.8, -0.97, 1.16, 1.86, -1.66, -1.05, -0.19, -1.26, -0.05, -0.37, -0.47, -0.85, -0.7356457669314812, -1.07, 0.14, -0.19, -0.28, 0.21, 1.22, 0.9, 0.8, -0.55, -0.81, -1.0, -0.32, -0.42, -0.3, -0.34, -0.23742395037612163, -0.83, -1.54, 0.7, -0.87, -1.41, -0.68, -0.09, -0.29, -0.07, 0.54, -0.41, 0.43, -0.59, -1.65, -2.86, -1.2], ['433', -2.32, -1.34, 0.0, -0.24, 0.37, -0.44, 0.7141152579598291, 0.0, 0.28, 1.3470884353741497, 1.22, 0.691934498041641, 0.58, 0.66, 1.86, 1.43, 1.74, 0.74, -2.89, 0.26, 1.21, 1.95, 2.15, 1.24, 0.44, -1.17, -0.32, -0.72, -0.6091666666666666, -0.55, 0.63, 0.2, 0.51, -0.48, -4.06, -0.95, -0.01, 0.72, 0.92, 0.02, -0.64, 2.17, 0.4, 0.09, 0.17, 1.36, 0.93, 1.24, 0.24, -3.36, -0.22880952380952382, 0.71, 1.45, 1.65, 0.74, -0.44, 0.22, -1.16, -0.13, 0.32, 0.08, 1.3848467679404526, 0.84, 1.15, 0.16, -3.45, -0.32, 0.62, 1.36, 1.56, 0.65, -0.49, 0.24, 1.19, 0.76, 1.07, 0.08, -3.52, -0.4, 0.54, 1.28, 1.48, 0.57, 0.83, -3.23, 3.29, -0.95, -0.43, -0.12, -1.1, -4.66, -1.57, -0.64, 0.09, 0.28, -0.61, -0.47, -0.52, 0.31, -0.68, -4.25, -1.15, -0.22, 0.52, 0.8511089783232642, -0.19, 0.12097959183673469, -0.57, -4.09, -0.53, -0.69, -0.59, -0.83, -0.98, -4.55, -1.45, -0.52, 0.21, 0.47598786341555266, -0.49, -1.02, 0.16, -3.6, -0.47, 0.47, 1.21, 1.4, 0.5, -1.8610416300368755, -1.7, -0.71, -1.26, -1.58, -0.15, -0.07, 0.19, -0.23, -0.17, -0.58, 1.08, -1.21, 0.95, 0.54, -1.16, -0.11, -1.94, 1.96, 1.59, -0.52, 0.26, -1.03, 1.5, -0.84, -2.48, -0.19, 1.57, 2.56, 1.29, 3.9, 3.24, 4.22, 4.98, 5.18, 4.25, -1.6, 0.64, 0.94, 1.69, 2.2994625850340134, 0.9814285714285714, -0.3, 0.74, 0.93, 0.03, 0.26, 0.31, -1.03, 0.19, -0.6277512446849837, -0.61, -0.7, -0.09, -0.93, -2.92, 0.96, -0.85, -0.85, -1.22, -0.89, -1.48, -0.11, -0.12, 0.16, -0.11, -0.34, -1.64, -1.85, -0.88], ['434', -2.95, 0.59, 0.011221715620458745, 0.0, -0.61, 1.03, -0.07, 0.72, 0.77, 1.26, 0.27, 1.56, 0.55, 1.14, 0.26, 2.4, -0.03, 1.2, 0.99, 1.1, 1.44, 0.57, 0.04, -0.18, 0.68, 0.72, 0.99, 1.28, 0.29, 1.01318993704708, -0.01, 2.13, -0.3, 0.93, 0.72, 0.83, 1.17, 0.3, -0.22, -0.45, 1.94, 1.3, -0.3, -0.99, -0.4, -1.28, 0.83, -1.56, -0.35, -0.56, -0.44, -0.12, -0.97, -1.49, -1.71, 1.09, 1.1, 0.67, 1.03, 0.7, 0.59, -0.3, 1.84, -0.58, 0.64, 0.43, 0.55, 0.88, 0.01, -0.51, -0.73, 1.08, 0.11, -0.88, 1.24, -1.16, 0.05, -0.15, -0.032285714285714286, 0.29, -0.57, -1.09, -1.31, 1.4, 3.45, -3.25, 1.0366982383853203, 2.14, -0.29, 0.94, 0.73, 0.85, 1.18, 0.31, -0.21, -0.44, -1.93, -1.12, -2.38, -1.18, -1.38, -1.27, -0.94, -1.79, -2.3, -2.53, 0.24, -1.13, 1.85, 1.07, 1.15, 1.08, 1.29, 1.23, 1.02, 1.14, 1.47, 0.6, 0.08, -0.15, 0.78, 0.06, -0.21, -0.09, 0.24, -0.62, -1.14, -1.37, 1.02, 1.169561224489796, 0.07, 1.43, -5.57, 0.08, 0.02, -2.14, 2.14, 1.1088101710076212, 0.75, 0.18, -0.27, -2.12, -1.04, -1.48, 0.8, 3.19, -3.23, -3.19, 1.06, -3.24, 2.12, -0.21, 0.12, 3.71, -9.67, -2.43, -3.71, 0.31, 0.26, 0.11, 0.44, -0.42, -0.94, -1.16, 3.25, 0.15, 0.33, -0.53, -1.05, -1.27, -0.18, -0.86, -1.37, -1.6, 0.85, 1.05, 0.68, -0.52, -0.6777512446849837, 1.07, 1.1, 0.62, -5.17, 1.95, 5.25, 1.69, 1.31, 1.21, -0.23, 1.66, 0.71, 0.5, 0.87, 1.06, 1.44, 0.98, 1.97, 1.57], ['435', -1.93, -0.55, 0.25122171562045875, -0.04, -0.55, -0.16, -0.69, -0.91, -0.78, -1.34, -0.88, -0.92, -0.82, -0.41, -0.05, -0.19143990929705207, -1.23, -1.14, -2.46, -0.62, -1.67, -1.6, -0.72, -1.23, -0.31, -0.03, -0.47, -0.04, 0.06, 0.47, 0.83, 0.6850357142857143, -0.36, -0.27, -1.59, 0.26, -0.8, -0.73, 0.16, -0.35, -1.16, -2.11, -0.43, 0.1911974674961171, 0.6878753944468231, 0.88, 0.42, -0.31, -0.22, -1.55, 0.31, -0.76, -0.68, 0.21, -0.31, -0.28, -0.59, -0.47, -0.79, -0.53, 0.41, 0.77, 0.31, -0.42, -0.33, -1.66, 0.20023809523809524, -0.86, -0.79, 0.10273474541331684, -0.41, -0.83, -0.94, 0.36, -0.1, -0.82, -0.74, -2.06, -0.21, -1.27, -1.19, -0.31, -0.82, -1.43, -1.51, 1.4793333333333334, -1.29, -0.45, -1.18, -1.09, -2.41, -0.56, -1.62, -1.55, -0.66, -1.1159922724755493, 2.84, -0.84, -0.73, -0.64, -1.96, -0.11, -1.17, -1.1, -0.21, -0.72, -0.21, -0.96, 1.09, -0.15, -0.24, -0.04, -0.11, 0.09, -1.24, 0.62, -0.45, -0.37, 0.52, 0.01, 0.22, -0.2, -1.33, 0.53, -0.53, -0.33420045034330736, 0.43, -0.08, -0.96, -1.11, -0.23, -0.11, 8.07, -0.14, -0.21, 0.0, 0.01, -0.02, 0.43, -1.57, 1.53, 0.37, 0.6182806122448982, -0.89, 0.04, -0.49, 0.49, 0.51, -0.15, 0.0, -0.29, 0.17, -0.14, -0.43, 2.992107142857143, 0.28, 0.45, -1.44, 1.14, 1.89, 0.81, 0.88, 1.78, 1.26, -0.51, -0.73, -1.06, -0.99, -0.1, -0.61, 0.33, 0.07, 0.97, 0.45, -0.85, -1.04, 0.26, 0.89, 0.38, -0.13, -0.12, -1.02, 1.11, 0.61, -1.14, -0.04, -0.11, -0.63, -0.51, -0.4, 0.35, -0.06, 0.39, -0.46, -0.12, 1.41, 0.32, 0.65], ['436', -0.64, -0.29, 0.03, 0.03, 0.48, 0.35, 0.0, 0.4, 0.79, 1.49, 0.5, 1.25, 1.06, 2.17, 0.48, 1.2, 0.88, 1.43, -1.33, 0.98, 1.9, 0.87, 1.19, 1.44, -0.33, 0.85, 1.0226583949931125, 0.75, 0.56, 1.66, -0.01, 0.7, 0.38, 1.0472589041444085, -1.82, 0.48, 1.4, 0.37, 0.69, 0.9738417231978392, 0.05, 1.5549361992161734, 0.24, -0.19, 0.9, -0.76, 0.04052947845804987, -0.37, 0.18, -2.55, -0.27, 0.64, -0.37, -0.06, 0.18, -0.27, 0.37, -0.04, 1.88, 0.43, 1.09, -0.57, 0.14, -0.18, 0.37, -2.37, -0.08, 0.84, -0.18, 0.13, 0.37, -0.02, -0.66, -1.65, -0.94, -1.26, -0.72, -3.42, -1.16, -0.26, -1.27, -0.8169045181009466, -0.71, 1.09, 1.04, -1.13, 1.0, 0.72, 0.39, 0.94, -1.81, 0.49, 1.41, 0.39, 0.7, 0.95, 1.57, 0.29, -0.32, 0.23, -2.51, -0.23, 0.69, -0.3036053391053391, -0.01, 0.23, 0.06, 0.32, 1.4, 0.31, 0.37, 0.28, 0.61, 0.55, -2.19, 0.1, 1.02, 0.0, 0.31, 0.55, 0.56, 0.06, -2.476314419707277, -0.45, 0.46, -0.55, -0.24, 0.0, 0.19, 0.53, 0.08, 0.49, 4.59, 0.18, 0.2, -0.41, 0.4, 0.22, 0.45, 0.56, -1.12, -0.62, -0.29, -0.32, 0.17, 0.9, -0.99, -0.95, 0.32, -0.59, 0.63, -0.09, 0.06, 1.8, -0.75, -1.29, -1.89, 1.07, 2.86, 2.34, 3.28, 2.23, 2.56, 2.8, 0.93, 0.51, 0.92, -0.1, 0.21, 0.46, -0.4, -1.01, -0.7, -0.46, 0.93, 1.22, 0.62, 0.31, 0.56, 0.4220800343140569, 0.35, 0.44, -0.68, 0.88, 0.66, 0.43, 1.04, 0.3, 0.24, 0.21, 0.51, 0.21, 0.12, -0.16, 0.06, 0.27, 2.23, 0.55], ['437', 1.18, -0.18, 0.08, 0.12, -0.56, -0.17, -0.14, -0.9, -0.83, -1.03, 0.03, -0.84, -0.4, -0.17, 0.71, -1.88, -0.68, -0.96, -2.64, -1.09, -1.6, -0.52, -0.16, -0.39, -1.08, -0.63, -1.0273416050068875, -0.8694545454545455, -0.43, -0.2, 0.68, -1.9, -0.71, -0.98, -2.67, -1.12, -1.63, -0.55, -0.19, -0.41, -1.38, -1.45, -0.19, 0.44, 0.67, 1.56, -1.05, 0.16, -0.12, -1.82, -0.25, -0.77, 0.32, 0.68, 0.46, -0.56, -0.8, -0.97, -0.38, -0.63, 0.23, 1.12, -1.48, -0.28, -0.56, -2.25, -0.69, -1.21, -0.12, 0.24, 0.01, -0.54, -0.86, 0.88, -1.71, -0.51, -0.79, -2.47, -0.6008690476190477, -1.43, -0.35, 0.01, -0.22, -1.17, -2.2, 2.22, -1.73, -2.57, -1.39, -1.66, -3.33, -1.79, -2.3, -1.23, -0.87, -1.09, 0.34, 0.86, 1.22, 0.94, -0.78, 0.8, 0.28, 1.38, 1.8911089783232642, 1.52, -0.03, 0.84, 0.25, -0.41, -0.45, -0.31, -0.35, -0.28, -1.97, -0.41, -0.92, 0.16, 0.52, 0.3, -0.38, -0.07, -1.7, -0.13, -0.65, 0.44, 0.8, 0.58, -0.85, -0.88, 0.23, -0.18, 1.3, -0.02, 0.03, 0.27, -0.31, -0.16, 0.13, -2.6, -0.15, 0.83, 0.36, 0.58, -0.21692021013122098, -1.22, 1.12, 1.18, -0.42, 0.38, -0.81, -1.11, 0.54, -1.03, 5.06, 0.76, 1.08, 0.05, 1.65, 1.59, 1.07, 2.18, 2.546751700680272, 2.31, -1.24, 0.06, -0.52, 0.57, 0.94, 0.71, 0.58, 1.1, 1.46, 1.23, -0.78, -0.99, -0.4227253150925656, 0.36, 0.14, -0.4, -0.4, -0.8174239503761216, 2.83, 0.3403332627840632, -2.84, -0.72, -0.53, -0.791362551799029, -0.22, -0.34, 0.07, -0.23, -0.31, -0.4, -0.65, 0.02, 0.03, -0.32], ['438', -3.11, 1.0, -0.12, 0.24, 0.25, -0.06158037632624053, 1.87, 0.32, 0.53, 0.99, 0.79, 0.0, 1.33, -0.65, 0.92, 1.32, 1.35, 1.07, 2.97, -0.9, 1.06, 0.76, 1.05, 1.15, -0.04, 0.32, 0.2, -0.79, 0.54, -1.28681006295292, 0.13, 0.53, 0.56, 0.28, 2.16, -1.68, 0.27, -0.03, 0.26, 0.36, 0.0, 0.99, 1.0, 1.34, -0.65, 0.93, 1.33, 1.36, 1.07, 2.97, -0.9, 1.07, 0.77, 1.06, 1.15, 0.07, -0.22, -0.67, 0.33, -0.34, -1.96, -0.41, -0.01, 0.02, -0.26, 1.61, -2.21, -0.27, -0.56, -0.28, -0.18, 0.48, 1.66, 1.59, 1.99, 2.02, 1.73, 3.64, 0.0691309523809524, 1.73, 1.42, 1.72, 1.81, 0.68, -0.07, 0.0, 0.0708709226619941, 0.4, 0.43, 0.14, 2.02, -1.81, 0.14, -0.16, 0.13, 0.27400772752445063, -0.76, -0.33, 0.03, -0.25, 1.62, -2.2, -0.26, -0.55, -0.27, -0.17, 0.0, -0.34, -0.37, -0.89, -0.92, -0.82, -0.36, -0.28, 1.59, -2.23, -0.29, -0.58, -0.3, -0.2, -1.14, -0.01692325186963274, 1.88, -1.95, 0.0, -0.1742004503433073, -0.01, 0.08, 0.04, 0.42, 0.4060371788780404, 0.2, -2.32, 0.15, -0.14, 0.31, -0.39, -0.18, -2.08, -0.33, -3.65, 0.54, 0.25, -1.53, -0.28, -0.75, 0.74, 0.77, -0.24, 0.46, -0.48, -0.96, 0.48, 1.48, 5.66, -1.09, -1.46, 3.73, -1.92, -3.76, -1.85, -2.14, -1.853248299319728, -1.76, -0.74, 1.91, 1.98, 1.68, 1.97, 2.07, -0.07, -0.3, -0.01, 0.09, 0.58, 0.45845354645354663, 0.23, 0.29, 0.38, -0.28, -0.10560369872470916, 0.33, 3.39, 0.3, -3.4, -0.1027361894755667, -0.08, -0.06, 0.1, -0.06, -0.07, -0.67, -0.46, -0.63, -0.074042472976186, -0.4, -0.14, 0.36], ['439', 4.62, 0.13, 0.13, -0.2, 0.03, 0.43, 1.0841152579598292, -0.35, 1.05, -0.4, -1.5196815287886714, -2.03, -0.48, -0.37, -0.38, -1.78, -1.7028571428571428, -0.93, -2.54, -2.08, -0.01, -0.37, -1.16, -1.3378253968253968, 0.08, 0.96, 1.35, -0.31, 1.2714285714285714, 1.38, 1.38, -0.05, -0.01, 0.81, -0.82, -0.36, 1.75, 1.39, 0.58, 0.44384172319783916, 0.43, 2.03, 1.66, 1.59, 1.7, 1.69, 0.2764030612244898, 0.3, 1.13, -0.51, -0.05, 2.06, 1.7, 0.89, 0.71, -0.87, -0.49, -1.6, 0.19, 0.07, 0.11, 0.1, -1.31, -0.5985714285714286, -0.45, -1.7803066893424033, -1.61, 0.47, 0.1259625850340136, -0.69, -0.87, -0.15, -0.03, -0.009285714285714286, -0.9733418367346938, -1.37, -0.56, -2.1669047619047617, -1.72, 0.36, 0.0, -0.8, -0.97, 1.19, 1.85, -1.85, -0.03, -1.41, -1.37, -0.56, -2.17, -1.71, 0.36, 0.01, -0.79, -0.97, 1.1812233560090704, 1.4, 0.04, 0.86, -0.77, -0.31, 1.79, 1.44, 0.63, 0.45, 0.35, 1.3, 0.43, 0.88, 0.94, 1.05, 1.36, 0.82, -0.81, -0.35, 1.75, 1.39, 0.59, 0.41, -0.11, 0.53, -1.62, -1.16, 0.92, 0.57, -0.031428571428571445, -0.41, 1.47, 1.62, -0.29, 1.24, 2.02, 0.04, 0.15, -2.31, 2.33, 1.17, 0.53, -0.67, -3.35, -1.75, -0.89, 2.45, 0.43, 2.9, -2.74, -2.72, 0.88, -3.47, 1.79, 2.83, -1.38, 4.1, -0.16, -2.79, -4.08, 3.39, 2.19, 0.47, 2.59, 2.23, 1.41, 1.23, 2.61, 1.71, 2.11, 1.75, 0.94, 0.76, -0.36773809523809525, -0.35, -1.15, -0.6785714285714286, 1.07, 0.61, -0.04, -0.8, -0.98, 0.81, 0.97, -0.17, 0.0, 1.29, -0.15, 1.73, 0.57, 0.77, -0.18, 1.75, 1.17, 0.1, 0.18, 0.87, 0.95, 2.02, 0.93, 1.54], ['440', 2.49, -0.01, 0.05122171562045875, -0.21, 0.11, 0.04, 1.424115257959829, 1.05, 0.52, 0.92, 0.35, 0.241934498041641, 1.24, -0.44, 0.14, 0.25, 0.7, 0.72, 0.92, 0.67, 0.83, 1.66, 0.73, 0.97, 0.78, 0.84, 0.58, -0.3, 0.89, -0.79, -0.2, -0.09, 0.35, 0.38, 0.58, 0.32, 0.48076068376068376, 1.31, 0.39, 0.62, 0.8, -0.48, 0.88, 1.1936589811608609, -0.48, 0.1, 0.21, 0.66, 0.68, 0.88, 0.63, 0.79, 1.62, 0.69, 1.2308287981859412, 0.87, 0.75, 0.08, 0.86, -0.31, -1.66, -1.08, -0.97, -0.53, -0.51, -0.31, -0.56, -0.4, 0.42, -0.5, -0.27, 2.31, 1.37, 0.59, 0.7, 1.15, 1.17, 1.37, 1.12, 1.28, 2.11, 1.18, 1.42, 0.13, 0.25, -0.34, 0.78, 0.11, 0.56, 0.58, 0.78, 0.53, 0.69, 1.52, 0.59, 0.82, 2.68, 0.67, 0.44, 0.47, 0.67, 0.41, 0.58, 1.41, 0.48, 0.71, 0.22, 0.66, -1.73, 0.23, 0.34, 0.06, 0.22, 0.02, 0.22, -0.03, 0.13, 0.96, 0.03, 0.3285846838830657, -0.75, 0.2, 0.2, -0.05, 0.11, 0.93, 0.01, 0.24, 0.7, 0.48, -0.23, 0.02, 8.12, 0.02, -0.07, -0.46, 0.46, 0.23, -0.29, 0.11, -0.48, -0.48, -0.2, 1.24, 0.22, 0.69, -0.77, -0.74, 0.24, -0.66, 0.48, 1.33, -0.65, 0.62, -3.75, -0.35, -0.71, 0.45, 0.0, -0.25, -0.09, 0.73, -0.19, 0.04, 0.63, 0.25, 0.16, 0.99, 0.06, 0.3, 0.09, 0.83, -0.1, 0.13, 0.51, 0.39, -0.73, -0.92, -0.68, 0.14, 0.22, 0.99, -1.92, -0.73, 1.88, -0.29, 0.62, 0.19, 0.23, 0.26, -0.1, 0.6, 0.08, 0.79, -0.04, 0.63, 0.63, -0.06], ['441', -4.94, 0.19, 0.011221715620458745, -0.24, -0.10702091900894042, 1.31, 0.6941152579598292, 1.75, 2.14, 0.63, -1.54, -0.2, -0.48, -1.78, -0.05, 1.49, -0.31, 0.24, 2.92, -0.84, 1.59, -0.42, -1.79, -0.62, 2.0, 1.46, 2.21, 1.36, 1.07, -0.24, 1.52, 3.08, 1.25, 1.8, 4.547761904761905, 0.71, 3.17, 1.14, -0.25, 0.93, 1.26, 4.97, 0.84, -0.28, -1.58, 0.16, 1.7, -0.11, 0.44, 3.12, -0.64, 1.79, -0.22, -1.59, -0.42, 1.34, 1.87, 1.78, 2.2699285714285713, 1.12, -1.3, 0.44, 1.98, 0.17, 0.72, 3.41, -0.36, 2.08, 0.06, -1.31, -0.14, 0.82, 2.45, 1.76, 3.33, 1.49, 2.05, 4.78, 0.96, 3.42, 1.38, -0.01, 1.18, 3.3, 6.37, -6.3, 0.68, 1.54, -0.27, 0.28, 2.96, -0.79, 1.7952352330209473, -0.37, -1.74, -0.57, -0.48, -0.85, -1.78, -1.24, 1.4, -2.3, 0.09, -1.88, -3.23, -2.08, 0.49, -0.89, 0.42572371188304003, 1.46, 1.77, 1.05, 0.95, 0.55, 3.24, -0.53, 2.0857782534925393, -0.11, -1.48, -0.25141531611693435, 1.1265360710717855, 0.4, 2.67, -1.07, 1.35, -0.65, -2.02, -0.85, 2.23, 1.93, -0.29, 1.04, -0.92, 0.46, 0.35, -1.73, 1.74, 0.85, 0.05, 2.82, -2.87, -2.95, -1.45, -2.53, 1.24, 4.2, -4.18, -4.29, 1.47, -2.57, 2.92, 2.15, -1.05, 2.79, -9.91, -1.86, -2.76, 2.93, -2.22, -3.65, -1.29, -3.24, -4.57, -3.44, 4.41, 1.48, 2.44, 0.42, -0.96, 0.22, -0.94, -1.98, -3.32, -2.17, 2.17, 2.57, 1.1472746849074344, -1.37, -0.2, 1.38, 1.31, 1.58, -5.17, 0.45, 5.12, 1.13, 1.86, 2.47, 1.19, 1.58, 0.83, 0.95, 1.55, 1.88, 1.26, 0.84, 0.91, 0.86], ['442', 1.49, 0.32, -0.22877828437954126, 0.04, 1.09, 0.15, -0.8358847420401708, -1.05, -2.12, -1.06, 1.68, -0.67, -1.21, -0.62, -0.23, -1.39, -1.55, -0.86, 0.7114818594104309, -2.83, -1.11, -1.58, -1.39, -1.11, -1.44, 0.07, -2.7, -2.31, -2.84, -2.11681006295292, -1.88, -3.02, -3.18, -2.5, -0.97, -4.44, -2.74, -3.21, -3.02, -2.75, -1.1, -3.0450638007838267, -0.39, -0.54, 0.05, 0.45, -0.72, -0.88, -0.19, 1.38, -2.17, -0.44, -0.92, -0.72, -0.44, -0.82, -1.91, -0.6, -2.52, 0.15, 0.6, 0.99, -0.18, -0.34, 0.35, 1.93, -1.64, 0.1, -0.38, -0.18, 0.1, -0.36, -0.45, 0.39, -0.78, -0.94, -0.25, 1.32, -2.23, -0.49, -0.97, -0.77, -0.5, -2.49, 0.98, -1.03, -0.8033017616146798, -1.16, -1.32, -0.64, 0.92, -2.61, -0.88, -1.36, -1.16, -0.89, 2.36, 0.33, -0.16, 0.53, 2.11, -1.46, 0.28, -0.2, 0.0, 0.28, -0.13, 0.33, 1.41, 0.2, 0.33, 0.20567351865003197, 0.5, 0.7, 2.28015873015873, -1.3, 0.45, -0.03, 0.16, 0.44, 0.61, -0.2, 1.57, -1.99, -0.25, -0.6042004503433073, -0.53, -0.25, 0.08, 0.08, 0.08, 0.46, 4.75, 0.11, 0.21, -0.17, 0.16, 0.07, 0.94, -0.24, -3.83, -0.33, -0.17, 0.84, -0.04, 0.6514761904761905, -0.65, -0.49, 0.19, -0.23, 0.33, 0.09, 0.0, 1.45, -2.47, -1.02, -1.46, 3.86, -1.74, -3.5, -1.79, -2.26, -2.07, -1.79, 0.53, 1.82, 1.77, 1.29, 1.48, 1.77, 0.05, -0.48, -0.28, 0.0, -0.27, -0.59, 0.53, 0.2, 0.48, 0.17, 0.27, 0.02, -1.07, 0.61, 1.3, 0.5, 0.95, 0.33, 0.28, 0.33, 0.04, -0.29, -0.12, -0.03, 0.05, 1.7, 1.31, -0.11], ['443', -0.76, -0.56, 0.011221715620458745, 0.01, 0.11, 0.12, -0.59, 0.29, -0.08, -0.29, 0.19, 0.09, -0.02, -1.63, -0.61, -0.33, -0.26, -0.39, 1.36, -0.06, -0.42, 0.61, -0.26, 0.22, 0.68, -0.11, -0.48, -0.1, -0.21, -1.82, -0.8, -0.52, -0.45, -0.58, 1.17, -0.25, -0.61, 0.42, -0.44, 0.04, 0.17, -0.47, -0.38, -0.11, -1.72, -0.7, -0.42, -0.35, -0.48, 1.27, -0.15, -0.51, 0.51, -0.35, 0.13, 0.21, -0.34, 0.48, 0.71, -0.27, -1.61, -0.59, -0.31, -0.25, -0.37, 1.38, -0.04, -0.4, 0.63, -0.24, 0.24, 0.32, 1.36, 1.03, 1.32, 1.39, 1.26, 3.04, 1.6, 1.23, 2.27, 1.4, 1.89, -0.52, 0.01, 0.09, 0.3666982383853202, 0.28, 0.35, 0.23, 1.98, 0.56, 0.19, 1.23, 0.36, 0.84, 0.97, 0.04, 0.07, -0.06, 1.7, 0.27, -0.09, 0.94, 0.08, 0.56, 0.21, 0.03, 0.65, 0.08, 0.19, 0.07567351865003197, -0.03, -0.13, 1.63, 0.2, -0.16, 0.87, 0.01, 0.49, -0.79, 0.1, 1.75, 0.33, -0.03, 1.1257995496566926, 0.13, 0.62, 0.18, 0.11, -0.18, 0.09, 2.91, 0.01, 0.05, 0.0, -0.02, -0.02, -0.03, 0.32, 0.45, -0.15, -0.09, -0.38, 0.04, 0.22, -0.26, -0.21, 0.07, -0.08, 0.14, 0.59, -0.24, -0.07, -3.45, 0.03, 0.05, -0.37, -1.63, -1.4, -1.76, -0.74, -1.59, -1.12, 0.22, -0.23, -0.36, 0.7557142857142858, -0.2, 0.28, 0.13, 1.03, 0.17, 0.65, 0.02, 0.04, -0.89, -0.86, -0.38, 0.09, 0.07, 0.4525760496238784, -2.01, 0.3711163791806698, 2.03, 0.25, 0.17, -0.03, 0.48, -0.14, 0.15, 0.53, -0.24, 0.34, -0.51, 0.26, 0.26, 0.34], ['444', 1.57, -1.29, -0.06877828437954125, -0.05, -0.57, -0.53, -3.31, -1.13, -0.8506219456129893, -0.65, -0.05, 1.31, -0.45, 2.63, 0.89, -1.39, 0.12, -0.34, 0.87, 1.11, 0.0, 1.5, -0.98, 0.04, -0.35, 0.25, -0.61, 1.36, -0.4, 2.68, 0.94, -1.35, 0.17, -0.29, 0.92, 1.16, 0.05, 1.55, -0.94, 0.09, -1.85, 0.0, -1.94, -1.73, 1.31, -0.41, -2.67, -1.17, -1.63, -0.43, -0.2, -1.29, 0.19, -2.27, -1.25, -0.72, -1.36, -0.14, -0.91, -0.21, 3.1, 1.35, -0.95, 0.57, 0.11, 1.32, 1.57, 0.45, 1.96, -0.54, 0.49, 0.26, -3.2, -1.7, -3.92, -2.45, -2.9, -1.72, -1.48, -2.57, -1.11, -3.53, -2.52, -0.51, 0.15, -0.22, -1.53, -2.27, -0.76, -1.22, -0.02, 0.22, -0.88, 0.6, -1.86, -0.84, 2.75, 0.75, 1.54, 1.07, 2.3, 2.54, 1.41, 2.93, 0.41, 1.46, -0.42, 0.78, -2.36, -0.45, -0.3, -0.69, -0.78, -0.46, 0.75, 0.99, -0.12, 1.37, -1.11, -0.08, -1.94, -0.32, 1.21, 1.46, 0.34, 1.85, -0.65, 0.38, 0.18, 0.05956122448979598, -0.04, -0.57, 8.17, -0.35, -0.57, 0.63, -0.61, -0.31, -0.07, -1.38, 3.38, 0.88, 0.42, 0.78, -1.36, -1.32, 1.39, 1.37, -0.44, 0.91, -0.88, -1.22, 0.62, -2.29, 1.94, 1.48, 2.28, -3.44, -1.51, 0.24, -0.86, 0.62, -1.84, -0.82, -1.24, -1.75, -1.1, 0.38, -2.07, -1.06, -0.66, 1.5, -0.99, 0.04, -0.97, -0.69, -2.12, -2.45, -1.43, -0.42, -0.52, -1.19, 1.36, -1.85, -0.9107193877551023, -0.22, -0.1, 0.33, 1.04, -0.24, -0.08, -1.56, -1.33, -1.31, -0.7, -0.58, 0.15, -0.47], ['445', 2.74, -0.2, -0.17, 0.01, 0.18, -0.36, 0.4841152579598291, -1.08, -0.26, -0.25, 0.33, -0.5506751700680272, 0.76, 1.55, 1.68, -0.08, 0.24, -0.08, 0.91, -0.4, 0.16733548208735893, 1.88, 0.92, 0.39, -0.64, -0.96, -0.5473416050068876, -0.89, 0.43, 1.21, 1.35, -0.4, -0.09, -0.41, 0.58, -0.73, -0.19, 1.55, 0.58, 0.06, -1.12, 0.34493619921617347, 0.31, 1.33, 2.12, 2.26, 0.49, 0.81, 0.48, 1.49, 0.16, 0.7, 2.46, 1.5871428571428572, 0.96, -0.3876426685347185, -1.26, -0.78, -0.98, -1.0, 0.78, 0.92, -0.83, -0.51, -0.83, 0.15, -1.15, -0.62, 1.11, 0.16, -0.37, -0.83, -1.77, 0.14, -1.5367057823129253, -1.28, -1.6, -0.62, -1.92, -1.39, 0.33, -0.62, -1.14, 0.18, -3.53, 3.53, -1.9, -1.73, -1.42, -1.73, -0.76, -2.05, -1.52, 0.2, -0.75, -1.27, 1.04, -0.18, 0.32, -0.01, 0.99, -0.33, 0.21, 1.96, 1.1311089783232642, 0.47, -0.14, -0.23, 0.0, -0.6, -0.86, -0.42, -0.49, -0.32, 0.67, -0.64, -0.11, 1.64, 0.67, 0.15, -1.99, -0.17, 1.0, -0.32, 0.22, 1.96, 1.0, 0.47, -1.1781719617057962, -1.76, -0.13, -0.91, 1.92, -0.43, -0.29, -0.92, 0.9, 0.46, -0.74, -0.46, -0.5, 1.22, 0.62, 1.34, -0.58, -1.8, 1.91, 1.83, -0.61, -1.32, -1.44, 0.46, -0.2, -1.42, 3.62, 0.96, 1.36, 0.4, -1.1416360544217685, -1.3, -0.77, 0.96, 0.0, -0.52, -1.87, 0.15, 0.54, 2.5371428571428574, 1.32, 0.79, -0.39, 1.74, 0.78, 0.26, -0.19, -0.36, -2.09, -0.95, -1.46, -0.4779199656859431, -0.65, -1.05, 1.84, -0.28, -1.85, -1.96, -1.45, -1.16, -0.52, -1.56, 0.64, -0.29, -0.35, -0.92, -0.64, -2.03, -0.65, -0.71], ['446', -0.75, 0.51, 0.07015289830927054, -0.07, -0.25, -0.3, 1.61, 1.36, 0.56, 1.35, 1.27, 0.64, 0.84, 0.28, -1.88, 0.68, 0.48, 1.33, 2.08, 1.87, 1.22, 0.31, 0.15, 0.32, -0.04, 0.16, 0.11265839499311246, -0.63, -0.43, -0.97, -3.11, -0.58, -0.78, 0.06, 0.8, 0.59, -0.05, -0.95, -1.11, -0.93, 1.99, 1.6849361992161733, 0.71, 0.2, -0.35, -2.5, 0.04, -0.16, 0.69, 1.43, 1.23, 0.58, -0.33, -0.49, -0.31, 0.06, 0.5, 2.74, 0.41, 0.52, -0.55, -2.69, -0.15, -0.35, 0.49, 1.2471802721088434, 1.03, 0.38, -0.52, -0.68, -0.51, 0.82, 1.07, -2.16, 0.39, 0.2, 1.04, 1.79, 1.58, 0.93, 0.02, -0.14, 0.04, 0.78, 3.18, -3.27, 3.3, 2.61, 2.4, 3.27, 4.03, 3.82, 3.16, 2.23, 2.06, 2.25, -0.04, 0.67, -0.2, 0.65, 1.39, 1.18, 0.54, -0.37, -0.53, -0.35, 0.0, 0.63, 2.58, 0.61, 0.65, 0.72, 0.87, 0.85, 1.59, 1.38, 0.74, -0.17, -0.33, -0.15, 0.83, 0.02, 0.74, 0.53, -0.11, -1.01, -1.17, -0.99, 1.18, 1.2, 0.0, 1.343186783623568, -0.24, 0.04, 0.05, -2.39, 2.43, 1.24, -0.15, -0.19, 1.17, -1.24, -0.64, -0.29, 0.83, 1.82, -1.88, -1.92, 0.6, -3.7, 1.23, 0.4, -0.25, 2.6, -8.33, -1.85, -2.62, -1.07, -0.71, -0.2, -0.84, -1.73, -1.89, -1.72, 1.79, -0.5098412698412699, -0.64, -1.53, -1.69, -1.52, 0.13, -0.9, -1.06, -0.88, 0.56, 0.6, 1.05, -0.16, 0.09224875531501633, 0.61, 0.71, 1.35, -5.0, 2.28, 4.72, 0.86, -0.66, 1.21, 0.18, 0.39, 0.03, 1.31, 0.62, 1.07, 1.03, -0.74, -1.08, 1.06], ['447', -8.49, 0.36, 0.05122171562045875, 0.08, -0.29, 0.37, 0.6541152579598292, 0.57, 0.61, -0.1, -0.63, -1.08, -0.36, -0.56, -0.89, 1.32, -0.65, -0.28, -2.81, -0.62, -0.01, -1.24, -1.21, -0.23, 0.56, -0.11, 0.53, -0.45, 0.27, 0.07, -0.27, 1.96, -0.02, 0.35, -2.2, 0.01, 0.62, -0.61, -0.59, 0.4, 0.89, 1.2, 0.98, 0.73, 0.53, 0.18, 2.43, 0.43, 0.81, -1.76, 0.46, 1.08, -0.16, -0.14, 0.86, 0.89, 0.55, 0.0, 0.61, 0.32924524706587754, -0.2, -0.54, 1.68, -0.29, 0.08, -2.47, -0.26, 0.35, -0.88, -0.86, 0.13, -0.13, 0.45, -0.34, 1.89, -0.09, 0.28, -2.27, -0.07, 0.55, -0.69, -0.5269045181009466, 0.33, 0.69, 3.05, -2.96, 0.8008709226619941, 2.24, 0.25, 0.62, -1.94, 0.28, 0.89, -0.35, -0.32, 0.67, -1.72, -1.41, -1.94, -1.58, -4.08, -1.92, -1.32, -2.53, -2.5, -1.53, 0.19, -1.42, 0.1, 0.43, 0.56, 0.26, 0.55, 0.37, -2.18, 0.22971268810554554, 0.8157782534925394, -0.59, -0.4940121365844473, 0.42, 1.05, 0.17, -2.54, -0.34, 0.27, -0.96, -0.94, 0.05, 0.46, 0.24, 0.13, 0.51, -5.2, 0.0, 0.05, -0.14, 0.11, 0.07, 0.29, 1.1961635321120496, -0.97, -0.91, -0.44, -4.22, 0.42, 1.36, -1.31, -1.31, 0.44, -0.2, 0.85, 0.27, -0.14, 1.72, 0.85, -1.1, -1.61, 1.1, 2.79, 2.26, 2.88, 1.62, 1.65, 2.66, 1.35, 0.52, 0.61, -0.62, -0.6, 0.39, -0.09, -1.23, -1.2, -0.22, -0.4, -0.33, 1.2372746849074343, 0.02, 1.02, 0.44, -0.28, -0.2974239503761216, 0.5, -0.19, -0.58, 0.64, 0.58, 1.12, 1.0, 0.34, 0.2, 0.55, 0.28, 0.2, 0.13, -0.09, 0.51, -0.16], ['448', -1.22, -0.18, -0.06, 0.23, -0.2, -0.02, 1.25, -0.31, -0.36, 0.9370884353741497, 0.970608843537415, -0.41, 0.41, 0.6, 0.76, 0.91, 0.57, 0.36, 1.66, 0.37, 0.35, 0.03, 0.87, 0.2, -0.57, -0.48, -0.42734160500688756, -1.35, -0.54, -0.35, -0.1421800287049088, -0.05, -0.39, -0.47274109585559154, 0.7, -0.58, -0.6, -0.92, -0.09, -0.75, 0.28, -1.06, 0.9, 0.82, 1.02, 1.17, 1.32, 0.98, 0.78, 2.08, 0.78, 0.77, 0.44, 1.28, 0.62, -0.9, 0.54, -0.22, -0.74, 0.15924524706587756, 0.19, 0.35, 0.5, 0.16, -0.05, 1.25, -0.04, -0.06, -0.38, 0.46, -0.21, -0.35, -0.11, 0.16, 0.3, -0.04, -0.24, 1.05, -0.23, -0.25, -0.57, 0.26, -0.4, -0.92, -1.11, 1.15, -0.23330176161467986, 0.15, -0.19, -0.39, 0.9, -0.39, -0.4, -0.72, 0.11, -0.55, -0.87, -0.41, -0.34, -0.54, 0.75, -0.54, -0.4873734626473065, -0.87, -0.04, -0.7, 0.16, -0.45, 2.61, 0.03, -0.11, 0.16, -0.0790429599640126, -0.2, 1.09, -0.2, -0.21, -0.53, 0.3, -0.36, 0.4, 0.13, 1.29, 0.0, -0.01, -0.33, 0.5, -0.16, -0.67, -0.35, 0.62, -0.08, -2.34, 0.0, 0.07, -0.94, 0.96, 0.47, -0.44, -1.28, -0.24, -0.08, -0.03, -0.56, 0.3, -0.01, -0.09, -0.17, 0.03, -1.33, 0.04, -1.06, 0.51, -0.38, 16.84, 0.28, 0.36, 0.24, -1.15, -1.27, -1.29, -1.6, -0.78, -1.44, 0.09, 0.12, -0.01, -0.34, 0.5, -0.16, 0.14, -0.32, 0.51, -0.15, -0.32, -0.83, 0.46, 0.84, 0.17, 0.06, 0.11439630127529085, -0.24, 7.56, 1.490333262784063, -7.7, 0.37, -0.73, -0.38, -0.66, 0.01, 0.3, 0.15, 0.63, 0.32, 0.29, 0.12, -1.29, 0.11], ['449', 3.584285714285714, -0.03, 0.13122171562045873, 0.1, 1.42, 0.8, 0.5641152579598292, 1.35, 1.33, 1.5, -0.14, 0.93, 1.78, 0.27, -0.04, 0.49, 0.62, 1.29, -1.67, -0.16, 1.947335482087359, 0.83, 0.96, 0.9, 1.73, 1.39, 1.65, 1.08, 1.93, 0.41, 0.1, 0.63, 0.77, 1.43, -1.53, -0.01, 2.06, 0.97, 1.1, 1.04, 0.79, 3.03, 0.56, 0.84, -0.66, -0.97, -0.44, -0.31, 0.35, -2.58, -1.08, 0.9980654680864429, -0.11, 0.02, -0.04, 0.7, 1.62, 2.217827972809784, 0.99, -0.28, -1.49, -1.79, -1.27, -1.14, -0.49, -3.4, -1.91, 0.12, -0.94, -0.81, -0.8605612244897959, 1.2436060011417156, 1.23, -0.2953571428571429, 0.22, 0.35, 1.01, -1.94, -0.42, 1.64, 0.55, 0.69, 0.62, 2.04, 1.59, -1.58, 1.54, 0.53, 0.66, 1.33, -1.63, -0.12, 1.95, 0.87, 1.0, 0.94, 1.7, 1.01, 0.13, 0.79, -2.15, -0.64, 1.41, 0.33, 0.47, 0.4, 0.15, 0.99, 0.22572371188304005, 0.84, 0.77, 0.9, 0.9418094764861292, 0.66, -2.28, -0.77, 1.28, 0.2, 0.33, 0.27, 0.61, 0.21, -2.92, -1.43, 0.62, -0.46, -0.33, -0.39, 0.4618280382942037, 0.45, 0.04, 0.86, 5.04, 0.32, 0.4, -2.33, 2.38, 1.19, 1.23, 0.23, -3.26, -1.64, -0.87, 1.6, 0.69, 2.53, -2.55, -2.49, 0.84, -3.56, 1.66, 0.03, -0.02, 2.62, -2.77, -1.79, -2.59, 3.26, 3.23, 1.54, 3.64, 2.54, 2.68, 2.61, 2.52, 1.66, 2.07, 0.98, 1.12, 1.05, -0.4, -1.07, -0.94, -1.0, 1.27, 1.52, 0.67, 0.13, 0.07, 0.84, 0.8, 1.31, -1.71, 0.3, 1.86, 1.27, 1.34, 0.54, -0.06, 0.61, 1.5, 0.37, 0.95, 0.61, 0.6, 1.8, 1.93, 0.44], ['450', 1.66, 0.38, 0.12, -0.04, 0.18, 0.56, 1.0041152579598291, 1.51, 1.2, 1.64, 0.46, 0.691934498041641, 0.57, -0.26, 0.24, 1.39, 0.44, 1.41, 2.91, 0.16, 1.96, 0.53, 0.64, 0.87, 1.72, 0.57, 1.2026583949931124, 0.02, 0.11, -0.72, -0.22, 0.92, -0.03, 0.95, 2.43, -0.3, 1.49, 0.07, 0.18, 0.4, 0.73, 0.8449361992161734, 1.14, 0.08, -0.74, -0.25, 0.89, -0.05, 0.92, 2.41, -0.33, 1.46, 0.04, 0.15, 0.38, 0.49, 1.67, 0.99, 1.22, 1.1392452470658776, -0.82, -0.33, 0.81, -0.13, 0.84, 2.32, -0.41, 1.38, -0.04, 0.07, 0.3, 1.85, 1.9, 0.5, 1.65, 0.7, 1.68, 3.17, 0.42, 2.22, 0.79, 0.9, 1.13, 0.94, 2.7, -2.63, 1.42669823838532, 1.15, 0.2, 1.17, 2.66, -0.08, 1.72, 0.29, 0.4, 0.63, -0.44, 0.25, -0.94, 0.03, 1.5, -1.21, 0.56, -0.84, -0.73, -0.51, 0.4, 0.24, 1.9001046511627906, 0.73, 0.68, 0.73, 1.19, 0.97, 2.46, -0.28, 1.52, 0.1, 0.2, 0.43, 1.09, 0.27307674813036725, 1.47, -1.24, 0.54, -0.87, -0.76, -0.29782256235827664, 0.87, 1.33, 0.24, 0.91, -1.55, 0.44, 0.62, -1.65, 1.8017201258125628, 0.84, 1.25, 2.96, -2.75, -1.39, -0.72, 0.82, 0.31, 2.14, -2.12, -2.16, 0.71, -2.45, 1.4, 0.47, -0.23, 3.65, -12.89, -2.49, -3.65, 2.81, -1.23, -2.67, -0.92, -2.31, -2.2, -1.98, 2.14, 1.47, 1.8, 0.37, 0.48, 0.71, -0.32, -1.4, -1.29, -1.07, 1.24, 1.29, 1.1, 0.11, 0.34, 0.76, 0.74, 1.62, -6.51, 1.55, 6.68, 0.49, 0.71, 0.99, 0.23, 1.0, 0.57, 0.43, -0.14, 0.78, 0.76, 0.04, 1.2415952380952382, 0.65], ['451', -12.94, -0.19, -0.5, 0.15, -3.29, -0.89, -0.25, -0.83, -0.88, -1.86, -0.96, -1.43, -0.66, -1.0, -0.88, 1.41, -0.54, -1.7, 2.7, 3.14, -2.03, -2.46, -2.13, -0.85, -1.24, -1.96, -0.8773416050068876, -0.4671394557823129, 0.3, -0.04, 0.07, 2.39, 0.42, -0.75, 3.700714285714286, 4.14, -1.0055463299214311, -1.52, -1.18, 0.11, -0.65, -2.17, -0.24069676751819596, 0.77, 0.44, 0.55, 2.88, 0.9, -0.28, 4.19, 4.63, -0.61, -1.05, -0.71, 0.58, -0.72, -1.04, -0.15, -1.19, -1.2, -0.33, -0.22, 2.09, 0.12, -1.04, 3.39, 3.83, -1.37, -1.4825351473922903, -1.47, -0.19, -1.67, -0.87, 0.11, 2.43, 0.46, -0.71, 3.74, 4.18, -1.04, -1.48, -1.14, 0.15, -1.1, 0.34, -0.33, -0.98, 2.32, 0.35, -0.82, 3.62, 4.06, -1.15, -1.59, -1.25, 0.04, -2.52, -3.22, -1.93, -2.9646649659863944, 1.27, 1.71, -3.39, -3.793605339105339, -3.49, -2.23, -0.25, -3.33, -2.66, -0.82, -0.57, -1.21, -1.32, -1.16, 3.26, 3.7, -1.49, -1.93, -1.59, -0.31, 0.56, -0.10692325186963274, 4.48, 4.92, -0.1613969800041227, -0.77, -0.44, 0.86, 0.16, 0.0, 0.06, -1.29, -7.6, -0.47, -0.48, 2.9, -2.9, -1.4111898289923788, -0.11, 0.17, 9.38, 1.61, 0.87, -6.5, -0.37, -2.73, 2.72, 2.49, -0.82, 4.31, -1.65, -2.63, 1.3, -3.95, 1.2, 2.66, 3.87, -9.52, -4.44, 0.43, -4.61, -5.03, -4.7, -3.46, -2.47, -4.84, -5.01, -5.43, -5.11, -3.87, 0.18, -0.44, -0.1, 1.2, -0.94, -1.08, 0.62, 0.34, 1.65, -0.85, -0.92, -0.92, 0.66, -2.39, -0.72, -0.3227361894755667, -2.59, 0.28, 1.31, -0.91, -1.41, -0.17470204795204777, -0.63, 0.15, -1.01, -1.17, -3.95, -0.83], ['452', -0.12, -0.12, 0.011221715620458745, 0.0, 0.1329790809910596, -0.04, -0.81, -0.87, -0.95, -0.33, 0.540608843537415, 0.69, 0.76, -0.06, 1.43, -0.11, 0.17, -0.06, -0.23, -0.53, -0.95, 1.36, 0.39, 0.05, -1.07, -0.89, -0.86, 0.16054545454545455, 0.23, -0.59, 0.9, -0.64, -0.36, -0.59, -0.75, -1.06, -1.47, 0.82, -0.14, -0.43615827680216085, -1.09, -2.77, -1.01, 0.07, -0.5821246055531769, 0.74, -0.8, -0.52, -0.74, -0.91, -1.21, -1.610345270762939, 0.66, -0.29, -0.64, -1.42, -0.51, -0.28217202719021606, -0.95, -1.08, -0.82, 0.67, -0.87, -0.59, -0.82, -0.98, -1.29, -1.7, 0.59, -0.37, -0.71, -1.25, -0.27, 1.5, -0.05, 0.23, 0.0, -0.16, -0.47, -0.88, 1.42, 0.45, 0.11, -1.17, -2.028257052471338, 2.22, -1.70330176161468, -1.53, -1.25, -1.48, -1.64, -1.94, -2.35, -0.08, -1.03, -1.37, -1.44, -0.22, 0.28, 0.05, -0.11, -0.42, -0.83, 1.47, 0.51, 0.16, -0.3090204081632653, -0.23, 0.09572371188304005, -0.2, -0.19, -0.2843264813499681, -0.42819052351387077, -0.23, -0.39, -0.7, -1.11, 1.19, 0.22, -0.12, -1.38, -0.21692325186963274, -0.16, -0.47, -0.89, 1.42, 0.45, 0.11, -1.2, -0.95, 0.03, -0.76, -4.27, 0.0, -0.07, 0.5, -0.4082798741874371, -0.25, 0.45, -0.4, -0.2, 0.53, 0.22, -0.03, 0.49, -0.65, 0.67, 0.62, -0.2, 0.81, -0.43, -0.61, 0.27, -1.51, 2.38, 0.97, 1.5, 0.44, -0.1, -0.31, -0.72, 1.58, 0.62, 0.27, -0.63, 0.21, -0.42, 1.9, 0.93, 0.58, 0.62, 2.32, 1.35, 1.0, -0.98, -1.06, -1.66, -0.95, -1.29, -0.22, -0.35, -0.86, 0.79, -0.43, -0.9634761904761905, -0.53, 0.08, -0.72, -0.34, -1.15, -0.28, 0.47, 0.47, 0.3646262438247291, -0.38, -1.56, -0.11, -0.37], ['453', -4.54, -0.3, -0.38877828437954126, -0.12, -0.77, -0.18, 0.9, -0.1, -0.27, -0.52, 0.24, -0.52, -1.17, -0.69, -0.65, 1.3, -0.84, -0.44, 0.2, 1.44, -0.662664517912641, -0.49, -0.29, -1.04, 0.04, -0.88, -0.76, -0.76, -1.41, -0.94, -0.9, 1.05, -1.08, -0.69, -0.04, 1.19, -0.94, -0.73, -0.54, -1.28, 0.02, -0.83, 0.0, -0.6463410188391392, -0.18, -0.14, 1.83, -0.33, 0.07, 0.72, 1.97, -0.18, 0.03, 0.22, -0.524952380952381, -0.47, -0.43, 0.0, -0.05, 0.66, 0.48, 0.52, 2.5, 0.33, 0.73, 1.38, 2.64, 0.47, 0.69, 0.88, 0.13, 0.06, 0.18, 0.04, 2.01, -0.15, 0.25, 0.9, 2.15, 0.0, 0.21, 0.4, -0.35, -0.86, -0.25, 0.26, 0.14, 1.97, -0.19, 0.21, 0.86, 2.303744771101914, 0.11523523302094742, 0.17, 0.36852380952380953, -0.39, -3.31, -1.79, -2.11, -1.72, -1.09, 0.14, -1.97, -1.77, -1.57, -2.31, -0.01, -1.75, 0.64, 0.01, -0.13, 0.24567351865003195, 0.33, 0.4, 1.0501587301587303, 2.3, 0.14, 0.36, 0.55, -0.2, 0.07, -0.07, 0.65, 1.982244713705627, -0.26, -0.04, 0.15, -0.6, -0.15, 0.16, -0.15, 0.12, -10.09, 0.0, -0.48, 0.01, -0.03, -0.01, -0.02, -0.87, 3.81, 0.0, -0.03, -2.27, 0.1, 0.021476190476190475, 0.0, -0.03, 0.01, -0.03, 0.03, 1.228390654979941, -0.56, 0.93, -2.25, -0.65, -0.98, -3.77, -0.72, 1.24, -0.9, -0.69, -0.49, -1.24, 0.0, -1.93, -2.11, -1.9, -1.71, -2.45, 0.18, 0.21, 0.41, -0.35, -0.3, -0.32, -0.03, 0.2, -0.56, 0.02, 0.04, 0.0, -1.17, 0.45, 1.13, -0.08, -1.03, -0.22, -0.75, 0.17, 0.1, 0.27, 0.33, 0.2, 0.53, -1.16, -1.76, 1.19], ['454', -1.44, 0.03, 0.16, 0.06, -1.01, -0.63, 0.07411525795982916, -0.95, -0.72, -1.15, 0.03, -0.84, -0.69, -0.07, -0.91, -0.47, 0.02, -1.12, -1.8, 0.53, -1.21, -0.68, -0.34, -1.29, -0.3, -0.5, -1.18, -0.8771394557823129, -0.7253571428571428, -0.11, -0.94, -0.5, -0.02, -1.16, -1.84, 0.49, -1.25, -0.71, -0.38, -1.32, -0.05, -3.14, -0.31, 0.15, 0.78, -0.07, 0.38, 0.87, -0.28, -0.97, 1.38, -0.341934531913557, 0.17, 0.51, -0.45, -0.8399371536943234, -0.47, -1.5580521152823785, 0.29, -0.46, 0.62, -0.22, 0.22, 0.71, -0.43, -1.12, 1.23, -0.53, 0.01, 0.35, -0.6, -0.96, -1.08, -0.84, -0.4, 0.09, -1.05, -1.73, 0.6, -1.14, -0.61, -0.1369045181009466, -1.22, -1.89, -2.29, 2.2, -0.24, 0.44, 0.93, -0.21, -0.9, 1.45, -0.31, 0.23, 0.57, -0.3259922724755494, -1.46, -0.68, 0.49, -0.66, -1.34, 1.0, -0.75, -0.21, 0.13, -0.82, -0.09, -0.7, -1.65, -0.46, -0.58, -0.32, -1.16, -1.14, -1.82, 0.51, -1.23, -0.6396949805527123, -0.36, -1.31, -0.44, -0.03, -0.43631441970727664, 1.67, -0.09, 0.45, 0.79, -0.17, -1.32, -1.54, 0.01, -0.59, -4.2, -0.03, 0.09, 0.81, -0.82, -0.43, 0.07, -1.07, 3.18, 0.97, 0.47, -0.65, -0.3, -1.34, 1.4, 1.5, -0.47, 1.19, -0.93, -0.44, 0.24, -3.49, 1.0486904761904763, 2.3, 3.52, -3.28, 0.67, 2.37, 0.6, 1.14, 1.49, 0.52, -1.35, -1.67, -1.73, -1.2, -0.86, -1.81, 0.07, 0.54, 0.88, -0.08, -0.75, -1.07, -0.47, 0.34, -0.62, -0.48, -0.49, -0.85, 2.39, -1.04, -2.61, -0.44, -0.5, -0.81, -0.95, -0.38, -0.9397802197802197, -0.15, -0.11, -0.22, 0.14, -1.12, -1.76, -0.36], ['455', -0.49, 0.03, 0.12, -0.06, -0.09, 0.51, 0.7, 0.17, 0.74, -0.33, -0.67, -0.94, -0.1, -0.74, -0.7, -0.55, -0.73, -0.43, 1.66, -0.38, -0.05, -1.54, -1.31, 0.29, 0.65, 0.33, 0.35, -0.27, 0.57, -0.06, -0.03, 0.13, -0.06, 0.24, 2.34, 0.29, 0.62, -0.87, -0.64, 0.96, 0.3774684253532108, 2.03, 0.62, 0.85, 0.21, 0.24, 0.4, 0.22, 0.52, 2.63, 0.57, 0.9, -0.5061344435209981, -0.37, 1.24, -0.29993715369432344, 0.31, 0.67, 0.4, -0.22, -0.63, -0.6, -0.44, -0.63, -0.33, 1.76, -0.28, 0.05, -1.44, -1.21, 0.39, 0.18, 0.41, 0.03, 0.19, 0.01, 0.31, 2.6574764481550197, 0.36, 0.69, -0.81, -0.58, 1.03, 1.08, 2.38, -2.29, 0.38, 0.16, -0.03, 0.27, 2.38, 0.33, 0.65, -0.84, -0.61, 1.0, 0.04, 0.22, -0.18, 0.12, 2.22, 0.17, 0.49, -1.0, -0.77, 0.84, 0.0, 0.22, 2.57572371188304, 0.18, 0.56, -0.28, 0.4, 0.3, 2.4, 0.35, 0.68, -0.82, -0.59, 1.02, 1.09, 0.1, 2.1, 0.05, 0.38, -1.11, -0.88, 0.72, 0.92, 1.2, -0.18, 0.09, 0.08, 0.1, 0.04, 1.91, -1.91, -0.94, 0.44, -0.51, 0.0, -0.43, -0.19, -0.28, 0.41, 0.48, -0.41, -0.41, 0.18, 2.68, 0.38, 0.85, -0.46, 1.21, -0.76, -0.81, -1.2, -0.07, -1.95, -1.9951904761904762, -1.68, -3.15, -2.92, -1.35, 0.59, 0.05, 0.32, -1.17, -0.93, 0.67, -0.27, -1.49, -1.26, 0.34, 0.72, 0.73, 1.23, 0.23, 1.85, 0.22, 0.16, 0.19, -0.98, 1.0701996269574994, 1.2, -0.08, 0.7, 1.0, 1.62, 0.93, -0.52, 0.0, 0.75, 0.28, -0.61, 1.09, 0.95, -2.19], ['456', -1.67, -0.03, 0.12, 0.14, 0.18, -0.72, -1.4858847420401708, -1.12, -1.33, 0.12, 1.89, 1.61, 0.74, 0.97, 1.55, -0.02, 0.98, -0.03, -1.41, 0.72, -0.10266451791264107, 0.24, 0.59, 0.59, -1.7, -1.23, -1.74, -0.28, -1.12, -0.9, -0.34, -1.87, -0.9, -1.88, -3.23, -1.15, -1.915546329921431, -1.62, -1.28, -1.28, -1.52, -1.46, -1.46, -0.85, -0.62, -0.06, -1.6, -0.62, -1.61, -2.97, -0.88, -1.691934531913557, -1.35, -1.01, -1.0, -0.52, -1.37, -0.48, -0.76, -0.62, 0.23, 0.9048467679404526, -0.75, 0.23, -0.6673949338599383, -2.13, 0.10397573353350675, -0.88, -0.5, -0.16, -0.15, -1.73, -0.85, 0.57, -0.98, 0.0, -0.99, -2.36, -0.25, -1.1, -0.73, -0.38, -0.38, -1.55, -1.46, 1.43, -1.4, -1.54, -0.56, -1.55, -2.91, -0.81, -1.66, -1.29, -0.95, -0.94, -0.45, 0.14, 0.99, -0.01, -1.39, 0.73, -0.12, 0.26, 0.6, 0.6, 0.02, 0.13, -0.24, -0.68, -0.65, -0.704326481349968, -0.85, -0.99, -2.36, -0.25, -1.11, -0.73, -0.38, -0.3214153161169343, -0.08, 0.15, -1.38, 0.75, -0.11, 0.27, 0.62, 0.62, -0.62, -0.57, 0.13, -0.73, -1.28, -0.1, 0.0, 1.96, -1.96, -0.97, 0.0, -1.83, 1.17, 1.4, 0.72, -0.81, -0.36, -2.06, 2.27, 2.05, -0.69, 2.9, -1.36, -1.45, 0.74, -2.6, 3.57, 1.75, 2.57, -1.17, 1.55, 2.15, 1.28, 1.67, 2.02, 2.02, -2.04, -0.59, -0.85, -0.47, -0.13, -0.13, 0.26, 0.38, 0.73, 0.73, -1.25, -1.02, -0.12, 0.34, 0.35, -0.7, -0.69, -1.14, 1.54, -0.43980037304250064, -1.62, -0.99, -1.2, -0.46, 0.0, -0.84, -1.08, -0.31, -0.3, -0.31, -0.46, -1.89, -1.74, -0.16], ['457', 1.48, -0.72, 0.3412217156204588, 0.03, 0.0, 0.17, -0.015884742040170832, 0.84, 0.1, 0.86, 0.81, 0.75, 1.44, -0.38, -1.34, 1.29, 0.39, 0.6, 2.8, 1.74, 1.13, 1.21, 0.41, 0.86, -0.14, -0.22, 0.05, -0.06, 0.63, -1.18, -2.13, 0.47, -0.41, -0.21, 1.97, 0.93, 0.32, 0.4, -0.39, 0.05, 0.58, -1.0450638007838267, 0.11, 0.7711974674961171, -1.12, -2.08, 0.53, -0.36, -0.15, 2.03, 0.99, 0.38, 0.46, -0.2528571428571429, 0.11, 0.37, -0.94, 0.25, -0.12, -0.57, -1.8, -2.74, -0.15, -1.03, -0.83, 1.34, 0.3, -0.14657884575741703, -0.23, -1.01, -0.57, -0.15639399885828442, 1.25, -0.96, 1.67, 0.78, 0.98, 3.19, 2.13, 1.52, 1.6, 0.8, 1.25, 0.37, 1.24, -1.21, 2.23, 2.66, 1.76, 1.96, 4.19, 3.13, 2.5, 2.59, 1.78, 2.23, 0.27, -0.42, -0.88, -0.68, 1.49, 0.45, -0.16, -0.07, -0.86, -0.42, 0.25, -0.44, 0.7201770034254836, 0.16, 0.29, 0.08, 0.47, 0.2, 2.39, 1.35, 0.73, 0.82, 0.02, 0.47, -0.25, 0.26, 2.19, 1.14, 0.53, 0.61, -0.18, 0.26, 1.39, 1.57, 0.02, 0.52, 0.74, 0.5, 0.01, 0.31, -0.31, -0.16, 0.31, 1.11, 1.82, -0.33, -0.18, 0.84, 0.0, 0.5914761904761905, -0.48, -0.4, 0.16, 0.39, 0.31, -0.58, 0.24, 1.38, -3.43, -0.88, -1.34, -1.68, -1.88, -1.02, -1.62, -1.54, -2.32, -1.88, 0.46, -0.87, -0.6, -0.52, -1.31, -0.87, -0.26, 0.08, -0.71, -0.26, 0.1, 0.27, -0.35, -0.79, -0.35, 0.24, 0.27439630127529085, 0.78, -1.54, 0.75, 1.52, 0.32, 0.47, 0.5286374482009709, 0.5227868514969317, 0.7300774025227806, -0.12, 0.09, 0.06, 0.08462624382472905, 0.085957527023814, 0.27, -0.27, 0.88], ['458', -4.2, -0.56, -0.45, 0.18, -1.3, -0.99, -1.98, -2.05, -1.94, -2.4492857142857143, -0.69, -0.9, -0.44, -1.1, -0.25, -1.22, -1.67, -2.37, -3.42, -0.81, -2.92, -1.58, -1.29, -2.18, -2.22, -0.67, -1.77, -0.22, 0.25, -0.41, 0.44, -0.54, -0.99, -1.7, -2.75, -0.12, -2.25, -0.9, -0.6, -1.5, -1.86, -2.9850638007838266, -1.56, 0.47, -0.2, 0.65, -0.32, -0.78, -1.48, -2.54, 0.09, -2.04, -0.69, -0.3028571428571429, -0.9691712018140588, -1.6, -2.27, -2.5, -2.0, -2.02, -0.66, 0.18079931972789115, -0.79, -1.24, -1.95, -2.7103066893424037, -0.38, -2.5, -1.15, -0.85, -1.75, -2.05, -1.37, 0.85, -0.12, -0.58, -1.135765306122449, -2.35, 0.29, -1.84, 0.16000000000000003, -0.19, -1.09, -2.29, -3.31, 3.36, -2.2, -0.97, -1.42, -2.12, -3.17, -0.56, -2.67, -1.33, -1.04, -1.93, 1.98, -1.25, -0.46, -1.17, -2.23, 0.41, -1.72, -0.37, -0.07, -0.97, -0.04885812600098299, -1.24, 0.33, -0.85, -1.02, -0.66, -0.79, -0.71, -1.78, 0.88, -1.27, 0.15030501944728758, 0.39, -0.51, -0.74, -0.026923251869632736, -1.07, 1.6, -0.5504376417233561, 0.81, 1.11, 0.2, -1.0710416300368755, -1.2, 0.33603717887804047, -0.75, 5.617738095238095, -0.26, 0.07, 1.43, -1.41, -0.72, -0.36, -4.11, 3.13, 1.65, 0.87, -2.09, -0.68, -2.56, 2.55, 2.6, -0.85, 2.23, -1.72, -2.8, 1.39, -2.37, 4.97, 1.71, 2.31, -3.38, 1.0, 2.7, 0.52, 1.9, 2.21, 1.29, -2.53, -1.65, -2.13, -0.78, -0.48, -1.38, 0.49, 1.38, 1.68, 0.77, -1.95, -1.96, -0.88, 0.3, -0.6, -0.81, -0.86, -2.04, 2.72, -0.29, -2.55, -0.22, -1.0, -1.18, -0.9, -0.97, -0.83, -0.59, -0.67, -0.91, -0.28, 0.25, -1.15, -0.14], ['459', -1.87, -0.13, 0.21, -0.09, 0.43, 0.53, 0.30411525795982913, 0.62, 0.98, 0.33, -1.62, 0.07, -0.56, 1.56, -0.15, 0.24, -1.35, -0.2, -2.86, -0.52, 0.42, -0.49, -0.45, -1.06, 1.15, 1.13, 2.0126583949931125, 1.72, 1.08, 3.23, 1.49, 1.89, 0.27, 1.44, -1.25, 1.12, 2.08, 1.16, 1.19, 0.57, 0.5, 3.2249361992161734, 0.26, -0.63, 1.48, -0.23, 0.17, -1.42, -0.27, -2.93, -0.59, 0.35, -0.56, -0.53, -1.13, 0.21, 1.1, 1.42, 0.43, 0.89, 2.13, 0.41, 0.8, -0.8, 0.36, -2.31, 0.04, 0.98, 0.07, 0.1, -0.51, 0.78, -1.21, -1.68, -1.3, -2.87, -1.73, -4.35, -2.05, -1.12, -2.01, -1.98, -2.58, 2.18, 2.68, -2.66, 0.5166982383853201, 0.4, -1.2, -0.05, -2.71, -0.37, 0.58, -0.33, -0.3, -0.91, 1.88, 0.09, -1.59, -0.44, -3.09, -0.76, 0.18, -0.72, -0.69, -1.3, 0.5, 0.09, 1.86, 1.2315981806829015, 0.82517906963434, 1.68, 1.71, 1.17, -1.52, 0.84, 1.8, 0.88, 0.91, 0.29, 0.84, 0.5830767481303673, -2.66, -0.32, 0.63, -0.28, -0.25, -0.86, 1.21, 1.49, -0.04, 1.61, 5.53, 0.21, 0.19, -4.91, 4.86, 2.44, 0.28, 0.34, -1.6, -2.35, -1.18, -1.0, 0.56, 3.63, -3.68, -3.42, 1.2132908048638529, -7.19, 2.399878357241315, 1.67, -0.82, 5.140714285714285, -7.49, -3.47, -5.08, 1.65, 3.28, 2.4, 3.37, 2.44, 2.47, 1.84, 3.49, 0.86, 0.95, 0.04, 0.07, -0.55, -0.09, -0.9, -0.87, -1.48, 0.99, 1.2, 0.82, 0.03, -0.58, 1.15, 1.26, 0.66, -4.84, 1.66, 5.05, 1.86, 0.37, 0.79, -0.61, 0.22, 2.62, 0.62, 0.46, 0.97, 1.41, 1.78, 1.9215952380952381, 1.74], ['460', -4.19, -0.21571428571428575, -0.43877828437954125, -0.5, -0.42, -0.83, -3.57, -2.0, -1.64, -2.33, -1.06, 0.43, -0.29, -0.08, 0.02726190476190476, -1.42, -1.15, -1.62, -0.96, -3.6, -2.46, -1.2269251700680273, -0.65, -1.22, -0.62, -1.69, -1.28, 1.5, 0.78, 1.0, 1.1, -0.36, -0.09, -0.57, 0.11, -2.57, -1.41, -0.09000000000000001, 0.42, -0.16, -1.47, 0.08006211180124224, -2.74, -0.72, -0.5, -0.4, -1.84, -1.57, -2.04, -1.38, -4.01, -2.87, -1.65, -0.4385714285714286, -1.63, -1.7, -2.36, -1.56, -1.06, -2.04, 0.22, 0.32, -1.13, -0.86, -1.33, -0.66, -3.32, -2.17, -0.94, -0.36, -0.92, -2.36, -2.25, 0.5202278911564625, -1.35, -1.08, -1.55, -0.88, -3.53, -2.38, -1.16, -0.57, -1.14, -1.5949404761904762, -4.44, 4.48, -2.35, -1.44, -1.18, -1.65, -0.98, -3.426255228898086, -2.48, -1.1642857142857144, -0.67, -1.1859922724755494, -3.62, -0.92, 0.27, -0.20788095238095236, 0.47, -2.21, -1.05, 0.19, 0.78, 0.21, -1.04, -0.95, -1.81, -1.11, -1.24, -0.91, -1.19, -0.48, 0.2, -2.48, -1.32, -0.08, 0.51, -0.06, -0.11, -0.72, 0.68, -2.01, -0.85, 0.4, 0.99, 0.42, -1.18, -0.4, -0.66, -1.05, -10.622047619047619, -1.11, -1.13, 1.9, -1.94, -0.94, -2.01, -0.62, -2.34, 2.21, 1.14, -2.12, -0.34, -3.37, 3.58, 3.33, -1.06, 2.89, -2.21, -0.39, 0.16, -3.53, 8.56, 2.4742857142857146, 3.6514285714285712, 2.42, -1.38, -2.67, -1.52, -0.28, 0.326625850340136, -0.26, -3.15, 1.3201587301587303, 1.19, 2.7071428571428573, 3.07, 2.48, 0.13, 1.26, 1.892857142857143, 1.27, -3.18, -3.4, -1.11, 0.59, 0.02, -1.64, -1.65, -3.33, 4.37, -2.18, -4.36, -1.67, -1.13, -1.69, -0.57, -1.61, -1.18, -0.29, -0.039047619047619046, -0.48, -1.13, -4.27, -1.43, -1.13], ['461', -0.04, -0.92, -0.1, 0.05, 0.1029790809910596, -1.18, -3.8799638336347195, -1.45, -1.79, -0.79, 0.04, 2.37, 1.42, 0.74, 0.47, -0.94, 0.22, -0.05, -0.75, -1.3, -0.62, -0.25, 0.59, 0.53, -3.0, -1.26, -0.84, 2.32, 1.38, 0.7, 0.43, -0.99, 0.18, 0.017258904144408435, -0.79, -1.34, -0.66, -0.3, 0.6388796134390452, 0.49, -2.83, -0.3891024373941227, -3.09, -0.92, -1.59, -1.85, -3.23, -2.1, -2.36, -3.04, -3.58, -2.92, -2.56, -1.74, -1.79, -0.66, -1.97, -0.35217202719021606, -1.16, -2.19, -0.67, -0.94, -2.33, -1.19, -1.45, -2.14, -2.69, -2.01, -1.65, -0.83, -0.88, -1.5, -1.53, -0.27, -1.67, -0.52, -0.79, -1.48, -2.03, -1.35, -0.99, -0.16, -0.1564403582748793, -1.03, -3.84, 3.8, -1.26, -1.41, -0.25, -0.52, -1.22, -1.76, -1.09, -0.72, 0.11, 0.06, -0.24, 0.15, 1.17, 0.9, 0.19, -0.36, 0.33, 0.69, 1.54, 1.49, -0.8, 0.16, -1.79, -1.07, -1.05, -1.12, -1.01, -0.27, -0.97, -1.52, -0.84, -0.47, 0.36, 0.31, -0.62, -0.74, -0.7, -1.25, -0.57, -0.2, 0.64, 0.58, -1.07, -0.86, -0.1, -0.92, -0.76, -0.48, -0.48, 2.01, -2.04, -1.03, -0.65, -2.1738364678879503, -1.01, 2.15, 1.06, 0.0, -0.76, -3.18, 3.04, 3.19, -1.06, 3.11, -2.14, -1.56, 0.81, -2.97, 5.62, 2.06, 3.05, 0.98, -0.05, -0.56, 0.13, 0.5, 1.34, 1.29, -3.18, 0.51, 0.69, 1.06, 1.91, 1.85, -0.18, 0.37, 1.21, 1.16, -1.84, -1.06, -0.54, 0.84, 0.79, -1.08, -1.08, -1.56, 3.31, -1.03, -3.38, -1.66, -0.61, -1.37, -0.05, -1.41, -0.85, -0.94, -0.59, -1.08, -1.32, -1.56, -1.15, -0.67], ['462', -4.7785714285714285, -0.81, -0.23877828437954127, -0.08, -0.45, -0.2, -0.79, -1.14, -0.43, -0.7946428571428571, -0.13, -0.34, 1.27, 0.67, 0.19, 0.1, 1.17, -0.34, 2.14, -0.74, -0.95, 1.75, 2.3, -0.59, 0.47, -1.6, -0.73, -0.2, 1.4, 0.8, 0.32, 0.24, 1.3, -0.21, 2.28, -0.61, -0.82, 1.89, 2.44, -0.46, 0.61, 0.16089756260587734, -0.529795918367347, 1.61, 1.01, 0.52, 0.44, 1.512857142857143, -0.01, 2.49, -0.4088095238095238, -0.62, 2.1, 2.65, -0.26, 0.0, -0.81, -1.22, 0.32, -2.11, -0.59, -1.07, -1.15, -0.1, -1.59, 0.86, -1.98, -2.19, 0.48, 1.02, -1.84, -0.08, -0.8742857142857143, -0.48, -0.56, 0.5, -1.01, 1.46, -1.4, -1.61, 1.73, 1.62, -1.25, -0.8510901360544217, -8.25, 8.24, -1.05, -0.08947959183673469, 0.98, -0.53, 1.95, -0.93, -1.14, 1.56, 2.11, -0.78, -2.63, -0.97, 1.07, -0.45, 2.04, -0.84, -1.05, 1.65, 2.2, -0.69, -0.47, -0.87, -2.35, -0.74, -1.01, -0.55, -2.01, -1.5, 0.96, -1.89, -2.1, 0.58, 1.12, -1.74, -2.55, -0.52, 2.5, -0.4, -0.61, 2.1, 2.66, -0.25, -3.84, -3.63, 0.16, -1.27, -5.24, -0.01, 0.21428571428571427, 1.08, -1.12, -0.57, -2.41, -0.81, 0.31, 1.47, 0.78, -2.2947789115646255, -0.31, -2.54, 2.46, 2.1, -0.76, 1.78, -1.45, 0.71, -0.36, -6.12, 5.23, 4.104285714285715, 6.325714285714286, -0.33, -2.94, -2.82, -3.03, -0.38, 0.16, -2.68, -2.24, -0.13, -0.22, 2.51, 3.07, 0.15, 0.09, 2.73, 3.9157142857142855, 0.37, -0.48, -0.68, -2.57, 0.54, -2.3, -0.86, -0.86, -1.12, 2.65, -2.06, -2.58, -2.18, -1.65, -3.1, -2.83, -0.46, -0.29, 0.3, 0.18, 0.0, -0.27, -3.43, -2.63, -0.82], ['463', -3.03, -0.09, 0.011221715620458745, 0.19, -2.29, -0.24158037632624055, -0.31, -0.74, -0.49, 0.33, 0.48, 1.04, 1.22, 0.88, 1.4, 0.86, 1.05, 0.35, 2.8, 2.39, 0.22733548208735893, 0.55, 1.11, 0.77, -1.06, -0.51, -0.15, 0.55, 0.74, 0.4, 0.91, 0.38, 0.57, -0.12, 2.310714285714286, 1.9, -0.29, 0.07, 0.62, 0.29, -0.38, -0.43506380078382656, -0.7, 0.18, -0.16, 0.36, -0.18, 0.02, -0.67, 1.75, 1.34, -0.84, -0.48, 0.07, -0.26, -1.0, -0.61, 0.07, -0.06, -0.88, -0.34, 0.17, -0.36, -0.17, -0.7573949338599383, 1.56, 1.15, -1.02, -0.67, -0.12, -0.44, -1.05, -0.54, 0.51, -0.02, 0.18, -0.52, 1.91, 1.49, -0.68, -0.33, 0.23, -0.1, -0.44, -2.17, 2.13, -1.05, -0.53, -0.34, -1.03, 1.39, 0.98, -1.19, -0.83, -0.29, -0.61, -0.32, -0.52, 0.2, -0.5, 1.93, 2.132857142857143, -0.66, -0.31, 0.25, -0.08, -0.01, -0.59, -1.68, -0.29, -0.52482093036566, -0.09, -0.72, -0.6886530612244898, 1.73, 1.32, -0.86, -0.5, 0.05, -0.28, -0.15346392892821453, -0.02, 2.693685580292723, 2.02, -0.16, 0.19, 0.75, 0.42, -1.73, -1.7972380952380953, 0.41, -0.86, -0.722047619047619, -0.13, -0.07, 0.3, -0.32, -0.14, -0.26, -1.37, 4.14, 0.61, 0.3, -1.49, -0.11, -0.88, 0.92, 0.9, -0.28, 0.46, -0.63, -1.92, 0.99, -2.11, -0.81, 1.46, 2.12, -3.98, -2.4, -0.4, -2.54, -2.19, -1.65, -1.97, -0.9, -2.01, -2.14, -1.79, -1.249142857142857, -0.9314285714285715, 0.14, 0.36, 0.91, 0.58, -0.46, -0.32, -0.22, 0.55, 0.22, -0.31, -0.39, -0.5574239503761216, 0.22, -1.35, -0.6, -1.2, -0.59, -0.77, -0.25721314850306837, -0.2999225974772193, -0.07, 0.17, -0.55, 0.35, -0.354042472976186, -2.28, -0.89, -0.75], ['464', -1.13, 1.35, 0.42122171562045874, 0.09, 0.6629790809910596, 0.67, 1.5641152579598292, 0.7, 1.0593780543870106, 0.59, -0.24, -0.19, -1.28, 1.12, -0.74, 0.3, -0.59, 0.24, -1.27, -0.75, 0.28, 0.48, -0.44, 0.78, 1.24, 0.52, 0.83, 0.05, -1.05, 1.36, -0.4421800287049088, 0.54, -0.35, 0.48, -1.03, -0.51, 0.52, 0.72, -0.2, 1.02, 1.58, 1.9849361992161734, 0.78, -1.1, 1.31, -0.47918497042472347, 0.49, -0.4, 0.43, -1.08, -0.56, 0.498065468086443, 0.67, -0.25, 0.97, 0.94, 1.45, 1.02, 0.69, 1.89, 2.43, 0.55, 1.61, 0.7, 1.54, 0.02, 0.54, 1.58, 1.79, 0.85, 2.09, 0.55, -0.53, -1.84, -0.81, -1.69, -0.87, -2.36, -1.84, -0.83, -0.63, -1.54, -0.33, 1.17, 2.83, -2.89, 1.34, 1.05, 0.15, 0.99, -0.53, -0.01, 1.02, 1.23, 0.3, 1.5840077275244506, -0.34, 0.28, -0.89, -0.06, -1.57, -1.05, -0.03, 0.18, -0.74, 0.48, 0.43, 0.32, 1.74, 0.8, 1.06, 0.5, 1.18, 0.9665993906886764, -0.68, -0.16, 0.87, 1.08, 0.15, 1.38, 0.27, 0.35, -1.5, -0.98, 0.04, 0.24, -0.68, 0.54, 1.2089583699631243, 1.37, 0.27603717887804047, 0.6, -1.02, 0.23, 0.41, -1.0, 0.95, 0.5, 0.8240662734668153, 0.56, -2.72, -1.56, -0.82, -0.53, 0.41, 2.24, -2.33, -2.44, 0.8, -1.51, 1.56, -0.32, 0.19, 3.46, -1.89, -2.37, -3.48, 2.74, 1.88, 0.53, 1.56, 1.811610544217687, 0.84, 2.08, 2.37, 1.34, 1.03, 1.24, 0.31, 1.54, 0.31, 0.2, -0.71, 0.51, 0.98, 0.79, 0.1, -0.92, 0.3, 0.82, 0.76, 0.63, -0.39, 1.25, 0.42, 0.93, 1.77, 1.03, 1.23, 1.0600774025227806, 0.53, 0.67, 1.1, 1.29, -0.2, 2.13, 3.13, -0.82], ['465', 1.49, -1.57, 0.2912217156204588, -0.28, 0.97, 0.7384196236737595, 2.2141152579598296, 0.8, 1.29, 1.94, 0.78, 0.2393248299319728, 1.48, 1.59, 0.93, 2.01, 0.51, 1.83, -0.12, -0.32, 2.0, 2.81, 0.75, 0.67, 0.81, 1.62, 1.1826583949931124, -0.54, 0.7, 0.81, 0.15, 1.22, -0.26, 1.05, -0.89, -1.09, 1.22, 2.02, -0.03, -0.11, 1.29, 2.61, 1.7, 1.25, 1.36, 0.69, 1.77, 0.28, 1.6, -0.35, -0.55, 1.77, 2.57, 0.52, 0.44, 0.1, 0.15, 0.81, 0.8, 0.44, 0.1, -0.55, 0.52, -0.96, 0.34, -1.59, -1.7797619047619049, 0.51, 1.31, -0.72, -0.8, 0.9, 0.34, -0.65, 0.41, -1.06, 0.24, -1.69, -1.88, 0.41, 1.2, -0.83, -0.91, 1.84, 2.79, -2.72, 1.0, 1.07, -0.41, 0.9, -1.04, -1.24, 1.07, 1.87, -0.17, -0.26, 0.98, -0.07, -1.46, -0.17, -2.0544149659863944, -2.29, 0.0, 0.79, -1.23, -1.31, -0.02, -0.11, 1.57, 0.8715981806829014, 0.93, 0.8, 1.41, 1.31, -0.64, -0.83, 1.48, 2.28, 0.23, 0.15, -0.82, 0.15307674813036726, -1.92, -2.12, 0.17, 0.96, -1.06, -1.14, 1.82, 1.43, -0.59, 1.34, 3.09, 0.14, -0.1, -2.19, 2.15, 1.09, -0.69, 1.74, -4.44, -1.65, -0.85, 0.74, -0.08, 2.47, -2.46, -2.45, 0.863290804863853, -3.27, 1.6998783572413152, 2.46, -1.27, 4.26, -1.42, -2.9, -4.24, 4.62, 2.06, -0.2, 2.13, 2.94, 0.88, 0.79, 2.4608051948051948, 2.27, 2.33, 3.14, 1.08, 1.0, -0.07, 0.8788785911064217, -1.23, -1.31, 1.27, 1.21, -0.85, -2.0, -2.08, 0.78, 0.93, 0.72, 0.84, 1.95, -0.73, 1.3472638105244332, 1.78, 1.18, -0.08, 1.35, 0.87, -0.10470204795204777, -0.42, 0.09, 1.26, 2.12, 3.04, 1.66], ['466', 8.66, 0.95, 0.26122171562045876, -0.12, 3.89, 1.85, 2.3041152579598294, 3.68, 3.47, 5.28, -0.16, 3.53, 2.79, 0.41, 2.24, 2.38, 2.23, 4.62, 4.66, -1.35, 6.75, 3.06, 3.18, 3.59, 3.68, 2.83, 5.482658394993113, 3.7, 2.960119047619048, 0.57, 2.457819971295091, 2.55, 2.4, 4.79, 4.83, -1.19, 6.92, 3.23, 3.34, 3.75, 2.32, 7.524936199216174, 1.68, -0.72, -3.02, -1.25, -1.11, -1.26, 1.05, 1.09, -4.71, 3.11, -0.46, -0.34, 0.05, 2.37, 2.67, 3.3, 2.2, 2.42, -2.32, -0.54, -0.39, -0.54, 1.78, 1.82, -4.02, 3.86, 0.32965816326530617, 0.38, 0.78, 4.03, 4.85, 1.82, 1.97, 1.82, 4.2, 4.24, -1.75, 6.761853741496599, 2.8671428571428574, 2.76, 3.16, 5.92, 6.01, -5.82, 3.0066982383853205, 0.14052040816326533, -0.01, 2.33, 2.37, -3.5, 4.42, 0.81, 0.92, 1.3740077275244507, 3.09, 2.83, -0.15, 2.19, 2.23, -3.64, 4.27, 0.66, 0.78, 1.18, 0.73, 2.89, 3.94, 2.11, 2.0, 2.31, 2.98, 2.4765993906886763, 2.38, -3.5, 4.42, 0.81, 0.93, 1.32, 1.89, 0.63, 0.04, -5.7, 2.04, -1.49, -1.38, -0.99, 2.0, 2.11, 0.03, 2.76, 9.27, 0.1, 0.02, -5.32, 5.29, 2.65, 0.28, 4.43, -13.65, -4.17, -2.11, 4.17, 1.18, 6.19, -6.22, -6.34, 2.12, -7.91, 4.13, 3.08, -1.52, 8.85, -8.74, -5.9, -8.74, 12.95, 0.59, -5.74, 2.0, -1.53, -1.42, -1.03, 6.41, 6.71, 8.21, 4.47, 4.59, 5.0, -1.38, -3.46, -3.35, -2.97, 3.51, 4.13, 2.15, 0.11, 0.51, 1.98, 2.334396301275291, 3.64, -5.34, 3.8, 5.39, 2.5218948994148556, 2.33, 2.03, 0.39, 3.08, 2.54, 1.55, 0.35, 1.55, 1.7159575270238139, 3.71, 3.53, 3.59], ['467', -8.035714285714285, -0.34, 0.11015289830927054, 0.2, -1.12, -0.18, -1.13, -1.74, -0.36, -1.92, -1.09, -2.08, -0.32, -0.89, -0.99, 1.8810714285714285, -1.3, -1.85, -3.41, 0.39, -1.87, -1.81, -1.29, -2.13, -0.8, -1.55, -0.8073416050068876, -1.0, 0.78, 0.2, 0.1, 3.0, -0.21, -0.6527410958555916, -2.35, 1.5, -0.715546329921431, -0.73, -0.2, -1.06, -0.08, -0.48, 0.17, 1.8, 1.21, 1.12, 4.05, 0.8, 0.24, -1.36, 2.53, 0.21, 0.28, 0.81, -0.05, -1.68, -0.86, -1.36, 0.0, -1.6, -0.58, -0.67, 2.21, -0.98, -1.53, -3.1, 0.71, -1.56, -1.5, -0.97, -1.82, -3.2, -1.03, -0.1, 3.236658163265306, -0.41, -0.96, -2.54, 1.3, -0.99, -0.93, -0.4, -1.25, -0.56, -1.94, 1.92, -0.94, 2.9, -0.31, -0.87, -2.45, 1.4, -0.89, -0.83, -0.3, -1.16, -4.73, -3.73, -3.12, -3.66, -5.19, -1.46, -3.68, -3.593605339105339, -3.11, -3.94, -0.07, -3.81, 0.0, -0.43, -0.53, -0.33, -0.5581905235138708, -0.56, -2.14, 1.71, -0.58, -0.52, 0.01, -0.85, -0.11, -0.07, -1.59, 2.28, -0.03, 0.04, 0.57, -0.29, -1.54, -0.95, 0.44, -0.6, -14.15, 0.04, 0.11, 0.4, -0.4, -0.2, -0.29, -1.21, 4.56, 0.87, 0.46, -4.385357142857143, 0.03, -1.45, 1.46, 1.37, -0.41, 0.7, -0.89, -2.76, 1.36, -1.82, 0.0, 1.26, 1.83, -4.42, 1.55, 3.94, 1.59, 1.701610544217687, 2.2, 1.32, -1.3, -2.3, -2.26, -2.2, -1.67, -2.52, -0.04, 0.06, 0.6, -0.26, -0.34, -0.36, -0.022725315092565576, 0.53, -0.33, -0.41, -0.49, -1.43, -0.32, 0.04033326278406317, 0.28, -1.75, -1.64, -0.64, -0.86, -0.67, -0.56, 0.15, 0.25, 0.07, 0.305957527023814, -2.75, -2.18, -0.36], ['468', 1.49, 0.65, -0.4, 0.21, 0.2929790809910596, -0.22, -2.91, 0.17, -0.02, 0.86, 0.4, 1.34, 0.45, 1.12, 0.76, -0.08, 0.69, 0.73, 5.22, -0.52, 2.21, -0.02, 0.47, 0.68, 0.09, 0.33, 0.46, 0.94, 0.05, 0.72, 0.36, -0.47, 0.3, 0.34, 4.81, -0.91, 1.8, -0.41, 0.08, 0.28, -0.26, -1.3350638007838267, -0.47, -0.88, -0.21, -0.57, -1.4, -0.64, -0.6, 3.83, -1.83, 0.86, -1.34, -0.86, -0.65, 0.64, -0.74, 0.07, -0.3, 0.41, 0.67, 0.32, -0.52, 0.25, 0.29, 4.76, -0.9597619047619047, 1.75, -0.46, 0.03, 0.23, 0.02, -0.26, -0.36, -1.19, -0.42, -0.38, 4.307476448155019, -1.62, 1.07, -1.13, -0.64, -0.44, 0.15, 1.12, -1.02, 0.1, -0.83, -0.07, 0.5971428571428571, 4.43, -1.27, 1.43, -0.77, -0.29, -0.08, 1.5, 0.94, 0.77, 0.81, 5.3, -0.44, 2.28, 0.06, 0.55, 0.75, 0.22, 1.1, 1.73, 0.07, 0.14, 0.09567351865003196, 0.1709570400359874, 0.04, 4.5, -1.2, 1.5, -0.7, -0.22, -0.02, 1.01, 0.12, 4.46, -1.24, 1.46, -0.74, -0.26, -0.06, 0.14, 0.0, 0.58, 0.543186783623568, 4.677738095238095, 0.13, 0.07, 0.68, -0.71, -0.36, 0.88, 0.08, -2.62, -0.17, -0.07, 0.83, 0.29, -0.02, -0.18, -0.24, 0.09, 0.99, 0.07, -1.14, 0.51, 0.7963956916099773, 5.18, -0.38, -0.51, 2.72, -4.15, -5.45, -2.87, -4.98, -4.52, -4.32, 0.41316789956075695, 1.38, 2.73, 0.5, 0.99, 1.2, -1.32, -2.17, -1.7, -1.49, -0.03, 0.06, 0.88, 0.49, 0.7622487553150162, 0.07, 0.12, 0.18, 2.44, 1.37, -2.44, 0.23, -0.11, 0.39, 0.21, 0.12, -0.41, -0.4, 0.72, 0.74, 0.18, 0.08, -0.13, -0.05], ['469', -4.6, -0.68, 0.0, 0.14, -1.0, -0.53, -0.71, -1.57, -0.68, -3.41, -1.99, -3.8, -2.15, -1.53, -1.86, -2.97, -2.4, -3.57, -1.15, -1.67, -3.54, -2.13, -2.235694768399324, -3.09, -0.9414063389924735, -1.44, -1.45, -1.85, -0.17, 0.46, 0.12, -1.0066496598639456, -0.42, -1.62, 0.85, 0.32, -1.59, -0.15, -0.35, -1.12, -0.48253157464678914, -1.41, 0.4, 1.71, 2.35, 2.01, 0.86, 1.45, 0.24, 2.75, 2.21, 0.298065468086443, 1.73, 1.53, 0.74, -0.5, -0.65, -0.13217202719021603, -1.0, -1.29, 0.63, 0.29, -0.84, -0.26, -1.45, 1.02, 0.49, -1.42, 0.02, -0.18, -0.96, -1.26, -1.91, -0.34, -1.46, -0.88, -2.07, 0.38, -0.14, -2.04, -0.61, -0.81, -1.58, -1.32, -2.92, 2.99, -1.5433017616146798, -1.13, -0.55, -1.74, 0.72, 0.2, -1.71, -0.28, -0.48, -1.25, -1.73, -0.45, 0.59, -0.62, 1.87, 1.34, -0.59, 0.86, 0.66, -0.12, 0.22, -0.44, -1.79, -0.69, -0.87, -0.534326481349968, -1.0390429599640125, -1.2, 1.28, 0.7505357142857143, -1.17, 0.27, 0.07, -0.7, -1.24, 0.16, 2.51, 1.97, 0.03, 1.49, 1.29, 0.5, -1.49, -1.63, -0.16, -1.03, -5.23, -0.2196768707482993, -0.17, 0.26, -0.28, -0.13, -0.7, -2.38, 3.49, 1.39, 0.72, -2.33, -0.15, -2.2, 2.21, 2.29, -0.7, 0.63, -1.4, -0.48, 0.23, -3.129285714285714, -16.57, 2.05, 3.13, -3.64, -2.28, -0.52, -2.42, -0.99, -1.19, -1.96, -2.06, -1.77, -1.9, -0.47, -0.67, -1.44, 0.14, 1.46, 1.26, 0.47, -0.71, -1.12, -1.31, -0.2, -0.8977512446849837, -0.7, -0.78, -1.51, 3.27, -1.49, -3.37, -1.6981051005851444, -2.33, -1.11, -0.77, -1.28, -0.17, 0.09, -0.29, -0.12, -0.34, -3.17, -3.38, -0.63], ['470', -0.55, 1.15, 0.011221715620458745, -0.07, 0.15, 0.03, 1.62, -0.01, 0.22, 0.4, 0.23, -0.28, -0.36, 0.77, 0.37, 0.87, 0.08, 0.3, 1.8, 0.28, 0.16, -0.4, 0.18, -0.26, 0.53, -0.07, 0.16, -0.52, -0.59, 0.54, 0.14, 0.63, -0.15, 0.07, 1.57, 0.04, -0.07, -0.64, 0.03887961343904518, -0.5, -0.36, -0.34, 0.68, -0.07, 1.06, 0.66, 1.15, 0.37, 0.59, 2.09, 0.56, 0.45, -0.12, 0.46, 0.02, -0.26, -0.65, -2.41, -0.43, 0.76, 1.13, 0.73, 1.23, 0.44, 0.66, 2.17, 0.64, 0.52, -0.05, 0.54, 0.09, -0.48, -0.37, -0.4, 0.09, -0.69, -0.47, 1.02, -0.49, -0.61, -1.17, -0.59, -1.03, 0.15, 0.99, -0.98, 0.03, 0.5, -0.29, -0.07, 1.43, -0.09, -0.21, -0.77, -0.19, -0.63, -1.54, -0.46, -0.78, -0.56, 0.93, -0.58, -0.7, -1.26, -0.68, -1.12, 0.1, -0.41, 1.74, 0.28, 0.19, 0.4, 0.32, 0.22, 1.72, 0.2, 0.2557782534925394, -0.49, 0.09, -0.35, 0.9765360710717854, 0.1, 1.5, -0.02, 0.038603019995877313, -0.7, -0.12, -0.56, 0.38, 0.13, 0.04, 0.43, -4.45, -0.06, -0.11, -0.42, 0.42, 0.21, 0.12, 0.82, -0.21948175112272847, -0.54, -0.29, -0.3, 0.25, 0.81, -0.79, -0.86, 0.26, -0.59, 0.54, 0.78, -0.42, 0.95, -3.77, -0.68, -0.93, 0.28, -1.38, -1.5, -1.61, -2.17, -1.6, -2.03, 0.82, 0.12, -0.12, -0.68, -0.1, -0.54, 0.24, -0.57, 0.01, -0.43, 0.2227953514739229, 0.08, 0.8972746849074344, 0.58, 0.14, 0.27, 0.29, 0.04, -2.13, 1.54, 2.18, 0.13, 0.36, 0.22043171114599686, -0.36721314850306835, 0.27, 0.07, 0.83, 0.18, -0.22, 0.67, -0.13, 0.89, 0.48], ['471', -1.75, 0.02, 0.20015289830927055, -0.04, -1.0, 1.03, 0.9641152579598291, 0.9117205965359587, 1.6, 1.14, -0.59, 0.08, 0.69, 0.77, 0.08, 1.78, 0.18, 0.56, -0.24, 0.76, 1.697335482087359, 0.5, 0.74, 0.31, 2.18, 0.96, 1.74, 0.67, 1.28, 1.37, 0.67, 2.38, 0.77, 1.16, 0.36, 1.36, 2.27, 1.1, 1.34, 0.91, 1.31, 2.44, 1.06, 0.61, 0.69, 0.0, 1.7, 0.1, 0.48, -0.21286444351387962, 0.69, 1.59, 0.43, 0.67, 0.23, 0.99, 1.33, 1.0, 1.54, 0.45, 0.08, -0.6, 1.08, -0.51, -0.13, -0.92, 0.07, 0.97, -0.18, 0.06, -0.37, 0.99, 0.37, -0.68, 1.0, -0.59, -0.2, -1.0, -0.01, 0.89, -0.26, -0.02, -0.45, 2.02, 0.9, -0.91, 1.06, 1.7, 0.1, 0.48, -0.32, 0.68, 1.58, 0.42, 0.67, 0.23, 0.35, -0.63, -1.57, -1.19, -1.98, -1.0, -0.11, -1.25, -1.01, -1.44, 0.6, -0.73, 0.16, 0.85, 0.78, 0.95, 0.96, 0.38, -0.41, 0.58, 1.49, 0.33, 0.57, 0.13, 0.63, 0.58, -0.79, 0.2, 1.1, -0.06, 0.18, -0.25, 0.29, 0.87, 0.17, 0.89, 0.58, 0.33, 0.42, -2.36, 2.39, 1.19, 0.55, 0.31, -0.73, -1.66, -0.88, -0.85, 0.44, 2.61, -2.62, -2.56, 0.86, -3.49, 1.7, 0.11, 0.03476526428424678, 2.88, -8.55, -1.96, -2.86, 0.69, 1.38, 1.0, 1.91, 0.74, 0.98, 0.55, 2.66, 0.38, 0.9, -0.26, -0.02, -0.45, -0.52, -1.14, -0.9, -1.33, 1.682795351473923, 1.65, 0.63, 0.24, -0.19, 0.87, 0.89, 0.89, -4.25, 0.5, 4.33, 1.16, 1.04, 0.39, -0.43, 1.56, 1.18, 0.55, 0.15, 0.37, 0.83, 1.76, 0.84, 0.66], ['472', -6.98, 0.13, -0.25, 0.11, -1.04, -1.5, -1.29, -2.25, -2.48, -2.24, 0.66, -1.02, -0.35608673487915105, -0.41, 0.49, -1.3, -0.34, -1.48, -3.86, 0.49, -3.162664517912641, 0.39, -0.3, -0.5, -2.28, -2.45, -2.88, -1.66, -1.07, -1.06, -0.16, -1.94, -0.99, -2.12, -4.04429761904762, -0.17, -3.83, -0.27, -0.96, -1.15, -2.7, -3.3, -1.24, 0.6, 0.61, 1.52, -0.28, 0.68, -0.47, -2.87, 1.52, -2.21, 1.42, 0.72, 0.52, -0.8199371536943234, -2.44, -3.1, -3.01, -1.83, 0.01, 0.92, -0.88, 0.08, -1.06, -3.45, 0.92, -2.79, 0.81, 0.12, -0.08, -3.12, -1.84, 0.91, -0.89, 0.07, -1.07, -3.47, 0.9, -2.8, 0.8, 0.11, -0.03644035827487928, -3.33, -5.78, 5.83, -2.72, -1.78, -0.83, -1.96, -4.33, 0.0, -3.67, -0.1, -0.79, -0.99, -2.34, -0.8826334687834371, 0.97, -0.19, -2.6, 1.81, -1.93, 1.7, 1.0, 0.81, -0.67, -0.93, -2.61, -1.54, -1.56, -1.54, -1.8381905235138707, -1.14, -3.53, 0.83, -2.87, 0.73, 0.04, -0.16, -2.52, -0.77, -2.42, 2.0, -1.75, 1.89, 1.19, 0.99, -2.31, -2.26, -0.04, -1.596813216376432, -4.62, -0.22, -0.16, 2.76, -2.78, -1.4, -1.26, -1.88, 5.27, 3.07, 1.55, -3.54, -0.93, -4.56, 4.63, 4.56, -1.466709195136147, 4.25, -3.07, -1.57, 0.77, -5.72, 8.58, 3.85, 5.71, -5.292869047619047, 1.68, 4.52, 0.69, 4.42, 3.7, 3.5, -4.52, -2.72, -3.67, -0.1, -0.79, -0.98, 0.99, 3.798878591106422, 2.99, 2.79, -2.6, -3.05, -2.62, -0.69, -0.88, -1.53, -1.61, -2.2, 4.16, -2.53, -4.2, -1.42, -2.02, -1.94, -0.2, -1.68, -1.23, -0.99, -0.38, -1.75, -1.75, -1.29, -1.86, -1.85], ['473', 2.3, 0.25, 0.18122171562045875, -0.14, 0.3329790809910596, 0.3, 0.97, 0.37, -0.35, 2.89, 3.56, 2.48, 2.14, 3.39, 1.94, 2.29, 1.14, 2.66, 2.44, 2.41, 1.87, 2.18, 1.644305231600676, 2.15, 0.12, 0.49, -0.65, -1.04, -1.37, -0.17, -1.56, -1.23, -2.33, -0.87, -1.08, -1.11, -1.63, -1.33, -1.94, -1.36, 0.17, -2.5050638007838266, 0.4, -0.33, 1.057875394446823, -0.52, -0.19, -1.31, 0.18, -0.04, -0.07, -0.5803452707629391, -0.29, -0.91, -0.32, 0.0, -0.24, 0.13, -0.24, 0.73, 1.22, -0.2, 0.14, -0.98, 0.51, 0.29, 0.26, -0.26, 0.04, -0.58, 0.01, 0.23, -0.48, -1.4, -1.06, -2.17, -0.71, -0.92, -0.95, -1.47, -1.17, -1.78, -1.2, -1.08, 3.49, -3.53, 0.93, 0.34, -0.78, 0.7, 0.49, 0.46, -0.07, 0.24, -0.39, 0.21, -0.04, 0.59, -1.12, 0.36, 0.15, 0.12, -0.41, -0.1, -0.72, -0.13, 0.28, 0.63, 3.6, 0.61, 0.72, 0.56, 1.73, 1.5, 1.28, 1.25, 0.72, 1.03, 0.4, 1.0585846838830657, 0.9265360710717855, 0.27307674813036725, 0.04368558029272332, -0.24, -0.77, -0.46, -1.08, -0.49, 2.0189583699631246, 1.98, -0.19396282112195956, 1.17, -0.29, 0.26, 0.13, -1.05, 1.03, 0.5788101710076211, 0.43, 0.52, -0.88, -1.3, -0.6, 1.25, 0.39, 1.8914761904761903, -1.9, -1.8, 0.6, -1.55, 1.24, 0.92, -0.5, 5.09, -3.79, -3.43, -5.18, 0.9, 0.44, -0.03, -0.55, -0.25, -0.87, -0.28, 1.79, 0.47, -0.38580741107631855, -0.22, -0.84, -0.25, 1.0, 0.31, -0.32, 0.28, -0.36, -0.76, 0.69, -0.62, -0.03, 0.59, 0.71, 0.43, -3.95, 2.62, 3.85, 0.4918948994148555, 0.54, 1.32, 0.6, 0.7200774025227806, 0.52, 0.3, 0.43, 0.42, 0.72, 2.86, 1.38, 1.25], ['474', -0.72, 0.41, 0.12, -0.1, 0.11, 0.1484196236737595, 0.24411525795982916, 0.09, -0.16, -0.08, 0.19, 0.05, 0.61, 0.67, -0.56, -0.14, -0.72, -0.1, 1.35, -0.66, -0.28, -0.53, -1.22, -0.48, -0.91, 0.36, -0.27, -0.14, 0.41, 0.48, -0.75, -0.33, -0.91, -0.29, 1.16, -0.85, -0.47, -0.72, -1.41, -0.67, 0.39, -0.38, -0.13, 0.56, 0.63, -0.6, -0.18, -0.77, -0.15, 1.3, -0.71, -0.301934531913557, -0.58, -1.2357142857142858, -0.53, 6.07, 0.42, 0.017827972809783946, 0.05, -0.68, 0.07, -1.15, -0.74, -1.32, -0.7, 0.74, -1.26, -0.88, -1.13, -1.82, -1.08, -0.41, -0.75, -1.22, -0.8, -1.38, -0.77, 0.67, -1.33, -0.95, -1.19, -1.88, -1.15, -0.23, 2.8, -2.83, 0.48, 0.42, -0.16, 0.46, 1.92, -0.11, 0.28, 0.03, -0.67, 0.07, 0.0, 0.06, -0.58, 0.03, 1.49, -0.53, -0.15, -0.39, -1.09, -0.35, -0.04, 0.07, 0.76, 0.38, 0.46, 0.29567351865003194, 0.64, 0.62, 2.09, 0.06, 0.44, 0.19, -0.51, 0.24, 0.35, 0.07307674813036727, 1.46, -0.56, -0.17043764172335601, -0.42, -1.12, -0.38, 0.92, 1.16, -0.09, 0.53, 0.01, 0.05, 0.04, -1.06, 1.1417201258125629, 0.51, 0.16, -0.18, -1.18, -0.75, -0.36, -0.35, -0.57, 1.14, -1.16, -1.12, 0.37, -1.55, 0.76, 0.83, -0.41, 1.91, -4.38, -1.29, -1.98, 1.23, -1.41, -1.99, -1.61, -1.86, -2.54, -1.6442382871563543, 1.12, 0.59, 0.39, 0.14, -0.56, 0.18, 0.2, -0.25, -0.94, -0.2, -0.1, -0.06, 0.45, -0.7, 0.04, 0.37, 0.42, 0.20257604962387837, -2.05, 0.8, 2.12, 0.2, 0.83, 1.16, 0.75, 0.58, 0.59, -0.67, -1.04, -0.23, 0.41, 0.29, 0.85, 0.13], ['475', -4.772857142857143, -0.07, -0.04, 0.18, -1.52, -1.12, 0.5, -1.29, -0.63, -1.04, 0.61, -1.8, -0.58, 0.55, 0.39, 0.42, 0.29, -0.85, 2.45, 2.3, -1.32, -1.04, 0.4, 0.26, -1.83, -1.35, -1.64, -2.39, -1.18, -0.06, -0.22, -0.19, -0.31, -1.45, 1.83, 1.67, -1.92, -1.64, -0.21, -0.35, -1.06, -0.19, 0.7702040816326531, 1.24, 2.39, 2.23, 2.26, 2.13, 0.96, 4.33, 4.17, 0.48, 0.77, 2.24, 2.1, -0.57, -0.5, -0.84, -1.25, -0.46, 1.14, 0.98, 1.0, 0.88, -0.27, 3.05, 2.89, -0.75, -0.46, 0.99, 0.85, -1.31, -1.58, -0.16, -0.13, -0.25, -1.39, 1.89, 1.74, -1.86, -1.58, -0.15, -0.29, -1.04, -3.71, 3.73, -1.43, 0.03, -0.1, -1.24, 2.05, 1.9, -1.71, -1.43, 0.01, -0.13, -3.54, -1.45, -0.12, -1.26, 2.02, 1.87, -1.73, -1.45, -0.02, -0.16, 0.061141873999016993, -1.5, -0.31, -1.09, -0.93, -1.24, -1.33, -1.0034006093113235, 2.15, 1.99, -1.61, -1.33, 0.11, -0.03, -0.08, -0.19, 3.33, 3.17, -0.48, -0.19, 1.26, 1.12, -1.53, -1.16, 0.35, -0.99, -10.61, -0.03, 0.14, 3.65, -3.63, -1.83, -0.21, -2.27, 6.38, 2.19, 1.1, -2.3747789115646256, -0.55, -3.35, 3.21, 3.33, -1.1, 5.45, -2.18, -1.22, 0.58, -3.89, 2.26, 2.57, 3.83, -6.28, -3.41, -0.15, -3.68, -3.41, -2.0, -2.14, -3.26, -3.26, -3.54, -3.26, -1.85, -1.99, 0.29, 0.29, 1.75, 1.6, -0.61, -1.07, 0.0, 1.46, 1.32, -1.07, -1.09, -1.35, 0.95, -0.39, -1.17, -0.96, -0.56, -1.44, -0.14, -1.09, -1.56, -0.32, 0.12022448979591838, -1.03, -1.3, -0.66, -0.37, -1.36], ['476', 5.09, 0.8, 0.011221715620458745, -0.1, 0.64, 0.56, 0.0, 1.4, 0.54, -0.03, -0.36, 0.801934498041641, -1.35, -2.18, -1.97, -0.84, -0.22, -0.22, 1.57, -0.8, 0.48, -0.18, -0.6, 0.03, 2.0, 1.49, 0.33, 0.96, -1.0, -1.83, -1.62, -0.49, 0.13, 0.13, 1.93, -0.45, 0.84, 0.18, -0.25, 0.38, 0.52, 1.77, -0.62, -1.94, -2.76, -2.55, -1.43, -0.82, -0.82, 0.971652133580705, -1.39, -0.12, -0.78, -1.19, -0.57, 1.11, 1.01, 0.15, 0.83, 1.34, -0.84, -0.62, 0.52, 1.15, 1.14, 2.96, 0.56, 1.86, 1.19, 0.76, 1.4, 1.0, 2.2, 0.22, 1.37, 2.0, 2.0, 3.83, 1.41, 2.72, 2.04, 1.61, 2.26, 0.87, 1.26, -1.29, 1.98, 1.15, 1.78, 1.78, 3.61, 1.19, 2.5, 1.82, 1.39, 2.04, 3.92, 0.82, 0.63, 0.62, 2.43, 0.04, 1.33, 0.67, 0.24, 0.88, 0.26, 0.9593682032253462, -0.73, 0.53, 0.52, 0.51, 0.19, 0.0, 1.8, -0.58, 0.7, 0.04, -0.38, 0.25, 0.11, 0.2, 1.8, -0.58, 0.7, 0.04, -0.38, 0.25, 0.38, 0.0, 0.12, 0.22, 11.79, 0.02, -0.02, -1.62, 1.63, 0.82, -0.06, 1.3661635321120496, -1.45, -1.02, -0.55, 2.51, 0.2, 1.61, -1.62, -1.55, 0.54, -2.4, 1.06, 0.26, -0.055234735715753214, 0.64, -3.65, -0.44, -0.61, 1.47, -1.57, -2.33, -1.07, -1.72, -2.14, -1.52, 1.51, 0.78, 1.29, 0.62, 0.2, 0.83, -0.5, -0.66, -1.07, -0.45, 0.57, 0.72, 0.15, -0.42, 0.21, 0.55, 0.47, 1.4425760496238782, -1.69, -0.68, 1.67, 1.2, 1.05, 0.58, 0.63, 0.34, 0.81, 0.19, 0.08, 0.59, -0.06, 3.63, 1.42, -0.28], ['477', -1.49, 0.06, 0.05122171562045875, 0.05, -0.14, 0.82, 1.79, 0.29, 1.26, 1.2, 0.3, -0.18, 0.64, 0.47, 1.15, 1.41, 0.25, 1.23, 0.1, 1.17, 1.1, 0.31, 0.32, 0.76, 1.67, 0.14, 0.9, -0.48, 0.33, 0.17, 0.85, 1.1, -0.05, 0.92, -0.2, 0.87, 0.8, 0.01, 0.02, 0.45, -0.86, 1.9700621118012422, 1.38, 0.81, 0.65, 1.33, 1.59, 0.43, 1.4, 0.28, 1.35, 1.28, 0.49, 0.5, 0.94, 0.85, 0.51, 0.52, 0.78, 0.56, -0.17, 0.51, 0.77, -0.38, 0.59, -0.53, 0.6539757335335068, 0.46, -0.32, -0.32, 0.12, 0.76, 0.73, 0.68, 0.93, -0.22, 0.75, -0.37, 0.7, 0.63, -0.16, -0.15, 0.29, 1.61, 2.34, -2.24, 0.05, 0.3480874332127649, -0.89, 0.08, -1.04, 0.2137447711019141, -0.04, -0.83, -0.82, -0.39, -0.34, -0.2, -1.14, -0.18, -1.29, -0.23, -0.3, -1.08, -1.07, -0.64, 0.04, -0.17, 0.89, 0.73, 0.71, 0.76, 0.9509570400359874, 0.97, -0.14984126984126983, 0.91, 0.85, 0.06, 0.07, 0.5585846838830657, 0.78, -0.02, -1.11, -0.05, -0.12, -0.9, -0.9, -0.46, 0.86, 0.83, 0.04, 0.8, -0.84, 0.11, 0.0, -1.62, 1.63, 0.82, 0.54, 0.34, -0.01, -1.4, -0.69, -0.75, 0.75, 2.18, -2.12, -2.17, 0.74, -2.43, 1.46, -0.39, 0.19, 2.82, -4.59, -1.86, -2.77, 0.0, 1.1, 1.07, 1.0, 0.21, 0.22, 0.66, 2.16, 0.03, -0.07, -0.85, -0.84, -0.41, 0.1, -0.78, -0.78, -0.34, 1.26, 1.32, 0.89, 0.01, 0.44, 0.73, 0.75, 0.31, -2.73, 1.0501996269574994, 2.69, 1.19, 0.74, 0.88, 0.44, 0.67, 1.06, 0.41, 0.93, 0.39, 0.44, 0.0, 1.33, -0.01], ['478', 3.22, -0.08, -0.17877828437954127, 0.08, -0.33, -0.6115803763262405, -0.71, -1.88, -1.79, -1.61, 1.58, -0.41, -0.11, -0.08, 0.38, -3.39, -0.41, -1.89, -2.3, -1.47, -2.63, -1.14, 0.26, -0.75, -1.85, -0.61, -3.14, -1.96, -1.66, -1.63, -1.18, -4.89, -1.96, -3.42, -3.81, -3.0, -4.149239316239316, -2.68, -1.3, -2.246158276802161, -1.66, -2.3550638007838267, -1.2, 0.3, 0.34, 0.8, -2.99, 0.0, -1.169454081632653, -1.89, -1.06, -2.23, -0.73, 0.67, -0.34, -0.9299371536943234, -1.75, -1.5321720271902162, -1.0, -1.5, 0.04, 0.49, -3.28, -0.3, -1.6773949338599383, -2.19, -1.36, -2.52, -1.03, 0.37, -0.64, -2.44, -1.53, 0.46, -3.31, -0.34, -1.82, -2.22, -1.4, -2.56, -1.07, 0.33, -0.67, -2.14, -4.91, 4.68, -1.98, -3.75, -0.79, -2.26, -2.67, -1.85, -3.0, -1.52, -0.12, -1.12, 1.71, 1.84, 3.08, 1.55, 1.13, 1.98, 0.78, 2.32, 3.77, 2.73, 0.21, 1.87, -1.79427628811696, -0.6584018193170985, -0.85, -0.584326481349968, -1.2, -1.3434006093113235, -1.89, -1.06, -2.23, -0.73, 0.67, -0.33, -0.46, 0.29, -0.41, 0.43, -0.76, 0.8857995496566927, 2.19, 1.17, -2.5, -2.53, -0.33, -0.8, 3.48, -0.56, -0.36, 0.51, -0.48, -0.26, -0.47, -1.21, 0.45775897911612196, 1.42, 0.73, 1.68, -0.12, -2.21, 2.25, 2.12, -0.73, 0.78, -1.45, -0.92, 0.46, -3.79, 2.73, 2.45, 3.54, -0.2, 0.7, 0.84, -0.35, 1.18, 2.61, 1.59, -2.2, -0.14, -1.18, 0.33, 1.75, 0.74, 1.05, 1.53, 2.97, 1.94, -1.83, -1.95, -0.47, 1.41, 0.4, -0.73, -0.79, -1.82, 1.46, -2.05, -1.49, -0.98, -0.82, -1.86, -1.0, -1.46, -0.23, 0.39529795204795226, 0.18, -0.66, -0.87, -0.72, -0.88, -1.3769832262926027], ['479', 3.21, 1.04, -0.04, 0.05, -0.41, -0.6015803763262405, -1.11, -0.9, -0.77, -1.55, -0.28, -1.55, -1.21, -0.09, -0.38, -2.14, -0.69, -1.47, -1.29, -0.44, -1.44, -1.52, -0.73, -0.69, -0.5314063389924735, -0.35, -1.27, -1.27, -0.94, 0.19, -0.1, -1.86, -0.41, -1.2, -1.01, -0.17, -1.16, -1.24, -0.45, -0.42, -0.26, -0.77, 0.0, 0.34, 1.48, 1.18, -0.6, 0.87, 0.39054591836734703, 0.26, 1.12, 0.11, 0.03, 0.83, 0.87, -0.28, 0.3, -0.68, -0.55, -0.34, 1.14, 0.84, -0.94, 0.53, -0.27, -0.08, 0.78, -0.23, -0.31, 0.49, 0.52, -1.46, -1.46, -0.3, -2.05, -0.6, -1.39, -1.2, -0.36, -1.35, -1.43, -0.65, -0.61, -1.36, -2.0, 2.19, -1.17, -1.76, -0.3, -1.1, -0.91, -0.06, -1.06, -1.14, -0.35, -0.2559922724755494, 2.78, 0.6, 1.48, 0.68, 0.87, 1.73, 0.71, 0.64, 1.44, 1.48, -0.16, 0.61, -1.67427628811696, -0.71, -0.71, -0.74, -0.87, -0.79, -0.61, 0.24, -0.76, -0.83, -0.05, -0.01, -0.01, -0.01692325186963274, 0.19, 1.04, 0.04, -0.04, 0.75, 0.79, -0.85, -0.66, 0.05, -0.82, 8.17, 0.05, 0.1, 2.06, -2.04, -1.0, 0.42, 0.29, 2.22, 1.44, 0.75, 1.68, -0.46, -2.09, 2.15, 2.17, -0.71, 3.1, -1.41, -1.49, 0.74, -2.56, 4.750651360544218, 1.83, 2.71, -2.15, -0.26, 0.85, -0.15, -0.23, 0.5966255411255412, 0.6, -2.2, -1.1098412698412699, -1.0, -1.08, -0.29, -0.25, -0.11, -0.08, 0.72, 0.76, -0.79, -1.2, -0.03, 0.8, 0.83, -0.6379199656859431, -0.74, -0.89, 2.65, -1.9196667372159368, -2.64, -1.39, -0.31, -0.82, 0.04, -0.89, -1.06, -0.31, -0.34, -0.58, -0.86, 0.1, -1.05, -1.15], ['480', 1.65, 0.0, 0.3412217156204588, -0.06, 0.61, -0.29, 0.43, 0.55, 0.5793780543870106, 0.23, -0.67, 0.32, -0.27, 0.11, -0.44, -0.31, 0.68, -0.1, -2.42, -1.88, 0.32, 0.19, -0.8, 0.72, 1.04, 0.689371414588892, 0.91, 1.0, 0.4, 0.79, 0.23, 0.36, 1.36, 0.58, -1.76, -1.22, 1.0, 0.86, -0.13, 1.4, 1.22, 1.04, -0.08, -0.59, -0.2, -0.6891849704247235, -0.63, 0.36, -0.42, -2.72, -2.19, 0.0, -0.13, -1.12, 0.4, 0.6900628463056766, 1.85, 0.22, 0.68, 0.51, 0.39, -0.17, -0.04, 0.95, 0.17, -2.15, -1.4960242664664933, 0.59, 0.46, -0.53, 1.0, 0.4336060011417156, 0.12, -0.56, -0.42, 0.56, -0.21, -2.53, -2.0, 0.2, 0.07, -0.92, 0.61, 0.69, 1.98, -2.07, 0.7166982383853202, 0.13, 1.12, 0.34, -1.98, -1.45, 0.77, 0.63, -0.36, 1.2240077275244505, -1.75, 0.54, 0.99, 0.21, -2.11, -1.58, 0.63, 0.5, -0.5, 1.03, 0.38, 0.53, -1.31, 0.12, 0.42, -0.36432648134996803, -0.44, -0.77, -3.07, -2.54, -0.34931972789115645, -0.49, -1.47, 0.04, 0.11, 0.33, -2.32, -1.79, 0.42, 0.29, -0.71, 0.82, 0.97, 0.63, 0.38603717887804045, -0.34, -6.09, 0.18, -0.2, 1.21, -1.31, -0.63, -0.69, 0.7, -4.25, -0.14, -0.09, 0.84, 0.15, 0.3, -0.32, -0.32, 0.13, 1.95, 0.23, -0.53, 0.24, -1.32, -1.91, 0.94, 1.43, 4.15, 2.71, 0.54, 2.8, 2.67, 1.65, 3.21, 0.33, 2.16, 2.25, 2.11, 1.1, 2.65, -0.09, -0.13, -1.12, 0.4, 0.55, 0.55, 0.13727468490743444, -0.99, 0.53, 0.1, 0.06439630127529085, 0.49, -1.17, -0.99, 1.18, -0.15, 1.6, 1.05, 1.54, -0.43, -0.48, -0.03, 0.45, -0.08, -0.404042472976186, 0.13, 1.7930376647162363, -0.79], ['481', -6.64, -0.28, -0.27, 0.09, -1.31, -1.6815803763262405, -1.4458847420401708, -3.76, -3.1, -5.36, -0.37, -3.41, -2.23, -1.64, -1.56, -2.73, -3.26, -4.95, -3.12, -3.8130204081632653, -6.38, -3.21, -2.69, -4.48, -3.28, -2.73, -4.977341605006887, -3.05, -1.87, -1.27, -1.2, -2.37, -2.9, -4.59, -2.76, -3.5, -6.04, -2.85, -2.32, -4.13, -2.73, -5.68, -2.02, 1.301197467496117, 1.83, 1.9808150295752764, 0.7, 0.15, -1.279454081632653, 0.3, -0.47, -3.08, 0.2, 0.75, -1.12, -2.13, -2.34, -1.92, -2.67, -3.2, 0.61, 0.69, -0.51, -1.05, -2.78, -0.91, -1.66, -4.25, -1.0, -0.46, -2.3, -3.53, -3.78, 0.08, -1.11, -1.65, -3.36, -1.5, -2.26, -4.83, -1.6, -1.07, -2.89, -4.38, -7.35, 7.3, -3.86, -1.19, -1.72, -3.44, -1.58, -2.34, -4.9, -1.67, -1.14, -2.9159922724755494, -4.32, -2.7, -0.54, -2.28, -0.4, -1.16, -3.76, -0.49, 0.04, -1.8, -0.47, -2.65, -2.15427628811696, -1.92, -2.06, -1.7543264813499682, -2.17, -1.75, 0.14, -0.62, -3.23, 0.05, 0.59, -1.27, -2.1, -0.43, 1.92, 1.14, -1.51, 1.83, 2.38, 0.49, -1.93, -1.51, -0.1, -2.18, -12.62, -0.5, -0.36, 3.01, -3.017537676609105, -1.53, -0.55, -5.22, 3.1, 3.89, 1.92, -3.42, -1.19, -5.9085238095238095, 5.8, 5.81, -1.94, 4.55, -3.85, -1.97, 1.05, -6.45, 5.04, 4.32, 6.13, -3.07, -2.31, -0.77, -3.37, -0.1, 0.45, -1.41, -5.79, -1.56, -2.63, 0.68, 1.22, -0.65, 1.1, 3.39, 3.95, 2.03, -2.98, -3.71, -2.22, 0.54, -1.32, -1.96, -1.92, -3.63, 2.78, -2.0698003730425008, -2.93, -2.7127361894755664, -3.48, -2.75, -1.85, -2.1199225974772196, -1.58, -1.09, -1.33, -1.39, -0.92, -4.85, -4.77, -0.95], ['482', 1.07, 0.3, -0.20877828437954127, 0.1, -0.17, -0.3, -0.84, -0.16, -1.15, 0.49535714285714283, 1.73, 1.23, 0.51, 0.97, 0.37, 0.92, 0.6, 0.23, -0.85, 1.12, 0.43, 0.66, 1.17, 0.41217460317460314, -1.1, -0.9, -1.28, -0.49, -1.2, -0.74, -1.34, -0.8, -1.11, -1.48, -2.54, -0.6, -1.28, -1.05, -0.56, -1.3, -0.11, -2.3450638007838265, -0.79, -0.71, -0.25, -0.85, -0.31, -0.62, -0.99, -2.06, -0.11, -0.79, -0.56, -0.06, -0.81, -0.61, -0.48, -1.95, -1.19, -0.08, 0.46, -0.15, 0.4, 0.09, -0.28, -1.36, 0.6, -0.08, 0.15, 0.65, -0.1, 1.17, -0.54, -0.17977210884353745, -0.06, -0.37, -0.74, -1.81, 0.14, -0.54, -0.31, 0.19, -0.56, -1.92, -1.4, 1.44, 0.07, 0.55, 0.23, -0.14, -1.21, 0.75, 0.06, 0.29, 0.8, 0.05, -1.55, -0.48, -0.31, -0.68, -1.75, 0.2, -0.48, -0.25, 0.25, -0.5, 0.18, -0.4, -0.04427628811695997, -0.32, -0.5, -0.06, -0.17, -0.37, -1.44, 0.51, -0.17, 0.06, 0.56, -0.13141531611693433, -0.34, 0.2, -1.08, 0.88, 0.2, 0.43, 0.93, 0.18, -0.08, -0.09, -0.01, 0.13, -4.65, 0.09354725829725827, 0.0, -0.12, 0.08, 0.03, -0.01, 0.8, 1.3, 0.61, 0.28, 0.53, -0.24, -0.83, 0.86, 1.02, -0.3, -0.19, -0.61, -0.44, 0.19, -0.53, 1.69, 0.3, 0.53, -1.26, 1.3, 1.98, 1.29, 1.53, 2.03, 1.27, -0.92, -0.67, -0.68, -0.45, 0.05, -0.7, 0.0, 0.23, 0.73, -0.02, -1.067204648526077, -1.28, -0.23, 0.5, -0.25, -0.32, -0.25, -0.11, 1.07, 0.21, -1.06, -0.53, -0.94, -0.72, -0.6672131485030683, -0.48, 0.06, -0.41, -0.01, 0.0, 0.105957527023814, -1.44, -0.9, 0.53], ['483', 1.8842857142857141, -0.54, -0.04, 0.02, -0.89, 0.12, -0.21588474204017086, 0.13, 1.05, -0.31, -1.9, -0.7, -0.56, -0.33, -0.16, -0.87, -0.2, -1.5494285714285714, 1.79, 2.49, 0.29733548208735894, -1.1, -0.68, -0.67, 0.8, -0.1, 1.62, 1.22, 1.37, 1.6, 1.77, 1.05, 1.73, 0.36, 3.76, 4.47, 2.2, 0.82, 1.25, 1.25, -0.03, 2.34, 0.5993032324818041, 0.15, 0.37, 0.54, -0.17, 0.5, -0.85, 2.51, 3.22, 0.97, -0.4, 0.03, 0.03, 1.62, 0.15, 0.0, 0.81, 0.25, 0.22, 0.4, -0.32, 0.36, -1.0, 2.36, 3.06, 0.83, -0.54, -0.12, -0.12, -0.0063939988582844, 0.03, 0.17, -0.54, 0.13, -1.22, 2.13, 2.83, 0.6, -0.77, -0.34, -0.34, 2.21, 1.61, -1.61, -0.14, -0.71, -0.04, -1.39, 1.96, 2.66, 0.43, -0.94, -0.51, -0.51, 0.54, 0.57, 0.67, -0.6778809523809525, 2.69, 3.39, 1.14, -0.23, 0.2, 0.2, 0.96, 0.54, 0.74, 0.26, 0.43, 0.07, -0.1, -1.35, 2.0, 2.7, 0.47, -0.9, -0.47, -0.47, 0.68, 1.26, 3.6436855802927233, 4.1, 1.84, 0.46, 0.89, 0.89, 0.3, 0.93, 0.09, -0.06, 1.2277380952380952, 0.31, 0.21, 0.44, -0.52, -0.48, -0.14, -0.34, 5.45, -0.49, -0.26, 0.81, 0.47, 0.77, -0.74, -0.74, -0.26, 1.01, 0.47, 0.93, -0.54, -0.3, -1.05, 0.17, 0.24, -5.42, -2.06, 0.69, -1.5, -2.84, -2.42, -2.42, 0.78, -2.73, -2.17, -3.5, -3.09, -3.09, -0.57, -1.36, -0.94, -0.93, 1.0, 1.52, 0.8, 0.43, 0.43, 0.22, 0.24, 0.04, -0.23, 0.66, 0.39, -0.71, -0.8, 0.37, 0.07278685149693166, 0.03, -0.45, -0.06, -0.38, -0.34, 0.37, -0.49, -0.2, 1.02], ['484', 5.91, 1.35, 0.46, -0.06, 2.0929790809910593, 1.28, 1.67, 1.41, 1.96, 0.76, -1.55, -0.94, -0.2, -0.26, -1.29, -0.55, -0.84, 0.28, 2.0, -2.08, 1.23, -0.23, -0.67, -0.97, 1.37, 1.55, 2.3826583949931126, 0.63, 1.38, 1.31, 0.26, 1.03, 0.73, 1.87, 3.61, -0.53, 2.83, 1.35, 0.9, 0.6338417231978392, 1.36, 3.13, 1.71, 0.74, 0.68, -0.36, 0.39, 0.1, 1.23, 2.96, -1.15, 2.19, 0.72, 0.27, -0.04, 0.48, 0.9, 0.79, 1.67, 0.96, -0.06, -1.1, -0.35, -0.64, 0.49, 2.2, -1.88, 1.43, -0.03, -0.47, -0.77, 2.1, 1.03, -1.03, -0.28, -0.58, 0.55, 2.27, -1.82, 1.5, 0.04, -0.41, -0.71, 2.55, 4.0, -3.95, 2.08, 0.76, 0.4717857142857143, 1.6, 3.33, -0.79, 2.56, 1.08, 0.63, 0.33, 2.58, 1.3873665312165628, -0.29, 0.83, 2.56, -1.54, 1.79, 0.32, -0.12, -0.43, 1.06, 1.31, 1.43, 1.6115981806829016, 1.4451790696343398, 1.69, 1.6818094764861293, 1.13, 2.86, -1.25, 2.09, 0.62, 0.17, -0.07141531611693433, 0.79, 0.48, 1.71, -2.36, 0.94, -0.51, -0.95, -1.25, 1.33, 1.43, 0.08, 1.51, 7.46, 0.18, 0.34, -3.78, 3.79, 1.89, 0.56, 1.0861635321120495, -5.83, -3.1, -1.54, 2.98, 0.56, 4.61, -4.7, -4.68, 1.54, -5.68, 3.07, 1.01, -0.53, 4.86, -11.72, -3.25, -4.8, 5.75, -1.21, -3.99, -0.75, -2.18, -2.61, -2.91, 4.69, 2.9, 3.38, 1.89, 1.44, 1.13, -0.46, -1.3511214088935783, -1.88, -2.17, 1.94, 2.3, 0.99, -0.44, -0.75, 1.54, 1.53, 1.38, -6.89, 1.93, 6.92, 2.09, 1.84, 1.44, -0.3, 1.55, 2.2, 1.16, -0.01, 0.8746262438247291, 1.75, 2.25, 2.75, 1.96], ['485', 4.95, 0.18, -0.19, -0.17, 0.92, -0.05, 1.47, -0.25, 0.34, 0.35, 0.19, -1.21, 0.73, 1.39, 0.11, -0.64, 0.9, 1.06, -1.37, 0.12, 0.76, 0.97, 0.46, 0.25, 0.08, -0.1, 0.16, -1.4, 0.53, 1.2, -0.09, -0.83, 0.7, 0.86, -1.56, -0.07, 0.57, 0.78, 0.3688796134390452, 0.10384172319783916, 0.1, -1.0250638007838266, 1.58, 1.96, 2.797875394446823, 1.33, 0.58, 2.13, 2.29, -0.16, 1.35, 2.028065468086443, 2.21, 1.69, 1.47, -0.7699371536943234, 0.55, 0.19, 0.0, -0.38, 0.66, -0.61, -1.36, 0.17, 0.33, -2.08, -0.6, 0.04, 0.25, -0.26, -0.47, -0.1, -1.03, -1.27, -2.01, -0.49, -0.33, -2.73, -1.26, -0.62, -0.41, -0.92, -1.13, 0.0, -0.37, 0.32, 0.27669823838532015, -0.75, 0.79, 0.95, -1.48, 0.01, 0.66, 0.87, 0.36, 0.14, 0.47, 0.99, 1.55, 1.71, -0.74, 0.77, 1.41, 1.62, 1.11, 0.89, -0.44, 0.95, -0.73427628811696, -0.05, -0.08, -0.03, -0.54, 0.16, -2.25, -0.77, -0.13, 0.08, -0.43, -0.64, -0.59, -0.7, -2.4, -0.93, -0.29, -0.08, -0.59, -0.8, 0.59, 0.18, -0.34, -0.27, 1.48, -0.15, 0.07, -0.25, 0.21, 0.13, 0.17, -0.97, -0.42, 0.1, 0.06, 2.5, -0.01, -0.18, 0.28, 0.19, 0.003290804863852956, -0.31, -0.1, 1.18, -0.6, -1.62, 5.05, 1.04, 1.53, 0.7956150793650794, 1.74, 1.51, 2.17, 2.38, 1.86, 1.64, -0.15, 0.23, 0.64, 0.85, 0.34, 0.13, -0.41, 0.21, -0.3, -0.51, 0.31, 0.06, -0.62, -0.51, -0.72, -0.06, -0.1, -0.27, 2.76, -0.4, -2.8, -0.13, -0.17, -0.11, -0.21, -0.39, 0.08, 0.08, 0.12, -0.02, 0.1, -0.43, 0.55, -0.68], ['486', -2.65, 0.7614285714285715, 0.7412217156204587, -0.12, 1.04, 2.01, 1.0741152579598292, 2.29, 2.26, 2.18, -0.84, 0.58, 0.57, -0.23602380952380952, 0.8, 5.75, -1.06, 1.49, 0.66, -1.29, 2.71, -0.54, -1.8, 0.09, 3.31, 1.48, 3.05, 1.43, 1.42, 0.61, 1.65, 6.64, -0.23, 2.34, 1.51, -0.45, 3.57, 0.3, -0.97, 0.94, 1.34, 2.8949361992161733, 1.6, -0.01, -0.81, 0.22, 5.14, -1.63, 0.9, 0.08, -1.85, 2.12, -1.11, -2.36, -0.48, 0.92, 2.22, 1.89, 2.31, 1.6, -0.8, 0.23, 5.15, -1.62, 0.91, 0.09, -1.85, 2.13, -1.1, -2.35, -0.47, 3.3, 2.42, 1.04, 6.0, -0.6805105874517637, 1.7332142857142856, 0.9, -1.05, 2.95, -0.3, -1.57, 0.33, 2.5, 11.23, -11.32, 1.37, 4.91, -1.85, 0.68, -0.14, -2.07, 1.89, -1.33, -2.58, -0.6459922724755494, -0.67, -3.37, -6.44, -4.03, -4.82, -6.65, -2.88, -5.95, -7.14, -5.35, 0.81, -3.38, 3.62, 2.38, 2.75, 2.28, 3.28, 2.58, 1.74, -0.22, 3.81, 0.53, -0.74, 1.17, 2.63, 0.69, -0.82, -2.73, 1.2, -1.99, -3.24, -1.37, 5.23, 5.45, 0.28, 3.13, -1.25, 0.92, 0.64, -4.07, 4.05, 2.01, 1.35, 2.08, -7.04, -4.74, -2.44, -1.24, 1.74, 7.5, -7.5, -7.16, 2.36, -6.16, 4.76, 2.55, -1.26, 9.95, -6.62, -6.71, -9.92, 6.8, 1.52, -1.93, 2.04, -1.19, -2.44, -0.56, 7.12, 3.5201587301587303, 4.05, 0.76, -0.52, 1.4, -0.51, -3.16, -4.39, -2.54, 2.33, 2.42, 2.73, -1.27, 0.63, 2.42, 2.55, 2.23, -3.04, 3.32, 3.22, 2.31, 3.21, 4.06, 1.93, 2.6, 2.02, 1.55, 1.13, 2.09, 2.09, 3.89, 5.08, 3.38], ['487', -4.29, -0.06, -0.5687782843795413, 0.29, -1.48, -1.15, -1.36, -2.31, -3.69, -1.94, 2.59, 3.01, 0.37, -0.23, 1.13, -0.87, -1.03, -1.46, -1.62, -1.09, -3.28, -1.95, 0.034305231600676125, -1.52, -3.06, -1.0, -4.42, 0.41, -1.7423253968253969, -2.75, -1.42, -3.37, -3.54, -3.96, -4.1, -3.59, -5.73, -4.43, -2.58, -4.01, -2.7625315746467893, -5.245063800783826, -4.81, -2.478802532503883, -3.14, -1.82, -3.76, -3.93, -4.34, -4.49, -3.98, -6.11, -4.81, -2.98, -4.4, -0.28, -3.36, -1.62, -2.36, -2.31, -0.6, 0.7507993197278912, -1.24, -1.4, -1.83, -1.98, -1.46, -3.65, -2.3067380952380954, -0.43, -1.89, -2.3, -1.72, 1.3746428571428573, -0.64, -0.81, -1.24, -1.39, -0.87, -3.06, -1.72, 0.30309548189905344, -1.3, -4.39, -4.53, 4.52, -3.0033017616146798, -1.98, -2.14, -2.57, -2.72, -2.2, -4.37, -3.04, -1.18, -2.62, -2.32, -1.09, -0.17, -0.6, -0.76, -0.23, -2.44, -1.09, 0.81, -0.66, -0.63, -1.06, -1.71, -1.19, -1.31, -1.01, -0.92, -0.3034006093113235, -0.59, -0.06, -2.27, -0.92, 0.99, -0.49, -0.19, -0.4369232518696327, -0.15, 0.38, -1.85, -0.49, 1.43, -0.06, -0.98, -0.46, 0.06, -0.92, -4.5, -0.71, -0.5, 1.45, -1.41, -0.7, -0.52, -3.41, 1.87, 2.38, 1.17, -2.16, -0.34, -3.42, 3.47, 3.6, -1.17, 2.21, -2.36, -5.09, 2.55, -2.66, 8.93, 1.84, 2.72, -1.97, -0.33, 0.53, -1.7, -0.34, 1.58, 0.1, -3.56, -0.86, -2.21, -0.86, 1.05, -0.43, 1.39, 1.38, 3.34, 1.82, -3.6, -3.29, 0.0, 1.93, 0.43, -1.22, -1.15, -2.34, 4.39, -0.72, -4.56, -2.84, -2.9, -1.89, -1.46, -1.17, -0.87, -0.35, 0.17, -0.77, -0.43, -4.79, -3.76, -0.35], ['488', 1.12, -0.45, -0.038778284379541256, 0.16, 0.02, -0.94, -0.9, -0.63, -0.51, -1.74, -1.52, -0.74, -0.86, -0.86, -2.37, -1.64, -1.52, -1.61, -1.96, -1.45, -1.6, -1.92, -1.65, -1.25, 0.0, -0.91, -0.22, 0.79, 0.6908333333333334, 0.8131899370470801, -0.86, -0.12, 0.0, -0.09, -0.44, 0.07, -0.08, -0.41, -0.13, 0.27, -0.38, -0.41, -1.0, -0.03880253250388291, -0.12, -1.63, -0.9, -0.79, -0.87, -1.22, -0.71, -0.8603452707629391, -1.19, -0.91, -0.51, -0.34, -0.75, -0.91, -0.44, -0.88, 0.0, -1.52, -0.79, -0.67, -0.6573949338599383, -1.0013219954648527, -0.59, -0.75, -1.07, -0.79, -0.4, -1.86, -0.88, -1.52, -0.79, -0.67, -0.76, -1.11, -0.59, -0.75, -1.07, -0.79, -0.39, -0.43, -0.41, 0.41, 0.64, 0.74, 0.86, 0.77, 0.42, 0.94, 0.78, 0.46, 0.74, 1.14, 0.35, -0.02263346878343711, 0.12, 0.03, -0.32, 0.19, 0.04, -0.28, -0.01, 0.39, -0.15, -0.12, 0.53, -0.63, -0.77, -0.53, -0.22, -0.09, -0.44, 0.07, -0.08, -0.33969498055271247, -0.12, 0.27, -0.12, -0.13, -0.35, 0.16, 0.01, -0.31, -0.03, 0.36, 0.03, -0.07, 0.22, -0.48, 1.06, 0.13, 0.1, 1.06, -1.06, -0.53, -2.03, -0.9, 0.63, 1.29, 0.67, 0.58, -0.32, -2.0, 1.99, 1.94, -0.66, 1.65, -1.32, -1.54, 0.73, -0.64, -1.33, 0.44, 0.65, -0.58, 0.22, 0.52, 0.36, 0.04, 0.32, 0.72, -1.94, -0.29, -0.16, -0.48, -0.2, 0.2, -0.14, -0.32, -0.04, 0.36, -0.49, -0.29, 0.19, 0.28, 0.68, -0.71, -0.64, -0.57, -0.97, 0.03019962695749935, 0.94, -1.12, -1.86, -0.09, 0.4, -0.87, -0.48, -0.25, -0.3, -0.98, -0.49, -1.1, -1.5084047619047618, -0.37], ['489', -4.43, 0.34, 0.09122171562045875, 0.13, 1.02, 1.52, 1.0441152579598292, 1.3, 1.59, 2.05, 0.35, 0.77, 1.93, 0.48, 0.91, 3.26, 0.3, 1.75, 2.36, -0.39, 2.48, 1.0570289115646259, 1.15, 0.27, 2.47, 1.7093714145888919, 1.7, 0.42, 1.58, 0.14, 0.57, 2.91, -0.04, 1.4, 2.01, -0.73, 2.13, 0.41, 0.81, -0.08, 1.08, 2.500897562605877, 1.28, 1.16, -0.28, 0.15, 2.48, -0.46, 0.97, 1.59, -1.14, 1.7, -0.01, 0.38, -0.5, 0.4, 1.25, 1.36, 1.1, 0.11, -1.43, -1.0, 1.31, -1.6, -0.18, 0.42, -2.28, 0.54, -1.15, -0.77, -1.64, 1.36, 1.56, 0.43, 2.77, -0.18, 1.26, 1.87, -0.86, 2.143081632653061, 0.28, 0.67, -0.21, 1.64, 2.56, -2.59, 1.13, 2.33, -0.6, 0.83, 1.44, -1.29, 1.55, -0.13428571428571429, 0.24, -0.64, -1.58, -1.18, -2.87, -1.456904761904762, -0.87, -3.54, -0.76, -2.42, -2.04, -2.9, 0.3009795918367347, -1.08, 2.7457237118830404, 1.4, 1.01, 1.8, 1.74, 1.44, 2.05, -0.69, 2.345778253492539, 0.46, 0.85, -0.04, 1.27, 0.3, 0.61, -2.1, 0.729562358276644, -0.97, -0.58, -1.45, 0.62, 0.99, 0.41, 1.56, -3.24, -0.12, 0.05, -4.08, 4.042462323390895, 2.02, 0.71, 2.24, -4.96, -2.67, -1.43, -2.21, 0.89, 4.16, -4.23, -4.15, 1.4, -6.06, 2.73, -2.49, 1.25, 5.16, -7.24, -3.5, -5.2, 4.96, -0.31, -2.69, 0.11, -1.57, -1.18, -1.884238287156354, 4.1, 2.45, 2.88, 1.15, 1.55, 0.66, -0.42, -1.68, -1.29, -2.16, 1.63, 1.68, 1.28, 0.39, -0.49, 1.41, 1.42, 1.2925760496238783, -3.59, 2.19, 3.52, 1.2772638105244332, 1.7, 0.968637448200971, -0.88, 1.12, 2.13, 1.35, 0.57, 0.69, 1.78, 1.59, 2.883037664716236, 1.69], ['490', 7.2, 0.03, -0.02, 0.2, 0.91, 0.56, -0.5558847420401708, 0.87, 0.78, 0.18, -1.07, 0.18, -0.45, 0.03, -0.12, -1.69, -0.14, -0.06, -0.99, -1.6, 0.72, 0.17, -0.22, -0.15, 1.12, 1.29, 1.26, 1.3784685082657773, 0.62, 1.11, 0.96, -0.6266496598639456, 0.94, 1.02, 0.08, -0.54, 1.81, 1.25, 0.86, 0.93, 0.98, 2.9949361992161734, 0.0, -0.63, -0.15, -0.3, -1.87, -0.32, -0.24, -1.17, -1.78, 0.54, -0.02, -0.4, -0.33, 0.76, 1.41, 1.04, 0.24, 0.64, 0.48, 0.33, -1.25, 0.31, 0.4, -0.54, -1.16, 1.343421154242583, 0.62, 0.24, 0.3, 1.04, 0.15, -0.15, -1.72, -0.17, -0.09, -1.02, -1.63, 0.69, 0.14, -0.24, -0.18, 1.58, 0.99, -1.06, 0.33669823838532015, -1.57, -0.02, 0.06, -0.87, -1.48, 0.84, 0.29, -0.09, -0.03, 3.82, 1.91, 1.58, 1.66, 0.71, 0.09, 2.5126265373526935, 1.89, 1.5, 1.57, 0.25, 1.97, 1.51, 0.39, 0.34, 0.45, 0.32, 0.08, -0.85, -1.47, 0.86, 0.31, -0.08, -0.01, 0.03, 0.29307674813036727, -0.94, -1.55, 0.78, 0.22, -0.16, 0.15217743764172342, 0.14, 0.12, 0.36, 0.32, 11.41, 0.1, -0.17, -0.94, 0.92, 0.47, 0.27, 0.15616353211204947, -3.42, -0.76, -0.43, 3.53, 0.17, 1.3, -1.21, -1.17, 0.39, -1.41, 0.8, -1.14, 0.6047652642842468, 0.95, -4.36, -0.65, -0.95, 3.47, 1.5103786848072562, -0.62, 1.73, 1.17, 0.78, 0.85, 1.24, 1.8201587301587303, 2.36, 1.8, 1.41, 1.48, -0.53, -0.55, -0.93, -0.86, 0.8, 0.93, 0.10727468490743443, -0.38, -0.31, 0.42, 0.42, 0.83, -2.57, 1.07, 2.54, 0.85, 0.78, 0.4, 0.07, 0.44, 0.6445528598385742, 0.37, -0.19, 0.1, 0.33, 1.24, 0.73, 0.05], ['491', 4.05, 0.19, 0.44122171562045875, 0.05, 0.44, 1.21, 0.17411525795982916, 1.98, 1.59, 1.3470884353741497, -2.18, 0.11, -0.04, -0.78, -1.0457142857142858, -0.06, 0.8214285714285714, -0.05, 0.78, 0.09366326530612246, 1.47, -1.05, -0.12, -0.73, 1.11, 1.12, 3.15, 2.3405454545454543, 2.19, 1.43, 1.16, 2.1702857142857144, 2.41, 2.18, 3.03, 2.3, 3.73, 1.16, 2.11, 1.48, 2.187468425353211, 1.6649361992161733, 0.79, -0.14, -0.88, -1.15, -0.17, 0.07, -0.16, 0.67, -0.04, 1.36, -1.16, -0.22, -0.83, 0.45, 0.52, 1.13, 1.67, 0.93, -0.74, -1.01, -0.02, 0.21, -0.02, 0.82, 0.11, 1.5, -1.01, -0.08, -0.69, 1.86, 1.69, -0.27, 0.72, 0.96, 0.73, 1.57, 0.86, 2.26, -0.27, 0.67, 0.05, 2.5, 3.06, -3.02, 1.96, 1.0, 1.24, 1.0, 1.85, 1.13, 2.54, 0.0, 0.94, 0.32, 0.96, 0.96, 0.24, 0.01, 0.84, 0.13, 1.53, -0.99, -0.06, -0.67, 0.86, 0.93, 1.66, 0.95, 0.98, 1.01, 0.72, -0.23, 0.6, -0.11, 1.28, -1.1696949805527124, -0.29, -0.8514153161169343, 1.72, 0.95, 0.84, 0.12, 1.52, -1.0, -0.0642857142857143, -0.68, 0.21, 0.9, 0.36603717887804044, 1.1, 1.84, 0.66, 0.01, -0.98, 0.97, 0.48, -0.98, 3.09, -1.56, -2.02, -0.96, 2.02, 1.06, 2.83, -2.85, -2.93, 0.95, -1.35, 1.95, 0.61, -0.28, 2.14, -5.39, -1.4, -2.27, 1.66, 0.11, -0.71, 0.68, -1.82, -0.89, -1.5, 2.97, 0.82, 1.39, -1.12, -0.19, -0.8, -0.11349829931972805, -2.48, -1.56, -2.16, 1.65, 2.18, 1.97, 0.94, 0.32, 0.98, 1.0, 1.95, -2.83, 2.34, 2.68, 1.35, 0.83, 1.02, -0.61, 0.91, 0.5202197802197802, 1.14, 1.23, 1.23, 1.64, 1.03, 1.09, 1.04], ['492', -1.05, -0.66, -0.12, 0.21, -0.8, -0.1, 0.17411525795982916, 0.21172059653595873, 0.15, 0.06, 0.27, -0.67, 1.52, -0.13, -0.27, 0.25, 0.87, 0.68, -1.22, 1.14, 0.09, -0.08405782312925174, -0.22, 0.55, 0.29, -0.16, -0.21, -0.94, 1.25, -0.4, -0.53, -0.02, 0.6, 0.41, -1.49, 0.86, -0.18, -0.47, -0.49, 0.28, -0.25, 0.5149361992161734, 0.74, 2.21, 0.54, 0.4, 0.92, 1.55, 1.35, -0.56, 1.82, 0.76, 0.47, 0.45, 1.23, 0.0, -0.09, 0.42, 0.4, -1.44, -1.63, -1.76, -1.26, -0.64, -0.83, -2.7, -0.38, -1.42, -1.7, -1.72, -0.96, 0.7436060011417156, 0.19, -0.14, 0.38, 1.0616609275411797, 0.81, -1.09, 1.27, 0.22, -0.07, -0.09, 0.68, 0.0, 0.26, -0.36, 0.3308709226619941, 0.52, 1.14, 0.95, -0.96, 1.41, 0.35, 0.07, 0.04, 0.82, -2.06, -0.18, 0.62, 0.43, -1.46, 0.89, -0.16, -0.45, -0.47, 0.3, -0.64, -0.17, -0.99, -0.39, -0.18, -0.69, -0.8, -0.19, -2.07, 0.26, -0.78, -1.06, -1.08, -0.32, 0.18, -0.61, -1.88, 0.46, -0.59, -0.87, -0.9, -0.12, 0.07895836996312448, -0.2, 0.47, -0.81, -6.04, -0.08, 0.06, 1.4, -1.39, -0.67, -0.23, -1.65, 2.15, 0.7, 0.37, -0.48, 0.19, -1.36, 1.29, 1.05, -0.36, 2.0, -0.69, -2.52, 1.25, -2.34, 4.53, 1.6, 2.34, -2.2, 1.3, 2.39, 1.32, 1.03, 1.01, 1.79, -0.99, -1.06, -1.04, -1.32, -1.34, -0.58, -0.02, -0.29, -0.31, 0.47, 0.21, 0.03, 0.26, -0.02, 0.75, -0.33, -0.44, 0.16, 1.75, -1.52, -2.22, -1.0, -0.86, 0.29, 0.78, -0.66, -0.58, -0.09, 0.55, -0.39537375617527093, -0.49, -3.43, -1.18, -1.08], ['493', -3.89, -0.13, -0.15, 0.26, -2.03, -0.79, -1.0158847420401709, -3.09, -2.12, -2.62, 1.1, -0.68, 0.703913265120849, 0.27, 2.29, -2.73, -1.32, -1.7, -1.23, -0.19, -3.19, -1.41, -0.76, -1.11, -1.83, -0.93, -3.68, -1.76, -0.46, -0.6768100629529199, 1.17, -3.79, -2.39, -2.77, -2.31, -1.27, -4.24, -2.48, -1.84, -2.18, -3.4925315746467893, -1.8450638007838267, -1.95, 1.33, 0.96, 3.0608150295752767, -2.0389563492063494, -0.6007210884353742, -1.03, -0.56, 0.5, -2.52, -0.73, -0.08, -0.43, -1.45, -2.11, -2.21, -1.44, -3.1607547529341224, -0.36, 1.64, -3.35, -1.94, -2.33, -1.86, -0.82, -3.8, -2.04, -1.39, -1.74, -2.24, -2.89, 2.01, -2.99, -1.58, -1.97, -1.5, -0.46, -3.45, -1.68, -1.03, -1.38, -2.9, -5.04, 5.11, -4.8, -4.9, -3.52, -3.9, -3.44, -2.42, -5.35, -3.61, -2.98, -3.32, 1.15, 0.11, 1.45, 1.05, 1.5415238095238095, 2.61, -0.47, 1.35, 2.03, 1.67, -1.04, 0.13, -2.5798953488372094, -0.98, -0.98, -0.984326481349968, -1.32, -0.39, 0.08, 1.14, -1.89, -0.039694980552712436, 0.57, 0.21, -1.27, -0.93, 0.48, 1.54, -1.51, 0.3, 0.96, 0.61, -2.08, -1.55, 0.38, -1.27, 2.36, -0.3796768707482993, -0.04, 2.48, -2.51, -1.27, -0.95, -4.8, 4.84, 2.14, 1.08, -2.04, 0.13, -3.15, 3.19, 3.09, -1.05, 3.76, -2.0, -3.18, 1.64, -3.96, 8.22, 2.54, 3.87, -4.81, -1.41, 1.06, -1.98, -0.18, 0.48, 0.13, -3.1, -2.44, -2.9964625850340134, -1.23, -0.57, -0.92, 0.58, 1.83, 2.51, 2.15, -2.07, -2.2, -1.23, 0.66, 0.31, -0.7879199656859431, -1.06, -3.29, 4.09, -2.6, -4.24, -2.1, -1.29, -1.88, -0.35, -1.89, -1.2, 0.17, -0.06, 0.31, -1.53, -2.2297593656343655, -2.17, -1.6269832262926027], ['494', 0.1, 0.01, -0.08, 0.15, 0.1, -0.49, -1.22, -0.31, 0.33, -0.51, -1.8, 0.03, 0.0, -1.42, 1.27, -1.06, 0.54, -0.08942857142857143, 0.56, -0.01, 0.29, -1.16, -0.25, 0.38, -0.12, -0.13, 1.32, 1.87, 1.83, 0.39, 3.187819971295091, 0.75, 2.39, 1.74, 2.41, 1.83, 2.13, 0.65, 1.58, 2.23, -1.24, 1.25, -0.54, 0.041197467496117086, -1.46, 1.24, -1.1, 0.51, -0.13, 0.53, -0.04, 0.25, -1.2, -0.28, 0.355047619047619, 0.07, 0.07, 0.13194788471762156, 0.43, -0.51, -1.42, 1.28, -1.06, 0.55, -0.09, 0.5871802721088435, 0.0, 0.29, -1.16, -0.25, 0.38, -0.51, 0.93, 2.74, 0.36, 2.1494894125482364, 1.35, 2.02, 1.44, 1.74, 0.26, 1.19, 1.8835596417251208, 1.07, -0.86, 0.83, -1.76, -2.31, -0.72, -1.35, -0.7, -1.066255228898086, -0.97, -2.41, -1.5, -0.88, 0.28, 0.56, 1.63, 0.98, 1.65, 1.07, 1.4326265373526936, 0.1428169964955679, 0.82, 1.46, -0.25, 0.52, -0.69, -0.57, -0.5, -0.69, -1.05, -0.63, 0.02, -0.55, -0.26, -1.7, -0.79, -0.16, 0.63, -0.42, 0.66, 0.09, 0.38, -1.07, 0.0657142857142857, 0.47, -0.38, -0.88, 0.23, -0.76, 0.53, 0.04, 0.14, 1.83, -1.79, -0.87, 0.13, -1.14, 1.09, 1.18, 1.028280612244898, 0.25, -0.56, -1.77, 1.71, 1.84, -0.56, 2.62, -1.11, -0.84, 0.44, -3.01, -0.29, 2.1, 3.02, -0.97, -1.07, -0.57, -0.28, -1.72, -0.81, -0.18, -1.67, -0.5, 0.29, -1.16, -0.24, 0.39, -0.79, -1.45, -0.54, 0.09, 0.34, 0.62, 0.66, 0.92, 1.56, -0.4, -0.64, -0.35, -0.18, -1.06, 0.29, -0.83, 0.53, -0.26, 0.63, -0.97, -0.96, -0.87, -0.3, -0.55, -0.89, -1.04, 0.15, -0.79], ['495', -2.12, 0.0, 0.46, 0.06, -0.14, -0.38, 0.18, 0.09172059653595872, -0.56, 1.46, 1.89, 2.4293248299319727, 2.1, 1.44, 1.15, 2.25, 1.15, 1.47, 2.57, 2.53, 1.23, 1.07, 1.93, 1.605116627420199, -0.64, -1.24, -0.39734160500688753, 0.51, 0.2, -0.44, -0.73, 0.35, -0.73, -0.41, 0.66, 0.62, -0.65, -0.81, 0.03, -0.43, 0.24, 0.63, -0.94, -0.31, -0.95, -1.24, -0.16, -1.24, -0.92, 0.15, 0.11, -1.16, -1.31, -0.48, -0.94, -0.5, -0.21, -0.44, -0.33, -0.63, -0.65, -0.94, 0.15, -0.93, -0.62, 0.46, 0.42, -0.85, -1.01, -0.11173538366395512, -0.63, 0.01360600114171559, 0.02, -0.29, 0.8, -0.29, 0.03, 1.11, 1.07, -0.21, -0.37, 0.48, 0.02, -0.7, -0.89, 0.92, 0.31, 1.1780874332127649, 0.01, 0.32, 1.41, 1.37, 0.08, -0.07, 0.7785238095238095, 0.31, -1.7, -0.78, -1.08, -0.76, 0.31, 0.27, -1.0, -1.15, -0.32, -0.78, 0.03, -0.84, 1.67, -0.24, -0.36, 0.015673518650031963, 0.3009570400359874, 0.32, 1.4, 1.36, 0.08, -0.08, 0.76, 0.3, 0.22, -0.01, 1.08, 1.04, -0.24, -0.39, 0.45, -0.01, -1.01, -0.27, 0.28, 0.17, -5.08, 0.03, -0.06, 0.43, -0.45, -0.2, 0.0, -0.24, 2.1, 0.46, 0.23, -0.99, -0.5, -0.68, 0.62, 0.79, -0.25, 0.56, -0.49, 0.1, -0.06, 0.89, 2.22, -0.7, -0.95, -1.98, -1.08, -0.04, -1.3, -1.46, -0.63, -1.08, -0.74, -0.9056457669314812, -1.26, -1.42, -0.59, -1.04, 0.22, -0.16, 0.69, 0.22, -0.56, -0.41, 0.38, 0.84, 0.38, -0.25, -0.16, 0.0, 1.15, 1.34, -1.09, -0.33, -0.53, -0.46, -0.46, -0.14, -0.15, -0.46, -0.89, 0.03, 0.0, -1.23, -0.69, 0.25], ['496', -5.95, 0.0, -0.03984710169072946, 0.06, -0.5070209190089403, -1.07, -1.6158847420401707, -2.138279403464041, -2.03, -3.18, 0.04, -2.08, -1.2, -0.75, -0.19, -2.7, -1.47, -2.85, -5.89, -1.96, -3.432664517912641, -1.61, -2.04, -1.78, -1.69, -1.48, -3.22, -2.11, -1.2191666666666667, -0.79, -0.23, -2.74, -1.51, -2.89, -5.93, -2.0, -3.51, -1.65, -2.08, -1.82, -1.82, -3.84, -1.13, 0.9711974674961171, 1.35, 1.93, -0.64, 0.62, -0.79, -3.9, 0.12, -1.391934531913557, 0.47, 0.04, 0.3, -1.06, -1.59, -1.92, -1.35, -2.01, 0.45, 1.02, -1.52, -0.28, -1.67, -4.75, -0.77, -2.3, -0.42, -0.85, -0.59, -1.8, -2.45, 0.57, -1.97, -0.72, -2.12, -5.18, -1.22, -2.74, -0.87, -1.29, -1.04, -2.81, -3.59, 3.64, -3.0, -2.52, -1.29, -2.67, -5.72, -1.78, -3.29, -1.43, -1.85, -1.6, -2.88, -0.49, 1.27, -0.15, -3.28, 0.76, -0.78, 1.12, 0.69, 0.95, -0.42, -0.48, -2.57, -1.05, -1.04, -1.14, -1.73, -1.4, -4.49, -0.5, -2.03, -0.14, -0.57, -0.32, -1.53, -0.28692325186963274, -3.13, 0.92, -0.63, 1.28, 0.84, 1.1, -0.78, -1.3, 0.04, -1.48, -8.87, -0.03, 0.23, 1.95, -2.02, -0.98, -0.09, -2.67, 2.45, 2.05, 1.04, -2.99, -1.01, -3.2, 3.19, 3.17, -1.05, 2.93, -2.09, -1.51, 0.76, -5.33, 4.58, 3.47, 5.21, -2.28, 2.88, 4.18, 2.58, 4.55, 4.1, 4.535761712843646, -3.1, -1.24, -1.54, 0.35, -0.08, 0.18, 0.3, 1.92, 1.48, 1.74, -1.91, -2.26, -1.59, -0.43, -0.17, -1.03, -1.13, -2.13, 3.99, -1.76, -4.05197619047619, -1.84, -0.3, -1.17, 0.26, -1.31, -0.79, -1.6, -0.66, -0.94, -1.42, -2.58, -0.78, -1.58], ['497', 0.43, 0.0, -0.25877828437954126, 0.1, 0.23, -0.38, -0.49588474204017086, -1.31, -0.65, -0.9, -0.19, -0.59, -0.47, -0.22, 0.95, -0.65, -0.4, -0.73, -1.45, -0.18, -1.03, -0.36, -0.15, -0.83, -0.85, -0.7, -0.71, -0.3998214285714286, -0.28, -0.03, 1.14, -0.46, -0.21, -0.54, -1.27, 0.01, -0.84, -0.17, 0.04, -0.64, -0.99, -1.71, -0.31, 0.12, 0.37, 1.54, -0.06, 0.19, -0.14, -0.87, 0.41, -0.45, 0.23, 0.44, -0.24, -0.82, -0.86, -1.44, -0.56, -0.43, 0.26, 1.43, -0.17, 0.08, -0.26, -0.98, 0.29, -0.56, 0.11, 0.32, -0.36, -1.71, -0.68, 1.17, -0.43, -0.18, -0.51, -1.24, 0.04, -0.82, -0.14, 0.07, -0.61, -1.03, -1.96, 1.89, -1.83, -1.58, -1.33, -1.66, -2.38, -1.12, -1.96, -1.3, -1.09, -1.76, -0.52, -0.25, 0.25, -0.08, -0.81, 0.47, -0.39, 0.29, 0.5, -0.18, -0.05, -0.3, -1.66427628811696, -0.28, -0.37, -0.19, -0.5, -0.33, -1.06, 0.22, -0.64, 0.04, 0.32598786341555264, -0.43, -0.6, -0.17, -0.73, 0.55, -0.13139698000412267, 0.37, 0.58, -0.1, -0.68, -0.81, 0.34, -0.34, -1.36, 0.0, -0.1, 0.36, -0.3675376766091052, -0.15118982899237887, -0.28, -0.71, 1.33, 0.54, 0.26, 0.18, -0.36, -0.79, 0.77, 0.75, -0.21670919513614706, 0.56, -0.47012164275868484, -1.87, 0.93, -1.4, 0.43, 0.86, 1.53, -1.36, 0.56, 1.29, 0.43, 1.11, 1.32, 0.64, -0.6768321004392431, -0.72, -0.85, -0.18, 0.03, -0.65, 0.14, 0.68, 0.89, 0.21, -0.61, -0.75, -0.54, 0.21, -0.39775124468498363, -0.25, -0.23, -1.24, 0.29, -0.59, -0.33, -0.92, 0.41, -0.75, -0.68, -0.32, -0.14, -0.06, -0.47, -0.61, -0.07, -0.95, 0.97, 0.16], ['498', 0.83, -1.24, 0.05122171562045875, 0.3, -1.23, -1.42, -1.6358847420401708, -1.9, -1.82, -1.53, 0.02, -0.62, 1.13, 0.75, 0.29, -2.62, 0.74, -1.17, 2.19, -0.3, -1.59, 0.27, 0.34, 0.47, -1.05, -1.53, -1.55, -0.64, 1.1, 0.73, 0.27, -2.6366496598639455, 0.72, -1.2, 2.17, -0.33, -1.62, 0.25, 0.32, 0.45, -1.8125315746467892, -3.64, -0.92, 1.75, 1.38, 0.91, -2.02, 1.36, -0.56, 2.82, 0.31, -0.99, 0.89, 0.96, 1.1, -1.17, -0.4, -1.67, -2.25, -2.63, -0.37, -0.83, -3.7, -0.38, -2.28, 1.05, -1.41, -2.69, -0.84, -0.78, -0.64, -2.36, -2.27, -0.46, -3.35, -0.01, -1.91, 1.43, -1.05, -2.33, -0.48, -0.41, -0.28, -2.29, -5.37, 5.28, -1.82, -2.9, 0.45, -1.46, 1.9, -0.59, -1.88, -0.02, 0.05, 0.18, 1.18, 1.12, 3.45, 1.48, 4.94, 2.38, 1.05, 2.97, 3.04, 3.18, -0.48, 1.03, -3.44, -1.43, -1.51, -1.5, -2.25, -1.9, 1.44, -1.04, -2.32, -0.46, -0.3240121365844474, -0.26, -1.67, -0.36, 3.41, 0.88, -0.42, 1.47, 1.53, 1.67, -1.84, -1.85, 0.07, -1.98, 3.9, -0.52, -0.35, 2.71, -2.8, -1.38, -0.75, -2.14, 2.4, 2.88, 1.41, 0.36, -0.996920210131221, -4.52, 4.53, 4.28, -1.44, 4.21, -2.84, -2.25, 1.04, -6.74, 13.503125850340135, 4.52, 6.78, -2.37, -3.64, -2.44, -3.71, -1.88, -1.8087142857142857, -1.68, -4.31, -1.23, -1.3, 0.58, 0.64, 0.78, 0.06, 1.9, 1.96, 2.1, -1.75, -2.23, -1.8, 0.06, 0.2, -1.44, -1.6, -1.7674239503761218, 7.11, -3.2398003730425007, -7.02, -1.86, -1.61, -1.86, 0.14, -1.99, -1.2, -0.69, -1.18, -0.84, -2.0, -1.2, -2.45, -2.09], ['499', 9.254285714285714, -0.9, -0.04, 0.07, -0.2, 0.02, 1.174115257959829, 0.98, 0.58, 1.99, 1.24, 0.54, 1.51, 0.4, 0.8, 1.1610714285714285, 2.65, 1.72, 5.24, 3.04, 2.3, 2.9870289115646256, 1.96, 1.71, -0.38, 0.38, 0.7726583949931125, -0.7, 0.26, -0.83, -0.44, -0.08, 1.39, 0.5872589041444084, 3.95, 1.78, 1.04, 1.43, 0.7, 0.46, 1.31, 0.22, 1.45, 0.97, -0.14, 0.26, 0.62, 2.1, 1.18, 4.68, 2.49, 1.75, 2.14, 1.4442857142857142, 1.16, -0.55, 0.24, 1.21, 0.46, 0.47, -1.1, -0.7, -0.35, 1.12, 0.21, 3.67, 1.51, 0.77, 1.16, 0.44, 0.19, 0.62, 1.59, 0.4, 0.76, 2.24, 1.32, 4.82, 2.63, 1.89, 2.28, 1.55, 1.3, 0.47, -0.1, 0.11, 1.18, 0.36, 1.83, 0.92, 4.41, 2.23, 1.6552352330209474, 1.88, 1.15, 0.9, 1.05, 0.82, 1.47, 0.56, 4.04, 1.86, 1.12, 1.51, 0.79, 0.54, 0.22, 0.84, -1.16, 0.05, -0.06, 0.05, -0.64, -0.9, 2.53, 0.38, -0.34, 0.04, -0.67, -0.8614153161169343, -0.69, 0.26, 3.46, 1.3, 0.56, 0.95, 0.23, -0.02, 0.04, -0.3, 0.4660371788780404, -0.54, 3.25, 0.14, 0.35, -1.09, 1.1, 0.56, -0.02, -0.72, 1.94, -0.12, -0.03, 4.469285714285714, -0.05, 0.01, 0.06, -0.1, 0.10329080486385296, -1.79, 0.07, -0.43, 0.22, -1.94, 1.51, 1.22, 1.89, -2.04, -3.09, -2.09, -2.8, -2.42, -3.12, -3.36, 0.18, -1.02, -0.72, -0.34, -1.05, -1.29, -0.3, 0.38, -0.33, -0.58, 0.61, 0.46, -0.68, -0.72, -0.96, 0.05, -0.03, 0.93, 0.32, -0.3, -0.34, -0.03273618947556672, -0.74, 0.03, -0.24, -0.37, 0.42, 0.13, -0.6, 0.39, 0.28, -0.09, -1.83, 0.89], ['500', -0.74, -0.25, 0.13122171562045873, -0.7, -0.36, -0.55, -0.015884742040170832, -0.6, -0.23, -0.42, -0.14, 0.4, 0.08, -0.09, -0.22, -0.65, 0.2, -0.11, 2.73, -0.24, -0.43266451791264104, 0.61, -0.24, -0.59, -0.4, -0.21, -0.2573416050068875, 0.54, 0.22, 0.05, -0.022180028704908802, -0.51, 0.33, 0.03, 2.87, -0.1, -0.33, 0.75, -0.1, -0.4061582768021609, -0.1, -0.7350638007838266, -0.82, -0.32, -0.49, -0.62, -1.04, -0.2, -0.5, 2.32, -0.64, -0.841934531913557, 0.21, -0.64, -0.99, 0.47, 0.22, -0.08, 0.06, -0.5, -0.17, -0.3, -0.73, 0.12, -0.19, 2.64, -0.32, -0.55, 0.53, -0.32, -0.67, -0.18, -0.34, -0.13, -0.56, 0.28, -0.02, 2.82, -0.15, -0.38, 0.7, -0.15, -0.4564403582748793, -0.42, -0.6, 0.66, -0.16330176161467985, -0.43, 0.42, 0.11, 2.95, -0.02, -0.25, 0.83, -0.02, -0.37, -0.89, 0.22, 0.85, 0.54, 3.39, 0.41, 0.18, 1.26, 0.41, 0.06, -0.36, 0.19, -0.26427628811695997, -0.43, -0.19, -0.13432648134996805, -0.62, -0.3, 2.53, -0.43, -0.66, 0.41, -0.44, -0.79, 0.12, -0.32, 2.83, -0.13, -0.36, 0.71, -0.14, -0.49, -0.59, -0.53, -0.06, -0.3, 0.2, -0.1, 0.0, 0.44, -0.56, -0.23, -0.29, -2.71, 0.37, 0.83, 0.38, -0.21, -0.04, -1.29, 1.25, 1.11, -0.45, 0.76, -0.84, 0.27, -0.2, -1.66, -0.8, 0.82, 1.73, -0.29, -3.07, -2.89, -3.11, -2.06, -2.89, -3.23, -1.17, -0.19, -0.23, 0.85, 0.0, -0.35, 0.05, 1.08, 0.23, -0.12, -0.26, 0.19, -1.03, -0.84, -1.19, -1.05, -0.41, -0.35, 0.09, -0.5798003730425006, 0.17, 0.27, -0.93, -0.18, -0.35, -0.42, -0.31, -0.37, -0.31, -0.5, 0.17, -0.47, -1.24, -0.11], ['501', -1.71, -0.18, 0.25122171562045875, 0.04, -1.02, -0.3, 0.22, -0.15, -0.45, -0.48, -0.67, -0.64, 0.54, 1.4, -1.0, 0.08, 0.02, -0.65, 0.62, 1.5, -0.3, -0.27, -0.03, 0.55, 0.13, -0.6, 0.2, 0.14846850826577718, 1.22, 2.09, -0.33, 0.7633503401360544, 0.7, 0.02, 1.3, 2.18, 0.37, 0.41, 0.65, 1.23, 0.06, -0.89, 0.17, 1.19, 2.06, -0.36, 0.72, 0.66, -0.01, 1.27, 2.15, 0.368065468086443, 0.38, 0.62, 1.2, 0.21, 0.08, 0.91, -1.11, -1.01, 0.9531047225355607, -1.53, -0.46, -0.52, -1.19, 0.07, 0.95, -0.84, -0.81, -0.57, 0.01, 2.31, -1.85, -2.37, -1.31, -1.36, -2.02, -0.77, 0.09, -1.68, -1.64, -1.41, -0.84, -0.44, -1.61, 1.51, 0.53, 1.09, 1.03, 0.35, 1.63, 2.52, 0.71, 0.74, 0.98, 1.56, -1.21, -0.55, -0.06, -0.73, 0.54, 1.42, -0.38, -0.34, -0.11, 0.47, -0.14, -0.56, -2.41, -0.3, -0.35, -0.31, -0.49, -0.67, 0.6, 1.48, -0.32, -0.28, -0.05, 0.5885846838830657, -0.29, 0.18, 1.28, 2.16, 0.35, 0.39, 0.63, 1.21, -0.32, -0.11, 0.26, -0.52, -3.53, 0.03, 0.1, -0.32, 0.3, 0.14, -0.13, -1.52, 3.78, 0.64, 0.31, -0.86, -0.64, -0.87, 0.9, 0.93, -0.3, -0.46, -0.6, 0.8283906549799409, -0.37, -1.39, 4.627380952380952, 0.91, 1.42, -3.73, -1.09, 0.87, -0.91, -0.88, -0.64, -0.07, -0.9, -1.94, -1.77, -1.74, -1.5, -0.93, -0.18, 0.03, 0.27, 0.85, -0.46, -0.67, -0.21, 0.24, 0.82, -0.3, -0.33, -0.13, 2.49, -2.23, -2.59, -0.46, -1.01, -0.45, 0.58, -0.11, 0.5945528598385743, -0.32, -0.81, -0.31, -1.02, 0.63, -1.19, -0.4], ['502', -1.99, 0.15, -0.04, 0.07, 0.11, -0.28, -1.1458847420401708, -0.26, -0.8, 0.27, 0.99, 0.69, 0.37, 0.87, 0.43, 0.06107142857142857, 1.19, 0.17, -3.18, 0.38, 0.25, 0.98, 1.19, 0.82, -0.63, -0.6, -0.6773416050068874, -0.3, -0.61, -0.11, -0.55, -0.92, 0.2, -0.81, -4.12, -0.61, -0.73, 0.0, 0.2, -0.11615827680216084, 0.26, -1.5350638007838266, -0.41, -0.31, 0.18, -0.25, -0.63, 0.5, -0.51, -3.84, -0.31, -0.43, 0.29, 0.5, 0.14, -0.4, -0.99, -0.62, -0.94, -0.1, 0.5, 0.060799319727891155, -0.31, 0.81, -0.2, -3.54, 0.0, -0.12, 0.61, 0.81, 0.45, -0.14, -0.59, -0.44, -0.81, 0.32, -0.69, -4.01, -0.49, -0.4669183673469388, 0.11, 0.31, -0.05, -1.33, -2.39, 2.36, -0.16, -0.37, 0.76, -0.26, -3.59, -0.05, -0.18, 0.55, 0.75, 0.39, -1.13, 0.22, 1.13, 0.12, -3.23, 0.32, 0.19, 0.93, 1.13, 0.77, 0.121141873999017, 0.12, -1.65, -0.47, -0.55, -0.5, -0.9, -1.0, -4.32, -0.8, -0.93, -0.2, 0.0, -0.36, -0.67, 0.1, -3.34, 0.292244713705627, 0.08, 0.81, 1.01, 0.65, -1.55, -1.58, 0.08, -0.73, -3.93, 0.13, 0.14, 1.02, -1.01, -0.49, -0.07, 0.1, 0.23, 0.93, 0.5, -0.99, -0.04692021013122094, -1.51, 1.55, 1.55, -0.48, 1.67, -0.95, -0.6, 0.3147652642842468, -2.75, 0.76, 1.82, 2.67, -0.18, 3.56, 3.67, 3.54, 4.3, 4.51, 4.13, -1.38, -0.1, -0.12, 0.61, 0.81, 0.45, 0.02, 0.73, 0.93, 0.57, -0.75, -0.84, -0.7, 0.2, -0.16, -0.5, -0.5156036987247091, -0.26, 1.97, -1.67, -2.05, -0.7, 0.44, -0.9, -0.36, -1.1, -0.6, -0.44, -0.08, -0.21, -0.54, 0.23, 0.61, -0.8], ['503', -1.31, 0.0, -0.08, 0.19, -0.25, -0.32, 0.88, -1.03, -0.98, 0.05, 1.32, 0.36, 1.61, 1.62, 0.48, 0.46, 0.82, 0.0, -3.55, -0.04, -0.54, 1.36, 1.64, 0.38, -1.61, -0.82, -1.25, -0.95, 0.29, 0.29, -0.82, -0.84, -0.49, -1.3, -4.8, -1.34, -1.83, 0.04, 0.32, -0.93, 0.66, -1.1050638007838267, -0.31, 1.25, 1.25, 0.12, 0.11, 0.46, -0.36, -3.89, -0.4, -0.89, 1.0838655564790018, 1.27, 0.02, -1.1, -0.71, -0.73, -0.98, -1.54, 0.0, -1.11, -1.13, -0.78, -1.59, -5.08, -1.63, -2.12, -0.26, 0.02, -1.22, -1.14, -1.54, -1.12, -1.13, -0.78, -1.59, -5.08, -1.63, -2.12, -0.26, 0.02, -1.22, -1.42, -3.6, 3.58, -0.43, -0.02, 0.34, -0.48, -4.01, -0.52, -1.02, 0.87, 1.15, -0.0459922724755494, -1.71, -0.41, 0.35, -0.46, -3.9894285714285718, -0.5, -1.0, 0.89, 1.17, -0.09, 0.231141873999017, -0.36, -1.57, -0.45, -0.56, -0.28, -0.77, -0.82, -4.33, -0.8594642857142857, -1.35, 0.53, 0.81, -0.44, -1.16, 0.10307674813036727, -3.55, -0.04, -0.5304376417233561, 1.36, 1.64, 0.38, -1.18, -1.34, 0.17, -0.34, -5.47, -0.01, 0.07, 0.48, -0.43, -0.22, -0.44, -1.01, -0.19, 0.88, 0.4, -0.67, -0.08, -1.31, 1.21, 1.34, -0.43, 0.67, -0.86, -1.52, 0.75, -2.27, 15.02, 1.5, 2.21, 0.24, 3.73, 3.64, 3.12, 5.08, 5.38, 4.07, -1.33, 0.09, -0.5, 1.4, 1.68, 0.42, 0.59, 1.9, 2.19, 0.92, -0.96, -1.19, -1.29, 0.28, -0.96, -0.48, -0.42, -0.96, 7.65, -1.77, -7.81, -1.59, -0.05, -1.56, -1.24, -0.64, -0.32, 0.12, -0.06, 0.11, -0.33, -2.55, 0.57, 0.35], ['504', 3.65, -1.46, 0.23, -0.24, 0.14, 0.33, 1.2900361663652804, 0.18, 0.43, -1.32, -1.93, -2.23, -1.64, -2.18, -1.04, -2.91, -1.33, -1.55, 1.96, -2.57, -0.67, -1.24, -1.45, -1.85, 0.01, -0.28, 0.63, -0.3, 0.3, -0.25, 0.9, -1.0, 0.61, 0.5072589041444084, 3.96, -0.65, 1.28, 0.71, 0.49, 0.08, -0.12, 1.51, 0.93, 0.6, 0.05, 1.21, -0.7, 0.92, 0.69, 4.28, -0.35, 1.59, 1.01, 0.8, 0.39, 0.12006284630567655, 0.24, 0.57, 0.17, 0.33, -0.55, 0.61, -1.3, 0.32, 0.09, 3.66, -0.94, 0.98, 0.41, 0.19, -0.21, 0.6336060011417156, 0.88, 1.16, -0.75, 0.87, 0.64, 4.23, -0.4, 1.54, 0.96, 0.74, 0.34, 1.03, 0.611742947528662, -0.38, -0.28, -1.89, -0.29, -0.52, 3.03, -1.54, 0.38, -0.2, -0.41, -0.81, -0.027904761904761904, 1.65, 1.63, 1.4, 5.02, 0.36, 2.31, 1.73, 1.51, 1.1, 0.28, 1.6424455782312923, 0.5, 0.29, 0.28, 0.29567351865003194, 0.01, -0.23, 3.33, -1.26, 0.66, 0.09, -0.12, -0.53, -0.08, 0.24, 3.57, -1.03, 0.89, 0.32, 0.1, -0.3, 0.61, 0.45, -0.25, 0.37318678362356794, 0.0, 0.13, 0.05, -0.44, 0.46, 0.23, 0.36, 0.76, -2.62, -0.48, -0.27, 1.86, 0.35, 0.82, -0.72, -0.85, 0.27, -0.7, 0.53, 3.108390654979941, -1.52, 0.06, 0.72, -0.03, -0.05, 2.67, -3.21, -4.44, -2.58, -3.13, -3.34, -3.73, 0.8, 1.28, 1.95, 1.37, 1.15, 0.74, -0.65, -0.57, -0.78, -1.18, 0.63, 0.69, -0.08, -0.22, -0.62, 0.25, 0.24, 0.22257604962387836, 0.4, -0.1, -0.35, -0.03, 0.16, 0.21863744820097092, -0.4, 0.0, 0.32, 0.15, 0.87, 0.29, 0.54, -0.94, 0.58, 0.43], ['505', -3.94, 0.63, 0.041221715620458746, -0.07, -0.5, 0.92, 1.07, 0.5817205965359588, 1.25, 0.27, -1.31, -0.52, -0.25, -1.51, 0.86, 1.27, -0.95, -0.02, 0.27, 0.65, -0.11, -0.42, -1.44, -0.7, 1.56, 0.04, 1.6326583949931126, 0.8, 1.07, -0.2, 2.19, 2.61, 0.36, 1.31, 1.6, 1.98, 1.22, 0.9, -0.14, 0.62, -0.07, 2.1749361992161735, 0.79, 0.27, -1.0, 1.38, 1.8, -0.43, 0.5, 0.79, 1.18, 0.41, 0.1, -0.93, -0.18, 0.19, -0.5, 0.22, 1.51, 0.52, -1.26, 1.11, 1.52, -0.7, 0.23, 0.52, 0.9, 0.14, -0.17, -1.2, -0.45, 0.41, 1.81, 2.4, 2.82, 0.57, 1.51, 1.81, 2.19, 1.42, 1.11, 0.07, 0.82, 2.05, 4.48, -4.45, -0.58, 0.41, -1.79, -0.87, -0.58, -0.2, -0.95, -1.26, -2.28, -1.54, -2.17, -0.99, -2.19, -1.28, -0.99, -0.61, -1.36, -1.67, -2.68, -1.94, 0.36, -0.8406317967746538, 3.39, 0.97, 1.0, 0.89, 1.23, 0.94, 1.23, 1.62, 0.85, 0.54, -0.5, 0.25, 0.67, 0.29, 0.29, 0.67, -0.09, -0.4, -1.42, -0.68, 1.12, 1.4227619047619047, 0.14, 0.98, -6.35, 0.22, 0.2, -2.01, 2.01, 1.0, 0.72, -0.31, 0.67, -1.91, -0.97, -1.99, 0.5030797898687791, 2.98, -2.7, -2.87, 0.99, -3.01, 1.95, 0.4, -0.2, 3.58, -8.25, -2.47, -3.63, -0.67, 0.0, 0.38, -0.38, -0.6483894557823129, -1.71, -0.97, 2.9, -0.38, -0.75, -1.06, -2.08, -1.34, 0.38, -0.31, -1.34, -0.59, 1.28, 1.59, 0.7772746849074343, -1.03, -0.28, 0.95, 1.0643963012752908, 0.5, -4.2, 2.21, 4.27, 0.71, 0.76, 1.74, 0.76, 0.66, 1.12, 0.6, 0.06, 0.79, 0.98, -0.71, 0.58, 1.0], ['506', 1.61, 1.11, -0.17, -0.11, -0.24, 0.24, 1.1, -0.08, 0.29, 0.19, 0.72, -0.6592857142857144, 0.62, -0.53, 0.41, 0.38, -0.73, -0.23, -0.69, 0.38, -0.2, -1.91, -1.43, 0.04511662742019901, 0.72, 1.29, -0.53, -1.38, -0.11, -1.25, -0.32, -0.34, -1.44, -0.95, -1.41, -0.34, -0.92, -2.61, -2.14, -0.81, 0.74, -0.37506380078382656, 0.86, 1.29, 0.13, 1.07, 1.05, -0.06, 0.43, -0.03, 1.05, 0.46, -1.25, -0.78, 0.57, 0.13006284630567655, 0.53, 0.35, 0.33, -0.43, -1.14, -0.21, -0.24, -1.34, -0.85, -1.3, -0.24, -0.82, -2.51, -2.04, -0.71, 0.0, 0.72, 0.94, 0.92, -0.2, 0.3, -0.16, 0.92, 0.33, -1.38, -0.91, 0.44, -0.04, 4.38, -4.42, -0.21, -0.02, -1.13, -0.64, -1.09, -0.03, -0.61, -2.3, -1.83, -0.5, 0.29, -0.19, -1.1, -0.61, -1.07, 0.0, -0.5173734626473064, -2.28, -1.81, -0.48, 0.69, -0.19, 2.55, 0.51, 0.76, 0.37, 0.92, 0.5, 0.03, 1.11, 0.53, -1.19, -0.71, 0.63, 2.02, 0.42, -0.46, 0.61, 0.03, -1.68, -1.2, 0.14, 0.69, 0.44, -0.09, 1.07, 0.68, 0.48, 0.42, -0.44, 0.44, 0.21, 1.29, -0.55, 0.417758979116122, -0.96, -0.54, 0.8, 0.38, 1.81, -1.77, -1.56, 0.54, -0.64, 1.06, 1.87, -0.97, 2.68, -3.08, -1.86, -2.67, -0.4, 0.89, 1.08, 0.49, -1.22, -0.75, 0.6, 1.55, -0.19, -0.58, -2.28, -1.81, -0.47, 0.39, -1.71, -1.23, 0.11, 0.27, -0.08, 2.14, 0.48, 1.85, 0.49, 0.63, 0.0, -1.62, 1.78, 1.53, 0.68, 0.31, 1.65, 1.36, 0.12, 0.47, -0.06, 0.75, 0.34, 0.29, -0.1, 1.44, 0.63], ['507', 2.84, -0.72, -0.028778284379541254, -0.05, -1.06, -0.35, -0.9358847420401708, -1.06, -0.87, -0.09, 0.74, 0.63, 1.35, 1.58, 0.63, -0.32, 0.92, -0.06, -2.85, 1.58, -0.31, 0.74, 1.38, 0.38, -0.21, -1.44, -0.7873416050068875, -0.11, 0.61, 0.84, -0.11, -1.06, 0.18, -0.8, -3.57, 0.83, -1.04, 0.0, 0.63, -0.36, -0.47, -1.99, -0.71, 0.72, 1.1178753944468232, 0.0, -0.94, 0.3, -0.68, -3.46, 0.95, -0.93, 0.12, 0.75, -0.25, -0.37, -1.28, -0.23217202719021607, -0.73, -1.42, 0.23, -0.71, -1.65, -0.42, -1.39, -4.15, 0.23, -1.64, -0.6, 0.03, -0.96, -0.8, -1.64, -0.94, -1.88, -0.65, -1.62, -4.37, 0.0, -1.86, -0.83, -0.2, -1.19, -1.24, -3.78, 3.76, -0.71, -0.95, 0.29, -0.68, -3.46, 1.143744771101914, -0.93, 0.11, 0.75, -0.1959922724755494, -2.2673809523809525, 0.3173665312165629, 1.25, 0.26, -2.54, 1.91, 0.08262653735269351, 1.07, 1.71, 0.7, -0.02, 0.23, -1.45427628811696, -0.72, -0.91, -0.59, -1.0, -0.97, -3.74, 0.65, -1.22, -0.18, 0.45, -0.54, -0.81, -0.02, -2.8, 1.64, -0.25, 0.8, 1.44, 0.44, -1.35, -0.16, -0.22, -0.94, -4.51, -0.13, 0.0, 0.84, -0.85, -0.4, -0.25, -0.11, 3.37, 1.42, 0.67, 1.47, -0.28, -2.17, 2.21, 2.13, -0.7, 1.14, -1.4, 1.31, -0.66, -2.97, 0.29, 1.99, 2.94, -3.34, 2.85, 4.56, 2.62, 3.7, 4.36, 3.33, -2.05, -1.64, -1.86, -0.82, -0.2, -1.19, 0.22, 1.05, 1.69, 0.68, -0.92, -1.0, -0.82, 0.63, -0.36, -0.69, -0.76, -0.95, 0.09, -1.17, -0.19, -0.47, -1.57, -1.45, -0.99, -0.44, -0.43, -0.32, -0.3, -0.51, -0.46, -1.03, -2.41, -0.9269832262926028], ['508', -0.33, 0.23, 0.13122171562045873, -0.02, -0.61, -0.05, -0.46, -1.25, 0.14, -0.8278571428571428, -0.67, -1.1410079365079364, -0.36, 0.25, 1.43, -0.69, -0.75, -0.75, -2.47, 0.37, -0.79, -1.49, -1.17, -1.34, -0.76, -0.67, -0.12734160500688754, -0.48, 0.32, 0.93, 2.167819971295091, -0.02, -0.08, 0.03725890414440844, -1.81, 1.05, -0.12, -0.82, -0.5, -0.6261582768021609, -1.34, -0.7150638007838266, 0.32, 0.8, 1.43, 2.61, 0.47, 0.41, 0.41, -1.33, 1.54, 0.37, -0.34, -0.02, -0.19, -0.1, -1.5, -1.62, 0.11, -0.48, 0.62, 1.79, -0.33, -0.39, -0.4, -2.12, 0.73, -0.43, -1.13, -0.81, -0.98, -1.02, -1.09, 1.17, -0.94, -1.0, -1.01, -2.72, 0.11, -1.04, -1.74, -1.42, -1.5364403582748793, 0.06, 0.9, -1.02, -2.1933017616146797, -2.09, -2.14, -2.15, -3.84, -1.04, -2.19, -2.87, -2.56, -2.73, -2.68, -0.14, -0.06, -0.06, -1.79, 1.07, -0.1, -0.8, -0.48, -0.65, 0.03, -0.19, 1.4101046511627906, 0.07, 0.11, 0.05, -0.09, -0.01, -1.74, 1.12, -0.04, -0.74, -0.43, -0.59, 0.72, -0.08, -1.73, 1.13, -0.04, -0.6142004503433073, -0.42, -0.59, 0.46, 0.16, -0.06, 0.03318678362356798, -7.85, 0.02, 0.12, -0.15, 0.14, 0.07, 0.37, -1.49, 2.46, -0.13, -0.09, -0.12, 0.4, 0.17, -0.15, -0.16, 0.12329080486385297, -0.17, 0.12, 0.78, -0.4, -0.18, -3.95, 0.14, 0.1, -2.46, 1.68, 2.91, 1.72, 1.01, 1.33, 1.16, 0.2, -1.0656457669314812, -1.15, -1.85, -1.53, -1.7, -0.04, -0.7, -0.38, -0.55, 0.08, 0.04, 0.66, 0.32, 0.15, 0.09, 0.08, -1.19, -2.55, 0.40111637918066984, 2.43, -0.36, -0.66, 0.34, -0.17, -0.56, 0.0, 0.42, 0.8, 0.16, 0.51, -1.81, -1.01, 0.3330167737073973], ['509', -1.13, 0.06, 0.011221715620458745, 0.16, 0.78, 0.8284196236737595, -0.06, -0.39, 0.66, -0.18, -1.15, -0.72, 0.47, -0.45, 0.58, 0.46, -1.02, -0.43, -5.43, -0.95, -0.25, 0.6, 0.27, -0.74, 0.74, 0.27, 0.98, 0.43, 1.64, 0.71, 1.75, 1.63, 0.13, 0.73, -4.33, 0.2, 0.91, 1.77, 1.43, 0.41, -0.18, -0.21, 0.55, 1.2, 0.28, 1.31, 1.19, -0.3, 0.3, -4.74, -0.23, 0.47, 1.33, 1.0, -0.02, 0.76, 0.23, -0.8, 0.67, -0.64, -0.91, 0.11, -0.01, -1.48, -0.89, -5.88, -1.41, -0.72, 0.13, -0.2, -1.21, -0.94, 0.27, 1.03, 0.91, -0.58, 0.02, -5.01, -0.5, 0.19, 1.05, 0.71, -0.3, 0.77, -0.9382570524713382, 1.06, -0.75, -0.12, -1.59, -1.0, -5.98, -1.52, -0.83, 0.02, -0.31, -1.32, -1.0187766439909298, -0.5526334687834371, -1.47, -0.88, -5.86, -1.4, -0.71, 0.14, -0.19, -1.2, 0.23, -0.59, -0.82, 0.66, 0.38, 0.93, 0.85, 0.6, -4.46, 0.07, 0.77, 1.64, 1.3, 0.28, -0.8434639289282145, 0.25, -5.03, -0.52, 0.17, 1.03, 0.7, -0.32, -0.36, -0.14, 0.58, 0.77, -4.05, 0.23, 0.2, -2.62, 2.59, 1.31, -0.96, -0.63, -1.72, -1.3, -0.62, -0.53, 0.29, 2.05, -1.91, -2.03, 0.68, -3.95, 1.33, -0.6, 0.26, 2.52, 1.56, -1.72, -2.62, 1.5938095238095238, 5.56, 4.74, 5.48, 6.38, 6.03, 4.96, 2.0931678995607568, 0.78, 0.7, 1.56, 1.22, 0.21, 0.08, 0.86, 0.52, -0.49, 0.6, 0.59, -0.77, -0.33, -1.2577512446849837, 0.64, 0.67, -0.2874239503761216, 0.94, 0.51, -0.97, 0.39, 0.66, -0.44, -1.01, 1.68, 1.66, -0.08, 0.32, 0.19, 0.57, -0.23, 0.92, 1.17], ['510', -7.99, -0.78, 0.01, 0.2, -1.57, -1.0, -2.76, -1.99, -2.44, -1.74, 1.29, 1.1789920634920634, -0.26, -0.23, -0.1, -0.06, 0.21, -1.51, -1.74, 0.6, -2.21, -1.07, -0.23, -0.45, -1.16, -2.15, -2.99, -0.11, -1.53, -1.5, -1.37, -1.33, -1.06, -2.77, -2.99, -0.68, -3.45, -2.33, -1.5, -1.6761582768021608, -1.48, -2.98, -2.88, -1.42, -1.39, -1.26, -1.20359693877551, -0.9107210884353741, -2.66, -2.88, -0.57, -3.34, -2.22, -1.38, -1.61, -1.22, -1.63, -1.99, -2.35, -1.48, 0.03, 0.16, 0.21, 0.48, -1.25, -1.48, 0.86, -1.95, -0.81, 0.04, -0.19, -2.16, -1.51, 0.13, 0.17, 0.44, -1.29, -1.51, 0.83, -1.98, -0.84, 0.0, -0.23, -2.8, -3.94, 4.02, -1.64, 0.04, 0.32, -1.41, -1.64, 0.7, -2.11, -0.97, -0.13, -0.35, -4.9, -1.68, 0.27, -1.46, -1.68, 0.65, -2.15, -1.01, -0.17, -0.4, -0.41, -1.74, -1.31, -1.08, -0.98, -1.25, -1.95, -1.72, -1.95, 0.38, -2.42, -1.28, -0.44, -0.67, -0.64, -0.23, -0.23, 2.14, -0.7, 0.45, 1.31, 1.08, -1.16, -1.46, 0.31, -1.33, -14.62, -0.29, -0.14, 3.27, -3.31, -1.64, -0.27, -2.4, 4.66, 2.15, 1.07, -4.02, -0.26, -3.3, 3.32, 3.15, -1.08, 4.78, -2.16, -2.15, 1.11, -5.77, 9.04, 3.83, 5.7, -4.55, 0.0, 2.38, -0.47, 0.68, 1.54, 1.31, -3.25, -2.32, -2.78, -1.66, -0.82, -1.04, 0.48, 1.16, 2.02, 1.79, -2.37, -2.53, -0.68, 0.85, 0.62, -1.05, -1.2, -2.14, 5.57, -1.37, -5.64, -1.59, -1.43, -1.52, -0.23, -0.8, -1.46, -0.15, -0.01, -0.53, -1.29, -2.57, -2.34, -1.41]], 'figimage': <function figimage at 0x3195140>, 'jet': <function jet at 0x3198848>, 'figaspect': <function figaspect at 0x3183938>, 'Line2D': <class 'matplotlib.lines.Line2D'>, 'exp2': <ufunc 'exp2'>, 'imshow': <function imshow at 0x3197398>, 'axhline': <function axhline at 0x31968c0>, 'bool8': <type 'numpy.bool_'>, 'colormaps': <function colormaps at 0x31961b8>, 'msort': <function msort at 0x236d5f0>, 'alltrue': <function alltrue at 0x21da2a8>, 'zeros': <built-in function zeros>, 'identity': <function identity at 0x21dbde8>, 'False_': False, 'ispower2': <function ispower2 at 0x2c522a8>, 'LogFormatterExponent': <class 'matplotlib.ticker.LogFormatterExponent'>, 'ihfft': <function ihfft at 0x24090c8>, 'nansum': <function nansum at 0x236cb18>, 'bool_': <type 'numpy.bool_'>, '_i78': u'train.shape', '_44': (200, 198), 'inexact': <type 'numpy.inexact'>, 'distances_along_curve': <function distances_along_curve at 0x2c53c08>, 'broadcast': <type 'numpy.broadcast'>, 'copyto': <built-in function copyto>, 'amin': <function amin at 0x21da5f0>, 'arctanh': <ufunc 'arctanh'>, 'typecodes': {'All': '?bhilqpBHILQPefdgFDGSUVOMm', 'Complex': 'FDG', 'AllFloat': 'efdgFDG', 'Integer': 'bhilqp', 'UnsignedInteger': 'BHILQP', 'Float': 'efdg', 'Character': 'c', 'Datetime': 'Mm', 'AllInteger': 'bBhHiIlLqQpP'}, 'number': <type 'numpy.number'>, 'savetxt': <function savetxt at 0x23fb410>, 'copy': <function copy at 0x236c500>, 'int_': <type 'numpy.int64'>, '_i69': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'std': <function std at 0x21daaa0>, 'segments_intersect': <function segments_intersect at 0x2c51848>, 'not_equal': <ufunc 'not_equal'>, 'fromfunction': <function fromfunction at 0x21dbb18>, 'Figure': <class 'matplotlib.figure.Figure'>, 'tril_indices_from': <function tril_indices_from at 0x230db18>, 'double': <type 'numpy.float64'>, 'require': <function require at 0x21c2758>, 'predicted_probs': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073016773707397273, 0.073016773707397273, 0.0, 0.0], 'triplot': <function triplot at 0x3197d70>, 'headers': array(['O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8', 'O9', 'O10', 'O11',\n       'O12', 'O13', 'O14', 'O15', 'O16', 'O17', 'O18', 'O19', 'O20',\n       'O21', 'O22', 'O23', 'O24', 'O25', 'O26', 'O27', 'O28', 'O29',\n       'O30', 'O31', 'O32', 'O33', 'O34', 'O35', 'O36', 'O37', 'O38',\n       'O39', 'O40', 'O41', 'O42', 'O43', 'O44', 'O45', 'O46', 'O47',\n       'O48', 'O49', 'O50', 'O51', 'O52', 'O53', 'O54', 'O55', 'O56',\n       'O57', 'O58', 'O59', 'O60', 'O61', 'O62', 'O63', 'O64', 'O65',\n       'O66', 'O67', 'O68', 'O69', 'O70', 'O71', 'O72', 'O73', 'O74',\n       'O75', 'O76', 'O77', 'O78', 'O79', 'O80', 'O81', 'O82', 'O83',\n       'O84', 'O85', 'O86', 'O87', 'O88', 'O89', 'O90', 'O91', 'O92',\n       'O93', 'O94', 'O95', 'O96', 'O97', 'O98', 'O99', 'O100', 'O101',\n       'O102', 'O103', 'O104', 'O105', 'O106', 'O107', 'O108', 'O109',\n       'O110', 'O111', 'O112', 'O113', 'O114', 'O115', 'O116', 'O117',\n       'O118', 'O119', 'O120', 'O121', 'O122', 'O123', 'O124', 'O125',\n       'O126', 'O127', 'O128', 'O129', 'O130', 'O131', 'O132', 'O133',\n       'O134', 'O135', 'O136', 'O137', 'O138', 'O139', 'O140', 'O141',\n       'O142', 'O143', 'O144', 'O145', 'O146', 'O147', 'O148', 'O149',\n       'O150', 'O151', 'O152', 'O153', 'O154', 'O155', 'O156', 'O157',\n       'O158', 'O159', 'O160', 'O161', 'O162', 'O163', 'O164', 'O165',\n       'O166', 'O167', 'O168', 'O169', 'O170', 'O171', 'O172', 'O173',\n       'O174', 'O175', 'O176', 'O177', 'O178', 'O179', 'O180', 'O181',\n       'O182', 'O183', 'O184', 'O185', 'O186', 'O187', 'O188', 'O189',\n       'O190', 'O191', 'O192', 'O193', 'O194', 'O195', 'O196', 'O197',\n       'O198', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10',\n       'I11', 'I12', 'I13', 'I14', 'I15', 'I16', 'I17', 'I18', 'I19',\n       'I20', 'I21', 'I22', 'I23', 'I24', 'I25', 'I26', 'I27', 'I28',\n       'I29', 'I30', 'I31', 'I32', 'I33', 'I34', 'I35', 'I36', 'I37',\n       'I38', 'I39', 'I40', 'I41', 'I42', 'I43', 'I44', 'I45', 'I46',\n       'I47', 'I48', 'I49', 'I50', 'I51', 'I52', 'I53', 'I54', 'I55',\n       'I56', 'I57', 'I58', 'I59', 'I60', 'I61', 'I62', 'I63', 'I64',\n       'I65', 'I66', 'I67', 'I68', 'I69', 'I70', 'I71', 'I72', 'I73',\n       'I74', 'I75', 'I76', 'I77', 'I78', 'I79', 'I80', 'I81', 'I82',\n       'I83', 'I84', 'I85', 'I86', 'I87', 'I88', 'I89', 'I90', 'I91',\n       'I92', 'I93', 'I94', 'I95', 'I96', 'I97', 'I98', 'I99', 'I100',\n       'I101', 'I102', 'I103', 'I104', 'I105', 'I106', 'I107', 'I108',\n       'I109', 'I110', 'I111', 'I112', 'I113', 'I114', 'I115', 'I116',\n       'I117', 'I118', 'I119', 'I120', 'I121', 'I122', 'I123', 'I124',\n       'I125', 'I126', 'I127', 'I128', 'I129', 'I130', 'I131', 'I132',\n       'I133', 'I134', 'I135', 'I136', 'I137', 'I138', 'I139', 'I140',\n       'I141', 'I142', 'I143', 'I144', 'I145', 'I146', 'I147', 'I148',\n       'I149', 'I150', 'I151', 'I152', 'I153', 'I154', 'I155', 'I156',\n       'I157', 'I158', 'I159', 'I160', 'I161', 'I162', 'I163', 'I164',\n       'I165', 'I166', 'I167', 'I168', 'I169', 'I170', 'I171', 'I172',\n       'I173', 'I174', 'I175', 'I176', 'I177', 'I178', 'I179', 'I180',\n       'I181', 'I182', 'I183', 'I184', 'I185', 'I186', 'I187', 'I188',\n       'I189', 'I190', 'I191', 'I192', 'I193', 'I194', 'I195', 'I196',\n       'I197', 'I198', 'I199', 'I200', 'I201', 'I202', 'I203', 'I204',\n       'I205', 'I206', 'I207', 'I208', 'I209', 'I210', 'I211', 'I212',\n       'I213', 'I214', 'I215', 'I216', 'I217', 'I218', 'I219', 'I220',\n       'I221', 'I222', 'I223', 'I224', 'I225', 'I226', 'I227', 'I228',\n       'I229', 'I230', 'I231', 'I232', 'I233', 'I234', 'I235', 'I236',\n       'I237', 'I238', 'I239', 'I240', 'I241', 'I242', 'I243', 'I244'], \n      dtype='|S10'), '_iii': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'xlabel': <function xlabel at 0x3195a28>, 'typeNA': {<type 'numpy.float16'>: 'Float16', <type 'numpy.int16'>: 'Int16', 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, <type 'numpy.timedelta64'>: 'Timedelta64', <type 'numpy.uint8'>: 'UInt8', 'c16': 'Complex64', <type 'numpy.datetime64'>: 'Datetime64', 'D': 'Complex64', <type 'numpy.int8'>: 'Int8', 'H': 'UInt16', 'L': 'UInt64', <type 'numpy.void'>: 'Void0', <type 'numpy.bool_'>: 'Bool', 'd': 'Float64', 'h': 'Int16', 'l': 'Int64', <type 'numpy.unicode_'>: 'Unicode0', 'c32': 'Complex128', <type 'numpy.string_'>: 'String0', 'Timedelta64': <type 'numpy.timedelta64'>, 'b1': 'Bool', 'M8': 'Datetime64', 'String0': <type 'numpy.string_'>, <type 'numpy.object_'>: 'Object0', 'I': 'UInt32', '?': 'Bool', 'Void0': <type 'numpy.void'>, <type 'numpy.complex256'>: 'Complex128', 'G': 'Complex128', 'O': 'Object0', 'UInt8': <type 'numpy.uint8'>, 'S': 'String0', <type 'numpy.complex128'>: 'Complex64', 'UInt64': <type 'numpy.uint64'>, 'g': 'Float128', <type 'numpy.complex64'>: 'Complex32', 'Float16': <type 'numpy.float16'>, <type 'numpy.float128'>: 'Float128', 'Bool': <type 'numpy.bool_'>, 'u8': <type 'numpy.uint64'>, <type 'numpy.float64'>: 'Float64', 'u4': <type 'numpy.uint32'>, 'Unicode0': <type 'numpy.unicode_'>, 'u1': <type 'numpy.uint8'>, 'u2': <type 'numpy.uint16'>, 'Datetime64': <type 'numpy.datetime64'>, 'Int8': <type 'numpy.int8'>, <type 'numpy.float32'>: 'Float32', 'B': 'UInt8', 'F': 'Complex32', 'c8': 'Complex32', 'Int64': <type 'numpy.int64'>, 'Complex32': <type 'numpy.complex64'>, 'V': 'Void0', <type 'numpy.uint64'>: 'UInt64', 'b': 'Int8', 'f': 'Float32', 'm8': 'Timedelta64', <type 'numpy.int64'>: 'Int64', 'f16': 'Float128', 'UInt32': <type 'numpy.uint32'>, 'f2': 'Float16', 'f4': 'Float32', 'f8': 'Float64', 'Complex128': <type 'numpy.complex256'>, <type 'numpy.uint64'>: 'UInt64', 'Object0': <type 'numpy.object_'>, 'Int16': <type 'numpy.int16'>, <type 'numpy.int64'>: 'Int64', 'Float64': <type 'numpy.float64'>, 'UInt16': <type 'numpy.uint16'>, 'Float32': <type 'numpy.float32'>, 'i8': <type 'numpy.int64'>, <type 'numpy.uint32'>: 'UInt32', 'i1': <type 'numpy.int8'>, 'i2': <type 'numpy.int16'>, 'M': 'Datetime64', 'i4': <type 'numpy.int32'>, 'Q': 'UInt64', 'U': 'Unicode0', <type 'numpy.int32'>: 'Int32', 'e': 'Float16', 'i': 'Int32', 'm': 'Timedelta64', 'q': 'Int64', <type 'numpy.uint16'>: 'UInt16', 'Float128': <type 'numpy.float128'>}, '_i11': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', 'lastObserved': array([[ 2.78,  0.77,  0.1 , ...,  3.25,  3.05,  1.55],\n       [-4.62,  0.06, -0.22, ...,  0.52, -0.56,  0.33],\n       [ 0.02,  0.13,  0.18, ..., -0.47,  0.91,  0.97],\n       ..., \n       [-0.33,  0.23,  0.12, ..., -1.81, -1.01,  0.26],\n       [-1.13,  0.06,  0.  , ..., -0.23,  0.92,  1.17],\n       [-7.99, -0.78,  0.01, ..., -2.57, -2.34, -1.41]]), 'getbuffer': <built-in function getbuffer>, 'xcorr': <function xcorr at 0x3197e60>, 'slogdet': <function slogdet at 0x238cb90>, 'clip': <function clip at 0x21da0c8>, 'tripcolor': <function tripcolor at 0x3197cf8>, '_i27': u'trainInput.shape', 'half': <type 'numpy.float16'>, 'normal': <built-in method normal of mtrand.RandomState object at 0x7f399f841690>, '_i126': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', 'savez_compressed': <function savez_compressed at 0x23fb230>, 'TickHelper': <class 'matplotlib.ticker.TickHelper'>, 'isinteractive': <function isinteractive at 0x3194410>, 'eigvals': <function eigvals at 0x238c758>, 'seed': <built-in method seed of mtrand.RandomState object at 0x7f399f841690>, 'triu_indices_from': <function triu_indices_from at 0x230dc08>, 'conjugate': <ufunc 'conjugate'>, 'clim': <function clim at 0x3196320>, 'array2string': <function array2string at 0x21db050>, 'alterdot': <built-in function alterdot>, 'cross_validation': <module 'sklearn.cross_validation' from '/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc'>, 'asfortranarray': <function asfortranarray at 0x21c26e0>, 'binary_repr': <function binary_repr at 0x21dbc08>, 'angle': <function angle at 0x236c6e0>, '_78': (510, 55, 442), '_i9': u'len(targets)', 'randint': <built-in method randint of mtrand.RandomState object at 0x7f399f841690>, '_i7': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(trainOutput), n_folds=63, indices=False)', '_i6': u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(train), n_folds=63, indices=False)', '_i5': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', 'linalg': <module 'numpy.linalg' from '/usr/local/lib/python2.7/dist-packages/numpy/linalg/__init__.pyc'>, 'apply_over_axes': <function apply_over_axes at 0x2374b18>, '_i2': u'ls', '_i1': u'cd /home/lane/Kaggle/03\\\\ Predicting\\\\ Stock\\\\ Prices/', 'yoda': array([ 0.        ,  0.22      ,  0.        ,  0.        ,  0.22      ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.1       ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.02714286,  0.        ,  0.01714286,\n        0.        ,  0.1       ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.02714286,  0.        ,  0.        ,  0.01714286,\n        0.        ,  0.        ,  0.61571429,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.61571429,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.02714286,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.1       ,  0.        ,  0.        ,\n        0.02714286,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.22      ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.02714286,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.61571429,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.1       ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.22      ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.61571429,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ]), 'figlegend': <function figlegend at 0x3194de8>, 'ERR_LOG': 5, 'right_shift': <ufunc 'right_shift'>, 'take': <function take at 0x21d16e0>, 'rollaxis': <function rollaxis at 0x21c2c08>, 'set_state': <built-in method set_state of mtrand.RandomState object at 0x7f399f841690>, 'solve': <function solve at 0x238c500>, 'FixedFormatter': <class 'matplotlib.ticker.FixedFormatter'>, 'boxplot': <function boxplot at 0x3196c08>, 'SecondLocator': <class 'matplotlib.dates.SecondLocator'>, 'spectral': <function spectral at 0x3198b18>, 'get_numarray_include': <function get_numarray_include at 0x23691b8>, 'trace': <function trace at 0x21d1de8>, 'Artist': <class 'matplotlib.artist.Artist'>, 'any': <function any at 0x21da320>, 'Button': <class 'matplotlib.widgets.Button'>, 'who': <function who at 0x2369578>, 'compress': <function compress at 0x21da050>, 'NullFormatter': <class 'matplotlib.ticker.NullFormatter'>, 'histogramdd': <function histogramdd at 0x236c2a8>, '_i88': u'test.shape', '_i89': u'y.shape', 'beta': <built-in method beta of mtrand.RandomState object at 0x7f399f841690>, 'amap': <function amap at 0x2c51d70>, 'multiply': <ufunc 'multiply'>, '_i81': u'X.shape', 'mask_indices': <function mask_indices at 0x230da28>, 'detrend_none': <function detrend_none at 0x2c4f7d0>, '_i84': u'test.shape', 'amax': <function amax at 0x21da578>, 'numCols': 442, '_66': (510, 55, 198), 'subplot': <function subplot at 0x3195500>, 'logical_not': <ufunc 'logical_not'>, 'dist_point_to_segment': <function dist_point_to_segment at 0x2c517d0>, 'trainingDays': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510], '_i75': u'traincv.shape', '_i74': u'traincv', '_i77': u'train[traincv]', '_i76': u'testcv.shape', '_i71': u'cv', 'nbytes': {<type 'numpy.float16'>: 2, <type 'numpy.string_'>: 0, <type 'numpy.float128'>: 16, <type 'numpy.uint64'>: 8, <type 'numpy.int16'>: 2, <type 'numpy.timedelta64'>: 8, <type 'numpy.object_'>: 8, <type 'numpy.float64'>: 8, <type 'numpy.int64'>: 8, <type 'numpy.uint8'>: 1, <type 'numpy.datetime64'>: 8, <type 'numpy.complex256'>: 32, <type 'numpy.float32'>: 4, <type 'numpy.uint32'>: 4, <type 'numpy.int8'>: 1, <type 'numpy.void'>: 0, <type 'numpy.complex128'>: 16, <type 'numpy.uint64'>: 8, <type 'numpy.int32'>: 4, <type 'numpy.bool_'>: 1, <type 'numpy.unicode_'>: 0, <type 'numpy.complex64'>: 8, <type 'numpy.int64'>: 8, <type 'numpy.uint16'>: 2}, 'exp': <ufunc 'exp'>, '_ih': ['', u\"get_ipython().magic(u'cd /home/lane/Kaggle/03\\\\\\\\ Predicting\\\\\\\\ Stock\\\\\\\\ Prices/')\", u\"get_ipython().system(u'ls -F --color ')\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(train), n_folds=63, indices=False)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(trainOutput), n_folds=63, indices=False)', u'len(trainOutput)', u'len(targets)', u'len(target)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'trainInput.shape', u'trainOutput.shape', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:197] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:198] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'trainInput[509,54,243]', u'trainInput[509,54,244]', u'trainInput[509,54,243]', u'fullInput[509,54,244+197]', u'train            = np.zeros((510,55,244+198))\\ntrain[:,:,0:198] = trainOutput\\ntrain[:,:,198:]  = trainInput', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(target[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'trainOutput.shape', u'len(trainOutput[0])', u'target.shape', u'target.shape', u'trainInput.shape', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput(:,-1,:)', u'lastObserved = trainOutput[:,-1,:]\\nlastObserved.shape', u'target.shape', u'normTarget   = target - lastObserved[:target.shape[0],:]', u'normTarget.shape', u'target.shape', u'plot(normTarget[:,0])', u'plot(normTarget[:,197])', u'hist(normTarget[:,197])', u'hist(normTarget)', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1)))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1)))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1))', u'yoda.shape', u'normTarget.shape', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-2,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((200*198,1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True)', u\"yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,4)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,6)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nyaxis('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',norm=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',normed=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\nderiv.shape', u'normTarget.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'len(target)', u'cv', u'for i in cv:\\n    print i', u'for i,j in cv:\\n    print i,j', u'traincv', u'traincv.shape', u'testcv.shape', u'train[traincv]', u'train.shape', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201,:]\\ntest  = X[201:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201]\\ntest  = X[201:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'train.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:200]\\ntest  = X[200:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'y.shape', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'train.shape', u'test.shape', u'yoda = X.reshape((X.shape[0],1))', u'yoda.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock].reshape((deriv.shape[0],1))\\ny     = normTarget[:,stock]\\ntrain = X[:200,:]\\ntest  = X[200:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'predicted_probs.shape', u'len(predicted_probs)', u'len(predicted_probs[0])', u'lastObserved[:,stock].shape', u'pred = predicted_probs + lastObserved[200:,stock]', u'pred = predicted_probs + lastObserved[200:,stock]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape[2]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'numStocks', u'type(predicted_probs)', u'yoda = np.asarray(predicted_probs)\\nyoda.shape', u'yoda = np.asarray(predicted_probs)\\nluke = np.zeros((310,198))\\nluke[:,0] = yoda', u'pred[0]', u'## Fit Random Forest and generate predictions\\nnumStocks   = trainOutput.shape[2]\\nperformance = []\\npred        = np.zeros((310,numStocks))\\nfor stock in xrange(numStocks):\\n    \\n    # get stock-specific features\\n    X     = deriv[:,stock].reshape((deriv.shape[0],1))\\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n\\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n\\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import smtplib', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import pybrain', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random\\nimport smtplib\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=500, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=25, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'sheet.shape', u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection'], 'axvspan': <function axvspan at 0x3196a28>, 'FuncFormatter': <class 'matplotlib.ticker.FuncFormatter'>, 'dot': <built-in function dot>, 'int0': <type 'numpy.int64'>, 'pylab': <module 'matplotlib.pylab' from '/usr/local/lib/python2.7/dist-packages/matplotlib/pylab.pyc'>, '_i23': u'trainOutput.shape', 'WE': WE, '_i121': u'import pybrain', 'longfloat': <type 'numpy.float128'>, 'draw_if_interactive': <function wrapper at 0x325c410>, 'rayleigh': <built-in method rayleigh of mtrand.RandomState object at 0x7f399f841690>, 'text': <function text at 0x31981b8>, 'random': <module 'random' from '/usr/lib/python2.7/random.pyc'>, 'demean': <function demean at 0x2c4f6e0>, 'random_integers': <built-in method random_integers of mtrand.RandomState object at 0x7f399f841690>, 'datetime': <module 'datetime' from '/usr/lib/python2.7/lib-dynload/datetime.so'>, 'colors': <function colors at 0x3196140>, 'stackplot': <function stackplot at 0x3197a28>, '_i124': u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", 'locator_params': <function locator_params at 0x3198320>, '_67': (510, 198), '_i125': u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', 'find': <function find at 0x2c51050>, '_i20': u'train            = np.zeros((510,55,244+198))\\ntrain[:,:,0:198] = trainOutput\\ntrain[:,:,198:]  = trainInput', 'pause': <function pause at 0x3194578>, 'randn': <built-in method randn of mtrand.RandomState object at 0x7f399f841690>, 'errstate': <class 'numpy.core.numeric.errstate'>, 'title': <function title at 0x3195938>, 'FPE_UNDERFLOW': 4, '_i108': u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", '_8': 510, '_i113': u'type(predicted_probs)', 'frexp': <ufunc 'frexp'>, 'savefig': <function savefig at 0x3194e60>, 'PolarAxes': <class 'matplotlib.projections.polar.PolarAxes'>, 'DAILY': 3, 'center_matrix': <function center_matrix at 0x2c51500>, '_65': <matplotlib.text.Text object at 0x92e02d0>, 'smtplib': <module 'smtplib' from '/usr/lib/python2.7/smtplib.pyc'>, 'SHIFT_OVERFLOW': 3, 'over': <function over at 0x31952a8>, 'complex256': <type 'numpy.complex256'>, 'plotfile': <function plotfile at 0x31965f0>, '_i96': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock].reshape((deriv.shape[0],1))\\ny     = normTarget[:,stock]\\ntrain = X[:200,:]\\ntest  = X[200:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'get': <function getp at 0x2a9d1b8>, 'luke': array([[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.22,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       ..., \n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ]]), 'NZERO': -0.0, 'ceil': <ufunc 'ceil'>, 'ones': <function ones at 0x21c2410>, 'add_newdoc_ufunc': <built-in function add_newdoc_ufunc>, 'X': array([[  0.04    ,   1.5     ,   2.      , ...,   0.439681,   0.074476,\n          0.142166],\n       [ -0.11    ,   0.789473,  19.      , ...,   0.767666,   0.147196,\n          0.272029],\n       [ -0.08    ,   0.5     ,  12.      , ...,   0.216333,   0.062503,\n          0.062272],\n       ..., \n       [  0.27    ,   0.323529,  34.      , ...,   0.179467,   0.085557,\n          0.083333],\n       [  0.      ,   0.294117,  17.      , ...,   0.195387,   0.076333,\n          0.062539],\n       [  0.31    ,   1.6     ,   5.      , ...,   1.05697 ,   0.411582,\n          0.452769]]), 'count_nonzero': <built-in function count_nonzero>, 'target': array([[ 2.53,  1.03,  0.12, ...,  3.69,  3.56,  2.03],\n       [-4.95,  0.18, -0.24, ...,  1.22, -0.04,  0.38],\n       [ 0.16,  0.  ,  0.2 , ..., -0.04,  1.3 ,  1.61],\n       ..., \n       [-1.02,  1.53,  0.62, ...,  3.85,  4.87,  2.06],\n       [ 0.43,  0.12, -0.08, ..., -0.59, -0.67,  0.2 ],\n       [ 0.11,  0.  ,  0.29, ...,  0.48,  2.58,  0.47]]), '_108': <matplotlib.text.Text object at 0x918f1d0>, 'gray': <function gray at 0x31986e0>, 'qr': <function qr at 0x238c6e0>, 'bar': <function bar at 0x3196aa0>, '_102': 310, 'median': <function median at 0x236d668>, '_i99': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'geterr': <function geterr at 0x21dd140>, 'convolve': <function convolve at 0x21c2a28>, 'twiny': <function twiny at 0x31956e0>, 'logistic': <built-in method logistic of mtrand.RandomState object at 0x7f399f841690>, 'weibull': <built-in method weibull of mtrand.RandomState object at 0x7f399f841690>, 'x': array([ 0.004,  0.02 ,  0.004,  0.002,  0.002,  0.006,  0.002,  0.002,\n        0.008,  0.   ,  0.002,  0.   ,  0.   ,  0.   ,  0.002,  0.004,\n        0.   ,  0.006,  0.002,  0.012,  0.018,  0.006,  0.004,  0.002,\n        0.012,  0.026,  0.006,  0.02 ,  0.012,  0.   ,  0.002,  0.002,\n        0.   ,  0.004,  0.008,  0.002,  0.006,  0.   ,  0.   ,  0.012,\n        0.006,  0.01 ,  0.012,  0.004,  0.006,  0.012,  0.012,  0.   ,\n        0.01 ,  0.002,  0.006,  0.008,  0.014,  0.   ,  0.   ,  0.006,\n        0.008,  0.004,  0.018,  0.008,  0.01 ,  0.002,  0.   ,  0.006,\n        0.   ,  0.016,  0.018,  0.   ,  0.004,  0.004,  0.004,  0.008,\n        0.01 ,  0.012,  0.004,  0.002,  0.004,  0.01 ,  0.002,  0.006,\n        0.006,  0.004,  0.004,  0.004,  0.03 ,  0.008,  0.   ,  0.006,\n        0.004,  0.008,  0.   ,  0.014,  0.03 ,  0.01 ,  0.004,  0.004,\n        0.016,  0.004,  0.002,  0.004,  0.   ,  0.002,  0.004,  0.008,\n        0.002,  0.004,  0.   ,  0.006,  0.004,  0.004,  0.006,  0.002,\n        0.016,  0.004,  0.032,  0.012,  0.   ,  0.01 ,  0.   ,  0.002,\n        0.   ,  0.   ,  0.016,  0.002,  0.004,  0.008,  0.008,  0.   ,\n        0.002,  0.004,  0.01 ,  0.006,  0.002,  0.002,  0.006,  0.002,\n        0.006,  0.004,  0.008,  0.   ,  0.006,  0.002,  0.004,  0.   ,\n        0.002,  0.006,  0.006,  0.   ,  0.   ,  0.   ,  0.002,  0.016,\n        0.004,  0.028,  0.002,  0.004,  0.002,  0.   ,  0.002,  0.01 ,\n        0.002,  0.   ,  0.002,  0.002,  0.   ,  0.012,  0.002,  0.   ,\n        0.016,  0.004,  0.   ,  0.006]), 'isreal': <function isreal at 0x23017d0>, 'where': <built-in function where>, 'rcParamsDefault': RcParams({'agg.path.chunksize': 0,\n          'animation.avconv_args': '',\n          'animation.avconv_path': 'avconv',\n          'animation.bitrate': -1,\n          'animation.codec': 'mpeg4',\n          'animation.convert_args': '',\n          'animation.convert_path': 'convert',\n          'animation.ffmpeg_args': '',\n          'animation.ffmpeg_path': 'ffmpeg',\n          'animation.frame_format': 'png',\n          'animation.mencoder_args': '',\n          'animation.mencoder_path': 'mencoder',\n          'animation.writer': 'ffmpeg',\n          'axes.axisbelow': False,\n          'axes.color_cycle': ['b', 'g', 'r', 'c', 'm', 'y', 'k'],\n          'axes.edgecolor': 'k',\n          'axes.facecolor': 'w',\n          'axes.formatter.limits': [-7, 7],\n          'axes.formatter.use_locale': False,\n          'axes.formatter.use_mathtext': False,\n          'axes.grid': False,\n          'axes.hold': True,\n          'axes.labelcolor': 'k',\n          'axes.labelsize': 'medium',\n          'axes.labelweight': 'normal',\n          'axes.linewidth': 1.0,\n          'axes.titlesize': 'large',\n          'axes.unicode_minus': True,\n          'axes.xmargin': 0,\n          'axes.ymargin': 0,\n          'axes3d.grid': True,\n          'backend': 'Agg',\n          'backend.qt4': 'PyQt4',\n          'backend_fallback': True,\n          'contour.negative_linestyle': 'dashed',\n          'datapath': '/usr/local/lib/python2.7/dist-packages/matplotlib/mpl-data',\n          'docstring.hardcopy': False,\n          'examples.directory': '',\n          'figure.autolayout': False,\n          'figure.dpi': 80,\n          'figure.edgecolor': 'w',\n          'figure.facecolor': '0.75',\n          'figure.figsize': [8.0, 6.0],\n          'figure.frameon': True,\n          'figure.max_open_warning': 20,\n          'figure.subplot.bottom': 0.1,\n          'figure.subplot.hspace': 0.2,\n          'figure.subplot.left': 0.125,\n          'figure.subplot.right': 0.9,\n          'figure.subplot.top': 0.9,\n          'figure.subplot.wspace': 0.2,\n          'font.cursive': ['Apple Chancery',\n                           'Textile',\n                           'Zapf Chancery',\n                           'Sand',\n                           'cursive'],\n          'font.family': 'sans-serif',\n          'font.fantasy': ['Comic Sans MS',\n                           'Chicago',\n                           'Charcoal',\n                           'ImpactWestern',\n                           'fantasy'],\n          'font.monospace': ['Bitstream Vera Sans Mono',\n                             'DejaVu Sans Mono',\n                             'Andale Mono',\n                             'Nimbus Mono L',\n                             'Courier New',\n                             'Courier',\n                             'Fixed',\n                             'Terminal',\n                             'monospace'],\n          'font.sans-serif': ['Bitstream Vera Sans',\n                              'DejaVu Sans',\n                              'Lucida Grande',\n                              'Verdana',\n                              'Geneva',\n                              'Lucid',\n                              'Arial',\n                              'Helvetica',\n                              'Avant Garde',\n                              'sans-serif'],\n          'font.serif': ['Bitstream Vera Serif',\n                         'DejaVu Serif',\n                         'New Century Schoolbook',\n                         'Century Schoolbook L',\n                         'Utopia',\n                         'ITC Bookman',\n                         'Bookman',\n                         'Nimbus Roman No9 L',\n                         'Times New Roman',\n                         'Times',\n                         'Palatino',\n                         'Charter',\n                         'serif'],\n          'font.size': 12,\n          'font.stretch': 'normal',\n          'font.style': 'normal',\n          'font.variant': 'normal',\n          'font.weight': 'normal',\n          'grid.alpha': 1.0,\n          'grid.color': 'k',\n          'grid.linestyle': ':',\n          'grid.linewidth': 0.5,\n          'image.aspect': 'equal',\n          'image.cmap': 'jet',\n          'image.interpolation': 'bilinear',\n          'image.lut': 256,\n          'image.origin': 'upper',\n          'image.resample': False,\n          'interactive': False,\n          'keymap.all_axes': 'a',\n          'keymap.back': ['left', 'c', 'backspace'],\n          'keymap.forward': ['right', 'v'],\n          'keymap.fullscreen': ('f', 'ctrl+f'),\n          'keymap.grid': 'g',\n          'keymap.home': ['h', 'r', 'home'],\n          'keymap.pan': 'p',\n          'keymap.quit': ('ctrl+w', 'cmd+w'),\n          'keymap.save': ('s', 'ctrl+s'),\n          'keymap.xscale': ['k', 'L'],\n          'keymap.yscale': 'l',\n          'keymap.zoom': 'o',\n          'legend.borderaxespad': 0.5,\n          'legend.borderpad': 0.4,\n          'legend.columnspacing': 2.0,\n          'legend.fancybox': False,\n          'legend.fontsize': 'large',\n          'legend.frameon': True,\n          'legend.handleheight': 0.7,\n          'legend.handlelength': 2.0,\n          'legend.handletextpad': 0.8,\n          'legend.isaxes': True,\n          'legend.labelspacing': 0.5,\n          'legend.loc': 'upper right',\n          'legend.markerscale': 1.0,\n          'legend.numpoints': 2,\n          'legend.scatterpoints': 3,\n          'legend.shadow': False,\n          'lines.antialiased': True,\n          'lines.color': 'b',\n          'lines.dash_capstyle': 'butt',\n          'lines.dash_joinstyle': 'round',\n          'lines.linestyle': '-',\n          'lines.linewidth': 1.0,\n          'lines.marker': 'None',\n          'lines.markeredgewidth': 0.5,\n          'lines.markersize': 6,\n          'lines.solid_capstyle': 'projecting',\n          'lines.solid_joinstyle': 'round',\n          'mathtext.bf': 'serif:bold',\n          'mathtext.cal': 'cursive',\n          'mathtext.default': 'it',\n          'mathtext.fallback_to_cm': True,\n          'mathtext.fontset': 'cm',\n          'mathtext.it': 'serif:italic',\n          'mathtext.rm': 'serif',\n          'mathtext.sf': 'sans\\\\-serif',\n          'mathtext.tt': 'monospace',\n          'patch.antialiased': True,\n          'patch.edgecolor': 'k',\n          'patch.facecolor': 'b',\n          'patch.linewidth': 1.0,\n          'path.effects': [],\n          'path.simplify': True,\n          'path.simplify_threshold': 0.1111111111111111,\n          'path.sketch': None,\n          'path.snap': True,\n          'pdf.compression': 6,\n          'pdf.fonttype': 3,\n          'pdf.inheritcolor': False,\n          'pdf.use14corefonts': False,\n          'pgf.debug': False,\n          'pgf.preamble': [''],\n          'pgf.rcfonts': True,\n          'pgf.texsystem': 'xelatex',\n          'plugins.directory': '.matplotlib_plugins',\n          'polaraxes.grid': True,\n          'ps.distiller.res': 6000,\n          'ps.fonttype': 3,\n          'ps.papersize': 'letter',\n          'ps.useafm': False,\n          'ps.usedistiller': False,\n          'savefig.bbox': None,\n          'savefig.directory': '~',\n          'savefig.dpi': 100,\n          'savefig.edgecolor': 'w',\n          'savefig.extension': 'png',\n          'savefig.facecolor': 'w',\n          'savefig.format': 'png',\n          'savefig.frameon': True,\n          'savefig.jpeg_quality': 95,\n          'savefig.orientation': 'portrait',\n          'savefig.pad_inches': 0.1,\n          'svg.embed_char_paths': True,\n          'svg.fonttype': 'path',\n          'svg.image_inline': True,\n          'svg.image_noscale': False,\n          'text.antialiased': True,\n          'text.color': 'k',\n          'text.dvipnghack': None,\n          'text.hinting': True,\n          'text.hinting_factor': 8,\n          'text.latex.preamble': [''],\n          'text.latex.preview': False,\n          'text.latex.unicode': False,\n          'text.usetex': False,\n          'timezone': 'UTC',\n          'tk.pythoninspect': False,\n          'tk.window_focus': False,\n          'toolbar': 'toolbar2',\n          'verbose.fileo': 'sys.stdout',\n          'verbose.level': 'silent',\n          'webagg.open_in_browser': True,\n          'webagg.port': 8988,\n          'webagg.port_retries': 50,\n          'xtick.color': 'k',\n          'xtick.direction': 'in',\n          'xtick.labelsize': 'medium',\n          'xtick.major.pad': 4,\n          'xtick.major.size': 4,\n          'xtick.major.width': 0.5,\n          'xtick.minor.pad': 4,\n          'xtick.minor.size': 2,\n          'xtick.minor.width': 0.5,\n          'ytick.color': 'k',\n          'ytick.direction': 'in',\n          'ytick.labelsize': 'medium',\n          'ytick.major.pad': 4,\n          'ytick.major.size': 4,\n          'ytick.major.width': 0.5,\n          'ytick.minor.pad': 4,\n          'ytick.minor.size': 2,\n          'ytick.minor.width': 0.5}), 'fftsurr': <function fftsurr at 0x2c518c0>, 'SHIFT_UNDERFLOW': 6, 'argmax': <function argmax at 0x21d1b18>, 'minorticks_on': <function minorticks_on at 0x3195de8>, 'prctile': <function prctile at 0x2c51230>, 'deprecate_with_doc': <function <lambda> at 0x2369410>, 'imsave': <function imsave at 0x3196500>, 'polyder': <function polyder at 0x238ce60>, 'LogFormatterMathtext': <class 'matplotlib.ticker.LogFormatterMathtext'>, 'imread': <function imread at 0x3196488>, 'close': <function close at 0x3194b90>, 'DayLocator': <class 'matplotlib.dates.DayLocator'>, 'Formatter': <class 'matplotlib.ticker.Formatter'>, 'is_string_like': <function is_string_like at 0x29927d0>, 'contour': <function contour at 0x3196d70>, 'rad2deg': <ufunc 'rad2deg'>, 'isnan': <ufunc 'isnan'>, 'autoscale': <function autoscale at 0x3198488>, 'firstLine': ['fileId', 'O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8', 'O9', 'O10', 'O11', 'O12', 'O13', 'O14', 'O15', 'O16', 'O17', 'O18', 'O19', 'O20', 'O21', 'O22', 'O23', 'O24', 'O25', 'O26', 'O27', 'O28', 'O29', 'O30', 'O31', 'O32', 'O33', 'O34', 'O35', 'O36', 'O37', 'O38', 'O39', 'O40', 'O41', 'O42', 'O43', 'O44', 'O45', 'O46', 'O47', 'O48', 'O49', 'O50', 'O51', 'O52', 'O53', 'O54', 'O55', 'O56', 'O57', 'O58', 'O59', 'O60', 'O61', 'O62', 'O63', 'O64', 'O65', 'O66', 'O67', 'O68', 'O69', 'O70', 'O71', 'O72', 'O73', 'O74', 'O75', 'O76', 'O77', 'O78', 'O79', 'O80', 'O81', 'O82', 'O83', 'O84', 'O85', 'O86', 'O87', 'O88', 'O89', 'O90', 'O91', 'O92', 'O93', 'O94', 'O95', 'O96', 'O97', 'O98', 'O99', 'O100', 'O101', 'O102', 'O103', 'O104', 'O105', 'O106', 'O107', 'O108', 'O109', 'O110', 'O111', 'O112', 'O113', 'O114', 'O115', 'O116', 'O117', 'O118', 'O119', 'O120', 'O121', 'O122', 'O123', 'O124', 'O125', 'O126', 'O127', 'O128', 'O129', 'O130', 'O131', 'O132', 'O133', 'O134', 'O135', 'O136', 'O137', 'O138', 'O139', 'O140', 'O141', 'O142', 'O143', 'O144', 'O145', 'O146', 'O147', 'O148', 'O149', 'O150', 'O151', 'O152', 'O153', 'O154', 'O155', 'O156', 'O157', 'O158', 'O159', 'O160', 'O161', 'O162', 'O163', 'O164', 'O165', 'O166', 'O167', 'O168', 'O169', 'O170', 'O171', 'O172', 'O173', 'O174', 'O175', 'O176', 'O177', 'O178', 'O179', 'O180', 'O181', 'O182', 'O183', 'O184', 'O185', 'O186', 'O187', 'O188', 'O189', 'O190', 'O191', 'O192', 'O193', 'O194', 'O195', 'O196', 'O197', 'O198'], 'get_xyz_where': <function get_xyz_where at 0x2c51668>, 'irr': <function irr at 0x23fe050>, 'sctypeDict': {0: <type 'numpy.bool_'>, 1: <type 'numpy.int8'>, 2: <type 'numpy.uint8'>, 3: <type 'numpy.int16'>, 4: <type 'numpy.uint16'>, 5: <type 'numpy.int32'>, 6: <type 'numpy.uint32'>, 7: <type 'numpy.int64'>, 8: <type 'numpy.uint64'>, 9: <type 'numpy.int64'>, 10: <type 'numpy.uint64'>, 11: <type 'numpy.float32'>, 12: <type 'numpy.float64'>, 13: <type 'numpy.float128'>, 14: <type 'numpy.complex64'>, 15: <type 'numpy.complex128'>, 16: <type 'numpy.complex256'>, 17: <type 'numpy.object_'>, 18: <type 'numpy.string_'>, 19: <type 'numpy.unicode_'>, 20: <type 'numpy.void'>, 21: <type 'numpy.datetime64'>, 'unicode': <type 'numpy.unicode_'>, 23: <type 'numpy.float16'>, 'cfloat': <type 'numpy.complex128'>, 'longfloat': <type 'numpy.float128'>, 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, 'unicode_': <type 'numpy.unicode_'>, 'complex': <type 'numpy.complex128'>, 'timedelta64': <type 'numpy.timedelta64'>, 'uint16': <type 'numpy.uint16'>, 'c16': <type 'numpy.complex128'>, 'float32': <type 'numpy.float32'>, 'complex256': <type 'numpy.complex256'>, 'D': <type 'numpy.complex128'>, 'H': <type 'numpy.uint16'>, 'void': <type 'numpy.void'>, 'unicode0': <type 'numpy.unicode_'>, 'L': <type 'numpy.uint64'>, 'P': <type 'numpy.uint64'>, 'half': <type 'numpy.float16'>, 'void0': <type 'numpy.void'>, 'd': <type 'numpy.float64'>, 'h': <type 'numpy.int16'>, 'l': <type 'numpy.int64'>, 'p': <type 'numpy.int64'>, 'c32': <type 'numpy.complex256'>, 22: <type 'numpy.timedelta64'>, 'O8': <type 'numpy.object_'>, 'Timedelta64': <type 'numpy.timedelta64'>, 'object0': <type 'numpy.object_'>, 'b1': <type 'numpy.bool_'>, 'float128': <type 'numpy.float128'>, 'M8': <type 'numpy.datetime64'>, 'String0': <type 'numpy.string_'>, 'float16': <type 'numpy.float16'>, 'ulonglong': <type 'numpy.uint64'>, 'i1': <type 'numpy.int8'>, 'uint32': <type 'numpy.uint32'>, '?': <type 'numpy.bool_'>, 'Void0': <type 'numpy.void'>, 'complex64': <type 'numpy.complex64'>, 'G': <type 'numpy.complex256'>, 'O': <type 'numpy.object_'>, 'UInt8': <type 'numpy.uint8'>, 'S': <type 'numpy.string_'>, 'byte': <type 'numpy.int8'>, 'UInt64': <type 'numpy.uint64'>, 'g': <type 'numpy.float128'>, 'float64': <type 'numpy.float64'>, 'ushort': <type 'numpy.uint16'>, 'float_': <type 'numpy.float64'>, 'uint': <type 'numpy.uint64'>, 'object_': <type 'numpy.object_'>, 'Float16': <type 'numpy.float16'>, 'complex_': <type 'numpy.complex128'>, 'Unicode0': <type 'numpy.unicode_'>, 'uintp': <type 'numpy.uint64'>, 'intc': <type 'numpy.int32'>, 'csingle': <type 'numpy.complex64'>, 'datetime64': <type 'numpy.datetime64'>, 'float': <type 'numpy.float64'>, 'bool8': <type 'numpy.bool_'>, 'Bool': <type 'numpy.bool_'>, 'intp': <type 'numpy.int64'>, 'uintc': <type 'numpy.uint32'>, 'bytes_': <type 'numpy.string_'>, 'u8': <type 'numpy.uint64'>, 'u4': <type 'numpy.uint32'>, 'int_': <type 'numpy.int64'>, 'cdouble': <type 'numpy.complex128'>, 'u1': <type 'numpy.uint8'>, 'complex128': <type 'numpy.complex128'>, 'u2': <type 'numpy.uint16'>, 'f8': <type 'numpy.float64'>, 'Datetime64': <type 'numpy.datetime64'>, 'ubyte': <type 'numpy.uint8'>, 'm8': <type 'numpy.timedelta64'>, 'B': <type 'numpy.uint8'>, 'uint0': <type 'numpy.uint64'>, 'F': <type 'numpy.complex64'>, 'bool_': <type 'numpy.bool_'>, 'uint8': <type 'numpy.uint8'>, 'c8': <type 'numpy.complex64'>, 'Int64': <type 'numpy.int64'>, 'Int8': <type 'numpy.int8'>, 'Complex32': <type 'numpy.complex64'>, 'V': <type 'numpy.void'>, 'int8': <type 'numpy.int8'>, 'uint64': <type 'numpy.uint64'>, 'b': <type 'numpy.int8'>, 'f': <type 'numpy.float32'>, 'double': <type 'numpy.float64'>, 'UInt32': <type 'numpy.uint32'>, 'clongdouble': <type 'numpy.complex256'>, 'str': <type 'numpy.string_'>, 'f16': <type 'numpy.float128'>, 'f2': <type 'numpy.float16'>, 'f4': <type 'numpy.float32'>, 'int32': <type 'numpy.int32'>, 'int': <type 'numpy.int64'>, 'longdouble': <type 'numpy.float128'>, 'Complex128': <type 'numpy.complex256'>, 'single': <type 'numpy.float32'>, 'string': <type 'numpy.string_'>, 'q': <type 'numpy.int64'>, 'Int16': <type 'numpy.int16'>, 'Float64': <type 'numpy.float64'>, 'longcomplex': <type 'numpy.complex256'>, 'UInt16': <type 'numpy.uint16'>, 'bool': <type 'numpy.bool_'>, 'Float32': <type 'numpy.float32'>, 'string0': <type 'numpy.string_'>, 'longlong': <type 'numpy.int64'>, 'i8': <type 'numpy.int64'>, 'int16': <type 'numpy.int16'>, 'str_': <type 'numpy.string_'>, 'I': <type 'numpy.uint32'>, 'object': <type 'numpy.object_'>, 'M': <type 'numpy.datetime64'>, 'i4': <type 'numpy.int32'>, 'singlecomplex': <type 'numpy.complex64'>, 'Q': <type 'numpy.uint64'>, 'string_': <type 'numpy.string_'>, 'U': <type 'numpy.unicode_'>, 'a': <type 'numpy.string_'>, 'short': <type 'numpy.int16'>, 'e': <type 'numpy.float16'>, 'i': <type 'numpy.int32'>, 'clongfloat': <type 'numpy.complex256'>, 'm': <type 'numpy.timedelta64'>, 'Object0': <type 'numpy.object_'>, 'int64': <type 'numpy.int64'>, 'Float128': <type 'numpy.float128'>, 'i2': <type 'numpy.int16'>, 'int0': <type 'numpy.int64'>}, 'xticks': <function xticks at 0x3195cf8>, 'hist': <function hist at 0x3197230>, 'bivariate_normal': <function bivariate_normal at 0x2c515f0>, 'NINF': -inf, 'min_scalar_type': <built-in function min_scalar_type>, 'geometric': <built-in method geometric of mtrand.RandomState object at 0x7f399f841690>, 'normTarget': array([[-0.25,  0.26,  0.02, ...,  0.44,  0.51,  0.48],\n       [-0.33,  0.12, -0.02, ...,  0.7 ,  0.52,  0.05],\n       [ 0.14, -0.13,  0.02, ...,  0.43,  0.39,  0.64],\n       ..., \n       [ 1.4 ,  0.26,  0.09, ...,  1.32,  0.72,  0.22],\n       [-0.54,  0.3 , -0.04, ..., -0.37, -0.02, -0.14],\n       [ 0.95,  0.18,  0.17, ...,  0.12,  0.37,  0.05]]), 'sort_complex': <function sort_complex at 0x236c7d0>, 'nested_iters': <built-in function nested_iters>, 'concatenate': <built-in function concatenate>, 'ERR_DEFAULT2': 521, '_i48': u'yoda = normTarget.reshape((200*198,1))', '_i49': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1]+1,0))', 'vdot': <built-in function vdot>, 'bincount': <built-in function bincount>, 'num2epoch': <function num2epoch at 0x307faa0>, '_i46': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-2,0))', 'sctypes': {'int': [<type 'numpy.int8'>, <type 'numpy.int16'>, <type 'numpy.int32'>, <type 'numpy.int64'>], 'float': [<type 'numpy.float16'>, <type 'numpy.float32'>, <type 'numpy.float64'>, <type 'numpy.float128'>], 'uint': [<type 'numpy.uint8'>, <type 'numpy.uint16'>, <type 'numpy.uint32'>, <type 'numpy.uint64'>], 'complex': [<type 'numpy.complex64'>, <type 'numpy.complex128'>, <type 'numpy.complex256'>], 'others': [<type 'bool'>, <type 'object'>, <type 'str'>, <type 'unicode'>, <type 'numpy.void'>]}, 'transpose': <function transpose at 0x21d19b0>, 'add_newdocs': <module 'numpy.add_newdocs' from '/usr/local/lib/python2.7/dist-packages/numpy/add_newdocs.pyc'>, '_i42': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1))', '_i41': u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1)))', 'detrend_linear': <function detrend_linear at 0x2c4f848>, 'corrcoef': <function corrcoef at 0x236d0c8>, 'fromregex': <function fromregex at 0x23fb488>, 'vector_lengths': <function vector_lengths at 0x2c53b90>, 'vectorize': <class 'numpy.lib.function_base.vectorize'>, 'set_printoptions': <function set_printoptions at 0x21dac08>, '_i43': u'yoda.shape', '_i44': u'normTarget.shape', 'trim_zeros': <function trim_zeros at 0x236c848>, 'WEEKLY': 2, 'cos': <ufunc 'cos'>, '_37': (array([   3.,   11.,   42.,  112.,   26.,    4.,    0.,    0.,    0.,    2.]), array([-2.12 , -1.478, -0.836, -0.194,  0.448,  1.09 ,  1.732,  2.374,\n        3.016,  3.658,  4.3  ]), <a list of 10 Patch objects>), 'vlines': <function vlines at 0x3197de8>, 'detrend': <function detrend at 0x2c4f668>, 'arccosh': <ufunc 'arccosh'>, 'DateFormatter': <class 'matplotlib.dates.DateFormatter'>, 'equal': <ufunc 'equal'>, 'display': <function display at 0x1d4c848>, '_i39': u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1))', 'cumprod': <function cumprod at 0x21da758>, 'LinAlgError': <class 'numpy.linalg.linalg.LinAlgError'>, 'float_': <type 'numpy.float64'>, 'deprecate': <function deprecate at 0x23692a8>, 'vander': <function vander at 0x230d938>, '_i31': u'target.shape', 'geterrobj': <built-in function geterrobj>, '_i33': u'normTarget.shape', 'interactive': <function interactive at 0x2a006e0>, '_i35': u'plot(normTarget[:,0])', 'clf': <function clf at 0x3194cf8>, '_i37': u'hist(normTarget[:,197])', 'prepca': <function prepca at 0x2c511b8>, 'wald': <built-in method wald of mtrand.RandomState object at 0x7f399f841690>, 'fromiter': <built-in function fromiter>, 'prctile_rank': <function prctile_rank at 0x2c51488>, '_i29': u'lastObserved = trainOutput(:,-1,:)', 'cm': <module 'matplotlib.cm' from '/usr/local/lib/python2.7/dist-packages/matplotlib/cm.pyc'>, 'tril': <function tril at 0x230d848>, 'poly': <function poly at 0x2377b90>, 'loglog': <function loglog at 0x3197410>, '_i100': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'bitwise_or': <ufunc 'bitwise_or'>, '_i102': u'len(predicted_probs)', '_i103': u'len(predicted_probs[0])', 'figtext': <function figtext at 0x3195050>, 'norm_flat': <function norm_flat at 0x2c51f50>, '_i3': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', '_i107': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', 'tricontourf': <function tricontourf at 0x3197c80>, 'diff': <function diff at 0x236c5f0>, 'cohere': <function cohere at 0x3196c80>, 'normpdf': <function normpdf at 0x2c4fed8>, 'AutoLocator': <class 'matplotlib.ticker.AutoLocator'>, 'iterable': <function iterable at 0x236c1b8>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x2728f10>, 'get_include': <function get_include at 0x2369140>, 'pv': <function pv at 0x23fbe60>, 'tensordot': <function tensordot at 0x21c2b18>, 'piecewise': <function piecewise at 0x236c410>, 'rfftn': <function rfftn at 0x2409410>, 'invert': <ufunc 'invert'>, 'UFUNC_PYVALS_NAME': 'UFUNC_PYVALS', 'fftpack_lite': <module 'numpy.fft.fftpack_lite' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.so'>, 'sinc': <function sinc at 0x236d578>, 'numRows': 55, 'SHIFT_INVALID': 9, 'ubyte': <type 'numpy.uint8'>, 'axis': <function axis at 0x31959b0>, '_i47': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]+1,0))', 'matrix_rank': <function matrix_rank at 0x238caa0>, 'degrees': <ufunc 'degrees'>, 'pi': 3.141592653589793, 'numpy': <module 'numpy' from '/usr/local/lib/python2.7/dist-packages/numpy/__init__.pyc'>, '__doc__': 'Automatically created module for IPython interactive environment', 'empty': <built-in function empty>, 'fig': <matplotlib.figure.Figure object at 0xaa97ad0>, 'find_common_type': <function find_common_type at 0x21bfe60>, 'random_sample': <built-in method random_sample of mtrand.RandomState object at 0x7f399f841690>, 'longest_ones': <function longest_ones at 0x2c51140>, 'irfft2': <function irfft2 at 0x2409578>, 'arcsin': <ufunc 'arcsin'>, 'sctypeNA': {<type 'numpy.float16'>: 'Float16', <type 'numpy.int16'>: 'Int16', 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, <type 'numpy.timedelta64'>: 'Timedelta64', <type 'numpy.uint8'>: 'UInt8', 'c16': 'Complex64', <type 'numpy.datetime64'>: 'Datetime64', 'D': 'Complex64', <type 'numpy.int8'>: 'Int8', 'H': 'UInt16', 'L': 'UInt64', <type 'numpy.void'>: 'Void0', <type 'numpy.bool_'>: 'Bool', 'd': 'Float64', 'h': 'Int16', 'l': 'Int64', <type 'numpy.unicode_'>: 'Unicode0', 'c32': 'Complex128', <type 'numpy.string_'>: 'String0', 'Timedelta64': <type 'numpy.timedelta64'>, 'b1': 'Bool', 'M8': 'Datetime64', 'String0': <type 'numpy.string_'>, <type 'numpy.object_'>: 'Object0', 'I': 'UInt32', '?': 'Bool', 'Void0': <type 'numpy.void'>, <type 'numpy.complex256'>: 'Complex128', 'G': 'Complex128', 'O': 'Object0', 'UInt8': <type 'numpy.uint8'>, 'S': 'String0', <type 'numpy.complex128'>: 'Complex64', 'UInt64': <type 'numpy.uint64'>, 'g': 'Float128', <type 'numpy.complex64'>: 'Complex32', 'Float16': <type 'numpy.float16'>, <type 'numpy.float128'>: 'Float128', 'Bool': <type 'numpy.bool_'>, 'u8': <type 'numpy.uint64'>, <type 'numpy.float64'>: 'Float64', 'u4': <type 'numpy.uint32'>, 'Unicode0': <type 'numpy.unicode_'>, 'u1': <type 'numpy.uint8'>, 'u2': <type 'numpy.uint16'>, 'Datetime64': <type 'numpy.datetime64'>, 'Int8': <type 'numpy.int8'>, <type 'numpy.float32'>: 'Float32', 'B': 'UInt8', 'F': 'Complex32', 'c8': 'Complex32', 'Int64': <type 'numpy.int64'>, 'Complex32': <type 'numpy.complex64'>, 'V': 'Void0', <type 'numpy.uint64'>: 'UInt64', 'b': 'Int8', 'f': 'Float32', 'm8': 'Timedelta64', <type 'numpy.int64'>: 'Int64', 'f16': 'Float128', 'UInt32': <type 'numpy.uint32'>, 'f2': 'Float16', 'f4': 'Float32', 'f8': 'Float64', 'Complex128': <type 'numpy.complex256'>, <type 'numpy.uint64'>: 'UInt64', 'Object0': <type 'numpy.object_'>, 'Int16': <type 'numpy.int16'>, <type 'numpy.int64'>: 'Int64', 'Float64': <type 'numpy.float64'>, 'UInt16': <type 'numpy.uint16'>, 'Float32': <type 'numpy.float32'>, 'i8': <type 'numpy.int64'>, <type 'numpy.uint32'>: 'UInt32', 'i1': <type 'numpy.int8'>, 'i2': <type 'numpy.int16'>, 'M': 'Datetime64', 'i4': <type 'numpy.int32'>, 'Q': 'UInt64', 'U': 'Unicode0', <type 'numpy.int32'>: 'Int32', 'e': 'Float16', 'i': 'Int32', 'm': 'Timedelta64', 'q': 'Int64', <type 'numpy.uint16'>: 'UInt16', 'Float128': <type 'numpy.float128'>}, 'imag': <function imag at 0x23016e0>, 'sctype2char': <function sctype2char at 0x21bf1b8>, 'singlecomplex': <type 'numpy.complex64'>, 'SHIFT_DIVIDEBYZERO': 0, 'sort': <function sort at 0x21d1a28>, 'standard_t': <built-in method standard_t of mtrand.RandomState object at 0x7f399f841690>, '_i40': u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1)))', 'csv2rec': <function csv2rec at 0x2c527d0>, 'MachAr': <class 'numpy.core.machar.MachAr'>, 'apply_along_axis': <function apply_along_axis at 0x2374aa0>, 'new_figure_manager': <function new_figure_manager at 0x3186f50>, 'tight_layout': <function tight_layout at 0x3195848>, 'array_repr': <function array_repr at 0x21db398>, '_i105': u'pred = predicted_probs + lastObserved[200:,stock]', 'reciprocal': <ufunc 'reciprocal'>, 'frompyfunc': <built-in function frompyfunc>, 'rot90': <function rot90 at 0x230d5f0>, 'dstack': <function dstack at 0x2374c80>, 'float64': <type 'numpy.float64'>, 'traincv': array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True, False, False, False, False, False, False,\n       False, False], dtype=bool), 'Annotation': <class 'matplotlib.text.Annotation'>, 'colorbar': <function colorbar at 0x31962a8>, 'cast': {<type 'numpy.float16'>: <function <lambda> at 0x21bf230>, <type 'numpy.string_'>: <function <lambda> at 0x21bf2a8>, <type 'numpy.float128'>: <function <lambda> at 0x21bf320>, <type 'numpy.uint64'>: <function <lambda> at 0x21bf398>, <type 'numpy.int16'>: <function <lambda> at 0x21bf410>, <type 'numpy.timedelta64'>: <function <lambda> at 0x21bf488>, <type 'numpy.object_'>: <function <lambda> at 0x21bf500>, <type 'numpy.float64'>: <function <lambda> at 0x21bf578>, <type 'numpy.int64'>: <function <lambda> at 0x21bf5f0>, <type 'numpy.uint8'>: <function <lambda> at 0x21bf668>, <type 'numpy.datetime64'>: <function <lambda> at 0x21bf6e0>, <type 'numpy.complex256'>: <function <lambda> at 0x21bf758>, <type 'numpy.float32'>: <function <lambda> at 0x21bf7d0>, <type 'numpy.uint32'>: <function <lambda> at 0x21bf848>, <type 'numpy.int8'>: <function <lambda> at 0x21bf8c0>, <type 'numpy.void'>: <function <lambda> at 0x21bf938>, <type 'numpy.complex128'>: <function <lambda> at 0x21bf9b0>, <type 'numpy.uint64'>: <function <lambda> at 0x21bfa28>, <type 'numpy.int32'>: <function <lambda> at 0x21bfaa0>, <type 'numpy.bool_'>: <function <lambda> at 0x21bfb18>, <type 'numpy.unicode_'>: <function <lambda> at 0x21bfb90>, <type 'numpy.complex64'>: <function <lambda> at 0x21bfc08>, <type 'numpy.int64'>: <function <lambda> at 0x21bfc80>, <type 'numpy.uint16'>: <function <lambda> at 0x21bfcf8>}, '_i94': u'yoda = X.reshape((X.shape[0],1))', 'gumbel': <built-in method gumbel of mtrand.RandomState object at 0x7f399f841690>, 'rfft2': <function rfft2 at 0x2409488>, 'eig': <function eig at 0x238c8c0>, 'packbits': <built-in function packbits>, 'issctype': <function issctype at 0x21b8de8>, 'mgrid': <numpy.lib.index_tricks.nd_grid object at 0x236f910>, 'vonmises': <built-in method vonmises of mtrand.RandomState object at 0x7f399f841690>, 'ushort': <type 'numpy.uint16'>, 'normTarget_vector': array([[-0.25],\n       [ 0.26],\n       [ 0.02],\n       ..., \n       [ 0.12],\n       [ 0.37],\n       [ 0.05]]), 'Polygon': <class 'matplotlib.patches.Polygon'>, 'helper': <module 'numpy.fft.helper' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/helper.pyc'>, 'empty_like': <built-in function empty_like>, '_75': (200,), '_74': array([False, False, False, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), '_77': array([[[ 0.      ,  0.      ,  0.      , ...,  0.160672,  0.054283,\n          0.060093],\n        [ 1.61    ,  0.12    ,  0.12    , ...,  0.246306,  0.448241,\n          0.377197],\n        [ 1.12    ,  0.31    ,  0.12    , ...,  0.281271,  0.484713,\n          0.431599],\n        ..., \n        [ 0.9     ,  0.19    ,  0.07    , ...,  0.119027,  0.084617,\n          0.074685],\n        [ 0.87    ,  0.22    ,  0.08    , ...,  0.122028,  0.058538,\n          0.080691],\n        [ 0.83    ,  0.25    ,  0.08    , ...,  0.125018,  0.043205,\n          0.088569]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.405808,  0.188892,\n          0.209284],\n        [ 0.95    , -0.18    ,  0.15    , ...,  0.42738 ,  0.348119,\n          0.34322 ],\n        [ 1.04    , -0.18    ,  0.15    , ...,  0.463135,  0.439758,\n          0.449271],\n        ..., \n        [ 0.87    , -0.01    ,  0.1     , ...,  0.447247,  0.132313,\n          0.208433],\n        [ 0.83    ,  0.      ,  0.05    , ...,  0.445714,  0.153232,\n          0.138243],\n        [ 0.97    , -0.05    ,  0.05    , ...,  0.445714,  0.155649,\n          0.138243]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.934708,  0.084538,\n          0.154596],\n        [ 2.75    ,  0.25    ,  0.      , ...,  0.859673,  0.675959,\n          0.553122],\n        [ 2.22    ,  0.24    ,  0.      , ...,  0.800801,  0.754047,\n          0.652951],\n        ..., \n        [ 6.09    , -0.13    ,  0.      , ...,  0.717239,  0.111535,\n          0.55109 ],\n        [ 6.22    , -0.13    ,  0.      , ...,  0.712795,  0.116218,\n          0.388987],\n        [ 5.75    , -0.17    ,  0.      , ...,  0.715292,  0.152665,\n          0.252609]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.199729,  0.051769,\n          0.117898],\n        [-3.29    ,  0.04    ,  0.24    , ...,  0.349317,  0.77501 ,\n          0.659621],\n        [-3.53    ,  0.06    ,  0.37    , ...,  0.460716,  1.013778,\n          0.894228],\n        ..., \n        [-2.21    ,  1.33    ,  0.5     , ...,  0.221407,  0.051251,\n          0.160312],\n        [-2.25    ,  1.27    ,  0.54    , ...,  0.203557,  0.054283,\n          0.14087 ],\n        [-2.42    ,  1.27    ,  0.53    , ...,  0.185629,  0.059889,\n          0.054874]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.52827 ,  0.128219,\n          0.104881],\n        [ 0.17    , -0.06    ,  0.      , ...,  0.520413,  0.180665,\n          0.150702],\n        [ 0.59    , -0.12    , -0.06    , ...,  0.520859,  0.288167,\n          0.243676],\n        ..., \n        [ 0.97    , -0.24    , -0.08    , ...,  0.296868,  0.023381,\n          0.264344],\n        [ 0.82    , -0.24    , -0.08    , ...,  0.297405,  0.037417,\n          0.211529],\n        [ 0.97    , -0.18    , -0.04    , ...,  0.298542,  0.037238,\n          0.132077]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.31634 ,  0.082624,\n          0.108628],\n        [-0.71    ,  0.26    ,  0.74    , ...,  0.307045,  0.20775 ,\n          0.205129],\n        [-1.06    ,  0.19    ,  0.74    , ...,  0.31471 ,  0.277897,\n          0.274672],\n        ..., \n        [-1.04    , -0.08    ,  0.12    , ...,  0.184709,  0.06532 ,  0.16    ],\n        [-0.95    , -0.19    ,  0.12    , ...,  0.178122,  0.028284,\n          0.152315],\n        [-0.84    , -0.18    ,  0.12    , ...,  0.173413,  0.054283,\n          0.123063]]]), 'einsum': <built-in function einsum>, '_71': sklearn.cross_validation.KFold(n=200, n_folds=63), '_70': 200, 'signbit': <ufunc 'signbit'>, 'cond': <function cond at 0x238ca28>, 'chisquare': <built-in method chisquare of mtrand.RandomState object at 0x7f399f841690>, 'conj': <ufunc 'conjugate'>, 'asmatrix': <function asmatrix at 0x236dc80>, 'floating': <type 'numpy.floating'>, 'flatiter': <type 'numpy.flatiter'>, 'bitwise_xor': <ufunc 'bitwise_xor'>, 'WeekdayLocator': <class 'matplotlib.dates.WeekdayLocator'>, '_34': (200, 198), 'fabs': <ufunc 'fabs'>, 'Locator': <class 'matplotlib.ticker.Locator'>, 'generic': <type 'numpy.generic'>, 'reshape': <function reshape at 0x21d1758>, 'to': 'lanemcintosh@gmail.com', 'NaN': nan, 'cross': <function cross at 0x21c2cf8>, 'sqrt': <ufunc 'sqrt'>, 'show_config': <function show at 0x20f9b18>, 'longcomplex': <type 'numpy.complex256'>, 'poly_between': <function poly_between at 0x2c53938>, 'pad': <function pad at 0x23fec08>, 'split': <function split at 0x2374de8>, 'getp': <function getp at 0x2a9d1b8>, 'floor_divide': <ufunc 'floor_divide'>, '__version__': '1.7.1', 'format_parser': <class numpy.core.records.format_parser at 0x226ebb0>, 'nextafter': <ufunc 'nextafter'>, 'exponential': <built-in method exponential of mtrand.RandomState object at 0x7f399f841690>, 'dedent': <function dedent at 0x2994938>, 'polyval': <function polyval at 0x238cf50>, 'infty': inf, 'flipud': <function flipud at 0x230d578>, 'i0': <function i0 at 0x236d488>, 'permutation': <built-in method permutation of mtrand.RandomState object at 0x7f399f841690>, 'disconnect': <function disconnect at 0x3194c80>, 'iscomplexobj': <function iscomplexobj at 0x2301848>, 'sys': <module 'sys' (built-in)>, 'average': <function average at 0x236c320>, '_exit_code': 0, 'setdiff1d': <function setdiff1d at 0x236c140>, 'psd': <function psd at 0x31976e0>, 'mafromtxt': <function mafromtxt at 0x23fb5f0>, 'bartlett': <function bartlett at 0x236d1b8>, 'polydiv': <function polydiv at 0x238d1b8>, 'numStocks': 198, 'drange': <function drange at 0x307d140>, 'safe_eval': <function safe_eval at 0x2369938>, 'ifft': <function ifft at 0x23fee60>, 'cov': <function cov at 0x236cde8>, 'greater_equal': <ufunc 'greater_equal'>, 'i': 243, 'Tester': <class 'numpy.testing.nosetester.NoseTester'>, 'trapz': <function trapz at 0x236d7d0>, 'PINF': inf, 'rec_drop_fields': <function rec_drop_fields at 0x2c52500>, 'recfromtxt': <function recfromtxt at 0x23fb668>, 'setp': <function setp at 0x31948c0>, 'In': ['', u\"get_ipython().magic(u'cd /home/lane/Kaggle/03\\\\\\\\ Predicting\\\\\\\\ Stock\\\\\\\\ Prices/')\", u\"get_ipython().system(u'ls -F --color ')\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(train), n_folds=63, indices=False)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(trainOutput), n_folds=63, indices=False)', u'len(trainOutput)', u'len(targets)', u'len(target)', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=1500, n_jobs=2)\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'trainInput.shape', u'trainOutput.shape', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:197] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'fullInput = np.zeros((510,55,244+198))\\nfullInput[:,:,0:198] = trainOutput\\nfullInput[:,:,198:] = trainInput', u'trainInput[509,54,243]', u'trainInput[509,54,244]', u'trainInput[509,54,243]', u'fullInput[509,54,244+197]', u'train            = np.zeros((510,55,244+198))\\ntrain[:,:,0:198] = trainOutput\\ntrain[:,:,198:]  = trainInput', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(target[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'trainOutput.shape', u'len(trainOutput[0])', u'target.shape', u'target.shape', u'trainInput.shape', u'#create and train the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput(:,-1,:)', u'lastObserved = trainOutput[:,-1,:]\\nlastObserved.shape', u'target.shape', u'normTarget   = target - lastObserved[:target.shape[0],:]', u'normTarget.shape', u'target.shape', u'plot(normTarget[:,0])', u'plot(normTarget[:,197])', u'hist(normTarget[:,197])', u'hist(normTarget)', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1],1)))', u'hist(normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1)))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,1))', u'yoda.shape', u'normTarget.shape', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-2,0))', u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((200*198,1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1]+1,0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],0))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100)', u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True)', u\"yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,4)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,6)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nyaxis('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('yoda')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',norm=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled',normed=True)\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\nderiv.shape', u'normTarget.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'len(target)', u'cv', u'for i in cv:\\n    print i', u'for i,j in cv:\\n    print i,j', u'traincv', u'traincv.shape', u'testcv.shape', u'train[traincv]', u'train.shape', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201,:]\\ntest  = X[201:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'X.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201]\\ntest  = X[201:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'train.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:200]\\ntest  = X[200:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'train.shape', u'test.shape', u'y.shape', u'train.shape', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'train.shape', u'test.shape', u'yoda = X.reshape((X.shape[0],1))', u'yoda.shape', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock].reshape((deriv.shape[0],1))\\ny     = normTarget[:,stock]\\ntrain = X[:200,:]\\ntest  = X[200:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', u'predicted_probs.shape', u'len(predicted_probs)', u'len(predicted_probs[0])', u'lastObserved[:,stock].shape', u'pred = predicted_probs + lastObserved[200:,stock]', u'pred = predicted_probs + lastObserved[200:,stock]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'trainOutput.shape[2]', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', u\"fig = gcf()\\nfig.set_size_inches(16,5.5)\\n\\nnormTarget_vector = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(normTarget_vector,100,log=True,histtype='stepfilled')\\ntitle('Distribution of Normalized Percent Gain/Loss after last observed value')\\nylabel('Frequency')\\nxlabel('Percent Gain/Loss After Last Observed Value')\", u'numStocks', u'type(predicted_probs)', u'yoda = np.asarray(predicted_probs)\\nyoda.shape', u'yoda = np.asarray(predicted_probs)\\nluke = np.zeros((310,198))\\nluke[:,0] = yoda', u'pred[0]', u'## Fit Random Forest and generate predictions\\nnumStocks   = trainOutput.shape[2]\\nperformance = []\\npred        = np.zeros((310,numStocks))\\nfor stock in xrange(numStocks):\\n    \\n    # get stock-specific features\\n    X     = deriv[:,stock].reshape((deriv.shape[0],1))\\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n\\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n\\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import smtplib', u'## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'import pybrain', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random\\nimport smtplib\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation', u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=700, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=63, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'#create the random forest\\n#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\\nrf = RandomForestClassifier(n_estimators=500, n_jobs=2)  #was 1500 n_estimators\\ncv = cross_validation.KFold(len(target), n_folds=25, indices=False)', u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', u'sheet.shape', u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection'], 'y': array([-0.25, -0.33,  0.14,  0.64, -0.07, -0.22, -0.67, -0.86,  0.3 ,\n        0.29,  0.04,  0.97,  0.36,  0.51, -0.49, -0.09,  0.53, -1.21,\n        2.27,  2.77, -0.52,  0.  ,  0.88,  0.29,  0.46,  0.9 ,  0.05,\n        0.33, -2.03,  0.43,  0.68,  0.56, -0.69, -1.95,  0.05, -0.7 ,\n       -0.47, -0.29,  0.68,  0.19,  0.87, -0.02,  0.38,  0.21, -0.36,\n        0.  , -0.55,  0.89, -0.14, -0.24, -2.89, -0.2 , -1.47, -1.58,\n       -0.86, -0.56, -0.13, -0.27, -0.07,  0.16, -1.16, -0.25,  0.65,\n        0.34,  0.34,  3.43,  0.41,  0.05,  0.1 ,  0.48,  0.1 , -0.63,\n       -2.05,  0.85,  0.57,  0.23,  0.2 ,  0.13,  0.88, -1.5 , -0.65,\n        0.09,  0.95, -0.72, -2.65, -0.09,  0.04,  0.36,  2.23, -0.33,\n       -0.02, -0.05,  1.37,  0.86,  0.04,  2.78, -0.76, -4.44, -0.15,\n        0.28, -0.99,  0.66,  0.19, -1.3 , -1.45, -0.52, -0.95,  0.27,\n       -3.92,  0.46, -0.5 , -0.17,  1.65,  3.24,  1.18,  0.55,  0.23,\n       -0.03, -0.43, -0.51,  0.08,  0.04, -1.49,  1.15, -0.77,  0.  ,\n       -0.26,  1.78,  0.99, -0.95, -0.76, -0.41, -0.14,  1.34,  0.15,\n       -1.35, -0.18, -0.21,  0.23, -1.52,  1.17, -0.25,  0.33,  0.02,\n        0.29,  0.74, -0.16, -0.06, -2.7 , -0.11,  1.05, -0.31, -0.95,\n       -0.9 ,  2.19,  0.09, -0.76, -0.57, -0.85,  2.14,  1.62,  0.05,\n       -0.4 ,  0.23,  2.3 ,  2.  ,  0.58, -0.37, -0.43,  0.01, -0.62,\n       -0.58, -0.52,  1.23,  0.57,  0.49, -0.02,  0.63, -0.1 ,  0.15,\n        0.96, -0.38,  0.73, -0.93,  0.1 ,  1.15,  0.39,  0.18, -3.55,\n       -0.53,  0.27,  0.05, -0.15, -1.86,  0.25,  0.08,  0.47,  1.4 ,\n       -0.54,  0.95]), 'grid': <function grid at 0x3198050>, 'trainOutput': array([[[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [ 0.97,  0.45,  0.16, ...,  1.37,  1.3 ,  0.29],\n        [ 1.69,  0.51,  0.  , ...,  1.62,  1.81,  0.48],\n        ..., \n        [ 2.79,  0.77,  0.08, ...,  3.17,  3.08,  1.61],\n        [ 2.74,  0.73,  0.12, ...,  3.25,  3.03,  1.59],\n        [ 2.78,  0.77,  0.1 , ...,  3.25,  3.05,  1.55]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-2.14,  0.  , -0.2 , ..., -0.5 ,  0.38,  0.43],\n        [-2.23, -0.07, -0.28, ..., -0.27, -0.02,  0.21],\n        ..., \n        [-4.72,  0.09, -0.2 , ...,  0.61, -0.54,  0.5 ],\n        [-4.51,  0.1 , -0.24, ...,  0.63, -0.52,  0.41],\n        [-4.62,  0.06, -0.22, ...,  0.52, -0.56,  0.33]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [ 0.52,  0.13,  0.12, ...,  0.43,  0.45,  0.16],\n        [ 0.48,  0.13,  0.1 , ...,  0.27,  0.58,  0.25],\n        ..., \n        [ 0.04,  0.12,  0.2 , ..., -0.4 ,  0.96,  1.03],\n        [ 0.1 ,  0.11,  0.2 , ..., -0.45,  0.93,  1.03],\n        [ 0.02,  0.13,  0.18, ..., -0.47,  0.91,  0.97]],\n\n       ..., \n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-0.28, -0.18,  0.08, ..., -0.98, -0.21,  0.07],\n        [-0.13, -0.23,  0.08, ..., -1.66, -0.54,  0.24],\n        ..., \n        [-0.66,  0.12,  0.12, ..., -2.06, -1.19,  0.3 ],\n        [-0.6 ,  0.21,  0.12, ..., -2.06, -1.16,  0.3 ],\n        [-0.33,  0.23,  0.12, ..., -1.81, -1.01,  0.26]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-1.07, -0.07,  0.  , ..., -0.7 , -0.2 , -0.2 ],\n        [-0.99, -0.01,  0.04, ..., -0.6 ,  0.25,  0.1 ],\n        ..., \n        [-0.99,  0.11,  0.  , ..., -0.08,  0.88,  1.29],\n        [-1.13,  0.07,  0.  , ..., -0.18,  0.9 ,  1.17],\n        [-1.13,  0.06,  0.  , ..., -0.23,  0.92,  1.17]],\n\n       [[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n        [-6.56, -0.36,  0.04, ..., -1.78, -1.83, -1.03],\n        [-5.8 , -0.36,  0.04, ..., -1.23, -1.33, -0.73],\n        ..., \n        [-8.24, -0.79,  0.04, ..., -2.59, -2.34, -1.49],\n        [-8.3 , -0.78,  0.04, ..., -2.61, -2.36, -1.47],\n        [-7.99, -0.78,  0.01, ..., -2.57, -2.34, -1.41]]]), 'standard_normal': <built-in method standard_normal of mtrand.RandomState object at 0x7f399f841690>, 'RankWarning': <class 'numpy.lib.polynomial.RankWarning'>, 'ascontiguousarray': <function ascontiguousarray at 0x21c2668>, '_89': (200,), 'load': <function load at 0x23f9aa0>, '_i4': u\"#DATA PROCESSING\\n#create the training & test sets, skipping the header row with [1:]\\ntrainingDays = range(1,511) #200 days of training data, 510 total days\\nheaders = np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='string')[0]\\nnumRows = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[0]\\nnumCols = (np.array(np.genfromtxt(open('Data/data/1.csv','r'),delimiter=',',dtype='f8')[1:])).shape[1]\\nisOutput = [headers[x][0] == 'O' for x in range(0,numCols)]\\nisInput  = [headers[x][0] == 'I' for x in range(0,numCols)]\\ntrainOutput = np.zeros((len(trainingDays),numRows,sum(isOutput)))\\ntrainInput  = np.zeros((len(trainingDays),numRows,sum(isInput)))\\nfor i in trainingDays:\\n    dataset = np.genfromtxt(open('Data/data/'+str(i)+'.csv','r'), delimiter=',', dtype='f8')[1:]\\n    dataset = np.array(dataset)  # (5minIncrement,stock/feature)\\n    for j in range(0,numCols):\\n        if headers[j][0] == 'O':\\n            trainOutput[i-1,:,j] = dataset[:,j]   # (day,5minIncrement,stock)\\n        elif headers[j][0] == 'I':\\n            trainInput[i-1,:,(j-sum(isOutput))] = dataset[:,j]    # (day,5minIncrement,feature)\\n\\n#target prices 2 hours later (only outputs, no inputs) \\ntarget = np.array(np.genfromtxt(open('Data/trainLabels.csv','r'), delimiter=',', dtype='f8')[1:])\\ntarget = target[:,1:]  # (day,price2HrsLater)\", 'hexbin': <function hexbin at 0x31971b8>, 'Arrow': <class 'matplotlib.patches.Arrow'>, 'less': <ufunc 'less'>, 'putmask': <built-in function putmask>, 'UFUNC_BUFSIZE_DEFAULT': 8192, 'get_state': <built-in method get_state of mtrand.RandomState object at 0x7f399f841690>, 'NAN': nan, 'test_transformed': array([[ -2.90000000e-01,   3.95000000e+01,   5.65000000e+01, ...,\n          8.48180000e-02,   1.46046000e-01,   2.20786000e-01],\n       [  3.80000000e-01,   2.80000000e+01,   3.50000000e+01, ...,\n          6.08164000e-01,   7.14327000e-01,   4.69965000e-01],\n       [  2.00000000e-02,   1.30250000e+02,   4.83750000e+01, ...,\n          9.14371000e-01,   8.75696000e-01,   1.20665000e-01],\n       ..., \n       [  2.70000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          1.78577000e-01,   7.33330000e-02,   8.55570000e-02],\n       [  0.00000000e+00,   4.14500000e+02,   2.80000000e+01, ...,\n          6.20088000e-01,   6.15484000e-01,   7.63330000e-02],\n       [  3.10000000e-01,   0.00000000e+00,   0.00000000e+00, ...,\n          6.87380000e-02,  -4.30400000e-03,   4.11582000e-01]]), 'typeDict': {0: <type 'numpy.bool_'>, 1: <type 'numpy.int8'>, 2: <type 'numpy.uint8'>, 3: <type 'numpy.int16'>, 4: <type 'numpy.uint16'>, 5: <type 'numpy.int32'>, 6: <type 'numpy.uint32'>, 7: <type 'numpy.int64'>, 8: <type 'numpy.uint64'>, 9: <type 'numpy.int64'>, 10: <type 'numpy.uint64'>, 11: <type 'numpy.float32'>, 12: <type 'numpy.float64'>, 13: <type 'numpy.float128'>, 14: <type 'numpy.complex64'>, 15: <type 'numpy.complex128'>, 16: <type 'numpy.complex256'>, 17: <type 'numpy.object_'>, 18: <type 'numpy.string_'>, 19: <type 'numpy.unicode_'>, 20: <type 'numpy.void'>, 21: <type 'numpy.datetime64'>, 'unicode': <type 'numpy.unicode_'>, 23: <type 'numpy.float16'>, 'cfloat': <type 'numpy.complex128'>, 'longfloat': <type 'numpy.float128'>, 'Int32': <type 'numpy.int32'>, 'Complex64': <type 'numpy.complex128'>, 'unicode_': <type 'numpy.unicode_'>, 'complex': <type 'numpy.complex128'>, 'timedelta64': <type 'numpy.timedelta64'>, 'uint16': <type 'numpy.uint16'>, 'c16': <type 'numpy.complex128'>, 'float32': <type 'numpy.float32'>, 'complex256': <type 'numpy.complex256'>, 'D': <type 'numpy.complex128'>, 'H': <type 'numpy.uint16'>, 'void': <type 'numpy.void'>, 'unicode0': <type 'numpy.unicode_'>, 'L': <type 'numpy.uint64'>, 'P': <type 'numpy.uint64'>, 'half': <type 'numpy.float16'>, 'void0': <type 'numpy.void'>, 'd': <type 'numpy.float64'>, 'h': <type 'numpy.int16'>, 'l': <type 'numpy.int64'>, 'p': <type 'numpy.int64'>, 'c32': <type 'numpy.complex256'>, 22: <type 'numpy.timedelta64'>, 'O8': <type 'numpy.object_'>, 'Timedelta64': <type 'numpy.timedelta64'>, 'object0': <type 'numpy.object_'>, 'b1': <type 'numpy.bool_'>, 'float128': <type 'numpy.float128'>, 'M8': <type 'numpy.datetime64'>, 'String0': <type 'numpy.string_'>, 'float16': <type 'numpy.float16'>, 'ulonglong': <type 'numpy.uint64'>, 'i1': <type 'numpy.int8'>, 'uint32': <type 'numpy.uint32'>, '?': <type 'numpy.bool_'>, 'Void0': <type 'numpy.void'>, 'complex64': <type 'numpy.complex64'>, 'G': <type 'numpy.complex256'>, 'O': <type 'numpy.object_'>, 'UInt8': <type 'numpy.uint8'>, 'S': <type 'numpy.string_'>, 'byte': <type 'numpy.int8'>, 'UInt64': <type 'numpy.uint64'>, 'g': <type 'numpy.float128'>, 'float64': <type 'numpy.float64'>, 'ushort': <type 'numpy.uint16'>, 'float_': <type 'numpy.float64'>, 'uint': <type 'numpy.uint64'>, 'object_': <type 'numpy.object_'>, 'Float16': <type 'numpy.float16'>, 'complex_': <type 'numpy.complex128'>, 'Unicode0': <type 'numpy.unicode_'>, 'uintp': <type 'numpy.uint64'>, 'intc': <type 'numpy.int32'>, 'csingle': <type 'numpy.complex64'>, 'datetime64': <type 'numpy.datetime64'>, 'float': <type 'numpy.float64'>, 'bool8': <type 'numpy.bool_'>, 'Bool': <type 'numpy.bool_'>, 'intp': <type 'numpy.int64'>, 'uintc': <type 'numpy.uint32'>, 'bytes_': <type 'numpy.string_'>, 'u8': <type 'numpy.uint64'>, 'u4': <type 'numpy.uint32'>, 'int_': <type 'numpy.int64'>, 'cdouble': <type 'numpy.complex128'>, 'u1': <type 'numpy.uint8'>, 'complex128': <type 'numpy.complex128'>, 'u2': <type 'numpy.uint16'>, 'f8': <type 'numpy.float64'>, 'Datetime64': <type 'numpy.datetime64'>, 'ubyte': <type 'numpy.uint8'>, 'm8': <type 'numpy.timedelta64'>, 'B': <type 'numpy.uint8'>, 'uint0': <type 'numpy.uint64'>, 'F': <type 'numpy.complex64'>, 'bool_': <type 'numpy.bool_'>, 'uint8': <type 'numpy.uint8'>, 'c8': <type 'numpy.complex64'>, 'Int64': <type 'numpy.int64'>, 'Int8': <type 'numpy.int8'>, 'Complex32': <type 'numpy.complex64'>, 'V': <type 'numpy.void'>, 'int8': <type 'numpy.int8'>, 'uint64': <type 'numpy.uint64'>, 'b': <type 'numpy.int8'>, 'f': <type 'numpy.float32'>, 'double': <type 'numpy.float64'>, 'UInt32': <type 'numpy.uint32'>, 'clongdouble': <type 'numpy.complex256'>, 'str': <type 'numpy.string_'>, 'f16': <type 'numpy.float128'>, 'f2': <type 'numpy.float16'>, 'f4': <type 'numpy.float32'>, 'int32': <type 'numpy.int32'>, 'int': <type 'numpy.int64'>, 'longdouble': <type 'numpy.float128'>, 'Complex128': <type 'numpy.complex256'>, 'single': <type 'numpy.float32'>, 'string': <type 'numpy.string_'>, 'q': <type 'numpy.int64'>, 'Int16': <type 'numpy.int16'>, 'Float64': <type 'numpy.float64'>, 'longcomplex': <type 'numpy.complex256'>, 'UInt16': <type 'numpy.uint16'>, 'bool': <type 'numpy.bool_'>, 'Float32': <type 'numpy.float32'>, 'string0': <type 'numpy.string_'>, 'longlong': <type 'numpy.int64'>, 'i8': <type 'numpy.int64'>, 'int16': <type 'numpy.int16'>, 'str_': <type 'numpy.string_'>, 'I': <type 'numpy.uint32'>, 'object': <type 'numpy.object_'>, 'M': <type 'numpy.datetime64'>, 'i4': <type 'numpy.int32'>, 'singlecomplex': <type 'numpy.complex64'>, 'Q': <type 'numpy.uint64'>, 'string_': <type 'numpy.string_'>, 'U': <type 'numpy.unicode_'>, 'a': <type 'numpy.string_'>, 'short': <type 'numpy.int16'>, 'e': <type 'numpy.float16'>, 'i': <type 'numpy.int32'>, 'clongfloat': <type 'numpy.complex256'>, 'm': <type 'numpy.timedelta64'>, 'Object0': <type 'numpy.object_'>, 'int64': <type 'numpy.int64'>, 'Float128': <type 'numpy.float128'>, 'i2': <type 'numpy.int16'>, 'int0': <type 'numpy.int64'>}, 'shape': <function shape at 0x21d1f50>, '_i98': u'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn import cross_validation\\nfrom scipy import optimize\\nimport meanAbsoluteError as err\\nimport numpy as np\\nimport datetime\\nimport random', 'setbufsize': <function setbufsize at 0x21dd1b8>, '_85': (201,), '_i93': u'test.shape', '_i92': u'train.shape', '_i91': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', '_i90': u'train.shape', '_i97': u'#iterate through the training and test cross validation segments and\\n#run the classifier on each one, aggregating the results into a list\\nresults = []\\nfor traincv, testcv in cv:\\n    probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n    results.append( err.maefun(y[testcv], [x[1] for x in probas]) )\\n\\n#print out the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(results).mean() )\\n   \\n#generate predictions and save to file\\npredicted_probs = [x[1] for x in rf.predict_proba(test)]', 'cfloat': <type 'numpy.complex128'>, '_i95': u'yoda.shape', 'RAISE': 2, 'detrend_mean': <function detrend_mean at 0x2c4f758>, '_87': (200,), 'isscalar': <function isscalar at 0x21dbb90>, 'SubplotTool': <class 'matplotlib.widgets.SubplotTool'>, 'get_current_fig_manager': <function get_current_fig_manager at 0x3194b18>, 'character': <type 'numpy.character'>, 'bench': <bound method NoseTester.test of <numpy.testing.nosetester.NoseTester object at 0x2383a90>>, 'fullInput': array([[[ 0.      ,  0.      ,  0.      , ...,  0.299584,  0.038816,\n          0.081309],\n        [ 0.97    ,  0.45    ,  0.16    , ...,  0.314446,  0.251952,\n          0.206263],\n        [ 1.69    ,  0.51    ,  0.      , ...,  0.357783,  0.510176,\n          0.429069],\n        ..., \n        [ 2.79    ,  0.77    ,  0.08    , ...,  0.269088,  0.126912,\n          0.103441],\n        [ 2.74    ,  0.73    ,  0.12    , ...,  0.262727,  0.133116,\n          0.111704],\n        [ 2.78    ,  0.77    ,  0.1     , ...,  0.259782,  0.121326,\n          0.124544]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.320344,  0.071274,\n          0.057831],\n        [-2.14    ,  0.      , -0.2     , ...,  0.410495,  0.634182,\n          0.521483],\n        [-2.23    , -0.07    , -0.28    , ...,  0.478352,  0.79485 ,\n          0.690853],\n        ..., \n        [-4.72    ,  0.09    , -0.2     , ...,  0.231589,  0.067725,\n          0.090799],\n        [-4.51    ,  0.1     , -0.24    , ...,  0.231602,  0.072388,\n          0.100995],\n        [-4.62    ,  0.06    , -0.22    , ...,  0.225328,  0.048442,\n          0.083666]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.19655 ,  0.150555,\n          0.12083 ],\n        [ 0.52    ,  0.13    ,  0.12    , ...,  0.194066,  0.153753,\n          0.128841],\n        [ 0.48    ,  0.13    ,  0.1     , ...,  0.187594,  0.153753,\n          0.132288],\n        ..., \n        [ 0.04    ,  0.12    ,  0.2     , ...,  0.183963,  0.073756,\n          0.08124 ],\n        [ 0.1     ,  0.11    ,  0.2     , ...,  0.177811,  0.060332,\n          0.066165],\n        [ 0.02    ,  0.13    ,  0.18    , ...,  0.174681,  0.06121 ,  0.06    ]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.150991,  0.073394,\n          0.067082],\n        [-0.28    , -0.18    ,  0.08    , ...,  0.150545,  0.066933,\n          0.067082],\n        [-0.13    , -0.23    ,  0.08    , ...,  0.15091 ,  0.068896,\n          0.069121],\n        ..., \n        [-0.66    ,  0.12    ,  0.12    , ...,  0.197203,  0.073121,\n          0.083666],\n        [-0.6     ,  0.21    ,  0.12    , ...,  0.198655,  0.074833,\n          0.069282],\n        [-0.33    ,  0.23    ,  0.12    , ...,  0.198691,  0.099599,  0.08    ]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.150959,  0.089443,\n          0.095102],\n        [-1.07    , -0.07    ,  0.      , ...,  0.191609,  0.267133,\n          0.241753],\n        [-0.99    , -0.01    ,  0.04    , ...,  0.223181,  0.315383,\n          0.298794],\n        ..., \n        [-0.99    ,  0.11    ,  0.      , ...,  0.188956,  0.062823,\n          0.055678],\n        [-1.13    ,  0.07    ,  0.      , ...,  0.191981,  0.066232,\n          0.058119],\n        [-1.13    ,  0.06    ,  0.      , ...,  0.191485,  0.062823,  0.06    ]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  1.10484 ,  0.054283,\n          0.094868],\n        [-6.56    , -0.36    ,  0.04    , ...,  1.356407,  1.782152,\n          1.461476],\n        [-5.8     , -0.36    ,  0.04    , ...,  1.523808,  2.131682,\n          1.812402],\n        ..., \n        [-8.24    , -0.79    ,  0.04    , ...,  0.575108,  0.300311,\n          0.310644],\n        [-8.3     , -0.78    ,  0.04    , ...,  0.569777,  0.276743,\n          0.284429],\n        [-7.99    , -0.78    ,  0.01    , ...,  0.557479,  0.214942,\n          0.323883]]]), 'source': <function source at 0x2369758>, 'add': <ufunc 'add'>, 'uint16': <type 'numpy.uint16'>, 'ndenumerate': <class 'numpy.lib.index_tricks.ndenumerate'>, 'hlines': <function hlines at 0x3197320>, 'ufunc': <type 'numpy.ufunc'>, 'save': <function save at 0x23fb140>, 'multinomial': <built-in method multinomial of mtrand.RandomState object at 0x7f399f841690>, 'ravel': <function ravel at 0x21d1e60>, 'float32': <type 'numpy.float32'>, 'real': <function real at 0x2301668>, 'int32': <type 'numpy.int32'>, 'path_length': <function path_length at 0x2c53c80>, 'tril_indices': <function tril_indices at 0x230daa0>, '_i117': u'## Fit Random Forest and generate predictions\\nnumStocks   = trainOutput.shape[2]\\nperformance = []\\npred        = np.zeros((310,numStocks))\\nfor stock in xrange(numStocks):\\n    \\n    # get stock-specific features\\n    X     = deriv[:,stock].reshape((deriv.shape[0],1))\\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n\\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train[traincv], y[traincv]).predict_proba(train[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n\\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'around': <function around at 0x21da938>, 'cbook': <module 'matplotlib.cbook' from '/usr/local/lib/python2.7/dist-packages/matplotlib/cbook.pyc'>, 'lexsort': <built-in function lexsort>, 'get_scale_names': <function get_scale_names at 0x2fc5050>, 'complex_': <type 'numpy.complex128'>, 'ComplexWarning': <class 'numpy.core.numeric.ComplexWarning'>, 'datestr2num': <function datestr2num at 0x307bd70>, 'np': <module 'numpy' from '/usr/local/lib/python2.7/dist-packages/numpy/__init__.pyc'>, 'unicode0': <type 'numpy.unicode_'>, 'ipmt': <function ipmt at 0x23fbcf8>, 'issubclass_': <function issubclass_ at 0x21b8ed8>, 'atleast_3d': <function atleast_3d at 0x22746e0>, 'nper': <function nper at 0x23fbc80>, 'integer': <type 'numpy.integer'>, 'unique': <function unique at 0x2369e60>, 'mod': <ufunc 'remainder'>, '_sh': <module 'IPython.core.shadowns' from '/usr/local/lib/python2.7/dist-packages/ipython-1.1.0-py2.7.egg/IPython/core/shadowns.pyc'>, 'bitwise_not': <ufunc 'invert'>, 'plot_date': <function plot_date at 0x3197668>, '_i101': u'predicted_probs.shape', '_i131': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'laplace': <built-in method laplace of mtrand.RandomState object at 0x7f399f841690>, 'getbufsize': <function getbufsize at 0x21dd230>, 'isfortran': <function isfortran at 0x21c27d0>, '_i134': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', 'get_printoptions': <function get_printoptions at 0x21dacf8>, 'asarray_chkfinite': <function asarray_chkfinite at 0x236c398>, 'rcParams': RcParams({'agg.path.chunksize': 0,\n          'animation.avconv_args': '',\n          'animation.avconv_path': 'avconv',\n          'animation.bitrate': -1,\n          'animation.codec': 'mpeg4',\n          'animation.convert_args': '',\n          'animation.convert_path': 'convert',\n          'animation.ffmpeg_args': '',\n          'animation.ffmpeg_path': 'ffmpeg',\n          'animation.frame_format': 'png',\n          'animation.mencoder_args': '',\n          'animation.mencoder_path': 'mencoder',\n          'animation.writer': 'ffmpeg',\n          'axes.axisbelow': False,\n          'axes.color_cycle': ['#66c2a5',\n                               '#fc8d62',\n                               '#8da0cb',\n                               '#e78ac3',\n                               '#a6d854',\n                               '#ffd92f',\n                               '#e5c494'],\n          'axes.edgecolor': 'k',\n          'axes.facecolor': 'w',\n          'axes.formatter.limits': [-7, 7],\n          'axes.formatter.use_locale': False,\n          'axes.formatter.use_mathtext': False,\n          'axes.grid': False,\n          'axes.hold': True,\n          'axes.labelcolor': 'k',\n          'axes.labelsize': 'medium',\n          'axes.labelweight': 'normal',\n          'axes.linewidth': 1.0,\n          'axes.titlesize': 'large',\n          'axes.unicode_minus': True,\n          'axes.xmargin': 0,\n          'axes.ymargin': 0,\n          'axes3d.grid': True,\n          'backend': 'module://IPython.kernel.zmq.pylab.backend_inline',\n          'backend.qt4': 'PyQt4',\n          'backend_fallback': True,\n          'contour.negative_linestyle': 'dashed',\n          'datapath': '/usr/local/lib/python2.7/dist-packages/matplotlib/mpl-data',\n          'docstring.hardcopy': False,\n          'examples.directory': '',\n          'figure.autolayout': False,\n          'figure.dpi': 80,\n          'figure.edgecolor': 'white',\n          'figure.facecolor': 'white',\n          'figure.figsize': (6.0, 4.0),\n          'figure.frameon': True,\n          'figure.max_open_warning': 20,\n          'figure.subplot.bottom': 0.125,\n          'figure.subplot.hspace': 0.2,\n          'figure.subplot.left': 0.125,\n          'figure.subplot.right': 0.9,\n          'figure.subplot.top': 0.9,\n          'figure.subplot.wspace': 0.2,\n          'font.cursive': ['Apple Chancery',\n                           'Textile',\n                           'Zapf Chancery',\n                           'Sand',\n                           'cursive'],\n          'font.family': 'sans-serif',\n          'font.fantasy': ['Comic Sans MS',\n                           'Chicago',\n                           'Charcoal',\n                           'ImpactWestern',\n                           'fantasy'],\n          'font.monospace': ['Bitstream Vera Sans Mono',\n                             'DejaVu Sans Mono',\n                             'Andale Mono',\n                             'Nimbus Mono L',\n                             'Courier New',\n                             'Courier',\n                             'Fixed',\n                             'Terminal',\n                             'monospace'],\n          'font.sans-serif': ['Bitstream Vera Sans',\n                              'DejaVu Sans',\n                              'Lucida Grande',\n                              'Verdana',\n                              'Geneva',\n                              'Lucid',\n                              'Arial',\n                              'Helvetica',\n                              'Avant Garde',\n                              'sans-serif'],\n          'font.serif': ['Bitstream Vera Serif',\n                         'DejaVu Serif',\n                         'New Century Schoolbook',\n                         'Century Schoolbook L',\n                         'Utopia',\n                         'ITC Bookman',\n                         'Bookman',\n                         'Nimbus Roman No9 L',\n                         'Times New Roman',\n                         'Times',\n                         'Palatino',\n                         'Charter',\n                         'serif'],\n          'font.size': 10,\n          'font.stretch': 'normal',\n          'font.style': 'normal',\n          'font.variant': 'normal',\n          'font.weight': 'normal',\n          'grid.alpha': 1.0,\n          'grid.color': 'k',\n          'grid.linestyle': ':',\n          'grid.linewidth': 0.5,\n          'image.aspect': 'equal',\n          'image.cmap': 'jet',\n          'image.interpolation': 'bilinear',\n          'image.lut': 256,\n          'image.origin': 'upper',\n          'image.resample': False,\n          'interactive': True,\n          'keymap.all_axes': 'a',\n          'keymap.back': ['left', 'c', 'backspace'],\n          'keymap.forward': ['right', 'v'],\n          'keymap.fullscreen': ('f', 'ctrl+f'),\n          'keymap.grid': 'g',\n          'keymap.home': ['h', 'r', 'home'],\n          'keymap.pan': 'p',\n          'keymap.quit': ('ctrl+w', 'cmd+w'),\n          'keymap.save': ('s', 'ctrl+s'),\n          'keymap.xscale': ['k', 'L'],\n          'keymap.yscale': 'l',\n          'keymap.zoom': 'o',\n          'legend.borderaxespad': 0.5,\n          'legend.borderpad': 0.4,\n          'legend.columnspacing': 2.0,\n          'legend.fancybox': False,\n          'legend.fontsize': 'large',\n          'legend.frameon': True,\n          'legend.handleheight': 0.7,\n          'legend.handlelength': 2.0,\n          'legend.handletextpad': 0.8,\n          'legend.isaxes': True,\n          'legend.labelspacing': 0.5,\n          'legend.loc': 'upper right',\n          'legend.markerscale': 1.0,\n          'legend.numpoints': 2,\n          'legend.scatterpoints': 3,\n          'legend.shadow': False,\n          'lines.antialiased': True,\n          'lines.color': 'b',\n          'lines.dash_capstyle': 'butt',\n          'lines.dash_joinstyle': 'round',\n          'lines.linestyle': '-',\n          'lines.linewidth': 1.0,\n          'lines.marker': 'None',\n          'lines.markeredgewidth': 0.5,\n          'lines.markersize': 6,\n          'lines.solid_capstyle': 'projecting',\n          'lines.solid_joinstyle': 'round',\n          'mathtext.bf': 'serif:bold',\n          'mathtext.cal': 'cursive',\n          'mathtext.default': 'it',\n          'mathtext.fallback_to_cm': True,\n          'mathtext.fontset': 'cm',\n          'mathtext.it': 'serif:italic',\n          'mathtext.rm': 'serif',\n          'mathtext.sf': 'sans\\\\-serif',\n          'mathtext.tt': 'monospace',\n          'patch.antialiased': True,\n          'patch.edgecolor': 'k',\n          'patch.facecolor': 'b',\n          'patch.linewidth': 1.0,\n          'path.effects': [],\n          'path.simplify': True,\n          'path.simplify_threshold': 0.1111111111111111,\n          'path.sketch': None,\n          'path.snap': True,\n          'pdf.compression': 6,\n          'pdf.fonttype': 3,\n          'pdf.inheritcolor': False,\n          'pdf.use14corefonts': False,\n          'pgf.debug': False,\n          'pgf.preamble': [''],\n          'pgf.rcfonts': True,\n          'pgf.texsystem': 'xelatex',\n          'plugins.directory': '.matplotlib_plugins',\n          'polaraxes.grid': True,\n          'ps.distiller.res': 6000,\n          'ps.fonttype': 3,\n          'ps.papersize': 'letter',\n          'ps.useafm': False,\n          'ps.usedistiller': False,\n          'savefig.bbox': None,\n          'savefig.directory': '~',\n          'savefig.dpi': 72,\n          'savefig.edgecolor': 'w',\n          'savefig.extension': 'png',\n          'savefig.facecolor': 'w',\n          'savefig.format': 'png',\n          'savefig.frameon': True,\n          'savefig.jpeg_quality': 95,\n          'savefig.orientation': 'portrait',\n          'savefig.pad_inches': 0.1,\n          'svg.embed_char_paths': True,\n          'svg.fonttype': 'path',\n          'svg.image_inline': True,\n          'svg.image_noscale': False,\n          'text.antialiased': True,\n          'text.color': 'k',\n          'text.dvipnghack': None,\n          'text.hinting': True,\n          'text.hinting_factor': 8,\n          'text.latex.preamble': [''],\n          'text.latex.preview': False,\n          'text.latex.unicode': False,\n          'text.usetex': False,\n          'timezone': 'UTC',\n          'tk.pythoninspect': False,\n          'tk.window_focus': False,\n          'toolbar': 'toolbar2',\n          'verbose.fileo': 'sys.stdout',\n          'verbose.level': 'silent',\n          'webagg.open_in_browser': True,\n          'webagg.port': 8988,\n          'webagg.port_retries': 50,\n          'xtick.color': 'k',\n          'xtick.direction': 'in',\n          'xtick.labelsize': 'medium',\n          'xtick.major.pad': 4,\n          'xtick.major.size': 4,\n          'xtick.major.width': 0.5,\n          'xtick.minor.pad': 4,\n          'xtick.minor.size': 2,\n          'xtick.minor.width': 0.5,\n          'ytick.color': 'k',\n          'ytick.direction': 'in',\n          'ytick.labelsize': 'medium',\n          'ytick.major.pad': 4,\n          'ytick.major.size': 4,\n          'ytick.major.width': 0.5,\n          'ytick.minor.pad': 4,\n          'ytick.minor.size': 2,\n          'ytick.minor.width': 0.5}), 'pcolormesh': <function pcolormesh at 0x3197500>, 'string0': <type 'numpy.string_'>, 'barh': <function barh at 0x3196b18>, '_i130': u'numStocks   = trainOutput.shape[2]\\npred        = np.zeros((310,numStocks))\\nperformance = []\\nfor stock in xrange(numStocks):\\n    numMetrics = len(trainInput[0,0])\\n    X = np.array(deriv[:,stock])\\n    X = X[...,None]\\n\\n    for j in xrange(1,10):\\n        for i in xrange(numMetrics):\\n            thisMetric = trainInput[:,-j,i]\\n            thisMetric = thisMetric[...,None]\\n            X = np.append(X,thisMetric,1)\\n    \\n    y     = normTarget[:,stock]\\n    train = X[:200,:]\\n    test  = X[200:,:]\\n    \\n    train_transformed = rf.fit_transform(train,y)\\n    test_transformed  = rf.transform(test)\\n    \\n    # iterate through the training and test cross validation segments and\\n    #run the classifier on each one, aggregating the results into a list\\n    results = []\\n    for traincv, testcv in cv:\\n        probas = rf.fit(train_transformed[traincv], y[traincv]).predict_proba(train_transformed[testcv])\\n        results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\\n\\n    performance.append(np.array(results).mean())\\n\\n    # generate predictions (making sure to add last observed value back in)\\n    predicted_probs = [x[1] for x in rf.predict_proba(test)]\\n    thisColumn      = np.asarray(predicted_probs)\\n    pred[:,stock]   = thisColumn + lastObserved[200:,stock]\\n\\n    \\n\\n#print out the mean of the mean of the cross-validated results\\nprint \"Results: \" + str( np.array(performance).mean() )\\n\\n    \\n    \\n## Save to file\\nsheet = pred.tolist()  # transform pred from np array to list\\n\\nfirstLine = [\\'O\\' + str(j) for j in xrange(1,len(sheet[0])+1)]\\nfirstLine.insert(0, \\'fileId\\')\\nsheet.insert(0, firstLine)\\nfor i in xrange(1,len(sheet)):\\n    sheet[i].insert(0, str(200+i))\\n\\nnp.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510\\n\\n\\n## Text me when you\\'re done\\nto = \\'lanemcintosh@gmail.com\\' #insert reciever email address (can be same as sender)\\ngmail_user = \\'mcintoshlane@gmail.com\\' #your gmail sender address\\ngmail_pwd = \\'hansolo8chewy\\' #your gmail password\\nsmtpserver = smtplib.SMTP(\"smtp.gmail.com\",587) #the technical stuff\\nsmtpserver.ehlo() #the technical stuff\\nsmtpserver.starttls() #the technical stuff\\nsmtpserver.ehlo #the technical stuff\\nsmtpserver.login(gmail_user, gmail_pwd) #the technical stuff\\nheader = \\'To:\\' + to + \\'\\\\n\\' + \\'From: \\' + gmail_user + \\'\\\\n\\' + \\'Subject:Local Kaggle iPython Notebook \\\\n\\'\\nmsg = header + \\'\\\\n\\' + \\'Your Python Script has now Completed!\\' #The completion message\\nsmtpserver.sendmail(gmail_user, to, msg) #Sending the mail\\nsmtpserver.close() #closing the mailserver connection', '_i104': u'lastObserved[:,stock].shape', '_i133': u'np.savetxt(\\'Data/submission\\'+str(datetime.date.today())+\\'.csv\\', sheet, delimiter=\\',\\', fmt=\"%s\")  #predictions for file 201 to 510', '_53': (array([  2.00000000e+00,   0.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         1.00000000e+00,   2.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         2.00000000e+00,   7.00000000e+00,   3.00000000e+00,\n         4.00000000e+00,   7.00000000e+00,   8.00000000e+00,\n         2.20000000e+01,   2.00000000e+01,   1.30000000e+01,\n         2.40000000e+01,   5.30000000e+01,   5.30000000e+01,\n         8.10000000e+01,   1.17000000e+02,   1.68000000e+02,\n         2.91000000e+02,   5.90000000e+02,   1.25600000e+03,\n         2.75800000e+03,   8.53900000e+03,   1.52450000e+04,\n         6.19300000e+03,   1.99500000e+03,   9.18000000e+02,\n         4.14000000e+02,   2.14000000e+02,   1.21000000e+02,\n         1.11000000e+02,   7.50000000e+01,   6.70000000e+01,\n         3.50000000e+01,   3.70000000e+01,   3.00000000e+01,\n         2.50000000e+01,   2.00000000e+01,   6.00000000e+00,\n         7.00000000e+00,   6.00000000e+00,   9.00000000e+00,\n         4.00000000e+00,   3.00000000e+00,   1.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n         3.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         3.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         1.00000000e+00]), array([-15.55  , -15.1994, -14.8488, -14.4982, -14.1476, -13.797 ,\n       -13.4464, -13.0958, -12.7452, -12.3946, -12.044 , -11.6934,\n       -11.3428, -10.9922, -10.6416, -10.291 ,  -9.9404,  -9.5898,\n        -9.2392,  -8.8886,  -8.538 ,  -8.1874,  -7.8368,  -7.4862,\n        -7.1356,  -6.785 ,  -6.4344,  -6.0838,  -5.7332,  -5.3826,\n        -5.032 ,  -4.6814,  -4.3308,  -3.9802,  -3.6296,  -3.279 ,\n        -2.9284,  -2.5778,  -2.2272,  -1.8766,  -1.526 ,  -1.1754,\n        -0.8248,  -0.4742,  -0.1236,   0.227 ,   0.5776,   0.9282,\n         1.2788,   1.6294,   1.98  ,   2.3306,   2.6812,   3.0318,\n         3.3824,   3.733 ,   4.0836,   4.4342,   4.7848,   5.1354,\n         5.486 ,   5.8366,   6.1872,   6.5378,   6.8884,   7.239 ,\n         7.5896,   7.9402,   8.2908,   8.6414,   8.992 ,   9.3426,\n         9.6932,  10.0438,  10.3944,  10.745 ,  11.0956,  11.4462,\n        11.7968,  12.1474,  12.498 ,  12.8486,  13.1992,  13.5498,\n        13.9004,  14.251 ,  14.6016,  14.9522,  15.3028,  15.6534,\n        16.004 ,  16.3546,  16.7052,  17.0558,  17.4064,  17.757 ,\n        18.1076,  18.4582,  18.8088,  19.1594,  19.51  ]), <a list of 100 Patch objects>), 'sign': <ufunc 'sign'>, '_dh': [u'/home/lane/iPython_notebooks', u'/home/lane/Kaggle/03 Predicting Stock Prices'], 'svd': <function svd at 0x238c9b0>, '_i106': u'pred = predicted_probs + lastObserved[200:,stock]', 'findobj': <function findobj at 0x31942a8>, 'spring': <function spring at 0x31989b0>, 'in1d': <function in1d at 0x236c050>, 'interp': <function interp at 0x236c668>, 'draw': <function draw at 0x3194d70>, 'ginput': <function ginput at 0x3194ed8>, 'rcdefaults': <function rcdefaults at 0x3194758>, 'rfft': <function rfft at 0x23feed8>, 'hypot': <ufunc 'hypot'>, 'logical_and': <ufunc 'logical_and'>, 'rrule': <class 'dateutil.rrule.rrule'>, 'table': <function table at 0x3198140>, 'diagflat': <function diagflat at 0x230d758>, 'float128': <type 'numpy.float128'>, 'matshow': <function matshow at 0x3196410>, 'isfinite': <ufunc 'isfinite'>, '_52': (array([  8.00000000e+00,   9.00000000e+00,   3.80000000e+01,\n         8.42000000e+02,   3.81220000e+04,   5.27000000e+02,\n         3.80000000e+01,   8.00000000e+00,   6.00000000e+00,\n         2.00000000e+00]), array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 10 Patch objects>), 'MINUTELY': 5, 'byte_bounds': <function byte_bounds at 0x2369488>, 'iinfo': <class 'numpy.core.getlimits.iinfo'>, 'kaiser': <function kaiser at 0x236d500>, 'ifftshift': <function ifftshift at 0x24096e0>, '_16': 0.32388299999999998, '_113': <type 'list'>, 'inside_poly': <function inside_poly at 0x2c53848>, 'warnings': <module 'warnings' from '/usr/lib/python2.7/warnings.pyc'>, '_116': -3.8199999999999998, 'cv': sklearn.cross_validation.KFold(n=200, n_folds=25), 'is_closed_polygon': <function is_closed_polygon at 0x2c539b0>, 'polysub': <function polysub at 0x238d0c8>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x2728f10>, 'ifftn': <function ifftn at 0x24092a8>, 'fromfile': <built-in function fromfile>, 'prod': <function prod at 0x21da6e0>, 'nanmax': <function nanmax at 0x236cc80>, 'LinearLocator': <class 'matplotlib.ticker.LinearLocator'>, 'tensorinv': <function tensorinv at 0x238c578>, 'plt': <module 'matplotlib.pyplot' from '/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc'>, 'seterrobj': <built-in function seterrobj>, 'power': <ufunc 'power'>, 'array_split': <function array_split at 0x2374d70>, 'zipf': <built-in method zipf of mtrand.RandomState object at 0x7f399f841690>, 'stem': <function stem at 0x3197aa0>, 'ioff': <function ioff at 0x3194488>, 'step': <function step at 0x3197b18>, 'percentile': <function percentile at 0x236d6e0>, 'hsv': <function hsv at 0x31987d0>, 'axhspan': <function axhspan at 0x3196938>, 'FPE_DIVIDEBYZERO': 1, '__name__': '__main__', 'subtract': <ufunc 'subtract'>, 'optimize': <module 'scipy.optimize' from '/usr/local/lib/python2.7/dist-packages/scipy/optimize/__init__.pyc'>, '_': -3.8199999999999998, 'mx2num': <function mx2num at 0x307fb18>, 'fft': <module 'numpy.fft' from '/usr/local/lib/python2.7/dist-packages/numpy/fft/__init__.pyc'>, 'frombuffer': <built-in function frombuffer>, 'iscomplex': <function iscomplex at 0x2301758>, 'fill_betweenx': <function fill_betweenx at 0x3197140>, 'multivariate_normal': <built-in method multivariate_normal of mtrand.RandomState object at 0x7f399f841690>, 'add_docstring': <built-in function add_docstring>, 'argsort': <function argsort at 0x21d1aa0>, '_38': ([array([   0.,    0.,    0.,   11.,  179.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  189.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  189.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  194.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  188.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  191.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   12.,  181.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  193.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   23.,  158.,   11.,    2.,    0.,    2.,    0.]), array([   2.,    0.,    2.,   16.,  159.,   19.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  196.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  187.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  192.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  194.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  184.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  192.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    3.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   1.,    0.,    2.,   28.,  148.,   17.,    3.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  186.,    9.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  184.,    2.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  177.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,    7.,  186.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   20.,  168.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    2.,    0.,   15.,  167.,   16.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    0.,   14.,  167.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,   16.,  165.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   14.,  182.,    2.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    3.,   26.,  153.,   16.,    0.,    0.,    2.,    0.]), array([   3.,    1.,    7.,   46.,  102.,   26.,    8.,    3.,    2.,    2.]), array([   0.,    2.,    0.,   12.,  176.,   10.,    0.,    0.,    0.,    0.]), array([   2.,    0.,    1.,   20.,  155.,   18.,    4.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  181.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  184.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  189.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  182.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   11.,  182.,    6.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  184.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   22.,  166.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  195.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    3.,  193.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  190.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  196.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   29.,  140.,   21.,    4.,    2.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  190.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    3.,   31.,  144.,   17.,    3.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  193.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  188.,    4.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.])], array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 198 Lists of Patches objects>), '_19': 0.32388299999999998, 'fmin': <ufunc 'fmin'>, 'loadtxt': <function loadtxt at 0x23fb398>, '_31': (200, 198), '_30': (510, 198), '_33': (200, 198), '_18': 0.32388299999999998, '_35': [<matplotlib.lines.Line2D object at 0x3c0f110>], 'bytes_': <type 'numpy.string_'>, 'ones_like': <function ones_like at 0x21c2488>, '_36': [<matplotlib.lines.Line2D object at 0x3df1610>], 'ScalarFormatter': <class 'matplotlib.ticker.ScalarFormatter'>, 'is_busday': <built-in function is_busday>, 'arcsinh': <ufunc 'arcsinh'>, 'CLIP': 0, 'exp_safe': <function exp_safe at 0x2c51cf8>, '_i57': u\"fig = gcf()\\nfig.set_size_inches(16,4)\\n\\nyoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", '_i56': u\"yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True,histtype='stepfilled')\", '_i55': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100,log=True)', '_i54': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\ny = hist(yoda,100)', '_i53': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda,100)', '_i52': u'yoda = normTarget.reshape((normTarget.shape[0]*normTarget.shape[1],1))\\nhist(yoda)', '__builtin__': <module '__builtin__' (built-in)>, 'dataset': array([[ 0.      ,  0.      ,  0.      , ...,  1.10484 ,  0.054283,\n         0.094868],\n       [-6.56    , -0.36    ,  0.04    , ...,  1.356407,  1.782152,\n         1.461476],\n       [-5.8     , -0.36    ,  0.04    , ...,  1.523808,  2.131682,\n         1.812402],\n       ..., \n       [-8.24    , -0.79    ,  0.04    , ...,  0.575108,  0.300311,\n         0.310644],\n       [-8.3     , -0.78    ,  0.04    , ...,  0.569777,  0.276743,\n         0.284429],\n       [-7.99    , -0.78    ,  0.01    , ...,  0.557479,  0.214942,\n         0.323883]]), 'annotate': <function annotate at 0x3198230>, '_i80': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201,:]\\ntest  = X[201:,:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'normalize': <function Normalize at 0x29e6b18>, 'intp': <type 'numpy.int64'>, 'standard_cauchy': <built-in method standard_cauchy of mtrand.RandomState object at 0x7f399f841690>, '_i82': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\n\\n# try for a single stock\\nstock = 0\\nX     = deriv[:,stock]\\ny     = normTarget[:,stock]\\ntrain = X[:201]\\ntest  = X[201:]\\n\\n#train            = np.zeros((510,55,244+198))\\n#train[:,:,0:198] = trainOutput\\n#train[:,:,198:]  = trainInput', 'unpackbits': <built-in function unpackbits>, 'HOURLY': 4, 'arrow': <function arrow at 0x3196848>, 'delete': <function delete at 0x236d938>, 'Infinity': inf, 'log': <ufunc 'log'>, 'numMetrics': 244, 'cdouble': <type 'numpy.complex128'>, 'complex128': <type 'numpy.complex128'>, 'tick_params': <function tick_params at 0x3198398>, 'switch_backend': <function switch_backend at 0x3194320>, 'round_': <function round_ at 0x21da9b0>, 'broadcast_arrays': <function broadcast_arrays at 0x2377410>, 'inner': <built-in function inner>, 'var': <function var at 0x21dab18>, 'c_': <numpy.lib.index_tricks.CClass object at 0x236f9d0>, 'slopes': <function slopes at 0x2c53758>, '_i87': u'train.shape', 'log10': <ufunc 'log10'>, 'thisMetric': array([[ 0.142166],\n       [ 0.272029],\n       [ 0.062272],\n       [ 0.229153],\n       [ 0.042557],\n       [ 0.33731 ],\n       [ 0.310483],\n       [ 0.133083],\n       [ 0.06245 ],\n       [ 0.110805],\n       [ 0.132204],\n       [ 0.169738],\n       [ 0.063246],\n       [ 0.260853],\n       [ 0.136382],\n       [ 0.095102],\n       [ 0.133041],\n       [ 0.175214],\n       [ 0.226495],\n       [ 0.153984],\n       [ 0.188709],\n       [ 0.045583],\n       [ 0.530984],\n       [ 0.060919],\n       [ 0.621289],\n       [ 0.048762],\n       [ 0.106771],\n       [ 0.088944],\n       [ 0.126271],\n       [ 0.07356 ],\n       [ 0.289156],\n       [ 0.109545],\n       [ 0.133791],\n       [ 0.127845],\n       [ 0.042164],\n       [ 0.206586],\n       [ 0.092436],\n       [ 0.125477],\n       [ 0.101871],\n       [ 0.1761  ],\n       [ 0.196723],\n       [ 0.097354],\n       [ 0.2     ],\n       [ 0.061192],\n       [ 0.096839],\n       [ 0.1     ],\n       [ 0.142867],\n       [ 0.21349 ],\n       [ 0.06    ],\n       [ 0.205047],\n       [ 0.251794],\n       [ 0.066332],\n       [ 0.078811],\n       [ 0.32426 ],\n       [ 0.034641],\n       [ 0.056372],\n       [ 0.314925],\n       [ 0.150481],\n       [ 0.109545],\n       [ 0.173429],\n       [ 0.467737],\n       [ 0.200942],\n       [ 0.135565],\n       [ 0.138363],\n       [ 0.166966],\n       [ 0.557494],\n       [ 0.292746],\n       [ 0.188267],\n       [ 0.129615],\n       [ 0.294524],\n       [ 0.057831],\n       [ 0.307571],\n       [ 0.476667],\n       [ 0.04    ],\n       [ 0.318974],\n       [ 0.061734],\n       [ 0.25307 ],\n       [ 0.34    ],\n       [ 0.239397],\n       [ 0.268701],\n       [ 0.291681],\n       [ 0.19    ],\n       [ 0.120324],\n       [ 0.146553],\n       [ 0.421189],\n       [ 0.25399 ],\n       [ 0.05831 ],\n       [ 0.119629],\n       [ 0.336452],\n       [ 0.073106],\n       [ 0.204885],\n       [ 0.11225 ],\n       [ 0.153768],\n       [ 0.181659],\n       [ 0.248149],\n       [ 0.371319],\n       [ 0.79813 ],\n       [ 0.303278],\n       [ 0.289271],\n       [ 0.513561],\n       [ 0.287653],\n       [ 0.106301],\n       [ 0.608997],\n       [ 0.136545],\n       [ 0.209152],\n       [ 0.304485],\n       [ 0.186934],\n       [ 0.319026],\n       [ 0.076449],\n       [ 0.109595],\n       [ 0.11949 ],\n       [ 0.15268 ],\n       [ 0.324157],\n       [ 0.679485],\n       [ 0.158254],\n       [ 0.179846],\n       [ 0.099722],\n       [ 0.034641],\n       [ 0.104297],\n       [ 0.075572],\n       [ 0.067905],\n       [ 0.564427],\n       [ 0.204559],\n       [ 0.153442],\n       [ 0.088192],\n       [ 0.068638],\n       [ 0.108525],\n       [ 0.14345 ],\n       [ 0.19105 ],\n       [ 0.164621],\n       [ 0.141067],\n       [ 0.104297],\n       [ 0.114066],\n       [ 0.172755],\n       [ 0.308887],\n       [ 0.067905],\n       [ 0.100222],\n       [ 0.200776],\n       [ 0.134164],\n       [ 0.122656],\n       [ 0.074833],\n       [ 0.249087],\n       [ 0.074012],\n       [ 0.119164],\n       [ 0.215587],\n       [ 0.424513],\n       [ 0.096437],\n       [ 0.103494],\n       [ 0.232809],\n       [ 0.052705],\n       [ 0.103441],\n       [ 0.189209],\n       [ 0.12    ],\n       [ 0.208113],\n       [ 1.304318],\n       [ 0.034641],\n       [ 0.340506],\n       [ 0.03    ],\n       [ 0.097011],\n       [ 0.216974],\n       [ 0.585928],\n       [ 0.231948],\n       [ 0.141578],\n       [ 0.089691],\n       [ 0.20445 ],\n       [ 0.125344],\n       [ 0.07746 ],\n       [ 0.083533],\n       [ 0.103655],\n       [ 0.052915],\n       [ 0.314713],\n       [ 0.405476],\n       [ 0.11879 ],\n       [ 0.283333],\n       [ 0.471181],\n       [ 0.228789],\n       [ 0.077746],\n       [ 0.074162],\n       [ 0.161245],\n       [ 0.212315],\n       [ 0.202731],\n       [ 0.131149],\n       [ 0.2319  ],\n       [ 0.244154],\n       [ 0.200693],\n       [ 0.453995],\n       [ 0.1206  ],\n       [ 0.220177],\n       [ 0.153623],\n       [ 0.270267],\n       [ 0.121655],\n       [ 0.074907],\n       [ 0.206263],\n       [ 0.157198],\n       [ 0.167929],\n       [ 0.111355],\n       [ 0.275035],\n       [ 0.126095],\n       [ 0.195192],\n       [ 0.113186],\n       [ 0.208753],\n       [ 0.536563],\n       [ 0.110905],\n       [ 0.083732],\n       [ 0.235891],\n       [ 0.131951],\n       [ 0.191949],\n       [ 0.129615],\n       [ 0.139443],\n       [ 0.261874],\n       [ 0.139084],\n       [ 0.321559],\n       [ 0.187113],\n       [ 0.090615],\n       [ 0.066165],\n       [ 0.067165],\n       [ 0.155385],\n       [ 0.119629],\n       [ 0.220454],\n       [ 0.17845 ],\n       [ 0.135195],\n       [ 0.30921 ],\n       [ 0.20955 ],\n       [ 0.086667],\n       [ 0.202731],\n       [ 0.072801],\n       [ 0.086859],\n       [ 0.183697],\n       [ 0.25738 ],\n       [ 0.202731],\n       [ 0.279106],\n       [ 0.114455],\n       [ 0.960422],\n       [ 0.151364],\n       [ 0.175531],\n       [ 0.122066],\n       [ 0.239049],\n       [ 0.150481],\n       [ 0.167332],\n       [ 0.36457 ],\n       [ 0.225389],\n       [ 0.279364],\n       [ 0.142867],\n       [ 0.020276],\n       [ 0.090615],\n       [ 0.426146],\n       [ 0.150591],\n       [ 0.296891],\n       [ 0.04    ],\n       [ 0.203415],\n       [ 0.25399 ],\n       [ 0.122384],\n       [ 0.112151],\n       [ 0.051424],\n       [ 0.08    ],\n       [ 0.380526],\n       [ 0.381838],\n       [ 0.133458],\n       [ 0.041231],\n       [ 0.338083],\n       [ 0.133583],\n       [ 0.215407],\n       [ 0.134454],\n       [ 0.109138],\n       [ 0.351568],\n       [ 0.263333],\n       [ 0.129529],\n       [ 0.098545],\n       [ 0.684471],\n       [ 0.348712],\n       [ 0.047958],\n       [ 0.298068],\n       [ 0.065405],\n       [ 0.364692],\n       [ 0.054263],\n       [ 0.301625],\n       [ 0.147309],\n       [ 0.605402],\n       [ 0.074162],\n       [ 0.129271],\n       [ 0.21    ],\n       [ 0.389102],\n       [ 0.304649],\n       [ 0.199109],\n       [ 0.08775 ],\n       [ 0.074012],\n       [ 0.25865 ],\n       [ 0.155885],\n       [ 0.156667],\n       [ 0.228206],\n       [ 0.099219],\n       [ 0.108679],\n       [ 0.08    ],\n       [ 0.124544],\n       [ 0.138724],\n       [ 0.104403],\n       [ 0.047958],\n       [ 0.264008],\n       [ 0.363517],\n       [ 0.558341],\n       [ 0.119629],\n       [ 0.106301],\n       [ 0.147121],\n       [ 0.124499],\n       [ 0.216795],\n       [ 0.145297],\n       [ 0.11348 ],\n       [ 0.311929],\n       [ 0.332265],\n       [ 0.244495],\n       [ 1.289358],\n       [ 0.079652],\n       [ 0.847526],\n       [ 0.108218],\n       [ 0.208992],\n       [ 0.393206],\n       [ 0.099051],\n       [ 0.050772],\n       [ 0.199444],\n       [ 0.093274],\n       [ 0.06    ],\n       [ 0.117898],\n       [ 0.380716],\n       [ 0.107703],\n       [ 0.080069],\n       [ 0.146287],\n       [ 0.218174],\n       [ 0.194165],\n       [ 0.166567],\n       [ 0.063596],\n       [ 0.184662],\n       [ 0.13784 ],\n       [ 0.618663],\n       [ 0.130384],\n       [ 0.164249],\n       [ 0.652687],\n       [ 0.693253],\n       [ 0.086667],\n       [ 0.317245],\n       [ 0.144837],\n       [ 0.016667],\n       [ 0.400222],\n       [ 0.079652],\n       [ 0.084327],\n       [ 0.156241],\n       [ 0.099051],\n       [ 0.193592],\n       [ 0.15748 ],\n       [ 0.152571],\n       [ 0.105251],\n       [ 0.220025],\n       [ 0.371349],\n       [ 0.053955],\n       [ 0.556996],\n       [ 0.149926],\n       [ 0.071414],\n       [ 0.932011],\n       [ 0.108372],\n       [ 0.36653 ],\n       [ 0.311359],\n       [ 0.199444],\n       [ 0.284917],\n       [ 0.066332],\n       [ 0.138924],\n       [ 0.091165],\n       [ 0.142127],\n       [ 0.219949],\n       [ 0.1294  ],\n       [ 0.30249 ],\n       [ 0.145258],\n       [ 0.06888 ],\n       [ 0.371139],\n       [ 0.251219],\n       [ 0.162207],\n       [ 0.124141],\n       [ 0.291738],\n       [ 0.35201 ],\n       [ 0.08124 ],\n       [ 0.174865],\n       [ 2.412726],\n       [ 0.063857],\n       [ 0.15592 ],\n       [ 0.261236],\n       [ 0.108628],\n       [ 0.138203],\n       [ 0.127671],\n       [ 0.345897],\n       [ 0.162788],\n       [ 0.271477],\n       [ 0.06888 ],\n       [ 0.148324],\n       [ 0.451934],\n       [ 0.036667],\n       [ 0.188532],\n       [ 0.093808],\n       [ 0.137113],\n       [ 0.509117],\n       [ 0.176068],\n       [ 0.319913],\n       [ 0.315718],\n       [ 0.244336],\n       [ 0.10198 ],\n       [ 0.182757],\n       [ 0.037417],\n       [ 0.07356 ],\n       [ 0.412432],\n       [ 0.064893],\n       [ 0.175784],\n       [ 0.194165],\n       [ 0.232904],\n       [ 0.044721],\n       [ 0.065574],\n       [ 0.146287],\n       [ 0.062004],\n       [ 0.176572],\n       [ 0.476527],\n       [ 0.238118],\n       [ 0.065574],\n       [ 0.11893 ],\n       [ 0.247745],\n       [ 0.172337],\n       [ 0.101379],\n       [ 0.059815],\n       [ 0.285326],\n       [ 0.091348],\n       [ 0.257833],\n       [ 0.546626],\n       [ 0.117379],\n       [ 0.26327 ],\n       [ 0.051099],\n       [ 0.102956],\n       [ 0.173141],\n       [ 0.117237],\n       [ 0.185472],\n       [ 0.171205],\n       [ 0.060828],\n       [ 0.094868],\n       [ 0.171205],\n       [ 0.27258 ],\n       [ 0.098995],\n       [ 0.854868],\n       [ 0.08    ],\n       [ 0.08705 ],\n       [ 0.12252 ],\n       [ 0.344384],\n       [ 0.353475],\n       [ 0.178263],\n       [ 0.10198 ],\n       [ 0.102198],\n       [ 0.174356],\n       [ 0.35819 ],\n       [ 0.136382],\n       [ 0.056075],\n       [ 0.127671],\n       [ 0.081854],\n       [ 0.109087],\n       [ 0.223557],\n       [ 0.325645],\n       [ 0.563777],\n       [ 0.140633],\n       [ 0.138564],\n       [ 0.954713],\n       [ 0.061644],\n       [ 0.095917],\n       [ 0.052915],\n       [ 0.495861],\n       [ 0.154416],\n       [ 0.095801],\n       [ 0.250422],\n       [ 0.031798],\n       [ 0.197737],\n       [ 0.317175],\n       [ 0.161898],\n       [ 0.038006],\n       [ 0.321472],\n       [ 0.072648],\n       [ 0.119907],\n       [ 0.118322],\n       [ 0.076012],\n       [ 0.236854],\n       [ 0.143798],\n       [ 0.164857],\n       [ 0.099387],\n       [ 0.021858],\n       [ 0.051424],\n       [ 0.291624],\n       [ 0.190029],\n       [ 0.133832],\n       [ 0.245515],\n       [ 0.273699],\n       [ 0.176289],\n       [ 0.200499],\n       [ 0.535859],\n       [ 0.159931],\n       [ 0.193075],\n       [ 0.285034],\n       [ 0.110454],\n       [ 0.194879],\n       [ 0.150997],\n       [ 0.043333],\n       [ 0.060645],\n       [ 0.150923],\n       [ 0.439634],\n       [ 0.230024],\n       [ 0.120046],\n       [ 0.103494],\n       [ 0.281267],\n       [ 0.083333],\n       [ 0.062539],\n       [ 0.452769]]), 'hypergeometric': <built-in method hypergeometric of mtrand.RandomState object at 0x7f399f841690>, 'uintp': <type 'numpy.uint64'>, 'unwrap': <function unwrap at 0x236c758>, 'NullLocator': <class 'matplotlib.ticker.NullLocator'>, '_i68': u'normTarget.shape', 'triangular': <built-in method triangular of mtrand.RandomState object at 0x7f399f841690>, 'noncentral_chisquare': <built-in method noncentral_chisquare of mtrand.RandomState object at 0x7f399f841690>, 'histogram': <function histogram at 0x236c230>, 'msg': 'To:lanemcintosh@gmail.com\\nFrom: mcintoshlane@gmail.com\\nSubject:Kaggle iPython Notebook \\n\\nYour Python Script has now Completed!', 'issubdtype': <function issubdtype at 0x21bf050>, 'maximum_sctype': <function maximum_sctype at 0x21b8cf8>, 'flexible': <type 'numpy.flexible'>, 'movavg': <function movavg at 0x2c51938>, 'squeeze': <function squeeze at 0x21d1cf8>, 'int8': <type 'numpy.int8'>, 'cholesky': <function cholesky at 0x238c668>, 'info': <function info at 0x23696e0>, 'seterr': <function seterr at 0x21dd0c8>, 'argmin': <function argmin at 0x21d1b90>, 'fignum_exists': <function has_fignum at 0x2cf9938>, 'genfromtxt': <function genfromtxt at 0x23fb500>, 'rec_append_fields': <function rec_append_fields at 0x2c52488>, 'j': 9, 'maximum': <ufunc 'maximum'>, '_23': (510, 55, 198), 'record': <class 'numpy.core.records.record'>, 'obj2sctype': <function obj2sctype at 0x21b8e60>, '_61': <matplotlib.text.Text object at 0x8c45410>, 'clongdouble': <type 'numpy.complex256'>, 'sum': <function sum at 0x21da140>, 'isrealobj': <function isrealobj at 0x23018c0>, 'log1p': <ufunc 'log1p'>, '_oh': {8: 510, 10: 200, 12: (510, 55, 244), 13: (510, 55, 198), 16: 0.32388299999999998, 18: 0.32388299999999998, 19: 0.32388299999999998, 21: (510, 55, 442), 23: (510, 55, 198), 24: 55, 25: (200, 198), 26: (200, 198), 27: (510, 55, 244), 30: (510, 198), 31: (200, 198), 33: (200, 198), 34: (200, 198), 35: [<matplotlib.lines.Line2D object at 0x3c0f110>], 36: [<matplotlib.lines.Line2D object at 0x3df1610>], 37: (array([   3.,   11.,   42.,  112.,   26.,    4.,    0.,    0.,    0.,    2.]), array([-2.12 , -1.478, -0.836, -0.194,  0.448,  1.09 ,  1.732,  2.374,\n        3.016,  3.658,  4.3  ]), <a list of 10 Patch objects>), 38: ([array([   0.,    0.,    0.,   11.,  179.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  189.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  197.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  189.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  194.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  188.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  191.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   12.,  181.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  193.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   23.,  158.,   11.,    2.,    0.,    2.,    0.]), array([   2.,    0.,    2.,   16.,  159.,   19.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  196.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  187.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  194.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  192.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  194.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  187.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  184.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  192.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  198.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  198.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  192.,    3.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   1.,    0.,    2.,   28.,  148.,   17.,    3.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  199.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    4.,  186.,    9.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  184.,    2.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    1.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   13.,  177.,   10.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,    7.,  186.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   20.,  168.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    2.,    0.,   15.,  167.,   16.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    0.,   14.,  167.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    2.,   16.,  165.,   16.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   14.,  182.,    2.,    2.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    3.,   26.,  153.,   16.,    0.,    0.,    2.,    0.]), array([   3.,    1.,    7.,   46.,  102.,   26.,    8.,    3.,    2.,    2.]), array([   0.,    2.,    0.,   12.,  176.,   10.,    0.,    0.,    0.,    0.]), array([   2.,    0.,    1.,   20.,  155.,   18.,    4.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   12.,  181.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  192.,    5.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  184.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  189.,    6.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   10.,  182.,    8.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,   11.,  182.,    6.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    9.,  184.,    7.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,   22.,  166.,    9.,    1.,    1.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  196.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    4.,  195.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    5.,  195.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  197.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    3.,  193.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    1.,    5.,  190.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  196.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  199.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    4.,   29.,  140.,   21.,    4.,    2.,    0.,    0.]), array([   0.,    0.,    0.,    8.,  190.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    2.,    3.,   31.,  144.,   17.,    3.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  194.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  193.,    4.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    0.,  200.,    0.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  197.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  198.,    1.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    2.,  196.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    1.,  197.,    2.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    6.,  191.,    3.,    0.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    7.,  188.,    4.,    1.,    0.,    0.,    0.]), array([   0.,    0.,    0.,    3.,  195.,    2.,    0.,    0.,    0.,    0.])], array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 198 Lists of Patches objects>), 44: (200, 198), 52: (array([  8.00000000e+00,   9.00000000e+00,   3.80000000e+01,\n         8.42000000e+02,   3.81220000e+04,   5.27000000e+02,\n         3.80000000e+01,   8.00000000e+00,   6.00000000e+00,\n         2.00000000e+00]), array([-15.55 , -12.044,  -8.538,  -5.032,  -1.526,   1.98 ,   5.486,\n         8.992,  12.498,  16.004,  19.51 ]), <a list of 10 Patch objects>), 53: (array([  2.00000000e+00,   0.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         1.00000000e+00,   2.00000000e+00,   2.00000000e+00,\n         0.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         2.00000000e+00,   7.00000000e+00,   3.00000000e+00,\n         4.00000000e+00,   7.00000000e+00,   8.00000000e+00,\n         2.20000000e+01,   2.00000000e+01,   1.30000000e+01,\n         2.40000000e+01,   5.30000000e+01,   5.30000000e+01,\n         8.10000000e+01,   1.17000000e+02,   1.68000000e+02,\n         2.91000000e+02,   5.90000000e+02,   1.25600000e+03,\n         2.75800000e+03,   8.53900000e+03,   1.52450000e+04,\n         6.19300000e+03,   1.99500000e+03,   9.18000000e+02,\n         4.14000000e+02,   2.14000000e+02,   1.21000000e+02,\n         1.11000000e+02,   7.50000000e+01,   6.70000000e+01,\n         3.50000000e+01,   3.70000000e+01,   3.00000000e+01,\n         2.50000000e+01,   2.00000000e+01,   6.00000000e+00,\n         7.00000000e+00,   6.00000000e+00,   9.00000000e+00,\n         4.00000000e+00,   3.00000000e+00,   1.00000000e+00,\n         2.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n         3.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         3.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n         1.00000000e+00]), array([-15.55  , -15.1994, -14.8488, -14.4982, -14.1476, -13.797 ,\n       -13.4464, -13.0958, -12.7452, -12.3946, -12.044 , -11.6934,\n       -11.3428, -10.9922, -10.6416, -10.291 ,  -9.9404,  -9.5898,\n        -9.2392,  -8.8886,  -8.538 ,  -8.1874,  -7.8368,  -7.4862,\n        -7.1356,  -6.785 ,  -6.4344,  -6.0838,  -5.7332,  -5.3826,\n        -5.032 ,  -4.6814,  -4.3308,  -3.9802,  -3.6296,  -3.279 ,\n        -2.9284,  -2.5778,  -2.2272,  -1.8766,  -1.526 ,  -1.1754,\n        -0.8248,  -0.4742,  -0.1236,   0.227 ,   0.5776,   0.9282,\n         1.2788,   1.6294,   1.98  ,   2.3306,   2.6812,   3.0318,\n         3.3824,   3.733 ,   4.0836,   4.4342,   4.7848,   5.1354,\n         5.486 ,   5.8366,   6.1872,   6.5378,   6.8884,   7.239 ,\n         7.5896,   7.9402,   8.2908,   8.6414,   8.992 ,   9.3426,\n         9.6932,  10.0438,  10.3944,  10.745 ,  11.0956,  11.4462,\n        11.7968,  12.1474,  12.498 ,  12.8486,  13.1992,  13.5498,\n        13.9004,  14.251 ,  14.6016,  14.9522,  15.3028,  15.6534,\n        16.004 ,  16.3546,  16.7052,  17.0558,  17.4064,  17.757 ,\n        18.1076,  18.4582,  18.8088,  19.1594,  19.51  ]), <a list of 100 Patch objects>), 61: <matplotlib.text.Text object at 0x8c45410>, 63: <matplotlib.text.Text object at 0x8d13e90>, 64: <matplotlib.text.Text object at 0x9b88ad0>, 65: <matplotlib.text.Text object at 0x92e02d0>, 66: (510, 55, 198), 67: (510, 198), 68: (200, 198), 70: 200, 71: sklearn.cross_validation.KFold(n=200, n_folds=63), 74: array([False, False, False, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True], dtype=bool), 75: (200,), 76: (200,), 77: array([[[ 0.      ,  0.      ,  0.      , ...,  0.160672,  0.054283,\n          0.060093],\n        [ 1.61    ,  0.12    ,  0.12    , ...,  0.246306,  0.448241,\n          0.377197],\n        [ 1.12    ,  0.31    ,  0.12    , ...,  0.281271,  0.484713,\n          0.431599],\n        ..., \n        [ 0.9     ,  0.19    ,  0.07    , ...,  0.119027,  0.084617,\n          0.074685],\n        [ 0.87    ,  0.22    ,  0.08    , ...,  0.122028,  0.058538,\n          0.080691],\n        [ 0.83    ,  0.25    ,  0.08    , ...,  0.125018,  0.043205,\n          0.088569]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.405808,  0.188892,\n          0.209284],\n        [ 0.95    , -0.18    ,  0.15    , ...,  0.42738 ,  0.348119,\n          0.34322 ],\n        [ 1.04    , -0.18    ,  0.15    , ...,  0.463135,  0.439758,\n          0.449271],\n        ..., \n        [ 0.87    , -0.01    ,  0.1     , ...,  0.447247,  0.132313,\n          0.208433],\n        [ 0.83    ,  0.      ,  0.05    , ...,  0.445714,  0.153232,\n          0.138243],\n        [ 0.97    , -0.05    ,  0.05    , ...,  0.445714,  0.155649,\n          0.138243]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.934708,  0.084538,\n          0.154596],\n        [ 2.75    ,  0.25    ,  0.      , ...,  0.859673,  0.675959,\n          0.553122],\n        [ 2.22    ,  0.24    ,  0.      , ...,  0.800801,  0.754047,\n          0.652951],\n        ..., \n        [ 6.09    , -0.13    ,  0.      , ...,  0.717239,  0.111535,\n          0.55109 ],\n        [ 6.22    , -0.13    ,  0.      , ...,  0.712795,  0.116218,\n          0.388987],\n        [ 5.75    , -0.17    ,  0.      , ...,  0.715292,  0.152665,\n          0.252609]],\n\n       ..., \n       [[ 0.      ,  0.      ,  0.      , ...,  0.199729,  0.051769,\n          0.117898],\n        [-3.29    ,  0.04    ,  0.24    , ...,  0.349317,  0.77501 ,\n          0.659621],\n        [-3.53    ,  0.06    ,  0.37    , ...,  0.460716,  1.013778,\n          0.894228],\n        ..., \n        [-2.21    ,  1.33    ,  0.5     , ...,  0.221407,  0.051251,\n          0.160312],\n        [-2.25    ,  1.27    ,  0.54    , ...,  0.203557,  0.054283,\n          0.14087 ],\n        [-2.42    ,  1.27    ,  0.53    , ...,  0.185629,  0.059889,\n          0.054874]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.52827 ,  0.128219,\n          0.104881],\n        [ 0.17    , -0.06    ,  0.      , ...,  0.520413,  0.180665,\n          0.150702],\n        [ 0.59    , -0.12    , -0.06    , ...,  0.520859,  0.288167,\n          0.243676],\n        ..., \n        [ 0.97    , -0.24    , -0.08    , ...,  0.296868,  0.023381,\n          0.264344],\n        [ 0.82    , -0.24    , -0.08    , ...,  0.297405,  0.037417,\n          0.211529],\n        [ 0.97    , -0.18    , -0.04    , ...,  0.298542,  0.037238,\n          0.132077]],\n\n       [[ 0.      ,  0.      ,  0.      , ...,  0.31634 ,  0.082624,\n          0.108628],\n        [-0.71    ,  0.26    ,  0.74    , ...,  0.307045,  0.20775 ,\n          0.205129],\n        [-1.06    ,  0.19    ,  0.74    , ...,  0.31471 ,  0.277897,\n          0.274672],\n        ..., \n        [-1.04    , -0.08    ,  0.12    , ...,  0.184709,  0.06532 ,  0.16    ],\n        [-0.95    , -0.19    ,  0.12    , ...,  0.178122,  0.028284,\n          0.152315],\n        [-0.84    , -0.18    ,  0.12    , ...,  0.173413,  0.054283,\n          0.123063]]]), 78: (510, 55, 442), 81: (510,), 83: (201,), 84: (309,), 85: (201,), 87: (200,), 88: (310,), 89: (200,), 90: (200,), 92: (200,), 93: (310,), 95: (510, 1), 102: 310, 104: (510,), 108: <matplotlib.text.Text object at 0x918f1d0>, 109: 198, 111: <matplotlib.text.Text object at 0x9894b90>, 113: <type 'list'>, 114: (310,), 116: -3.8199999999999998}, 'flatten': <function flatten at 0x2992b90>, 'gmail_pwd': 'hansolo8chewy', 'YEARLY': 0, 'digitize': <built-in function digitize>, 'clongfloat': <type 'numpy.complex256'>, 'ylim': <function ylim at 0x3195b90>, 'yscale': <function yscale at 0x3195c80>, 'inv': <function inv at 0x238c5f0>, 'ediff1d': <function ediff1d at 0x2369050>, 'pie': <function pie at 0x3197578>, '_i45': u'yoda = normTarget.reshape((normTarget.shape[0]+normTarget.shape[1]-1,0))', 'char': <module 'numpy.core.defchararray' from '/usr/local/lib/python2.7/dist-packages/numpy/core/defchararray.pyc'>, 'single': <type 'numpy.float32'>, 'isposinf': <function isposinf at 0x2301500>, 'set_cmap': <function set_cmap at 0x3196398>, 'ScalarType': (<type 'int'>, <type 'float'>, <type 'complex'>, <type 'long'>, <type 'bool'>, <type 'str'>, <type 'unicode'>, <type 'buffer'>, <type 'numpy.float16'>, <type 'numpy.string_'>, <type 'numpy.float128'>, <type 'numpy.uint64'>, <type 'numpy.int16'>, <type 'numpy.timedelta64'>, <type 'numpy.object_'>, <type 'numpy.float64'>, <type 'numpy.int64'>, <type 'numpy.uint8'>, <type 'numpy.datetime64'>, <type 'numpy.complex256'>, <type 'numpy.float32'>, <type 'numpy.uint32'>, <type 'numpy.int8'>, <type 'numpy.void'>, <type 'numpy.complex128'>, <type 'numpy.uint64'>, <type 'numpy.int32'>, <type 'numpy.bool_'>, <type 'numpy.unicode_'>, <type 'numpy.complex64'>, <type 'numpy.int64'>, <type 'numpy.uint16'>), 'noncentral_f': <built-in method noncentral_f of mtrand.RandomState object at 0x7f399f841690>, 'triu': <function triu at 0x230d8c0>, 'inf': inf, 'fill': <function fill at 0x3197050>, 'expand_dims': <function expand_dims at 0x2374b90>, 'pareto': <built-in method pareto of mtrand.RandomState object at 0x7f399f841690>, 'logspace': <function logspace at 0x2270de8>, 'floor': <ufunc 'floor'>, 'polyadd': <function polyadd at 0x238d050>, 'TU': TU, 'nan': nan, 'modf': <ufunc 'modf'>, 'emath': <module 'numpy.lib.scimath' from '/usr/local/lib/python2.7/dist-packages/numpy/lib/scimath.pyc'>, 'arctan': <ufunc 'arctan'>, 'bmat': <function bmat at 0x2373cf8>, 'Slider': <class 'matplotlib.widgets.Slider'>, 'prism': <function prism at 0x3198938>, 'isclose': <function isclose at 0x21dbed8>, 'ERR_DEFAULT': 0, 'TH': TH, 'xscale': <function xscale at 0x3195c08>, '_i109': u'trainOutput.shape[2]', 'register_cmap': <function register_cmap at 0x2b80e60>, 'roll': <function roll at 0x21c2b90>, 'figsize': <function figsize at 0x1de18c0>, '_i70': u'len(target)', 'compare_chararrays': <built-in function compare_chararrays>, 'vsplit': <function vsplit at 0x2374ed8>, 'real_if_close': <function real_if_close at 0x2301a28>, 'repeat': <function repeat at 0x21d1848>, 'hamming': <function hamming at 0x236d2a8>, 'ALLOW_THREADS': 1, '_i66': u'trainOutput.shape', 'isInput': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True], '_12': (510, 55, 244), 'errorbar': <function errorbar at 0x3196ed8>, 'ravel_multi_index': <built-in function ravel_multi_index>, '_i67': u'lastObserved = trainOutput[:,-1,:]\\nderiv        = trainOutput[:,-1,:] - trainOutput[:,-2,:]\\nnormTarget   = target - lastObserved[:target.shape[0],:]  # normalize the target by lastObserved\\nderiv.shape', 'string_': <type 'numpy.string_'>, 'isinf': <ufunc 'isinf'>, 'spacing': <ufunc 'spacing'>, 'Inf': inf, 'ndarray': <type 'numpy.ndarray'>, 'delaxes': <function delaxes at 0x3195398>, 'pcolor': <function pcolor at 0x3197488>, 'e': 2.718281828459045, 'ERR_CALL': 3, 'datetime_data': <built-in function datetime_data>, '_i79': u'X.shape', 'test': array([[ -2.90000000e-01,   2.85714000e-01,   7.00000000e+00, ...,\n          5.15190000e-01,   2.20786000e-01,   2.08753000e-01],\n       [  3.80000000e-01,   1.60000000e+00,   5.00000000e+00, ...,\n          8.83311000e-01,   4.69965000e-01,   5.36563000e-01],\n       [  2.00000000e-02,   1.11111000e-01,   9.00000000e+00, ...,\n          3.90504000e-01,   1.20665000e-01,   1.10905000e-01],\n       ..., \n       [  2.70000000e-01,   3.23529000e-01,   3.40000000e+01, ...,\n          1.79467000e-01,   8.55570000e-02,   8.33330000e-02],\n       [  0.00000000e+00,   2.94117000e-01,   1.70000000e+01, ...,\n          1.95387000e-01,   7.63330000e-02,   6.25390000e-02],\n       [  3.10000000e-01,   1.60000000e+00,   5.00000000e+00, ...,\n          1.05697000e+00,   4.11582000e-01,   4.52769000e-01]]), 'ERR_IGNORE': 0, 'flag': <function flag at 0x3198668>, 'hsplit': <function hsplit at 0x2374e60>, 'result_type': <built-in function result_type>, 'gradient': <function gradient at 0x236c578>, 'base_repr': <function base_repr at 0x21dbc80>, 'eigh': <function eigh at 0x238c938>, 'argwhere': <function argwhere at 0x21c2848>, 'set_string_function': <function set_string_function at 0x21dba28>, 'swapaxes': <function swapaxes at 0x21d1938>, 'FixedLocator': <class 'matplotlib.ticker.FixedLocator'>, '_111': <matplotlib.text.Text object at 0x9894b90>, 'tensorsolve': <function tensorsolve at 0x238c488>}\n   2828             finally:\n   2829                 # Reset our crash handler in place\n   2830                 sys.excepthook = old_excepthook\n   2831         except SystemExit:\n\n...........................................................................\n/home/lane/Kaggle/03 Predicting Stock Prices/<ipython-input-134-831b400e8055> in <module>()\n     27         results.append( err.maeFun(y[testcv], [x[1] for x in probas]) )\n     28 \n     29     performance.append(np.array(results).mean())\n     30 \n     31     # generate predictions (making sure to add last observed value back in)\n---> 32     predicted_probs = [x[1] for x in rf.predict_proba(test)]\n     33     thisColumn      = np.asarray(predicted_probs)\n     34     pred[:,stock]   = thisColumn + lastObserved[200:,stock]\n     35 \n     36     \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, compute_i...=False, random_state=None,\n            verbose=0), X=array([[ -2.89999992e-01,   2.85714000e-01,   7.....11581993e-01,   4.52769011e-01]], dtype=float32))\n    486             delayed(_parallel_predict_proba)(\n    487                 self.estimators_[starts[i]:starts[i + 1]],\n    488                 X,\n    489                 self.n_classes_,\n    490                 self.n_outputs_)\n--> 491             for i in range(n_jobs))\n        n_jobs = 2\n    492 \n    493         # Reduce\n    494         proba = all_proba[0]\n    495 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object <genexpr>>)\n    514         self.n_dispatched = 0\n    515         try:\n    516             for function, args, kwargs in iterable:\n    517                 self.dispatch(function, args, kwargs)\n    518 \n--> 519             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    520             # Make sure that we get a last message telling us we are done\n    521             elapsed_time = time.time() - self._start_time\n    522             self._print('Done %3i out of %3i | elapsed: %s finished',\n    523                         (len(self._output),\n\n    ---------------------------------------------------------------------------\n    Sub-process traceback:\n    ---------------------------------------------------------------------------\n    ValueError                                         Wed Oct  2 10:04:55 2013\nPID: 21086                                    Python 2.7.3: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.pyc in _parallel_predict_proba(trees=[DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f0d8>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f0c0>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f138>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f180>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f150>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f210>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f078>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f0a8>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f090>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f030>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f048>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f108>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f0f0>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f168>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f120>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f228>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f240>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f258>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f270>,\n            splitter='best'), DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f288>,\n            splitter='best'), ...], X=array([[ -2.89999992e-01,   2.85714000e-01,   7.....11581993e-01,   4.52769011e-01]], dtype=float32), n_classes=172, n_outputs=1)\n    115 \n    116     if n_outputs == 1:\n    117         proba = np.zeros((n_samples, n_classes))\n    118 \n    119         for tree in trees:\n--> 120             proba_tree = tree.predict_proba(X)\n    121 \n    122             if n_classes == tree.n_classes_:\n    123                 proba += proba_tree\n    124 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.pyc in predict_proba(self=DecisionTreeClassifier(compute_importances=None,... at 0x7f394dd7f0d8>,\n            splitter='best'), X=array([[ -2.89999992e-01,   2.85714000e-01,   7.....11581993e-01,   4.52769011e-01]], dtype=float32))\n    470 \n    471         if self.n_features_ != n_features:\n    472             raise ValueError(\"Number of features of the model must \"\n    473                              \" match the input. Model n_features is %s and \"\n    474                              \" input n_features is %s \"\n--> 475                              % (self.n_features_, n_features))\n    476 \n    477         proba = self.tree_.predict(X)\n    478 \n    479         if self.n_outputs_ == 1:\n\nValueError: Number of features of the model must  match the input. Model n_features is 1003 and  input n_features is 2197 \n___________________________________________________________________________"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Neural networks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pybrain"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named pybrain",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-121-0fb7233d2a8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpybrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mImportError\u001b[0m: No module named pybrain"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}