{
 "metadata": {
  "name": "",
  "signature": "sha256:a8dc0709cd3eb30465b9331b671a3cdd4b3ef5479ee0b4e04f685a6dfe5a1747"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy.io\n",
      "import itertools\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Retina 1 - Sunrise/sunset experiment"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/lane/00_Baccus/Data\\ 2014_04_28\\ retina1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/lane/00_Baccus/Data 2014_04_28 retina1\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "042814.mat  c03.txt  c06.txt  c09.txt  c12.txt  c15.txt  c18.txt  c21.txt  c24.txt\r\n",
        "c01.txt     c04.txt  c07.txt  c10.txt  c13.txt  c16.txt  c19.txt  c22.txt\r\n",
        "c02.txt     c05.txt  c08.txt  c11.txt  c14.txt  c17.txt  c20.txt  c23.txt\r\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fs = sorted(os.listdir(os.getcwd()))\n",
      "fs = [f for f in fs if f.endswith(\".txt\")]\n",
      "\n",
      "cells1 = []\n",
      "for f in fs:\n",
      "    text_file = open(f, \"r\")\n",
      "    spikes = text_file.read().split('\\r')\n",
      "    cells1.append([float(spike) for spike in spikes if not (not spike)])\n",
      "    \n",
      "    text_file.close()\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Retina 2 - Foggy day experiment"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/lane/00_Baccus/Data\\ 2014_04_28\\ retina2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/lane/00_Baccus/Data 2014_04_28 retina2\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "042814.mat  c02.txt  c04.txt  c06.txt  c08.txt  c10.txt  c12.txt  c14.txt\r\n",
        "c01.txt     c03.txt  c05.txt  c07.txt  c09.txt  c11.txt  c13.txt\r\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fs = sorted(os.listdir(os.getcwd()))\n",
      "fs = [f for f in fs if f.endswith(\".txt\")]\n",
      "\n",
      "cells2 = []\n",
      "for f in fs:\n",
      "    text_file = open(f, \"r\")\n",
      "    spikes = text_file.read().split('\\n')\n",
      "    cells2.append([float(spike) for spike in spikes if not (not spike)])\n",
      "    \n",
      "    text_file.close()\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}