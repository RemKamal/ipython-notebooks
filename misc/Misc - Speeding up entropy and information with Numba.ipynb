{
 "metadata": {
  "name": "",
  "signature": "sha256:24d5c75de5cd9fadb7b47ff074fe5b38516945188c65100eb59c24c3af1c6155"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numba"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from timeit import default_timer as timer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def entropy(x, Bins=10):\n",
      "    '''Function to compute the entropy of a random variable x.  \n",
      "    \n",
      "    x should be samples by dimensions.  x also needs to be an array, so you could use asarray(x) \n",
      "    if you encounter errors.\n",
      "\n",
      "    Bins can either be the number of bins (either one number to apply to all dimensions, or a sequence\n",
      "    of nBins for each dimension), or can be a sequence of arrays of the bin edges along each dimension.\n",
      "    \n",
      "    I have also found that the smoothness of the estimate becomes better with more bins, since\n",
      "    you get artifacts when a random variable moves into another bin whenever you sample.'''\n",
      "    \n",
      "\n",
      "    Counts, edges = np.histogramdd(x, bins=Bins)\n",
      "    Probs         = Counts.astype(float)/float(sum(Counts))\n",
      "    \n",
      "    if abs(1 - sum(Probs)) > 0.01:\n",
      "        print 'Probabilities do not sum to one ' + str(sum(Probs))\n",
      "    \n",
      "    H = 0.0\n",
      "    for p in Probs.flat:\n",
      "        if p != 0:\n",
      "            H = H - p * log2(p)\n",
      "            \n",
      "    return H"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = timer()\n",
      "x = entropy(randn(10e3,5))\n",
      "dt = timer() - start\n",
      "print 'Completed in %f s' %dt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Completed in 0.089545 s\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Now with Numba"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numba import autojit\n",
      "\n",
      "@autojit\n",
      "def entropy(x, Bins=10):\n",
      "    '''Function to compute the entropy of a random variable x.  \n",
      "    \n",
      "    x should be samples by dimensions.  x also needs to be an array, so you could use asarray(x) \n",
      "    if you encounter errors.\n",
      "\n",
      "    Bins can either be the number of bins (either one number to apply to all dimensions, or a sequence\n",
      "    of nBins for each dimension), or can be a sequence of arrays of the bin edges along each dimension.\n",
      "    \n",
      "    I have also found that the smoothness of the estimate becomes better with more bins, since\n",
      "    you get artifacts when a random variable moves into another bin whenever you sample.'''\n",
      "    \n",
      "\n",
      "    Counts, edges = np.histogramdd(x, bins=Bins)\n",
      "    Probs         = Counts.astype(float)/float(sum(Counts))\n",
      "    \n",
      "    if abs(1 - sum(Probs)) > 0.01:\n",
      "        print 'Probabilities do not sum to one ' + str(sum(Probs))\n",
      "    \n",
      "    H = 0.0\n",
      "    for p in Probs.flat:\n",
      "        if p != 0:\n",
      "            H = H - p * log2(p)\n",
      "            \n",
      "    return H"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = timer()\n",
      "x = entropy(randn(10e3,5), 10)\n",
      "dt = timer() - start\n",
      "print 'Completed in %f s' %dt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Completed in 0.431720 s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Library/Frameworks/EPD64.framework/Versions/7.3/lib/python2.7/site-packages/numba/dataflow.py:276: RuntimeWarning: Python2 style print partially supported.  Please use Python3 style print.\n",
        "  \"Python3 style print.\", RuntimeWarning)\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Still slower! Note that this this ends up being faster, you can put it in a script as autojit(entropy)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Experimenting with pyCUDA again"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pycuda"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pycuda.driver as cuda"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named _driver",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-18-b2dd91e7bf60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Users/lmcintosh/Git/pycuda/pycuda/driver.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_driver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"_v2\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: No module named _driver"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}