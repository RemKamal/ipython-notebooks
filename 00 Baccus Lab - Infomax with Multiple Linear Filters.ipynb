{
 "metadata": {
  "name": "",
  "signature": "sha256:579576a2dbd643d7439de7cbdda75326f6b3d692c24a7175e9295b13841781ca"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy.interpolate import interp1d\n",
      "from scipy.signal import fftconvolve\n",
      "#from numpy import fft\n",
      "from scipy import fft, arange\n",
      "from scipy.stats import sem\n",
      "from random import randint\n",
      "from cmath import polar\n",
      "from numpy.fft import fft2\n",
      "from numpy.fft import fftshift\n",
      "\n",
      "from lnl_model_functions import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import brewer2mpl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from info_theory_functions import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Select image directory"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#im_path = '/Users/lmcintosh/Documents/Natural_Images/RawData/cd13A' # flood plain, water, horizon\n",
      "#im_path = '/Volumes/Lane/RawData/cd13A' # flood plain, water, horizon\n",
      "#im_path = '/Volumes/Lane/RawData/cd01A' # baboons, trees, bushes\n",
      "im_path = '/Users/lmcintosh/Documents/Natural_Images/imc'\n",
      "#im_path = '/home/lane/Natural_images/imc'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls -1 $im_path | wc -l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     400\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Functions for loading images"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_images(path, numImages, patchSize=None, acceptedExtensions=['.imc','LUM.mat'], square=False):\n",
      "    from os import listdir\n",
      "    from os.path import isfile, join\n",
      "    import array as ar\n",
      "    import scipy.io\n",
      "    \n",
      "    allfiles = []\n",
      "    for ext in acceptedExtensions:\n",
      "        allfiles = allfiles + [f for f in listdir(path) if isfile(join(path,f)) and ext in f]\n",
      "    if len(allfiles) < numImages:\n",
      "        print 'Only ' + str(len(allfiles)) + ' files in directory.'\n",
      "    names    = allfiles[:numImages]\n",
      "    patches  = []\n",
      "\n",
      "    for im in names:\n",
      "        if '.imc' in im:\n",
      "            fin = open(path+'/'+im, 'rb')\n",
      "            s   = fin.read()\n",
      "            fin.close()\n",
      "            arr = ar.array('H', s)\n",
      "            arr.byteswap()\n",
      "            img = np.array(arr, dtype='uint16').reshape(1024,1536)\n",
      "        elif '.mat' in im:\n",
      "            fin = scipy.io.loadmat(path+'/'+im)\n",
      "            arr = fin['LUM_Image']\n",
      "            # make 0 to 255\n",
      "            arr = arr - min(arr.flat)\n",
      "            arr = 255.*arr/max(arr.flat)\n",
      "            img = np.array(arr, dtype='uint16')\n",
      "            \n",
      "        # make patches\n",
      "        if patchSize:\n",
      "            img_center = [np.shape(img)[0]/2,np.shape(img)[1]/2]\n",
      "            img        = img[img_center[0]-patchSize/2:img_center[0]+patchSize/2,img_center[1]-patchSize/2:img_center[1]+patchSize/2]\n",
      "            \n",
      "        if square:\n",
      "            N = min(shape(img))\n",
      "            N = N - (N % 2) # make even\n",
      "            img = img[:N,:N]\n",
      "        \n",
      "        # normalize to unit variance and zero mean\n",
      "        img        = img/np.sqrt(np.var(img))\n",
      "        patches.append(img - np.mean(img))\n",
      "\n",
      "    return patches"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Load image dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numImages = 400\n",
      "patchSize = None\n",
      "pixelsToDeg = 92./2\n",
      "averageGanglionSize = 1.5*pixelsToDeg+1 # in pixels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patches = load_images(im_path, numImages, patchSize, square=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# # fix center to 0.25, vary surround [0.5, 1, 2]\n",
      "# sfilter1 = [spatial_filter_2d(c_width=0.25, s_width=s, xs_num=averageGanglionSize) for s in [0.375, 0.5, 1., 2.]]\n",
      "# sfilter2 = [spatial_filter_2d(c_width=0.25, s_width=s, xs_num=averageGanglionSize) for s in [0.375, 0.5, 1., 2.]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Define noise model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def noise_var(m, w):\n",
      "    '''INPUT: m is mean, w is standard deviation\n",
      "       OUTPUT: variance of noise'''\n",
      "    contrast = w/m\n",
      "    snr = 15.1*contrast + 2.06\n",
      "    return (w**2)/snr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Define coefficients"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gaussian2d(xs, sigma):\n",
      "    '''Returns 2d symmetric Gaussian'''\n",
      "    p = gaussian(x=xs, sigma=sigma)\n",
      "    p_2d = zeros((len(p),len(p)))\n",
      "    for idx,x in enumerate(xs):\n",
      "        for idy,y in enumerate(xs):\n",
      "            p_2d[idx,idy] = p[np.min([int(np.sqrt((idx-np.floor(len(xs)/2.))**2 \n",
      "                                                     + (idy-np.floor(len(xs)/2.))**2) + np.floor(len(xs)/2.)), len(xs)-1])]\n",
      "    return p_2d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def coeff(centerStrength, centerSize, horzStrength, horzSize, amaStrength, amaSize, receptiveFieldSize=averageGanglionSize):\n",
      "    '''Compute 2d linear coefficients for receptive field. Arguments are strength\n",
      "    and size of excitatory center, horizontal surround, and amacrine surround.\n",
      "    ASSUMPTIONS: each contribution is a spherically symmetrical gaussian.'''\n",
      "    x = np.linspace(-10,10,receptiveFieldSize)\n",
      "    return centerStrength*gaussian2d(xs=x, sigma=centerSize) \\\n",
      "                - horzStrength*gaussian2d(xs=x, sigma=horzSize) \\\n",
      "                - amaStrength*gaussian2d(xs=x, sigma=amaSize)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exampleRF = coeff(centerStrength=1., centerSize=0.25, horzStrength=0.8, horzSize=1., amaStrength=0.2, amaSize=0.5)\n",
      "plot(exampleRF[averageGanglionSize//2,:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "[<matplotlib.lines.Line2D at 0x10df67d50>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGsTQl6QG+X8rg3BcdfASgwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10fd7ead0>"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Define objective function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def objective(coeff, images):\n",
      "    filteredImages = [fftconvolve(im, coeff, mode='same') for im in images]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Info computation takes way too long and too much memory, even using nearest neighbors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "infoBetweenTwoImages = nnInfo(patches[0].flatten(),patches[1].flatten())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}